[
  {
    "title": "Redis documentation",
    "source": "https://github.com/redis/redis-doc/tree/master/",
    "content": "Redis documentation\nClients\nAll clients are listed under language specific sub-folders of clients\nThe path follows the pattern: `clients/{language}/github.com/{owner}/{repository}.json`.\nThe `{language}` component of the path is the path-safe representation\nof the full language name which is mapped in languages.json.\nEach client's JSON object represents the details displayed on the clients documentation page.\nFor example clients/python/github.com/redis:\n`{\n    \"name\": \"redis-py\",\n    \"description\": \"Mature and supported. Currently the way to go for Python.\",\n    \"recommended\": true\n}`\nCommands\nRedis commands are described in the `commands.json` file that is auto generated\nfrom the Redis repo based on the JSON files in the commands folder.\nSee: https://github.com/redis/redis/tree/unstable/src/commands\nSee: https://github.com/redis/redis/tree/unstable/utils/generate-commands-json.py\nFor each command there's a Markdown file with a complete, human-readable\ndescription.\nWe process this Markdown to provide a better experience, so some things to take\ninto account:\n\n\nInside text, all commands should be written in all caps, in between\n    backticks.\n    For example: `INCR`.\n\n\nYou can use some magic keywords to name common elements in Redis.\n    For example: `@multi-bulk-reply`.\n    These keywords will get expanded and auto-linked to relevant parts of the\n    documentation.\n\n\nThere should be at least two predefined sections: description and return value.\nThe return value section is marked using the @return keyword:\n```\nReturns all keys matching the given pattern.\n@return\n@multi-bulk-reply: all the keys that matched the pattern.\n```\nStyling guidelines\nPlease use the following formatting rules (aiming for smaller diffs that are easier to review):\n\nNo need for manual lines wrapping at any specific length,\n  doing so usually means that adding a word creates a cascade effect and changes other lines.\nPlease avoid writing lines that are too long,\n  this makes the diff harder to review when only one word is changed. \nStart every sentence on a new line.\n\nChecking your work\nAfter making changes to the documentation, you can use the spellchecker-cli package to validate your spelling as well as some minor grammatical errors. You can install the spellchecker locally by running:\n`bash\nnpm install --global spellchecker-cli`\nYou can than validate your spelling by running the following\n`spellchecker --no-suggestions -f '**/*.md' -l en-US -q -d wordlist`",
    "tag": "redis"
  },
  {
    "title": "Command line usage",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/ui/cli.md",
    "content": "\ntitle: \"Redis CLI\"\nlinkTitle: \"CLI\"\nweight: 1\ndescription: >\n    Overview of redis-cli, the Redis command line interface\naliases:\n    - /docs/manual/cli\n    - /docs/management/cli\n\nIn interactive mode, `redis-cli` has basic line editing capabilities to provide a familiar typing experience.\nTo launch the program in special modes, you can use several options, including:\n\nSimulate a replica and print the replication stream it receives from the primary.\nCheck the latency of a Redis server and display statistics. \nRequest ASCII-art spectrogram of latency samples and frequencies.\n\nThis topic covers the different aspects of `redis-cli`, starting from the simplest and ending with the more advanced features.\nCommand line usage\nTo run a Redis command and return a standard output at the terminal, include the command to execute as separate arguments of `redis-cli`:\n\n\n```$ redis-cli INCR mycounter\n(integer) 7\n```\n\n\nThe reply of the command is \"7\". Since Redis replies are typed (strings, arrays, integers, nil, errors, etc.), you see the type of the reply between parentheses. This additional information may not be ideal when the output of `redis-cli` must be used as input of another command or redirected into a file.\n`redis-cli` only shows additional information for human readability when it detects the standard output is a tty, or terminal. For all other outputs it will auto-enable the raw output mode, as in the following example:\n\n\n```$ redis-cli INCR mycounter > /tmp/output.txt\n$ cat /tmp/output.txt\n8\n```\n\n\nNote that `(integer)` is omitted from the output because `redis-cli` detects\nthe output is no longer written to the terminal. You can force raw output\neven on the terminal with the `--raw` option:\n\n\n```$ redis-cli --raw INCR mycounter\n9\n```\n\n\nYou can force human readable output when writing to a file or in\npipe to other commands by using `--no-raw`.\nString quoting and escaping\nWhen `redis-cli` parses a command, whitespace characters automatically delimit the arguments.\nIn interactive mode, a newline sends the command for parsing and execution.\nTo input string values that contain whitespaces or non-printable characters, you can use quoted and escaped strings.\nQuoted string values are enclosed in double (`\"`) or single (`'`) quotation marks.\nEscape sequences are used to put nonprintable characters in character and string literals.\nAn escape sequence contains a backslash (`\\`) symbol followed by one of the escape sequence characters.\nDoubly-quoted strings support the following escape sequences:\n\n`\\\"` - double-quote\n`\\n` - newline\n`\\r` - carriage return\n`\\t` - horizontal tab\n`\\b` - backspace\n`\\a` - alert\n`\\\\` - backslash\n`\\xhh` - any ASCII character represented by a hexadecimal number (hh)\n\nSingle quotes assume the string is literal, and allow only the following escape sequences:\n* `\\'` - single quote\n* `\\\\` - backslash\nFor example, to return `Hello World` on two lines:\n`127.0.0.1:6379> SET mykey \"Hello\\nWorld\"\nOK\n127.0.0.1:6379> GET mykey\nHello\nWorld`\nWhen you input strings that contain single or double quotes, as you might in passwords, for example, escape the string, like so: \n`127.0.0.1:6379> AUTH some_admin_user \">^8T>6Na{u|jp>+v\\\"55\\@_;OU(OR]7mbAYGqsfyu48(j'%hQH7;v*f1H${*gD(Se'\"`\nHost, port, password, and database\nBy default, `redis-cli` connects to the server at the address 127.0.0.1 with port 6379.\nYou can change the port using several command line options. To specify a different host name or an IP address, use the `-h` option. In order to set a different port, use `-p`.\n\n\n```$ redis-cli -h redis15.localnet.org -p 6390 PING\nPONG\n```\n\n\nIf your instance is password protected, the `-a <password>` option will\nperform authentication saving the need of explicitly using the `AUTH` command:\n\n\n```$ redis-cli -a myUnguessablePazzzzzword123 PING\nPONG\n```\n\n\nNOTE: For security reasons, provide the password to `redis-cli` automatically via the\n`REDISCLI_AUTH` environment variable.\nFinally, it's possible to send a command that operates on a database number\nother than the default number zero by using the `-n <dbnum>` option:\n\n\n```$ redis-cli FLUSHALL\nOK\n$ redis-cli -n 1 INCR a\n(integer) 1\n$ redis-cli -n 1 INCR a\n(integer) 2\n$ redis-cli -n 2 INCR a\n(integer) 1\n```\n\n\nSome or all of this information can also be provided by using the `-u <uri>`\noption and the URI pattern `redis://user:password@host:port/dbnum`:\n\n\n```$ redis-cli -u redis://LJenkins:p%40ssw0rd@redis-16379.hosted.com:16379/0 PING\nPONG\n```\n\n\nSSL/TLS\nBy default, `redis-cli` uses a plain TCP connection to connect to Redis.\nYou may enable SSL/TLS using the `--tls` option, along with `--cacert` or\n`--cacertdir` to configure a trusted root certificate bundle or directory.\nIf the target server requires authentication using a client side certificate,\nyou can specify a certificate and a corresponding private key using `--cert` and\n`--key`.\nGetting input from other programs\nThere are two ways you can use `redis-cli` in order to receive input from other\ncommands via the standard input. One is to use the target payload as the last argument\nfrom stdin. For example, in order to set the Redis key `net_services`\nto the content of the file `/etc/services` from a local file system, use the `-x`\noption:\n\n\n```$ redis-cli -x SET net_services < /etc/services\nOK\n$ redis-cli GETRANGE net_services 0 50\n\"#\\n# Network services, Internet style\\n#\\n# Note that \"\n```\n\n\nIn the first line of the above session, `redis-cli` was executed with the `-x` option and a file was redirected to the CLI's\nstandard input as the value to satisfy the `SET net_services` command phrase. This is useful for scripting.\nA different approach is to feed `redis-cli` a sequence of commands written in a\ntext file:\n\n\n```$ cat /tmp/commands.txt\nSET item:3374 100\nINCR item:3374\nAPPEND item:3374 xxx\nGET item:3374\n$ cat /tmp/commands.txt | redis-cli\nOK\n(integer) 101\n(integer) 6\n\"101xxx\"\n```\n\n\nAll the commands in `commands.txt` are executed consecutively by\n`redis-cli` as if they were typed by the user in interactive mode. Strings can be\nquoted inside the file if needed, so that it's possible to have single\narguments with spaces, newlines, or other special characters:\n\n\n```$ cat /tmp/commands.txt\nSET arg_example \"This is a single argument\"\nSTRLEN arg_example\n$ cat /tmp/commands.txt | redis-cli\nOK\n(integer) 25\n```\n\n\nContinuously run the same command\nIt is possible to execute a single command a specified number of times\nwith a user-selected pause between executions. This is useful in\ndifferent contexts - for example when we want to continuously monitor some\nkey content or `INFO` field output, or when we want to simulate some\nrecurring write event, such as pushing a new item into a list every 5 seconds.\nThis feature is controlled by two options: `-r <count>` and `-i <delay>`.\nThe `-r` option states how many times to run a command and `-i` sets\nthe delay between the different command calls in seconds (with the ability\nto specify values such as 0.1 to represent 100 milliseconds).\nBy default the interval (or delay) is set to 0, so commands are just executed\nASAP:\n\n\n```$ redis-cli -r 5 INCR counter_value\n(integer) 1\n(integer) 2\n(integer) 3\n(integer) 4\n(integer) 5\n```\n\n\nTo run the same command indefinitely, use `-1` as the count value.\nTo monitor over time the RSS memory size it's possible to use the following command:\n\n\n```$ redis-cli -r -1 -i 1 INFO | grep rss_human\nused_memory_rss_human:2.71M\nused_memory_rss_human:2.73M\nused_memory_rss_human:2.73M\nused_memory_rss_human:2.73M\n... a new line will be printed each second ...\n```\n\n\nMass insertion of data using `redis-cli`\nMass insertion using `redis-cli` is covered in a separate page as it is a\nworthwhile topic itself. Please refer to our mass insertion guide.\nCSV output\nA CSV (Comma Separated Values) output feature exists within `redis-cli` to export data from Redis to an external program.  \n\n\n```$ redis-cli LPUSH mylist a b c d\n(integer) 4\n$ redis-cli --csv LRANGE mylist 0 -1\n\"d\",\"c\",\"b\",\"a\"\n```\n\n\nNote that the `--csv` flag will only work on a single command, not the entirety of a DB as an export.\nRunning Lua scripts\nThe `redis-cli` has extensive support for using the debugging facility\nof Lua scripting, available with Redis 3.2 onwards. For this feature, refer to the Redis Lua debugger documentation.\nEven without using the debugger, `redis-cli` can be used to\nrun scripts from a file as an argument:\n\n\n```$ cat /tmp/script.lua\nreturn redis.call('SET',KEYS[1],ARGV[1])\n$ redis-cli --eval /tmp/script.lua location:hastings:temp , 23\nOK\n```\n\n\nThe Redis `EVAL` command takes the list of keys the script uses, and the\nother non key arguments, as different arrays. When calling `EVAL` you\nprovide the number of keys as a number. \nWhen calling `redis-cli` with the `--eval` option above, there is no need to specify the number of keys\nexplicitly. Instead it uses the convention of separating keys and arguments\nwith a comma. This is why in the above call you see `location:hastings:temp , 23` as arguments.\nSo `location:hastings:temp` will populate the `KEYS` array, and `23` the `ARGV` array.\nThe `--eval` option is useful when writing simple scripts. For more\ncomplex work, the Lua debugger is recommended. It is possible to mix the two approaches, since the debugger can also execute scripts from an external file.\nInteractive mode\nWe have explored how to use the Redis CLI as a command line program.\nThis is useful for scripts and certain types of testing, however most\npeople will spend the majority of time in `redis-cli` using its interactive\nmode.\nIn interactive mode the user types Redis commands at the prompt. The command\nis sent to the server, processed, and the reply is parsed back and rendered\ninto a simpler form to read.\nNothing special is needed for running the `redis-cli` in interactive mode -\njust execute it without any arguments\n\n\n```$ redis-cli\n127.0.0.1:6379> PING\nPONG\n```\n\n\nThe string `127.0.0.1:6379>` is the prompt. It displays the connected Redis server instance's hostname and port.\nThe prompt updates as the connected server changes or when operating on a database different from the database number zero:\n\n\n```127.0.0.1:6379> SELECT 2\nOK\n127.0.0.1:6379[2]> DBSIZE\n(integer) 1\n127.0.0.1:6379[2]> SELECT 0\nOK\n127.0.0.1:6379> DBSIZE\n(integer) 503\n```\n\n\nHandling connections and reconnections\nUsing the `CONNECT` command in interactive mode makes it possible to connect\nto a different instance, by specifying the hostname and port we want\nto connect to:\n\n\n```127.0.0.1:6379> CONNECT metal 6379\nmetal:6379> PING\nPONG\n```\n\n\nAs you can see the prompt changes accordingly when connecting to a different server instance.\nIf a connection is attempted to an instance that is unreachable, the `redis-cli` goes into disconnected\nmode and attempts to reconnect with each new command:\n\n\n```127.0.0.1:6379> CONNECT 127.0.0.1 9999\nCould not connect to Redis at 127.0.0.1:9999: Connection refused\nnot connected> PING\nCould not connect to Redis at 127.0.0.1:9999: Connection refused\nnot connected> PING\nCould not connect to Redis at 127.0.0.1:9999: Connection refused\n```\n\n\nGenerally after a disconnection is detected, `redis-cli` always attempts to\nreconnect transparently; if the attempt fails, it shows the error and\nenters the disconnected state. The following is an example of disconnection\nand reconnection:\n\n\n```127.0.0.1:6379> INFO SERVER\nCould not connect to Redis at 127.0.0.1:6379: Connection refused\nnot connected> PING\nPONG\n127.0.0.1:6379> \n(now we are connected again)\n```\n\n\nWhen a reconnection is performed, `redis-cli` automatically re-selects the\nlast database number selected. However, all other states about the\nconnection is lost, such as within a MULTI/EXEC transaction:\n\n\n```$ redis-cli\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> PING\nQUEUED\n\n( here the server is manually restarted )\n\n127.0.0.1:6379> EXEC\n(error) ERR EXEC without MULTI\n```\n\n\nThis is usually not an issue when using the `redis-cli` in interactive mode for\ntesting, but this limitation should be known.\nEditing, history, completion and hints\nBecause `redis-cli` uses the\nlinenoise line editing library, it\nalways has line editing capabilities, without depending on `libreadline` or\nother optional libraries.\nCommand execution history can be accessed in order to avoid retyping commands by pressing the arrow keys (up and down).\nThe history is preserved between restarts of the CLI, in a file named\n`.rediscli_history` inside the user home directory, as specified\nby the `HOME` environment variable. It is possible to use a different\nhistory filename by setting the `REDISCLI_HISTFILE` environment variable,\nand disable it by setting it to `/dev/null`.\nThe `redis-cli` is also able to perform command-name completion by pressing the TAB\nkey, as in the following example:\n\n\n```127.0.0.1:6379> Z<TAB>\n127.0.0.1:6379> ZADD<TAB>\n127.0.0.1:6379> ZCARD<TAB>\n```\n\n\nOnce Redis command name has been entered at the prompt, the `redis-cli` will display\nsyntax hints. Like command history, this behavior can be turned on and off via the `redis-cli` preferences.\nPreferences\nThere are two ways to customize `redis-cli` behavior. The file `.redisclirc`\nin the home directory is loaded by the CLI on startup. You can override the\nfile's default location by setting the `REDISCLI_RCFILE` environment variable to\nan alternative path. Preferences can also be set during a CLI session, in which \ncase they will last only the duration of the session.\nTo set preferences, use the special `:set` command. The following preferences\ncan be set, either by typing the command in the CLI or adding it to the\n`.redisclirc` file:\n\n`:set hints` - enables syntax hints\n`:set nohints` - disables syntax hints\n\nRunning the same command N times\nIt is possible to run the same command multiple times in interactive mode by prefixing the command\nname by a number:\n\n\n```127.0.0.1:6379> 5 INCR mycounter\n(integer) 1\n(integer) 2\n(integer) 3\n(integer) 4\n(integer) 5\n```\n\n\nShowing help about Redis commands\n`redis-cli` provides online help for most Redis commands, using the `HELP` command. The command can be used\nin two forms:\n\n`HELP @<category>` shows all the commands about a given category. The\ncategories are: \n`@generic`\n`@string`\n`@list`\n`@set`\n`@sorted_set`\n`@hash`\n`@pubsub`\n`@transactions`\n`@connection`\n`@server`\n`@scripting`\n`@hyperloglog`\n`@cluster`\n`@geo`\n`@stream`\n\n\n`HELP <commandname>` shows specific help for the command given as argument.\n\nFor example in order to show help for the `PFADD` command, use:\n\n\n```127.0.0.1:6379> HELP PFADD\n\nPFADD key element [element ...]\nsummary: Adds the specified elements to the specified HyperLogLog.\nsince: 2.8.9\n```\n\n\nNote that `HELP` supports TAB completion as well.\nClearing the terminal screen\nUsing the `CLEAR` command in interactive mode clears the terminal's screen.\nSpecial modes of operation\nSo far we saw two main modes of `redis-cli`.\n\nCommand line execution of Redis commands.\nInteractive \"REPL\" usage.\n\nThe CLI performs other auxiliary tasks related to Redis that\nare explained in the next sections:\n\nMonitoring tool to show continuous stats about a Redis server.\nScanning a Redis database for very large keys.\nKey space scanner with pattern matching.\nActing as a Pub/Sub client to subscribe to channels.\nMonitoring the commands executed into a Redis instance.\nChecking the latency of a Redis server in different ways.\nChecking the scheduler latency of the local computer.\nTransferring RDB backups from a remote Redis server locally.\nActing as a Redis replica for showing what a replica receives.\nSimulating LRU workloads for showing stats about keys hits.\nA client for the Lua debugger.\n\nContinuous stats mode\nContinuous stats mode is probably one of the lesser known yet very useful features of `redis-cli` to monitor Redis instances in real time. To enable this mode, the `--stat` option is used.\nThe output is very clear about the behavior of the CLI in this mode:\n\n\n```$ redis-cli --stat\n------- data ------ --------------------- load -------------------- - child -\nkeys       mem      clients blocked requests            connections\n506        1015.00K 1       0       24 (+0)             7\n506        1015.00K 1       0       25 (+1)             7\n506        3.40M    51      0       60461 (+60436)      57\n506        3.40M    51      0       146425 (+85964)     107\n507        3.40M    51      0       233844 (+87419)     157\n507        3.40M    51      0       321715 (+87871)     207\n508        3.40M    51      0       408642 (+86927)     257\n508        3.40M    51      0       497038 (+88396)     257\n```\n\n\nIn this mode a new line is printed every second with useful information and differences of request values between old data points. Memory usage, client connection counts, and various other statistics about the connected Redis database can be easily understood with this auxiliary `redis-cli` tool.\nThe `-i <interval>` option in this case works as a modifier in order to\nchange the frequency at which new lines are emitted. The default is one\nsecond.\nScanning for big keys\nIn this special mode, `redis-cli` works as a key space analyzer. It scans the\ndataset for big keys, but also provides information about the data types\nthat the data set consists of. This mode is enabled with the `--bigkeys` option,\nand produces verbose output:\n\n\n```$ redis-cli --bigkeys\n\n# Scanning the entire keyspace to find biggest keys as well as\n# average sizes per key type.  You can use -i 0.01 to sleep 0.01 sec\n# per SCAN command (not usually needed).\n\n[00.00%] Biggest string found so far 'key-419' with 3 bytes\n[05.14%] Biggest list   found so far 'mylist' with 100004 items\n[35.77%] Biggest string found so far 'counter:__rand_int__' with 6 bytes\n[73.91%] Biggest hash   found so far 'myobject' with 3 fields\n\n-------- summary -------\n\nSampled 506 keys in the keyspace!\nTotal key length in bytes is 3452 (avg len 6.82)\n\nBiggest string found 'counter:__rand_int__' has 6 bytes\nBiggest   list found 'mylist' has 100004 items\nBiggest   hash found 'myobject' has 3 fields\n\n504 strings with 1403 bytes (99.60% of keys, avg size 2.78)\n1 lists with 100004 items (00.20% of keys, avg size 100004.00)\n0 sets with 0 members (00.00% of keys, avg size 0.00)\n1 hashs with 3 fields (00.20% of keys, avg size 3.00)\n0 zsets with 0 members (00.00% of keys, avg size 0.00)\n```\n\n\nIn the first part of the output, each new key larger than the previous larger\nkey (of the same type) encountered is reported. The summary section\nprovides general stats about the data inside the Redis instance.\nThe program uses the `SCAN` command, so it can be executed against a busy\nserver without impacting the operations, however the `-i` option can be\nused in order to throttle the scanning process of the specified fraction\nof second for each `SCAN` command. \nFor example, `-i 0.01` will slow down the program execution considerably, but will also reduce the load on the server\nto a negligible amount.\nNote that the summary also reports in a cleaner form the biggest keys found\nfor each time. The initial output is just to provide some interesting info\nASAP if running against a very large data set.\nGetting a list of keys\nIt is also possible to scan the key space, again in a way that does not\nblock the Redis server (which does happen when you use a command\nlike `KEYS *`), and print all the key names, or filter them for specific\npatterns. This mode, like the `--bigkeys` option, uses the `SCAN` command,\nso keys may be reported multiple times if the dataset is changing, but no\nkey would ever be missing, if that key was present since the start of the\niteration. Because of the command that it uses this option is called `--scan`.\n\n\n```$ redis-cli --scan | head -10\nkey-419\nkey-71\nkey-236\nkey-50\nkey-38\nkey-458\nkey-453\nkey-499\nkey-446\nkey-371\n```\n\n\nNote that `head -10` is used in order to print only the first ten lines of the\noutput.\nScanning is able to use the underlying pattern matching capability of\nthe `SCAN` command with the `--pattern` option.\n\n\n```$ redis-cli --scan --pattern '*-11*'\nkey-114\nkey-117\nkey-118\nkey-113\nkey-115\nkey-112\nkey-119\nkey-11\nkey-111\nkey-110\nkey-116\n```\n\n\nPiping the output through the `wc` command can be used to count specific\nkind of objects, by key name:\n\n\n```$ redis-cli --scan --pattern 'user:*' | wc -l\n3829433\n```\n\n\nYou can use `-i 0.01` to add a delay between calls to the `SCAN` command.\nThis will make the command slower but will significantly reduce load on the server.\nPub/sub mode\nThe CLI is able to publish messages in Redis Pub/Sub channels using\nthe `PUBLISH` command. Subscribing to channels in order to receive\nmessages is different - the terminal is blocked and waits for\nmessages, so this is implemented as a special mode in `redis-cli`. Unlike\nother special modes this mode is not enabled by using a special option,\nbut simply by using the `SUBSCRIBE` or `PSUBSCRIBE` command, which are available in\ninteractive or command mode:\n\n\n```$ redis-cli PSUBSCRIBE '*'\nReading messages... (press Ctrl-C to quit)\n1) \"PSUBSCRIBE\"\n2) \"*\"\n3) (integer) 1\n```\n\n\nThe reading messages message shows that we entered Pub/Sub mode.\nWhen another client publishes some message in some channel, such as with the command `redis-cli PUBLISH mychannel mymessage`, the CLI in Pub/Sub mode will show something such as:\n\n\n```1) \"pmessage\"\n2) \"*\"\n3) \"mychannel\"\n4) \"mymessage\"\n```\n\n\nThis is very useful for debugging Pub/Sub issues.\nTo exit the Pub/Sub mode just process `CTRL-C`.\nMonitoring commands executed in Redis\nSimilarly to the Pub/Sub mode, the monitoring mode is entered automatically\nonce you use the `MONITOR` command. All commands received by the active Redis instance will be printed to the standard output:\n\n\n```$ redis-cli MONITOR\nOK\n1460100081.165665 [0 127.0.0.1:51706] \"set\" \"shipment:8000736522714:status\" \"sorting\"\n1460100083.053365 [0 127.0.0.1:51707] \"get\" \"shipment:8000736522714:status\"\n```\n\n\nNote that it is possible to use to pipe the output, so you can monitor\nfor specific patterns using tools such as `grep`.\nMonitoring the latency of Redis instances\nRedis is often used in contexts where latency is very critical. Latency\ninvolves multiple moving parts within the application, from the client library\nto the network stack, to the Redis instance itself.\nThe `redis-cli` has multiple facilities for studying the latency of a Redis\ninstance and understanding the latency's maximum, average and distribution.\nThe basic latency-checking tool is the `--latency` option. Using this\noption the CLI runs a loop where the `PING` command is sent to the Redis\ninstance and the time to receive a reply is measured. This happens 100\ntimes per second, and stats are updated in a real time in the console:\n\n\n```$ redis-cli --latency\nmin: 0, max: 1, avg: 0.19 (427 samples)\n```\n\n\nThe stats are provided in milliseconds. Usually, the average latency of\na very fast instance tends to be overestimated a bit because of the\nlatency due to the kernel scheduler of the system running `redis-cli`\nitself, so the average latency of 0.19 above may easily be 0.01 or less.\nHowever this is usually not a big problem, since most developers are interested in\nevents of a few milliseconds or more.\nSometimes it is useful to study how the maximum and average latencies\nevolve during time. The `--latency-history` option is used for that\npurpose: it works exactly like `--latency`, but every 15 seconds (by\ndefault) a new sampling session is started from scratch:\n\n\n```$ redis-cli --latency-history\nmin: 0, max: 1, avg: 0.14 (1314 samples) -- 15.01 seconds range\nmin: 0, max: 1, avg: 0.18 (1299 samples) -- 15.00 seconds range\nmin: 0, max: 1, avg: 0.20 (113 samples)^C\n```\n\n\nSampling sessions' length can be changed with the `-i <interval>` option.\nThe most advanced latency study tool, but also the most complex to\ninterpret for non-experienced users, is the ability to use color terminals\nto show a spectrum of latencies. You'll see a colored output that indicates the\ndifferent percentages of samples, and different ASCII characters that indicate\ndifferent latency figures. This mode is enabled using the `--latency-dist`\noption:\n\n\n```$ redis-cli --latency-dist\n(output not displayed, requires a color terminal, try it!)\n```\n\n\nThere is another pretty unusual latency tool implemented inside `redis-cli`.\nIt does not check the latency of a Redis instance, but the latency of the\ncomputer running `redis-cli`. This latency is intrinsic to the kernel scheduler, \nthe hypervisor in case of virtualized instances, and so forth.\nRedis calls it intrinsic latency because it's mostly opaque to the programmer.\nIf the Redis instance has high latency regardless of all the obvious things\nthat may be the source cause, it's worth to check what's the best your system\ncan do by running `redis-cli` in this special mode directly in the system you\nare running Redis servers on.\nBy measuring the intrinsic latency, you know that this is the baseline,\nand Redis cannot outdo your system. In order to run the CLI\nin this mode, use the `--intrinsic-latency <test-time>`. Note that the test time is in seconds and dictates how long the test should run.\n\n\n```$ ./redis-cli --intrinsic-latency 5\nMax latency so far: 1 microseconds.\nMax latency so far: 7 microseconds.\nMax latency so far: 9 microseconds.\nMax latency so far: 11 microseconds.\nMax latency so far: 13 microseconds.\nMax latency so far: 15 microseconds.\nMax latency so far: 34 microseconds.\nMax latency so far: 82 microseconds.\nMax latency so far: 586 microseconds.\nMax latency so far: 739 microseconds.\n\n65433042 total runs (avg latency: 0.0764 microseconds / 764.14 nanoseconds per run).\nWorst run took 9671x longer than the average latency.\n```\n\n\nIMPORTANT: this command must be executed on the computer that runs the Redis server instance, not on a different host. It does not connect to a Redis instance and performs the test locally.\nIn the above case, the system cannot do better than 739 microseconds of worst\ncase latency, so one can expect certain queries to occasionally run less than 1 millisecond.\nRemote backups of RDB files\nDuring a Redis replication's first synchronization, the primary and the replica\nexchange the whole data set in the form of an RDB file. This feature is exploited\nby `redis-cli` in order to provide a remote backup facility that allows a\ntransfer of an RDB file from any Redis instance to the local computer running\n`redis-cli`. To use this mode, call the CLI with the `--rdb <dest-filename>`\noption:\n\n\n```$ redis-cli --rdb /tmp/dump.rdb\nSYNC sent to master, writing 13256 bytes to '/tmp/dump.rdb'\nTransfer finished with success.\n```\n\n\nThis is a simple but effective way to ensure disaster recovery\nRDB backups exist of your Redis instance. When using this options in\nscripts or `cron` jobs, make sure to check the return value of the command.\nIf it is non zero, an error occurred as in the following example:\n\n\n```$ redis-cli --rdb /tmp/dump.rdb\nSYNC with master failed: -ERR Can't SYNC while not connected with my master\n$ echo $?\n1\n```\n\n\nReplica mode\nThe replica mode of the CLI is an advanced feature useful for\nRedis developers and for debugging operations.\nIt allows for the inspection of the content a primary sends to its replicas in the replication\nstream in order to propagate the writes to its replicas. The option\nname is simply `--replica`. The following is a working example:\n\n\n```$ redis-cli --replica\nSYNC with master, discarding 13256 bytes of bulk transfer...\nSYNC done. Logging commands from master.\n\"PING\"\n\"SELECT\",\"0\"\n\"SET\",\"last_name\",\"Enigk\"\n\"PING\"\n\"INCR\",\"mycounter\"\n```\n\n\nThe command begins by discarding the RDB file of the first synchronization\nand then logs each command received in CSV format.\nIf you think some of the commands are not replicated correctly in your replicas\nthis is a good way to check what's happening, and also useful information\nin order to improve the bug report.\nPerforming an LRU simulation\nRedis is often used as a cache with LRU eviction.\nDepending on the number of keys and the amount of memory allocated for the\ncache (specified via the `maxmemory` directive), the amount of cache hits\nand misses will change. Sometimes, simulating the rate of hits is very\nuseful to correctly provision your cache.\nThe `redis-cli` has a special mode where it performs a simulation of GET and SET\noperations, using an 80-20% power law distribution in the requests pattern.\nThis means that 20% of keys will be requested 80% of times, which is a\ncommon distribution in caching scenarios.\nTheoretically, given the distribution of the requests and the Redis memory\noverhead, it should be possible to compute the hit rate analytically\nwith a mathematical formula. However, Redis can be configured with\ndifferent LRU settings (number of samples) and LRU's implementation, which\nis approximated in Redis, changes a lot between different versions. Similarly\nthe amount of memory per key may change between versions. That is why this\ntool was built: its main motivation was for testing the quality of Redis' LRU\nimplementation, but now is also useful for testing how a given version\nbehaves with the settings originally intended for deployment.\nTo use this mode, specify the amount of keys in the test and configure a sensible `maxmemory` setting as a first attempt.\nIMPORTANT NOTE: Configuring the `maxmemory` setting in the Redis configuration\nis crucial: if there is no cap to the maximum memory usage, the hit will\neventually be 100% since all the keys can be stored in memory. If too many keys are specified with maximum memory, eventually all of the computer RAM will be used. It is also needed to configure an appropriate\nmaxmemory policy; most of the time `allkeys-lru` is selected.\nIn the following example there is a configured a memory limit of 100MB and an LRU\nsimulation using 10 million keys.\nWARNING: the test uses pipelining and will stress the server, don't use it\nwith production instances.\n\n\n```$ ./redis-cli --lru-test 10000000\n156000 Gets/sec | Hits: 4552 (2.92%) | Misses: 151448 (97.08%)\n153750 Gets/sec | Hits: 12906 (8.39%) | Misses: 140844 (91.61%)\n159250 Gets/sec | Hits: 21811 (13.70%) | Misses: 137439 (86.30%)\n151000 Gets/sec | Hits: 27615 (18.29%) | Misses: 123385 (81.71%)\n145000 Gets/sec | Hits: 32791 (22.61%) | Misses: 112209 (77.39%)\n157750 Gets/sec | Hits: 42178 (26.74%) | Misses: 115572 (73.26%)\n154500 Gets/sec | Hits: 47418 (30.69%) | Misses: 107082 (69.31%)\n151250 Gets/sec | Hits: 51636 (34.14%) | Misses: 99614 (65.86%)\n```\n\n\nThe program shows stats every second. In the first seconds the cache starts to be populated. The misses rate later stabilizes into the actual figure that can be expected:\n\n\n```120750 Gets/sec | Hits: 48774 (40.39%) | Misses: 71976 (59.61%)\n122500 Gets/sec | Hits: 49052 (40.04%) | Misses: 73448 (59.96%)\n127000 Gets/sec | Hits: 50870 (40.06%) | Misses: 76130 (59.94%)\n124250 Gets/sec | Hits: 50147 (40.36%) | Misses: 74103 (59.64%)\n```\n\n\nA miss rate of 59% may not be acceptable for certain use cases therefor\n100MB of memory is not enough. Observe an example using a half gigabyte of memory. After several\nminutes the output stabilizes to the following figures:\n\n\n```140000 Gets/sec | Hits: 135376 (96.70%) | Misses: 4624 (3.30%)\n141250 Gets/sec | Hits: 136523 (96.65%) | Misses: 4727 (3.35%)\n140250 Gets/sec | Hits: 135457 (96.58%) | Misses: 4793 (3.42%)\n140500 Gets/sec | Hits: 135947 (96.76%) | Misses: 4553 (3.24%)\n```\n\n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/geospatial.md",
    "content": "\ufeff---\ntitle: \"Redis geospatial\"\nlinkTitle: \"Geospatial\"\nweight: 80\ndescription: >\n    Introduction to the Redis Geospatial data type\n\nRedis geospatial indexes let you store coordinates and search for them.\nThis data structure is useful for finding nearby points within a given radius or bounding box.\nExamples\nSuppose you're building a mobile app that lets you find all of the electric car charging stations closest to your current location.\nAdd several locations to a geospatial index:\n```\n\nGEOADD locations:ca -122.27652 37.805186 station:1\n(integer) 1\nGEOADD locations:ca -122.2674626 37.8062344 station:2\n(integer) 1\nGEOADD locations:ca -122.2469854 37.8104049 station:3\n(integer) 1\n```\n\nFind all locations within a 5 kilometer radius of a given location, and return the distance to each location:\n```\n\nGEOSEARCH locations:ca FROMLONLAT -122.2612767 37.7936847 BYRADIUS 5 km WITHDIST\n1) 1) \"station:1\"\n   2) \"1.8523\"\n2) 1) \"station:2\"\n   2) \"1.4979\"\n3) 1) \"station:3\"\n   2) \"2.2441\"\n```\n\nBasic commands\n\n`GEOADD` adds a location to a given geospatial index (note that longitude comes before latitude with this command).\n`GEOSEARCH` returns locations with a given radius or a bounding box.\n\nSee the complete list of geospatial index commands.\nLearn more\n\nRedis Geospatial Explained introduces geospatial indexes by showing you how to build a map of local park attractions.\n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/sorted-sets.md",
    "content": "\ufeff---\ntitle: \"Redis sorted sets\"\nlinkTitle: \"Sorted sets\"\nweight: 50\ndescription: >\n    Introduction to Redis sorted sets\n\nA Redis sorted set is a collection of unique strings (members) ordered by an associated score.\nWhen more than one string has the same score, the strings are ordered lexicographically.\nSome use cases for sorted sets include:\n\nLeaderboards. For example, you can use sorted sets to easily maintain  ordered lists of the highest scores in a massive online game.\nRate limiters. In particular, you can use a sorted set to build a sliding-window rate limiter to prevent excessive API requests.\n\nExamples\n\nUpdate a real-time leaderboard as players' scores change:\n```\nZADD leaderboard:455 100 user:1\n(integer) 1\nZADD leaderboard:455 75 user:2\n(integer) 1\nZADD leaderboard:455 101 user:3\n(integer) 1\nZADD leaderboard:455 15 user:4\n(integer) 1\nZADD leaderboard:455 275 user:2\n(integer) 0\n```\n\n\n\nNotice that `user:2`'s score is updated in the final `ZADD` call.\n\n\nGet the top 3 players' scores:\n```\n\nZRANGE leaderboard:455 0 2 REV WITHSCORES\n1) \"user:2\"\n2) \"275\"\n3) \"user:3\"\n4) \"101\"\n5) \"user:1\"\n6) \"100\"\n```\n\n\n\nWhat's the rank of user 2?\n```\n\nZREVRANK leaderboard:455 user:2\n(integer) 0\n```\n\n\n\nBasic commands\n\n`ZADD` adds a new member and associated score to a sorted set. If the member already exists, the score is updated.\n`ZRANGE` returns members of a sorted set, sorted within a given range.\n`ZRANK` returns the rank of the provided member, assuming the sorted is in ascending order.\n`ZREVRANK` returns the rank of the provided member, assuming the sorted set is in descending order.\n\nSee the complete list of sorted set commands.\nPerformance\nMost sorted set operations are O(log(n)), where n is the number of members.\nExercise some caution when running the `ZRANGE` command with large returns values (e.g., in the tens of thousands or more).\nThis command's time complexity is O(log(n) + m), where m is the number of results returned. \nAlternatives\nRedis sorted sets are sometimes used for indexing other Redis data structures.\nIf you need to index and query your data, consider RediSearch and RedisJSON.\nLearn more\n\nRedis Sorted Sets Explained is an entertaining introduction to sorted sets in Redis.\n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/bitmaps.md",
    "content": "\ufeff---\ntitle: \"Redis bitmaps\"\nlinkTitle: \"Bitmaps\"\nweight: 120\ndescription: >\n    Introduction to Redis bitmaps\n\nRedis bitmaps are an extension of the string data type that lets you treat a string like a bit vector.\nYou can also perform bitwise operations on one or more strings.\nSome examples of bitmap use cases include:\n\nEfficient set representations for cases where the members of a set correspond to the integers 0-N.\nObject permissions, where each bit represents a particular permission, similar to the way that file systems store permissions.\n\nExamples\nSuppose you have 1000 sensors deployed in the field, labeled 0-999.\nYou want to quickly determine whether a given sensor has pinged the server within the hour. \nYou can represent this scenario using a bitmap whose key references the current hour.\n\n\nSensor 123 pings the server on January 1, 2024 within the 00:00 hour.\n```\n\nSETBIT pings:2024-01-01-00:00 123 1\n(integer) 0\n```\n\n\n\nDid sensor 123 ping the server on January 1, 2024 within the 00:00 hour?\n```\n\nGETBIT pings:2024-01-01-00:00 123\n1\n```\n\n\n\nWhat about server 456?\n```\n\nGETBIT pings:2024-01-01-00:00 456\n0\n```\n\n\n\nBasic commands\n\n`SETBIT` sets a bit at the provided offset to 0 or 1.\n`GETBIT` returns the value of a bit at a given offset.\n`BITOP` lets you perform bitwise operations against one or more strings.\n\nSee the complete list of bitmap commands.\nPerformance\n`SETBIT` and `GETBIT` are O(1).\n`BITOP` is O(n), where n is the length of the longest string in the comparison.\nLearn more\n\nRedis Bitmaps Explained teaches you how to use bitmaps for map exploration in an online game. \n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/strings.md",
    "content": "\ufeff---\ntitle: \"Redis Strings\"\nlinkTitle: \"Strings\"\nweight: 10\ndescription: >\n    Introduction to Redis strings\n\nRedis strings store sequences of bytes, including text, serialized objects, and binary arrays.\nAs such, strings are the most basic Redis data type.\nThey're often used for caching, but they support additional functionality that lets you implement counters and perform bitwise operations, too.\nExamples\n\nStore and then retrieve a string in Redis:\n\n```\n\nSET user:1 salvatore\nOK\nGET user:1\n\"salvatore\"\n```\n\n\nStore a serialized JSON string and set it to expire 100 seconds from now:\n\n```\n\nSET ticket:27 \"\\\"{'username': 'priya', 'ticket_id': 321}\\\"\" EX 100\n```\n\n\nIncrement a counter:\n\n```\n\nINCR views:page:2\n(integer) 1\nINCRBY views:page:2 10\n(integer) 11\n```\n\nLimits\nBy default, a single Redis string can be a maximum of 512 MB.\nBasic commands\nGetting and setting Strings\n\n`SET` stores a string value.\n`SETNX` stores a string value only if the key doesn't already exist. Useful for implementing locks.\n`GET` retrieves a string value.\n`MGET` retrieves multiple string values in a single operation.\n\nManaging counters\n\n`INCRBY` atomically increments (and decrements when passing a negative number) counters stored at a given key.\nAnother command exists for floating point counters: INCRBYFLOAT.\n\nBitwise operations\nTo perform bitwise operations on a string, see the bitmaps data type docs.\nSee the complete list of string commands.\nPerformance\nMost string operations are O(1), which means they're highly efficient.\nHowever, be careful with the `SUBSTR`, `GETRANGE`, and `SETRANGE` commands, which can be O(n).\nThese random-access string commands may cause performance issues when dealing with large strings.\nAlternatives\nIf you're storing structured data as a serialized string, you may also want to consider Redis hashes or RedisJSON.\nLearn more\n\nRedis Strings Explained is a short, comprehensive video explainer on Redis strings.\n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/hashes.md",
    "content": "\ufeff---\ntitle: \"Redis hashes\"\nlinkTitle: \"Hashes\"\nweight: 40\ndescription: >\n    Introduction to Redis hashes\n\nRedis hashes are record types structured as collections of field-value pairs.\nYou can use hashes to represent basic objects and to store groupings of counters, among other things.\nExamples\n\n\nRepresent a basic user profile as a hash:\n```\n\nHSET user:123 username martina firstName Martina lastName Elisa country GB\n(integer) 4\nHGET user:123 username\n\"martina\"\nHGETALL user:123\n1) \"username\"\n2) \"martina\"\n3) \"firstName\"\n4) \"Martina\"\n5) \"lastName\"\n6) \"Elisa\"\n7) \"country\"\n8) \"GB\"\n```\n\n\n\nStore counters for the number of times device 777 had pinged the server, issued a request, or sent an error:\n```\n\nHINCRBY device:777:stats pings 1\n(integer) 1\nHINCRBY device:777:stats pings 1\n(integer) 2\nHINCRBY device:777:stats pings 1\n(integer) 3\nHINCRBY device:777:stats errors 1\n(integer) 1\nHINCRBY device:777:stats requests 1\n(integer) 1\nHGET device:777:stats pings\n\"3\"\nHMGET device:777:stats requests errors\n1) \"1\"\n2) \"1\"\n```\n\n\n\nBasic commands\n\n`HSET` sets the value of one or more fields on a hash.\n`HGET` returns the value at a given field.\n`HMGET` returns the values at one or more given fields.\n`HINCRBY` increments the value at a given field by the integer provided.\n\nSee the complete list of hash commands.\nPerformance\nMost Redis hash commands are O(1).\nA few commands - such as `HKEYS`, `HVALS`, and `HGETALL` - are O(n), where n is the number of field-value pairs.\nLimits\nEvery hash can store up to 4,294,967,295 (2^32 - 1) field-value pairs.\nIn practice, your hashes are limited only by the overall memory on the VMs hosting your Redis deployment.\nLearn more\n\nRedis Hashes Explained is a short, comprehensive video explainer covering Redis hashes.\n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/sets.md",
    "content": "\ufeff---\ntitle: \"Redis sets\"\nlinkTitle: \"Sets\"\nweight: 30\ndescription: >\n    Introduction to Redis sets\n\nA Redis set is an unordered collection of unique strings (members).\nYou can use Redis sets to efficiently:\n\nTrack unique items (e.g., track all unique IP addresses accessing a given blog post).\nRepresent relations (e.g., the set of all users with a given role).\nPerform common set operations such as intersection, unions, and differences.\n\nExamples\n\n\nStore the set of favorited book IDs for users 123 and 456:\n```\n\nSADD user:123:favorites 347\n(integer) 1\nSADD user:123:favorites 561\n(integer) 1\nSADD user:123:favorites 742\n(integer) 1\nSADD user:456:favorites 561\n(integer) 1\n```\n\n\n\nCheck whether user 123 likes books 742 and 299\n```\n\nSISMEMBER user:123:favorites 742\n(integer) 1\nSISMEMBER user:123:favorites 299\n(integer) 0\n```\n\n\n\nDo user 123 and 456 have any favorite books in common?\n```\n\nSINTER user:123:favorites user:456:favorites\n1) \"561\"\n```\n\n\n\nHow many books has user 123 favorited?\n```\n\nSCARD user:123:favorites\n(integer) 3\n```\n\n\n\nLimits\nThe max size of a Redis set is 2^32 - 1 (4,294,967,295) members.\nBasic commands\n\n`SADD` adds a new member to a set.\n`SREM` removes the specified member from the set.\n`SISMEMBER` tests a string for set membership.\n`SINTER` returns the set of members that two or more sets have in common (i.e., the intersection).\n`SCARD` returns the size (a.k.a. cardinality) of a set.\n\nSee the complete list of set commands.\nPerformance\nMost set operations, including adding, removing, and checking whether an item is a set member, are O(1).\nThis means that they're highly efficient.\nHowever, for large sets with hundreds of thousands of members or more, you should exercise caution when running the `SMEMBERS` command.\nThis command is O(n) and returns the entire set in a single response. \nAs an alternative, consider the `SSCAN`, which lets you retrieve all members of a set iteratively.\nAlternatives\nSets membership checks on large datasets (or on streaming data) can use a lot of memory.\nIf you're concerned about memory usage and don't need perfect precision, consider a Bloom filter or Cuckoo filter as an alternative to a set.\nRedis sets are frequently used as a kind of index.\nIf you need to index and query your data, consider RediSearch and RedisJSON.\nLearn more\n\nRedis Sets Explained and Redis Sets Elaborated are two short but thorough video explainers covering Redis sets.\n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/hyperloglogs.md",
    "content": "\ufeff---\ntitle: \"Redis HyperLogLog\"\nlinkTitle: \"HyperLogLog\"\nweight: 90\ndescription: >\n    Introduction to the Redis HyperLogLog data type\n\nHyperLogLog is a data structure that estimates the cardinality of a set. As a probabilistic data structure, HyperLogLog trades perfect accuracy for efficient space utilization.\nThe Redis HyperLogLog implementation uses up to 12 KB and provides a standard error of 0.81%.\nExamples\n\n\nAdd some items to the HyperLogLog:\n```\n\nPFADD members 123\n(integer) 1\nPFADD members 500\n(integer) 1\nPFADD members 12\n(integer) 1\n```\n\n\n\nEstimate the number of members in the set:\n```\n\nPFCOUNT members\n(integer) 3\n```\n\n\n\nBasic commands\n\n`PFADD` adds an item to a HyperLogLog.\n`PFCOUNT` returns an estimate of the number of items in the set.\n`PFMERGE` combines two or more HyperLogLogs into one.\n\nSee the complete list of HyperLogLog commands.\nPerformance\nWriting (`PFADD`) to and reading from (`PFCOUNT`) the HyperLogLog is done in constant time and space.\nMerging HLLs is O(n), where n is the number of sketches.\nLimits\nThe HyperLogLog can estimate the cardinality of sets with up to 18,446,744,073,709,551,616 (2^64) members.\nLearn more\n\nRedis new data structure: the HyperLogLog has a lot of details about the data structure and its implementation in Redis.\n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/streams.md",
    "content": "\ntitle: \"Redis Streams\"\nlinkTitle: \"Streams\"\nweight: 60\ndescription: >\n    Introduction to Redis streams\n\nA Redis stream is a data structure that acts like an append-only log.\nYou can use streams to record and simultaneously syndicate events in real time.\nExamples of Redis stream use cases include:\n\nEvent sourcing (e.g., tracking user actions, clicks, etc.)\nSensor monitoring (e.g., readings from devices in the field) \nNotifications (e.g., storing a record of each user's notifications in a separate stream)\n\nRedis generates a unique ID for each stream entry.\nYou can use these IDs to retrieve their associated entries later or to read and process all subsequent entries in the stream.\nRedis streams support several trimming strategies (to prevent streams from growing unbounded) and more than one consumption strategy (see `XREAD`, `XREADGROUP`, and `XRANGE`).\nExamples\n\n\nAdd several temperature readings to a stream\n```\n\nXADD temperatures:us-ny:10007 * temp_f 87.2 pressure 29.69 humidity 46\n\"1658354918398-0\"\nXADD temperatures:us-ny:10007 * temp_f 83.1 pressure 29.21 humidity 46.5\n\"1658354934941-0\"\nXADD temperatures:us-ny:10007 * temp_f 81.9 pressure 28.37 humidity 43.7\n\"1658354957524-0\"\n```\n\n\n\nRead the first two stream entries starting at ID `1658354934941-0`:\n```\n\nXRANGE temperatures:us-ny:10007 1658354934941-0 + COUNT 2\n1) 1) \"1658354934941-0\"\n   2) 1) \"temp_f\"\n      2) \"83.1\"\n      3) \"pressure\"\n      4) \"29.21\"\n      5) \"humidity\"\n      6) \"46.5\"\n2) 1) \"1658354957524-0\"\n   2) 1) \"temp_f\"\n      2) \"81.9\"\n      3) \"pressure\"\n      4) \"28.37\"\n      5) \"humidity\"\n      6) \"43.7\"\n``` \n\n\n\nRead up to 100 new stream entries, starting at the end of the stream, and block for up to 300 ms if no entries are being written:\n```\n\nXREAD COUNT 100 BLOCK 300 STREAMS temperatures:us-ny:10007 $\n(nil)\n```\n\n\n\nBasic commands\n\n`XADD` adds a new entry to a stream.\n`XREAD` reads one or more entries, starting at a given position and moving forward in time.\n`XRANGE` returns a range of entries between two supplied entry IDs.\n`XLEN` returns the length of a stream.\n\nSee the complete list of stream commands.\nPerformance\nAdding an entry to a stream is O(1).\nAccessing any single entry is O(n), where n is the length of the ID.\nSince stream IDs are typically short and of a fixed length, this effectively reduces to a constant time lookup.\nFor details on why, note that streams are implemented as radix trees.\nSimply put, Redis streams provide highly efficient inserts and reads.\nSee each command's time complexity for the details.\nLearn more\n\nThe Redis Streams Tutorial explains Redis streams with many examples.\nRedis Streams Explained is an entertaining introduction to streams in Redis.\n",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/lists.md",
    "content": "\ufeff---\ntitle: \"Redis lists\"\nlinkTitle: \"Lists\"\nweight: 20\ndescription: >\n    Introduction to Redis lists\n\nRedis lists are linked lists of string values.\nRedis lists are frequently used to:\n\nImplement stacks and queues.\nBuild queue management for background worker systems.\n\nExamples\n\n\nTreat a list like a queue (first in, first out):\n```\n\nLPUSH work:queue:ids 101\n(integer) 1\nLPUSH work:queue:ids 237\n(integer) 2\nRPOP work:queue:ids\n\"101\"\nRPOP work:queue:ids\n\"237\"\n```\n\n\n\nTreat a list like a stack (first in, last out):\n```\n\nLPUSH work:queue:ids 101\n(integer) 1\nLPUSH work:queue:ids 237\n(integer) 2\nLPOP work:queue:ids\n\"237\"\nLPOP work:queue:ids\n\"101\"\n```\n\n\n\nCheck the length of a list:\n```\n\nLLEN work:queue:ids\n(integer) 0\n```\n\n\n\nAtomically pop an element from one list and push to another:\n```\n\nLPUSH board:todo:ids 101\n(integer) 1\nLPUSH board:todo:ids 273\n(integer) 2\nLMOVE board:todo:ids board:in-progress:ids LEFT LEFT\n\"273\"\nLRANGE board:todo:ids 0 -1\n1) \"101\"\nLRANGE board:in-progress:ids 0 -1\n1) \"273\"\n```\n\n\n\nTo create a capped list that never grows beyond 100 elements, you can call `LTRIM` after each call to `LPUSH`:\n```\n\nLPUSH notifications:user:1 \"You've got mail!\"\n(integer) 1\nLTRIM notifications:user:1 0 99\nOK\nLPUSH notifications:user:1 \"Your package will be delivered at 12:01 today.\"\n(integer) 2\nLTRIM notifications:user:1 0 99\nOK\n```\n\n\n\nLimits\nThe max length of a Redis list is 2^32 - 1 (4,294,967,295) elements.\nBasic commands\n\n`LPUSH` adds a new element to the head of a list; `RPUSH` adds to the tail.\n`LPOP` removes and returns an element from the head of a list; `RPOP` does the same but from the tails of a list. \n`LLEN` returns the length of a list.\n`LMOVE` atomically moves elements from one list to another.\n`LTRIM` reduces a list to the specified range of elements.\n\nBlocking commands\nLists support several blocking commands.\nFor example:\n\n`BLPOP` removes and returns an element from the head of a list.\n  If the list is empty, the command blocks until an element becomes available or until the specified timeout is reached.\n`BLMOVE` atomically moves elements from a source list to a target list.\n  If the source list is empty, the command will block until a new element becomes available.\n\nSee the complete series of list commands.\nPerformance\nList operations that access its head or tail are O(1), which means they're highly efficient.\nHowever, commands that manipulate elements within a list are usually O(n).\nExamples of these include `LINDEX`, `LINSERT`, and `LSET`.\nExercise caution when running these commands, mainly when operating on large lists.\nAlternatives\nConsider Redis streams as an alternative to lists when you need to store and process an indeterminate series of events.\nLearn more\n\nRedis Lists Explained is a short, comprehensive video explainer on Redis lists.\n",
    "tag": "redis"
  },
  {
    "title": "Keys",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/tutorial.md",
    "content": "\ntitle: \"Redis data types tutorial\"\nlinkTitle: \"Tutorial\"\ndescription: Learning the basic Redis data types and how to use them\nweight: 1\naliases:\n    - /topics/data-types-intro\n    - /docs/manual/data-types/data-types-tutorial\n\nThe following is a hands-on tutorial that teaches the core Redis data types using the Redis CLI. For a general overview of the data types, see the data types introduction.\nKeys\nRedis keys are binary safe, this means that you can use any binary sequence as a\nkey, from a string like \"foo\" to the content of a JPEG file.\nThe empty string is also a valid key.\nA few other rules about keys:\n\nVery long keys are not a good idea. For instance a key of 1024 bytes is a bad\n  idea not only memory-wise, but also because the lookup of the key in the\n  dataset may require several costly key-comparisons. Even when the task at hand\n  is to match the existence of a large value, hashing it (for example\n  with SHA1) is a better idea, especially from the perspective of memory\n  and bandwidth.\nVery short keys are often not a good idea. There is little point in writing\n  \"u1000flw\" as a key if you can instead write \"user:1000:followers\".  The latter\n  is more readable and the added space is minor compared to the space used by\n  the key object itself and the value object. While short keys will obviously\n  consume a bit less memory, your job is to find the right balance.\nTry to stick with a schema. For instance \"object-type:id\" is a good\n  idea, as in \"user:1000\". Dots or dashes are often used for multi-word\n  fields, as in \"comment:4321:reply.to\" or \"comment:4321:reply-to\".\nThe maximum allowed key size is 512 MB.\n\n\nStrings\nThe Redis String type is the simplest type of value you can associate with\na Redis key. It is the only data type in Memcached, so it is also very natural\nfor newcomers to use it in Redis.\nSince Redis keys are strings, when we use the string type as a value too,\nwe are mapping a string to another string. The string data type is useful\nfor a number of use cases, like caching HTML fragments or pages.\nLet's play a bit with the string type, using `redis-cli` (all the examples\nwill be performed via `redis-cli` in this tutorial).\n\n\n```> set mykey somevalue\nOK\n> get mykey\n\"somevalue\"\n```\n\n\nAs you can see using the `SET` and the `GET` commands are the way we set\nand retrieve a string value. Note that `SET` will replace any existing value\nalready stored into the key, in the case that the key already exists, even if\nthe key is associated with a non-string value. So `SET` performs an assignment.\nValues can be strings (including binary data) of every kind, for instance you\ncan store a jpeg image inside a value. A value can't be bigger than 512 MB.\nThe `SET` command has interesting options, that are provided as additional\narguments. For example, I may ask `SET` to fail if the key already exists,\nor the opposite, that it only succeed if the key already exists:\n\n\n```> set mykey newval nx\n(nil)\n> set mykey newval xx\nOK\n```\n\n\nEven if strings are the basic values of Redis, there are interesting operations\nyou can perform with them. For instance, one is atomic increment:\n\n\n```> set counter 100\nOK\n> incr counter\n(integer) 101\n> incr counter\n(integer) 102\n> incrby counter 50\n(integer) 152\n```\n\n\nThe INCR command parses the string value as an integer,\nincrements it by one, and finally sets the obtained value as the new value.\nThere are other similar commands like INCRBY,\nDECR and DECRBY. Internally it's\nalways the same command, acting in a slightly different way.\nWhat does it mean that INCR is atomic?\nThat even multiple clients issuing INCR against\nthe same key will never enter into a race condition. For instance, it will never\nhappen that client 1 reads \"10\", client 2 reads \"10\" at the same time, both\nincrement to 11, and set the new value to 11. The final value will always be\n12 and the read-increment-set operation is performed while all the other\nclients are not executing a command at the same time.\nThere are a number of commands for operating on strings. For example\nthe `GETSET` command sets a key to a new value, returning the old value as the\nresult. You can use this command, for example, if you have a\nsystem that increments a Redis key using `INCR`\nevery time your web site receives a new visitor. You may want to collect this\ninformation once every hour, without losing a single increment.\nYou can `GETSET` the key, assigning it the new value of \"0\" and reading the\nold value back.\nThe ability to set or retrieve the value of multiple keys in a single\ncommand is also useful for reduced latency. For this reason there are\nthe `MSET` and `MGET` commands:\n\n\n```> mset a 10 b 20 c 30\nOK\n> mget a b c\n1) \"10\"\n2) \"20\"\n3) \"30\"\n```\n\n\nWhen `MGET` is used, Redis returns an array of values.\nAltering and querying the key space\nThere are commands that are not defined on particular types, but are useful\nin order to interact with the space of keys, and thus, can be used with\nkeys of any type.\nFor example the `EXISTS` command returns 1 or 0 to signal if a given key\nexists or not in the database, while the `DEL` command deletes a key\nand associated value, whatever the value is.\n\n\n```> set mykey hello\nOK\n> exists mykey\n(integer) 1\n> del mykey\n(integer) 1\n> exists mykey\n(integer) 0\n```\n\n\nFrom the examples you can also see how `DEL` itself returns 1 or 0 depending on whether\nthe key was removed (it existed) or not (there was no such key with that\nname).\nThere are many key space related commands, but the above two are the\nessential ones together with the `TYPE` command, which returns the kind\nof value stored at the specified key:\n\n\n```> set mykey x\nOK\n> type mykey\nstring\n> del mykey\n(integer) 1\n> type mykey\nnone\n```\n\n\nKey expiration\nBefore moving on, we should look at an important Redis feature that works regardless of the type of value you're storing: key expiration. Key expiration lets you set a timeout for a key, also known as a \"time to live\", or \"TTL\". When the time to live elapses, the key is automatically destroyed. \nA few important notes about key expiration:\n\nThey can be set both using seconds or milliseconds precision.\nHowever the expire time resolution is always 1 millisecond.\nInformation about expires are replicated and persisted on disk, the time virtually passes when your Redis server remains stopped (this means that Redis saves the date at which a key will expire).\n\nUse the `EXPIRE` command to set a key's expiration:\n\n\n```> set key some-value\nOK\n> expire key 5\n(integer) 1\n> get key (immediately)\n\"some-value\"\n> get key (after some time)\n(nil)\n```\n\n\nThe key vanished between the two `GET` calls, since the second call was\ndelayed more than 5 seconds. In the example above we used `EXPIRE` in\norder to set the expire (it can also be used in order to set a different\nexpire to a key already having one, like `PERSIST` can be used in order\nto remove the expire and make the key persistent forever). However we\ncan also create keys with expires using other Redis commands. For example\nusing `SET` options:\n\n\n```> set key 100 ex 10\nOK\n> ttl key\n(integer) 9\n```\n\n\nThe example above sets a key with the string value `100`, having an expire\nof ten seconds. Later the `TTL` command is called in order to check the\nremaining time to live for the key.\nIn order to set and check expires in milliseconds, check the `PEXPIRE` and\nthe `PTTL` commands, and the full list of `SET` options.\n\nLists\nTo explain the List data type it's better to start with a little bit of theory,\nas the term List is often used in an improper way by information technology\nfolks. For instance \"Python Lists\" are not what the name may suggest (Linked\nLists), but rather Arrays (the same data type is called Array in\nRuby actually).\nFrom a very general point of view a List is just a sequence of ordered\nelements: 10,20,1,2,3 is a list. But the properties of a List implemented using\nan Array are very different from the properties of a List implemented using a\nLinked List.\nRedis lists are implemented via Linked Lists. This means that even if you have\nmillions of elements inside a list, the operation of adding a new element in\nthe head or in the tail of the list is performed in constant time. The speed of adding a\nnew element with the `LPUSH` command to the head of a list with ten\nelements is the same as adding an element to the head of list with 10\nmillion elements.\nWhat's the downside? Accessing an element by index is very fast in lists\nimplemented with an Array (constant time indexed access) and not so fast in\nlists implemented by linked lists (where the operation requires an amount of\nwork proportional to the index of the accessed element).\nRedis Lists are implemented with linked lists because for a database system it\nis crucial to be able to add elements to a very long list in a very fast way.\nAnother strong advantage, as you'll see in a moment, is that Redis Lists can be\ntaken at constant length in constant time.\nWhen fast access to the middle of a large collection of elements is important,\nthere is a different data structure that can be used, called sorted sets.\nSorted sets will be covered later in this tutorial.\nFirst steps with Redis Lists\nThe `LPUSH` command adds a new element into a list, on the\nleft (at the head), while the `RPUSH` command adds a new\nelement into a list, on the right (at the tail). Finally the\n`LRANGE` command extracts ranges of elements from lists:\n\n\n```> rpush mylist A\n(integer) 1\n> rpush mylist B\n(integer) 2\n> lpush mylist first\n(integer) 3\n> lrange mylist 0 -1\n1) \"first\"\n2) \"A\"\n3) \"B\"\n```\n\n\nNote that LRANGE takes two indexes, the first and the last\nelement of the range to return. Both the indexes can be negative, telling Redis\nto start counting from the end: so -1 is the last element, -2 is the\npenultimate element of the list, and so forth.\nAs you can see `RPUSH` appended the elements on the right of the list, while\nthe final `LPUSH` appended the element on the left.\nBoth commands are variadic commands, meaning that you are free to push\nmultiple elements into a list in a single call:\n\n\n```> rpush mylist 1 2 3 4 5 \"foo bar\"\n(integer) 9\n> lrange mylist 0 -1\n1) \"first\"\n2) \"A\"\n3) \"B\"\n4) \"1\"\n5) \"2\"\n6) \"3\"\n7) \"4\"\n8) \"5\"\n9) \"foo bar\"\n```\n\n\nAn important operation defined on Redis lists is the ability to pop elements.\nPopping elements is the operation of both retrieving the element from the list,\nand eliminating it from the list, at the same time. You can pop elements\nfrom left and right, similarly to how you can push elements in both sides\nof the list:\n\n\n```> rpush mylist a b c\n(integer) 3\n> rpop mylist\n\"c\"\n> rpop mylist\n\"b\"\n> rpop mylist\n\"a\"\n```\n\n\nWe added three elements and popped three elements, so at the end of this\nsequence of commands the list is empty and there are no more elements to\npop. If we try to pop yet another element, this is the result we get:\n\n\n```> rpop mylist\n(nil)\n```\n\n\nRedis returned a NULL value to signal that there are no elements in the\nlist.\nCommon use cases for lists\nLists are useful for a number of tasks, two very representative use cases\nare the following:\n\nRemember the latest updates posted by users into a social network.\nCommunication between processes, using a consumer-producer pattern where the producer pushes items into a list, and a consumer (usually a worker) consumes those items and executes actions. Redis has special list commands to make this use case both more reliable and efficient.\n\nFor example both the popular Ruby libraries resque and\nsidekiq use Redis lists under the hood in order to\nimplement background jobs.\nThe popular Twitter social network takes the latest tweets\nposted by users into Redis lists.\nTo describe a common use case step by step, imagine your home page shows the latest\nphotos published in a photo sharing social network and you want to speedup access.\n\nEvery time a user posts a new photo, we add its ID into a list with `LPUSH`.\nWhen users visit the home page, we use `LRANGE 0 9` in order to get the latest 10 posted items.\n\nCapped lists\nIn many use cases we just want to use lists to store the latest items,\nwhatever they are: social network updates, logs, or anything else.\nRedis allows us to use lists as a capped collection, only remembering the latest\nN items and discarding all the oldest items using the `LTRIM` command.\nThe `LTRIM` command is similar to `LRANGE`, but instead of displaying the\nspecified range of elements it sets this range as the new list value. All\nthe elements outside the given range are removed.\nAn example will make it more clear:\n\n\n```> rpush mylist 1 2 3 4 5\n(integer) 5\n> ltrim mylist 0 2\nOK\n> lrange mylist 0 -1\n1) \"1\"\n2) \"2\"\n3) \"3\"\n```\n\n\nThe above `LTRIM` command tells Redis to take just list elements from index\n0 to 2, everything else will be discarded. This allows for a very simple but\nuseful pattern: doing a List push operation + a List trim operation together\nin order to add a new element and discard elements exceeding a limit:\n\n\n```LPUSH mylist <some element>\nLTRIM mylist 0 999\n```\n\n\nThe above combination adds a new element and takes only the 1000\nnewest elements into the list. With `LRANGE` you can access the top items\nwithout any need to remember very old data.\nNote: while `LRANGE` is technically an O(N) command, accessing small ranges\ntowards the head or the tail of the list is a constant time operation.\nBlocking operations on lists\nLists have a special feature that make them suitable to implement queues,\nand in general as a building block for inter process communication systems:\nblocking operations.\nImagine you want to push items into a list with one process, and use\na different process in order to actually do some kind of work with those\nitems. This is the usual producer / consumer setup, and can be implemented\nin the following simple way:\n\nTo push items into the list, producers call `LPUSH`.\nTo extract / process items from the list, consumers call `RPOP`.\n\nHowever it is possible that sometimes the list is empty and there is nothing\nto process, so `RPOP` just returns NULL. In this case a consumer is forced to wait\nsome time and retry again with `RPOP`. This is called polling, and is not\na good idea in this context because it has several drawbacks:\n\nForces Redis and clients to process useless commands (all the requests when the list is empty will get no actual work done, they'll just return NULL).\nAdds a delay to the processing of items, since after a worker receives a NULL, it waits some time. To make the delay smaller, we could wait less between calls to `RPOP`, with the effect of amplifying problem number 1, i.e. more useless calls to Redis.\n\nSo Redis implements commands called `BRPOP` and `BLPOP` which are versions\nof `RPOP` and `LPOP` able to block if the list is empty: they'll return to\nthe caller only when a new element is added to the list, or when a user-specified\ntimeout is reached.\nThis is an example of a `BRPOP` call we could use in the worker:\n\n\n```> brpop tasks 5\n1) \"tasks\"\n2) \"do_something\"\n```\n\n\nIt means: \"wait for elements in the list `tasks`, but return if after 5 seconds\nno element is available\".\nNote that you can use 0 as timeout to wait for elements forever, and you can\nalso specify multiple lists and not just one, in order to wait on multiple\nlists at the same time, and get notified when the first list receives an\nelement.\nA few things to note about `BRPOP`:\n\nClients are served in an ordered way: the first client that blocked waiting for a list, is served first when an element is pushed by some other client, and so forth.\nThe return value is different compared to `RPOP`: it is a two-element array since it also includes the name of the key, because `BRPOP` and `BLPOP` are able to block waiting for elements from multiple lists.\nIf the timeout is reached, NULL is returned.\n\nThere are more things you should know about lists and blocking ops. We\nsuggest that you read more on the following:\n\nIt is possible to build safer queues or rotating queues using `LMOVE`.\nThere is also a blocking variant of the command, called `BLMOVE`.\n\nAutomatic creation and removal of keys\nSo far in our examples we never had to create empty lists before pushing\nelements, or removing empty lists when they no longer have elements inside.\nIt is Redis' responsibility to delete keys when lists are left empty, or to create\nan empty list if the key does not exist and we are trying to add elements\nto it, for example, with `LPUSH`.\nThis is not specific to lists, it applies to all the Redis data types\ncomposed of multiple elements -- Streams, Sets, Sorted Sets and Hashes.\nBasically we can summarize the behavior with three rules:\n\nWhen we add an element to an aggregate data type, if the target key does not exist, an empty aggregate data type is created before adding the element.\nWhen we remove elements from an aggregate data type, if the value remains empty, the key is automatically destroyed. The Stream data type is the only exception to this rule.\nCalling a read-only command such as `LLEN` (which returns the length of the list), or a write command removing elements, with an empty key, always produces the same result as if the key is holding an empty aggregate type of the type the command expects to find.\n\nExamples of rule 1:\n\n\n```> del mylist\n(integer) 1\n> lpush mylist 1 2 3\n(integer) 3\n```\n\n\nHowever we can't perform operations against the wrong type if the key exists:\n\n\n```> set foo bar\nOK\n> lpush foo 1 2 3\n(error) WRONGTYPE Operation against a key holding the wrong kind of value\n> type foo\nstring\n```\n\n\nExample of rule 2:\n\n\n```> lpush mylist 1 2 3\n(integer) 3\n> exists mylist\n(integer) 1\n> lpop mylist\n\"3\"\n> lpop mylist\n\"2\"\n> lpop mylist\n\"1\"\n> exists mylist\n(integer) 0\n```\n\n\nThe key no longer exists after all the elements are popped.\nExample of rule 3:\n\n\n```> del mylist\n(integer) 0\n> llen mylist\n(integer) 0\n> lpop mylist\n(nil)\n```\n\n\n\nHashes\nRedis hashes look exactly how one might expect a \"hash\" to look, with field-value pairs:\n\n\n```> hset user:1000 username antirez birthyear 1977 verified 1\n(integer) 3\n> hget user:1000 username\n\"antirez\"\n> hget user:1000 birthyear\n\"1977\"\n> hgetall user:1000\n1) \"username\"\n2) \"antirez\"\n3) \"birthyear\"\n4) \"1977\"\n5) \"verified\"\n6) \"1\"\n```\n\n\nWhile hashes are handy to represent objects, actually the number of fields you can\nput inside a hash has no practical limits (other than available memory), so you can use\nhashes in many different ways inside your application.\nThe command `HSET` sets multiple fields of the hash, while `HGET` retrieves\na single field. `HMGET` is similar to `HGET` but returns an array of values:\n\n\n```> hmget user:1000 username birthyear no-such-field\n1) \"antirez\"\n2) \"1977\"\n3) (nil)\n```\n\n\nThere are commands that are able to perform operations on individual fields\nas well, like `HINCRBY`:\n\n\n```> hincrby user:1000 birthyear 10\n(integer) 1987\n> hincrby user:1000 birthyear 10\n(integer) 1997\n```\n\n\nYou can find the full list of hash commands in the documentation.\nIt is worth noting that small hashes (i.e., a few elements with small values) are\nencoded in special way in memory that make them very memory efficient.\n\nSets\nRedis Sets are unordered collections of strings. The\n`SADD` command adds new elements to a set. It's also possible\nto do a number of other operations against sets like testing if a given element\nalready exists, performing the intersection, union or difference between\nmultiple sets, and so forth.\n\n\n```> sadd myset 1 2 3\n(integer) 3\n> smembers myset\n1. 3\n2. 1\n3. 2\n```\n\n\nHere I've added three elements to my set and told Redis to return all the\nelements. As you can see they are not sorted -- Redis is free to return the\nelements in any order at every call, since there is no contract with the\nuser about element ordering.\nRedis has commands to test for membership. For example, checking if an element exists:\n\n\n```> sismember myset 3\n(integer) 1\n> sismember myset 30\n(integer) 0\n```\n\n\n\"3\" is a member of the set, while \"30\" is not.\nSets are good for expressing relations between objects.\nFor instance we can easily use sets in order to implement tags.\nA simple way to model this problem is to have a set for every object we\nwant to tag. The set contains the IDs of the tags associated with the object.\nOne illustration is tagging news articles.\nIf article ID 1000 is tagged with tags 1, 2, 5 and 77, a set\ncan associate these tag IDs with the news item:\n\n\n```> sadd news:1000:tags 1 2 5 77\n(integer) 4\n```\n\n\nWe may also want to have the inverse relation as well: the list\nof all the news tagged with a given tag:\n\n\n```> sadd tag:1:news 1000\n(integer) 1\n> sadd tag:2:news 1000\n(integer) 1\n> sadd tag:5:news 1000\n(integer) 1\n> sadd tag:77:news 1000\n(integer) 1\n```\n\n\nTo get all the tags for a given object is trivial:\n\n\n```> smembers news:1000:tags\n1. 5\n2. 1\n3. 77\n4. 2\n```\n\n\nNote: in the example we assume you have another data structure, for example\na Redis hash, which maps tag IDs to tag names.\nThere are other non trivial operations that are still easy to implement\nusing the right Redis commands. For instance we may want a list of all the\nobjects with the tags 1, 2, 10, and 27 together. We can do this using\nthe `SINTER` command, which performs the intersection between different\nsets. We can use:\n\n\n```> sinter tag:1:news tag:2:news tag:10:news tag:27:news\n... results here ...\n```\n\n\nIn addition to intersection you can also perform\nunions, difference, extract a random element, and so forth.\nThe command to extract an element is called `SPOP`, and is handy to model\ncertain problems. For example in order to implement a web-based poker game,\nyou may want to represent your deck with a set. Imagine we use a one-char\nprefix for (C)lubs, (D)iamonds, (H)earts, (S)pades:\n\n\n```> sadd deck C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 CJ CQ CK\n  D1 D2 D3 D4 D5 D6 D7 D8 D9 D10 DJ DQ DK H1 H2 H3\n  H4 H5 H6 H7 H8 H9 H10 HJ HQ HK S1 S2 S3 S4 S5 S6\n  S7 S8 S9 S10 SJ SQ SK\n(integer) 52\n```\n\n\nNow we want to provide each player with 5 cards. The `SPOP` command\nremoves a random element, returning it to the client, so it is the\nperfect operation in this case.\nHowever if we call it against our deck directly, in the next play of the\ngame we'll need to populate the deck of cards again, which may not be\nideal. So to start, we can make a copy of the set stored in the `deck` key\ninto the `game:1:deck` key.\nThis is accomplished using `SUNIONSTORE`, which normally performs the\nunion between multiple sets, and stores the result into another set.\nHowever, since the union of a single set is itself, I can copy my deck\nwith:\n\n\n```> sunionstore game:1:deck deck\n(integer) 52\n```\n\n\nNow I'm ready to provide the first player with five cards:\n\n\n```> spop game:1:deck\n\"C6\"\n> spop game:1:deck\n\"CQ\"\n> spop game:1:deck\n\"D1\"\n> spop game:1:deck\n\"CJ\"\n> spop game:1:deck\n\"SJ\"\n```\n\n\nOne pair of jacks, not great...\nThis is a good time to introduce the set command that provides the number\nof elements inside a set. This is often called the cardinality of a set\nin the context of set theory, so the Redis command is called `SCARD`.\n\n\n```> scard game:1:deck\n(integer) 47\n```\n\n\nThe math works: 52 - 5 = 47.\nWhen you need to just get random elements without removing them from the\nset, there is the `SRANDMEMBER` command suitable for the task. It also features\nthe ability to return both repeating and non-repeating elements.\n\nSorted sets\nSorted sets are a data type which is similar to a mix between a Set and\na Hash. Like sets, sorted sets are composed of unique, non-repeating\nstring elements, so in some sense a sorted set is a set as well.\nHowever while elements inside sets are not ordered, every element in\na sorted set is associated with a floating point value, called the score\n(this is why the type is also similar to a hash, since every element\nis mapped to a value).\nMoreover, elements in a sorted set are taken in order (so they are not\nordered on request, order is a peculiarity of the data structure used to\nrepresent sorted sets). They are ordered according to the following rule:\n\nIf B and A are two elements with a different score, then A > B if A.score is > B.score.\nIf B and A have exactly the same score, then A > B if the A string is lexicographically greater than the B string. B and A strings can't be equal since sorted sets only have unique elements.\n\nLet's start with a simple example, adding a few selected hackers names as\nsorted set elements, with their year of birth as \"score\".\n\n\n```> zadd hackers 1940 \"Alan Kay\"\n(integer) 1\n> zadd hackers 1957 \"Sophie Wilson\"\n(integer) 1\n> zadd hackers 1953 \"Richard Stallman\"\n(integer) 1\n> zadd hackers 1949 \"Anita Borg\"\n(integer) 1\n> zadd hackers 1965 \"Yukihiro Matsumoto\"\n(integer) 1\n> zadd hackers 1914 \"Hedy Lamarr\"\n(integer) 1\n> zadd hackers 1916 \"Claude Shannon\"\n(integer) 1\n> zadd hackers 1969 \"Linus Torvalds\"\n(integer) 1\n> zadd hackers 1912 \"Alan Turing\"\n(integer) 1\n```\n\n\nAs you can see `ZADD` is similar to `SADD`, but takes one additional argument\n(placed before the element to be added) which is the score.\n`ZADD` is also variadic, so you are free to specify multiple score-value\npairs, even if this is not used in the example above.\nWith sorted sets it is trivial to return a list of hackers sorted by their\nbirth year because actually they are already sorted.\nImplementation note: Sorted sets are implemented via a\ndual-ported data structure containing both a skip list and a hash table, so\nevery time we add an element Redis performs an O(log(N)) operation. That's\ngood, but when we ask for sorted elements Redis does not have to do any work at\nall, it's already all sorted:\n\n\n```> zrange hackers 0 -1\n1) \"Alan Turing\"\n2) \"Hedy Lamarr\"\n3) \"Claude Shannon\"\n4) \"Alan Kay\"\n5) \"Anita Borg\"\n6) \"Richard Stallman\"\n7) \"Sophie Wilson\"\n8) \"Yukihiro Matsumoto\"\n9) \"Linus Torvalds\"\n```\n\n\nNote: 0 and -1 means from element index 0 to the last element (-1 works\nhere just as it does in the case of the `LRANGE` command).\nWhat if I want to order them the opposite way, youngest to oldest?\nUse ZREVRANGE instead of ZRANGE:\n\n\n```> zrevrange hackers 0 -1\n1) \"Linus Torvalds\"\n2) \"Yukihiro Matsumoto\"\n3) \"Sophie Wilson\"\n4) \"Richard Stallman\"\n5) \"Anita Borg\"\n6) \"Alan Kay\"\n7) \"Claude Shannon\"\n8) \"Hedy Lamarr\"\n9) \"Alan Turing\"\n```\n\n\nIt is possible to return scores as well, using the `WITHSCORES` argument:\n\n\n```> zrange hackers 0 -1 withscores\n1) \"Alan Turing\"\n2) \"1912\"\n3) \"Hedy Lamarr\"\n4) \"1914\"\n5) \"Claude Shannon\"\n6) \"1916\"\n7) \"Alan Kay\"\n8) \"1940\"\n9) \"Anita Borg\"\n10) \"1949\"\n11) \"Richard Stallman\"\n12) \"1953\"\n13) \"Sophie Wilson\"\n14) \"1957\"\n15) \"Yukihiro Matsumoto\"\n16) \"1965\"\n17) \"Linus Torvalds\"\n18) \"1969\"\n```\n\n\nOperating on ranges\nSorted sets are more powerful than this. They can operate on ranges.\nLet's get all the individuals that were born up to 1950 inclusive. We\nuse the `ZRANGEBYSCORE` command to do it:\n\n\n```> zrangebyscore hackers -inf 1950\n1) \"Alan Turing\"\n2) \"Hedy Lamarr\"\n3) \"Claude Shannon\"\n4) \"Alan Kay\"\n5) \"Anita Borg\"\n```\n\n\nWe asked Redis to return all the elements with a score between negative\ninfinity and 1950 (both extremes are included).\nIt's also possible to remove ranges of elements. Let's remove all\nthe hackers born between 1940 and 1960 from the sorted set:\n\n\n```> zremrangebyscore hackers 1940 1960\n(integer) 4\n```\n\n\n`ZREMRANGEBYSCORE` is perhaps not the best command name,\nbut it can be very useful, and returns the number of removed elements.\nAnother extremely useful operation defined for sorted set elements\nis the get-rank operation. It is possible to ask what is the\nposition of an element in the set of the ordered elements.\n\n\n```> zrank hackers \"Anita Borg\"\n(integer) 4\n```\n\n\nThe `ZREVRANK` command is also available in order to get the rank, considering\nthe elements sorted a descending way.\nLexicographical scores\nWith recent versions of Redis 2.8, a new feature was introduced that allows\ngetting ranges lexicographically, assuming elements in a sorted set are all\ninserted with the same identical score (elements are compared with the C\n`memcmp` function, so it is guaranteed that there is no collation, and every\nRedis instance will reply with the same output).\nThe main commands to operate with lexicographical ranges are `ZRANGEBYLEX`,\n`ZREVRANGEBYLEX`, `ZREMRANGEBYLEX` and `ZLEXCOUNT`.\nFor example, let's add again our list of famous hackers, but this time\nuse a score of zero for all the elements:\n\n\n```> zadd hackers 0 \"Alan Kay\" 0 \"Sophie Wilson\" 0 \"Richard Stallman\" 0\n  \"Anita Borg\" 0 \"Yukihiro Matsumoto\" 0 \"Hedy Lamarr\" 0 \"Claude Shannon\"\n  0 \"Linus Torvalds\" 0 \"Alan Turing\"\n```\n\n\nBecause of the sorted sets ordering rules, they are already sorted\nlexicographically:\n\n\n```> zrange hackers 0 -1\n1) \"Alan Kay\"\n2) \"Alan Turing\"\n3) \"Anita Borg\"\n4) \"Claude Shannon\"\n5) \"Hedy Lamarr\"\n6) \"Linus Torvalds\"\n7) \"Richard Stallman\"\n8) \"Sophie Wilson\"\n9) \"Yukihiro Matsumoto\"\n```\n\n\nUsing `ZRANGEBYLEX` we can ask for lexicographical ranges:\n\n\n```> zrangebylex hackers [B [P\n1) \"Claude Shannon\"\n2) \"Hedy Lamarr\"\n3) \"Linus Torvalds\"\n```\n\n\nRanges can be inclusive or exclusive (depending on the first character),\nalso string infinite and minus infinite are specified respectively with\nthe `+` and `-` strings. See the documentation for more information.\nThis feature is important because it allows us to use sorted sets as a generic\nindex. For example, if you want to index elements by a 128-bit unsigned\ninteger argument, all you need to do is to add elements into a sorted\nset with the same score (for example 0) but with a 16 byte prefix\nconsisting of the 128 bit number in big endian. Since numbers in big\nendian, when ordered lexicographically (in raw bytes order) are actually\nordered numerically as well, you can ask for ranges in the 128 bit space,\nand get the element's value discarding the prefix.\nIf you want to see the feature in the context of a more serious demo,\ncheck the Redis autocomplete demo.\nUpdating the score: leader boards\nJust a final note about sorted sets before switching to the next topic.\nSorted sets' scores can be updated at any time. Just calling `ZADD` against\nan element already included in the sorted set will update its score\n(and position) with O(log(N)) time complexity.  As such, sorted sets are suitable\nwhen there are tons of updates.\nBecause of this characteristic a common use case is leader boards.\nThe typical application is a Facebook game where you combine the ability to\ntake users sorted by their high score, plus the get-rank operation, in order\nto show the top-N users, and the user rank in the leader board (e.g., \"you are\nthe #4932 best score here\").\n\nBitmaps\nBitmaps are not an actual data type, but a set of bit-oriented operations\ndefined on the String type. Since strings are binary safe blobs and their\nmaximum length is 512 MB, they are suitable to set up to 2^32 different\nbits.\nBit operations are divided into two groups: constant-time single bit\noperations, like setting a bit to 1 or 0, or getting its value, and\noperations on groups of bits, for example counting the number of set\nbits in a given range of bits (e.g., population counting).\nOne of the biggest advantages of bitmaps is that they often provide\nextreme space savings when storing information. For example in a system\nwhere different users are represented by incremental user IDs, it is possible\nto remember a single bit information (for example, knowing whether\na user wants to receive a newsletter) of 4 billion of users using just 512 MB of memory.\nBits are set and retrieved using the `SETBIT` and `GETBIT` commands:\n\n\n```> setbit key 10 1\n(integer) 0\n> getbit key 10\n(integer) 1\n> getbit key 11\n(integer) 0\n```\n\n\nThe `SETBIT` command takes as its first argument the bit number, and as its second\nargument the value to set the bit to, which is 1 or 0. The command\nautomatically enlarges the string if the addressed bit is outside the\ncurrent string length.\n`GETBIT` just returns the value of the bit at the specified index.\nOut of range bits (addressing a bit that is outside the length of the string\nstored into the target key) are always considered to be zero.\nThere are three commands operating on group of bits:\n\n`BITOP` performs bit-wise operations between different strings. The provided operations are AND, OR, XOR and NOT.\n`BITCOUNT` performs population counting, reporting the number of bits set to 1.\n`BITPOS` finds the first bit having the specified value of 0 or 1.\n\nBoth `BITPOS` and `BITCOUNT` are able to operate with byte ranges of the\nstring, instead of running for the whole length of the string. The following\nis a trivial example of `BITCOUNT` call:\n\n\n```> setbit key 0 1\n(integer) 0\n> setbit key 100 1\n(integer) 0\n> bitcount key\n(integer) 2\n```\n\n\nCommon use cases for bitmaps are:\n\nReal time analytics of all kinds.\nStoring space efficient but high performance boolean information associated with object IDs.\n\nFor example imagine you want to know the longest streak of daily visits of\nyour web site users. You start counting days starting from zero, that is the\nday you made your web site public, and set a bit with `SETBIT` every time\nthe user visits the web site. As a bit index you simply take the current unix\ntime, subtract the initial offset, and divide by the number of seconds in a day\n(normally, 3600*24).\nThis way for each user you have a small string containing the visit\ninformation for each day. With `BITCOUNT` it is possible to easily get\nthe number of days a given user visited the web site, while with\na few `BITPOS` calls, or simply fetching and analyzing the bitmap client-side,\nit is possible to easily compute the longest streak.\nBitmaps are trivial to split into multiple keys, for example for\nthe sake of sharding the data set and because in general it is better to\navoid working with huge keys. To split a bitmap across different keys\ninstead of setting all the bits into a key, a trivial strategy is just\nto store M bits per key and obtain the key name with `bit-number/M` and\nthe Nth bit to address inside the key with `bit-number MOD M`.\n\nHyperLogLogs\nA HyperLogLog is a probabilistic data structure used in order to count\nunique things (technically this is referred to estimating the cardinality\nof a set). Usually counting unique items requires using an amount of memory\nproportional to the number of items you want to count, because you need\nto remember the elements you have already seen in the past in order to avoid\ncounting them multiple times. However there is a set of algorithms that trade\nmemory for precision: you end with an estimated measure with a standard error,\nwhich in the case of the Redis implementation is less than 1%.  The\nmagic of this algorithm is that you no longer need to use an amount of memory\nproportional to the number of items counted, and instead can use a\nconstant amount of memory! 12k bytes in the worst case, or a lot less if your\nHyperLogLog (We'll just call them HLL from now) has seen very few elements.\nHLLs in Redis, while technically a different data structure, are encoded\nas a Redis string, so you can call `GET` to serialize a HLL, and `SET`\nto deserialize it back to the server.\nConceptually the HLL API is like using Sets to do the same task. You would\n`SADD` every observed element into a set, and would use `SCARD` to check the\nnumber of elements inside the set, which are unique since `SADD` will not\nre-add an existing element.\nWhile you don't really add items into an HLL, because the data structure\nonly contains a state that does not include actual elements, the API is the\nsame:\n\nEvery time you see a new element, you add it to the count with `PFADD`.\nEvery time you want to retrieve the current approximation of the unique elements added with `PFADD` so far, you use the `PFCOUNT`.\n\n```> pfadd hll a b c d\n(integer) 1\n> pfcount hll\n(integer) 4\n```\n\n\n\n\nAn example of use case for this data structure is counting unique queries\nperformed by users in a search form every day.\nRedis is also able to perform the union of HLLs, please check the\nfull documentation for more information.\nOther notable features\nThere are other important things in the Redis API that can't be explored\nin the context of this document, but are worth your attention:\n\nIt is possible to iterate the key space of a large collection incrementally.\nIt is possible to run Lua scripts server side to improve latency and bandwidth.\nRedis is also a Pub-Sub server.\n\nLearn more\nThis tutorial is in no way complete and has covered just the basics of the API.\nRead the command reference to discover a lot more.",
    "tag": "redis"
  },
  {
    "title": "Examples",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/bitfields.md",
    "content": "\ntitle: \"Redis bitfields\"\nlinkTitle: \"Bitfields\"\nweight: 130\ndescription: >\n    Introduction to Redis bitfields\n\nRedis bitfields let you set, increment, and get integer values of arbitrary bit length.\nFor example, you can operate on anything from unsigned 1-bit integers to signed 63-bit integers.\nThese values are stored using binary-encoded Redis strings.\nBitfields support atomic read, write and increment operations, making them a good choice for managing counters and similar numerical values.\nExamples\nSuppose you're keeping track of activity in an online game.\nYou want to maintain two crucial metrics for each player: the total amount of gold and the number of monsters slain.\nBecause your game is highly addictive, these counters should be at least 32 bits wide.\nYou can represent these counters with one bitfield per player.\n\n\nNew players start the tutorial with 1000 gold (counter in offset 0).\n```\n\nBITFIELD player:1:stats SET u32 #0 1000\n1) (integer) 0\n```\n\n\n\nAfter killing the goblin holding the prince captive, add the 50 gold earned and increment the \"slain\" counter (offset 1).\n```\n\nBITFIELD player:1:stats INCRBY u32 #0 50 INCRBY u32 #1 1\n1) (integer) 1050\n2) (integer) 1\n```\n\n\n\nPay the blacksmith 999 gold to buy a legendary rusty dagger.\n```\n\nBITFIELD player:1:stats INCRBY u32 #0 -999\n1) (integer) 51\n```\n\n\n\nRead the player's stats:\n```\n\nBITFIELD player:1:stats GET u32 #0 GET u32 #1\n1) (integer) 51\n2) (integer) 1\n```\n\n\n\nBasic commands\n\n`BITFIELD` atomically sets, increments and reads one or more values.\n`BITFIELD_RO` is a read-only variant of `BITFIELD`.\n\nPerformance",
    "tag": "redis"
  },
  {
    "title": "Introduction",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/streams-tutorial.md",
    "content": "\ufeff---\ntitle: \"Redis Streams tutorial\"\nlinkTitle: \"Streams tutorial\"\nweight: 61\ndescription: >\n    A comprehensive tutorial on Redis streams\naliases:\n    - /topics/streams-intro\n    - /docs/manual/data-types/streams\n\nIf you're new to streams, see the Redis Streams introduction. For a more comprehensive tutorial, read on.\nIntroduction\nThe Redis stream data type was introduced in Redis 5.0. Streams model a log data structure but also implement several operations to overcome some of the limits of a typical append-only log. These include random access in O(1) time and complex consumption strategies, such as consumer groups.\nStreams basics\nStreams are an append-only data structure. The fundamental write command, called XADD, appends a new entry to the specified stream.\nEach stream entry consists of one or more field-value pairs, somewhat like a record or a Redis hash:\n```\n\nXADD mystream * sensor-id 1234 temperature 19.8\n1518951480106-0\n```\n\nThe above call to the `XADD` command adds an entry `sensor-id: 1234, temperature: 19.8` to the stream at key `mystream`, using an auto-generated entry ID, which is the one returned by the command, specifically `1518951480106-0`. It gets as its first argument the key name `mystream`, the second argument is the entry ID that identifies every entry inside a stream. However, in this case, we passed `*` because we want the server to generate a new ID for us. Every new ID will be monotonically increasing, so in more simple terms, every new entry added will have a higher ID compared to all the past entries. Auto-generation of IDs by the server is almost always what you want, and the reasons for specifying an ID explicitly are very rare. We'll talk more about this later. The fact that each Stream entry has an ID is another similarity with log files, where line numbers, or the byte offset inside the file, can be used in order to identify a given entry. Returning back at our `XADD` example, after the key name and ID, the next arguments are the field-value pairs composing our stream entry.\nIt is possible to get the number of items inside a Stream just using the `XLEN` command:\n```\n\nXLEN mystream\n(integer) 1\n```\n\nEntry IDs\nThe entry ID returned by the `XADD` command, and identifying univocally each entry inside a given stream, is composed of two parts:\n`<millisecondsTime>-<sequenceNumber>`\nThe milliseconds time part is actually the local time in the local Redis node generating the stream ID, however if the current milliseconds time happens to be smaller than the previous entry time, then the previous entry time is used instead, so if a clock jumps backward the monotonically incrementing ID property still holds. The sequence number is used for entries created in the same millisecond. Since the sequence number is 64 bit wide, in practical terms there is no limit to the number of entries that can be generated within the same millisecond.\nThe format of such IDs may look strange at first, and the gentle reader may wonder why the time is part of the ID. The reason is that Redis streams support range queries by ID. Because the ID is related to the time the entry is generated, this gives the ability to query for time ranges basically for free. We will see this soon while covering the `XRANGE` command.\nIf for some reason the user needs incremental IDs that are not related to time but are actually associated to another external system ID, as previously mentioned, the `XADD` command can take an explicit ID instead of the `*` wildcard ID that triggers auto-generation, like in the following examples:\n```\n\nXADD somestream 0-1 field value\n0-1\nXADD somestream 0-2 foo bar\n0-2\n```\n\nNote that in this case, the minimum ID is 0-1 and that the command will not accept an ID equal or smaller than a previous one:\n```\n\nXADD somestream 0-1 foo bar\n(error) ERR The ID specified in XADD is equal or smaller than the target stream top item\n```\n\nIf you're running Redis 7 or later, you can also provide an explicit ID consisting of the milliseconds part only. In this case, the sequence portion of the ID will be automatically generated. To do this, use the syntax below:\n```\n\nXADD somestream 0-* baz qux\n0-3\n```\n\nGetting data from Streams\nNow we are finally able to append entries in our stream via `XADD`. However, while appending data to a stream is quite obvious, the way streams can be queried in order to extract data is not so obvious. If we continue with the analogy of the log file, one obvious way is to mimic what we normally do with the Unix command `tail -f`, that is, we may start to listen in order to get the new messages that are appended to the stream. Note that unlike the blocking list operations of Redis, where a given element will reach a single client which is blocking in a pop style operation like `BLPOP`, with streams we want multiple consumers to see the new messages appended to the stream (the same way many `tail -f` processes can see what is added to a log). Using the traditional terminology we want the streams to be able to fan out messages to multiple clients.\nHowever, this is just one potential access mode. We could also see a stream in quite a different way: not as a messaging system, but as a time series store. In this case, maybe it's also useful to get the new messages appended, but another natural query mode is to get messages by ranges of time, or alternatively to iterate the messages using a cursor to incrementally check all the history. This is definitely another useful access mode.\nFinally, if we see a stream from the point of view of consumers, we may want to access the stream in yet another way, that is, as a stream of messages that can be partitioned to multiple consumers that are processing such messages, so that groups of consumers can only see a subset of the messages arriving in a single stream. In this way, it is possible to scale the message processing across different consumers, without single consumers having to process all the messages: each consumer will just get different messages to process. This is basically what Kafka (TM) does with consumer groups. Reading messages via consumer groups is yet another interesting mode of reading from a Redis Stream.\nRedis Streams support all three of the query modes described above via different commands. The next sections will show them all, starting from the simplest and most direct to use: range queries.\nQuerying by range: XRANGE and XREVRANGE\nTo query the stream by range we are only required to specify two IDs, start and end. The range returned will include the elements having start or end as ID, so the range is inclusive. The two special IDs `-` and `+` respectively mean the smallest and the greatest ID possible.\n```\n\nXRANGE mystream - +\n1) 1) 1518951480106-0\n   2) 1) \"sensor-id\"\n      2) \"1234\"\n      3) \"temperature\"\n      4) \"19.8\"\n2) 1) 1518951482479-0\n   2) 1) \"sensor-id\"\n      2) \"9999\"\n      3) \"temperature\"\n      4) \"18.2\"\n```\n\nEach entry returned is an array of two items: the ID and the list of field-value pairs. We already said that the entry IDs have a relation with the time, because the part at the left of the `-` character is the Unix time in milliseconds of the local node that created the stream entry, at the moment the entry was created (however note that streams are replicated with fully specified `XADD` commands, so the replicas will have identical IDs to the master). This means that I could query a range of time using `XRANGE`. In order to do so, however, I may want to omit the sequence part of the ID: if omitted, in the start of the range it will be assumed to be 0, while in the end part it will be assumed to be the maximum sequence number available. This way, querying using just two milliseconds Unix times, we get all the entries that were generated in that range of time, in an inclusive way. For instance, if I want to query a two milliseconds period I could use:\n```\n\nXRANGE mystream 1518951480106 1518951480107\n1) 1) 1518951480106-0\n   2) 1) \"sensor-id\"\n      2) \"1234\"\n      3) \"temperature\"\n      4) \"19.8\"\n```\n\nI have only a single entry in this range, however in real data sets, I could query for ranges of hours, or there could be many items in just two milliseconds, and the result returned could be huge. For this reason, `XRANGE` supports an optional COUNT option at the end. By specifying a count, I can just get the first N items. If I want more, I can get the last ID returned, increment the sequence part by one, and query again. Let's see this in the following example. We start adding 10 items with `XADD` (I won't show that, lets assume that the stream `mystream` was populated with 10 items). To start my iteration, getting 2 items per command, I start with the full range, but with a count of 2.\n```\n\nXRANGE mystream - + COUNT 2\n1) 1) 1519073278252-0\n   2) 1) \"foo\"\n      2) \"value_1\"\n2) 1) 1519073279157-0\n   2) 1) \"foo\"\n      2) \"value_2\"\n```\n\nIn order to continue the iteration with the next two items, I have to pick the last ID returned, that is `1519073279157-0` and add the prefix `(` to it. The resulting exclusive range interval, that is `(1519073279157-0` in this case, can now be used as the new start argument for the next `XRANGE` call:\n```\n\nXRANGE mystream (1519073279157-0 + COUNT 2\n1) 1) 1519073280281-0\n   2) 1) \"foo\"\n      2) \"value_3\"\n2) 1) 1519073281432-0\n   2) 1) \"foo\"\n      2) \"value_4\"\n```\n\nAnd so forth. Since `XRANGE` complexity is O(log(N)) to seek, and then O(M) to return M elements, with a small count the command has a logarithmic time complexity, which means that each step of the iteration is fast. So `XRANGE` is also the de facto streams iterator and does not require an XSCAN command.\nThe command `XREVRANGE` is the equivalent of `XRANGE` but returning the elements in inverted order, so a practical use for `XREVRANGE` is to check what is the last item in a Stream:\n```\n\nXREVRANGE mystream + - COUNT 1\n1) 1) 1519073287312-0\n   2) 1) \"foo\"\n      2) \"value_10\"\n```\n\nNote that the `XREVRANGE` command takes the start and stop arguments in reverse order.\nListening for new items with XREAD\nWhen we do not want to access items by a range in a stream, usually what we want instead is to subscribe to new items arriving to the stream. This concept may appear related to Redis Pub/Sub, where you subscribe to a channel, or to Redis blocking lists, where you wait for a key to get new elements to fetch, but there are fundamental differences in the way you consume a stream:\n\nA stream can have multiple clients (consumers) waiting for data. Every new item, by default, will be delivered to every consumer that is waiting for data in a given stream. This behavior is different than blocking lists, where each consumer will get a different element. However, the ability to fan out to multiple consumers is similar to Pub/Sub.\nWhile in Pub/Sub messages are fire and forget and are never stored anyway, and while when using blocking lists, when a message is received by the client it is popped (effectively removed) from the list, streams work in a fundamentally different way. All the messages are appended in the stream indefinitely (unless the user explicitly asks to delete entries): different consumers will know what is a new message from its point of view by remembering the ID of the last message received.\nStreams Consumer Groups provide a level of control that Pub/Sub or blocking lists cannot achieve, with different groups for the same stream, explicit acknowledgment of processed items, ability to inspect the pending items, claiming of unprocessed messages, and coherent history visibility for each single client, that is only able to see its private past history of messages.\n\nThe command that provides the ability to listen for new messages arriving into a stream is called `XREAD`. It's a bit more complex than `XRANGE`, so we'll start showing simple forms, and later the whole command layout will be provided.\n```\n\nXREAD COUNT 2 STREAMS mystream 0\n1) 1) \"mystream\"\n   2) 1) 1) 1519073278252-0\n         2) 1) \"foo\"\n            2) \"value_1\"\n      2) 1) 1519073279157-0\n         2) 1) \"foo\"\n            2) \"value_2\"\n```\n\nThe above is the non-blocking form of `XREAD`. Note that the COUNT option is not mandatory, in fact the only mandatory option of the command is the STREAMS option, that specifies a list of keys together with the corresponding maximum ID already seen for each stream by the calling consumer, so that the command will provide the client only with messages with an ID greater than the one we specified.\nIn the above command we wrote `STREAMS mystream 0` so we want all the messages in the Stream `mystream` having an ID greater than `0-0`. As you can see in the example above, the command returns the key name, because actually it is possible to call this command with more than one key to read from different streams at the same time. I could write, for instance: `STREAMS mystream otherstream 0 0`. Note how after the STREAMS option we need to provide the key names, and later the IDs. For this reason, the STREAMS option must always be the last option.\nAny other options must come before the STREAMS option.\nApart from the fact that `XREAD` can access multiple streams at once, and that we are able to specify the last ID we own to just get newer messages, in this simple form the command is not doing something so different compared to `XRANGE`. However, the interesting part is that we can turn `XREAD` into a blocking command easily, by specifying the BLOCK argument:\n```\n\nXREAD BLOCK 0 STREAMS mystream $\n```\n\nNote that in the example above, other than removing COUNT, I specified the new BLOCK option with a timeout of 0 milliseconds (that means to never timeout). Moreover, instead of passing a normal ID for the stream `mystream` I passed the special ID `$`. This special ID means that `XREAD` should use as last ID the maximum ID already stored in the stream `mystream`, so that we will receive only new messages, starting from the time we started listening. This is similar to the `tail -f` Unix command in some way.\nNote that when the BLOCK option is used, we do not have to use the special ID `$`. We can use any valid ID. If the command is able to serve our request immediately without blocking, it will do so, otherwise it will block. Normally if we want to consume the stream starting from new entries, we start with the ID `$`, and after that we continue using the ID of the last message received to make the next call, and so forth.\nThe blocking form of `XREAD` is also able to listen to multiple Streams, just by specifying multiple key names. If the request can be served synchronously because there is at least one stream with elements greater than the corresponding ID we specified, it returns with the results. Otherwise, the command will block and will return the items of the first stream which gets new data (according to the specified ID).\nSimilarly to blocking list operations, blocking stream reads are fair from the point of view of clients waiting for data, since the semantics is FIFO style. The first client that blocked for a given stream will be the first to be unblocked when new items are available.\n`XREAD` has no other options than COUNT and BLOCK, so it's a pretty basic command with a specific purpose to attach consumers to one or multiple streams. More powerful features to consume streams are available using the consumer groups API, however reading via consumer groups is implemented by a different command called `XREADGROUP`, covered in the next section of this guide.\nConsumer groups\nWhen the task at hand is to consume the same stream from different clients, then `XREAD` already offers a way to fan-out to N clients, potentially also using replicas in order to provide more read scalability. However in certain problems what we want to do is not to provide the same stream of messages to many clients, but to provide a different subset of messages from the same stream to many clients. An obvious case where this is useful is that of messages which are slow to process: the ability to have N different workers that will receive different parts of the stream allows us to scale message processing, by routing different messages to different workers that are ready to do more work.\nIn practical terms, if we imagine having three consumers C1, C2, C3, and a stream that contains the messages 1, 2, 3, 4, 5, 6, 7 then what we want is to serve the messages according to the following diagram:\n`1 -> C1\n2 -> C2\n3 -> C3\n4 -> C1\n5 -> C2\n6 -> C3\n7 -> C1`\nIn order to achieve this, Redis uses a concept called consumer groups. It is very important to understand that Redis consumer groups have nothing to do, from an implementation standpoint, with Kafka (TM) consumer groups. Yet they are similar in functionality, so I decided to keep Kafka's (TM) terminology, as it originally popularized this idea.\nA consumer group is like a pseudo consumer that gets data from a stream, and actually serves multiple consumers, providing certain guarantees:\n\nEach message is served to a different consumer so that it is not possible that the same message will be delivered to multiple consumers.\nConsumers are identified, within a consumer group, by a name, which is a case-sensitive string that the clients implementing consumers must choose. This means that even after a disconnect, the stream consumer group retains all the state, since the client will claim again to be the same consumer. However, this also means that it is up to the client to provide a unique identifier.\nEach consumer group has the concept of the first ID never consumed so that, when a consumer asks for new messages, it can provide just messages that were not previously delivered.\nConsuming a message, however, requires an explicit acknowledgment using a specific command. Redis interprets the acknowledgment as: this message was correctly processed so it can be evicted from the consumer group.\nA consumer group tracks all the messages that are currently pending, that is, messages that were delivered to some consumer of the consumer group, but are yet to be acknowledged as processed. Thanks to this feature, when accessing the message history of a stream, each consumer will only see messages that were delivered to it.\n\nIn a way, a consumer group can be imagined as some amount of state about a stream:\n`+----------------------------------------+\n| consumer_group_name: mygroup           |\n| consumer_group_stream: somekey         |\n| last_delivered_id: 1292309234234-92    |\n|                                        |\n| consumers:                             |\n|    \"consumer-1\" with pending messages  |\n|       1292309234234-4                  |\n|       1292309234232-8                  |\n|    \"consumer-42\" with pending messages |\n|       ... (and so forth)               |\n+----------------------------------------+`\nIf you see this from this point of view, it is very simple to understand what a consumer group can do, how it is able to just provide consumers with their history of pending messages, and how consumers asking for new messages will just be served with message IDs greater than `last_delivered_id`. At the same time, if you look at the consumer group as an auxiliary data structure for Redis streams, it is obvious that a single stream can have multiple consumer groups, that have a different set of consumers. Actually, it is even possible for the same stream to have clients reading without consumer groups via `XREAD`, and clients reading via `XREADGROUP` in different consumer groups.\nNow it's time to zoom in to see the fundamental consumer group commands. They are the following:\n\n`XGROUP` is used in order to create, destroy and manage consumer groups.\n`XREADGROUP` is used to read from a stream via a consumer group.\n`XACK` is the command that allows a consumer to mark a pending message as correctly processed.\n\nCreating a consumer group\nAssuming I have a key `mystream` of type stream already existing, in order to create a consumer group I just need to do the following:\n```\n\nXGROUP CREATE mystream mygroup $\nOK\n```\n\nAs you can see in the command above when creating the consumer group we have to specify an ID, which in the example is just `$`. This is needed because the consumer group, among the other states, must have an idea about what message to serve next at the first consumer connecting, that is, what was the last message ID when the group was just created. If we provide `$` as we did, then only new messages arriving in the stream from now on will be provided to the consumers in the group. If we specify `0` instead the consumer group will consume all the messages in the stream history to start with. Of course, you can specify any other valid ID. What you know is that the consumer group will start delivering messages that are greater than the ID you specify. Because `$` means the current greatest ID in the stream, specifying `$` will have the effect of consuming only new messages.\n`XGROUP CREATE` also supports creating the stream automatically, if it doesn't exist, using the optional `MKSTREAM` subcommand as the last argument:\n```\n\nXGROUP CREATE newstream mygroup $ MKSTREAM\nOK\n```\n\nNow that the consumer group is created we can immediately try to read messages via the consumer group using the `XREADGROUP` command. We'll read from consumers, that we will call Alice and Bob, to see how the system will return different messages to Alice or Bob.\n`XREADGROUP` is very similar to `XREAD` and provides the same BLOCK option, otherwise it is a synchronous command. However there is a mandatory option that must be always specified, which is GROUP and has two arguments: the name of the consumer group, and the name of the consumer that is attempting to read. The option COUNT is also supported and is identical to the one in `XREAD`.\nBefore reading from the stream, let's put some messages inside:\n```\n\nXADD mystream * message apple\n1526569495631-0\nXADD mystream * message orange\n1526569498055-0\nXADD mystream * message strawberry\n1526569506935-0\nXADD mystream * message apricot\n1526569535168-0\nXADD mystream * message banana\n1526569544280-0\n```\n\nNote: here message is the field name, and the fruit is the associated value, remember that stream items are small dictionaries.\nIt is time to try reading something using the consumer group:\n```\n\nXREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream >\n1) 1) \"mystream\"\n   2) 1) 1) 1526569495631-0\n         2) 1) \"message\"\n            2) \"apple\"\n```\n\n`XREADGROUP` replies are just like `XREAD` replies. Note however the `GROUP <group-name> <consumer-name>` provided above. It states that I want to read from the stream using the consumer group `mygroup` and I'm the consumer `Alice`. Every time a consumer performs an operation with a consumer group, it must specify its name, uniquely identifying this consumer inside the group.\nThere is another very important detail in the command line above, after the mandatory STREAMS option the ID requested for the key `mystream` is the special ID `>`. This special ID is only valid in the context of consumer groups, and it means: messages never delivered to other consumers so far.\nThis is almost always what you want, however it is also possible to specify a real ID, such as `0` or any other valid ID, in this case, however, what happens is that we request from `XREADGROUP` to just provide us with the history of pending messages, and in such case, will never see new messages in the group. So basically `XREADGROUP` has the following behavior based on the ID we specify:\n\nIf the ID is the special ID `>` then the command will return only new messages never delivered to other consumers so far, and as a side effect, will update the consumer group's last ID.\nIf the ID is any other valid numerical ID, then the command will let us access our history of pending messages. That is, the set of messages that were delivered to this specified consumer (identified by the provided name), and never acknowledged so far with `XACK`.\n\nWe can test this behavior immediately specifying an ID of 0, without any COUNT option: we'll just see the only pending message, that is, the one about apples:\n```\n\nXREADGROUP GROUP mygroup Alice STREAMS mystream 0\n1) 1) \"mystream\"\n   2) 1) 1) 1526569495631-0\n         2) 1) \"message\"\n            2) \"apple\"\n```\n\nHowever, if we acknowledge the message as processed, it will no longer be part of the pending messages history, so the system will no longer report anything:\n```\n\nXACK mystream mygroup 1526569495631-0\n(integer) 1\nXREADGROUP GROUP mygroup Alice STREAMS mystream 0\n1) 1) \"mystream\"\n   2) (empty list or set)\n```\n\nDon't worry if you yet don't know how `XACK` works, the idea is just that processed messages are no longer part of the history that we can access.\nNow it's Bob's turn to read something:\n```\n\nXREADGROUP GROUP mygroup Bob COUNT 2 STREAMS mystream >\n1) 1) \"mystream\"\n   2) 1) 1) 1526569498055-0\n         2) 1) \"message\"\n            2) \"orange\"\n      2) 1) 1526569506935-0\n         2) 1) \"message\"\n            2) \"strawberry\"\n```\n\nBob asked for a maximum of two messages and is reading via the same group `mygroup`. So what happens is that Redis reports just new messages. As you can see the \"apple\" message is not delivered, since it was already delivered to Alice, so Bob gets orange and strawberry, and so forth.\nThis way Alice, Bob, and any other consumer in the group, are able to read different messages from the same stream, to read their history of yet to process messages, or to mark messages as processed. This allows creating different topologies and semantics for consuming messages from a stream.\nThere are a few things to keep in mind:\n\nConsumers are auto-created the first time they are mentioned, no need for explicit creation.\nEven with `XREADGROUP` you can read from multiple keys at the same time, however for this to work, you need to create a consumer group with the same name in every stream. This is not a common need, but it is worth mentioning that the feature is technically available.\n`XREADGROUP` is a write command because even if it reads from the stream, the consumer group is modified as a side effect of reading, so it can only be called on master instances.\n\nAn example of a consumer implementation, using consumer groups, written in the Ruby language could be the following. The Ruby code is aimed to be readable by virtually any experienced programmer, even if they do not know Ruby:\n```ruby\nrequire 'redis'\nif ARGV.length == 0\n    puts \"Please specify a consumer name\"\n    exit 1\nend\nConsumerName = ARGV[0]\nGroupName = \"mygroup\"\nr = Redis.new\ndef process_message(id,msg)\n    puts \"[#{ConsumerName}] #{id} = #{msg.inspect}\"\nend\n$lastid = '0-0'\nputs \"Consumer #{ConsumerName} starting...\"\ncheck_backlog = true\nwhile true\n    # Pick the ID based on the iteration: the first time we want to\n    # read our pending messages, in case we crashed and are recovering.\n    # Once we consumed our history, we can start getting new messages.\n    if check_backlog\n        myid = $lastid\n    else\n        myid = '>'\n    end\n\n\n```items = r.xreadgroup('GROUP',GroupName,ConsumerName,'BLOCK','2000','COUNT','10','STREAMS',:my_stream_key,myid)\n\nif items == nil\n    puts \"Timeout!\"\n    next\nend\n\n# If we receive an empty reply, it means we were consuming our history\n# and that the history is now empty. Let's start to consume new messages.\ncheck_backlog = false if items[0][1].length == 0\n\nitems[0][1].each{|i|\n    id,fields = i\n\n    # Process the message\n    process_message(id,fields)\n\n    # Acknowledge the message as processed\n    r.xack(:my_stream_key,GroupName,id)\n\n    $lastid = id\n}\n```\n\n\nend\n```\nAs you can see the idea here is to start by consuming the history, that is, our list of pending messages. This is useful because the consumer may have crashed before, so in the event of a restart we want to re-read messages that were delivered to us without getting acknowledged. Note that we might process a message multiple times or one time (at least in the case of consumer failures, but there are also the limits of Redis persistence and replication involved, see the specific section about this topic).\nOnce the history was consumed, and we get an empty list of messages, we can switch to using the `>` special ID in order to consume new messages.\nRecovering from permanent failures\nThe example above allows us to write consumers that participate in the same consumer group, each taking a subset of messages to process, and when recovering from failures re-reading the pending messages that were delivered just to them. However in the real world consumers may permanently fail and never recover. What happens to the pending messages of the consumer that never recovers after stopping for any reason?\nRedis consumer groups offer a feature that is used in these situations in order to claim the pending messages of a given consumer so that such messages will change ownership and will be re-assigned to a different consumer. The feature is very explicit. A consumer has to inspect the list of pending messages, and will have to claim specific messages using a special command, otherwise the server will leave the messages pending forever and assigned to the old consumer. In this way different applications can choose if to use such a feature or not, and exactly how to use it.\nThe first step of this process is just a command that provides observability of pending entries in the consumer group and is called `XPENDING`.\nThis is a read-only command which is always safe to call and will not change ownership of any message.\nIn its simplest form, the command is called with two arguments, which are the name of the stream and the name of the consumer group.\n```\n\nXPENDING mystream mygroup\n1) (integer) 2\n2) 1526569498055-0\n3) 1526569506935-0\n4) 1) 1) \"Bob\"\n      2) \"2\"\n```\n\nWhen called in this way, the command outputs the total number of pending messages in the consumer group (two in this case), the lower and higher message ID among the pending messages, and finally a list of consumers and the number of pending messages they have.\nWe have only Bob with two pending messages because the single message that Alice requested was acknowledged using `XACK`.\nWe can ask for more information by giving more arguments to `XPENDING`, because the full command signature is the following:\n`XPENDING <key> <groupname> [[IDLE <min-idle-time>] <start-id> <end-id> <count> [<consumer-name>]]`\nBy providing a start and end ID (that can be just `-` and `+` as in `XRANGE`) and a count to control the amount of information returned by the command, we are able to know more about the pending messages. The optional final argument, the consumer name, is used if we want to limit the output to just messages pending for a given consumer, but won't use this feature in the following example.\n```\n\nXPENDING mystream mygroup - + 10\n1) 1) 1526569498055-0\n   2) \"Bob\"\n   3) (integer) 74170458\n   4) (integer) 1\n2) 1) 1526569506935-0\n   2) \"Bob\"\n   3) (integer) 74170458\n   4) (integer) 1\n```\n\nNow we have the details for each message: the ID, the consumer name, the idle time in milliseconds, which is how many milliseconds have passed since the last time the message was delivered to some consumer, and finally the number of times that a given message was delivered.\nWe have two messages from Bob, and they are idle for 74170458 milliseconds, about 20 hours.\nNote that nobody prevents us from checking what the first message content was by just using `XRANGE`.\n```\n\nXRANGE mystream 1526569498055-0 1526569498055-0\n1) 1) 1526569498055-0\n   2) 1) \"message\"\n      2) \"orange\"\n```\n\nWe have just to repeat the same ID twice in the arguments. Now that we have some ideas, Alice may decide that after 20 hours of not processing messages, Bob will probably not recover in time, and it's time to claim such messages and resume the processing in place of Bob. To do so, we use the `XCLAIM` command.\nThis command is very complex and full of options in its full form, since it is used for replication of consumer groups changes, but we'll use just the arguments that we need normally. In this case it is as simple as:\n`XCLAIM <key> <group> <consumer> <min-idle-time> <ID-1> <ID-2> ... <ID-N>`\nBasically we say, for this specific key and group, I want that the message IDs specified will change ownership, and will be assigned to the specified consumer name `<consumer>`. However, we also provide a minimum idle time, so that the operation will only work if the idle time of the mentioned messages is greater than the specified idle time. This is useful because maybe two clients are retrying to claim a message at the same time:\n`Client 1: XCLAIM mystream mygroup Alice 3600000 1526569498055-0\nClient 2: XCLAIM mystream mygroup Lora 3600000 1526569498055-0`\nHowever, as a side effect, claiming a message will reset its idle time and will increment its number of deliveries counter, so the second client will fail claiming it. In this way we avoid trivial re-processing of messages (even if in the general case you cannot obtain exactly once processing).\nThis is the result of the command execution:\n```\n\nXCLAIM mystream mygroup Alice 3600000 1526569498055-0\n1) 1) 1526569498055-0\n   2) 1) \"message\"\n      2) \"orange\"\n```\n\nThe message was successfully claimed by Alice, who can now process the message and acknowledge it, and move things forward even if the original consumer is not recovering.\nIt is clear from the example above that as a side effect of successfully claiming a given message, the `XCLAIM` command also returns it. However this is not mandatory. The JUSTID option can be used in order to return just the IDs of the message successfully claimed. This is useful if you want to reduce the bandwidth used between the client and the server (and also the performance of the command) and you are not interested in the message because your consumer is implemented in a way that it will rescan the history of pending messages from time to time.\nClaiming may also be implemented by a separate process: one that just checks the list of pending messages, and assigns idle messages to consumers that appear to be active. Active consumers can be obtained using one of the observability features of Redis streams. This is the topic of the next section.\nAutomatic claiming\nThe `XAUTOCLAIM` command, added in Redis 6.2, implements the claiming process that we've described above.\n`XPENDING` and `XCLAIM` provide the basic building blocks for different types of recovery mechanisms.\nThis command optimizes the generic process by having Redis manage it and offers a simple solution for most recovery needs.\n`XAUTOCLAIM` identifies idle pending messages and transfers ownership of them to a consumer.\nThe command's signature looks like this:\n`XAUTOCLAIM <key> <group> <consumer> <min-idle-time> <start> [COUNT count] [JUSTID]`\nSo, in the example above, I could have used automatic claiming to claim a single message like this:\n```\n\nXAUTOCLAIM mystream mygroup Alice 3600000 0-0 COUNT 1\n1) 1526569498055-0\n2) 1) 1526569498055-0\n   2) 1) \"message\"\n      2) \"orange\"\n```\n\nLike `XCLAIM`, the command replies with an array of the claimed messages, but it also returns a stream ID that allows iterating the pending entries.\nThe stream ID is a cursor, and I can use it in my next call to continue in claiming idle pending messages:\n```\n\nXAUTOCLAIM mystream mygroup Lora 3600000 1526569498055-0 COUNT 1\n1) 0-0\n2) 1) 1526569506935-0\n   2) 1) \"message\"\n      2) \"strawberry\"\n```\nWhen`XAUTOCLAIM`returns the \"0-0\" stream ID as a cursor, that means that it reached the end of the consumer group pending entries list.\nThat doesn't mean that there are no new idle pending messages, so the process continues by calling`XAUTOCLAIM` from the beginning of the stream.\n\nClaiming and the delivery counter\nThe counter that you observe in the `XPENDING` output is the number of deliveries of each message. The counter is incremented in two ways: when a message is successfully claimed via `XCLAIM` or when an `XREADGROUP` call is used in order to access the history of pending messages.\nWhen there are failures, it is normal that messages will be delivered multiple times, but eventually they usually get processed and acknowledged. However there might be a problem processing some specific message, because it is corrupted or crafted in a way that triggers a bug in the processing code. In such a case what happens is that consumers will continuously fail to process this particular message. Because we have the counter of the delivery attempts, we can use that counter to detect messages that for some reason are not processable. So once the deliveries counter reaches a given large number that you chose, it is probably wiser to put such messages in another stream and send a notification to the system administrator. This is basically the way that Redis Streams implements the dead letter concept.\nStreams observability\nMessaging systems that lack observability are very hard to work with. Not knowing who is consuming messages, what messages are pending, the set of consumer groups active in a given stream, makes everything opaque. For this reason, Redis Streams and consumer groups have different ways to observe what is happening. We already covered `XPENDING`, which allows us to inspect the list of messages that are under processing at a given moment, together with their idle time and number of deliveries.\nHowever we may want to do more than that, and the `XINFO` command is an observability interface that can be used with sub-commands in order to get information about streams or consumer groups.\nThis command uses subcommands in order to show different information about the status of the stream and its consumer groups. For instance XINFO STREAM  reports information about the stream itself.\n```\n\nXINFO STREAM mystream\n 1) \"length\"\n 2) (integer) 2\n 3) \"radix-tree-keys\"\n 4) (integer) 1\n 5) \"radix-tree-nodes\"\n 6) (integer) 2\n 7) \"last-generated-id\"\n 8) \"1638125141232-0\"\n 9) \"max-deleted-entryid\"\n10) \"0-0\"\n11) \"entries-added\"\n12) (integer) 2\n13) \"groups\"\n14) (integer) 1\n15) \"first-entry\"\n16) 1) \"1638125133432-0\"\n    2) 1) \"message\"\n       2) \"apple\"\n17) \"last-entry\"\n18) 1) \"1638125141232-0\"\n    2) 1) \"message\"\n       2) \"banana\"\n```\n\nThe output shows information about how the stream is encoded internally, and also shows the first and last message in the stream. Another piece of information available is the number of consumer groups associated with this stream. We can dig further asking for more information about the consumer groups.\n```\n\nXINFO GROUPS mystream\n1)  1) \"name\"\n    2) \"mygroup\"\n    3) \"consumers\"\n    4) (integer) 2\n    5) \"pending\"\n    6) (integer) 2\n    7) \"last-delivered-id\"\n    8) \"1638126030001-0\"\n    9) \"entries-read\"\n   10) (integer) 2\n   11) \"lag\"\n   12) (integer) 0\n2)  1) \"name\"\n    2) \"some-other-group\"\n    3) \"consumers\"\n    4) (integer) 1\n    5) \"pending\"\n    6) (integer) 0\n    7) \"last-delivered-id\"\n    8) \"1638126028070-0\"\n    9) \"entries-read\"\n   10) (integer) 1\n   11) \"lag\"\n   12) (integer) 1\n```\n\nAs you can see in this and in the previous output, the `XINFO` command outputs a sequence of field-value items. Because it is an observability command this allows the human user to immediately understand what information is reported, and allows the command to report more information in the future by adding more fields without breaking compatibility with older clients. Other commands that must be more bandwidth efficient, like `XPENDING`, just report the information without the field names.\nThe output of the example above, where the GROUPS subcommand is used, should be clear observing the field names. We can check in more detail the state of a specific consumer group by checking the consumers that are registered in the group.\n```\n\nXINFO CONSUMERS mystream mygroup\n1) 1) name\n   2) \"Alice\"\n   3) pending\n   4) (integer) 1\n   5) idle\n   6) (integer) 9104628\n2) 1) name\n   2) \"Bob\"\n   3) pending\n   4) (integer) 1\n   5) idle\n   6) (integer) 83841983\n```\n\nIn case you do not remember the syntax of the command, just ask the command itself for help:\n```\n\nXINFO HELP\n1) XINFO  [ [value] [opt] ...]. Subcommands are:\n2) CONSUMERS  \n3)     Show consumers of .\n4) GROUPS \n5)     Show the stream consumer groups.\n6) STREAM  [FULL [COUNT ]\n7)     Show information about the stream.\n8) HELP\n9)     Prints this help.\n```\n\nDifferences with Kafka (TM) partitions\nConsumer groups in Redis streams may resemble in some way Kafka (TM) partitioning-based consumer groups, however note that Redis streams are, in practical terms, very different. The partitions are only logical and the messages are just put into a single Redis key, so the way the different clients are served is based on who is ready to process new messages, and not from which partition clients are reading. For instance, if the consumer C3 at some point fails permanently, Redis will continue to serve C1 and C2 all the new messages arriving, as if now there are only two logical partitions.\nSimilarly, if a given consumer is much faster at processing messages than the other consumers, this consumer will receive proportionally more messages in the same unit of time. This is possible since Redis tracks all the unacknowledged messages explicitly, and remembers who received which message and the ID of the first message never delivered to any consumer.\nHowever, this also means that in Redis if you really want to partition messages in the same stream into multiple Redis instances, you have to use multiple keys and some sharding system such as Redis Cluster or some other application-specific sharding system. A single Redis stream is not automatically partitioned to multiple instances.\nWe could say that schematically the following is true:\n\nIf you use 1 stream -> 1 consumer, you are processing messages in order.\nIf you use N streams with N consumers, so that only a given consumer hits a subset of the N streams, you can scale the above model of 1 stream -> 1 consumer.\nIf you use 1 stream -> N consumers, you are load balancing to N consumers, however in that case, messages about the same logical item may be consumed out of order, because a given consumer may process message 3 faster than another consumer is processing message 4.\n\nSo basically Kafka partitions are more similar to using N different Redis keys, while Redis consumer groups are a server-side load balancing system of messages from a given stream to N different consumers.\nCapped Streams\nMany applications do not want to collect data into a stream forever. Sometimes it is useful to have at maximum a given number of items inside a stream, other times once a given size is reached, it is useful to move data from Redis to a storage which is not in memory and not as fast but suited to store the history for, potentially, decades to come. Redis streams have some support for this. One is the MAXLEN option of the `XADD` command. This option is very simple to use:\n```\n\nXADD mystream MAXLEN 2 * value 1\n1526654998691-0\nXADD mystream MAXLEN 2 * value 2\n1526654999635-0\nXADD mystream MAXLEN 2 * value 3\n1526655000369-0\nXLEN mystream\n(integer) 2\nXRANGE mystream - +\n1) 1) 1526654999635-0\n   2) 1) \"value\"\n      2) \"2\"\n2) 1) 1526655000369-0\n   2) 1) \"value\"\n      2) \"3\"\n```\n\nUsing MAXLEN the old entries are automatically evicted when the specified length is reached, so that the stream is left at a constant size. There is currently no option to tell the stream to just retain items that are not older than a given period, because such command, in order to run consistently, would potentially block for a long time in order to evict items. Imagine for example what happens if there is an insertion spike, then a long pause, and another insertion, all with the same maximum time. The stream would block to evict the data that became too old during the pause. So it is up to the user to do some planning and understand what is the maximum stream length desired. Moreover, while the length of the stream is proportional to the memory used, trimming by time is less simple to control and anticipate: it depends on the insertion rate which often changes over time (and when it does not change, then to just trim by size is trivial).\nHowever trimming with MAXLEN can be expensive: streams are represented by macro nodes into a radix tree, in order to be very memory efficient. Altering the single macro node, consisting of a few tens of elements, is not optimal. So it's possible to use the command in the following special form:\n`XADD mystream MAXLEN ~ 1000 * ... entry fields here ...`\nThe `~` argument between the MAXLEN option and the actual count means, I don't really need this to be exactly 1000 items. It can be 1000 or 1010 or 1030, just make sure to save at least 1000 items. With this argument, the trimming is performed only when we can remove a whole node. This makes it much more efficient, and it is usually what you want.\nThere is also the `XTRIM` command, which performs something very similar to what the MAXLEN option does above, except that it can be run by itself:\n```\n\nXTRIM mystream MAXLEN 10\n```\n\nOr, as for the `XADD` option:\n```\n\nXTRIM mystream MAXLEN ~ 10\n```\n\nHowever, `XTRIM` is designed to accept different trimming strategies. Another trimming strategy is MINID, that evicts entries with IDs lower than the one specified.\nAs `XTRIM` is an explicit command, the user is expected to know about the possible shortcomings of different trimming strategies.\nAnother useful eviction strategy that may be added to `XTRIM` in the future, is to remove by a range of IDs to ease use of `XRANGE` and `XTRIM` to move data from Redis to other storage systems if needed.\nSpecial IDs in the streams API\nYou may have noticed that there are several special IDs that can be used in the Redis API. Here is a short recap, so that they can make more sense in the future.\nThe first two special IDs are `-` and `+`, and are used in range queries with the `XRANGE` command. Those two IDs respectively mean the smallest ID possible (that is basically `0-1`) and the greatest ID possible (that is `18446744073709551615-18446744073709551615`). As you can see it is a lot cleaner to write `-` and `+` instead of those numbers.\nThen there are APIs where we want to say, the ID of the item with the greatest ID inside the stream. This is what `$` means. So for instance if I want only new entries with `XREADGROUP` I use this ID to signify I already have all the existing entries, but not the new ones that will be inserted in the future. Similarly when I create or set the ID of a consumer group, I can set the last delivered item to `$` in order to just deliver new entries to the consumers in the group.\nAs you can see `$` does not mean `+`, they are two different things, as `+` is the greatest ID possible in every possible stream, while `$` is the greatest ID in a given stream containing given entries. Moreover APIs will usually only understand `+` or `$`, yet it was useful to avoid loading a given symbol with multiple meanings.\nAnother special ID is `>`, that is a special meaning only related to consumer groups and only when the `XREADGROUP` command is used. This special ID means that we want only entries that were never delivered to other consumers so far. So basically the `>` ID is the last delivered ID of a consumer group.\nFinally the special ID `*`, that can be used only with the `XADD` command, means to auto select an ID for us for the new entry.\nSo we have `-`, `+`, `$`, `>` and `*`, and all have a different meaning, and most of the time, can be used in different contexts.\nPersistence, replication and message safety\nA Stream, like any other Redis data structure, is asynchronously replicated to replicas and persisted into AOF and RDB files. However what may not be so obvious is that also the consumer groups full state is propagated to AOF, RDB and replicas, so if a message is pending in the master, also the replica will have the same information. Similarly, after a restart, the AOF will restore the consumer groups' state.\nHowever note that Redis streams and consumer groups are persisted and replicated using the Redis default replication, so:\n\nAOF must be used with a strong fsync policy if persistence of messages is important in your application.\nBy default the asynchronous replication will not guarantee that `XADD` commands or consumer groups state changes are replicated: after a failover something can be missing depending on the ability of replicas to receive the data from the master.\nThe `WAIT` command may be used in order to force the propagation of the changes to a set of replicas. However note that while this makes it very unlikely that data is lost, the Redis failover process as operated by Sentinel or Redis Cluster performs only a best effort check to failover to the replica which is the most updated, and under certain specific failure conditions may promote a replica that lacks some data.\n\nSo when designing an application using Redis streams and consumer groups, make sure to understand the semantical properties your application should have during failures, and configure things accordingly, evaluating whether it is safe enough for your use case.\nRemoving single items from a stream\nStreams also have a special command for removing items from the middle of a stream, just by ID. Normally for an append only data structure this may look like an odd feature, but it is actually useful for applications involving, for instance, privacy regulations. The command is called `XDEL` and receives the name of the stream followed by the IDs to delete:\n```\n\nXRANGE mystream - + COUNT 2\n1) 1) 1526654999635-0\n   2) 1) \"value\"\n      2) \"2\"\n2) 1) 1526655000369-0\n   2) 1) \"value\"\n      2) \"3\"\nXDEL mystream 1526654999635-0\n(integer) 1\nXRANGE mystream - + COUNT 2\n1) 1) 1526655000369-0\n   2) 1) \"value\"\n      2) \"3\"\n```\n\nHowever in the current implementation, memory is not really reclaimed until a macro node is completely empty, so you should not abuse this feature.\nZero length streams\nA difference between streams and other Redis data structures is that when the other data structures no longer have any elements, as a side effect of calling commands that remove elements, the key itself will be removed. So for instance, a sorted set will be completely removed when a call to `ZREM` will remove the last element in the sorted set. Streams, on the other hand, are allowed to stay at zero elements, both as a result of using a MAXLEN option with a count of zero (`XADD` and `XTRIM` commands), or because `XDEL` was called.\nThe reason why such an asymmetry exists is because Streams may have associated consumer groups, and we do not want to lose the state that the consumer groups defined just because there are no longer any items in the stream. Currently the stream is not deleted even when it has no associated consumer groups.\nTotal latency of consuming a message\nNon blocking stream commands like `XRANGE` and `XREAD` or `XREADGROUP` without the BLOCK option are served synchronously like any other Redis command, so to discuss latency of such commands is meaningless: it is more interesting to check the time complexity of the commands in the Redis documentation. It should be enough to say that stream commands are at least as fast as sorted set commands when extracting ranges, and that `XADD` is very fast and can easily insert from half a million to one million items per second in an average machine if pipelining is used.\nHowever latency becomes an interesting parameter if we want to understand the delay of processing a message, in the context of blocking consumers in a consumer group, from the moment the message is produced via `XADD`, to the moment the message is obtained by the consumer because `XREADGROUP` returned with the message.\nHow serving blocked consumers works\nBefore providing the results of performed tests, it is interesting to understand what model Redis uses in order to route stream messages (and in general actually how any blocking operation waiting for data is managed).\n\nThe blocked client is referenced in a hash table that maps keys for which there is at least one blocking consumer, to a list of consumers that are waiting for such key. This way, given a key that received data, we can resolve all the clients that are waiting for such data.\nWhen a write happens, in this case when the `XADD` command is called, it calls the `signalKeyAsReady()` function. This function will put the key into a list of keys that need to be processed, because such keys may have new data for blocked consumers. Note that such ready keys will be processed later, so in the course of the same event loop cycle, it is possible that the key will receive other writes.\nFinally, before returning into the event loop, the ready keys are finally processed. For each key the list of clients waiting for data is scanned, and if applicable, such clients will receive the new data that arrived. In the case of streams the data is the messages in the applicable range requested by the consumer.\n\nAs you can see, basically, before returning to the event loop both the client calling `XADD` and the clients blocked to consume messages, will have their reply in the output buffers, so the caller of `XADD` should receive the reply from Redis at about the same time the consumers will receive the new messages.\nThis model is push-based, since adding data to the consumers buffers will be performed directly by the action of calling `XADD`, so the latency tends to be quite predictable.\nLatency tests results\nIn order to check these latency characteristics a test was performed using multiple instances of Ruby programs pushing messages having as an additional field the computer millisecond time, and Ruby programs reading the messages from the consumer group and processing them. The message processing step consisted of comparing the current computer time with the message timestamp, in order to understand the total latency.\nResults obtained:\n`Processed between 0 and 1 ms -> 74.11%\nProcessed between 1 and 2 ms -> 25.80%\nProcessed between 2 and 3 ms -> 0.06%\nProcessed between 3 and 4 ms -> 0.01%\nProcessed between 4 and 5 ms -> 0.02%`\nSo 99.9% of requests have a latency <= 2 milliseconds, with the outliers that remain still very close to the average.\nAdding a few million unacknowledged messages to the stream does not change the gist of the benchmark, with most queries still processed with very short latency.\nA few remarks:\n\nHere we processed up to 10k messages per iteration, this means that the `COUNT` parameter of `XREADGROUP` was set to 10000. This adds a lot of latency but is needed in order to allow the slow consumers to be able to keep with the message flow. So you can expect a real world latency that is a lot smaller.\n",
    "tag": "redis"
  },
  {
    "title": "Core",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/data-types/_index.md",
    "content": "\ntitle: \"Redis data types\"\nlinkTitle: \"Data types\"\ndescription: Overview of data types supported by Redis\nweight: 40\naliases:\n    - /docs/manual/data-types\n    - /topics/data-types\n\nRedis is a data structure server.\nAt its core, Redis provides a collection of native data types that help you solve a wide variety of problems, from caching to queuing to event processing.\nBelow is a short description of each data type, with links to broader overviews and command references.\nIf you'd like to try a comprehensive tutorial, see the Redis data types tutorial.\nCore\nStrings\nRedis strings are the most basic Redis data type, representing a sequence of bytes.\nFor more information, see:\n\nOverview of Redis strings\nRedis string command reference\n\nLists\nRedis lists are lists of strings sorted by insertion order.\nFor more information, see:\n\nOverview of Redis lists\nRedis list command reference\n\nSets\nRedis sets are unordered collections of unique strings that act like the sets from your favorite programming language (for example, Java HashSets, Python sets, and so on).\nWith a Redis set, you can add, remove, and test for existence O(1) time (in other words, regardless of the number of set elements).\nFor more information, see:\n\nOverview of Redis sets\nRedis set command reference\n\nHashes\nRedis hashes are record types modeled as collections of field-value pairs.\nAs such, Redis hashes resemble Python dictionaries, Java HashMaps, and Ruby hashes.\nFor more information, see:\n\nOverview of Redis hashes\nRedis hashes command reference\n\nSorted sets\nRedis sorted sets are collections of unique strings that maintain order by each string's associated score.\nFor more information, see:\n\nOverview of Redis sorted sets\nRedis sorted set command reference\n\nStreams\nA Redis stream is a data structure that acts like an append-only log.\nStreams help record events in the order they occur and then syndicate them for processing.\nFor more information, see:\n\nOverview of Redis Streams\nRedis Streams command reference\nRedis Streams tutorial\n\nGeospatial indexes\nRedis geospatial indexes are useful for finding locations within a given geographic radius or bounding box.\nFor more information, see:\n\nOverview of Redis geospatial indexes\nRedis geospatial indexes command reference\n\nBitmaps\nRedis bitmaps let you perform bitwise operations on strings. \nFor more information, see:\n\nOverview of Redis bitmaps\nRedis bitmap command reference\n\nBitfields\nRedis bitfields efficiently encode multiple counters in a string value.\nBitfields provide atomic get, set, and increment operations and support different overflow policies.\nFor more information, see:\n\nOverview of Redis bitfields\nThe `BITFIELD` command.\n\nHyperLogLog\nThe Redis HyperLogLog data structures provide probabilistic estimates of the cardinality (i.e., number of elements) of large sets. For more information, see:\n\nOverview of Redis HyperLogLog\nRedis HyperLogLog command reference\n\nExtensions\nTo extend the features provided by the included data types, use one of these options:\n\nWrite your own custom server-side functions in Lua.\nWrite your own Redis module using the modules API or check out the community-supported modules.\n",
    "tag": "redis"
  },
  {
    "title": "Safety of replication when master has persistence turned off",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/replication.md",
    "content": "\ntitle: Redis replication\nlinkTitle: Replication\nweight: 5\ndescription: How Redis supports high availability and failover with replication\naliases: [\n    /topics/replication,\n    /topics/replication.md,\n    /docs/manual/replication,\n    /docs/manual/replication.md\n]\n\nAt the base of Redis replication (excluding the high availability features provided as an additional layer by Redis Cluster or Redis Sentinel) there is a leader follower (master-replica) replication that is simple to use and configure. It allows replica Redis instances to be exact copies of master instances. The replica will automatically reconnect to the master every time the link breaks, and will attempt to be an exact copy of it regardless of what happens to the master.\nThis system works using three main mechanisms:\n\nWhen a master and a replica instances are well-connected, the master keeps the replica updated by sending a stream of commands to the replica to replicate the effects on the dataset happening in the master side due to: client writes, keys expired or evicted, any other action changing the master dataset.\nWhen the link between the master and the replica breaks, for network issues or because a timeout is sensed in the master or the replica, the replica reconnects and attempts to proceed with a partial resynchronization: it means that it will try to just obtain the part of the stream of commands it missed during the disconnection.\nWhen a partial resynchronization is not possible, the replica will ask for a full resynchronization. This will involve a more complex process in which the master needs to create a snapshot of all its data, send it to the replica, and then continue sending the stream of commands as the dataset changes.\n\nRedis uses by default asynchronous replication, which being low latency and\nhigh performance, is the natural replication mode for the vast majority of Redis\nuse cases. However, Redis replicas asynchronously acknowledge the amount of data\nthey received periodically with the master. So the master does not wait every time\nfor a command to be processed by the replicas, however it knows, if needed, what\nreplica already processed what command. This allows having optional synchronous replication.\nSynchronous replication of certain data can be requested by the clients using\nthe `WAIT` command. However `WAIT` is only able to ensure there are the\nspecified number of acknowledged copies in the other Redis instances, it does not\nturn a set of Redis instances into a CP system with strong consistency: acknowledged\nwrites can still be lost during a failover, depending on the exact configuration\nof the Redis persistence. However with `WAIT` the probability of losing a write\nafter a failure event is greatly reduced to certain hard to trigger failure\nmodes.\nYou can check the Redis Sentinel or Redis Cluster documentation for more information\nabout high availability and failover. The rest of this document mainly describes the basic characteristics of Redis basic replication.\nImportant facts about Redis replication\n\nRedis uses asynchronous replication, with asynchronous replica-to-master acknowledges of the amount of data processed.\nA master can have multiple replicas.\nReplicas are able to accept connections from other replicas. Aside from connecting a number of replicas to the same master, replicas can also be connected to other replicas in a cascading-like structure. Since Redis 4.0, all the sub-replicas will receive exactly the same replication stream from the master.\nRedis replication is non-blocking on the master side. This means that the master will continue to handle queries when one or more replicas perform the initial synchronization or a partial resynchronization.\nReplication is also largely non-blocking on the replica side. While the replica is performing the initial synchronization, it can handle queries using the old version of the dataset, assuming you configured Redis to do so in redis.conf.  Otherwise, you can configure Redis replicas to return an error to clients if the replication stream is down. However, after the initial sync, the old dataset must be deleted and the new one must be loaded. The replica will block incoming connections during this brief window (that can be as long as many seconds for very large datasets). Since Redis 4.0 you can configure Redis so that the deletion of the old data set happens in a different thread, however loading the new initial dataset will still happen in the main thread and block the replica.\nReplication can be used both for scalability, to have multiple replicas for read-only queries (for example, slow O(N) operations can be offloaded to replicas), or simply for improving data safety and high availability.\nYou can use replication to avoid the cost of having the master writing the full dataset to disk: a typical technique involves configuring your master `redis.conf` to avoid persisting to disk at all, then connect a replica configured to save from time to time, or with AOF enabled. However, this setup must be handled with care, since a restarting master will start with an empty dataset: if the replica tries to sync with it, the replica will be emptied as well.\n\nSafety of replication when master has persistence turned off\nIn setups where Redis replication is used, it is strongly advised to have\npersistence turned on in the master and in the replicas. When this is not possible,\nfor example because of latency concerns due to very slow disks, instances should\nbe configured to avoid restarting automatically after a reboot.\nTo better understand why masters with persistence turned off configured to\nauto restart are dangerous, check the following failure mode where data\nis wiped from the master and all its replicas:\n\nWe have a setup with node A acting as master, with persistence turned down, and nodes B and C replicating from node A.\nNode A crashes, however it has some auto-restart system, that restarts the process. However since persistence is turned off, the node restarts with an empty data set.\nNodes B and C will replicate from node A, which is empty, so they'll effectively destroy their copy of the data.\n\nWhen Redis Sentinel is used for high availability, also turning off persistence\non the master, together with auto restart of the process, is dangerous. For example the master can restart fast enough for Sentinel to not detect a failure, so that the failure mode described above happens.\nEvery time data safety is important, and replication is used with master configured without persistence, auto restart of instances should be disabled.\nHow Redis replication works\nEvery Redis master has a replication ID: it is a large pseudo random string\nthat marks a given story of the dataset. Each master also takes an offset that\nincrements for every byte of replication stream that it is produced to be\nsent to replicas, to update the state of the replicas with the new changes\nmodifying the dataset. The replication offset is incremented even if no replica\nis actually connected, so basically every given pair of:\n\n\n```Replication ID, offset\n```\n\n\nIdentifies an exact version of the dataset of a master.\nWhen replicas connect to masters, they use the `PSYNC` command to send\ntheir old master replication ID and the offsets they processed so far. This way\nthe master can send just the incremental part needed. However if there is not\nenough backlog in the master buffers, or if the replica is referring to an\nhistory (replication ID) which is no longer known, then a full resynchronization\nhappens: in this case the replica will get a full copy of the dataset, from scratch.\nThis is how a full synchronization works in more details:\nThe master starts a background saving process to produce an RDB file. At the same time it starts to buffer all new write commands received from the clients. When the background saving is complete, the master transfers the database file to the replica, which saves it on disk, and then loads it into memory. The master will then send all buffered commands to the replica. This is done as a stream of commands and is in the same format of the Redis protocol itself.\nYou can try it yourself via telnet. Connect to the Redis port while the\nserver is doing some work and issue the `SYNC` command. You'll see a bulk\ntransfer and then every command received by the master will be re-issued\nin the telnet session. Actually `SYNC` is an old protocol no longer used by\nnewer Redis instances, but is still there for backward compatibility: it does\nnot allow partial resynchronizations, so now `PSYNC` is used instead.\nAs already said, replicas are able to automatically reconnect when the master-replica link goes down for some reason. If the master receives multiple concurrent replica synchronization requests, it performs a single background save in to serve all of them.\nReplication ID explained\nIn the previous section we said that if two instances have the same replication\nID and replication offset, they have exactly the same data. However it is useful\nto understand what exactly is the replication ID, and why instances have actually\ntwo replication IDs: the main ID and the secondary ID.\nA replication ID basically marks a given history of the data set. Every time\nan instance restarts from scratch as a master, or a replica is promoted to master,\na new replication ID is generated for this instance. The replicas connected to\na master will inherit its replication ID after the handshake. So two instances\nwith the same ID are related by the fact that they hold the same data, but\npotentially at a different time. It is the offset that works as a logical time\nto understand, for a given history (replication ID), who holds the most updated\ndata set.\nFor instance, if two instances A and B have the same replication ID, but one\nwith offset 1000 and one with offset 1023, it means that the first lacks certain\ncommands applied to the data set. It also means that A, by applying just a few\ncommands, may reach exactly the same state of B.\nThe reason why Redis instances have two replication IDs is because of replicas\nthat are promoted to masters. After a failover, the promoted replica requires\nto still remember what was its past replication ID, because such replication ID\nwas the one of the former master. In this way, when other replicas will sync\nwith the new master, they will try to perform a partial resynchronization using the\nold master replication ID. This will work as expected, because when the replica\nis promoted to master it sets its secondary ID to its main ID, remembering what\nwas the offset when this ID switch happened. Later it will select a new random\nreplication ID, because a new history begins. When handling the new replicas\nconnecting, the master will match their IDs and offsets both with the current\nID and the secondary ID (up to a given offset, for safety). In short this means\nthat after a failover, replicas connecting to the newly promoted master don't have\nto perform a full sync.\nIn case you wonder why a replica promoted to master needs to change its\nreplication ID after a failover: it is possible that the old master is still\nworking as a master because of some network partition: retaining the same\nreplication ID would violate the fact that the same ID and same offset of any\ntwo random instances mean they have the same data set.\nDiskless replication\nNormally a full resynchronization requires creating an RDB file on disk,\nthen reloading the same RDB from disk to feed the replicas with the data.\nWith slow disks this can be a very stressing operation for the master.\nRedis version 2.8.18 is the first version to have support for diskless\nreplication. In this setup the child process directly sends the\nRDB over the wire to replicas, without using the disk as intermediate storage.\nConfiguration\nTo configure basic Redis replication is trivial: just add the following line to the replica configuration file:\n\n\n```replicaof 192.168.1.1 6379\n```\n\n\nOf course you need to replace 192.168.1.1 6379 with your master IP address (or\nhostname) and port. Alternatively, you can call the `REPLICAOF` command and the\nmaster host will start a sync with the replica.\nThere are also a few parameters for tuning the replication backlog taken\nin memory by the master to perform the partial resynchronization. See the example\n`redis.conf` shipped with the Redis distribution for more information.\nDiskless replication can be enabled using the `repl-diskless-sync` configuration\nparameter. The delay to start the transfer to wait for more replicas to\narrive after the first one is controlled by the `repl-diskless-sync-delay`\nparameter. Please refer to the example `redis.conf` file in the Redis distribution\nfor more details.\nRead-only replica\nSince Redis 2.6, replicas support a read-only mode that is enabled by default.\nThis behavior is controlled by the `replica-read-only` option in the redis.conf file, and can be enabled and disabled at runtime using `CONFIG SET`.\nRead-only replicas will reject all write commands, so that it is not possible to write to a replica because of a mistake. This does not mean that the feature is intended to expose a replica instance to the internet or more generally to a network where untrusted clients exist, because administrative commands like `DEBUG` or `CONFIG` are still enabled. The Security page describes how to secure a Redis instance.\nYou may wonder why it is possible to revert the read-only setting\nand have replica instances that can be targeted by write operations.\nThe answer is that writable replicas exist only for historical reasons.\nUsing writable replicas can result in inconsistency between the master and the replica, so it is not recommended to use writable replicas.\nTo understand in which situations this can be a problem, we need to understand how replication works.\nChanges on the master is replicated by propagating regular Redis commands to the replica.\nWhen a key expires on the master, this is propagated as a DEL command.\nIf a key which exists on the master but is deleted, expired or has a different type on the replica compared to the master will react differently to commands like DEL, INCR or RPOP propagated from the master than intended.\nThe propagated command may fail on the replica or result in a different outcome.\nTo minimize the risks (if you insist on using writable replicas) we suggest you follow these recommendations:\n\n\nDon't write to keys in a writable replica that are also used on the master.\n  (This can be hard to guarantee if you don't have control over all the clients that write to the master.)\n\n\nDon't configure an instance as a writable replica as an intermediary step when upgrading a set of instances in a running system.\n  In general, don't configure an instance as a writable replica if it can ever be promoted to a master if you want to guarantee data consistency.\n\n\nHistorically, there were some use cases that were considered legitimate for writable replicas.\nAs of version 7.0, these use cases are now all obsolete and the same can be achieved by other means.\nFor example:\n\n\nComputing slow Set or Sorted set operations and storing the result in temporary local keys using commands like SUNIONSTORE and ZINTERSTORE.\n  Instead, use commands that return the result without storing it, such as SUNION and ZINTER.\n\n\nUsing the SORT command (which is not considered a read-only command because of the optional STORE option and therefore cannot be used on a read-only replica).\n  Instead, use SORT_RO, which is a read-only command.\n\n\nUsing EVAL and EVALSHA are also not considered read-only commands, because the Lua script may call write commands.\n  Instead, use EVAL_RO and EVALSHA_RO where the Lua script can only call read-only commands.\n\n\nWhile writes to a replica will be discarded if the replica and the master resync or if the replica is restarted, there is no guarantee that they will sync automatically.\nBefore version 4.0, writable replicas were incapable of expiring keys with a time to live set.\nThis means that if you use `EXPIRE` or other commands that set a maximum TTL for a key, the key will leak, and while you may no longer see it while accessing it with read commands, you will see it in the count of keys and it will still use memory.\nRedis 4.0 RC3 and greater versions are able to evict keys with TTL as masters do, with the exceptions of keys written in DB numbers greater than 63 (but by default Redis instances only have 16 databases).\nNote though that even in versions greater than 4.0, using `EXPIRE` on a key that could ever exists on the master can cause inconsistency between the replica and the master.\nAlso note that since Redis 4.0 replica writes are only local, and are not propagated to sub-replicas attached to the instance. Sub-replicas instead will always receive the replication stream identical to the one sent by the top-level master to the intermediate replicas. So for example in the following setup:\n\n\n```A ---> B ---> C\n```\n\n\nEven if `B` is writable, C will not see `B` writes and will instead have identical dataset as the master instance `A`.\nSetting a replica to authenticate to a master\nIf your master has a password via `requirepass`, it's trivial to configure the\nreplica to use that password in all sync operations.\nTo do it on a running instance, use `redis-cli` and type:\n\n\n```config set masterauth <password>\n```\n\n\nTo set it permanently, add this to your config file:\n\n\n```masterauth <password>\n```\n\n\nAllow writes only with N attached replicas\nStarting with Redis 2.8, you can configure a Redis master to\naccept write queries only if at least N replicas are currently connected to the\nmaster.\nHowever, because Redis uses asynchronous replication it is not possible to ensure\nthe replica actually received a given write, so there is always a window for data\nloss.\nThis is how the feature works:\n\nRedis replicas ping the master every second, acknowledging the amount of replication stream processed.\nRedis masters will remember the last time it received a ping from every replica.\nThe user can configure a minimum number of replicas that have a lag not greater than a maximum number of seconds.\n\nIf there are at least N replicas, with a lag less than M seconds, then the write will be accepted.\nYou may think of it as a best effort data safety mechanism, where consistency is not ensured for a given write, but at least the time window for data loss is restricted to a given number of seconds. In general bound data loss is better than unbound one.\nIf the conditions are not met, the master will instead reply with an error and the write will not be accepted.\nThere are two configuration parameters for this feature:\n\nmin-replicas-to-write `<number of replicas>`\nmin-replicas-max-lag `<number of seconds>`\n\nFor more information, please check the example `redis.conf` file shipped with the\nRedis source distribution.\nHow Redis replication deals with expires on keys\nRedis expires allow keys to have a limited time to live (TTL). Such a feature depends\non the ability of an instance to count the time, however Redis replicas correctly\nreplicate keys with expires, even when such keys are altered using Lua\nscripts.\nTo implement such a feature Redis cannot rely on the ability of the master and\nreplica to have synced clocks, since this is a problem that cannot be solved\nand would result in race conditions and diverging data sets, so Redis\nuses three main techniques to make the replication of expired keys\nable to work:\n\nReplicas don't expire keys, instead they wait for masters to expire the keys. When a master expires a key (or evict it because of LRU), it synthesizes a `DEL` command which is transmitted to all the replicas.\nHowever because of master-driven expire, sometimes replicas may still have in memory keys that are already logically expired, since the master was not able to provide the `DEL` command in time. To deal with that the replica uses its logical clock to report that a key does not exist only for read operations that don't violate the consistency of the data set (as new commands from the master will arrive). In this way replicas avoid reporting logically expired keys that are still existing. In practical terms, an HTML fragments cache that uses replicas to scale will avoid returning items that are already older than the desired time to live.\nDuring Lua scripts executions no key expiries are performed. As a Lua script runs, conceptually the time in the master is frozen, so that a given key will either exist or not for all the time the script runs. This prevents keys expiring in the middle of a script, and is needed to send the same script to the replica in a way that is guaranteed to have the same effects in the data set.\n\nOnce a replica is promoted to a master it will start to expire keys independently, and will not require any help from its old master.\nConfiguring replication in Docker and NAT\nWhen Docker, or other types of containers using port forwarding, or Network Address Translation is used, Redis replication needs some extra care, especially when using Redis Sentinel or other systems where the master `INFO` or `ROLE` commands output is scanned to discover replicas' addresses.\nThe problem is that the `ROLE` command, and the replication section of\nthe `INFO` output, when issued into a master instance, will show replicas\nas having the IP address they use to connect to the master, which, in\nenvironments using NAT may be different compared to the logical address of the\nreplica instance (the one that clients should use to connect to replicas).\nSimilarly the replicas will be listed with the listening port configured\ninto `redis.conf`, that may be different from the forwarded port in case\nthe port is remapped.\nTo fix both issues, it is possible, since Redis 3.2.2, to force\na replica to announce an arbitrary pair of IP and port to the master.\nThe two configurations directives to use are:\n\n\n```replica-announce-ip 5.5.5.5\nreplica-announce-port 1234\n```\n\n\nAnd are documented in the example `redis.conf` of recent Redis distributions.\nThe INFO and ROLE command\nThere are two Redis commands that provide a lot of information on the current\nreplication parameters of master and replica instances. One is `INFO`. If the\ncommand is called with the `replication` argument as `INFO replication` only\ninformation relevant to the replication are displayed. Another more\ncomputer-friendly command is `ROLE`, that provides the replication status of\nmasters and replicas together with their replication offsets, list of connected\nreplicas and so forth.\nPartial sync after restarts and failovers\nSince Redis 4.0, when an instance is promoted to master after a failover,\nit will still be able to perform a partial resynchronization with the replicas\nof the old master. To do so, the replica remembers the old replication ID and\noffset of its former master, so can provide part of the backlog to the connecting\nreplicas even if they ask for the old replication ID.\nHowever the new replication ID of the promoted replica will be different, since it\nconstitutes a different history of the data set. For example, the master can\nreturn available and can continue accepting writes for some time, so using the\nsame replication ID in the promoted replica would violate the rule that a\nreplication ID and offset pair identifies only a single data set.\nMoreover, replicas - when powered off gently and restarted - are able to store\nin the `RDB` file the information needed to resync with their\nmaster. This is useful in case of upgrades. When this is needed, it is better to\nuse the `SHUTDOWN` command in order to perform a `save & quit` operation on the\nreplica.\nIt is not possible to partially sync a replica that restarted via the\nAOF file. However the instance may be turned to RDB persistence before shutting\ndown it, than can be restarted, and finally AOF can be enabled again.\n`Maxmemory` on replicas\nBy default, a replica will ignore `maxmemory` (unless it is promoted to master after a failover or manually).\nIt means that the eviction of keys will be handled by the master, sending the DEL commands to the replica as keys evict in the master side.\nThis behavior ensures that masters and replicas stay consistent, which is usually what you want.\nHowever, if your replica is writable, or you want the replica to have a different memory setting, and you are sure all the writes performed to the replica are idempotent, then you may change this default (but be sure to understand what you are doing).\nNote that since the replica by default does not evict, it may end up using more memory than what is set via `maxmemory` (since there are certain buffers that may be larger on the replica, or data structures may sometimes take more memory and so forth).\nMake sure you monitor your replicas, and make sure they have enough memory to never hit a real out-of-memory condition before the master hits the configured `maxmemory` setting.\nTo change this behavior, you can allow a replica to not ignore the `maxmemory`. The configuration directives to use is:",
    "tag": "redis"
  },
  {
    "title": "Redis setup tips",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/admin.md",
    "content": "\ntitle: Redis administration\nlinkTitle: Administration\nweight: 1\ndescription: Advice for configuring and managing Redis in production\naliases: [\n    /topics/admin,\n    /topics/admin.md,\n    /manual/admin,\n    /manual/admin.md\n]\n\nRedis setup tips\nLinux\n\n\nDeploy Redis using the Linux operating system. Redis is also tested on OS X, and from time to time on FreeBSD and OpenBSD systems. However, Linux is where most of the stress testing is performed, and where most production deployments are run.\n\n\nSet the Linux kernel overcommit memory setting to 1. Add `vm.overcommit_memory = 1` to `/etc/sysctl.conf`. Then, reboot or run the command `sysctl vm.overcommit_memory=1` to activate the setting.\n\n\nTo ensure the Linux kernel feature Transparent Huge Pages does not impact Redis memory usage and latency, use this command:\n\n\n`echo never > /sys/kernel/mm/transparent_hugepage/enabled`\nMemory\n\n\nEnsured that swap is enabled and that your swap file size is equal to amount of memory on your system. If Linux does not have swap set up, and your Redis instance accidentally consumes too much memory, Redis can crash when it is out of memory, or the Linux kernel OOM killer can kill the Redis process. When swapping is enabled, you can detect latency spikes and act on them.\n\n\nSet an explicit `maxmemory` option limit in your instance to make sure that it will report errors instead of failing when the system memory limit is near to be reached. Note that `maxmemory` should be set by calculating the overhead for Redis, other than data, and the fragmentation overhead. So if you think you have 10 GB of free memory, set it to 8 or 9.\n\n\nIf you are using Redis in a write-heavy application, while saving an RDB file on disk or rewriting the AOF log, Redis can use up to 2 times the memory normally used. The additional memory used is proportional to the number of memory pages modified by writes during the saving process, so it is often proportional to the number of keys (or aggregate types items) touched during this time. Make sure to size your memory accordingly.\n\n\nSee the `LATENCY DOCTOR` and `MEMORY DOCTOR` commands to assist in troubleshooting.\n\n\nImaging\n\nWhen running under daemontools, use `daemonize no`.\n\nReplication\n\n\nSet up a non-trivial replication backlog in proportion to the amount of memory Redis is using. The backlog allows replicas to sync with the primary (master) instance much more easily.\n\n\nIf you use replication, Redis performs RDB saves even if persistence is disabled. (This does not apply to diskless replication.) If you don't have disk usage on the master, enable diskless replication.\n\n\nIf you are using replication, ensure that either your master has persistence enabled, or that it does not automatically restart on crashes. Replicas will try to maintain an exact copy of the master, so if a master restarts with an empty data set, replicas will be wiped as well.\n\n\nSecurity\n\nBy default, Redis does not require any authentication and listens to all the network interfaces. This is a big security issue if you leave Redis exposed on the internet or other places where attackers can reach it. See for example this attack to see how dangerous it can be. Please check our security page and the quick start for information about how to secure Redis.\n\nRunning Redis on EC2\n\nUse HVM based instances, not PV based instances.\nDo not use old instance families. For example, use m3.medium with HVM instead of m1.medium with PV.\nThe use of Redis persistence with EC2 EBS volumes needs to be handled with care because sometimes EBS volumes have high latency characteristics.\nYou may want to try the new diskless replication if you have issues when replicas are synchronizing with the master.\n\nUpgrading or restarting a Redis instance without downtime\nRedis is designed to be a long-running process in your server. You can modify many configuration options without a restart using the CONFIG SET command. You can also switch from AOF to RDB snapshots persistence, or the other way around, without restarting Redis. Check the output of the `CONFIG GET *` command for more information.\nFrom time to time, a restart is required, for example, to upgrade the Redis process to a newer version, or when you need to modify a configuration parameter that is currently not supported by the `CONFIG` command.\nFollow these steps to avoid downtime.\n\n\nSet up your new Redis instance as a replica for your current Redis instance. In order to do so, you need a different server, or a server that has enough RAM to keep two instances of Redis running at the same time.\n\n\nIf you use a single server, ensure that the replica is started on a different port than the master instance, otherwise the replica cannot start.\n\n\nWait for the replication initial synchronization to complete. Check the replica's log file.\n\n\nUsing `INFO`, ensure the master and replica have the same number of keys. Use `redis-cli` to check that the replica is working as expected and is replying to your commands.\n\n\nAllow writes to the replica using `CONFIG SET slave-read-only no`.\n\n\nConfigure all your clients to use the new instance (the replica). Note that you may want to use the `CLIENT PAUSE` command to ensure that no client can write to the old master during the switch.\n\n\nOnce you confirm that the master is no longer receiving any queries (you can check this using the MONITOR command), elect the replica to master using the `REPLICAOF NO ONE` command, and then shut down your master.\n\n\nIf you are using Redis Sentinel or Redis Cluster, the simplest way to upgrade to newer versions is to upgrade one replica after the other. Then you can perform a manual failover to promote one of the upgraded replicas to master, and finally promote the last replica.\n\nNOTE \nRedis Cluster 4.0 is not compatible with Redis Cluster 3.2 at cluster bus protocol level, so a mass restart is needed in this case. However, Redis 5 cluster bus is backward compatible with Redis 4.",
    "tag": "redis"
  },
  {
    "title": "troubleshooting.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/troubleshooting.md",
    "content": "\ntitle: \"Troubleshooting Redis\"\nlinkTitle: \"Troubleshooting\"\nweight: 9\ndescription: Problems with Redis? Start here.\naliases: [\n    /topics/problems,\n    /docs/manual/troubleshooting,\n    /docs/manual/troubleshooting.md\n]\n\nThis page tries to help you with what to do if you have issues with Redis. Part of the Redis project is helping people that are experiencing problems because we don't like to leave people alone with their issues.\n\nIf you have latency problems with Redis, that in some way appears to be idle for some time, read our Redis latency troubleshooting guide.\nRedis stable releases are usually very reliable, however in the rare event you are experiencing crashes the developers can help a lot more if you provide debugging information. Please read our Debugging Redis guide.\nWe have a long history of users experiencing crashes with Redis that actually turned out to be servers with broken RAM. Please test your RAM using redis-server --test-memory in case Redis is not stable in your system. Redis built-in memory test is fast and reasonably reliable, but if you can you should reboot your server and use memtest86.\n\nFor every other problem please drop a message to the Redis Google Group. We will be glad to help.\nYou can also find assistance on the Redis Discord server.\nList of known critical bugs in Redis 3.0.x, 2.8.x and 2.6.x\nTo find a list of critical bugs please refer to the changelogs:\n\nRedis 3.0 Changelog.\nRedis 2.8 Changelog.\nRedis 2.6 Changelog.\n\nCheck the upgrade urgency level in each patch release to more easily spot\nreleases that included important fixes.\nList of known Linux related bugs affecting Redis.\n\nUbuntu 10.04 and 10.10 contain bugs that can cause performance issues. The default kernels shipped with these distributions are not recommended. Bugs were reported as having affected EC2 instances, but some users also cited server impact.\n",
    "tag": "redis"
  },
  {
    "title": "Sentinel as a distributed system",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/sentinel.md",
    "content": "\ntitle: \"High availability with Redis Sentinel\"\nlinkTitle: \"High availability with Sentinel\"\nweight: 4\ndescription: High availability for non-clustered Redis\naliases: [\n    /topics/sentinel,\n    /docs/manual/sentinel,\n    /docs/manual/sentinel.md\n]\n\nRedis Sentinel provides high availability for Redis when not using Redis Cluster. \nRedis Sentinel also provides other collateral tasks such as monitoring,\nnotifications and acts as a configuration provider for clients.\nThis is the full list of Sentinel capabilities at a macroscopic level (i.e. the big picture):\n\nMonitoring. Sentinel constantly checks if your master and replica instances are working as expected.\nNotification. Sentinel can notify the system administrator, or other computer programs, via an API, that something is wrong with one of the monitored Redis instances.\nAutomatic failover. If a master is not working as expected, Sentinel can start a failover process where a replica is promoted to master, the other additional replicas are reconfigured to use the new master, and the applications using the Redis server are informed about the new address to use when connecting.\nConfiguration provider. Sentinel acts as a source of authority for clients service discovery: clients connect to Sentinels in order to ask for the address of the current Redis master responsible for a given service. If a failover occurs, Sentinels will report the new address.\n\nSentinel as a distributed system\nRedis Sentinel is a distributed system:\nSentinel itself is designed to run in a configuration where there are multiple Sentinel processes cooperating together. The advantage of having multiple Sentinel processes cooperating are the following:\n\nFailure detection is performed when multiple Sentinels agree about the fact a given master is no longer available. This lowers the probability of false positives.\nSentinel works even if not all the Sentinel processes are working, making the system robust against failures. There is no fun in having a failover system which is itself a single point of failure, after all.\n\nThe sum of Sentinels, Redis instances (masters and replicas) and clients\nconnecting to Sentinel and Redis, are also a larger distributed system with\nspecific properties. In this document concepts will be introduced gradually\nstarting from basic information needed in order to understand the basic\nproperties of Sentinel, to more complex information (that are optional) in\norder to understand how exactly Sentinel works.\nSentinel quick start\nObtaining Sentinel\nThe current version of Sentinel is called Sentinel 2. It is a rewrite of\nthe initial Sentinel implementation using stronger and simpler-to-predict\nalgorithms (that are explained in this documentation).\nA stable release of Redis Sentinel is shipped since Redis 2.8.\nNew developments are performed in the unstable branch, and new features\nsometimes are back ported into the latest stable branch as soon as they are\nconsidered to be stable.\nRedis Sentinel version 1, shipped with Redis 2.6, is deprecated and should not be used.\nRunning Sentinel\nIf you are using the `redis-sentinel` executable (or if you have a symbolic\nlink with that name to the `redis-server` executable) you can run Sentinel\nwith the following command line:\n\n\n```redis-sentinel /path/to/sentinel.conf\n```\n\n\nOtherwise you can use directly the `redis-server` executable starting it in\nSentinel mode:\n\n\n```redis-server /path/to/sentinel.conf --sentinel\n```\n\n\nBoth ways work the same.\nHowever it is mandatory to use a configuration file when running Sentinel, as this file will be used by the system in order to save the current state that will be reloaded in case of restarts. Sentinel will simply refuse to start if no configuration file is given or if the configuration file path is not writable.\nSentinels by default run listening for connections to TCP port 26379, so\nfor Sentinels to work, port 26379 of your servers must be open to receive\nconnections from the IP addresses of the other Sentinel instances.\nOtherwise Sentinels can't talk and can't agree about what to do, so failover\nwill never be performed.\nFundamental things to know about Sentinel before deploying\n\nYou need at least three Sentinel instances for a robust deployment.\nThe three Sentinel instances should be placed into computers or virtual machines that are believed to fail in an independent way. So for example different physical servers or Virtual Machines executed on different availability zones.\nSentinel + Redis distributed system does not guarantee that acknowledged writes are retained during failures, since Redis uses asynchronous replication. However there are ways to deploy Sentinel that make the window to lose writes limited to certain moments, while there are other less secure ways to deploy it.\nYou need Sentinel support in your clients. Popular client libraries have Sentinel support, but not all.\nThere is no HA setup which is safe if you don't test from time to time in development environments, or even better if you can, in production environments, if they work. You may have a misconfiguration that will become apparent only when it's too late (at 3am when your master stops working).\nSentinel, Docker, or other forms of Network Address Translation or Port Mapping should be mixed with care: Docker performs port remapping, breaking Sentinel auto discovery of other Sentinel processes and the list of replicas for a master. Check the section about Sentinel and Docker later in this document for more information.\n\nConfiguring Sentinel\nThe Redis source distribution contains a file called `sentinel.conf`\nthat is a self-documented example configuration file you can use to\nconfigure Sentinel, however a typical minimal configuration file looks like the\nfollowing:\n\n\n```sentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 60000\nsentinel failover-timeout mymaster 180000\nsentinel parallel-syncs mymaster 1\n\nsentinel monitor resque 192.168.1.3 6380 4\nsentinel down-after-milliseconds resque 10000\nsentinel failover-timeout resque 180000\nsentinel parallel-syncs resque 5\n```\n\n\nYou only need to specify the masters to monitor, giving to each separated\nmaster (that may have any number of replicas) a different name. There is no\nneed to specify replicas, which are auto-discovered. Sentinel will update the\nconfiguration automatically with additional information about replicas (in\norder to retain the information in case of restart). The configuration is\nalso rewritten every time a replica is promoted to master during a failover\nand every time a new Sentinel is discovered.\nThe example configuration above basically monitors two sets of Redis\ninstances, each composed of a master and an undefined number of replicas.\nOne set of instances is called `mymaster`, and the other `resque`.\nThe meaning of the arguments of `sentinel monitor` statements is the following:\n\n\n```sentinel monitor <master-name> <ip> <port> <quorum>\n```\n\n\nFor the sake of clarity, let's check line by line what the configuration\noptions mean:\nThe first line is used to tell Redis to monitor a master called mymaster,\nthat is at address 127.0.0.1 and port 6379, with a quorum of 2. Everything\nis pretty obvious but the quorum argument:\n\nThe quorum is the number of Sentinels that need to agree about the fact the master is not reachable, in order to really mark the master as failing, and eventually start a failover procedure if possible.\nHowever the quorum is only used to detect the failure. In order to actually perform a failover, one of the Sentinels need to be elected leader for the failover and be authorized to proceed. This only happens with the vote of the majority of the Sentinel processes.\n\nSo for example if you have 5 Sentinel processes, and the quorum for a given\nmaster set to the value of 2, this is what happens:\n\nIf two Sentinels agree at the same time about the master being unreachable, one of the two will try to start a failover.\nIf there are at least a total of three Sentinels reachable, the failover will be authorized and will actually start.\n\nIn practical terms this means during failures Sentinel never starts a failover if the majority of Sentinel processes are unable to talk (aka no failover in the minority partition).\nOther Sentinel options\nThe other options are almost always in the form:\n\n\n```sentinel <option_name> <master_name> <option_value>\n```\n\n\nAnd are used for the following purposes:\n\n`down-after-milliseconds` is the time in milliseconds an instance should not\nbe reachable (either does not reply to our PINGs or it is replying with an\nerror) for a Sentinel starting to think it is down.\n`parallel-syncs` sets the number of replicas that can be reconfigured to use\nthe new master after a failover at the same time. The lower the number, the\nmore time it will take for the failover process to complete, however if the\nreplicas are configured to serve old data, you may not want all the replicas to\nre-synchronize with the master at the same time. While the replication\nprocess is mostly non blocking for a replica, there is a moment when it stops to\nload the bulk data from the master. You may want to make sure only one replica\nat a time is not reachable by setting this option to the value of 1.\n\nAdditional options are described in the rest of this document and\ndocumented in the example `sentinel.conf` file shipped with the Redis\ndistribution.\nConfiguration parameters can be modified at runtime:\n\nMaster-specific configuration parameters are modified using `SENTINEL SET`.\nGlobal configuration parameters are modified using `SENTINEL CONFIG SET`.\n\nSee the Reconfiguring Sentinel at runtime section for more information.\nExample Sentinel deployments\nNow that you know the basic information about Sentinel, you may wonder where\nyou should place your Sentinel processes, how many Sentinel processes you need\nand so forth. This section shows a few example deployments.\nWe use ASCII art in order to show you configuration examples in a graphical\nformat, this is what the different symbols means:\n\n\n```+--------------------+\n| This is a computer |\n| or VM that fails   |\n| independently. We  |\n| call it a \"box\"    |\n+--------------------+\n```\n\n\nWe write inside the boxes what they are running:\n\n\n```+-------------------+\n| Redis master M1   |\n| Redis Sentinel S1 |\n+-------------------+\n```\n\n\nDifferent boxes are connected by lines, to show that they are able to talk:\n\n\n```+-------------+               +-------------+\n| Sentinel S1 |---------------| Sentinel S2 |\n+-------------+               +-------------+\n```\n\n\nNetwork partitions are shown as interrupted lines using slashes:\n\n\n```+-------------+                +-------------+\n| Sentinel S1 |------ // ------| Sentinel S2 |\n+-------------+                +-------------+\n```\n\n\nAlso note that:\n\nMasters are called M1, M2, M3, ..., Mn.\nReplicas are called R1, R2, R3, ..., Rn (R stands for replica).\nSentinels are called S1, S2, S3, ..., Sn.\nClients are called C1, C2, C3, ..., Cn.\nWhen an instance changes role because of Sentinel actions, we put it inside square brackets, so [M1] means an instance that is now a master because of Sentinel intervention.\n\nNote that we will never show setups where just two Sentinels are used, since\nSentinels always need to talk with the majority in order to start a\nfailover.\nExample 1: just two Sentinels, DON'T DO THIS\n\n\n```+----+         +----+\n| M1 |---------| R1 |\n| S1 |         | S2 |\n+----+         +----+\n\nConfiguration: quorum = 1\n```\n\n\n\nIn this setup, if the master M1 fails, R1 will be promoted since the two Sentinels can reach agreement about the failure (obviously with quorum set to 1) and can also authorize a failover because the majority is two. So apparently it could superficially work, however check the next points to see why this setup is broken.\nIf the box where M1 is running stops working, also S1 stops working. The Sentinel running in the other box S2 will not be able to authorize a failover, so the system will become not available.\n\nNote that a majority is needed in order to order different failovers, and later propagate the latest configuration to all the Sentinels. Also note that the ability to failover in a single side of the above setup, without any agreement, would be very dangerous:\n\n\n```+----+           +------+\n| M1 |----//-----| [M1] |\n| S1 |           | S2   |\n+----+           +------+\n```\n\n\nIn the above configuration we created two masters (assuming S2 could failover\nwithout authorization) in a perfectly symmetrical way. Clients may write\nindefinitely to both sides, and there is no way to understand when the\npartition heals what configuration is the right one, in order to prevent\na permanent split brain condition.\nSo please deploy at least three Sentinels in three different boxes always.\nExample 2: basic setup with three boxes\nThis is a very simple setup, that has the advantage to be simple to tune\nfor additional safety. It is based on three boxes, each box running both\na Redis process and a Sentinel process.\n\n\n```       +----+\n       | M1 |\n       | S1 |\n       +----+\n          |\n+----+    |    +----+\n| R2 |----+----| R3 |\n| S2 |         | S3 |\n+----+         +----+\n\nConfiguration: quorum = 2\n```\n\n\nIf the master M1 fails, S2 and S3 will agree about the failure and will\nbe able to authorize a failover, making clients able to continue.\nIn every Sentinel setup, as Redis uses asynchronous replication, there is\nalways the risk of losing some writes because a given acknowledged write\nmay not be able to reach the replica which is promoted to master. However in\nthe above setup there is a higher risk due to clients being partitioned away\nwith an old master, like in the following picture:\n\n\n```         +----+\n         | M1 |\n         | S1 | <- C1 (writes will be lost)\n         +----+\n            |\n            /\n            /\n+------+    |    +----+\n| [M2] |----+----| R3 |\n| S2   |         | S3 |\n+------+         +----+\n```\n\n\nIn this case a network partition isolated the old master M1, so the\nreplica R2 is promoted to master. However clients, like C1, that are\nin the same partition as the old master, may continue to write data\nto the old master. This data will be lost forever since when the partition\nwill heal, the master will be reconfigured as a replica of the new master,\ndiscarding its data set.\nThis problem can be mitigated using the following Redis replication\nfeature, that allows to stop accepting writes if a master detects that\nit is no longer able to transfer its writes to the specified number of replicas.\n\n\n```min-replicas-to-write 1\nmin-replicas-max-lag 10\n```\n\n\nWith the above configuration (please see the self-commented `redis.conf` example in the Redis distribution for more information) a Redis instance, when acting as a master, will stop accepting writes if it can't write to at least 1 replica. Since replication is asynchronous not being able to write actually means that the replica is either disconnected, or is not sending us asynchronous acknowledges for more than the specified `max-lag` number of seconds.\nUsing this configuration, the old Redis master M1 in the above example, will become unavailable after 10 seconds. When the partition heals, the Sentinel configuration will converge to the new one, the client C1 will be able to fetch a valid configuration and will continue with the new master.\nHowever there is no free lunch. With this refinement, if the two replicas are\ndown, the master will stop accepting writes. It's a trade off.\nExample 3: Sentinel in the client boxes\nSometimes we have only two Redis boxes available, one for the master and\none for the replica. The configuration in the example 2 is not viable in\nthat case, so we can resort to the following, where Sentinels are placed\nwhere clients are:\n\n\n```            +----+         +----+\n            | M1 |----+----| R1 |\n            |    |    |    |    |\n            +----+    |    +----+\n                      |\n         +------------+------------+\n         |            |            |\n         |            |            |\n      +----+        +----+      +----+\n      | C1 |        | C2 |      | C3 |\n      | S1 |        | S2 |      | S3 |\n      +----+        +----+      +----+\n\n      Configuration: quorum = 2\n```\n\n\nIn this setup, the point of view Sentinels is the same as the clients: if\na master is reachable by the majority of the clients, it is fine.\nC1, C2, C3 here are generic clients, it does not mean that C1 identifies\na single client connected to Redis. It is more likely something like\nan application server, a Rails app, or something like that.\nIf the box where M1 and S1 are running fails, the failover will happen\nwithout issues, however it is easy to see that different network partitions\nwill result in different behaviors. For example Sentinel will not be able\nto setup if the network between the clients and the Redis servers is\ndisconnected, since the Redis master and replica will both be unavailable.\nNote that if C3 gets partitioned with M1 (hardly possible with\nthe network described above, but more likely possible with different\nlayouts, or because of failures at the software layer), we have a similar\nissue as described in Example 2, with the difference that here we have\nno way to break the symmetry, since there is just a replica and master, so\nthe master can't stop accepting queries when it is disconnected from its replica,\notherwise the master would never be available during replica failures.\nSo this is a valid setup but the setup in the Example 2 has advantages\nsuch as the HA system of Redis running in the same boxes as Redis itself\nwhich may be simpler to manage, and the ability to put a bound on the amount\nof time a master in the minority partition can receive writes.\nExample 4: Sentinel client side with less than three clients\nThe setup described in the Example 3 cannot be used if there are less than\nthree boxes in the client side (for example three web servers). In this\ncase we need to resort to a mixed setup like the following:\n\n\n```            +----+         +----+\n            | M1 |----+----| R1 |\n            | S1 |    |    | S2 |\n            +----+    |    +----+\n                      |\n               +------+-----+\n               |            |\n               |            |\n            +----+        +----+\n            | C1 |        | C2 |\n            | S3 |        | S4 |\n            +----+        +----+\n\n      Configuration: quorum = 3\n```\n\n\nThis is similar to the setup in Example 3, but here we run four Sentinels\nin the four boxes we have available. If the master M1 becomes unavailable\nthe other three Sentinels will perform the failover.\nIn theory this setup works removing the box where C2 and S4 are running, and\nsetting the quorum to 2. However it is unlikely that we want HA in the\nRedis side without having high availability in our application layer.\nSentinel, Docker, NAT, and possible issues\nDocker uses a technique called port mapping: programs running inside Docker\ncontainers may be exposed with a different port compared to the one the\nprogram believes to be using. This is useful in order to run multiple\ncontainers using the same ports, at the same time, in the same server.\nDocker is not the only software system where this happens, there are other\nNetwork Address Translation setups where ports may be remapped, and sometimes\nnot ports but also IP addresses.\nRemapping ports and addresses creates issues with Sentinel in two ways:\n\nSentinel auto-discovery of other Sentinels no longer works, since it is based on hello messages where each Sentinel announce at which port and IP address they are listening for connection. However Sentinels have no way to understand that an address or port is remapped, so it is announcing an information that is not correct for other Sentinels to connect.\nReplicas are listed in the `INFO` output of a Redis master in a similar way: the address is detected by the master checking the remote peer of the TCP connection, while the port is advertised by the replica itself during the handshake, however the port may be wrong for the same reason as exposed in point 1.\n\nSince Sentinels auto detect replicas using masters `INFO` output information,\nthe detected replicas will not be reachable, and Sentinel will never be able to\nfailover the master, since there are no good replicas from the point of view of\nthe system, so there is currently no way to monitor with Sentinel a set of\nmaster and replica instances deployed with Docker, unless you instruct Docker\nto map the port 1:1.\nFor the first problem, in case you want to run a set of Sentinel\ninstances using Docker with forwarded ports (or any other NAT setup where ports\nare remapped), you can use the following two Sentinel configuration directives\nin order to force Sentinel to announce a specific set of IP and port:\n\n\n```sentinel announce-ip <ip>\nsentinel announce-port <port>\n```\n\n\nNote that Docker has the ability to run in host networking mode (check the `--net=host` option for more information). This should create no issues since ports are not remapped in this setup.\nIP Addresses and DNS names\nOlder versions of Sentinel did not support host names and required IP addresses to be specified everywhere.\nStarting with version 6.2, Sentinel has optional support for host names.\nThis capability is disabled by default. If you're going to enable DNS/hostnames support, please note:\n\nThe name resolution configuration on your Redis and Sentinel nodes must be reliable and be able to resolve addresses quickly. Unexpected delays in address resolution may have a negative impact on Sentinel.\nYou should use hostnames everywhere and avoid mixing hostnames and IP addresses. To do that, use `replica-announce-ip <hostname>` and `sentinel announce-ip <hostname>` for all Redis and Sentinel instances, respectively.\n\nEnabling the `resolve-hostnames` global configuration allows Sentinel to accept host names:\n\nAs part of a `sentinel monitor` command\nAs a replica address, if the replica uses a host name value for `replica-announce-ip`\n\nSentinel will accept host names as valid inputs and resolve them, but will still refer to IP addresses when announcing an instance, updating configuration files, etc.\nEnabling the `announce-hostnames` global configuration makes Sentinel use host names instead. This affects replies to clients, values written in configuration files, the `REPLICAOF` command issued to replicas, etc.\nThis behavior may not be compatible with all Sentinel clients, that may explicitly expect an IP address.\nUsing host names may be useful when clients use TLS to connect to instances and require a name rather than an IP address in order to perform certificate ASN matching.\nA quick tutorial\nIn the next sections of this document, all the details about Sentinel API,\nconfiguration and semantics will be covered incrementally. However for people\nthat want to play with the system ASAP, this section is a tutorial that shows\nhow to configure and interact with 3 Sentinel instances.\nHere we assume that the instances are executed at port 5000, 5001, 5002.\nWe also assume that you have a running Redis master at port 6379 with a\nreplica running at port 6380. We will use the IPv4 loopback address 127.0.0.1\neverywhere during the tutorial, assuming you are running the simulation\non your personal computer.\nThe three Sentinel configuration files should look like the following:\n\n\n```port 5000\nsentinel monitor mymaster 127.0.0.1 6379 2\nsentinel down-after-milliseconds mymaster 5000\nsentinel failover-timeout mymaster 60000\nsentinel parallel-syncs mymaster 1\n```\n\n\nThe other two configuration files will be identical but using 5001 and 5002\nas port numbers.\nA few things to note about the above configuration:\n\nThe master set is called `mymaster`. It identifies the master and its replicas. Since each master set has a different name, Sentinel can monitor different sets of masters and replicas at the same time.\nThe quorum was set to the value of 2 (last argument of `sentinel monitor` configuration directive).\nThe `down-after-milliseconds` value is 5000 milliseconds, that is 5 seconds, so masters will be detected as failing as soon as we don't receive any reply from our pings within this amount of time.\n\nOnce you start the three Sentinels, you'll see a few messages they log, like:\n\n\n```+monitor master mymaster 127.0.0.1 6379 quorum 2\n```\n\n\nThis is a Sentinel event, and you can receive this kind of events via Pub/Sub\nif you `SUBSCRIBE` to the event name as specified later in Pub/Sub Messages section.\nSentinel generates and logs different events during failure detection and\nfailover.\nAsking Sentinel about the state of a master\nThe most obvious thing to do with Sentinel to get started, is check if the\nmaster it is monitoring is doing well:\n\n\n```$ redis-cli -p 5000\n127.0.0.1:5000> sentinel master mymaster\n 1) \"name\"\n 2) \"mymaster\"\n 3) \"ip\"\n 4) \"127.0.0.1\"\n 5) \"port\"\n 6) \"6379\"\n 7) \"runid\"\n 8) \"953ae6a589449c13ddefaee3538d356d287f509b\"\n 9) \"flags\"\n10) \"master\"\n11) \"link-pending-commands\"\n12) \"0\"\n13) \"link-refcount\"\n14) \"1\"\n15) \"last-ping-sent\"\n16) \"0\"\n17) \"last-ok-ping-reply\"\n18) \"735\"\n19) \"last-ping-reply\"\n20) \"735\"\n21) \"down-after-milliseconds\"\n22) \"5000\"\n23) \"info-refresh\"\n24) \"126\"\n25) \"role-reported\"\n26) \"master\"\n27) \"role-reported-time\"\n28) \"532439\"\n29) \"config-epoch\"\n30) \"1\"\n31) \"num-slaves\"\n32) \"1\"\n33) \"num-other-sentinels\"\n34) \"2\"\n35) \"quorum\"\n36) \"2\"\n37) \"failover-timeout\"\n38) \"60000\"\n39) \"parallel-syncs\"\n40) \"1\"\n```\n\n\nAs you can see, it prints a number of information about the master. There are\na few that are of particular interest for us:\n\n`num-other-sentinels` is 2, so we know the Sentinel already detected two more Sentinels for this master. If you check the logs you'll see the `+sentinel` events generated.\n`flags` is just `master`. If the master was down we could expect to see `s_down` or `o_down` flag as well here.\n`num-slaves` is correctly set to 1, so Sentinel also detected that there is an attached replica to our master.\n\nIn order to explore more about this instance, you may want to try the following\ntwo commands:\n\n\n```SENTINEL replicas mymaster\nSENTINEL sentinels mymaster\n```\n\n\nThe first will provide similar information about the replicas connected to the\nmaster, and the second about the other Sentinels.\nObtaining the address of the current master\nAs we already specified, Sentinel also acts as a configuration provider for\nclients that want to connect to a set of master and replicas. Because of\npossible failovers or reconfigurations, clients have no idea about who is\nthe currently active master for a given set of instances, so Sentinel exports\nan API to ask this question:\n\n\n```127.0.0.1:5000> SENTINEL get-master-addr-by-name mymaster\n1) \"127.0.0.1\"\n2) \"6379\"\n```\n\n\nTesting the failover\nAt this point our toy Sentinel deployment is ready to be tested. We can\njust kill our master and check if the configuration changes. To do so\nwe can just do:\n\n\n```redis-cli -p 6379 DEBUG sleep 30\n```\n\n\nThis command will make our master no longer reachable, sleeping for 30 seconds.\nIt basically simulates a master hanging for some reason.\nIf you check the Sentinel logs, you should be able to see a lot of action:\n\nEach Sentinel detects the master is down with an `+sdown` event.\nThis event is later escalated to `+odown`, which means that multiple Sentinels agree about the fact the master is not reachable.\nSentinels vote a Sentinel that will start the first failover attempt.\nThe failover happens.\n\nIf you ask again what is the current master address for `mymaster`, eventually\nwe should get a different reply this time:\n\n\n```127.0.0.1:5000> SENTINEL get-master-addr-by-name mymaster\n1) \"127.0.0.1\"\n2) \"6380\"\n```\n\n\nSo far so good... At this point you may jump to create your Sentinel deployment\nor can read more to understand all the Sentinel commands and internals.\nSentinel API\nSentinel provides an API in order to inspect its state, check the health\nof monitored masters and replicas, subscribe in order to receive specific\nnotifications, and change the Sentinel configuration at run time.\nBy default Sentinel runs using TCP port 26379 (note that 6379 is the normal\nRedis port). Sentinels accept commands using the Redis protocol, so you can\nuse `redis-cli` or any other unmodified Redis client in order to talk with\nSentinel.\nIt is possible to directly query a Sentinel to check what is the state of\nthe monitored Redis instances from its point of view, to see what other\nSentinels it knows, and so forth. Alternatively, using Pub/Sub, it is possible\nto receive push style notifications from Sentinels, every time some event\nhappens, like a failover, or an instance entering an error condition, and\nso forth.\nSentinel commands\nThe `SENTINEL` command is the main API for Sentinel. The following is the list of its subcommands (minimal version is noted for where applicable):\n\nSENTINEL CONFIG GET `<name>` (`>= 6.2`) Get the current value of a global Sentinel configuration parameter. The specified name may be a wildcard, similar to the Redis `CONFIG GET` command.\nSENTINEL CONFIG SET `<name>` `<value>` (`>= 6.2`) Set the value of a global Sentinel configuration parameter.\nSENTINEL CKQUORUM `<master name>` Check if the current Sentinel configuration is able to reach the quorum needed to failover a master, and the majority needed to authorize the failover. This command should be used in monitoring systems to check if a Sentinel deployment is ok.\nSENTINEL FLUSHCONFIG Force Sentinel to rewrite its configuration on disk, including the current Sentinel state. Normally Sentinel rewrites the configuration every time something changes in its state (in the context of the subset of the state which is persisted on disk across restart). However sometimes it is possible that the configuration file is lost because of operation errors, disk failures, package upgrade scripts or configuration managers. In those cases a way to force Sentinel to rewrite the configuration file is handy. This command works even if the previous configuration file is completely missing.\nSENTINEL FAILOVER `<master name>` Force a failover as if the master was not reachable, and without asking for agreement to other Sentinels (however a new version of the configuration will be published so that the other Sentinels will update their configurations).\nSENTINEL GET-MASTER-ADDR-BY-NAME `<master name>` Return the ip and port number of the master with that name. If a failover is in progress or terminated successfully for this master it returns the address and port of the promoted replica.\nSENTINEL INFO-CACHE (`>= 3.2`) Return cached `INFO` output from masters and replicas.\nSENTINEL IS-MASTER-DOWN-BY-ADDR     Check if the master specified by ip:port is down from current Sentinel's point of view. This command is mostly for internal use.\nSENTINEL MASTER `<master name>` Show the state and info of the specified master.\nSENTINEL MASTERS Show a list of monitored masters and their state.\nSENTINEL MONITOR Start Sentinel's monitoring. Refer to the Reconfiguring Sentinel at Runtime section for more information.\nSENTINEL MYID (`>= 6.2`) Return the ID of the Sentinel instance.\nSENTINEL PENDING-SCRIPTS This command returns information about pending scripts.\nSENTINEL REMOVE Stop Sentinel's monitoring. Refer to the Reconfiguring Sentinel at Runtime section for more information.\nSENTINEL REPLICAS `<master name>` (`>= 5.0`) Show a list of replicas for this master, and their state.\nSENTINEL SENTINELS `<master name>` Show a list of sentinel instances for this master, and their state.\nSENTINEL SET Set Sentinel's monitoring configuration. Refer to the Reconfiguring Sentinel at Runtime section for more information.\nSENTINEL SIMULATE-FAILURE (crash-after-election|crash-after-promotion|help) (`>= 3.2`) This command simulates different Sentinel crash scenarios.\nSENTINEL RESET `<pattern>` This command will reset all the masters with matching name. The pattern argument is a glob-style pattern. The reset process clears any previous state in a master (including a failover in progress), and removes every replica and sentinel already discovered and associated with the master.\n\nFor connection management and administration purposes, Sentinel supports the following subset of Redis' commands:\n\nACL (`>= 6.2`) This command manages the Sentinel Access Control List. For more information refer to the ACL documentation page and the Sentinel Access Control List authentication.\nAUTH (`>= 5.0.1`) Authenticate a client connection. For more information refer to the `AUTH` command and the Configuring Sentinel instances with authentication section.\nCLIENT This command manages client connections. For more information refer to its subcommands' pages.\nCOMMAND (`>= 6.2`) This command returns information about commands. For more information refer to the `COMMAND` command and its various subcommands.\nHELLO (`>= 6.0`) Switch the connection's protocol. For more information refer to the `HELLO` command.\nINFO Return information and statistics about the Sentinel server. For more information see the `INFO` command.\nPING This command simply returns PONG.\nROLE This command returns the string \"sentinel\" and a list of monitored masters. For more information refer to the `ROLE` command.\nSHUTDOWN Shut down the Sentinel instance.\n\nLastly, Sentinel also supports the `SUBSCRIBE`, `UNSUBSCRIBE`, `PSUBSCRIBE` and `PUNSUBSCRIBE` commands. Refer to the Pub/Sub Messages section for more details.\nReconfiguring Sentinel at Runtime\nStarting with Redis version 2.8.4, Sentinel provides an API in order to add, remove, or change the configuration of a given master. Note that if you have multiple sentinels you should apply the changes to all to your instances for Redis Sentinel to work properly. This means that changing the configuration of a single Sentinel does not automatically propagate the changes to the other Sentinels in the network.\nThe following is a list of `SENTINEL` subcommands used in order to update the configuration of a Sentinel instance.\n\nSENTINEL MONITOR `<name>` `<ip>` `<port>` `<quorum>` This command tells the Sentinel to start monitoring a new master with the specified name, ip, port, and quorum. It is identical to the `sentinel monitor` configuration directive in `sentinel.conf` configuration file, with the difference that you can't use a hostname in as `ip`, but you need to provide an IPv4 or IPv6 address.\nSENTINEL REMOVE `<name>` is used in order to remove the specified master: the master will no longer be monitored, and will totally be removed from the internal state of the Sentinel, so it will no longer listed by `SENTINEL masters` and so forth.\nSENTINEL SET `<name>` [`<option>` `<value>` ...] The SET command is very similar to the `CONFIG SET` command of Redis, and is used in order to change configuration parameters of a specific master. Multiple option / value pairs can be specified (or none at all). All the configuration parameters that can be configured via `sentinel.conf` are also configurable using the SET command.\n\nThe following is an example of `SENTINEL SET` command in order to modify the `down-after-milliseconds` configuration of a master called `objects-cache`:\n\n\n```SENTINEL SET objects-cache-master down-after-milliseconds 1000\n```\n\n\nAs already stated, `SENTINEL SET` can be used to set all the configuration parameters that are settable in the startup configuration file. Moreover it is possible to change just the master quorum configuration without removing and re-adding the master with `SENTINEL REMOVE` followed by `SENTINEL MONITOR`, but simply using:\n\n\n```SENTINEL SET objects-cache-master quorum 5\n```\n\n\nNote that there is no equivalent GET command since `SENTINEL MASTER` provides all the configuration parameters in a simple to parse format (as a field/value pairs array).\nStarting with Redis version 6.2, Sentinel also allows getting and setting global configuration parameters which were only supported in the configuration file prior to that.\n\nSENTINEL CONFIG GET `<name>` Get the current value of a global Sentinel configuration parameter. The specified name may be a wildcard, similar to the Redis `CONFIG GET` command.\nSENTINEL CONFIG SET `<name>` `<value>` Set the value of a global Sentinel configuration parameter.\n\nGlobal parameters that can be manipulated include:\n\n`resolve-hostnames`, `announce-hostnames`. See IP addresses and DNS names.\n`announce-ip`, `announce-port`. See Sentinel, Docker, NAT, and possible issues.\n`sentinel-user`, `sentinel-pass`. See Configuring Sentinel instances with authentication.\n\nAdding or removing Sentinels\nAdding a new Sentinel to your deployment is a simple process because of the\nauto-discover mechanism implemented by Sentinel. All you need to do is to\nstart the new Sentinel configured to monitor the currently active master.\nWithin 10 seconds the Sentinel will acquire the list of other Sentinels and\nthe set of replicas attached to the master.\nIf you need to add multiple Sentinels at once, it is suggested to add it\none after the other, waiting for all the other Sentinels to already know\nabout the first one before adding the next. This is useful in order to still\nguarantee that majority can be achieved only in one side of a partition,\nin the chance failures should happen in the process of adding new Sentinels.\nThis can be easily achieved by adding every new Sentinel with a 30 seconds delay, and during absence of network partitions.\nAt the end of the process it is possible to use the command\n`SENTINEL MASTER mastername` in order to check if all the Sentinels agree about\nthe total number of Sentinels monitoring the master.\nRemoving a Sentinel is a bit more complex: Sentinels never forget already seen\nSentinels, even if they are not reachable for a long time, since we don't\nwant to dynamically change the majority needed to authorize a failover and\nthe creation of a new configuration number. So in order to remove a Sentinel\nthe following steps should be performed in absence of network partitions:\n\nStop the Sentinel process of the Sentinel you want to remove.\nSend a `SENTINEL RESET *` command to all the other Sentinel instances (instead of `*` you can use the exact master name if you want to reset just a single master). One after the other, waiting at least 30 seconds between instances.\nCheck that all the Sentinels agree about the number of Sentinels currently active, by inspecting the output of `SENTINEL MASTER mastername` of every Sentinel.\n\nRemoving the old master or unreachable replicas\nSentinels never forget about replicas of a given master, even when they are\nunreachable for a long time. This is useful, because Sentinels should be able\nto correctly reconfigure a returning replica after a network partition or a\nfailure event.\nMoreover, after a failover, the failed over master is virtually added as a\nreplica of the new master, this way it will be reconfigured to replicate with\nthe new master as soon as it will be available again.\nHowever sometimes you want to remove a replica (that may be the old master)\nforever from the list of replicas monitored by Sentinels.\nIn order to do this, you need to send a `SENTINEL RESET mastername` command\nto all the Sentinels: they'll refresh the list of replicas within the next\n10 seconds, only adding the ones listed as correctly replicating from the\ncurrent master `INFO` output.\nPub/Sub messages\nA client can use a Sentinel as a Redis-compatible Pub/Sub server\n(but you can't use `PUBLISH`) in order to `SUBSCRIBE` or `PSUBSCRIBE` to\nchannels and get notified about specific events.\nThe channel name is the same as the name of the event. For instance the\nchannel named `+sdown` will receive all the notifications related to instances\nentering an `SDOWN` (SDOWN means the instance is no longer reachable from\nthe point of view of the Sentinel you are querying) condition.\nTo get all the messages simply subscribe using `PSUBSCRIBE *`.\nThe following is a list of channels and message formats you can receive using\nthis API. The first word is the channel / event name, the rest is the format of the data.\nNote: where instance details is specified it means that the following arguments are provided to identify the target instance:\n\n\n```<instance-type> <name> <ip> <port> @ <master-name> <master-ip> <master-port>\n```\n\n\nThe part identifying the master (from the @ argument to the end) is optional\nand is only specified if the instance is not a master itself.\n\n+reset-master `<instance details>` -- The master was reset.\n+slave `<instance details>` -- A new replica was detected and attached.\n+failover-state-reconf-slaves `<instance details>` -- Failover state changed to `reconf-slaves` state.\n+failover-detected `<instance details>` -- A failover started by another Sentinel or any other external entity was detected (An attached replica turned into a master).\n+slave-reconf-sent `<instance details>` -- The leader sentinel sent the `REPLICAOF` command to this instance in order to reconfigure it for the new replica.\n+slave-reconf-inprog `<instance details>` -- The replica being reconfigured showed to be a replica of the new master ip:port pair, but the synchronization process is not yet complete.\n+slave-reconf-done `<instance details>` -- The replica is now synchronized with the new master.\n-dup-sentinel `<instance details>` -- One or more sentinels for the specified master were removed as duplicated (this happens for instance when a Sentinel instance is restarted).\n+sentinel `<instance details>` -- A new sentinel for this master was detected and attached.\n+sdown `<instance details>` -- The specified instance is now in Subjectively Down state.\n-sdown `<instance details>` -- The specified instance is no longer in Subjectively Down state.\n+odown `<instance details>` -- The specified instance is now in Objectively Down state.\n-odown `<instance details>` -- The specified instance is no longer in Objectively Down state.\n+new-epoch `<instance details>` -- The current epoch was updated.\n+try-failover `<instance details>` -- New failover in progress, waiting to be elected by the majority.\n+elected-leader `<instance details>` -- Won the election for the specified epoch, can do the failover.\n+failover-state-select-slave `<instance details>` -- New failover state is `select-slave`: we are trying to find a suitable replica for promotion.\nno-good-slave `<instance details>` -- There is no good replica to promote. Currently we'll try after some time, but probably this will change and the state machine will abort the failover at all in this case.\nselected-slave `<instance details>` -- We found the specified good replica to promote.\nfailover-state-send-slaveof-noone `<instance details>` -- We are trying to reconfigure the promoted replica as master, waiting for it to switch.\nfailover-end-for-timeout `<instance details>` -- The failover terminated for timeout, replicas will eventually be configured to replicate with the new master anyway.\nfailover-end `<instance details>` -- The failover terminated with success. All the replicas appears to be reconfigured to replicate with the new master.\nswitch-master `<master name> <oldip> <oldport> <newip> <newport>` -- The master new IP and address is the specified one after a configuration change. This is the message most external users are interested in.\n+tilt -- Tilt mode entered.\n-tilt -- Tilt mode exited.\n\nHandling of -BUSY state\nThe -BUSY error is returned by a Redis instance when a Lua script is running for\nmore time than the configured Lua script time limit. When this happens before\ntriggering a fail over Redis Sentinel will try to send a `SCRIPT KILL`\ncommand, that will only succeed if the script was read-only.\nIf the instance is still in an error condition after this try, it will\neventually be failed over.\nReplicas priority\nRedis instances have a configuration parameter called `replica-priority`.\nThis information is exposed by Redis replica instances in their `INFO` output,\nand Sentinel uses it in order to pick a replica among the ones that can be\nused in order to failover a master:\n\nIf the replica priority is set to 0, the replica is never promoted to master.\nReplicas with a lower priority number are preferred by Sentinel.\n\nFor example if there is a replica S1 in the same data center of the current\nmaster, and another replica S2 in another data center, it is possible to set\nS1 with a priority of 10 and S2 with a priority of 100, so that if the master\nfails and both S1 and S2 are available, S1 will be preferred.\nFor more information about the way replicas are selected, please check the Replica selection and priority section of this documentation.\nSentinel and Redis authentication\nWhen the master is configured to require authentication from clients,\nas a security measure, replicas need to also be aware of the credentials in\norder to authenticate with the master and create the master-replica connection\nused for the asynchronous replication protocol.\nRedis Access Control List authentication\nStarting with Redis 6, user authentication and permission is managed with the Access Control List (ACL).\nIn order for Sentinels to connect to Redis server instances when they are\nconfigured with ACL, the Sentinel configuration must include the\nfollowing directives:\n\n\n```sentinel auth-user <master-name> <username>\nsentinel auth-pass <master-name> <password>\n```\n\n\nWhere `<username>` and `<password>` are the username and password for accessing the group's instances. These credentials should be provisioned on all of the group's Redis instances with the minimal control permissions. For example:\n\n\n```127.0.0.1:6379> ACL SETUSER sentinel-user ON >somepassword allchannels +multi +slaveof +ping +exec +subscribe +config|rewrite +role +publish +info +client|setname +client|kill +script|kill\n```\n\n\nRedis password-only authentication\nUntil Redis 6, authentication is achieved using the following configuration directives:\n\n`requirepass` in the master, in order to set the authentication password, and to make sure the instance will not process requests for non authenticated clients.\n`masterauth` in the replicas in order for the replicas to authenticate with the master in order to correctly replicate data from it.\n\nWhen Sentinel is used, there is not a single master, since after a failover\nreplicas may play the role of masters, and old masters can be reconfigured in\norder to act as replicas, so what you want to do is to set the above directives\nin all your instances, both masters and replicas.\nThis is also usually a sane setup since you don't want to protect\ndata only in the master, having the same data accessible in the replicas.\nHowever, in the uncommon case where you need a replica that is accessible\nwithout authentication, you can still do it by setting up a replica priority\nof zero, to prevent this replica from being promoted to master, and\nconfiguring in this replica only the `masterauth` directive, without\nusing the `requirepass` directive, so that data will be readable by\nunauthenticated clients.\nIn order for Sentinels to connect to Redis server instances when they are\nconfigured with `requirepass`, the Sentinel configuration must include the\n`sentinel auth-pass` directive, in the format:\n\n\n```sentinel auth-pass <master-name> <password>\n```\n\n\nConfiguring Sentinel instances with authentication\nSentinel instances themselves can be secured by requiring clients to authenticate via the `AUTH` command. Starting with Redis 6.2, the Access Control List (ACL) is available, whereas previous versions (starting with Redis 5.0.1) support password-only authentication. \nNote that Sentinel's authentication configuration should be applied to each of the instances in your deployment, and all instances should use the same configuration. Furthermore, ACL and password-only authentication should not be used together.\nSentinel Access Control List authentication\nThe first step in securing a Sentinel instance with ACL is preventing any unauthorized access to it. To do that, you'll need to disable the default superuser (or at the very least set it up with a strong password) and create a new one and allow it access to Pub/Sub channels:\n\n\n```127.0.0.1:5000> ACL SETUSER admin ON >admin-password allchannels +@all\nOK\n127.0.0.1:5000> ACL SETUSER default off\nOK\n```\n\n\nThe default user is used by Sentinel to connect to other instances. You can provide the credentials of another superuser with the following configuration directives:\n\n\n```sentinel sentinel-user <username>\nsentinel sentinel-pass <password>\n```\n\n\nWhere `<username>` and `<password>` are the Sentinel's superuser and password, respectively (e.g. `admin` and `admin-password` in the example above).\nLastly, for authenticating incoming client connections, you can create a Sentinel restricted user profile such as the following:\n\n\n```127.0.0.1:5000> ACL SETUSER sentinel-user ON >user-password -@all +auth +client|getname +client|id +client|setname +command +hello +ping +role +sentinel|get-master-addr-by-name +sentinel|master +sentinel|myid +sentinel|replicas +sentinel|sentinels\n```\n\n\nRefer to the documentation of your Sentinel client of choice for further information.\nSentinel password-only authentication\nTo use Sentinel with password-only authentication, add the `requirepass` configuration directive to all your Sentinel instances as follows:\n\n\n```requirepass \"your_password_here\"\n```\n\n\nWhen configured this way, Sentinels will do two things:\n\nA password will be required from clients in order to send commands to Sentinels. This is obvious since this is how such configuration directive works in Redis in general.\nMoreover the same password configured to access the local Sentinel, will be used by this Sentinel instance in order to authenticate to all the other Sentinel instances it connects to.\n\nThis means that you will have to configure the same `requirepass` password in all the Sentinel instances. This way every Sentinel can talk with every other Sentinel without any need to configure for each Sentinel the password to access all the other Sentinels, that would be very impractical.\nBefore using this configuration, make sure your client library can send the `AUTH` command to Sentinel instances.\nSentinel clients implementation\n\nSentinel requires explicit client support, unless the system is configured to execute a script that performs a transparent redirection of all the requests to the new master instance (virtual IP or other similar systems). The topic of client libraries implementation is covered in the document Sentinel clients guidelines.\nMore advanced concepts\nIn the following sections we'll cover a few details about how Sentinel works,\nwithout resorting to implementation details and algorithms that will be\ncovered in the final part of this document.\nSDOWN and ODOWN failure state\nRedis Sentinel has two different concepts of being down, one is called\na Subjectively Down condition (SDOWN) and is a down condition that is\nlocal to a given Sentinel instance. Another is called Objectively Down\ncondition (ODOWN) and is reached when enough Sentinels (at least the\nnumber configured as the `quorum` parameter of the monitored master) have\nan SDOWN condition, and get feedback from other Sentinels using\nthe `SENTINEL is-master-down-by-addr` command.\nFrom the point of view of a Sentinel an SDOWN condition is reached when it\ndoes not receive a valid reply to PING requests for the number of seconds\nspecified in the configuration as `is-master-down-after-milliseconds`\nparameter.\nAn acceptable reply to PING is one of the following:\n\nPING replied with +PONG.\nPING replied with -LOADING error.\nPING replied with -MASTERDOWN error.\n\nAny other reply (or no reply at all) is considered non valid.\nHowever note that a logical master that advertises itself as a replica in\nthe INFO output is considered to be down.\nNote that SDOWN requires that no acceptable reply is received for the whole\ninterval configured, so for instance if the interval is 30000 milliseconds\n(30 seconds) and we receive an acceptable ping reply every 29 seconds, the\ninstance is considered to be working.\nSDOWN is not enough to trigger a failover: it only means a single Sentinel\nbelieves a Redis instance is not available. To trigger a failover, the\nODOWN state must be reached.\nTo switch from SDOWN to ODOWN no strong consensus algorithm is used, but\njust a form of gossip: if a given Sentinel gets reports that a master\nis not working from enough Sentinels in a given time range, the SDOWN is\npromoted to ODOWN. If this acknowledge is later missing, the flag is cleared.\nA more strict authorization that uses an actual majority is required in\norder to really start the failover, but no failover can be triggered without\nreaching the ODOWN state.\nThe ODOWN condition only applies to masters. For other kind of instances\nSentinel doesn't require to act, so the ODOWN state is never reached for replicas\nand other sentinels, but only SDOWN is.\nHowever SDOWN has also semantic implications. For example a replica in SDOWN\nstate is not selected to be promoted by a Sentinel performing a failover.\nSentinels and replicas auto discovery\nSentinels stay connected with other Sentinels in order to reciprocally\ncheck the availability of each other, and to exchange messages. However you\ndon't need to configure a list of other Sentinel addresses in every Sentinel\ninstance you run, as Sentinel uses the Redis instances Pub/Sub capabilities\nin order to discover the other Sentinels that are monitoring the same masters\nand replicas.\nThis feature is implemented by sending hello messages into the channel named\n`__sentinel__:hello`.\nSimilarly you don't need to configure what is the list of the replicas attached\nto a master, as Sentinel will auto discover this list querying Redis.\n\nEvery Sentinel publishes a message to every monitored master and replica Pub/Sub channel `__sentinel__:hello`, every two seconds, announcing its presence with ip, port, runid.\nEvery Sentinel is subscribed to the Pub/Sub channel `__sentinel__:hello` of every master and replica, looking for unknown sentinels. When new sentinels are detected, they are added as sentinels of this master.\nHello messages also include the full current configuration of the master. If the receiving Sentinel has a configuration for a given master which is older than the one received, it updates to the new configuration immediately.\nBefore adding a new sentinel to a master a Sentinel always checks if there is already a sentinel with the same runid or the same address (ip and port pair). In that case all the matching sentinels are removed, and the new added.\n\nSentinel reconfiguration of instances outside the failover procedure\nEven when no failover is in progress, Sentinels will always try to set the\ncurrent configuration on monitored instances. Specifically:\n\nReplicas (according to the current configuration) that claim to be masters, will be configured as replicas to replicate with the current master.\nReplicas connected to a wrong master, will be reconfigured to replicate with the right master.\n\nFor Sentinels to reconfigure replicas, the wrong configuration must be observed for some time, that is greater than the period used to broadcast new configurations.\nThis prevents Sentinels with a stale configuration (for example because they just rejoined from a partition) will try to change the replicas configuration before receiving an update.\nAlso note how the semantics of always trying to impose the current configuration makes the failover more resistant to partitions:\n\nMasters failed over are reconfigured as replicas when they return available.\nReplicas partitioned away during a partition are reconfigured once reachable.\n\nThe important lesson to remember about this section is: Sentinel is a system where each process will always try to impose the last logical configuration to the set of monitored instances.\nReplica selection and priority\nWhen a Sentinel instance is ready to perform a failover, since the master\nis in `ODOWN` state and the Sentinel received the authorization to failover\nfrom the majority of the Sentinel instances known, a suitable replica needs\nto be selected.\nThe replica selection process evaluates the following information about replicas:\n\nDisconnection time from the master.\nReplica priority.\nReplication offset processed.\nRun ID.\n\nA replica that is found to be disconnected from the master for more than ten\ntimes the configured master timeout (down-after-milliseconds option), plus\nthe time the master is also not available from the point of view of the\nSentinel doing the failover, is considered to be not suitable for the failover\nand is skipped.\nIn more rigorous terms, a replica whose the `INFO` output suggests it has been\ndisconnected from the master for more than:\n\n\n```(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state\n```\n\n\nIs considered to be unreliable and is disregarded entirely.\nThe replica selection only considers the replicas that passed the above test,\nand sorts it based on the above criteria, in the following order.\n\nThe replicas are sorted by `replica-priority` as configured in the `redis.conf` file of the Redis instance. A lower priority will be preferred.\nIf the priority is the same, the replication offset processed by the replica is checked, and the replica that received more data from the master is selected.\nIf multiple replicas have the same priority and processed the same data from the master, a further check is performed, selecting the replica with the lexicographically smaller run ID. Having a lower run ID is not a real advantage for a replica, but is useful in order to make the process of replica selection more deterministic, instead of resorting to select a random replica.\n\nIn most cases, `replica-priority` does not need to be set explicitly so all\ninstances will use the same default value. If there is a particular fail-over\npreference, `replica-priority` must be set on all instances, including masters,\nas a master may become a replica at some future point in time - and it will then\nneed the proper `replica-priority` settings.\nA Redis instance can be configured with a special `replica-priority` of zero\nin order to be never selected by Sentinels as the new master.\nHowever a replica configured in this way will still be reconfigured by\nSentinels in order to replicate with the new master after a failover, the\nonly difference is that it will never become a master itself.\nAlgorithms and internals\nIn the following sections we will explore the details of Sentinel behavior.\nIt is not strictly needed for users to be aware of all the details, but a\ndeep understanding of Sentinel may help to deploy and operate Sentinel in\na more effective way.\nQuorum\nThe previous sections showed that every master monitored by Sentinel is associated to a configured quorum. It specifies the number of Sentinel processes\nthat need to agree about the unreachability or error condition of the master in\norder to trigger a failover.\nHowever, after the failover is triggered, in order for the failover to actually be performed, at least a majority of Sentinels must authorize the Sentinel to\nfailover. Sentinel never performs a failover in the partition where a\nminority of Sentinels exist.\nLet's try to make things a bit more clear:\n\nQuorum: the number of Sentinel processes that need to detect an error condition in order for a master to be flagged as ODOWN.\nThe failover is triggered by the ODOWN state.\nOnce the failover is triggered, the Sentinel trying to failover is required to ask for authorization to a majority of Sentinels (or more than the majority if the quorum is set to a number greater than the majority).\n\nThe difference may seem subtle but is actually quite simple to understand and use.  For example if you have 5 Sentinel instances, and the quorum is set to 2, a failover will be triggered as soon as 2 Sentinels believe that the master is not reachable, however one of the two Sentinels will be able to failover only if it gets authorization at least from 3 Sentinels.\nIf instead the quorum is configured to 5, all the Sentinels must agree about the master error condition, and the authorization from all Sentinels is required in order to failover.\nThis means that the quorum can be used to tune Sentinel in two ways:\n\nIf a quorum is set to a value smaller than the majority of Sentinels we deploy, we are basically making Sentinel more sensitive to master failures, triggering a failover as soon as even just a minority of Sentinels is no longer able to talk with the master.\nIf a quorum is set to a value greater than the majority of Sentinels, we are making Sentinel able to failover only when there are a very large number (larger than majority) of well connected Sentinels which agree about the master being down.\n\nConfiguration epochs\nSentinels require to get authorizations from a majority in order to start a\nfailover for a few important reasons:\nWhen a Sentinel is authorized, it gets a unique configuration epoch for the master it is failing over. This is a number that will be used to version the new configuration after the failover is completed. Because a majority agreed that a given version was assigned to a given Sentinel, no other Sentinel will be able to use it. This means that every configuration of every failover is versioned with a unique version. We'll see why this is so important.\nMoreover Sentinels have a rule: if a Sentinel voted another Sentinel for the failover of a given master, it will wait some time to try to failover the same master again. This delay is the `2 * failover-timeout` you can configure in `sentinel.conf`. This means that Sentinels will not try to failover the same master at the same time, the first to ask to be authorized will try, if it fails another will try after some time, and so forth.\nRedis Sentinel guarantees the liveness property that if a majority of Sentinels are able to talk, eventually one will be authorized to failover if the master is down.\nRedis Sentinel also guarantees the safety property that every Sentinel will failover the same master using a different configuration epoch.\nConfiguration propagation\nOnce a Sentinel is able to failover a master successfully, it will start to broadcast the new configuration so that the other Sentinels will update their information about a given master.\nFor a failover to be considered successful, it requires that the Sentinel was able to send the `REPLICAOF NO ONE` command to the selected replica, and that the switch to master was later observed in the `INFO` output of the master.\nAt this point, even if the reconfiguration of the replicas is in progress, the failover is considered to be successful, and all the Sentinels are required to start reporting the new configuration.\nThe way a new configuration is propagated is the reason why we need that every\nSentinel failover is authorized with a different version number (configuration epoch).\nEvery Sentinel continuously broadcast its version of the configuration of a master using Redis Pub/Sub messages, both in the master and all the replicas.  At the same time all the Sentinels wait for messages to see what is the configuration\nadvertised by the other Sentinels.\nConfigurations are broadcast in the `__sentinel__:hello` Pub/Sub channel.\nBecause every configuration has a different version number, the greater version\nalways wins over smaller versions.\nSo for example the configuration for the master `mymaster` start with all the\nSentinels believing the master is at 192.168.1.50:6379. This configuration\nhas version 1. After some time a Sentinel is authorized to failover with version 2. If the failover is successful, it will start to broadcast a new configuration, let's say 192.168.1.50:9000, with version 2. All the other instances will see this configuration and will update their configuration accordingly, since the new configuration has a greater version.\nThis means that Sentinel guarantees a second liveness property: a set of\nSentinels that are able to communicate will all converge to the same configuration with the higher version number.\nBasically if the net is partitioned, every partition will converge to the higher\nlocal configuration. In the special case of no partitions, there is a single\npartition and every Sentinel will agree about the configuration.\nConsistency under partitions\nRedis Sentinel configurations are eventually consistent, so every partition will\nconverge to the higher configuration available.\nHowever in a real-world system using Sentinel there are three different players:\n\nRedis instances.\nSentinel instances.\nClients.\n\nIn order to define the behavior of the system we have to consider all three.\nThe following is a simple network where there are 3 nodes, each running\na Redis instance, and a Sentinel instance:\n\n\n```            +-------------+\n            | Sentinel 1  |----- Client A\n            | Redis 1 (M) |\n            +-------------+\n                    |\n                    |\n+-------------+     |          +------------+\n| Sentinel 2  |-----+-- // ----| Sentinel 3 |----- Client B\n| Redis 2 (S) |                | Redis 3 (M)|\n+-------------+                +------------+\n```\n\n\nIn this system the original state was that Redis 3 was the master, while\nRedis 1 and 2 were replicas. A partition occurred isolating the old master.\nSentinels 1 and 2 started a failover promoting Sentinel 1 as the new master.\nThe Sentinel properties guarantee that Sentinel 1 and 2 now have the new\nconfiguration for the master. However Sentinel 3 has still the old configuration\nsince it lives in a different partition.\nWe know that Sentinel 3 will get its configuration updated when the network\npartition will heal, however what happens during the partition if there\nare clients partitioned with the old master?\nClients will be still able to write to Redis 3, the old master. When the\npartition will rejoin, Redis 3 will be turned into a replica of Redis 1, and\nall the data written during the partition will be lost.\nDepending on your configuration you may want or not that this scenario happens:\n\nIf you are using Redis as a cache, it could be handy that Client B is still able to write to the old master, even if its data will be lost.\nIf you are using Redis as a store, this is not good and you need to configure the system in order to partially prevent this problem.\n\nSince Redis is asynchronously replicated, there is no way to totally prevent data loss in this scenario, however you can bound the divergence between Redis 3 and Redis 1\nusing the following Redis configuration option:\n\n\n```min-replicas-to-write 1\nmin-replicas-max-lag 10\n```\n\n\nWith the above configuration (please see the self-commented `redis.conf` example in the Redis distribution for more information) a Redis instance, when acting as a master, will stop accepting writes if it can't write to at least 1 replica. Since replication is asynchronous not being able to write actually means that the replica is either disconnected, or is not sending us asynchronous acknowledges for more than the specified `max-lag` number of seconds.\nUsing this configuration the Redis 3 in the above example will become unavailable after 10 seconds. When the partition heals, the Sentinel 3 configuration will converge to\nthe new one, and Client B will be able to fetch a valid configuration and continue.\nIn general Redis + Sentinel as a whole are an eventually consistent system where the merge function is last failover wins, and the data from old masters are discarded to replicate the data of the current master, so there is always a window for losing acknowledged writes. This is due to Redis asynchronous\nreplication and the discarding nature of the \"virtual\" merge function of the system. Note that this is not a limitation of Sentinel itself, and if you orchestrate the failover with a strongly consistent replicated state machine, the same properties will still apply. There are only two ways to avoid losing acknowledged writes:\n\nUse synchronous replication (and a proper consensus algorithm to run a replicated state machine).\nUse an eventually consistent system where different versions of the same object can be merged.\n\nRedis currently is not able to use any of the above systems, and is currently outside the development goals. However there are proxies implementing solution \"2\" on top of Redis stores such as SoundCloud Roshi, or Netflix Dynomite.\nSentinel persistent state\nSentinel state is persisted in the sentinel configuration file. For example\nevery time a new configuration is received, or created (leader Sentinels), for\na master, the configuration is persisted on disk together with the configuration\nepoch. This means that it is safe to stop and restart Sentinel processes.\nTILT mode\nRedis Sentinel is heavily dependent on the computer time: for instance in\norder to understand if an instance is available it remembers the time of the\nlatest successful reply to the PING command, and compares it with the current\ntime to understand how old it is.\nHowever if the computer time changes in an unexpected way, or if the computer\nis very busy, or the process blocked for some reason, Sentinel may start to\nbehave in an unexpected way.\nThe TILT mode is a special \"protection\" mode that a Sentinel can enter when\nsomething odd is detected that can lower the reliability of the system.\nThe Sentinel timer interrupt is normally called 10 times per second, so we\nexpect that more or less 100 milliseconds will elapse between two calls\nto the timer interrupt.\nWhat a Sentinel does is to register the previous time the timer interrupt\nwas called, and compare it with the current call: if the time difference\nis negative or unexpectedly big (2 seconds or more) the TILT mode is entered\n(or if it was already entered the exit from the TILT mode postponed).\nWhen in TILT mode the Sentinel will continue to monitor everything, but:\n\nIt stops acting at all.\nIt starts to reply negatively to `SENTINEL is-master-down-by-addr` requests as the ability to detect a failure is no longer trusted.\n\nIf everything appears to be normal for 30 second, the TILT mode is exited.\nIn the Sentinel TILT mode, if we send the INFO command, we could get the following response:\n\n\n```$ redis-cli -p 26379\n127.0.0.1:26379> info\n(Other information from Sentinel server skipped.)\n\n# Sentinel\nsentinel_masters:1\nsentinel_tilt:0\nsentinel_tilt_since_seconds:-1\nsentinel_running_scripts:0\nsentinel_scripts_queue_length:0\nsentinel_simulate_failure_flags:0\nmaster0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=0,sentinels=1\n```\n\n\nThe field \"sentinel_tilt_since_seconds\" indicates how many seconds the Sentinel already is in the TILT mode.\nIf it is not in TILT mode, the value will be -1.\nNote that in some ways TILT mode could be replaced using the monotonic clock\nAPI that many kernels offer. However it is not still clear if this is a good\nsolution since the current system avoids issues in case the process is just\nsuspended or not executed by the scheduler for a long time.",
    "tag": "redis"
  },
  {
    "title": "config.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/config.md",
    "content": "\ntitle: \"Redis configuration\"\nlinkTitle: \"Configuration\"\nweight: 2\ndescription: >\n    Overview of redis.conf, the Redis configuration file\naliases: [\n    /docs/manual/config\n    ]\n\nRedis is able to start without a configuration file using a built-in default\nconfiguration, however this setup is only recommended for testing and\ndevelopment purposes.\nThe proper way to configure Redis is by providing a Redis configuration file,\nusually called `redis.conf`.\nThe `redis.conf` file contains a number of directives that have a very simple\nformat:\n\n\n```keyword argument1 argument2 ... argumentN\n```\n\n\nThis is an example of a configuration directive:\n\n\n```replicaof 127.0.0.1 6380\n```\n\n\nIt is possible to provide strings containing spaces as arguments using\n(double or single) quotes, as in the following example:\n\n\n```requirepass \"hello world\"\n```\n\n\nSingle-quoted string can contain characters escaped by backslashes, and\ndouble-quoted strings can additionally include any ASCII symbols encoded using\nbackslashed hexadecimal notation \"\\xff\".\nThe list of configuration directives, and their meaning and intended usage\nis available in the self documented example redis.conf shipped into the\nRedis distribution.\n\nThe self documented redis.conf for Redis 7.0.\nThe self documented redis.conf for Redis 6.2.\nThe self documented redis.conf for Redis 6.0.\nThe self documented redis.conf for Redis 5.0.\nThe self documented redis.conf for Redis 4.0.\nThe self documented redis.conf for Redis 3.2.\nThe self documented redis.conf for Redis 3.0.\nThe self documented redis.conf for Redis 2.8.\nThe self documented redis.conf for Redis 2.6.\nThe self documented redis.conf for Redis 2.4.\n\nPassing arguments via the command line\nYou can also pass Redis configuration parameters\nusing the command line directly. This is very useful for testing purposes.\nThe following is an example that starts a new Redis instance using port 6380\nas a replica of the instance running at 127.0.0.1 port 6379.\n\n\n```./redis-server --port 6380 --replicaof 127.0.0.1 6379\n```\n\n\nThe format of the arguments passed via the command line is exactly the same\nas the one used in the redis.conf file, with the exception that the keyword\nis prefixed with `--`.\nNote that internally this generates an in-memory temporary config file\n(possibly concatenating the config file passed by the user, if any) where\narguments are translated into the format of redis.conf.\nChanging Redis configuration while the server is running\nIt is possible to reconfigure Redis on the fly without stopping and restarting\nthe service, or querying the current configuration programmatically using the\nspecial commands `CONFIG SET` and `CONFIG GET`.\nNot all of the configuration directives are supported in this way, but most\nare supported as expected.\nPlease refer to the `CONFIG SET` and `CONFIG GET` pages for more information.\nNote that modifying the configuration on the fly has no effects on the\nredis.conf file so at the next restart of Redis the old configuration will\nbe used instead.\nMake sure to also modify the `redis.conf` file accordingly to the configuration\nyou set using `CONFIG SET`.\nYou can do it manually, or you can use `CONFIG REWRITE`, which will automatically scan your `redis.conf` file and update the fields which don't match the current configuration value.\nFields non existing but set to the default value are not added.\nComments inside your configuration file are retained.\nConfiguring Redis as a cache\nIf you plan to use Redis as a cache where every key will have an\nexpire set, you may consider using the following configuration instead\n(assuming a max memory limit of 2 megabytes as an example):\n\n\n```maxmemory 2mb\nmaxmemory-policy allkeys-lru\n```\n\n\nIn this configuration there is no need for the application to set a\ntime to live for keys using the `EXPIRE` command (or equivalent) since\nall the keys will be evicted using an approximated LRU algorithm as long\nas we hit the 2 megabyte memory limit.\nBasically, in this configuration Redis acts in a similar way to memcached.",
    "tag": "redis"
  },
  {
    "title": "!!! Warning: short read while loading the AOF file !!!",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/persistence.md",
    "content": "\ntitle: Redis persistence\nlinkTitle: Persistence\nweight: 7\ndescription: How Redis writes data to disk\naliases: [\n    /topics/persistence,\n    /topics/persistence.md,\n    /docs/manual/persistence,\n    /docs/manual/persistence.md\n]\n\nPersistence refers to the writing of data to durable storage, such as a solid-state disk (SSD). Redis provides a range of persistence options. These include:\n\nRDB (Redis Database): RDB persistence performs point-in-time snapshots of your dataset at specified intervals.\nAOF (Append Only File): AOF persistence logs every write operation received by the server. These operations can then be replayed again at server startup, reconstructing the original dataset. Commands are logged using the same format as the Redis protocol itself.\nNo persistence: You can disable persistence completely. This is sometimes used when caching.\nRDB + AOF: You can also combine both AOF and RDB in the same instance.\n\nIf you'd rather not think about the tradeoffs between these different persistence strategies, you may want to consider Redis Enterprise's persistence options, which can be pre-configured using a UI.\nTo learn more about how to evaluate your Redis persistence strategy, read on.\nRDB advantages\n\nRDB is a very compact single-file point-in-time representation of your Redis data. RDB files are perfect for backups. For instance you may want to archive your RDB files every hour for the latest 24 hours, and to save an RDB snapshot every day for 30 days. This allows you to easily restore different versions of the data set in case of disasters.\nRDB is very good for disaster recovery, being a single compact file that can be transferred to far data centers, or onto Amazon S3 (possibly encrypted).\nRDB maximizes Redis performances since the only work the Redis parent process needs to do in order to persist is forking a child that will do all the rest. The parent process will never perform disk I/O or alike.\nRDB allows faster restarts with big datasets compared to AOF.\nOn replicas, RDB supports partial resynchronizations after restarts and failovers.\n\nRDB disadvantages\n\nRDB is NOT good if you need to minimize the chance of data loss in case Redis stops working (for example after a power outage). You can configure different save points where an RDB is produced (for instance after at least five minutes and 100 writes against the data set, you can have multiple save points). However you'll usually create an RDB snapshot every five minutes or more, so in case of Redis stopping working without a correct shutdown for any reason you should be prepared to lose the latest minutes of data.\nRDB needs to fork() often in order to persist on disk using a child process. fork() can be time consuming if the dataset is big, and may result in Redis stopping serving clients for some milliseconds or even for one second if the dataset is very big and the CPU performance is not great. AOF also needs to fork() but less frequently and you can tune how often you want to rewrite your logs without any trade-off on durability.\n\nAOF advantages\n\nUsing AOF Redis is much more durable: you can have different fsync policies: no fsync at all, fsync every second, fsync at every query. With the default policy of fsync every second, write performance is still great. fsync is performed using a background thread and the main thread will try hard to perform writes when no fsync is in progress, so you can only lose one second worth of writes.\nThe AOF log is an append-only log, so there are no seeks, nor corruption problems if there is a power outage. Even if the log ends with a half-written command for some reason (disk full or other reasons) the redis-check-aof tool is able to fix it easily.\nRedis is able to automatically rewrite the AOF in background when it gets too big. The rewrite is completely safe as while Redis continues appending to the old file, a completely new one is produced with the minimal set of operations needed to create the current data set, and once this second file is ready Redis switches the two and starts appending to the new one.\nAOF contains a log of all the operations one after the other in an easy to understand and parse format. You can even easily export an AOF file. For instance even if you've accidentally flushed everything using the `FLUSHALL` command, as long as no rewrite of the log was performed in the meantime, you can still save your data set just by stopping the server, removing the latest command, and restarting Redis again.\n\nAOF disadvantages\n\nAOF files are usually bigger than the equivalent RDB files for the same dataset.\nAOF can be slower than RDB depending on the exact fsync policy. In general with fsync set to every second performance is still very high, and with fsync disabled it should be exactly as fast as RDB even under high load. Still RDB is able to provide more guarantees about the maximum latency even in the case of a huge write load.\n\nRedis < 7.0\n\nAOF can use a lot of memory if there are writes to the database during a rewrite (these are buffered in memory and written to the new AOF at the end).\nAll write commands that arrive during rewrite are written to disk twice.\nRedis could freeze writing and fsyncing these write commands to the new AOF file at the end of the rewrite.\n\nOk, so what should I use?\nThe general indication you should use both persistence methods is if\nyou want a degree of data safety comparable to what PostgreSQL can provide you.\nIf you care a lot about your data, but still can live with a few minutes of\ndata loss in case of disasters, you can simply use RDB alone.\nThere are many users using AOF alone, but we discourage it since to have an\nRDB snapshot from time to time is a great idea for doing database backups,\nfor faster restarts, and in the event of bugs in the AOF engine.\nThe following sections will illustrate a few more details about the two persistence models.\nSnapshotting\nBy default Redis saves snapshots of the dataset on disk, in a binary\nfile called `dump.rdb`. You can configure Redis to have it save the\ndataset every N seconds if there are at least M changes in the dataset,\nor you can manually call the `SAVE` or `BGSAVE` commands.\nFor example, this configuration will make Redis automatically dump the\ndataset to disk every 60 seconds if at least 1000 keys changed:\n\n\n```save 60 1000\n```\n\n\nThis strategy is known as snapshotting.\nHow it works\nWhenever Redis needs to dump the dataset to disk, this is what happens:\n\n\nRedis forks. We now have a child\nand a parent process.\n\n\nThe child starts to write the dataset to a temporary RDB file.\n\n\nWhen the child is done writing the new RDB file, it replaces the old\none.\n\n\nThis method allows Redis to benefit from copy-on-write semantics.\nAppend-only file\nSnapshotting is not very durable. If your computer running Redis stops,\nyour power line fails, or you accidentally `kill -9` your instance, the\nlatest data written to Redis will be lost.  While this may not be a big\ndeal for some applications, there are use cases for full durability, and\nin these cases Redis snapshotting alone is not a viable option.\nThe append-only file is an alternative, fully-durable strategy for\nRedis.  It became available in version 1.1.\nYou can turn on the AOF in your configuration file:\n\n\n```appendonly yes\n```\n\n\nFrom now on, every time Redis receives a command that changes the\ndataset (e.g. `SET`) it will append it to the AOF.  When you restart\nRedis it will re-play the AOF to rebuild the state.\nSince Redis 7.0.0, Redis uses a multi part AOF mechanism.\nThat is, the original single AOF file is split into base file (at most one) and incremental files (there may be more than one).\nThe base file represents an initial (RDB or AOF format) snapshot of the data present when the AOF is rewritten.\nThe incremental files contains incremental changes since the last base AOF file was created. All these files are put in a separate directory and are tracked by a manifest file.\nLog rewriting\nThe AOF gets bigger and bigger as write operations are\nperformed.  For example, if you are incrementing a counter 100 times,\nyou'll end up with a single key in your dataset containing the final\nvalue, but 100 entries in your AOF. 99 of those entries are not needed\nto rebuild the current state.\nThe rewrite is completely safe.\nWhile Redis continues appending to the old file,\na completely new one is produced with the minimal set of operations needed to create the current data set,\nand once this second file is ready Redis switches the two and starts appending to the new one.\nSo Redis supports an interesting feature: it is able to rebuild the AOF\nin the background without interrupting service to clients. Whenever\nyou issue a `BGREWRITEAOF`, Redis will write the shortest sequence of\ncommands needed to rebuild the current dataset in memory.  If you're\nusing the AOF with Redis 2.2 you'll need to run `BGREWRITEAOF` from time to\ntime. Since Redis 2.4 is able to trigger log rewriting automatically (see the\nexample configuration file for more information).\nSince Redis 7.0.0, when an AOF rewrite is scheduled, the Redis parent process opens a new incremental AOF file to continue writing.\nThe child process executes the rewrite logic and generates a new base AOF.\nRedis will use a temporary manifest file to track the newly generated base file and incremental file.\nWhen they are ready, Redis will perform an atomic replacement operation to make this temporary manifest file take effect.\nIn order to avoid the problem of creating many incremental files in case of repeated failures and retries of an AOF rewrite,\nRedis introduces an AOF rewrite limiting mechanism to ensure that failed AOF rewrites are retried at a slower and slower rate.\nHow durable is the append only file?\nYou can configure how many times Redis will\nfsync data on disk. There are\nthree options:\n\n`appendfsync always`: `fsync` every time new commands are appended to the AOF. Very very slow, very safe. Note that the commands are appended to the AOF after a batch of commands from multiple clients or a pipeline are executed, so it means a single write and a single fsync (before sending the replies).\n`appendfsync everysec`: `fsync` every second. Fast enough (since version 2.4 likely to be as fast as snapshotting), and you may lose 1 second of data if there is a disaster.\n`appendfsync no`: Never `fsync`, just put your data in the hands of the Operating System. The faster and less safe method. Normally Linux will flush data every 30 seconds with this configuration, but it's up to the kernel's exact tuning.\n\nThe suggested (and default) policy is to `fsync` every second. It is\nboth fast and relatively safe. The `always` policy is very slow in\npractice, but it supports group commit, so if there are multiple parallel\nwrites Redis will try to perform a single `fsync` operation.\nWhat should I do if my AOF gets truncated?\nIt is possible the server crashed while writing the AOF file, or the\nvolume where the AOF file is stored was full at the time of writing. When this happens the\nAOF still contains consistent data representing a given point-in-time version\nof the dataset (that may be old up to one second with the default AOF fsync\npolicy), but the last command in the AOF could be truncated.\nThe latest major versions of Redis will be able to load the AOF anyway, just\ndiscarding the last non well formed command in the file. In this case the\nserver will emit a log like the following:\n```\n* Reading RDB preamble from AOF file...\n* Reading the remaining AOF tail...\n!!! Warning: short read while loading the AOF file !!!\n!!! Truncating the AOF at offset 439 !!!\nAOF loaded anyway because aof-load-truncated is enabled\n```\nYou can change the default configuration to force Redis to stop in such\ncases if you want, but the default configuration is to continue regardless of\nthe fact the last command in the file is not well-formed, in order to guarantee\navailability after a restart.\nOlder versions of Redis may not recover, and may require the following steps:\n\nMake a backup copy of your AOF file.\n\nFix the original file using the `redis-check-aof` tool that ships with Redis:\n$ redis-check-aof --fix \n\n\nOptionally use `diff -u` to check what is the difference between two files.\n\nRestart the server with the fixed file.\n\nWhat should I do if my AOF gets corrupted?\nIf the AOF file is not just truncated, but corrupted with invalid byte\nsequences in the middle, things are more complex. Redis will complain\nat startup and will abort:\n```\n* Reading the remaining AOF tail...\nBad file format reading the append only file: make a backup of your AOF file, then use ./redis-check-aof --fix \n```\nThe best thing to do is to run the `redis-check-aof` utility, initially without\nthe `--fix` option, then understand the problem, jump to the given\noffset in the file, and see if it is possible to manually repair the file:\nThe AOF uses the same format of the Redis protocol and is quite simple to fix\nmanually. Otherwise it is possible to let the utility fix the file for us, but\nin that case all the AOF portion from the invalid part to the end of the\nfile may be discarded, leading to a massive amount of data loss if the\ncorruption happened to be in the initial part of the file.\nHow it works\nLog rewriting uses the same copy-on-write trick already in use for\nsnapshotting.  This is how it works:\nRedis >= 7.0\n\n\nRedis forks, so now we have a child\nand a parent process.\n\n\nThe child starts writing the new base AOF in a temporary file.\n\n\nThe parent opens a new increments AOF file to continue writing updates.\n  If the rewriting fails, the old base and increment files (if there are any) plus this newly opened increment file represent the complete updated dataset,\n  so we are safe.\n\n\nWhen the child is done rewriting the base file, the parent gets a signal,\nand uses the newly opened increment file and child generated base file to build a temp manifest,\nand persist it.\n\n\nProfit! Now Redis does an atomic exchange of the manifest files so that the result of this AOF rewrite takes effect. Redis also cleans up the old base file and any unused increment files.\n\n\nRedis < 7.0\n\n\nRedis forks, so now we have a child\nand a parent process.\n\n\nThe child starts writing the new AOF in a temporary file.\n\n\nThe parent accumulates all the new changes in an in-memory buffer (but\nat the same time it writes the new changes in the old append-only file,\nso if the rewriting fails, we are safe).\n\n\nWhen the child is done rewriting the file, the parent gets a signal,\nand appends the in-memory buffer at the end of the file generated by the\nchild.\n\n\nNow Redis atomically renames the new file into the old one,\nand starts appending new data into the new file.\n\n\nHow I can switch to AOF, if I'm currently using dump.rdb snapshots?\nThere is a different procedure to do this in version 2.0 and later versions, as you\ncan guess it's simpler since Redis 2.2 and does not require a restart at all.\nRedis >= 2.2\n\nMake a backup of your latest dump.rdb file.\nTransfer this backup to a safe place.\nIssue the following two commands:\n`redis-cli config set appendonly yes`\n`redis-cli config set save \"\"`\nMake sure your database contains the same number of keys it contained.\nMake sure writes are appended to the append only file correctly.\n\nThe first CONFIG command enables the Append Only File persistence.\nThe second CONFIG command is used to turn off snapshotting persistence. This is optional, if you wish you can take both the persistence methods enabled.\nIMPORTANT: remember to edit your redis.conf to turn on the AOF, otherwise\nwhen you restart the server the configuration changes will be lost and the\nserver will start again with the old configuration.\nRedis 2.0\n\nMake a backup of your latest dump.rdb file.\nTransfer this backup into a safe place.\nStop all the writes against the database!\nIssue a `redis-cli BGREWRITEAOF`. This will create the append only file.\nStop the server when Redis finished generating the AOF dump.\nEdit redis.conf end enable append only file persistence.\nRestart the server.\nMake sure that your database contains the same number of keys it contained before the switch.\nMake sure that writes are appended to the append only file correctly.\n\nInteractions between AOF and RDB persistence\nRedis >= 2.4 makes sure to avoid triggering an AOF rewrite when an RDB\nsnapshotting operation is already in progress, or allowing a `BGSAVE` while the\nAOF rewrite is in progress. This prevents two Redis background processes\nfrom doing heavy disk I/O at the same time.\nWhen snapshotting is in progress and the user explicitly requests a log\nrewrite operation using `BGREWRITEAOF` the server will reply with an OK\nstatus code telling the user the operation is scheduled, and the rewrite\nwill start once the snapshotting is completed.\nIn the case both AOF and RDB persistence are enabled and Redis restarts the\nAOF file will be used to reconstruct the original dataset since it is\nguaranteed to be the most complete.\nBacking up Redis data\nBefore starting this section, make sure to read the following sentence: Make Sure to Backup Your Database. Disks break, instances in the cloud disappear, and so forth: no backups means huge risk of data disappearing into /dev/null.\nRedis is very data backup friendly since you can copy RDB files while the\ndatabase is running: the RDB is never modified once produced, and while it\ngets produced it uses a temporary name and is renamed into its final destination\natomically using rename(2) only when the new snapshot is complete.\nThis means that copying the RDB file is completely safe while the server is\nrunning. This is what we suggest:\n\nCreate a cron job in your server creating hourly snapshots of the RDB file in one directory, and daily snapshots in a different directory.\nEvery time the cron script runs, make sure to call the `find` command to make sure too old snapshots are deleted: for instance you can take hourly snapshots for the latest 48 hours, and daily snapshots for one or two months. Make sure to name the snapshots with date and time information.\nAt least one time every day make sure to transfer an RDB snapshot outside your data center or at least outside the physical machine running your Redis instance.\n\nBacking up AOF persistence\nIf you run a Redis instance with only AOF persistence enabled, you can still perform backups.\nSince Redis 7.0.0, AOF files are split into multiple files which reside in a single directory determined by the `appenddirname` configuration.\nDuring normal operation all you need to do is copy/tar the files in this directory to achieve a backup. However, if this is done during a rewrite, you might end up with an invalid backup.\nTo work around this you must disable AOF rewrites during the backup:\n\nTurn off automatic rewrites with\n`CONFIG SET` `auto-aof-rewrite-percentage 0`\n   Make sure you don't manually start a rewrite (using `BGREWRITEAOF`) during this time.\nCheck there's no current rewrite in progress using\n`INFO` `persistence`\n   and verifying `aof_rewrite_in_progress` is 0. If it's 1, then you'll need to wait for the rewrite to complete.\nNow you can safely copy the files in the `appenddirname` directory.\nRe-enable rewrites when done:\n`CONFIG SET` `auto-aof-rewrite-percentage <prev-value>`\n\nNote: If you want to minimize the time AOF rewrites are disabled you may create hard links to the files in `appenddirname` (in step 3 above) and then re-enable rewrites (step 4) after the hard links are created.\nNow you can copy/tar the hardlinks and delete them when done. This works because Redis guarantees that it\nonly appends to files in this directory, or completely replaces them if necessary, so the content should be\nconsistent at any given point in time.\nNote: If you want to handle the case of the server being restarted during the backup and make sure no rewrite will automatically start after the restart you can change step 1 above to also persist the updated configuration via `CONFIG REWRITE`.\nJust make sure to re-enable automatic rewrites when done (step 4) and persist it with another `CONFIG REWRITE`.\nPrior to version 7.0.0 backing up the AOF file can be done simply by copying the aof file (like backing up the RDB snapshot). The file may lack the final part\nbut Redis will still be able to load it (see the previous sections about truncated AOF files).\nDisaster recovery\nDisaster recovery in the context of Redis is basically the same story as\nbackups, plus the ability to transfer those backups in many different external\ndata centers. This way data is secured even in the case of some catastrophic\nevent affecting the main data center where Redis is running and producing its\nsnapshots.\nWe'll review the most interesting disaster recovery techniques\nthat don't have too high costs.\n\nAmazon S3 and other similar services are a good way for implementing your disaster recovery system. Simply transfer your daily or hourly RDB snapshot to S3 in an encrypted form. You can encrypt your data using `gpg -c` (in symmetric encryption mode). Make sure to store your password in many different safe places (for instance give a copy to the most important people of your organization). It is recommended to use multiple storage services for improved data safety.\nTransfer your snapshots using SCP (part of SSH) to far servers. This is a fairly simple and safe route: get a small VPS in a place that is very far from you, install ssh there, and generate a ssh client key without passphrase, then add it in the `authorized_keys` file of your small VPS. You are ready to transfer backups in an automated fashion. Get at least two VPS in two different providers\nfor best results.\n\nIt is important to understand that this system can easily fail if not\nimplemented in the right way. At least, make absolutely sure that after the\ntransfer is completed you are able to verify the file size (that should match\nthe one of the file you copied) and possibly the SHA1 digest, if you are using\na VPS.\nYou also need some kind of independent alert system if the transfer of fresh",
    "tag": "redis"
  },
  {
    "title": "Redis Cluster 101",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/scaling.md",
    "content": "\ntitle: Scaling with Redis Cluster\nlinkTitle: Scaling\nweight: 6\ndescription: Horizontal scaling with Redis Cluster\naliases: [\n    /topics/cluster-tutorial,\n    /topics/partitioning,\n    /docs/manual/scaling,\n    /docs/manual/scaling.md\n]\n\nRedis scales horizontally with a deployment topology called Redis Cluster. \nThis topic will teach you how to set up, test, and operate Redis Cluster in production.\nYou will learn about the availability and consistency characteristics of Redis Cluster from the end user's point of view.\nIf you plan to run a production Redis Cluster deployment or want to understand better how Redis Cluster works internally, consult the Redis Cluster specification. To learn how Redis Enterprise handles scaling, see Linear Scaling with Redis Enterprise.\nRedis Cluster 101\nRedis Cluster provides a way to run a Redis installation where data is automatically sharded across multiple Redis nodes. \nRedis Cluster also provides some degree of availability during partitions\u2014in practical terms, the ability to continue operations when some nodes fail or are unable to communicate. \nHowever, the cluster will become unavailable in the event of larger failures (for example, when the majority of masters are unavailable).\nSo, with Redis Cluster, you get the ability to:\n\nAutomatically split your dataset among multiple nodes.\nContinue operations when a subset of the nodes are experiencing failures or are unable to communicate with the rest of the cluster.\n\nRedis Cluster TCP ports\nEvery Redis Cluster node requires two open TCP connections: a Redis TCP port used to serve clients, e.g., 6379, and second port known as the cluster bus port. \nBy default, the cluster bus port is set by adding 10000 to the data port (e.g., 16379); however, you can override this in the `cluster-port` configuration.\nCluster bus is a node-to-node communication channel that uses a binary protocol, which is more suited to exchanging information between nodes due to\nlittle bandwidth and processing time. \nNodes use the cluster bus for failure detection, configuration updates, failover authorization, and so forth. \nClients should never try to communicate with the cluster bus port, but rather use the Redis command port. \nHowever, make sure you open both ports in your firewall, otherwise Redis cluster nodes won't be able to communicate.\nFor a Redis Cluster to work properly you need, for each node:\n\nThe client communication port (usually 6379) used to communicate with clients and be open to all the clients that need to reach the cluster, plus all the other cluster nodes that use the client port for key migrations.\nThe cluster bus port must be reachable from all the other cluster nodes.\n\nIf you don't open both TCP ports, your cluster will not work as expected.\nRedis Cluster and Docker\nCurrently, Redis Cluster does not support NATted environments and in general\nenvironments where IP addresses or TCP ports are remapped.\nDocker uses a technique called port mapping: programs running inside Docker containers may be exposed with a different port compared to the one the program believes to be using. \nThis is useful for running multiple containers using the same ports, at the same time, in the same server.\nTo make Docker compatible with Redis Cluster, you need to use Docker's host networking mode. \nPlease see the `--net=host` option in the Docker documentation for more information.\nRedis Cluster data sharding\nRedis Cluster does not use consistent hashing, but a different form of sharding\nwhere every key is conceptually part of what we call a hash slot.\nThere are 16384 hash slots in Redis Cluster, and to compute the hash\nslot for a given key, we simply take the CRC16 of the key modulo\n16384.\nEvery node in a Redis Cluster is responsible for a subset of the hash slots,\nso, for example, you may have a cluster with 3 nodes, where:\n\nNode A contains hash slots from 0 to 5500.\nNode B contains hash slots from 5501 to 11000.\nNode C contains hash slots from 11001 to 16383.\n\nThis makes it easy to add and remove cluster nodes. For example, if\nI want to add a new node D, I need to move some hash slots from nodes A, B, C\nto D. Similarly, if I want to remove node A from the cluster, I can just\nmove the hash slots served by A to B and C. Once node A is empty,\nI can remove it from the cluster completely.\nMoving hash slots from a node to another does not require stopping\nany operations; therefore, adding and removing nodes, or changing the percentage of hash slots held by a node, requires no downtime.\nRedis Cluster supports multiple key operations as long as all of the keys involved in a single command execution (or whole transaction, or Lua script\nexecution) belong to the same hash slot. The user can force multiple keys\nto be part of the same hash slot by using a feature called hash tags.\nHash tags are documented in the Redis Cluster specification, but the gist is\nthat if there is a substring between {} brackets in a key, only what is\ninside the string is hashed. For example, the keys `user:{123}:profile` and `user:{123}:account` are guaranteed to be in the same hash slot because they share the same hash tag. As a result, you can operate on these two keys in the same multi-key operation.\nRedis Cluster master-replica model\nTo remain available when a subset of master nodes are failing or are\nnot able to communicate with the majority of nodes, Redis Cluster uses a\nmaster-replica model where every hash slot has from 1 (the master itself) to N\nreplicas (N-1 additional replica nodes).\nIn our example cluster with nodes A, B, C, if node B fails the cluster is not\nable to continue, since we no longer have a way to serve hash slots in the\nrange 5501-11000.\nHowever, when the cluster is created (or at a later time), we add a replica\nnode to every master, so that the final cluster is composed of A, B, C\nthat are master nodes, and A1, B1, C1 that are replica nodes.\nThis way, the system can continue if node B fails.\nNode B1 replicates B, and B fails, the cluster will promote node B1 as the new\nmaster and will continue to operate correctly.\nHowever, note that if nodes B and B1 fail at the same time, Redis Cluster will not be able to continue to operate.\nRedis Cluster consistency guarantees\nRedis Cluster does not guarantee strong consistency. In practical\nterms this means that under certain conditions it is possible that Redis\nCluster will lose writes that were acknowledged by the system to the client.\nThe first reason why Redis Cluster can lose writes is because it uses\nasynchronous replication. This means that during writes the following\nhappens:\n\nYour client writes to the master B.\nThe master B replies OK to your client.\nThe master B propagates the write to its replicas B1, B2 and B3.\n\nAs you can see, B does not wait for an acknowledgement from B1, B2, B3 before\nreplying to the client, since this would be a prohibitive latency penalty\nfor Redis, so if your client writes something, B acknowledges the write,\nbut crashes before being able to send the write to its replicas, one of the\nreplicas (that did not receive the write) can be promoted to master, losing\nthe write forever.\nThis is very similar to what happens with most databases that are\nconfigured to flush data to disk every second, so it is a scenario you\nare already able to reason about because of past experiences with traditional\ndatabase systems not involving distributed systems. Similarly you can\nimprove consistency by forcing the database to flush data to disk before\nreplying to the client, but this usually results in prohibitively low\nperformance. That would be the equivalent of synchronous replication in\nthe case of Redis Cluster.\nBasically, there is a trade-off to be made between performance and consistency.\nRedis Cluster has support for synchronous writes when absolutely needed,\nimplemented via the `WAIT` command. This makes losing writes a lot less\nlikely. However, note that Redis Cluster does not implement strong consistency\neven when synchronous replication is used: it is always possible, under more\ncomplex failure scenarios, that a replica that was not able to receive the write\nwill be elected as master.\nThere is another notable scenario where Redis Cluster will lose writes, that\nhappens during a network partition where a client is isolated with a minority\nof instances including at least a master.\nTake as an example our 6 nodes cluster composed of A, B, C, A1, B1, C1,\nwith 3 masters and 3 replicas. There is also a client, that we will call Z1.\nAfter a partition occurs, it is possible that in one side of the\npartition we have A, C, A1, B1, C1, and in the other side we have B and Z1.\nZ1 is still able to write to B, which will accept its writes. If the\npartition heals in a very short time, the cluster will continue normally.\nHowever, if the partition lasts enough time for B1 to be promoted to master\non the majority side of the partition, the writes that Z1 has sent to B\nin the meantime will be lost.\n{{% alert title=\"Note\" color=\"info\" %}}\nThere is a maximum window to the amount of writes Z1 will be able\nto send to B: if enough time has elapsed for the majority side of the\npartition to elect a replica as master, every master node in the minority\nside will have stopped accepting writes.\n{{% /alert %}}\nThis amount of time is a very important configuration directive of Redis\nCluster, and is called the node timeout.\nAfter node timeout has elapsed, a master node is considered to be failing,\nand can be replaced by one of its replicas.\nSimilarly, after node timeout has elapsed without a master node to be able\nto sense the majority of the other master nodes, it enters an error state\nand stops accepting writes.\nRedis Cluster configuration parameters\nWe are about to create an example cluster deployment. \nBefore we continue, let's introduce the configuration parameters that Redis Cluster introduces\nin the `redis.conf` file.\n\ncluster-enabled `<yes/no>`: If yes, enables Redis Cluster support in a specific Redis instance. Otherwise the instance starts as a standalone instance as usual.\ncluster-config-file `<filename>`: Note that despite the name of this option, this is not a user editable configuration file, but the file where a Redis Cluster node automatically persists the cluster configuration (the state, basically) every time there is a change, in order to be able to re-read it at startup. The file lists things like the other nodes in the cluster, their state, persistent variables, and so forth. Often this file is rewritten and flushed on disk as a result of some message reception.\ncluster-node-timeout `<milliseconds>`: The maximum amount of time a Redis Cluster node can be unavailable, without it being considered as failing. If a master node is not reachable for more than the specified amount of time, it will be failed over by its replicas. This parameter controls other important things in Redis Cluster. Notably, every node that can't reach the majority of master nodes for the specified amount of time, will stop accepting queries.\ncluster-slave-validity-factor `<factor>`: If set to zero, a replica will always consider itself valid, and will therefore always try to failover a master, regardless of the amount of time the link between the master and the replica remained disconnected. If the value is positive, a maximum disconnection time is calculated as the node timeout value multiplied by the factor provided with this option, and if the node is a replica, it will not try to start a failover if the master link was disconnected for more than the specified amount of time. For example, if the node timeout is set to 5 seconds and the validity factor is set to 10, a replica disconnected from the master for more than 50 seconds will not try to failover its master. Note that any value different than zero may result in Redis Cluster being unavailable after a master failure if there is no replica that is able to failover it. In that case the cluster will return to being available only when the original master rejoins the cluster.\ncluster-migration-barrier `<count>`: Minimum number of replicas a master will remain connected with, for another replica to migrate to a master which is no longer covered by any replica. See the appropriate section about replica migration in this tutorial for more information.\ncluster-require-full-coverage `<yes/no>`: If this is set to yes, as it is by default, the cluster stops accepting writes if some percentage of the key space is not covered by any node. If the option is set to no, the cluster will still serve queries even if only requests about a subset of keys can be processed.\ncluster-allow-reads-when-down `<yes/no>`: If this is set to no, as it is by default, a node in a Redis Cluster will stop serving all traffic when the cluster is marked as failed, either when a node can't reach a quorum of masters or when full coverage is not met. This prevents reading potentially inconsistent data from a node that is unaware of changes in the cluster. This option can be set to yes to allow reads from a node during the fail state, which is useful for applications that want to prioritize read availability but still want to prevent inconsistent writes. It can also be used for when using Redis Cluster with only one or two shards, as it allows the nodes to continue serving writes when a master fails but automatic failover is impossible.\n\nCreate and use a Redis Cluster\nTo create and use a Redis Cluster, follow these steps:\n\nCreate a Redis Cluster\nInteract with the cluster\nWrite an example app with redis-rb-cluster\nReshard the cluster\nA more interesting example application\nTest the failover\nManual failover\nAdd a new node\nRemove a node\nReplica migration\nUpgrade nodes in a Redis Cluster\nMigrate to Redis Cluster\n\nBut, first, familiarize yourself with the requirements for creating a cluster.\nRequirements to create a Redis Cluster\nTo create a cluster, the first thing you need is to have a few empty Redis instances running in cluster mode. \nAt minimum, set the following directives in the `redis.conf` file:\n`port 7000\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\nappendonly yes`\nTo enable cluster mode, set the `cluster-enabled` directive to `yes`.\nEvery instance also contains the path of a file where the\nconfiguration for this node is stored, which by default is `nodes.conf`.\nThis file is never touched by humans; it is simply generated at startup\nby the Redis Cluster instances, and updated every time it is needed.\nNote that the minimal cluster that works as expected must contain\nat least three master nodes. For deployment, we strongly recommend\na six-node cluster, with three masters and three replicas.\nYou can test this locally by creating the following directories named\nafter the port number of the instance you'll run inside any given directory.\nFor example:\n`mkdir cluster-test\ncd cluster-test\nmkdir 7000 7001 7002 7003 7004 7005`\nCreate a `redis.conf` file inside each of the directories, from 7000 to 7005.\nAs a template for your configuration file just use the small example above,\nbut make sure to replace the port number `7000` with the right port number\naccording to the directory name.\nYou can start each instance as follows, each running in a separate terminal tab:\n`cd 7000\nredis-server ./redis.conf`\nYou'll see from the logs that every node assigns itself a new ID:\n\n\n```[82462] 26 Nov 11:56:55.329 * No cluster configuration found, I'm 97a3a64667477371c4479320d683e4c8db5858b1\n```\n\n\nThis ID will be used forever by this specific instance in order for the instance\nto have a unique name in the context of the cluster. Every node\nremembers every other node using this IDs, and not by IP or port.\nIP addresses and ports may change, but the unique node identifier will never\nchange for all the life of the node. We call this identifier simply Node ID.\nCreate a Redis Cluster\nNow that we have a number of instances running, you need to create your cluster by writing some meaningful configuration to the nodes.\nYou can configure and execute individual instances manually or use the create-cluster script.\nLet's go over how you do it manually.\nTo create the cluster, run:\n\n\n```redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \\\n127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \\\n--cluster-replicas 1\n```\n\n\nThe command used here is create, since we want to create a new cluster.\nThe option `--cluster-replicas 1` means that we want a replica for every master created.\nThe other arguments are the list of addresses of the instances I want to use\nto create the new cluster.\n`redis-cli` will propose a configuration. Accept the proposed configuration by typing yes.\nThe cluster will be configured and joined, which means that instances will be\nbootstrapped into talking with each other. Finally, if everything has gone well, you'll see a message like this:\n\n\n```[OK] All 16384 slots covered\n```\n\n\nThis means that there is at least one master instance serving each of the\n16384 available slots.\nIf you don't want to create a Redis Cluster by configuring and executing\nindividual instances manually as explained above, there is a much simpler\nsystem (but you'll not learn the same amount of operational details).\nFind the `utils/create-cluster` directory in the Redis distribution.\nThere is a script called `create-cluster` inside (same name as the directory\nit is contained into), it's a simple bash script. In order to start\na 6 nodes cluster with 3 masters and 3 replicas just type the following\ncommands:\n\n`create-cluster start`\n`create-cluster create`\n\nReply to `yes` in step 2 when the `redis-cli` utility wants you to accept\nthe cluster layout.\nYou can now interact with the cluster, the first node will start at port 30001\nby default. When you are done, stop the cluster with:\n\n`create-cluster stop`\n\nPlease read the `README` inside this directory for more information on how\nto run the script.\nInteract with the cluster\nTo connect to Redis Cluster, you'll need a cluster-aware Redis client. \nSee the documentation for your client of choice to determine its cluster support.\nYou can also test your Redis Cluster using the `redis-cli` command line utility:\n`$ redis-cli -c -p 7000\nredis 127.0.0.1:7000> set foo bar\n-> Redirected to slot [12182] located at 127.0.0.1:7002\nOK\nredis 127.0.0.1:7002> set hello world\n-> Redirected to slot [866] located at 127.0.0.1:7000\nOK\nredis 127.0.0.1:7000> get foo\n-> Redirected to slot [12182] located at 127.0.0.1:7002\n\"bar\"\nredis 127.0.0.1:7002> get hello\n-> Redirected to slot [866] located at 127.0.0.1:7000\n\"world\"`\n{{% alert title=\"Note\" color=\"info\" %}} \nIf you created the cluster using the script, your nodes may listen\non different ports, starting from 30001 by default.\n{{% /alert %}}\nThe `redis-cli` cluster support is very basic, so it always uses the fact that\nRedis Cluster nodes are able to redirect a client to the right node.\nA serious client is able to do better than that, and cache the map between\nhash slots and nodes addresses, to directly use the right connection to the\nright node. The map is refreshed only when something changed in the cluster\nconfiguration, for example after a failover or after the system administrator\nchanged the cluster layout by adding or removing nodes.\nWrite an example app with redis-rb-cluster\nBefore going forward showing how to operate the Redis Cluster, doing things\nlike a failover, or a resharding, we need to create some example application\nor at least to be able to understand the semantics of a simple Redis Cluster\nclient interaction.\nIn this way we can run an example and at the same time try to make nodes\nfailing, or start a resharding, to see how Redis Cluster behaves under real\nworld conditions. It is not very helpful to see what happens while nobody\nis writing to the cluster.\nThis section explains some basic usage of\nredis-rb-cluster showing two\nexamples. \nThe first is the following, and is the\nexample.rb\nfile inside the redis-rb-cluster distribution:\n`1  require './cluster'\n   2\n   3  if ARGV.length != 2\n   4      startup_nodes = [\n   5          {:host => \"127.0.0.1\", :port => 7000},\n   6          {:host => \"127.0.0.1\", :port => 7001}\n   7      ]\n   8  else\n   9      startup_nodes = [\n  10          {:host => ARGV[0], :port => ARGV[1].to_i}\n  11      ]\n  12  end\n  13\n  14  rc = RedisCluster.new(startup_nodes,32,:timeout => 0.1)\n  15\n  16  last = false\n  17\n  18  while not last\n  19      begin\n  20          last = rc.get(\"__last__\")\n  21          last = 0 if !last\n  22      rescue => e\n  23          puts \"error #{e.to_s}\"\n  24          sleep 1\n  25      end\n  26  end\n  27\n  28  ((last.to_i+1)..1000000000).each{|x|\n  29      begin\n  30          rc.set(\"foo#{x}\",x)\n  31          puts rc.get(\"foo#{x}\")\n  32          rc.set(\"__last__\",x)\n  33      rescue => e\n  34          puts \"error #{e.to_s}\"\n  35      end\n  36      sleep 0.1\n  37  }`\nThe application does a very simple thing, it sets keys in the form `foo<number>` to `number`, one after the other. So if you run the program the result is the\nfollowing stream of commands:\n\nSET foo0 0\nSET foo1 1\nSET foo2 2\nAnd so forth...\n\nThe program looks more complex than it should usually as it is designed to\nshow errors on the screen instead of exiting with an exception, so every\noperation performed with the cluster is wrapped by `begin` `rescue` blocks.\nThe line 14 is the first interesting line in the program. It creates the\nRedis Cluster object, using as argument a list of startup nodes, the maximum\nnumber of connections this object is allowed to take against different nodes,\nand finally the timeout after a given operation is considered to be failed.\nThe startup nodes don't need to be all the nodes of the cluster. The important\nthing is that at least one node is reachable. Also note that redis-rb-cluster\nupdates this list of startup nodes as soon as it is able to connect with the\nfirst node. You should expect such a behavior with any other serious client.\nNow that we have the Redis Cluster object instance stored in the rc variable,\nwe are ready to use the object like if it was a normal Redis object instance.\nThis is exactly what happens in line 18 to 26: when we restart the example\nwe don't want to start again with `foo0`, so we store the counter inside\nRedis itself. The code above is designed to read this counter, or if the\ncounter does not exist, to assign it the value of zero.\nHowever note how it is a while loop, as we want to try again and again even\nif the cluster is down and is returning errors. Normal applications don't need\nto be so careful.\nLines between 28 and 37 start the main loop where the keys are set or\nan error is displayed.\nNote the `sleep` call at the end of the loop. In your tests you can remove\nthe sleep if you want to write to the cluster as fast as possible (relatively\nto the fact that this is a busy loop without real parallelism of course, so\nyou'll get the usually 10k ops/second in the best of the conditions).\nNormally writes are slowed down in order for the example application to be\neasier to follow by humans.\nStarting the application produces the following output:\n`ruby ./example.rb\n1\n2\n3\n4\n5\n6\n7\n8\n9\n^C (I stopped the program here)`\nThis is not a very interesting program and we'll use a better one in a moment\nbut we can already see what happens during a resharding when the program\nis running.\nReshard the cluster\nNow we are ready to try a cluster resharding. To do this, please\nkeep the example.rb program running, so that you can see if there is some\nimpact on the program running. Also, you may want to comment the `sleep`\ncall to have some more serious write load during resharding.\nResharding basically means to move hash slots from a set of nodes to another\nset of nodes. \nLike cluster creation, it is accomplished using the redis-cli utility.\nTo start a resharding, just type:\n\n\n```redis-cli --cluster reshard 127.0.0.1:7000\n```\n\n\nYou only need to specify a single node, redis-cli will find the other nodes\nautomatically.\nCurrently redis-cli is only able to reshard with the administrator support,\nyou can't just say move 5% of slots from this node to the other one (but\nthis is pretty trivial to implement). So it starts with questions. The first\nis how much of a resharding do you want to do:\n\n\n```How many slots do you want to move (from 1 to 16384)?\n```\n\n\nWe can try to reshard 1000 hash slots, that should already contain a non\ntrivial amount of keys if the example is still running without the sleep\ncall.\nThen redis-cli needs to know what is the target of the resharding, that is,\nthe node that will receive the hash slots.\nI'll use the first master node, that is, 127.0.0.1:7000, but I need\nto specify the Node ID of the instance. This was already printed in a\nlist by redis-cli, but I can always find the ID of a node with the following\ncommand if I need:\n`$ redis-cli -p 7000 cluster nodes | grep myself\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5460`\nOk so my target node is 97a3a64667477371c4479320d683e4c8db5858b1.\nNow you'll get asked from what nodes you want to take those keys.\nI'll just type `all` in order to take a bit of hash slots from all the\nother master nodes.\nAfter the final confirmation you'll see a message for every slot that\nredis-cli is going to move from a node to another, and a dot will be printed\nfor every actual key moved from one side to the other.\nWhile the resharding is in progress you should be able to see your\nexample program running unaffected. You can stop and restart it multiple times\nduring the resharding if you want.\nAt the end of the resharding, you can test the health of the cluster with\nthe following command:\n\n\n```redis-cli --cluster check 127.0.0.1:7000\n```\n\n\nAll the slots will be covered as usual, but this time the master at\n127.0.0.1:7000 will have more hash slots, something around 6461.\nResharding can be performed automatically without the need to manually\nenter the parameters in an interactive way. This is possible using a command\nline like the following:\n\n\n```redis-cli --cluster reshard <host>:<port> --cluster-from <node-id> --cluster-to <node-id> --cluster-slots <number of slots> --cluster-yes\n```\n\n\nThis allows to build some automatism if you are likely to reshard often,\nhowever currently there is no way for `redis-cli` to automatically\nrebalance the cluster checking the distribution of keys across the cluster\nnodes and intelligently moving slots as needed. This feature will be added\nin the future.\nThe `--cluster-yes` option instructs the cluster manager to automatically answer\n\"yes\" to the command's prompts, allowing it to run in a non-interactive mode.\nNote that this option can also be activated by setting the\n`REDISCLI_CLUSTER_YES` environment variable.\nA more interesting example application\nThe example application we wrote early is not very good.\nIt writes to the cluster in a simple way without even checking if what was\nwritten is the right thing.\nFrom our point of view the cluster receiving the writes could just always\nwrite the key `foo` to `42` to every operation, and we would not notice at\nall.\nSo in the `redis-rb-cluster` repository, there is a more interesting application\nthat is called `consistency-test.rb`. It uses a set of counters, by default 1000, and sends `INCR` commands in order to increment the counters.\nHowever instead of just writing, the application does two additional things:\n\nWhen a counter is updated using `INCR`, the application remembers the write.\nIt also reads a random counter before every write, and check if the value is what we expected it to be, comparing it with the value it has in memory.\n\nWhat this means is that this application is a simple consistency checker,\nand is able to tell you if the cluster lost some write, or if it accepted\na write that we did not receive acknowledgment for. In the first case we'll\nsee a counter having a value that is smaller than the one we remember, while\nin the second case the value will be greater.\nRunning the consistency-test application produces a line of output every\nsecond:\n`$ ruby consistency-test.rb\n925 R (0 err) | 925 W (0 err) |\n5030 R (0 err) | 5030 W (0 err) |\n9261 R (0 err) | 9261 W (0 err) |\n13517 R (0 err) | 13517 W (0 err) |\n17780 R (0 err) | 17780 W (0 err) |\n22025 R (0 err) | 22025 W (0 err) |\n25818 R (0 err) | 25818 W (0 err) |`\nThe line shows the number of Reads and Writes performed, and the\nnumber of errors (query not accepted because of errors since the system was\nnot available).\nIf some inconsistency is found, new lines are added to the output.\nThis is what happens, for example, if I reset a counter manually while\nthe program is running:\n```\n$ redis-cli -h 127.0.0.1 -p 7000 set key_217 0\nOK\n(in the other tab I see...)\n94774 R (0 err) | 94774 W (0 err) |\n98821 R (0 err) | 98821 W (0 err) |\n102886 R (0 err) | 102886 W (0 err) | 114 lost |\n107046 R (0 err) | 107046 W (0 err) | 114 lost |\n```\nWhen I set the counter to 0 the real value was 114, so the program reports\n114 lost writes (`INCR` commands that are not remembered by the cluster).\nThis program is much more interesting as a test case, so we'll use it\nto test the Redis Cluster failover.\nTest the failover\nTo trigger the failover, the simplest thing we can do (that is also\nthe semantically simplest failure that can occur in a distributed system)\nis to crash a single process, in our case a single master.\n{{% alert title=\"Note\" color=\"info\" %}} \nDuring this test, you should take a tab open with the consistency test\napplication running.\n{{% /alert %}} \nWe can identify a master and crash it with the following command:\n`$ redis-cli -p 7000 cluster nodes | grep master\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385482984082 0 connected 5960-10921\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 master - 0 1385482983582 0 connected 11423-16383\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-11422`\nOk, so 7000, 7001, and 7002 are masters. Let's crash node 7002 with the\nDEBUG SEGFAULT command:\n`$ redis-cli -p 7002 debug segfault\nError: Server closed the connection`\nNow we can look at the output of the consistency test to see what it reported.\n```\n18849 R (0 err) | 18849 W (0 err) |\n23151 R (0 err) | 23151 W (0 err) |\n27302 R (0 err) | 27302 W (0 err) |\n... many error warnings here ...\n29659 R (578 err) | 29660 W (577 err) |\n33749 R (578 err) | 33750 W (577 err) |\n37918 R (578 err) | 37919 W (577 err) |\n42077 R (578 err) | 42078 W (577 err) |\n```\nAs you can see during the failover the system was not able to accept 578 reads and 577 writes, however no inconsistency was created in the database. This may\nsound unexpected as in the first part of this tutorial we stated that Redis\nCluster can lose writes during the failover because it uses asynchronous\nreplication. What we did not say is that this is not very likely to happen\nbecause Redis sends the reply to the client, and the commands to replicate\nto the replicas, about at the same time, so there is a very small window to\nlose data. However the fact that it is hard to trigger does not mean that it\nis impossible, so this does not change the consistency guarantees provided\nby Redis cluster.\nWe can now check what is the cluster setup after the failover (note that\nin the meantime I restarted the crashed instance so that it rejoins the\ncluster as a replica):\n`$ redis-cli -p 7000 cluster nodes\n3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385503418521 0 connected\na211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385503419023 0 connected\n97a3a64667477371c4479320d683e4c8db5858b1 :0 myself,master - 0 0 0 connected 0-5959 10922-11422\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385503419023 3 connected 11423-16383\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385503417005 0 connected 5960-10921\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385503418016 3 connected`\nNow the masters are running on ports 7000, 7001 and 7005. What was previously\na master, that is the Redis instance running on port 7002, is now a replica of\n7005.\nThe output of the `CLUSTER NODES` command may look intimidating, but it is actually pretty simple, and is composed of the following tokens:\n\nNode ID\nip:port\nflags: master, replica, myself, fail, ...\nif it is a replica, the Node ID of the master\nTime of the last pending PING still waiting for a reply.\nTime of the last PONG received.\nConfiguration epoch for this node (see the Cluster specification).\nStatus of the link to this node.\nSlots served...\n\nManual failover\nSometimes it is useful to force a failover without actually causing any problem\non a master. For example, to upgrade the Redis process of one of the\nmaster nodes it is a good idea to failover it to turn it into a replica\nwith minimal impact on availability.\nManual failovers are supported by Redis Cluster using the `CLUSTER FAILOVER`\ncommand, that must be executed in one of the replicas of the master you want\nto failover.\nManual failovers are special and are safer compared to failovers resulting from\nactual master failures. They occur in a way that avoids data loss in the\nprocess, by switching clients from the original master to the new master only\nwhen the system is sure that the new master processed all the replication stream\nfrom the old one.\nThis is what you see in the replica log when you perform a manual failover:\n\n\n```# Manual failover user request accepted.\n# Received replication offset for paused master manual failover: 347540\n# All master replication stream processed, manual failover can start.\n# Start of election delayed for 0 milliseconds (rank #0, offset 347540).\n# Starting a failover election for epoch 7545.\n# Failover election won: I'm the new master.\n```\n\n\nBasically clients connected to the master we are failing over are stopped.\nAt the same time the master sends its replication offset to the replica, that\nwaits to reach the offset on its side. When the replication offset is reached,\nthe failover starts, and the old master is informed about the configuration\nswitch. When the clients are unblocked on the old master, they are redirected\nto the new master.\n{{% alert title=\"Note\" color=\"info\" %}} \nTo promote a replica to master, it must first be known as a replica by a majority of the masters in the cluster.\n  Otherwise, it cannot win the failover election.\n  If the replica has just been added to the cluster (see Add a new node as a replica), you may need to wait a while before sending the `CLUSTER FAILOVER` command, to make sure the masters in cluster are aware of the new replica.\n{{% /alert %}} \nAdd a new node\nAdding a new node is basically the process of adding an empty node and then\nmoving some data into it, in case it is a new master, or telling it to\nsetup as a replica of a known node, in case it is a replica.\nWe'll show both, starting with the addition of a new master instance.\nIn both cases the first step to perform is adding an empty node.\nThis is as simple as to start a new node in port 7006 (we already used\nfrom 7000 to 7005 for our existing 6 nodes) with the same configuration\nused for the other nodes, except for the port number, so what you should\ndo in order to conform with the setup we used for the previous nodes:\n\nCreate a new tab in your terminal application.\nEnter the `cluster-test` directory.\nCreate a directory named `7006`.\nCreate a redis.conf file inside, similar to the one used for the other nodes but using 7006 as port number.\nFinally start the server with `../redis-server ./redis.conf`\n\nAt this point the server should be running.\nNow we can use redis-cli as usual in order to add the node to\nthe existing cluster.\n\n\n```redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000\n```\n\n\nAs you can see I used the add-node command specifying the address of the\nnew node as first argument, and the address of a random existing node in the\ncluster as second argument.\nIn practical terms redis-cli here did very little to help us, it just\nsent a `CLUSTER MEET` message to the node, something that is also possible\nto accomplish manually. However redis-cli also checks the state of the\ncluster before to operate, so it is a good idea to perform cluster operations\nalways via redis-cli even when you know how the internals work.\nNow we can connect to the new node to see if it really joined the cluster:\n`redis 127.0.0.1:7006> cluster nodes\n3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 127.0.0.1:7001 master - 0 1385543178575 0 connected 5960-10921\n3fc783611028b1707fd65345e763befb36454d73 127.0.0.1:7004 slave 3e3a6cb0d9a9a87168e266b0a0b24026c0aae3f0 0 1385543179583 0 connected\nf093c80dde814da99c5cf72a7dd01590792b783b :0 myself,master - 0 0 0 connected\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543178072 3 connected\na211e242fc6b22a9427fed61285e85892fa04e08 127.0.0.1:7003 slave 97a3a64667477371c4479320d683e4c8db5858b1 0 1385543178575 0 connected\n97a3a64667477371c4479320d683e4c8db5858b1 127.0.0.1:7000 master - 0 1385543179080 0 connected 0-5959 10922-11422\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 127.0.0.1:7005 master - 0 1385543177568 3 connected 11423-16383`\nNote that since this node is already connected to the cluster it is already\nable to redirect client queries correctly and is generally speaking part of\nthe cluster. However it has two peculiarities compared to the other masters:\n\nIt holds no data as it has no assigned hash slots.\nBecause it is a master without assigned slots, it does not participate in the election process when a replica wants to become a master.\n\nNow it is possible to assign hash slots to this node using the resharding\nfeature of `redis-cli`. \nIt is basically useless to show this as we already\ndid in a previous section, there is no difference, it is just a resharding\nhaving as a target the empty node.\nAdd a new node as a replica\nAdding a new replica can be performed in two ways. The obvious one is to\nuse redis-cli again, but with the --cluster-slave option, like this:\n\n\n```redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-slave\n```\n\n\nNote that the command line here is exactly like the one we used to add\na new master, so we are not specifying to which master we want to add\nthe replica. In this case, what happens is that redis-cli will add the new\nnode as replica of a random master among the masters with fewer replicas.\nHowever you can specify exactly what master you want to target with your\nnew replica with the following command line:\n\n\n```redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-slave --cluster-master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\n```\n\n\nThis way we assign the new replica to a specific master.\nA more manual way to add a replica to a specific master is to add the new\nnode as an empty master, and then turn it into a replica using the\n`CLUSTER REPLICATE` command. This also works if the node was added as a replica\nbut you want to move it as a replica of a different master.\nFor example in order to add a replica for the node 127.0.0.1:7005 that is\ncurrently serving hash slots in the range 11423-16383, that has a Node ID\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e, all I need to do is to connect\nwith the new node (already added as empty master) and send the command:\n\n\n```redis 127.0.0.1:7006> cluster replicate 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\n```\n\n\nThat's it. Now we have a new replica for this set of hash slots, and all\nthe other nodes in the cluster already know (after a few seconds needed to\nupdate their config). We can verify with the following command:\n`$ redis-cli -p 7000 cluster nodes | grep slave | grep 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e\nf093c80dde814da99c5cf72a7dd01590792b783b 127.0.0.1:7006 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543617702 3 connected\n2938205e12de373867bf38f1ca29d31d0ddb3e46 127.0.0.1:7002 slave 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e 0 1385543617198 3 connected`\nThe node 3c3a0c... now has two replicas, running on ports 7002 (the existing one) and 7006 (the new one).\nRemove a node\nTo remove a replica node just use the `del-node` command of redis-cli:\n\n\n```redis-cli --cluster del-node 127.0.0.1:7000 `<node-id>`\n```\n\n\nThe first argument is just a random node in the cluster, the second argument\nis the ID of the node you want to remove.\nYou can remove a master node in the same way as well, however in order to\nremove a master node it must be empty. If the master is not empty you need\nto reshard data away from it to all the other master nodes before.\nAn alternative to remove a master node is to perform a manual failover of it\nover one of its replicas and remove the node after it turned into a replica of the\nnew master. Obviously this does not help when you want to reduce the actual\nnumber of masters in your cluster, in that case, a resharding is needed.\nReplica migration\nIn Redis Cluster, you can reconfigure a replica to replicate with a\ndifferent master at any time just using this command:\n\n\n```CLUSTER REPLICATE <master-node-id>\n```\n\n\nHowever there is a special scenario where you want replicas to move from one\nmaster to another one automatically, without the help of the system administrator.\nThe automatic reconfiguration of replicas is called replicas migration and is\nable to improve the reliability of a Redis Cluster.\n{{% alert title=\"Note\" color=\"info\" %}} \nYou can read the details of replicas migration in the Redis Cluster Specification, here we'll only provide some information about the\ngeneral idea and what you should do in order to benefit from it.\n{{% /alert %}} \nThe reason why you may want to let your cluster replicas to move from one master\nto another under certain condition, is that usually the Redis Cluster is as\nresistant to failures as the number of replicas attached to a given master.\nFor example a cluster where every master has a single replica can't continue\noperations if the master and its replica fail at the same time, simply because\nthere is no other instance to have a copy of the hash slots the master was\nserving. However while net-splits are likely to isolate a number of nodes\nat the same time, many other kind of failures, like hardware or software failures\nlocal to a single node, are a very notable class of failures that are unlikely\nto happen at the same time, so it is possible that in your cluster where\nevery master has a replica, the replica is killed at 4am, and the master is killed\nat 6am. This still will result in a cluster that can no longer operate.\nTo improve reliability of the system we have the option to add additional\nreplicas to every master, but this is expensive. Replica migration allows to\nadd more replicas to just a few masters. So you have 10 masters with 1 replica\neach, for a total of 20 instances. However you add, for example, 3 instances\nmore as replicas of some of your masters, so certain masters will have more\nthan a single replica.\nWith replicas migration what happens is that if a master is left without\nreplicas, a replica from a master that has multiple replicas will migrate to\nthe orphaned master. So after your replica goes down at 4am as in the example\nwe made above, another replica will take its place, and when the master\nwill fail as well at 5am, there is still a replica that can be elected so that\nthe cluster can continue to operate.\nSo what you should know about replicas migration in short?\n\nThe cluster will try to migrate a replica from the master that has the greatest number of replicas in a given moment.\nTo benefit from replica migration you have just to add a few more replicas to a single master in your cluster, it does not matter what master.\nThere is a configuration parameter that controls the replica migration feature that is called `cluster-migration-barrier`: you can read more about it in the example `redis.conf` file provided with Redis Cluster.\n\nUpgrade nodes in a Redis Cluster\nUpgrading replica nodes is easy since you just need to stop the node and restart\nit with an updated version of Redis. If there are clients scaling reads using\nreplica nodes, they should be able to reconnect to a different replica if a given\none is not available.\nUpgrading masters is a bit more complex, and the suggested procedure is:\n\nUse `CLUSTER FAILOVER` to trigger a manual failover of the master to one of its replicas.\n   (See the Manual failover in this topic.)\nWait for the master to turn into a replica.\nFinally upgrade the node as you do for replicas.\nIf you want the master to be the node you just upgraded, trigger a new manual failover in order to turn back the upgraded node into a master.\n\nFollowing this procedure you should upgrade one node after the other until\nall the nodes are upgraded.\nMigrate to Redis Cluster\nUsers willing to migrate to Redis Cluster may have just a single master, or\nmay already using a preexisting sharding setup, where keys\nare split among N nodes, using some in-house algorithm or a sharding algorithm\nimplemented by their client library or Redis proxy.\nIn both cases it is possible to migrate to Redis Cluster easily, however\nwhat is the most important detail is if multiple-keys operations are used\nby the application, and how. There are three different cases:\n\nMultiple keys operations, or transactions, or Lua scripts involving multiple keys, are not used. Keys are accessed independently (even if accessed via transactions or Lua scripts grouping multiple commands, about the same key, together).\nMultiple keys operations, or transactions, or Lua scripts involving multiple keys are used but only with keys having the same hash tag, which means that the keys used together all have a `{...}` sub-string that happens to be identical. For example the following multiple keys operation is defined in the context of the same hash tag: `SUNION {user:1000}.foo {user:1000}.bar`.\nMultiple keys operations, or transactions, or Lua scripts involving multiple keys are used with key names not having an explicit, or the same, hash tag.\n\nThe third case is not handled by Redis Cluster: the application requires to\nbe modified in order to don't use multi keys operations or only use them in\nthe context of the same hash tag.\nCase 1 and 2 are covered, so we'll focus on those two cases, that are handled\nin the same way, so no distinction will be made in the documentation.\nAssuming you have your preexisting data set split into N masters, where\nN=1 if you have no preexisting sharding, the following steps are needed\nin order to migrate your data set to Redis Cluster:\n\nStop your clients. No automatic live-migration to Redis Cluster is currently possible. You may be able to do it orchestrating a live migration in the context of your application / environment.\nGenerate an append only file for all of your N masters using the `BGREWRITEAOF` command, and waiting for the AOF file to be completely generated.\nSave your AOF files from aof-1 to aof-N somewhere. At this point you can stop your old instances if you wish (this is useful since in non-virtualized deployments you often need to reuse the same computers).\nCreate a Redis Cluster composed of N masters and zero replicas. You'll add replicas later. Make sure all your nodes are using the append only file for persistence.\nStop all the cluster nodes, substitute their append only file with your pre-existing append only files, aof-1 for the first node, aof-2 for the second node, up to aof-N.\nRestart your Redis Cluster nodes with the new AOF files. They'll complain that there are keys that should not be there according to their configuration.\nUse `redis-cli --cluster fix` command in order to fix the cluster so that keys will be migrated according to the hash slots each node is authoritative or not.\nUse `redis-cli --cluster check` at the end to make sure your cluster is ok.\nRestart your clients modified to use a Redis Cluster aware client library.\n\nThere is an alternative way to import data from external instances to a Redis\nCluster, which is to use the `redis-cli --cluster import` command.\nThe command moves all the keys of a running instance (deleting the keys from\nthe source instance) to the specified pre-existing Redis Cluster. However\nnote that if you use a Redis 2.8 instance as source instance the operation\nmay be slow since 2.8 does not implement migrate connection caching, so you\nmay want to restart your source instance with a Redis 3.x version before\nto perform such operation.\n{{% alert title=\"Note\" color=\"info\" %}} \nStarting with Redis 5, if not for backward compatibility, the Redis project no longer uses the word slave. Unfortunately in this command the word slave is part of the protocol, so we'll be able to remove such occurrences only when this API will be naturally deprecated.\n{{% /alert %}} \nLearn more\n\nRedis Cluster specification\nLinear Scaling with Redis Enterprise\nDocker documentation\n",
    "tag": "redis"
  },
  {
    "title": "What is GDB?",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/debugging.md",
    "content": "\ntitle: \"Debugging\"\nlinkTitle: \"Debugging\"\nweight: 10\ndescription: >\n    A guide to debugging Redis server processes\naliases: [\n    /topics/debugging,\n    /docs/reference/debugging,\n    /docs/reference/debugging.md\n]\n\nRedis is developed with an emphasis on stability. We do our best with\nevery release to make sure you'll experience a stable product with no\ncrashes. However, if you ever need to debug the Redis process itself, read on.\nWhen Redis crashes, it produces a detailed report of what happened. However,\nsometimes looking at the crash report is not enough, nor is it possible for\nthe Redis core team to reproduce the issue independently. In this scenario, we\nneed help from the user who can reproduce the issue.\nThis guide shows how to use GDB to provide the information the\nRedis developers will need to track the bug more easily.\nWhat is GDB?\nGDB is the Gnu Debugger: a program that is able to inspect the internal state\nof another program. Usually tracking and fixing a bug is an exercise in\ngathering more information about the state of the program at the moment the\nbug happens, so GDB is an extremely useful tool.\nGDB can be used in two ways:\n\nIt can attach to a running program and inspect the state of it at runtime.\nIt can inspect the state of a program that already terminated using what is called a core file, that is, the image of the memory at the time the program was running.\n\nFrom the point of view of investigating Redis bugs we need to use both of these\nGDB modes. The user able to reproduce the bug attaches GDB to their running Redis\ninstance, and when the crash happens, they create the `core` file that in turn\nthe developer will use to inspect the Redis internals at the time of the crash.\nThis way the developer can perform all the inspections in his or her computer\nwithout the help of the user, and the user is free to restart Redis in their\nproduction environment.\nCompiling Redis without optimizations\nBy default Redis is compiled with the `-O2` switch, this means that compiler\noptimizations are enabled. This makes the Redis executable faster, but at the\nsame time it makes Redis (like any other program) harder to inspect using GDB.\nIt is better to attach GDB to Redis compiled without optimizations using the\n`make noopt` command (instead of just using the plain `make` command). However,\nif you have an already running Redis in production there is no need to recompile\nand restart it if this is going to create problems on your side. GDB still works\nagainst executables compiled with optimizations.\nYou should not be overly concerned at the loss of performance from compiling Redis\nwithout optimizations. It is unlikely that this will cause problems in your\nenvironment as Redis is not very CPU-bound.\nAttaching GDB to a running process\nIf you have an already running Redis server, you can attach GDB to it, so that\nif Redis crashes it will be possible to both inspect the internals and generate\na `core dump` file.\nAfter you attach GDB to the Redis process it will continue running as usual without\nany loss of performance, so this is not a dangerous procedure.\nIn order to attach GDB the first thing you need is the process ID of the running\nRedis instance (the pid of the process). You can easily obtain it using\n`redis-cli`:\n\n\n```$ redis-cli info | grep process_id\nprocess_id:58414\n```\n\n\nIn the above example the process ID is 58414.\nLogin into your Redis server.\n(Optional but recommended) Start screen or tmux or any other program that will make sure that your GDB session will not be closed if your ssh connection times out. You can learn more about screen in this article.\nAttach GDB to the running Redis server by typing:\n\n\n```$ gdb <path-to-redis-executable> <pid>\n```\n\n\nFor example:\n\n\n```$ gdb /usr/local/bin/redis-server 58414\n```\n\n\nGDB will start and will attach to the running server printing something like the following:\n\n\n```Reading symbols for shared libraries + done\n0x00007fff8d4797e6 in epoll_wait ()\n(gdb)\n```\n\n\nAt this point GDB is attached but your Redis instance is blocked by GDB. In\norder to let the Redis instance continue the execution just type continue at\nthe GDB prompt, and press enter.\n\n\n```(gdb) continue\nContinuing.\n```\n\n\nDone! Now your Redis instance has GDB attached. Now you can wait for the next crash. :)\nNow it's time to detach your screen/tmux session, if you are running GDB using it, by\npressing Ctrl-a a key combination.\nAfter the crash\nRedis has a command to simulate a segmentation fault (in other words a bad crash) using\nthe `DEBUG SEGFAULT` command (don't use it against a real production instance of course!\nSo I'll use this command to crash my instance to show what happens in the GDB side:\n\n\n```(gdb) continue\nContinuing.\n\nProgram received signal EXC_BAD_ACCESS, Could not access memory.\nReason: KERN_INVALID_ADDRESS at address: 0xffffffffffffffff\ndebugCommand (c=0x7ffc32005000) at debug.c:220\n220         *((char*)-1) = 'x';\n```\n\n\nAs you can see GDB detected that Redis crashed, and was even able to show me\nthe file name and line number causing the crash. This is already much better\nthan the Redis crash report back trace (containing just function names and\nbinary offsets).\nObtaining the stack trace\nThe first thing to do is to obtain a full stack trace with GDB. This is as\nsimple as using the bt command:\n\n\n```(gdb) bt\n#0  debugCommand (c=0x7ffc32005000) at debug.c:220\n#1  0x000000010d246d63 in call (c=0x7ffc32005000) at redis.c:1163\n#2  0x000000010d247290 in processCommand (c=0x7ffc32005000) at redis.c:1305\n#3  0x000000010d251660 in processInputBuffer (c=0x7ffc32005000) at networking.c:959\n#4  0x000000010d251872 in readQueryFromClient (el=0x0, fd=5, privdata=0x7fff76f1c0b0, mask=220924512) at networking.c:1021\n#5  0x000000010d243523 in aeProcessEvents (eventLoop=0x7fff6ce408d0, flags=220829559) at ae.c:352\n#6  0x000000010d24373b in aeMain (eventLoop=0x10d429ef0) at ae.c:397\n#7  0x000000010d2494ff in main (argc=1, argv=0x10d2b2900) at redis.c:2046\n```\n\n\nThis shows the backtrace, but we also want to dump the processor registers using the info registers command:\n\n\n```(gdb) info registers\nrax            0x0  0\nrbx            0x7ffc32005000   140721147367424\nrcx            0x10d2b0a60  4515891808\nrdx            0x7fff76f1c0b0   140735188943024\nrsi            0x10d299777  4515796855\nrdi            0x0  0\nrbp            0x7fff6ce40730   0x7fff6ce40730\nrsp            0x7fff6ce40650   0x7fff6ce40650\nr8             0x4f26b3f7   1327936503\nr9             0x7fff6ce40718   140735020271384\nr10            0x81 129\nr11            0x10d430398  4517462936\nr12            0x4b7c04f8babc0  1327936503000000\nr13            0x10d3350a0  4516434080\nr14            0x10d42d9f0  4517452272\nr15            0x10d430398  4517462936\nrip            0x10d26cfd4  0x10d26cfd4 <debugCommand+68>\neflags         0x10246  66118\ncs             0x2b 43\nss             0x0  0\nds             0x0  0\nes             0x0  0\nfs             0x0  0\ngs             0x0  0\n```\n\n\nPlease make sure to include both of these outputs in your bug report.\nObtaining the core file\nThe next step is to generate the core dump, that is the image of the memory of the running Redis process. This is done using the `gcore` command:\n\n\n```(gdb) gcore\nSaved corefile core.58414\n```\n\n\nNow you have the core dump to send to the Redis developer, but it is important\nto understand that this happens to contain all the data that was inside the\nRedis instance at the time of the crash; Redis developers will make sure not to\nshare the content with anyone else, and will delete the file as soon as it is no\nlonger used for debugging purposes, but you are warned that by sending the core\nfile you are sending your data.\nWhat to send to developers\nFinally you can send everything to the Redis core team:\n\nThe Redis executable you are using.\nThe stack trace produced by the bt command, and the registers dump.\nThe core file you generated with gdb.\nInformation about the operating system and GCC version, and Redis version you are using.\n\nThank you\nYour help is extremely important! Many issues can only be tracked this way. So",
    "tag": "redis"
  },
  {
    "title": "When ACLs are useful",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/security/acl.md",
    "content": "\ntitle: \"ACL\"\nlinkTitle: \"ACL\"\nweight: 1\ndescription: Redis Access Control List\naliases: [\n    /topics/acl,\n    /docs/manual/security/acl,\n    /docs/manual/security/acl.md\n]\n\nThe Redis ACL, short for Access Control List, is the feature that allows certain\nconnections to be limited in terms of the commands that can be executed and the\nkeys that can be accessed. The way it works is that, after connecting, a client\nis required to provide a username and a valid password to authenticate. If authentication succeeded, the connection is associated with a given\nuser and the limits the user has. Redis can be configured so that new\nconnections are already authenticated with a \"default\" user (this is the\ndefault configuration). Configuring the default user has, as a side effect,\nthe ability to provide only a specific subset of functionalities to connections\nthat are not explicitly authenticated.\nIn the default configuration, Redis 6 (the first version to have ACLs) works\nexactly like older versions of Redis. Every new connection is\ncapable of calling every possible command and accessing every key, so the\nACL feature is backward compatible with old clients and applications. Also\nthe old way to configure a password, using the requirepass configuration\ndirective, still works as expected. However, it now\nsets a password for the default user.\nThe Redis `AUTH` command was extended in Redis 6, so now it is possible to\nuse it in the two-arguments form:\n\n\n```AUTH <username> <password>\n```\n\n\nHere's an example of the old form:\n\n\n```AUTH <password>\n```\n\n\nWhat happens is that the username used to authenticate is \"default\", so\njust specifying the password implies that we want to authenticate against\nthe default user. This provides backward compatibility.\nWhen ACLs are useful\nBefore using ACLs, you may want to ask yourself what's the goal you want to\naccomplish by implementing this layer of protection. Normally there are\ntwo main goals that are well served by ACLs:\n\nYou want to improve security by restricting the access to commands and keys, so that untrusted clients have no access and trusted clients have just the minimum access level to the database in order to perform the work needed. For instance, certain clients may just be able to execute read only commands.\nYou want to improve operational safety, so that processes or humans accessing Redis are not allowed to damage the data or the configuration due to software errors or manual mistakes. For instance, there is no reason for a worker that fetches delayed jobs from Redis to be able to call the `FLUSHALL` command.\n\nAnother typical usage of ACLs is related to managed Redis instances. Redis is\noften provided as a managed service both by internal company teams that handle\nthe Redis infrastructure for the other internal customers they have, or is\nprovided in a software-as-a-service setup by cloud providers. In both \nsetups, we want to be sure that configuration commands are excluded for the\ncustomers.\nConfigure ACLs with the ACL command\nACLs are defined using a DSL (domain specific language) that describes what\na given user is allowed to do. Such rules are always implemented from the\nfirst to the last, left-to-right, because sometimes the order of the rules is\nimportant to understand what the user is really able to do.\nBy default there is a single user defined, called default. We\ncan use the `ACL LIST` command in order to check the currently active ACLs\nand verify what the configuration of a freshly started, defaults-configured\nRedis instance is:\n\n\n```> ACL LIST\n1) \"user default on nopass ~* &* +@all\"\n```\n\n\nThe command above reports the list of users in the same format that is\nused in the Redis configuration files, by translating the current ACLs set\nfor the users back into their description.\nThe first two words in each line are \"user\" followed by the username. The\nnext words are ACL rules that describe different things. We'll show how the rules work in detail, but for now it is enough to say that the default\nuser is configured to be active (on), to require no password (nopass), to\naccess every possible key (`~*`) and Pub/Sub channel (`&*`), and be able to\ncall every possible command (`+@all`).\nAlso, in the special case of the default user, having the nopass rule means\nthat new connections are automatically authenticated with the default user\nwithout any explicit `AUTH` call needed.\nACL rules\nThe following is the list of valid ACL rules. Certain rules are just\nsingle words that are used in order to activate or remove a flag, or to\nperform a given change to the user ACL. Other rules are char prefixes that\nare concatenated with command or category names, key patterns, and\nso forth.\nEnable and disallow users:\n\n`on`: Enable the user: it is possible to authenticate as this user.\n`off`: Disallow the user: it's no longer possible to authenticate with this user; however, previously authenticated connections will still work. Note that if the default user is flagged as off, new connections will start as not authenticated and will require the user to send `AUTH` or `HELLO` with the AUTH option in order to authenticate in some way, regardless of the default user configuration.\n\nAllow and disallow commands:\n\n`+<command>`: Add the command to the list of commands the user can call. Can be used with `|` for allowing subcommands (e.g \"+config|get\").\n`-<command>`: Remove the command to the list of commands the user can call. Starting Redis 7.0, it can be used with `|` for blocking subcommands (e.g \"-config|set\").\n`+@<category>`: Add all the commands in such category to be called by the user, with valid categories being like @admin, @set, @sortedset, ... and so forth, see the full list by calling the `ACL CAT` command. The special category @all means all the commands, both the ones currently present in the server, and the ones that will be loaded in the future via modules.\n`-@<category>`: Like `+@<category>` but removes the commands from the list of commands the client can call.\n`+<command>|first-arg`: Allow a specific first argument of an otherwise disabled command. It is only supported on commands with no sub-commands, and is not allowed as negative form like -SELECT|1, only additive starting with \"+\". This feature is deprecated and may be removed in the future.\n`allcommands`: Alias for +@all. Note that it implies the ability to execute all the future commands loaded via the modules system.\n`nocommands`: Alias for -@all.\n\nAllow and disallow certain keys and key permissions:\n\n`~<pattern>`: Add a pattern of keys that can be mentioned as part of commands. For instance `~*` allows all the keys. The pattern is a glob-style pattern like the one of `KEYS`. It is possible to specify multiple patterns.\n`%R~<pattern>`: (Available in Redis 7.0 and later) Add the specified read key pattern. This behaves similar to the regular key pattern but only grants permission to read from keys that match the given pattern. See key permissions for more information.\n`%W~<pattern>`: (Available in Redis 7.0 and later) Add the specified write key pattern. This behaves similar to the regular key pattern but only grants permission to write to keys that match the given pattern. See key permissions for more information.\n`%RW~<pattern>`: (Available in Redis 7.0 and later) Alias for `~<pattern>`. \n`allkeys`: Alias for `~*`.\n`resetkeys`: Flush the list of allowed keys patterns. For instance the ACL `~foo:* ~bar:* resetkeys ~objects:*`, will only allow the client to access keys that match the pattern `objects:*`.\n\nAllow and disallow Pub/Sub channels:\n\n`&<pattern>`: (Available in Redis 6.2 and later) Add a glob style pattern of Pub/Sub channels that can be accessed by the user. It is possible to specify multiple channel patterns. Note that pattern matching is done only for channels mentioned by `PUBLISH` and `SUBSCRIBE`, whereas `PSUBSCRIBE` requires a literal match between its channel patterns and those allowed for user.\n`allchannels`: Alias for `&*` that allows the user to access all Pub/Sub channels.\n`resetchannels`: Flush the list of allowed channel patterns and disconnect the user's Pub/Sub clients if these are no longer able to access their respective channels and/or channel patterns.\n\nConfigure valid passwords for the user:\n\n`><password>`: Add this password to the list of valid passwords for the user. For example `>mypass` will add \"mypass\" to the list of valid passwords.  This directive clears the nopass flag (see later). Every user can have any number of passwords.\n`<<password>`: Remove this password from the list of valid passwords. Emits an error in case the password you are trying to remove is actually not set.\n`#<hash>`: Add this SHA-256 hash value to the list of valid passwords for the user. This hash value will be compared to the hash of a password entered for an ACL user. This allows users to store hashes in the `acl.conf` file rather than storing cleartext passwords. Only SHA-256 hash values are accepted as the password hash must be 64 characters and only contain lowercase hexadecimal characters.\n`!<hash>`: Remove this hash value from the list of valid passwords. This is useful when you do not know the password specified by the hash value but would like to remove the password from the user.\n`nopass`: All the set passwords of the user are removed, and the user is flagged as requiring no password: it means that every password will work against this user. If this directive is used for the default user, every new connection will be immediately authenticated with the default user without any explicit AUTH command required. Note that the resetpass directive will clear this condition.\n`resetpass`: Flushes the list of allowed passwords and removes the nopass status. After resetpass, the user has no associated passwords and there is no way to authenticate without adding some password (or setting it as nopass later).\n\nNote: if a user is not flagged with nopass and has no list of valid passwords, that user is effectively impossible to use because there will be no way to log in as that user.\nConfigure selectors for the user:\n\n`(<rule list>)`: (Available in Redis 7.0 and later) Create a new selector to match rules against. Selectors are evaluated after the user permissions, and are evaluated according to the order they are defined. If a command matches either the user permissions or any selector, it is allowed. See selectors for more information.\n`clearselectors`: (Available in Redis 7.0 and later) Delete all of the selectors attached to the user.\n\nReset the user:\n\n`reset` Performs the following actions: resetpass, resetkeys, resetchannels, allchannels (if acl-pubsub-default is set), off, clearselectors, -@all. The user returns to the same state it had immediately after its creation.\n\nCreate and edit user ACLs with the ACL SETUSER command\nUsers can be created and modified in two main ways:\n\nUsing the ACL command and its `ACL SETUSER` subcommand.\nModifying the server configuration, where users can be defined, and restarting the server. With an external ACL file, just call `ACL LOAD`.\n\nIn this section we'll learn how to define users using the `ACL` command.\nWith such knowledge, it will be trivial to do the same things via the\nconfiguration files. Defining users in the configuration deserves its own\nsection and will be discussed later separately.\nTo start, try the simplest `ACL SETUSER` command call:\n\n\n```> ACL SETUSER alice\nOK\n```\n\n\nThe `ACL SETUSER` command takes the username and a list of ACL rules to apply\nto the user. However the above example did not specify any rule at all.\nThis will just create the user if it did not exist, using the defaults for new\nusers. If the user already exists, the command above will do nothing at all.\nCheck the default user status:\n\n\n```> ACL LIST\n1) \"user alice off resetchannels -@all\"\n2) \"user default on nopass ~* &* +@all\"\n```\n\n\nThe new user \"alice\" is:\n\nIn the off status, so `AUTH` will not work for the user \"alice\".\nThe user also has no passwords set.\nCannot access any command. Note that the user is created by default without the ability to access any command, so the `-@all` in the output above could be omitted; however, `ACL LIST` attempts to be explicit rather than implicit.\nThere are no key patterns that the user can access.\nThere are no Pub/Sub channels that the user can access.\n\nNew users are created with restrictive permissions by default. Starting with Redis 6.2, ACL provides Pub/Sub channels access management as well. To ensure backward compatibility with version 6.0 when upgrading to Redis 6.2, new users are granted the 'allchannels' permission by default. The default can be set to `resetchannels` via the `acl-pubsub-default` configuration directive.\nFrom 7.0, The `acl-pubsub-default` value is set to `resetchannels` to restrict the channels access by default to provide better security.\nThe default can be set to `allchannels` via the `acl-pubsub-default` configuration directive to be compatible with previous versions.\nSuch user is completely useless. Let's try to define the user so that\nit is active, has a password, and can access with only the `GET` command\nto key names starting with the string \"cached:\".\n\n\n```> ACL SETUSER alice on >p1pp0 ~cached:* +get\nOK\n```\n\n\nNow the user can do something, but will refuse to do other things:\n\n\n```> AUTH alice p1pp0\nOK\n> GET foo\n(error) NOPERM this user has no permissions to access one of the keys used as arguments\n> GET cached:1234\n(nil)\n> SET cached:1234 zap\n(error) NOPERM this user has no permissions to run the 'set' command\n```\n\n\nThings are working as expected. In order to inspect the configuration of the\nuser alice (remember that user names are case sensitive), it is possible to\nuse an alternative to `ACL LIST` which is designed to be more suitable for\ncomputers to read, while `ACL GETUSER` is more human readable.\n\n\n```> ACL GETUSER alice\n1) \"flags\"\n2) 1) \"on\"\n3) \"passwords\"\n4) 1) \"2d9c75...\"\n5) \"commands\"\n6) \"-@all +get\"\n7) \"keys\"\n8) \"~cached:*\"\n9) \"channels\"\n10) \"\"\n11) \"selectors\"\n12) (empty array)\n```\n\n\nThe `ACL GETUSER` returns a field-value array that describes the user in more parsable terms. The output includes the set of flags, a list of key patterns, passwords, and so forth. The output is probably more readable if we use RESP3, so that it is returned as a map reply:\n\n\n```> ACL GETUSER alice\n1# \"flags\" => 1~ \"on\"\n2# \"passwords\" => 1) \"2d9c75273d72b32df726fb545c8a4edc719f0a95a6fd993950b10c474ad9c927\"\n3# \"commands\" => \"-@all +get\"\n4# \"keys\" => \"~cached:*\"\n5# \"channels\" => \"\"\n6# \"selectors\" => (empty array)\n```\n\n\nNote: from now on, we'll continue using the Redis default protocol, version 2\nUsing another `ACL SETUSER` command (from a different user, because alice cannot run the `ACL` command), we can add multiple patterns to the user:\n\n\n```> ACL SETUSER alice ~objects:* ~items:* ~public:*\nOK\n> ACL LIST\n1) \"user alice on #2d9c75... ~cached:* ~objects:* ~items:* ~public:* resetchannels -@all +get\"\n2) \"user default on nopass ~* &* +@all\"\n```\n\n\nThe user representation in memory is now as we expect it to be.\nMultiple calls to ACL SETUSER\nIt is very important to understand what happens when `ACL SETUSER` is called\nmultiple times. What is critical to know is that every `ACL SETUSER` call will\nNOT reset the user, but will just apply the ACL rules to the existing user.\nThe user is reset only if it was not known before. In that case, a brand new\nuser is created with zeroed-ACLs. The user cannot do anything, is\ndisallowed, has no passwords, and so forth. This is the best default for safety.\nHowever later calls will just modify the user incrementally. For instance,\nthe following sequence:\n\n\n```> ACL SETUSER myuser +set\nOK\n> ACL SETUSER myuser +get\nOK\n```\n\n\nWill result in myuser being able to call both `GET` and `SET`:\n\n\n```> ACL LIST\n1) \"user default on nopass ~* &* +@all\"\n2) \"user myuser off resetchannels -@all +get +set\"\n```\n\n\nCommand categories\nSetting user ACLs by specifying all the commands one after the other is\nreally annoying, so instead we do things like this:\n\n\n```> ACL SETUSER antirez on +@all -@dangerous >42a979... ~*\n```\n\n\nBy saying +@all and -@dangerous, we included all the commands and later removed\nall the commands that are tagged as dangerous inside the Redis command table.\nNote that command categories never include modules commands with\nthe exception of +@all. If you say +@all, all the commands can be executed by\nthe user, even future commands loaded via the modules system. However if you\nuse the ACL rule +@read or any other, the modules commands are always\nexcluded. This is very important because you should just trust the Redis\ninternal command table. Modules may expose dangerous things and in\nthe case of an ACL that is just additive, that is, in the form of `+@all -...`\nYou should be absolutely sure that you'll never include what you did not mean\nto.\nThe following is a list of command categories and their meanings:\n\nadmin - Administrative commands. Normal applications will never need to use\n  these. Includes `REPLICAOF`, `CONFIG`, `DEBUG`, `SAVE`, `MONITOR`, `ACL`, `SHUTDOWN`, etc.\nbitmap - Data type: bitmaps related.\nblocking - Potentially blocking the connection until released by another\n  command.\nconnection - Commands affecting the connection or other connections.\n  This includes `AUTH`, `SELECT`, `COMMAND`, `CLIENT`, `ECHO`, `PING`, etc.\ndangerous - Potentially dangerous commands (each should be considered with care for\n  various reasons). This includes `FLUSHALL`, `MIGRATE`, `RESTORE`, `SORT`, `KEYS`,\n  `CLIENT`, `DEBUG`, `INFO`, `CONFIG`, `SAVE`, `REPLICAOF`, etc.\ngeo - Data type: geospatial indexes related.\nhash - Data type: hashes related.\nhyperloglog - Data type: hyperloglog related.\nfast - Fast O(1) commands. May loop on the number of arguments, but not the\n  number of elements in the key.\nkeyspace - Writing or reading from keys, databases, or their metadata \n  in a type agnostic way. Includes `DEL`, `RESTORE`, `DUMP`, `RENAME`, `EXISTS`, `DBSIZE`,\n  `KEYS`, `EXPIRE`, `TTL`, `FLUSHALL`, etc. Commands that may modify the keyspace,\n  key, or metadata will also have the `write` category. Commands that only read\n  the keyspace, key, or metadata will have the `read` category.\nlist - Data type: lists related.\npubsub - PubSub-related commands.\nread - Reading from keys (values or metadata). Note that commands that don't\n  interact with keys, will not have either `read` or `write`.\nscripting - Scripting related.\nset - Data type: sets related.\nsortedset - Data type: sorted sets related.\nslow - All commands that are not `fast`.\nstream - Data type: streams related.\nstring - Data type: strings related.\ntransaction - `WATCH` / `MULTI` / `EXEC` related commands.\nwrite - Writing to keys (values or metadata).\n\nRedis can also show you a list of all categories and the exact commands each category includes using the Redis `ACL CAT` command. It can be used in two forms:\n\n\n```ACL CAT -- Will just list all the categories available\nACL CAT <category-name> -- Will list all the commands inside the category\n```\n\n\nExamples:\n\n\n``` > ACL CAT\n 1) \"keyspace\"\n 2) \"read\"\n 3) \"write\"\n 4) \"set\"\n 5) \"sortedset\"\n 6) \"list\"\n 7) \"hash\"\n 8) \"string\"\n 9) \"bitmap\"\n10) \"hyperloglog\"\n11) \"geo\"\n12) \"stream\"\n13) \"pubsub\"\n14) \"admin\"\n15) \"fast\"\n16) \"slow\"\n17) \"blocking\"\n18) \"dangerous\"\n19) \"connection\"\n20) \"transaction\"\n21) \"scripting\"\n```\n\n\nAs you can see, so far there are 21 distinct categories. Now let's check what\ncommand is part of the geo category:\n\n\n``` > ACL CAT geo\n 1) \"geohash\"\n 2) \"georadius_ro\"\n 3) \"georadiusbymember\"\n 4) \"geopos\"\n 5) \"geoadd\"\n 6) \"georadiusbymember_ro\"\n 7) \"geodist\"\n 8) \"georadius\"\n 9) \"geosearch\"\n10) \"geosearchstore\"\n```\n\n\nNote that commands may be part of multiple categories. For example, an\nACL rule like `+@geo -@read` will result in certain geo commands to be\nexcluded because they are read-only commands.\nAllow/block subcommands\nStarting from Redis 7.0, subcommands can be allowed/blocked just like other\ncommands (by using the separator `|` between the command and subcommand, for\nexample: `+config|get` or `-config|set`)\nThat is true for all commands except DEBUG. In order to allow/block specific\nDEBUG subcommands, see the next section.\nAllow the first-arg of a blocked command\nNote: This feature is deprecated since Redis 7.0 and may be removed in the future.\nSometimes the ability to exclude or include a command or a subcommand as a whole is not enough.\nMany deployments may not be happy providing the ability to execute a `SELECT` for any DB, but may\nstill want to be able to run `SELECT 0`.\nIn such case we could alter the ACL of a user in the following way:\n\n\n```ACL SETUSER myuser -select +select|0\n```\n\n\nFirst, remove the `SELECT` command and then add the allowed\nfirst-arg. Note that it is not possible to do the reverse since first-args\ncan be only added, not excluded. It is safer to specify all the first-args\nthat are valid for some user since it is possible that\nnew first-args may be added in the future.\nAnother example:\n\n\n```ACL SETUSER myuser -debug +debug|digest\n```\n\n\nNote that first-arg matching may add some performance penalty; however, it is hard to measure even with synthetic benchmarks. The\nadditional CPU cost is only paid when such commands are called, and not when\nother commands are called.\nIt is possible to use this mechanism in order to allow subcommands in Redis\nversions prior to 7.0 (see above section).\n+@all VS -@all\nIn the previous section, it was observed how it is possible to define command\nACLs based on adding/removing single commands.\nSelectors\nStarting with Redis 7.0, Redis supports adding multiple sets of rules that are evaluated independently of each other.\nThese secondary sets of permissions are called selectors and added by wrapping a set of rules within parentheses.\nIn order to execute a command, either the root permissions (rules defined outside of parenthesis) or any of the selectors (rules defined inside parenthesis) must match the given command.\nInternally, the root permissions are checked first followed by selectors in the order they were added.\nFor example, consider a user with the ACL rules `+GET ~key1 (+SET ~key2)`.\nThis user is able to execute `GET key1` and `SET key2 hello`, but not `GET key2` or `SET key1 world`.\nUnlike the user's root permissions, selectors cannot be modified after they are added.\nInstead, selectors can be removed with the `clearselectors` keyword, which removes all of the added selectors.\nNote that `clearselectors` does not remove the root permissions.\nKey permissions\nStarting with Redis 7.0, key patterns can also be used to define how a command is able to touch a key.\nThis is achieved through rules that define key permissions.\nThe key permission rules take the form of `%(<permission>)~<pattern>`.\nPermissions are defined as individual characters that map to the following key permissions:\n\nW (Write): The data stored within the key may be updated or deleted. \nR (Read): User supplied data from the key is processed, copied or returned. Note that this does not include metadata such as size information (example `STRLEN`), type information (example `TYPE`) or information about whether a value exists within a collection (example `SISMEMBER`). \n\nPermissions can be composed together by specifying multiple characters. \nSpecifying the permission as 'RW' is considered full access and is analogous to just passing in `~<pattern>`.\nFor a concrete example, consider a user with ACL rules `+@all ~app1:* (+@readonly ~app2:*)`.\nThis user has full access on `app1:*` and readonly access on `app2:*`.\nHowever, some commands support reading data from one key, doing some transformation, and storing it into another key.\nOne such command is the `COPY` command, which copies the data from the source key into the destination key.\nThe example set of ACL rules is unable to handle a request copying data from `app2:user` into `app1:user`, since neither the root permission nor the selector fully matches the command.\nHowever, using key selectors you can define a set of ACL rules that can handle this request `+@all ~app1:* %R~app2:*`.\nThe first pattern is able to match `app1:user` and the second pattern is able to match `app2:user`.\nWhich type of permission is required for a command is documented through key specifications.\nThe type of permission is based off the keys logical operation flags. \nThe insert, update, and delete flags map to the write key permission. \nThe access flag maps to the read key permission.\nIf the key has no logical operation flags, such as `EXISTS`, the user still needs either key read or key write permissions to execute the command. \nNote: Side channels to accessing user data are ignored when it comes to evaluating whether read permissions are required to execute a command.\nThis means that some write commands that return metadata about the modified key only require write permission on the key to execute.\nFor example, consider the following two commands:\n\n`LPUSH key1 data`: modifies \"key1\" but only returns metadata about it, the size of the list after the push, so the command only requires write permission on \"key1\" to execute.\n`LPOP key2`: modifies \"key2\" but also returns data from it, the left most item in the list, so the command requires both read and write permission on \"key2\" to execute.\n\nIf an application needs to make sure no data is accessed from a key, including side channels, it's recommended to not provide any access to the key.\nHow passwords are stored internally\nRedis internally stores passwords hashed with SHA256. If you set a password\nand check the output of `ACL LIST` or `ACL GETUSER`, you'll see a long hex\nstring that looks pseudo random. Here is an example, because in the previous\nexamples, for the sake of brevity, the long hex string was trimmed:\n\n\n```> ACL GETUSER default\n1) \"flags\"\n2) 1) \"on\"\n3) \"passwords\"\n4) 1) \"2d9c75273d72b32df726fb545c8a4edc719f0a95a6fd993950b10c474ad9c927\"\n5) \"commands\"\n6) \"+@all\"\n7) \"keys\"\n8) \"~*\"\n9) \"channels\"\n10) \"&*\"\n11) \"selectors\"\n12) (empty array)\n```\n\n\nUsing SHA256 provides the ability to avoid storing the password in clear text\nwhile still allowing for a very fast `AUTH` command, which is a very important\nfeature of Redis and is coherent with what clients expect from Redis.\nHowever ACL passwords are not really passwords. They are shared secrets\nbetween the server and the client, because the password is\nnot an authentication token used by a human being. For instance:\n\nThere are no length limits, the password will just be memorized in some client software. There is no human that needs to recall a password in this context.\nThe ACL password does not protect any other thing. For example, it will never be the password for some email account.\nOften when you are able to access the hashed password itself, by having full access to the Redis commands of a given server, or corrupting the system itself, you already have access to what the password is protecting: the Redis instance stability and the data it contains.\n\nFor this reason, slowing down the password authentication, in order to use an\nalgorithm that uses time and space to make password cracking hard,\nis a very poor choice. What we suggest instead is to generate strong\npasswords, so that nobody will be able to crack it using a\ndictionary or a brute force attack even if they have the hash. To do so, there is a special ACL\ncommand `ACL GENPASS` that generates passwords using the system cryptographic pseudorandom\ngenerator:\n\n\n```> ACL GENPASS\n\"dd721260bfe1b3d9601e7fbab36de6d04e2e67b0ef1c53de59d45950db0dd3cc\"\n```\n\n\nThe command outputs a 32-byte (256-bit) pseudorandom string converted to a\n64-byte alphanumerical string. This is long enough to avoid attacks and short\nenough to be easy to manage, cut & paste, store, and so forth. This is what\nyou should use in order to generate Redis passwords.\nUse an external ACL file\nThere are two ways to store users inside the Redis configuration:\n\nUsers can be specified directly inside the `redis.conf` file.\nIt is possible to specify an external ACL file.\n\nThe two methods are mutually incompatible, so Redis will ask you to use one\nor the other. Specifying users inside `redis.conf` is\ngood for simple use cases. When there are multiple users to define, in a\ncomplex environment, we recommend you use the ACL file instead.\nThe format used inside `redis.conf` and in the external ACL file is exactly\nthe same, so it is trivial to switch from one to the other, and is\nthe following:\n\n\n```user <username> ... acl rules ...\n```\n\n\nFor instance:\n\n\n```user worker +@list +@connection ~jobs:* on >ffa9203c493aa99\n```\n\n\nWhen you want to use an external ACL file, you are required to specify\nthe configuration directive called `aclfile`, like this:\n\n\n```aclfile /etc/redis/users.acl\n```\n\n\nWhen you are just specifying a few users directly inside the `redis.conf`\nfile, you can use `CONFIG REWRITE` in order to store the new user configuration\ninside the file by rewriting it.\nThe external ACL file however is more powerful. You can do the following:\n\nUse `ACL LOAD` if you modified the ACL file manually and you want Redis to reload the new configuration. Note that this command is able to load the file only if all the users are correctly specified. Otherwise, an error is reported to the user, and the old configuration will remain valid.\nUse `ACL SAVE` to save the current ACL configuration to the ACL file.\n\nNote that `CONFIG REWRITE` does not also trigger `ACL SAVE`. When you use\nan ACL file, the configuration and the ACLs are handled separately.\nACL rules for Sentinel and Replicas\nIn case you don't want to provide Redis replicas and Redis Sentinel instances\nfull access to your Redis instances, the following is the set of commands\nthat must be allowed in order for everything to work correctly.\nFor Sentinel, allow the user to access the following commands both in the master and replica instances:\n\nAUTH, CLIENT, SUBSCRIBE, SCRIPT, PUBLISH, PING, INFO, MULTI, SLAVEOF, CONFIG, CLIENT, EXEC.\n\nSentinel does not need to access any key in the database but does use Pub/Sub, so the ACL rule would be the following (note: `AUTH` is not needed since it is always allowed):\n\n\n```ACL SETUSER sentinel-user on >somepassword allchannels +multi +slaveof +ping +exec +subscribe +config|rewrite +role +publish +info +client|setname +client|kill +script|kill\n```\n\n\nRedis replicas require the following commands to be allowed on the master instance:\n\nPSYNC, REPLCONF, PING\n\nNo keys need to be accessed, so this translates to the following rules:\n\n\n```ACL setuser replica-user on >somepassword +psync +replconf +ping\n```\n\n",
    "tag": "redis"
  },
  {
    "title": "Getting Started",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/security/encryption.md",
    "content": "\ntitle: \"TLS\"\nlinkTitle: \"TLS\"\nweight: 1\ndescription: Redis TLS support\naliases: [\n    /topics/encryption,\n    /docs/manual/security/encryption,\n    /docs/manual/security/encryption.md\n]\n\nSSL/TLS is supported by Redis starting with version 6 as an optional feature\nthat needs to be enabled at compile time.\nGetting Started\nBuilding\nTo build with TLS support you'll need OpenSSL development libraries (e.g.\n`libssl-dev` on Debian/Ubuntu).\nBuild Redis with the following command:\n`sh\nmake BUILD_TLS=yes`\nTests\nTo run Redis test suite with TLS, you'll need TLS support for TCL (i.e.\n`tcl-tls` package on Debian/Ubuntu).\n\n\nRun `./utils/gen-test-certs.sh` to generate a root CA and a server\n   certificate.\n\n\nRun `./runtest --tls` or `./runtest-cluster --tls` to run Redis and Redis\n   Cluster tests in TLS mode.\n\n\nRunning manually\nTo manually run a Redis server with TLS mode (assuming `gen-test-certs.sh` was\ninvoked so sample certificates/keys are available):\n\n\n```./src/redis-server --tls-port 6379 --port 0 \\\n    --tls-cert-file ./tests/tls/redis.crt \\\n    --tls-key-file ./tests/tls/redis.key \\\n    --tls-ca-cert-file ./tests/tls/ca.crt\n```\n\n\nTo connect to this Redis server with `redis-cli`:\n\n\n```./src/redis-cli --tls \\\n    --cert ./tests/tls/redis.crt \\\n    --key ./tests/tls/redis.key \\\n    --cacert ./tests/tls/ca.crt\n```\n\n\nCertificate configuration\nIn order to support TLS, Redis must be configured with a X.509 certificate and a\nprivate key. In addition, it is necessary to specify a CA certificate bundle\nfile or path to be used as a trusted root when validating certificates. To\nsupport DH based ciphers, a DH params file can also be configured. For example:\n`tls-cert-file /path/to/redis.crt\ntls-key-file /path/to/redis.key\ntls-ca-cert-file /path/to/ca.crt\ntls-dh-params-file /path/to/redis.dh`\nTLS listening port\nThe `tls-port` configuration directive enables accepting SSL/TLS connections on\nthe specified port. This is in addition to listening on `port` for TCP\nconnections, so it is possible to access Redis on different ports using TLS and\nnon-TLS connections simultaneously.\nYou may specify `port 0` to disable the non-TLS port completely. To enable only\nTLS on the default Redis port, use:\n`port 0\ntls-port 6379`\nClient certificate authentication\nBy default, Redis uses mutual TLS and requires clients to authenticate with a\nvalid certificate (authenticated against trusted root CAs specified by\n`ca-cert-file` or `ca-cert-dir`).\nYou may use `tls-auth-clients no` to disable client authentication.\nReplication\nA Redis master server handles connecting clients and replica servers in the same\nway, so the above `tls-port` and `tls-auth-clients` directives apply to\nreplication links as well.\nOn the replica server side, it is necessary to specify `tls-replication yes` to\nuse TLS for outgoing connections to the master.\nCluster\nWhen Redis Cluster is used, use `tls-cluster yes` in order to enable TLS for the\ncluster bus and cross-node connections.\nSentinel\nSentinel inherits its networking configuration from the common Redis\nconfiguration, so all of the above applies to Sentinel as well.\nWhen connecting to master servers, Sentinel will use the `tls-replication`\ndirective to determine if a TLS or non-TLS connection is required.\nIn addition, the very same `tls-replication` directive will determine whether Sentinel's\nport, that accepts connections from other Sentinels, will support TLS as well. That is,\nSentinel will be configured with `tls-port` if and only if `tls-replication` is enabled. \nAdditional configuration\nAdditional TLS configuration is available to control the choice of TLS protocol\nversions, ciphers and cipher suites, etc. Please consult the self documented\n`redis.conf` for more information.\nPerformance considerations\nTLS adds a layer to the communication stack with overheads due to writing/reading to/from an SSL connection, encryption/decryption and integrity checks. Consequently, using TLS results in a decrease of the achievable throughput per Redis instance (for more information refer to this discussion). \nLimitations",
    "tag": "redis"
  },
  {
    "title": "Security model",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/security/_index.md",
    "content": "\ntitle: \"Redis security\"\nlinkTitle: \"Security\"\nweight: 1\ndescription: Security model and features in Redis\naliases: [\n    /topics/security,\n    /docs/manual/security,\n    /docs/manual/security.md\n]\n\nThis document provides an introduction to the topic of security from the point of\nview of Redis. It covers the access control provided by Redis, code security concerns,\nattacks that can be triggered from the outside by selecting malicious inputs, and\nother similar topics. \nYou can learn more about access control, data protection and encryption, secure Redis architectures, and secure deployment techniques by taking the Redis University security course.\nFor security-related contacts, open an issue on GitHub, or when you feel it\nis really important to preserve the security of the communication, use the\nGPG key at the end of this document.\nSecurity model\nRedis is designed to be accessed by trusted clients inside trusted environments.\nThis means that usually it is not a good idea to expose the Redis instance\ndirectly to the internet or, in general, to an environment where untrusted\nclients can directly access the Redis TCP port or UNIX socket.\nFor instance, in the common context of a web application implemented using Redis\nas a database, cache, or messaging system, the clients inside the front-end\n(web side) of the application will query Redis to generate pages or\nto perform operations requested or triggered by the web application user.\nIn this case, the web application mediates access between Redis and\nuntrusted clients (the user browsers accessing the web application).\nIn general, untrusted access to Redis should\nalways be mediated by a layer implementing ACLs, validating user input,\nand deciding what operations to perform against the Redis instance.\nNetwork security\nAccess to the Redis port should be denied to everybody but trusted clients\nin the network, so the servers running Redis should be directly accessible\nonly by the computers implementing the application using Redis.\nIn the common case of a single computer directly exposed to the internet, such\nas a virtualized Linux instance (Linode, EC2, ...), the Redis port should be\nfirewalled to prevent access from the outside. Clients will still be able to\naccess Redis using the loopback interface.\nNote that it is possible to bind Redis to a single interface by adding a line\nlike the following to the redis.conf file:\n\n\n```bind 127.0.0.1\n```\n\n\nFailing to protect the Redis port from the outside can have a big security\nimpact because of the nature of Redis. For instance, a single `FLUSHALL` command can be used by an external attacker to delete the whole data set.\nProtected mode\nUnfortunately, many users fail to protect Redis instances from being accessed\nfrom external networks. Many instances are simply left exposed on the\ninternet with public IPs. Since version 3.2.0, Redis enters a special mode called protected mode when it is\nexecuted with the default configuration (binding all the interfaces) and\nwithout any password in order to access it. In this mode, Redis only replies to queries from the\nloopback interfaces, and replies to clients connecting from other\naddresses with an error that explains the problem and how to configure\nRedis properly.\nWe expect protected mode to seriously decrease the security issues caused\nby unprotected Redis instances executed without proper administration. However,\nthe system administrator can still ignore the error given by Redis and\ndisable protected mode or manually bind all the interfaces.\nAuthentication\nRedis provides two ways to authenticate clients.\nThe recommended authentication method, introduced in Redis 6, is via Access Control Lists, allowing named users to be created and assigned fine-grained permissions.\nRead more about Access Control Lists here.\nThe legacy authentication method is enabled by editing the redis.conf file, and providing a database password using the `requirepass` setting.\nThis password is then used by all clients.\nWhen the `requirepass` setting is enabled, Redis will refuse any query by\nunauthenticated clients. A client can authenticate itself by sending the\nAUTH command followed by the password.\nThe password is set by the system administrator in clear text inside the\nredis.conf file. It should be long enough to prevent brute force attacks\nfor two reasons:\n\nRedis is very fast at serving queries. Many passwords per second can be tested by an external client.\nThe Redis password is stored in the redis.conf file and inside the client configuration. Since the system administrator does not need to remember it, the password can be very long.\n\nThe goal of the authentication layer is to optionally provide a layer of\nredundancy. If firewalling or any other system implemented to protect Redis\nfrom external attackers fail, an external client will still not be able to\naccess the Redis instance without knowledge of the authentication password.\nSince the `AUTH` command, like every other Redis command, is sent unencrypted, it\ndoes not protect against an attacker that has enough access to the network to\nperform eavesdropping.\nTLS support\nRedis has optional support for TLS on all communication channels, including\nclient connections, replication links, and the Redis Cluster bus protocol.\nDisallowing specific commands\nIt is possible to disallow commands in Redis or to rename them as an unguessable\nname, so that normal clients are limited to a specified set of commands.\nFor instance, a virtualized server provider may offer a managed Redis instance\nservice. In this context, normal users should probably not be able to\ncall the Redis CONFIG command to alter the configuration of the instance,\nbut the systems that provide and remove instances should be able to do so.\nIn this case, it is possible to either rename or completely shadow commands from\nthe command table. This feature is available as a statement that can be used\ninside the redis.conf configuration file. For example:\n\n\n```rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52\n```\n\n\nIn the above example, the CONFIG command was renamed into an unguessable name.  It is also possible to completely disallow it (or any other command) by renaming it to the empty string, like in the following example:\n\n\n```rename-command CONFIG \"\"\n```\n\n\nAttacks triggered by malicious inputs from external clients\nThere is a class of attacks that an attacker can trigger from the outside even\nwithout external access to the instance. For example, an attacker might insert data into Redis that triggers pathological (worst case)\nalgorithm complexity on data structures implemented inside Redis internals.\nAn attacker could supply, via a web form, a set of strings that\nare known to hash to the same bucket in a hash table in order to turn the\nO(1) expected time (the average time) to the O(N) worst case. This can consume more\nCPU than expected and ultimately cause a Denial of Service.\nTo prevent this specific attack, Redis uses a per-execution, pseudo-random\nseed to the hash function.\nRedis implements the SORT command using the qsort algorithm. Currently,\nthe algorithm is not randomized, so it is possible to trigger a quadratic\nworst-case behavior by carefully selecting the right set of inputs.\nString escaping and NoSQL injection\nThe Redis protocol has no concept of string escaping, so injection\nis impossible under normal circumstances using a normal client library.\nThe protocol uses prefixed-length strings and is completely binary safe.\nSince Lua scripts executed by the `EVAL` and `EVALSHA` commands follow the\nsame rules, those commands are also safe.\nWhile it would be a strange use case, the application should avoid composing the body of the Lua script from strings obtained from untrusted sources.\nCode security\nIn a classical Redis setup, clients are allowed full access to the command set,\nbut accessing the instance should never result in the ability to control the\nsystem where Redis is running.\nInternally, Redis uses all the well-known practices for writing secure code to\nprevent buffer overflows, format bugs, and other memory corruption issues.\nHowever, the ability to control the server configuration using the CONFIG\ncommand allows the client to change the working directory of the program and\nthe name of the dump file. This allows clients to write RDB Redis files\nto random paths. This is a security issue that may lead to the ability to compromise the system and/or run untrusted code as the same user as Redis is running.\nRedis does not require root privileges to run. It is recommended to\nrun it as an unprivileged redis user that is only used for this purpose.\nGPG key\n```\n-----BEGIN PGP PUBLIC KEY BLOCK-----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\nU9XKndQE028dGZv1E3S5BwpnikrUkWdxcYrVZ4fiNIy5I3My2yCe\n=J9BD\n-----END PGP PUBLIC KEY BLOCK-----",
    "tag": "redis"
  },
  {
    "title": "Filling the performance checklist",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/optimization/cpu-profiling.md",
    "content": "\ntitle: \"Redis CPU profiling\"\nlinkTitle: \"CPU profiling\"\nweight: 1\ndescription: >\n    Performance engineering guide for on-CPU profiling and tracing\naliases: [\n    /topics/performance-on-cpu,\n    /docs/reference/optimization/cpu-profiling\n]\n\nFilling the performance checklist\nRedis is developed with a great emphasis on performance. We do our best with\nevery release to make sure you'll experience a very stable and fast product. \nNevertheless, if you're finding room to improve the efficiency of Redis or\nare pursuing a performance regression investigation you will need a concise\nmethodical way of monitoring and analyzing Redis performance. \nTo do so you can rely on different methodologies (some more suited than other \ndepending on the class of issues/analysis we intent to make). A curated list\nof methodologies and their steps are enumerated by Brendan Greg at the\nfollowing link. \nWe recommend the Utilization Saturation and Errors (USE) Method for answering\nthe question of what is your bottleneck. Check the following mapping between\nsystem resource, metric, and tools for a pratical deep dive:\nUSE method. \nEnsuring the CPU is your bottleneck\nThis guide assumes you've followed one of the above methodologies to perform a \ncomplete check of system health, and identified the bottleneck being the CPU. \nIf you have identified that most of the time is spent blocked on I/O, locks,\ntimers, paging/swapping, etc., this guide is not for you. \nBuild Prerequisites\nFor a proper On-CPU analysis, Redis (and any dynamically loaded library like\nRedis Modules) requires stack traces to be available to tracers, which you may\nneed to fix first. \nBy default, Redis is compiled with the `-O2` switch (which we intent to keep\nduring profiling). This means that compiler optimizations are enabled. Many\ncompilers omit the frame pointer as a runtime optimization (saving a register),\nthus breaking frame pointer-based stack walking. This makes the Redis\nexecutable faster, but at the same time it makes Redis (like any other program)\nharder to trace, potentially wrongfully pinpointing on-CPU time to the last\navailable frame pointer of a call stack that can get a lot deeper (but\nimpossible to trace).\nIt's important that you ensure that:\n- debug information is present: compile option `-g`\n- frame pointer register is present: `-fno-omit-frame-pointer`\n- we still run with optimizations to get an accurate representation of production run times, meaning we will keep: `-O2`\nYou can do it as follows within redis main repo:\n\n\n```$ make REDIS_CFLAGS=\"-g -fno-omit-frame-pointer\"\n```\n\n\nA set of instruments to identify performance regressions and/or potential on-CPU performance improvements\nThis document focuses specifically on on-CPU resource bottlenecks analysis,\nmeaning we're interested in understanding where threads are spending CPU cycles\nwhile running on-CPU and, as importantly, whether those cycles are effectively\nbeing used for computation or stalled waiting (not blocked!) for memory I/O,\nand cache misses, etc.\nFor that we will rely on toolkits (perf, bcc tools), and hardware specific PMCs\n(Performance Monitoring Counters), to proceed with:\n\n\nHotspot analysis (pref or bcc tools): to profile code execution and determine which functions are consuming the most time and thus are targets for optimization. We'll present two options to collect, report, and visualize hotspots either with perf or bcc/BPF tracing tools.\n\n\nCall counts analysis: to count events including function calls, enabling us to correlate several calls/components at once, relying on bcc/BPF tracing tools.\n\n\nHardware event sampling: crucial for understanding CPU behavior, including memory I/O, stall cycles, and cache misses.\n\n\nTool prerequesits\nThe following steps rely on Linux perf_events (aka \"perf\"), bcc/BPF tracing tools, and Brendan Greg\u2019s FlameGraph repo.\nWe assume beforehand you have:\n\nInstalled the perf tool on your system. Most Linux distributions will likely package this as a package related to the kernel. More information about the perf tool can be found at perf wiki.\nFollowed the install bcc/BPF instructions to install bcc toolkit on your machine.\nCloned Brendan Greg\u2019s FlameGraph repo and made accessible the `difffolded.pl` and `flamegraph.pl` files, to generated the collapsed stack traces and Flame Graphs.\n\nHotspot analysis with perf or eBPF (stack traces sampling)\nProfiling CPU usage by sampling stack traces at a timed interval is a fast and\neasy way to identify performance-critical code sections (hotspots).\nSampling stack traces using perf\nTo profile both user- and kernel-level stacks of redis-server for a specific\nlength of time, for example 60 seconds, at a sampling frequency of 999 samples\nper second:\n\n\n```$ perf record -g --pid $(pgrep redis-server) -F 999 -- sleep 60\n```\n\n\nDisplaying the recorded profile information using perf report\nBy default perf record will generate a perf.data file in the current working\ndirectory. \nYou can then report with a call-graph output (call chain, stack backtrace),\nwith a minimum call graph inclusion threshold of 0.5%, with:\n\n\n```$ perf report -g \"graph,0.5,caller\"\n```\n\n\nSee the perf report\ndocumentation for advanced filtering, sorting and aggregation capabilities.\nVisualizing the recorded profile information using Flame Graphs\nFlame graphs allow for a quick\nand accurate visualization of frequent code-paths. They can be generated using\nBrendan Greg's open source programs on github,\nwhich create interactive SVGs from folded stack files.\nSpecifically, for perf we need to convert the generated perf.data into the\ncaptured stacks, and fold each of them into single lines. You can then render\nthe on-CPU flame graph with:\n\n\n```$ perf script > redis.perf.stacks\n$ stackcollapse-perf.pl redis.perf.stacks > redis.folded.stacks\n$ flamegraph.pl redis.folded.stacks > redis.svg\n```\n\n\nBy default, perf script will generate a perf.data file in the current working\ndirectory. See the perf script\ndocumentation for advanced usage.\nSee FlameGraph usage options\nfor more advanced stack trace visualizations (like the differential one).\nArchiving and sharing recorded profile information\nSo that analysis of the perf.data contents can be possible on a machine other\nthan the one on which collection happened, you need to export along with the\nperf.data file all object files with build-ids found in the record data file.\nThis can be easily done with the help of \nperf-archive.sh\nscript:\n\n\n```$ perf-archive.sh perf.data\n```\n\n\nNow please run:\n\n\n```$ tar xvf perf.data.tar.bz2 -C ~/.debug\n```\n\n\non the machine where you need to run `perf report`.\nSampling stack traces using bcc/BPF's profile\nSimilarly to perf, as of Linux kernel 4.9, BPF-optimized profiling is now fully\navailable with the promise of lower overhead on CPU (as stack traces are\nfrequency counted in kernel context) and disk I/O resources during profiling. \nApart from that, and relying solely on bcc/BPF's profile tool, we have also\nremoved the perf.data and intermediate steps if stack traces analysis is our\nmain goal. You can use bcc's profile tool to output folded format directly, for\nflame graph generation:\n\n\n```$ /usr/share/bcc/tools/profile -F 999 -f --pid $(pgrep redis-server) --duration 60 > redis.folded.stacks\n```\n\n\nIn that manner, we've remove any preprocessing and can render the on-CPU flame\ngraph with a single command:\n\n\n```$ flamegraph.pl redis.folded.stacks > redis.svg\n```\n\n\nVisualizing the recorded profile information using Flame Graphs\nCall counts analysis with bcc/BPF\nA function may consume significant CPU cycles either because its code is slow\nor because it's frequently called. To answer at what rate functions are being\ncalled, you can rely upon call counts analysis using BCC's `funccount` tool:\n\n\n```$ /usr/share/bcc/tools/funccount 'redis-server:(call*|*Read*|*Write*)' --pid $(pgrep redis-server) --duration 60\nTracing 64 functions for \"redis-server:(call*|*Read*|*Write*)\"... Hit Ctrl-C to end.\n\nFUNC                                    COUNT\ncall                                      334\nhandleClientsWithPendingWrites            388\nclientInstallWriteHandler                 388\npostponeClientRead                        514\nhandleClientsWithPendingReadsUsingThreads      735\nhandleClientsWithPendingWritesUsingThreads      735\nprepareClientToWrite                     1442\nDetaching...\n```\n\n\nThe above output shows that, while tracing, the Redis's call() function was\ncalled 334 times, handleClientsWithPendingWrites() 388 times, etc.\nHardware event counting with Performance Monitoring Counters (PMCs)\nMany modern processors contain a performance monitoring unit (PMU) exposing\nPerformance Monitoring Counters (PMCs). PMCs are crucial for understanding CPU\nbehavior, including memory I/O, stall cycles, and cache misses, and provide\nlow-level CPU performance statistics that aren't available anywhere else.\nThe design and functionality of a PMU is CPU-specific and you should assess\nyour CPU supported counters and features by using `perf list`. \nTo calculate the number of instructions per cycle, the number of micro ops\nexecuted, the number of cycles during which no micro ops were dispatched, the\nnumber stalled cycles on memory, including a per memory type stalls, for the\nduration of 60s, specifically for redis process: \n\n\n```$ perf stat -e \"cpu-clock,cpu-cycles,instructions,uops_executed.core,uops_executed.stall_cycles,cache-references,cache-misses,cycle_activity.stalls_total,cycle_activity.stalls_mem_any,cycle_activity.stalls_l3_miss,cycle_activity.stalls_l2_miss,cycle_activity.stalls_l1d_miss\" --pid $(pgrep redis-server) -- sleep 60\n\nPerformance counter stats for process id '3038':\n\n  60046.411437      cpu-clock (msec)          #    1.001 CPUs utilized          \n  168991975443      cpu-cycles                #    2.814 GHz                      (36.40%)\n  388248178431      instructions              #    2.30  insn per cycle           (45.50%)\n  443134227322      uops_executed.core        # 7379.862 M/sec                    (45.51%)\n   30317116399      uops_executed.stall_cycles #  504.895 M/sec                    (45.51%)\n     670821512      cache-references          #   11.172 M/sec                    (45.52%)\n      23727619      cache-misses              #    3.537 % of all cache refs      (45.43%)\n   30278479141      cycle_activity.stalls_total #  504.251 M/sec                    (36.33%)\n   19981138777      cycle_activity.stalls_mem_any #  332.762 M/sec                    (36.33%)\n     725708324      cycle_activity.stalls_l3_miss #   12.086 M/sec                    (36.33%)\n    8487905659      cycle_activity.stalls_l2_miss #  141.356 M/sec                    (36.32%)\n   10011909368      cycle_activity.stalls_l1d_miss #  166.736 M/sec                    (36.31%)\n\n  60.002765665 seconds time elapsed\n```\n\n\nIt's important to know that there are two very different ways in which PMCs can\nbe used (counting and sampling), and we've focused solely on PMCs counting for\nthe sake of this analysis. Brendan Greg clearly explains it on the following\nlink.",
    "tag": "redis"
  },
  {
    "title": "Events and time series",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/optimization/latency-monitor.md",
    "content": "\ntitle: \"Redis latency monitoring\"\nlinkTitle: \"Latency monitoring\"\nweight: 1\ndescription: Discovering slow server events in Redis\naliases: [\n    /topics/latency-monitor,\n    /docs/reference/optimization/latency-monitor\n]\n\nRedis is often used for demanding use cases, where it\nserves a large number of queries per second per instance, but also has strict latency requirements for the average response\ntime and the worst-case latency.\nWhile Redis is an in-memory system, it deals with the operating system in\ndifferent ways, for example, in the context of persisting to disk.\nMoreover Redis implements a rich set of commands. Certain commands\nare fast and run in constant or logarithmic time. Other commands are slower\nO(N) commands that can cause latency spikes.\nFinally, Redis is single threaded. This is usually an advantage\nfrom the point of view of the amount of work it can perform per core, and in\nthe latency figures it is able to provide. However, it poses\na challenge for latency, since the single\nthread must be able to perform certain tasks incrementally, for\nexample key expiration, in a way that does not impact the other clients\nthat are served.\nFor all these reasons, Redis 2.8.13 introduced a new feature called\nLatency Monitoring, that helps the user to check and troubleshoot possible\nlatency problems. Latency monitoring is composed of the following conceptual\nparts:\n\nLatency hooks that sample different latency-sensitive code paths.\nTime series recording of latency spikes, split by different events.\nReporting engine to fetch raw data from the time series.\nAnalysis engine to provide human-readable reports and hints according to the measurements.\n\nThe rest of this document covers the latency monitoring subsystem\ndetails. For more information about the general topic of Redis\nand latency, see Redis latency problems troubleshooting.\nEvents and time series\nDifferent monitored code paths have different names and are called events.\nFor example, `command` is an event that measures latency spikes of possibly slow\ncommand executions, while `fast-command` is the event name for the monitoring\nof the O(1) and O(log N) commands. Other events are less generic and monitor\nspecific operations performed by Redis. For example, the `fork` event\nonly monitors the time taken by Redis to execute the `fork(2)` system call.\nA latency spike is an event that takes more time to run than the configured latency\nthreshold. There is a separate time series associated with every monitored\nevent. This is how the time series work:\n\nEvery time a latency spike happens, it is logged in the appropriate time series.\nEvery time series is composed of 160 elements.\nEach element is a pair made of a Unix timestamp of the time the latency spike was measured and the number of milliseconds the event took to execute.\nLatency spikes for the same event that occur in the same second are merged by taking the maximum latency. Even if continuous latency spikes are measured for a given event, which could happen with a low threshold, at least 160 seconds of history are available.\nRecords the all-time maximum latency for every element.\n\nThe framework monitors and logs latency spikes in the execution time of these events:\n\n`command`: regular commands.\n`fast-command`: O(1) and O(log N) commands.\n`fork`: the `fork(2)` system call.\n`rdb-unlink-temp-file`: the `unlink(2)` system call.\n`aof-fsync-always`: the `fsync(2)` system call when invoked by the `appendfsync allways` policy.\n`aof-write`: writing to the AOF - a catchall event for `write(2)` system calls.\n`aof-write-pending-fsync`: the `write(2)` system call when there is a pending fsync.\n`aof-write-active-child`: the `write(2)` system call when there are active child processes.\n`aof-write-alone`: the `write(2)` system call when no pending fsync and no active child process.\n`aof-fstat`: the `fstat(2)` system call.\n`aof-rename`: the `rename(2)` system call for renaming the temporary file after completing `BGREWRITEAOF`.\n`aof-rewrite-diff-write`: writing the differences accumulated while performing `BGREWRITEAOF`.\n`active-defrag-cycle`: the active defragmentation cycle.\n`expire-cycle`: the expiration cycle.\n`eviction-cycle`: the eviction cycle.\n`eviction-del`: deletes during the eviction cycle.\n\nHow to enable latency monitoring\nWhat is high latency for one use case may not be considered high latency for another. Some applications may require that all queries be served in less than 1 millisecond. For other applications, it may be acceptable for a small amount of clients to experience a 2 second latency on occasion.\nThe first step to enable the latency monitor is to set a latency threshold in milliseconds. Only events that take longer than the specified threshold will be logged as latency spikes. The user should set the threshold according to their needs. For example, if the application requires a maximum acceptable latency of 100 milliseconds, the threshold should be set to log all the events blocking the server for a time equal or greater to 100 milliseconds.\nEnable the latency monitor at runtime in a production server\nwith the following command:\n\n\n```CONFIG SET latency-monitor-threshold 100\n```\n\n\nMonitoring is turned off by default (threshold set to 0), even if the actual cost of latency monitoring is near zero. While the memory requirements of latency monitoring are very small, there is no good reason to raise the baseline memory usage of a Redis instance that is working well.\nReport information with the LATENCY command\nThe user interface to the latency monitoring subsystem is the `LATENCY` command.\nLike many other Redis commands, `LATENCY` accepts subcommands that modify its behavior. These subcommands are:\n\n`LATENCY LATEST` - returns the latest latency samples for all events.\n`LATENCY HISTORY` - returns latency time series for a given event.\n`LATENCY RESET` - resets latency time series data for one or more events.\n`LATENCY GRAPH` - renders an ASCII-art graph of an event's latency samples.\n`LATENCY DOCTOR` - replies with a human-readable latency analysis report.\n",
    "tag": "redis"
  },
  {
    "title": "latency.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/optimization/latency.md",
    "content": "\ntitle: \"Diagnosing latency issues\"\nlinkTitle: \"Latency diagnosis\"\nweight: 1\ndescription: Finding the causes of slow responses\naliases: [\n    /topics/latency,\n    /docs/reference/optimization/latency\n]\n\nThis document will help you understand what the problem could be if you\nare experiencing latency problems with Redis.\nIn this context latency is the maximum delay between the time a client\nissues a command and the time the reply to the command is received by the\nclient. Usually Redis processing time is extremely low, in the sub microsecond\nrange, but there are certain conditions leading to higher latency figures.\nI've little time, give me the checklist\nThe following documentation is very important in order to run Redis in\na low latency fashion. However I understand that we are busy people, so\nlet's start with a quick checklist. If you fail following these steps, please\nreturn here to read the full documentation.\n\nMake sure you are not running slow commands that are blocking the server. Use the Redis Slow Log feature to check this.\nFor EC2 users, make sure you use HVM based modern EC2 instances, like m3.medium. Otherwise fork() is too slow.\nTransparent huge pages must be disabled from your kernel. Use `echo never > /sys/kernel/mm/transparent_hugepage/enabled` to disable them, and restart your Redis process.\nIf you are using a virtual machine, it is possible that you have an intrinsic latency that has nothing to do with Redis. Check the minimum latency you can expect from your runtime environment using `./redis-cli --intrinsic-latency 100`. Note: you need to run this command in the server not in the client.\nEnable and use the Latency monitor feature of Redis in order to get a human readable description of the latency events and causes in your Redis instance.\n\nIn general, use the following table for durability VS latency/performance tradeoffs, ordered from stronger safety to better latency.\n\nAOF + fsync always: this is very slow, you should use it only if you know what you are doing.\nAOF + fsync every second: this is a good compromise.\nAOF + fsync every second + no-appendfsync-on-rewrite option set to yes: this is as the above, but avoids to fsync during rewrites to lower the disk pressure.\nAOF + fsync never. Fsyncing is up to the kernel in this setup, even less disk pressure and risk of latency spikes.\nRDB. Here you have a vast spectrum of tradeoffs depending on the save triggers you configure.\n\nAnd now for people with 15 minutes to spend, the details...\nMeasuring latency\nIf you are experiencing latency problems, you probably know how to measure\nit in the context of your application, or maybe your latency problem is very\nevident even macroscopically. However redis-cli can be used to measure the\nlatency of a Redis server in milliseconds, just try:\n\n\n```redis-cli --latency -h `host` -p `port`\n```\n\n\nUsing the internal Redis latency monitoring subsystem\nSince Redis 2.8.13, Redis provides latency monitoring capabilities that\nare able to sample different execution paths to understand where the\nserver is blocking. This makes debugging of the problems illustrated in\nthis documentation much simpler, so we suggest enabling latency monitoring\nASAP. Please refer to the Latency monitor documentation.\nWhile the latency monitoring sampling and reporting capabilities will make\nit simpler to understand the source of latency in your Redis system, it is still\nadvised that you read this documentation extensively to better understand\nthe topic of Redis and latency spikes.\nLatency baseline\nThere is a kind of latency that is inherently part of the environment where\nyou run Redis, that is the latency provided by your operating system kernel\nand, if you are using virtualization, by the hypervisor you are using.\nWhile this latency can't be removed it is important to study it because\nit is the baseline, or in other words, you won't be able to achieve a Redis\nlatency that is better than the latency that every process running in your\nenvironment will experience because of the kernel or hypervisor implementation\nor setup.\nWe call this kind of latency intrinsic latency, and `redis-cli` starting\nfrom Redis version 2.8.7 is able to measure it. This is an example run\nunder Linux 3.11.0 running on an entry level server.\nNote: the argument `100` is the number of seconds the test will be executed.\nThe more time we run the test, the more likely we'll be able to spot\nlatency spikes. 100 seconds is usually appropriate, however you may want\nto perform a few runs at different times. Please note that the test is CPU\nintensive and will likely saturate a single core in your system.\n\n\n```$ ./redis-cli --intrinsic-latency 100\nMax latency so far: 1 microseconds.\nMax latency so far: 16 microseconds.\nMax latency so far: 50 microseconds.\nMax latency so far: 53 microseconds.\nMax latency so far: 83 microseconds.\nMax latency so far: 115 microseconds.\n```\n\n\nNote: redis-cli in this special case needs to run in the server where you run or plan to run Redis, not in the client. In this special mode redis-cli does not connect to a Redis server at all: it will just try to measure the largest time the kernel does not provide CPU time to run to the redis-cli process itself.\nIn the above example, the intrinsic latency of the system is just 0.115\nmilliseconds (or 115 microseconds), which is a good news, however keep in mind\nthat the intrinsic latency may change over time depending on the load of the\nsystem.\nVirtualized environments will not show so good numbers, especially with high\nload or if there are noisy neighbors. The following is a run on a Linode 4096\ninstance running Redis and Apache:\n\n\n```$ ./redis-cli --intrinsic-latency 100\nMax latency so far: 573 microseconds.\nMax latency so far: 695 microseconds.\nMax latency so far: 919 microseconds.\nMax latency so far: 1606 microseconds.\nMax latency so far: 3191 microseconds.\nMax latency so far: 9243 microseconds.\nMax latency so far: 9671 microseconds.\n```\n\n\nHere we have an intrinsic latency of 9.7 milliseconds: this means that we can't ask better than that to Redis. However other runs at different times in different virtualization environments with higher load or with noisy neighbors can easily show even worse values. We were able to measure up to 40 milliseconds in\nsystems otherwise apparently running normally.\nLatency induced by network and communication\nClients connect to Redis using a TCP/IP connection or a Unix domain connection.\nThe typical latency of a 1 Gbit/s network is about 200 us, while the latency\nwith a Unix domain socket can be as low as 30 us. It actually depends on your\nnetwork and system hardware. On top of the communication itself, the system\nadds some more latency (due to thread scheduling, CPU caches, NUMA placement,\netc ...). System induced latencies are significantly higher on a virtualized\nenvironment than on a physical machine.\nThe consequence is even if Redis processes most commands in sub microsecond\nrange, a client performing many roundtrips to the server will have to pay\nfor these network and system related latencies.\nAn efficient client will therefore try to limit the number of roundtrips by\npipelining several commands together. This is fully supported by the servers\nand most clients. Aggregated commands like MSET/MGET can be also used for\nthat purpose. Starting with Redis 2.4, a number of commands also support\nvariadic parameters for all data types.\nHere are some guidelines:\n\nIf you can afford it, prefer a physical machine over a VM to host the server.\nDo not systematically connect/disconnect to the server (especially true\n  for web based applications). Keep your connections as long lived as possible.\nIf your client is on the same host than the server, use Unix domain sockets.\nPrefer to use aggregated commands (MSET/MGET), or commands with variadic\n  parameters (if possible) over pipelining.\nPrefer to use pipelining (if possible) over sequence of roundtrips.\nRedis supports Lua server-side scripting to cover cases that are not suitable\n  for raw pipelining (for instance when the result of a command is an input for\n  the following commands).\n\nOn Linux, some people can achieve better latencies by playing with process\nplacement (taskset), cgroups, real-time priorities (chrt), NUMA\nconfiguration (numactl), or by using a low-latency kernel. Please note\nvanilla Redis is not really suitable to be bound on a single CPU core.\nRedis can fork background tasks that can be extremely CPU consuming\nlike `BGSAVE` or `BGREWRITEAOF`. These tasks must never run on the same core\nas the main event loop.\nIn most situations, these kind of system level optimizations are not needed.\nOnly do them if you require them, and if you are familiar with them.\nSingle threaded nature of Redis\nRedis uses a mostly single threaded design. This means that a single process\nserves all the client requests, using a technique called multiplexing.\nThis means that Redis can serve a single request in every given moment, so\nall the requests are served sequentially. This is very similar to how Node.js\nworks as well. However, both products are not often perceived as being slow.\nThis is caused in part by the small amount of time to complete a single request,\nbut primarily because these products are designed to not block on system calls,\nsuch as reading data from or writing data to a socket.\nI said that Redis is mostly single threaded since actually from Redis 2.4\nwe use threads in Redis in order to perform some slow I/O operations in the\nbackground, mainly related to disk I/O, but this does not change the fact\nthat Redis serves all the requests using a single thread.\nLatency generated by slow commands\nA consequence of being single thread is that when a request is slow to serve\nall the other clients will wait for this request to be served. When executing\nnormal commands, like `GET` or `SET` or `LPUSH` this is not a problem\nat all since these commands are executed in constant (and very small) time.\nHowever there are commands operating on many elements, like `SORT`, `LREM`,\n`SUNION` and others. For instance taking the intersection of two big sets\ncan take a considerable amount of time.\nThe algorithmic complexity of all commands is documented. A good practice\nis to systematically check it when using commands you are not familiar with.\nIf you have latency concerns you should either not use slow commands against\nvalues composed of many elements, or you should run a replica using Redis\nreplication where you run all your slow queries.\nIt is possible to monitor slow commands using the Redis\nSlow Log feature.\nAdditionally, you can use your favorite per-process monitoring program\n(top, htop, prstat, etc ...) to quickly check the CPU consumption of the\nmain Redis process. If it is high while the traffic is not, it is usually\na sign that slow commands are used.\nIMPORTANT NOTE: a VERY common source of latency generated by the execution\nof slow commands is the use of the `KEYS` command in production environments.\n`KEYS`, as documented in the Redis documentation, should only be used for\ndebugging purposes. Since Redis 2.8 a new commands were introduced in order to\niterate the key space and other large collections incrementally, please check\nthe `SCAN`, `SSCAN`, `HSCAN` and `ZSCAN` commands for more information.\nLatency generated by fork\nIn order to generate the RDB file in background, or to rewrite the Append Only File if AOF persistence is enabled, Redis has to fork background processes.\nThe fork operation (running in the main thread) can induce latency by itself.\nForking is an expensive operation on most Unix-like systems, since it involves\ncopying a good number of objects linked to the process. This is especially\ntrue for the page table associated to the virtual memory mechanism.\nFor instance on a Linux/AMD64 system, the memory is divided in 4 kB pages.\nTo convert virtual addresses to physical addresses, each process stores\na page table (actually represented as a tree) containing at least a pointer\nper page of the address space of the process. So a large 24 GB Redis instance\nrequires a page table of 24 GB / 4 kB * 8 = 48 MB.\nWhen a background save is performed, this instance will have to be forked,\nwhich will involve allocating and copying 48 MB of memory. It takes time\nand CPU, especially on virtual machines where allocation and initialization\nof a large memory chunk can be expensive.\nFork time in different systems\nModern hardware is pretty fast at copying the page table, but Xen is not.\nThe problem with Xen is not virtualization-specific, but Xen-specific. For instance using VMware or Virtual Box does not result into slow fork time.\nThe following is a table that compares fork time for different Redis instance\nsize. Data is obtained performing a BGSAVE and looking at the `latest_fork_usec` filed in the `INFO` command output.\nHowever the good news is that new types of EC2 HVM based instances are much\nbetter with fork times, almost on par with physical servers, so for example\nusing m3.medium (or better) instances will provide good results.\n\nLinux beefy VM on VMware 6.0GB RSS forked in 77 milliseconds (12.8 milliseconds per GB).\nLinux running on physical machine (Unknown HW) 6.1GB RSS forked in 80 milliseconds (13.1 milliseconds per GB)\nLinux running on physical machine (Xeon @ 2.27Ghz) 6.9GB RSS forked into 62 milliseconds (9 milliseconds per GB).\nLinux VM on 6sync (KVM) 360 MB RSS forked in 8.2 milliseconds (23.3 milliseconds per GB).\nLinux VM on EC2, old instance types (Xen) 6.1GB RSS forked in 1460 milliseconds (239.3 milliseconds per GB).\nLinux VM on EC2, new instance types (Xen) 1GB RSS forked in 10 milliseconds (10 milliseconds per GB).\nLinux VM on Linode (Xen) 0.9GBRSS forked into 382 milliseconds (424 milliseconds per GB).\n\nAs you can see certain VMs running on Xen have a performance hit that is between one order to two orders of magnitude. For EC2 users the suggestion is simple: use modern HVM based instances.\nLatency induced by transparent huge pages\nUnfortunately when a Linux kernel has transparent huge pages enabled, Redis\nincurs to a big latency penalty after the `fork` call is used in order to\npersist on disk. Huge pages are the cause of the following issue:\n\nFork is called, two processes with shared huge pages are created.\nIn a busy instance, a few event loops runs will cause commands to target a few thousand of pages, causing the copy on write of almost the whole process memory.\nThis will result in big latency and big memory usage.\n\nMake sure to disable transparent huge pages using the following command:\n\n\n```echo never > /sys/kernel/mm/transparent_hugepage/enabled\n```\n\n\nLatency induced by swapping (operating system paging)\nLinux (and many other modern operating systems) is able to relocate memory\npages from the memory to the disk, and vice versa, in order to use the\nsystem memory efficiently.\nIf a Redis page is moved by the kernel from the memory to the swap file, when\nthe data stored in this memory page is used by Redis (for example accessing\na key stored into this memory page) the kernel will stop the Redis process\nin order to move the page back into the main memory. This is a slow operation\ninvolving random I/Os (compared to accessing a page that is already in memory)\nand will result into anomalous latency experienced by Redis clients.\nThe kernel relocates Redis memory pages on disk mainly because of three reasons:\n\nThe system is under memory pressure since the running processes are demanding\nmore physical memory than the amount that is available. The simplest instance of\nthis problem is simply Redis using more memory than is available.\nThe Redis instance data set, or part of the data set, is mostly completely idle\n(never accessed by clients), so the kernel could swap idle memory pages on disk.\nThis problem is very rare since even a moderately slow instance will touch all\nthe memory pages often, forcing the kernel to retain all the pages in memory.\nSome processes are generating massive read or write I/Os on the system. Because\nfiles are generally cached, it tends to put pressure on the kernel to increase\nthe filesystem cache, and therefore generate swapping activity. Please note it\nincludes Redis RDB and/or AOF background threads which can produce large files.\n\nFortunately Linux offers good tools to investigate the problem, so the simplest\nthing to do is when latency due to swapping is suspected is just to check if\nthis is the case.\nThe first thing to do is to checking the amount of Redis memory that is swapped\non disk. In order to do so you need to obtain the Redis instance pid:\n\n\n```$ redis-cli info | grep process_id\nprocess_id:5454\n```\n\n\nNow enter the /proc file system directory for this process:\n\n\n```$ cd /proc/5454\n```\n\n\nHere you'll find a file called smaps that describes the memory layout of\nthe Redis process (assuming you are using Linux 2.6.16 or newer).\nThis file contains very detailed information about our process memory maps,\nand one field called Swap is exactly what we are looking for. However\nthere is not just a single swap field since the smaps file contains the\ndifferent memory maps of our Redis process (The memory layout of a process\nis more complex than a simple linear array of pages).\nSince we are interested in all the memory swapped by our process the first thing\nto do is to grep for the Swap field across all the file:\n\n\n```$ cat smaps | grep 'Swap:'\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                 12 kB\nSwap:                156 kB\nSwap:                  8 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  4 kB\nSwap:                  4 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\nSwap:                  0 kB\n```\n\n\nIf everything is 0 kB, or if there are sporadic 4k entries, everything is\nperfectly normal. Actually in our example instance (the one of a real web\nsite running Redis and serving hundreds of users every second) there are a\nfew entries that show more swapped pages. To investigate if this is a serious\nproblem or not we change our command in order to also print the size of the\nmemory map:\n\n\n```$ cat smaps | egrep '^(Swap|Size)'\nSize:                316 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                 40 kB\nSwap:                  0 kB\nSize:                132 kB\nSwap:                  0 kB\nSize:             720896 kB\nSwap:                 12 kB\nSize:               4096 kB\nSwap:                156 kB\nSize:               4096 kB\nSwap:                  8 kB\nSize:               4096 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:               1272 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                 16 kB\nSwap:                  0 kB\nSize:                 84 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  8 kB\nSwap:                  4 kB\nSize:                  8 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  4 kB\nSize:                144 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  4 kB\nSize:                 12 kB\nSwap:                  4 kB\nSize:                108 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\nSize:                272 kB\nSwap:                  0 kB\nSize:                  4 kB\nSwap:                  0 kB\n```\n\n\nAs you can see from the output, there is a map of 720896 kB\n(with just 12 kB swapped) and 156 kB more swapped in another map:\nbasically a very small amount of our memory is swapped so this is not\ngoing to create any problem at all.\nIf instead a non trivial amount of the process memory is swapped on disk your\nlatency problems are likely related to swapping. If this is the case with your\nRedis instance you can further verify it using the vmstat command:\n\n\n```$ vmstat 1\nprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa\n 0  0   3980 697932 147180 1406456    0    0     2     2    2    0  4  4 91  0\n 0  0   3980 697428 147180 1406580    0    0     0     0 19088 16104  9  6 84  0\n 0  0   3980 697296 147180 1406616    0    0     0    28 18936 16193  7  6 87  0\n 0  0   3980 697048 147180 1406640    0    0     0     0 18613 15987  6  6 88  0\n 2  0   3980 696924 147180 1406656    0    0     0     0 18744 16299  6  5 88  0\n 0  0   3980 697048 147180 1406688    0    0     0     4 18520 15974  6  6 88  0\n^C\n```\n\n\nThe interesting part of the output for our needs are the two columns si\nand so, that counts the amount of memory swapped from/to the swap file. If\nyou see non zero counts in those two columns then there is swapping activity\nin your system.\nFinally, the iostat command can be used to check the global I/O activity of\nthe system.\n\n\n```$ iostat -xk 1\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n          13.55    0.04    2.92    0.53    0.00   82.95\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util\nsda               0.77     0.00    0.01    0.00     0.40     0.00    73.65     0.00    3.62   2.58   0.00\nsdb               1.27     4.75    0.82    3.54    38.00    32.32    32.19     0.11   24.80   4.24   1.85\n```\n\n\nIf your latency problem is due to Redis memory being swapped on disk you need\nto lower the memory pressure in your system, either adding more RAM if Redis\nis using more memory than the available, or avoiding running other memory\nhungry processes in the same system.\nLatency due to AOF and disk I/O\nAnother source of latency is due to the Append Only File support on Redis.\nThe AOF basically uses two system calls to accomplish its work. One is\nwrite(2) that is used in order to write data to the append only file, and\nthe other one is fdatasync(2) that is used in order to flush the kernel\nfile buffer on disk in order to ensure the durability level specified by\nthe user.\nBoth the write(2) and fdatasync(2) calls can be source of latency.\nFor instance write(2) can block both when there is a system wide sync\nin progress, or when the output buffers are full and the kernel requires\nto flush on disk in order to accept new writes.\nThe fdatasync(2) call is a worse source of latency as with many combinations\nof kernels and file systems used it can take from a few milliseconds to\na few seconds to complete, especially in the case of some other process\ndoing I/O. For this reason when possible Redis does the fdatasync(2) call\nin a different thread since Redis 2.4.\nWe'll see how configuration can affect the amount and source of latency\nwhen using the AOF file.\nThe AOF can be configured to perform a fsync on disk in three different\nways using the appendfsync configuration option (this setting can be\nmodified at runtime using the CONFIG SET command).\n\n\nWhen appendfsync is set to the value of no Redis performs no fsync.\nIn this configuration the only source of latency can be write(2).\nWhen this happens usually there is no solution since simply the disk can't\ncope with the speed at which Redis is receiving data, however this is\nuncommon if the disk is not seriously slowed down by other processes doing\nI/O.\n\n\nWhen appendfsync is set to the value of everysec Redis performs a\nfsync every second. It uses a different thread, and if the fsync is still\nin progress Redis uses a buffer to delay the write(2) call up to two seconds\n(since write would block on Linux if a fsync is in progress against the\nsame file). However if the fsync is taking too long Redis will eventually\nperform the write(2) call even if the fsync is still in progress, and this\ncan be a source of latency.\n\n\nWhen appendfsync is set to the value of always a fsync is performed\nat every write operation before replying back to the client with an OK code\n(actually Redis will try to cluster many commands executed at the same time\ninto a single fsync). In this mode performances are very low in general and\nit is strongly recommended to use a fast disk and a file system implementation\nthat can perform the fsync in short time.\n\n\nMost Redis users will use either the no or everysec setting for the\nappendfsync configuration directive. The suggestion for minimum latency is\nto avoid other processes doing I/O in the same system.\nUsing an SSD disk can help as well, but usually even non SSD disks perform\nwell with the append only file if the disk is spare as Redis writes\nto the append only file without performing any seek.\nIf you want to investigate your latency issues related to the append only\nfile you can use the strace command under Linux:\n\n\n```sudo strace -p $(pidof redis-server) -T -e trace=fdatasync\n```\n\n\nThe above command will show all the fdatasync(2) system calls performed by\nRedis in the main thread. With the above command you'll not see the\nfdatasync system calls performed by the background thread when the\nappendfsync config option is set to everysec. In order to do so\njust add the -f switch to strace.\nIf you wish you can also see both fdatasync and write system calls with the\nfollowing command:\n\n\n```sudo strace -p $(pidof redis-server) -T -e trace=fdatasync,write\n```\n\n\nHowever since write(2) is also used in order to write data to the client\nsockets this will likely show too many things unrelated to disk I/O.\nApparently there is no way to tell strace to just show slow system calls so\nI use the following command:\n\n\n```sudo strace -f -p $(pidof redis-server) -T -e trace=fdatasync,write 2>&1 | grep -v '0.0' | grep -v unfinished\n```\n\n\nLatency generated by expires\nRedis evict expired keys in two ways:\n\nOne lazy way expires a key when it is requested by a command, but it is found to be already expired.\nOne active way expires a few keys every 100 milliseconds.\n\nThe active expiring is designed to be adaptive. An expire cycle is started every 100 milliseconds (10 times per second), and will do the following:\n\nSample `ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP` keys, evicting all the keys already expired.\nIf the more than 25% of the keys were found expired, repeat.\n\nGiven that `ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP` is set to 20 by default, and the process is performed ten times per second, usually just 200 keys per second are actively expired. This is enough to clean the DB fast enough even when already expired keys are not accessed for a long time, so that the lazy algorithm does not help. At the same time expiring just 200 keys per second has no effects in the latency a Redis instance.\nHowever the algorithm is adaptive and will loop if it finds more than 25% of keys already expired in the set of sampled keys. But given that we run the algorithm ten times per second, this means that the unlucky event of more than 25% of the keys in our random sample are expiring at least in the same second.\nBasically this means that if the database has many, many keys expiring in the same second, and these make up at least 25% of the current population of keys with an expire set, Redis can block in order to get the percentage of keys already expired below 25%.\nThis approach is needed in order to avoid using too much memory for keys that are already expired, and usually is absolutely harmless since it's strange that a big number of keys are going to expire in the same exact second, but it is not impossible that the user used `EXPIREAT` extensively with the same Unix time.\nIn short: be aware that many keys expiring at the same moment can be a source of latency.\nRedis software watchdog\nRedis 2.6 introduces the Redis Software Watchdog that is a debugging tool\ndesigned to track those latency problems that for one reason or the other\nescaped an analysis using normal tools.\nThe software watchdog is an experimental feature. While it is designed to\nbe used in production environments care should be taken to backup the database\nbefore proceeding as it could possibly have unexpected interactions with the\nnormal execution of the Redis server.\nIt is important to use it only as last resort when there is no way to track the issue by other means.\nThis is how this feature works:\n\nThe user enables the software watchdog using the `CONFIG SET` command.\nRedis starts monitoring itself constantly.\nIf Redis detects that the server is blocked into some operation that is not returning fast enough, and that may be the source of the latency issue, a low level report about where the server is blocked is dumped on the log file.\nThe user contacts the developers writing a message in the Redis Google Group, including the watchdog report in the message.\n\nNote that this feature cannot be enabled using the redis.conf file, because it is designed to be enabled only in already running instances and only for debugging purposes.\nTo enable the feature just use the following:\n\n\n```CONFIG SET watchdog-period 500\n```\n\n\nThe period is specified in milliseconds. In the above example I specified to log latency issues only if the server detects a delay of 500 milliseconds or greater. The minimum configurable period is 200 milliseconds.\nWhen you are done with the software watchdog you can turn it off setting the `watchdog-period` parameter to 0. Important: remember to do this because keeping the instance with the watchdog turned on for a longer time than needed is generally not a good idea.\nThe following is an example of what you'll see printed in the log file once the software watchdog detects a delay longer than the configured one:\n\n\n```[8547 | signal handler] (1333114359)\n--- WATCHDOG TIMER EXPIRED ---\n/lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]\n/lib/libpthread.so.0(+0xf8f0) [0x7f16b5f158f0]\n/lib/libc.so.6(nanosleep+0x2d) [0x7f16b5c2d39d]\n/lib/libc.so.6(usleep+0x34) [0x7f16b5c62844]\n./redis-server(debugCommand+0x3e1) [0x43ab41]\n./redis-server(call+0x5d) [0x415a9d]\n./redis-server(processCommand+0x375) [0x415fc5]\n./redis-server(processInputBuffer+0x4f) [0x4203cf]\n./redis-server(readQueryFromClient+0xa0) [0x4204e0]\n./redis-server(aeProcessEvents+0x128) [0x411b48]\n./redis-server(aeMain+0x2b) [0x411dbb]\n./redis-server(main+0x2b6) [0x418556]\n/lib/libc.so.6(__libc_start_main+0xfd) [0x7f16b5ba1c4d]\n./redis-server() [0x411099]\n------\n```\n\n\nNote: in the example the DEBUG SLEEP command was used in order to block the server. The stack trace is different if the server blocks in a different context.",
    "tag": "redis"
  },
  {
    "title": "Special encoding of small aggregate data types",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/optimization/memory-optimization.md",
    "content": "\ntitle: Memory optimization\nlinkTitle: Memory optimization\ndescription: Strategies for optimizing memory usage in Redis\nweight: 1\naliases: [\n    /topics/memory-optimization,\n    /docs/reference/optimization/memory-optimization\n]\n\nSpecial encoding of small aggregate data types\nSince Redis 2.2 many data types are optimized to use less space up to a certain size.\nHashes, Lists, Sets composed of just integers, and Sorted Sets, when smaller than a given number of elements, and up to a maximum element size, are encoded in a very memory efficient way that uses up to 10 times less memory (with 5 time less memory used being the average saving).\nThis is completely transparent from the point of view of the user and API.\nSince this is a CPU / memory trade off it is possible to tune the maximum \nnumber of elements and maximum element size for special encoded types \nusing the following redis.conf directives.\n`hash-max-ziplist-entries 512\nhash-max-ziplist-value 64\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\nset-max-intset-entries 512`\nIf a specially encoded value overflows the configured max size,\nRedis will automatically convert it into normal encoding.\nThis operation is very fast for small values,\nbut if you change the setting in order to use specially encoded values\nfor much larger aggregate types the suggestion is to run some \nbenchmarks and tests to check the conversion time.\nUsing 32 bit instances\nRedis compiled with 32 bit target uses a lot less memory per key, since pointers are small,\nbut such an instance will be limited to 4 GB of maximum memory usage.\nTo compile Redis as 32 bit binary use make 32bit.\nRDB and AOF files are compatible between 32 bit and 64 bit instances\n(and between little and big endian of course) so you can switch from 32 to 64 bit, or the contrary, without problems.\nBit and byte level operations\nRedis 2.2 introduced new bit and byte level operations: `GETRANGE`, `SETRANGE`, `GETBIT` and `SETBIT`.\nUsing these commands you can treat the Redis string type as a random access array.\nFor instance if you have an application where users are identified by a unique progressive integer number,\nyou can use a bitmap in order to save information about the subscription of users in a mailing list,\nsetting the bit for subscribed and clearing it for unsubscribed, or the other way around.\nWith 100 million users this data will take just 12 megabytes of RAM in a Redis instance.\nYou can do the same using `GETRANGE` and `SETRANGE` in order to store one byte of information for each user.\nThis is just an example but it is actually possible to model a number of problems in very little space with these new primitives.\nUse hashes when possible\nSmall hashes are encoded in a very small space, so you should try representing your data using hashes whenever possible.\nFor instance if you have objects representing users in a web application, \ninstead of using different keys for name, surname, email, password, use a single hash with all the required fields.\nIf you want to know more about this, read the next section.\nUsing hashes to abstract a very memory efficient plain key-value store on top of Redis\nI understand the title of this section is a bit scary, but I'm going to explain in details what this is about.\nBasically it is possible to model a plain key-value store using Redis\nwhere values can just be just strings, that is not just more memory efficient\nthan Redis plain keys but also much more memory efficient than memcached.\nLet's start with some facts: a few keys use a lot more memory than a single key\ncontaining a hash with a few fields. How is this possible? We use a trick.\nIn theory in order to guarantee that we perform lookups in constant time\n(also known as O(1) in big O notation) there is the need to use a data structure\nwith a constant time complexity in the average case, like a hash table.\nBut many times hashes contain just a few fields. When hashes are small we can\ninstead just encode them in an O(N) data structure, like a linear\narray with length-prefixed key value pairs. Since we do this only when N\nis small, the amortized time for `HGET` and `HSET` commands is still O(1): the\nhash will be converted into a real hash table as soon as the number of elements\nit contains grows too large (you can configure the limit in redis.conf).\nThis does not only work well from the point of view of time complexity, but\nalso from the point of view of constant times, since a linear array of key\nvalue pairs happens to play very well with the CPU cache (it has a better\ncache locality than a hash table).\nHowever since hash fields and values are not (always) represented as full\nfeatured Redis objects, hash fields can't have an associated time to live\n(expire) like a real key, and can only contain a string. But we are okay with\nthis, this was the intention anyway when the hash data type API was\ndesigned (we trust simplicity more than features, so nested data structures\nare not allowed, as expires of single fields are not allowed).\nSo hashes are memory efficient. This is useful when using hashes\nto represent objects or to model other problems when there are group of\nrelated fields. But what about if we have a plain key value business?\nImagine we want to use Redis as a cache for many small objects, that can be\nJSON encoded objects, small HTML fragments, simple key -> boolean values\nand so forth. Basically anything is a string -> string map with small keys\nand values.\nNow let's assume the objects we want to cache are numbered, like:\n\nobject:102393\nobject:1234\nobject:5\n\nThis is what we can do. Every time we perform a\nSET operation to set a new value, we actually split the key into two parts,\none part used as a key, and the other part used as the field name for the hash. For instance the\nobject named \"object:1234\" is actually split into:\n\na Key named object:12\na Field named 34\n\nSo we use all the characters but the last two for the key, and the final\ntwo characters for the hash field name. To set our key we use the following\ncommand:\n`HSET object:12 34 somevalue`\nAs you can see every hash will end containing 100 fields, that\nis an optimal compromise between CPU and memory saved.\nThere is another important thing to note, with this schema\nevery hash will have more or\nless 100 fields regardless of the number of objects we cached. This is since\nour objects will always end with a number, and not a random string. In some\nway the final number can be considered as a form of implicit pre-sharding.\nWhat about small numbers? Like object:2? We handle this case using just\n\"object:\" as a key name, and the whole number as the hash field name.\nSo object:2 and object:10 will both end inside the key \"object:\", but one\nas field name \"2\" and one as \"10\".\nHow much memory do we save this way?\nI used the following Ruby program to test how this works:\n```ruby\nrequire 'rubygems'\nrequire 'redis'\nUSE_OPTIMIZATION = true\ndef hash_get_key_field(key)\n  s = key.split(':')\n  if s[1].length > 2\n    { key: s[0] + ':' + s[1][0..-3], field: s[1][-2..-1] }\n  else\n    { key: s[0] + ':', field: s[1] }\n  end\nend\ndef hash_set(r, key, value)\n  kf = hash_get_key_field(key)\n  r.hset(kf[:key], kf[:field], value)\nend\ndef hash_get(r, key, value)\n  kf = hash_get_key_field(key)\n  r.hget(kf[:key], kf[:field], value)\nend\nr = Redis.new\n(0..100_000).each do |id|\n  key = \"object:#{id}\"\n  if USE_OPTIMIZATION\n    hash_set(r, key, 'val')\n  else\n    r.set(key, 'val')\n  end\nend\n```\nThis is the result against a 64 bit instance of Redis 2.2:\n\nUSE_OPTIMIZATION set to true: 1.7 MB of used memory\nUSE_OPTIMIZATION set to false; 11 MB of used memory\n\nThis is an order of magnitude, I think this makes Redis more or less the most\nmemory efficient plain key value store out there.\nWARNING: for this to work, make sure that in your redis.conf you have\nsomething like this:\n`hash-max-zipmap-entries 256`\nAlso remember to set the following field accordingly to the maximum size\nof your keys and values:\n`hash-max-zipmap-value 1024`\nEvery time a hash exceeds the number of elements or element size specified\nit will be converted into a real hash table, and the memory saving will be lost.\nYou may ask, why don't you do this implicitly in the normal key space so that\nI don't have to care? There are two reasons: one is that we tend to make\ntradeoffs explicit, and this is a clear tradeoff between many things: CPU,\nmemory, max element size. The second is that the top level key space must\nsupport a lot of interesting things like expires, LRU data, and so\nforth so it is not practical to do this in a general way.\nBut the Redis Way is that the user must understand how things work so that\nhe is able to pick the best compromise, and to understand how the system will\nbehave exactly.\nMemory allocation\nTo store user keys, Redis allocates at most as much memory as the `maxmemory`\nsetting enables (however there are small extra allocations possible).\nThe exact value can be set in the configuration file or set later via\n`CONFIG SET` (for more info, see Using memory as an LRU cache).\nThere are a few things that should be noted about how Redis manages memory:\n\nRedis will not always free up (return) memory to the OS when keys are removed.\nThis is not something special about Redis, but it is how most malloc() implementations work.\nFor example if you fill an instance with 5GB worth of data, and then\nremove the equivalent of 2GB of data, the Resident Set Size (also known as\nthe RSS, which is the number of memory pages consumed by the process)\nwill probably still be around 5GB, even if Redis will claim that the user\nmemory is around 3GB.  This happens because the underlying allocator can't easily release the memory.\nFor example often most of the removed keys were allocated in the same pages as the other keys that still exist.\nThe previous point means that you need to provision memory based on your\npeak memory usage. If your workload from time to time requires 10GB, even if\nmost of the times 5GB could do, you need to provision for 10GB.\nHowever allocators are smart and are able to reuse free chunks of memory,\nso after you freed 2GB of your 5GB data set, when you start adding more keys\nagain, you'll see the RSS (Resident Set Size) stay steady and not grow\nmore, as you add up to 2GB of additional keys. The allocator is basically\ntrying to reuse the 2GB of memory previously (logically) freed.\nBecause of all this, the fragmentation ratio is not reliable when you\nhad a memory usage that at peak is much larger than the currently used memory.\nThe fragmentation is calculated as the physical memory actually used (the RSS\nvalue) divided by the amount of memory currently in use (as the sum of all\nthe allocations performed by Redis). Because the RSS reflects the peak memory,\nwhen the (virtually) used memory is low since a lot of keys / values were\nfreed, but the RSS is high, the ratio `RSS / mem_used` will be very high.\n\nIf `maxmemory` is not set Redis will keep allocating memory as it sees\nfit and thus it can (gradually) eat up all your free memory.\nTherefore it is generally advisable to configure some limit. You may also\nwant to set `maxmemory-policy` to `noeviction` (which is not the default\nvalue in some older versions of Redis).\nIt makes Redis return an out of memory error for write commands if and when it reaches the \nlimit - which in turn may result in errors in the application but will not render the ",
    "tag": "redis"
  },
  {
    "title": "index.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/management/optimization/benchmarks/index.md",
    "content": "\ntitle: \"Redis benchmark\"\nlinkTitle: \"Benchmarking\"\nweight: 1\ndescription: >\n    Using the redis-benchmark utility on a Redis server\naliases: [\n    /topics/benchmarks,\n    /docs/reference/optimization/benchmarks,\n    /docs/reference/optimization/benchmarks.md\n]\n\nRedis includes the `redis-benchmark` utility that simulates running commands done\nby N clients while at the same time sending M total queries. The utility provides\na default set of tests, or you can supply a custom set of tests.\nThe following options are supported:\n\n\n```Usage: redis-benchmark [-h <host>] [-p <port>] [-c <clients>] [-n <requests]> [-k <boolean>]\n\n -h <hostname>      Server hostname (default 127.0.0.1)\n -p <port>          Server port (default 6379)\n -s <socket>        Server socket (overrides host and port)\n -a <password>      Password for Redis Auth\n -c <clients>       Number of parallel connections (default 50)\n -n <requests>      Total number of requests (default 100000)\n -d <size>          Data size of SET/GET value in bytes (default 3)\n --dbnum <db>       SELECT the specified db number (default 0)\n -k <boolean>       1=keep alive 0=reconnect (default 1)\n -r <keyspacelen>   Use random keys for SET/GET/INCR, random values for SADD\n  Using this option the benchmark will expand the string __rand_int__\n  inside an argument with a 12 digits number in the specified range\n  from 0 to keyspacelen-1. The substitution changes every time a command\n  is executed. Default tests use this to hit random keys in the\n  specified range.\n -P <numreq>        Pipeline <numreq> requests. Default 1 (no pipeline).\n -q                 Quiet. Just show query/sec values\n --csv              Output in CSV format\n -l                 Loop. Run the tests forever\n -t <tests>         Only run the comma separated list of tests. The test\n                    names are the same as the ones produced as output.\n -I                 Idle mode. Just open N idle connections and wait.\n```\n\n\nYou need to have a running Redis instance before launching the benchmark.\nYou can run the benchmarking utility like so:\n\n\n```redis-benchmark -q -n 100000\n```\n\n\nRunning only a subset of the tests\nYou don't need to run all the default tests every time you execute `redis-benchmark`.\nFor example, to select only a subset of tests, use the `-t` option\nas in the following example:\n\n\n```$ redis-benchmark -t set,lpush -n 100000 -q\nSET: 74239.05 requests per second\nLPUSH: 79239.30 requests per second\n```\n\n\nThis example runs the tests for the `SET` and `LPUSH` commands and uses quiet mode (see the `-q` switch).\nYou can even benchmark a specific command:\n\n\n```$ redis-benchmark -n 100000 -q script load \"redis.call('set','foo','bar')\"\nscript load redis.call('set','foo','bar'): 69881.20 requests per second\n```\n\n\nSelecting the size of the key space\nBy default, the benchmark runs against a single key. In Redis the difference\nbetween such a synthetic benchmark and a real one is not huge since it is an\nin-memory system, however it is possible to stress cache misses and in general\nto simulate a more real-world work load by using a large key space.\nThis is obtained by using the `-r` switch. For instance if I want to run\none million SET operations, using a random key for every operation out of\n100k possible keys, I'll use the following command line:\n\n\n```$ redis-cli flushall\nOK\n\n$ redis-benchmark -t set -r 100000 -n 1000000\n====== SET ======\n  1000000 requests completed in 13.86 seconds\n  50 parallel clients\n  3 bytes payload\n  keep alive: 1\n\n99.76% `<=` 1 milliseconds\n99.98% `<=` 2 milliseconds\n100.00% `<=` 3 milliseconds\n100.00% `<=` 3 milliseconds\n72144.87 requests per second\n\n$ redis-cli dbsize\n(integer) 99993\n```\n\n\nUsing pipelining\nBy default every client (the benchmark simulates 50 clients if not otherwise\nspecified with `-c`) sends the next command only when the reply of the previous\ncommand is received, this means that the server will likely need a read call\nin order to read each command from every client. Also RTT is paid as well.\nRedis supports pipelining, so it is possible to send\nmultiple commands at once, a feature often exploited by real world applications.\nRedis pipelining is able to dramatically improve the number of operations per\nsecond a server is able do deliver.\nConsider this example of running the benchmark using a\npipelining of 16 commands:\n\n\n```$ redis-benchmark -n 1000000 -t set,get -P 16 -q\nSET: 403063.28 requests per second\nGET: 508388.41 requests per second\n```\n\n\nUsing pipelining results in a significant increase in performance.\nPitfalls and misconceptions\nThe first point is obvious: the golden rule of a useful benchmark is to\nonly compare apples and apples. You can compare different versions of Redis on the same workload or the same version of Redis, but with\ndifferent options. If you plan to compare Redis to something else, then it is\nimportant to evaluate the functional and technical differences, and take them\nin account.\n\nRedis is a server: all commands involve network or IPC round trips. It is meaningless to compare it to embedded data stores, because the cost of most operations is primarily in network/protocol management.\nRedis commands return an acknowledgment for all usual commands. Some other data stores do not. Comparing Redis to stores involving one-way queries is only mildly useful.\nNaively iterating on synchronous Redis commands does not benchmark Redis itself, but rather measure your network (or IPC) latency and the client library intrinsic latency. To really test Redis, you need multiple connections (like redis-benchmark) and/or to use pipelining to aggregate several commands and/or multiple threads or processes.\nRedis is an in-memory data store with some optional persistence options. If you plan to compare it to transactional servers (MySQL, PostgreSQL, etc ...), then you should consider activating AOF and decide on a suitable fsync policy.\nRedis is, mostly, a single-threaded server from the POV of commands execution (actually modern versions of Redis use threads for different things). It is not designed to benefit from multiple CPU cores. People are supposed to launch several Redis instances to scale out on several cores if needed. It is not really fair to compare one single Redis instance to a multi-threaded data store.\n\nThe `redis-benchmark` program is a quick and useful way to get some figures and\nevaluate the performance of a Redis instance on a given hardware. However,\nby default, it does not represent the maximum throughput a Redis instance can\nsustain. Actually, by using pipelining and a fast client (hiredis), it is fairly\neasy to write a program generating more throughput than redis-benchmark. The\ndefault behavior of redis-benchmark is to achieve throughput by exploiting\nconcurrency only (i.e. it creates several connections to the server).\nIt does not use pipelining or any parallelism at all (one pending query per\nconnection at most, and no multi-threading), if not explicitly enabled via\nthe `-P` parameter. So in some way using `redis-benchmark` and, triggering, for\nexample, a `BGSAVE` operation in the background at the same time, will provide\nthe user with numbers more near to the worst case than to the best case.\nTo run a benchmark using pipelining mode (and achieve higher throughput),\nyou need to explicitly use the -P option. Please note that it is still a\nrealistic behavior since a lot of Redis based applications actively use\npipelining to improve performance. However you should use a pipeline size that\nis more or less the average pipeline length you'll be able to use in your\napplication in order to get realistic numbers.\nThe benchmark should apply the same operations, and work in the same way\nwith the multiple data stores you want to compare. It is absolutely pointless to\ncompare the result of redis-benchmark to the result of another benchmark\nprogram and extrapolate.\nFor instance, Redis and memcached in single-threaded mode can be compared on\nGET/SET operations. Both are in-memory data stores, working mostly in the same\nway at the protocol level. Provided their respective benchmark application is\naggregating queries in the same way (pipelining) and use a similar number of\nconnections, the comparison is actually meaningful.\nWhen you're benchmarking a high-performance, in-memory database like Redis,\nit may be difficult to saturate\nthe server. Sometimes, the performance bottleneck is on the client side,\nand not the server-side. In that case, the client (i.e., the benchmarking program itself)\nmust be fixed, or perhaps scaled out, to reach the maximum throughput.\nFactors impacting Redis performance\nThere are multiple factors having direct consequences on Redis performance.\nWe mention them here, since they can alter the result of any benchmarks.\nPlease note however, that a typical Redis instance running on a low end,\nuntuned box usually provides good enough performance for most applications.\n\nNetwork bandwidth and latency usually have a direct impact on the performance.\nIt is a good practice to use the ping program to quickly check the latency\nbetween the client and server hosts is normal before launching the benchmark.\nRegarding the bandwidth, it is generally useful to estimate\nthe throughput in Gbit/s and compare it to the theoretical bandwidth\nof the network. For instance a benchmark setting 4 KB strings\nin Redis at 100000 q/s, would actually consume 3.2 Gbit/s of bandwidth\nand probably fit within a 10 Gbit/s link, but not a 1 Gbit/s one. In many real\nworld scenarios, Redis throughput is limited by the network well before being\nlimited by the CPU. To consolidate several high-throughput Redis instances\non a single server, it worth considering putting a 10 Gbit/s NIC\nor multiple 1 Gbit/s NICs with TCP/IP bonding.\nCPU is another very important factor. Being single-threaded, Redis favors\nfast CPUs with large caches and not many cores. At this game, Intel CPUs are\ncurrently the winners. It is not uncommon to get only half the performance on\nan AMD Opteron CPU compared to similar Nehalem EP/Westmere EP/Sandy Bridge\nIntel CPUs with Redis. When client and server run on the same box, the CPU is\nthe limiting factor with redis-benchmark.\nSpeed of RAM and memory bandwidth seem less critical for global performance\nespecially for small objects. For large objects (>10 KB), it may become\nnoticeable though. Usually, it is not really cost-effective to buy expensive\nfast memory modules to optimize Redis.\nRedis runs slower on a VM compared to running without virtualization using\nthe same hardware. If you have the chance to run Redis on a physical machine\nthis is preferred. However this does not mean that Redis is slow in\nvirtualized environments, the delivered performances are still very good\nand most of the serious performance issues you may incur in virtualized\nenvironments are due to over-provisioning, non-local disks with high latency,\nor old hypervisor software that have slow `fork` syscall implementation.\nWhen the server and client benchmark programs run on the same box, both\nthe TCP/IP loopback and unix domain sockets can be used. Depending on the\nplatform, unix domain sockets can achieve around 50% more throughput than\nthe TCP/IP loopback (on Linux for instance). The default behavior of\nredis-benchmark is to use the TCP/IP loopback.\nThe performance benefit of unix domain sockets compared to TCP/IP loopback\ntends to decrease when pipelining is heavily used (i.e. long pipelines).\n\nWhen an ethernet network is used to access Redis, aggregating commands using\npipelining is especially efficient when the size of the data is kept under\nthe ethernet packet size (about 1500 bytes). Actually, processing 10 bytes,\n100 bytes, or 1000 bytes queries almost result in the same throughput.\nSee the graph below.\n\n\n\nOn multi CPU sockets servers, Redis performance becomes dependent on the\nNUMA configuration and process location. The most visible effect is that\nredis-benchmark results seem non-deterministic because client and server\nprocesses are distributed randomly on the cores. To get deterministic results,\nit is required to use process placement tools (on Linux: taskset or numactl).\nThe most efficient combination is always to put the client and server on two\ndifferent cores of the same CPU to benefit from the L3 cache.\nHere are some results of 4 KB SET benchmark for 3 server CPUs (AMD Istanbul,\nIntel Nehalem EX, and Intel Westmere) with different relative placements.\nPlease note this benchmark is not meant to compare CPU models between themselves\n(CPUs exact model and frequency are therefore not disclosed).\n\n\n\nWith high-end configurations, the number of client connections is also an\nimportant factor. Being based on epoll/kqueue, the Redis event loop is quite\nscalable. Redis has already been benchmarked at more than 60000 connections,\nand was still able to sustain 50000 q/s in these conditions. As a rule of thumb,\nan instance with 30000 connections can only process half the throughput\nachievable with 100 connections. Here is an example showing the throughput of\na Redis instance per number of connections:\n\n\n\nWith high-end configurations, it is possible to achieve higher throughput by\ntuning the NIC(s) configuration and associated interruptions. Best throughput\nis achieved by setting an affinity between Rx/Tx NIC queues and CPU cores,\nand activating RPS (Receive Packet Steering) support. More information in this\nthread.\nJumbo frames may also provide a performance boost when large objects are used.\n\nDepending on the platform, Redis can be compiled against different memory\nallocators (libc malloc, jemalloc, tcmalloc), which may have different behaviors\nin term of raw speed, internal and external fragmentation.\nIf you did not compile Redis yourself, you can use the INFO command to check\nthe `mem_allocator` field. Please note most benchmarks do not run long enough to\ngenerate significant external fragmentation (contrary to production Redis\ninstances).\n\nOther things to consider\nOne important goal of any benchmark is to get reproducible results, so they\ncan be compared to the results of other tests.\n\nA good practice is to try to run tests on isolated hardware as much as possible.\nIf it is not possible, then the system must be monitored to check the benchmark\nis not impacted by some external activity.\nSome configurations (desktops and laptops for sure, some servers as well)\nhave a variable CPU core frequency mechanism. The policy controlling this\nmechanism can be set at the OS level. Some CPU models are more aggressive than\nothers at adapting the frequency of the CPU cores to the workload. To get\nreproducible results, it is better to set the highest possible fixed frequency\nfor all the CPU cores involved in the benchmark.\nAn important point is to size the system accordingly to the benchmark.\nThe system must have enough RAM and must not swap. On Linux, do not forget\nto set the `overcommit_memory` parameter correctly. Please note 32 and 64 bit\nRedis instances do not have the same memory footprint.\nIf you plan to use RDB or AOF for your benchmark, please check there is no other\nI/O activity in the system. Avoid putting RDB or AOF files on NAS or NFS shares,\nor on any other devices impacting your network bandwidth and/or latency\n(for instance, EBS on Amazon EC2).\nSet Redis logging level (loglevel parameter) to warning or notice. Avoid putting\nthe generated log file on a remote filesystem.\nAvoid using monitoring tools which can alter the result of the benchmark. For\ninstance using INFO at regular interval to gather statistics is probably fine,\nbut MONITOR will impact the measured performance significantly.\n\nOther Redis benchmarking tools\nThere are several third-party tools that can be used for benchmarking Redis. Refer to each tool's\ndocumentation for more information about its goals and capabilities.\n\nmemtier_benchmark from Redis Ltd. is a NoSQL Redis and Memcache traffic generation and benchmarking tool.\nrpc-perf from Twitter is a tool for benchmarking RPC services that supports Redis and Memcache.\n",
    "tag": "redis"
  },
  {
    "title": "Three clause BSD license",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/about/license.md",
    "content": "\ntitle: \"Redis license\"\nlinkTitle: \"License\"\nweight: 5\ndescription: >\n    Redis license and trademark information\naliases:\n    - /topics/license\n\nRedis is open source software released under the terms of the three clause BSD license. Most of the Redis source code was written and is copyrighted by Salvatore Sanfilippo and Pieter Noordhuis. A list of other contributors can be found in the git history.\nThe Redis trademark and logo are owned by Redis Ltd. and can be\nused in accordance with the Redis Trademark Guidelines.\nThree clause BSD license\nEvery file in the Redis distribution, with the exceptions of third party files specified in the list below, contain the following license:\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n\nRedistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimer.\n\n\nRedistributions in binary form must reproduce the above copyright\n  notice, this list of conditions and the following disclaimer in the\n  documentation and/or other materials provided with the distribution.\n\n\nNeither the name of Redis nor the names of its contributors may be used\n  to endorse or promote products derived from this software without\n  specific prior written permission.\n\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\nThird-party files and licenses\nRedis uses source code from third parties. All this code contains a BSD or BSD-compatible license. The following is a list of third-party files and information about their copyright.\n\n\nRedis uses the LHF compression library. LibLZF is copyright Marc Alexander Lehmann and is released under the terms of the two-clause BSD license.\n\n\nRedis uses the `sha1.c` file that is copyright by Steve Reid and released under the public domain. This file is extremely popular and used among open source and proprietary code.\n\n\nWhen compiled on Linux, Redis uses the Jemalloc allocator, which is copyrighted by Jason Evans, Mozilla Foundation, and Facebook, Inc and released under the two-clause BSD license.\n\n\nInside Jemalloc, the file `pprof` is copyrighted by Google Inc. and released under the three-clause BSD license.\n\n\nInside Jemalloc the files `inttypes.h`, `stdbool.h`, `stdint.h`, `strings.h` under the `msvc_compat` directory are copyright Alexander Chemeris and released under the three-clause BSD license.\n\n\nThe libraries hiredis and linenoise also included inside the Redis distribution are copyright Salvatore Sanfilippo and Pieter Noordhuis and released under the terms respectively of the three-clause BSD license and two-clause BSD license.\n\n",
    "tag": "redis"
  },
  {
    "title": "Release cycle",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/about/releases.md",
    "content": "\ntitle: \"Redis release cycle\"\nlinkTitle: \"Release cycle\"\nweight: 4\ndescription: How are new versions of Redis released?\naliases:\n    - /topics/releases\n\nRedis is system software and a type of system software that holds user data, so\nit is among the most critical pieces of a software stack.\nFor this reason, Redis' release cycle is such that it ensures highly-stable\nreleases, even at the cost of slower cycles.\nNew releases are published in the Redis GitHub repository\nand are also available for download. Announcements are sent to the\nRedis mailing list and by\n@redisfeed on Twitter.\nRelease cycle\nA given version of Redis can be at three different levels of stability:\n\nUnstable\nRelease Candidate\nStable\n\nUnstable tree\nThe unstable version of Redis is located in the `unstable` branch in the\nRedis GitHub repository.\nThis branch is the source tree where most of the new features are under\ndevelopment. `unstable` is not considered production-ready: it may contain\ncritical bugs, incomplete features, and is potentially unstable.\nHowever, we try hard to make sure that even the unstable branch is usable most\nof the time in a development environment without significant issues.\nRelease candidate\nNew minor and major versions of Redis begin as forks of the `unstable` branch.\nThe forked branch's name is the target release\nFor example, when Redis 6.0 was released as a release candidate, the `unstable`\nbranch was forked into the `6.0` branch. The new branch is the release\ncandidate (RC) for that version.\nBug fixes and new features that can be stabilized during the release's time\nframe are committed to the unstable branch and backported to the release\ncandidate branch. The `unstable` branch may include additional work that is not\na part of the release candidate and scheduled for future releases.\nThe first release candidate, or RC1, is released once it can be used for\ndevelopment purposes and for testing the new version. At this stage, most of\nthe new features and changes the new version brings are ready for review, and\nthe release's purpose is collecting the public's feedback.\nSubsequent release candidates are released every three weeks or so, primarily\nfor fixing bugs. These may also add new features and introduce changes, but at\na decreasing rate and decreasing potential risk towards the final release\ncandidate.\nStable tree\nOnce development has ended and the frequency of critical bug reports for the\nrelease candidate wanes, it is ready for the final release. At this point, the\nrelease is marked as stable and is released with \"0\" as its patch-level\nversion.\nVersioning\nStable releases liberally follow the usual `major.minor.patch` semantic\nversioning schema. The primary goal is to provide explicit guarantees regarding\nbackward compatibility.\nPatch-Level versions\nPatches primarily consist of bug fixes and very rarely introduce any\ncompatibility issues.\nUpgrading from a previous patch-level version is almost always safe and\nseamless.\nNew features and configuration directives may be added, or default values\nchanged, as long as these don\u2019t carry significant impacts or introduce\noperations-related issues.\nMinor versions\nMinor versions usually deliver maturity and extended functionality.\nUpgrading between minor versions does not introduce any application-level\ncompatibility issues.\nMinor releases may include new commands and data types that introduce\noperations-related incompatibilities, including changes in data persistence\nformat and replication protocol.\nMajor versions\nMajor versions introduce new capabilities and significant changes.\nIdeally, these don't introduce application-level compatibility issues.\nRelease schedule\nA new major version is planned for release once a year.\nGenerally, every major release is followed by a minor version after six months.\nPatches are released as needed to fix high-urgency issues, or once a stable\nversion accumulates enough fixes to justify it.\nFor contacting the core team on sensitive matters and security issues, please\nemail redis@redis.io.\nSupport\nAs a rule, older versions are not supported as we try very hard to make the\nRedis API mostly backward compatible.\nUpgrading to newer versions is the recommended approach and is usually trivial.\nThe latest stable release is always fully supported and maintained.\nTwo additional versions receive maintenance only, meaning that only fixes for\ncritical bugs and major security issues are committed and released as patches:\n\nThe previous minor version of the latest stable release.\nThe previous stable major release.\n\nFor example, consider the following hypothetical versions: 1.2, 2.0, 2.2, 3.0,\n3.2.\nWhen version 2.2 is the latest stable release, both 2.0 and 1.2 are maintained.\nOnce version 3.0.0 replaces 2.2 as the latest stable, versions 2.0 and 2.2 are\nmaintained, whereas version 1.x reaches its end of life.\nThis process repeats with version 3.2.0, after which only versions 2.2 and 3.0\nare maintained.\nThe above are guidelines rather than rules set in stone and will not replace\ncommon sense.",
    "tag": "redis"
  },
  {
    "title": "Current governance structure",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/about/governance.md",
    "content": "\ntitle: \"Redis open source governance\"\nlinkTitle: \"Governance\"\nweight: 3\ndescription: >\n    Governance model for the Redis open source project\naliases:\n    - /topics/governance\n\nFrom 2009-2020, Salvatore Sanfilippo built, led, and maintained the Redis open source project. During this time, Redis had no formal governance structure, operating primarily as a BDFL-style project.\nAs Redis grew, matured, and expanded its user base, it became increasingly important to form a sustainable structure for its ongoing development and maintenance. Salvatore and the core Redis contributors wanted to ensure the project\u2019s continuity and reflect its larger community.  With this in mind, a new governance structure was adopted.\nCurrent governance structure\nStarting on June 30, 2020, Redis adopted a light governance model that matches the current size of the project and minimizes the changes from its earlier model. The governance model is intended to be a meritocracy, aiming to empower individuals who demonstrate a long-term commitment and make significant contributions.\nThe Redis core team\nSalvatore Sanfilippo named two successors to take over and lead the Redis project: Yossi Gottlieb (yossigo) and Oran Agra (oranagra)\nWith the backing and blessing of Redis Ltd., we took this opportunity to create a more open, scalable, and community-driven \u201ccore team\u201d structure to run the project. The core team consists of members selected based on demonstrated, long-term personal involvement and contributions.\nThe current core team members are:\n\nProject Lead: Yossi Gottlieb (yossigo) from Redis Ltd.\nProject Lead: Oran Agra  (oranagra) from Redis Ltd.\nCommunity Lead: Itamar Haber (itamarhaber) from Redis Ltd.\nMember: Zhao Zhao (soloestoy) from Alibaba\nMember: Madelyn Olson (madolson) from Amazon Web Services\n\nThe Redis core team members serve the Redis open source project and community. They are expected to set a good example of behavior, culture, and tone in accordance with the adopted Code of Conduct. They should also consider and act upon the best interests of the project and the community in a way that is free from foreign or conflicting interests.\nThe core team will be responsible for the Redis core project, which is the part of Redis that is hosted in the main Redis repository and is BSD licensed. It will also aim to maintain coordination and collaboration with other projects that make up the Redis ecosystem, including Redis clients, satellite projects, major middleware that relies on Redis, etc.\nRoles and responsibilities\nThe core team has the following remit:\n\nManaging the core Redis code and documentation\nManaging new Redis releases\nMaintaining a high-level technical direction/roadmap\nProviding a fast response, including fixes/patches, to address security vulnerabilities and other major issues\nProject governance decisions and changes\nCoordination of Redis core with the rest of the Redis ecosystem\nManaging the membership of the core team\n\nThe core team aims to form and empower a community of contributors by further delegating tasks to individuals who demonstrate commitment, know-how, and skills. In particular, we hope to see greater community involvement in the following areas:\n\nSupport, troubleshooting, and bug fixes of reported issues\nTriage of contributions/pull requests\n\nDecision making\n\nNormal decisions will be made by core team members based on a lazy consensus approach: each member may vote +1 (positive) or -1 (negative). A negative vote must include thorough reasoning and better yet, an alternative proposal. The core team will always attempt to reach a full consensus rather than a majority. Examples of normal decisions:\nDay-to-day approval of pull requests and closing issues\nOpening new issues for discussion\n\n\nMajor decisions that have a significant impact on the Redis architecture, design, or philosophy as well as core-team structure or membership changes should preferably be determined by full consensus. If the team is not able to achieve a full consensus, a majority vote is required. Examples of major decisions:\nFundamental changes to the Redis core\nAdding a new data structure\nCreating a new version of RESP (Redis Serialization Protocol)\nChanges that affect backward compatibility\nAdding or changing core team members\n\n\nProject leads have a right to veto major decisions\n\nCore team membership\n\nThe core team is not expected to serve for life, however, long-term participation is desired to provide stability and consistency in the Redis programming style and the community.\nIf a core-team member whose work is funded by Redis Ltd. must be replaced, the replacement will be designated by Redis Ltd. after consultation with the remaining core-team members.\nIf a core-team member not funded by Redis Ltd. will no longer participate, for whatever reason, the other team members will select a replacement.\n\nCommunity forums and communications\nWe want the Redis community to be as welcoming and inclusive as possible. To that end, we have adopted a Code of Conduct that we ask all community members to read and observe.\nWe encourage that all significant communications will be public, asynchronous, archived, and open for the community to actively participate in using the channels described here. The exception to that is sensitive security issues that require resolution prior to public disclosure.\nTo contact the core team about sensitive matters, such as misconduct or security issues, please email redis@redis.io.\nNew Redis repository and commits approval process\nThe Redis core source repository is hosted under https://github.com/redis/redis. Our target is to eventually host everything (the Redis core source and other ecosystem projects) under the Redis GitHub organization (https://github.com/redis). Commits to the Redis source repository will require code review, approval of at least one core-team member who is not the author of the commit, and no objections.\nProject and development updates\nStay connected to the project and the community! For project and community updates, follow the project channels. Development announcements will be made via the Redis mailing list.\nUpdates to these governance rules",
    "tag": "redis"
  },
  {
    "title": "_index.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/about/_index.md",
    "content": "\ntitle: Introduction to Redis\nlinkTitle: \"About\"\nweight: 10\ndescription: Learn about the Redis open source project\naliases:\n  - /topics/introduction\n  - /buzz\n\nRedis is an open source (BSD licensed), in-memory data structure store used as a database, cache, message broker, and streaming engine. Redis provides data structures such as\nstrings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, geospatial indexes, and streams. Redis has built-in replication, Lua scripting, LRU eviction, transactions, and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.\nYou can run atomic operations\non these types, like appending to a string;\nincrementing the value in a hash; pushing an element to a\nlist; computing set intersection,\nunion and difference;\nor getting the member with highest ranking in a sorted set.\nTo achieve top performance, Redis works with an\nin-memory dataset. Depending on your use case, Redis can persist your data either\nby periodically dumping the dataset to disk\nor by appending each command to a disk-based log. You can also disable persistence if you just need a feature-rich, networked, in-memory cache.\nRedis supports asynchronous replication, with fast non-blocking synchronization and auto-reconnection with partial resynchronization on net split.\nRedis also includes:\n\nTransactions\nPub/Sub\nLua scripting\nKeys with a limited time-to-live\nLRU eviction of keys\nAutomatic failover\n\nYou can use Redis from most programming languages.\nRedis is written in ANSI C and works on most POSIX systems like Linux,\n*BSD, and Mac OS X, without external dependencies. Linux and OS X are the two operating systems where Redis is developed and tested the most, and we recommend using Linux for deployment. Redis may work in Solaris-derived systems like SmartOS, but support is best effort.",
    "tag": "redis"
  },
  {
    "title": "redis.io",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/about/sponsors.md",
    "content": "\ntitle: \"Redis sponsors\"\nlinkTitle: \"Sponsors\"\nweight: 4\ndescription: Current and former Redis sponsors\naliases:\n    - /topics/sponsors\n\nFrom 2015 to 2020, Salvatore Sanfilippo's work on Redis was sponsored by Redis Ltd. Since June 2020, Redis Ltd. has sponsored the governance of Redis. Redis Ltd. also sponsors the hosting and maintenance of redis.io. \nPast sponsorships:\n\nThe Shuttleworth Foundation has donated 5000 USD to the Redis project in form of a flash grant.\nFrom May 2013 to June 2015, the work Salvatore Sanfilippo did to develop Redis was sponsored by Pivotal.\nBefore May 2013, the project was sponsored by VMware with the work of Salvatore Sanfilippo and Pieter Noordhuis.\nVMware and later Pivotal provided a 24 GB RAM workstation for Salvatore to run the Redis CI test and other long running tests. Later, Salvatore equipped the server with an SSD drive in order to test in the same hardware with rotating and flash drives.\nLinode, in January 2010, provided virtual machines for Redis testing in a virtualized environment.\nSlicehost, January 2010, provided Virtual Machines for Redis testing in a virtualized environment.\nCitrusbyte, in December 2009, contributed part of Virtual Memory implementation.\nHitmeister, in December 2009, contributed part of Redis Cluster.\nEngine Yard, in December 2009, contributed blocking POP (BLPOP) and part of the Virtual Memory implementation.\n\nAlso thanks to the following people or organizations that donated to the Project:\n\nEmil Vladev\nBrad Jasper\nMrkris\n\nThe Redis community is grateful to Redis Ltd., Pivotal, VMware and to the other companies and people who have donated to the Redis project. Thank you.\nredis.io\nCitrusbyte sponsored the creation of the official\nRedis logo (designed by Carlos Prioglio) and\ntransferred its copyright to Salvatore Sanfilippo.\nThey also sponsored the initial implementation of this site by\nDamian Janowski and Michel\nMartens.\nThe `redis.io` domain was donated for a few years to the project by [I Want My",
    "tag": "redis"
  },
  {
    "title": "Format of pushed messages",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/pubsub.md",
    "content": "\ntitle: Redis Pub/Sub\nlinkTitle: \"Pub/sub\"\nweight: 4\ndescription: How to use pub/sub channels in Redis\naliases:\n  - /topics/pubsub\n  - /docs/manual/pub-sub\n\n`SUBSCRIBE`, `UNSUBSCRIBE` and `PUBLISH`\nimplement the Publish/Subscribe messaging\nparadigm where\n(citing Wikipedia) senders (publishers) are not programmed to send\ntheir messages to specific receivers (subscribers). Rather, published\nmessages are characterized into channels, without knowledge of what (if\nany) subscribers there may be. Subscribers express interest in one or\nmore channels, and only receive messages that are of interest, without\nknowledge of what (if any) publishers there are. This decoupling of\npublishers and subscribers can allow for greater scalability and a more\ndynamic network topology.\nFor instance in order to subscribe to channels `foo` and `bar` the\nclient issues a `SUBSCRIBE` providing the names of the channels:\n`bash\nSUBSCRIBE foo bar`\nMessages sent by other clients to these channels will be pushed by Redis\nto all the subscribed clients.\nA client subscribed to one or more channels should not issue commands,\nalthough it can subscribe and unsubscribe to and from other channels.\nThe replies to subscription and unsubscribing operations are sent in\nthe form of messages, so that the client can just read a coherent\nstream of messages where the first element indicates the type of\nmessage. The commands that are allowed in the context of a subscribed\nclient are `SUBSCRIBE`, `SSUBSCRIBE`, `SUNSUBSCRIBE`, `PSUBSCRIBE`, `UNSUBSCRIBE`, `PUNSUBSCRIBE`, `PING`, `RESET`, and `QUIT`.\nPlease note that when using `redis-cli`, in subscribed mode\ncommands such as `UNSUBSCRIBE` and `PUNSUBSCRIBE` cannot be used because \n`redis-cli` will not accept any commands and can only quit the mode with `Ctrl-C`.\nFormat of pushed messages\nA message is an array-reply with three elements.\nThe first element is the kind of message:\n\n\n`subscribe`: means that we successfully subscribed to the channel\ngiven as the second element in the reply. The third argument represents\nthe number of channels we are currently subscribed to.\n\n\n`unsubscribe`: means that we successfully unsubscribed from the\nchannel given as second element in the reply. The third argument\nrepresents the number of channels we are currently subscribed to. When\nthe last argument is zero, we are no longer subscribed to any channel,\nand the client can issue any kind of Redis command as we are outside the\nPub/Sub state.\n\n\n`message`: it is a message received as result of a `PUBLISH` command\nissued by another client. The second element is the name of the\noriginating channel, and the third argument is the actual message\npayload.\n\n\nDatabase & Scoping\nPub/Sub has no relation to the key space.\nIt was made to not interfere with it on any level, including database numbers.\nPublishing on db 10, will be heard by a subscriber on db 1.\nIf you need scoping of some kind, prefix the channels with the name of the\nenvironment (test, staging, production...).\nWire protocol example\n`SUBSCRIBE first second\n*3\n$9\nsubscribe\n$5\nfirst\n:1\n*3\n$9\nsubscribe\n$6\nsecond\n:2`\nAt this point, from another client we issue a `PUBLISH` operation\nagainst the channel named `second`:\n```\n\nPUBLISH second Hello\n```\n\nThis is what the first client receives:\n`*3\n$7\nmessage\n$6\nsecond\n$5\nHello`\nNow the client unsubscribes itself from all the channels using the\n`UNSUBSCRIBE` command without additional arguments:\n`UNSUBSCRIBE\n*3\n$11\nunsubscribe\n$6\nsecond\n:1\n*3\n$11\nunsubscribe\n$5\nfirst\n:0`\nPattern-matching subscriptions\nThe Redis Pub/Sub implementation supports pattern matching. Clients may\nsubscribe to glob-style patterns in order to receive all the messages\nsent to channel names matching a given pattern.\nFor instance:\n`PSUBSCRIBE news.*`\nWill receive all the messages sent to the channel `news.art.figurative`,\n`news.music.jazz`, etc.\nAll the glob-style patterns are valid, so multiple wildcards are supported.\n`PUNSUBSCRIBE news.*`\nWill then unsubscribe the client from that pattern.\nNo other subscriptions will be affected by this call.\nMessages received as a result of pattern matching are sent in a\ndifferent format:\n\nThe type of the message is `pmessage`: it is a message received\nas result of a `PUBLISH` command issued by another client, matching\na pattern-matching subscription. The second element is the original\npattern matched, the third element is the name of the originating\nchannel, and the last element the actual message payload.\n\nSimilarly to `SUBSCRIBE` and `UNSUBSCRIBE`, `PSUBSCRIBE` and\n`PUNSUBSCRIBE` commands are acknowledged by the system sending a message\nof type `psubscribe` and `punsubscribe` using the same format as the\n`subscribe` and `unsubscribe` message format.\nMessages matching both a pattern and a channel subscription\nA client may receive a single message multiple times if it's subscribed\nto multiple patterns matching a published message, or if it is\nsubscribed to both patterns and channels matching the message. Like in\nthe following example:\n`SUBSCRIBE foo\nPSUBSCRIBE f*`\nIn the above example, if a message is sent to channel `foo`, the client\nwill receive two messages: one of type `message` and one of type\n`pmessage`.\nThe meaning of the subscription count with pattern matching\nIn `subscribe`, `unsubscribe`, `psubscribe` and `punsubscribe`\nmessage types, the last argument is the count of subscriptions still\nactive. This number is actually the total number of channels and\npatterns the client is still subscribed to. So the client will exit\nthe Pub/Sub state only when this count drops to zero as a result of\nunsubscribing from all the channels and patterns.\nSharded Pub/Sub\nFrom 7.0, sharded Pub/Sub is introduced in which shard channels are assigned to slots by the same algorithm used to assign keys to slots. \nA shard message must be sent to a node that own the slot the shard channel is hashed to. \nThe cluster makes sure the published shard messages are forwarded to all nodes in the shard, so clients can subscribe to a shard channel by connecting to either the master responsible for the slot, or to any of its replicas.\n`SSUBSCRIBE`, `SUNSUBSCRIBE` and `SPUBLISH` are used to implement sharded Pub/Sub.\nSharded Pub/Sub helps to scale the usage of Pub/Sub in cluster mode. \nIt restricts the propagation of message to be within the shard of a cluster. \nHence, the amount of data passing through the cluster bus is limited in comparison to global Pub/Sub where each message propagates to each node in the cluster.\nThis allows users to horizontally scale the Pub/Sub usage by adding more shards.\nProgramming example\nPieter Noordhuis provided a great example using EventMachine\nand Redis to create a multi user high performance web\nchat.\nClient library implementation hints\nBecause all the messages received contain the original subscription\ncausing the message delivery (the channel in the case of message type,\nand the original pattern in the case of pmessage type) client libraries\nmay bind the original subscription to callbacks (that can be anonymous\nfunctions, blocks, function pointers), using a hash table.\nWhen a message is received an O(1) lookup can be done in order to",
    "tag": "redis"
  },
  {
    "title": "keyspace-notifications.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/keyspace-notifications.md",
    "content": "\ntitle: \"Redis keyspace notifications\"\nlinkTitle: \"Keyspace notifications\"\nweight: 3\ndescription: >\n    Monitor changes to Redis keys and values in real time\naliases:\n    - /topics/notifications\n\nKeyspace notifications allow clients to subscribe to Pub/Sub channels in order\nto receive events affecting the Redis data set in some way.\nExamples of events that can be received are:\n\nAll the commands affecting a given key.\nAll the keys receiving an LPUSH operation.\nAll the keys expiring in the database 0.\n\nNote: Redis Pub/Sub is fire and forget that is, if your Pub/Sub client disconnects,\nand reconnects later, all the events delivered during the time the client was\ndisconnected are lost.\nType of events\nKeyspace notifications are implemented by sending two distinct types of events\nfor every operation affecting the Redis data space. For instance a `DEL`\noperation targeting the key named `mykey` in database `0` will trigger\nthe delivering of two messages, exactly equivalent to the following two\n`PUBLISH` commands:\n\n\n```PUBLISH __keyspace@0__:mykey del\nPUBLISH __keyevent@0__:del mykey\n```\n\n\nThe first channel listens to all the events targeting\nthe key `mykey` and the other channel listens only to `del` operation\nevents on the key `mykey`\nThe first kind of event, with `keyspace` prefix in the channel is called\na Key-space notification, while the second, with the `keyevent` prefix,\nis called a Key-event notification.\nIn the previous example a `del` event was generated for the key `mykey` resulting\nin two messages:\n\nThe Key-space channel receives as message the name of the event.\nThe Key-event channel receives as message the name of the key.\n\nIt is possible to enable only one kind of notification in order to deliver\njust the subset of events we are interested in.\nConfiguration\nBy default keyspace event notifications are disabled because while not\nvery sensible the feature uses some CPU power. Notifications are enabled\nusing the `notify-keyspace-events` of redis.conf or via the CONFIG SET.\nSetting the parameter to the empty string disables notifications.\nIn order to enable the feature a non-empty string is used, composed of multiple\ncharacters, where every character has a special meaning according to the\nfollowing table:\n\n\n```K     Keyspace events, published with __keyspace@<db>__ prefix.\nE     Keyevent events, published with __keyevent@<db>__ prefix.\ng     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...\n$     String commands\nl     List commands\ns     Set commands\nh     Hash commands\nz     Sorted set commands\nt     Stream commands\nd     Module key type events\nx     Expired events (events generated every time a key expires)\ne     Evicted events (events generated when a key is evicted for maxmemory)\nm     Key miss events (events generated when a key that doesn't exist is accessed)\nn     New key events (Note: not included in the 'A' class)\nA     Alias for \"g$lshztxed\", so that the \"AKE\" string means all the events except \"m\" and \"n\".\n```\n\n\nAt least `K` or `E` should be present in the string, otherwise no event\nwill be delivered regardless of the rest of the string.\nFor instance to enable just Key-space events for lists, the configuration\nparameter must be set to `Kl`, and so forth.\nYou can use the string `KEA` to enable most types of events.\nEvents generated by different commands\nDifferent commands generate different kind of events according to the following list.\n\n`DEL` generates a `del` event for every deleted key.\n`RENAME` generates two events, a `rename_from` event for the source key, and a `rename_to` event for the destination key.\n`MOVE` generates two events, a `move_from` event for the source key, and a `move_to` event for the destination key.\n`COPY` generates a `copy_to` event.\n`MIGRATE` generates a `del` event if the source key is removed.\n`RESTORE` generates a `restore` event for the key.\n`EXPIRE` and all its variants (`PEXPIRE`, `EXPIREAT`, `PEXPIREAT`) generate an `expire` event when called with a positive timeout (or a future timestamp). Note that when these commands are called with a negative timeout value or timestamp in the past, the key is deleted and only a `del` event is generated instead.\n`SORT` generates a `sortstore` event when `STORE` is used to set a new key. If the resulting list is empty, and the `STORE` option is used, and there was already an existing key with that name, the result is that the key is deleted, so a `del` event is generated in this condition.\n`SET` and all its variants (`SETEX`, `SETNX`,`GETSET`) generate `set` events. However `SETEX` will also generate an `expire` events.\n`MSET` generates a separate `set` event for every key.\n`SETRANGE` generates a `setrange` event.\n`INCR`, `DECR`, `INCRBY`, `DECRBY` commands all generate `incrby` events.\n`INCRBYFLOAT` generates an `incrbyfloat` events.\n`APPEND` generates an `append` event.\n`LPUSH` and `LPUSHX` generates a single `lpush` event, even in the variadic case.\n`RPUSH` and `RPUSHX` generates a single `rpush` event, even in the variadic case.\n`RPOP` generates an `rpop` event. Additionally a `del` event is generated if the key is removed because the last element from the list was popped.\n`LPOP` generates an `lpop` event. Additionally a `del` event is generated if the key is removed because the last element from the list was popped.\n`LINSERT` generates an `linsert` event.\n`LSET` generates an `lset` event.\n`LREM` generates an `lrem` event, and additionally a `del` event if the resulting list is empty and the key is removed.\n`LTRIM` generates an `ltrim` event, and additionally a `del` event if the resulting list is empty and the key is removed.\n`RPOPLPUSH` and `BRPOPLPUSH` generate an `rpop` event and an `lpush` event. In both cases the order is guaranteed (the `lpush` event will always be delivered after the `rpop` event). Additionally a `del` event will be generated if the resulting list is zero length and the key is removed.\n`LMOVE` and `BLMOVE` generate an `lpop`/`rpop` event (depending on the wherefrom argument) and an `lpush`/`rpush` event (depending on the whereto argument). In both cases the order is guaranteed (the `lpush`/`rpush` event will always be delivered after the `lpop`/`rpop` event). Additionally a `del` event will be generated if the resulting list is zero length and the key is removed.\n`HSET`, `HSETNX` and `HMSET` all generate a single `hset` event.\n`HINCRBY` generates an `hincrby` event.\n`HINCRBYFLOAT` generates an `hincrbyfloat` event.\n`HDEL` generates a single `hdel` event, and an additional `del` event if the resulting hash is empty and the key is removed.\n`SADD` generates a single `sadd` event, even in the variadic case.\n`SREM` generates a single `srem` event, and an additional `del` event if the resulting set is empty and the key is removed.\n`SMOVE` generates an `srem` event for the source key, and an `sadd` event for the destination key.\n`SPOP` generates an `spop` event, and an additional `del` event if the resulting set is empty and the key is removed.\n`SINTERSTORE`, `SUNIONSTORE`, `SDIFFSTORE` generate `sinterstore`, `sunionstore`, `sdiffstore` events respectively. In the special case the resulting set is empty, and the key where the result is stored already exists, a `del` event is generated since the key is removed.\n`ZINCR` generates a `zincr` event.\n`ZADD` generates a single `zadd` event even when multiple elements are added.\n`ZREM` generates a single `zrem` event even when multiple elements are deleted. When the resulting sorted set is empty and the key is generated, an additional `del` event is generated.\n`ZREMBYSCORE` generates a single `zrembyscore` event. When the resulting sorted set is empty and the key is generated, an additional `del` event is generated.\n`ZREMBYRANK` generates a single `zrembyrank` event. When the resulting sorted set is empty and the key is generated, an additional `del` event is generated.\n`ZDIFFSTORE`, `ZINTERSTORE` and `ZUNIONSTORE` respectively generate `zdiffstore`, `zinterstore` and `zunionstore` events. In the special case the resulting sorted set is empty, and the key where the result is stored already exists, a `del` event is generated since the key is removed.\n`XADD` generates an `xadd` event, possibly followed an `xtrim` event when used with the `MAXLEN` subcommand.\n`XDEL` generates a single `xdel` event even when multiple entries are deleted.\n`XGROUP CREATE` generates an `xgroup-create` event.\n`XGROUP CREATECONSUMER` generates an `xgroup-createconsumer` event.\n`XGROUP DELCONSUMER` generates an `xgroup-delconsumer` event.\n`XGROUP DESTROY` generates an `xgroup-destroy` event.\n`XGROUP SETID` generates an `xgroup-setid` event.\n`XSETID` generates an `xsetid` event.\n`XTRIM` generates an `xtrim` event.\n`PERSIST` generates a `persist` event if the expiry time associated with key has been successfully deleted.\nEvery time a key with a time to live associated is removed from the data set because it expired, an `expired` event is generated.\nEvery time a key is evicted from the data set in order to free memory as a result of the `maxmemory` policy, an `evicted` event is generated.\nEvery time a new key is added to the data set, a `new` event is generated.\n\nIMPORTANT all the commands generate events only if the target key is really modified. For instance an `SREM` deleting a non-existing element from a Set will not actually change the value of the key, so no event will be generated.\nIf in doubt about how events are generated for a given command, the simplest\nthing to do is to watch yourself:\n\n\n```$ redis-cli config set notify-keyspace-events KEA\n$ redis-cli --csv psubscribe '__key*__:*'\nReading messages... (press Ctrl-C to quit)\n\"psubscribe\",\"__key*__:*\",1\n```\n\n\nAt this point use `redis-cli` in another terminal to send commands to the\nRedis server and watch the events generated:\n\n\n```\"pmessage\",\"__key*__:*\",\"__keyspace@0__:foo\",\"set\"\n\"pmessage\",\"__key*__:*\",\"__keyevent@0__:set\",\"foo\"\n...\n```\n\n\nTiming of expired events\nKeys with a time to live associated are expired by Redis in two ways:\n\nWhen the key is accessed by a command and is found to be expired.\nVia a background system that looks for expired keys in the background, incrementally, in order to be able to also collect keys that are never accessed.\n\nThe `expired` events are generated when a key is accessed and is found to be expired by one of the above systems, as a result there are no guarantees that the Redis server will be able to generate the `expired` event at the time the key time to live reaches the value of zero.\nIf no command targets the key constantly, and there are many keys with a TTL associated, there can be a significant delay between the time the key time to live drops to zero, and the time the `expired` event is generated.\nBasically `expired` events are generated when the Redis server deletes the key and not when the time to live theoretically reaches the value of zero.\nEvents in a cluster\nEvery node of a Redis cluster generates events about its own subset of the keyspace as described above. However, unlike regular Pub/Sub communication in a cluster, events' notifications are not broadcasted to all nodes. Put differently, keyspace events are node-specific. This means that to receive all keyspace events of a cluster, clients need to subscribe to each of the nodes.\n@history\n\n`>= 6.0`: Key miss events were added.\n`>= 7.0`: Event type `new` added\n",
    "tag": "redis"
  },
  {
    "title": "There are two hard problems in computer science...",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/client-side-caching.md",
    "content": "\ntitle: \"Client-side caching in Redis\"\nlinkTitle: \"Client-side caching\"\nweight: 1\ndescription: >\n    Server-assisted, client-side caching in Redis\naliases:\n    - /topics/client-side-caching\n\nClient-side caching is a technique used to create high performance services.\nIt exploits the memory available on application servers, servers that are\nusually distinct computers compared to the database nodes, to store some subset\nof the database information directly in the application side.\nNormally when data is required, the application servers ask the database about\nsuch information, like in the following diagram:\n\n\n```+-------------+                                +----------+\n|             | ------- GET user:1234 -------> |          |\n| Application |                                | Database |\n|             | <---- username = Alice ------- |          |\n+-------------+                                +----------+\n```\n\n\nWhen client-side caching is used, the application will store the reply of\npopular queries directly inside the application memory, so that it can\nreuse such replies later, without contacting the database again:\n\n\n```+-------------+                                +----------+\n|             |                                |          |\n| Application |       ( No chat needed )       | Database |\n|             |                                |          |\n+-------------+                                +----------+\n| Local cache |\n|             |\n| user:1234 = |\n| username    |\n| Alice       |\n+-------------+\n```\n\n\nWhile the application memory used for the local cache may not be very big,\nthe time needed in order to access the local computer memory is orders of\nmagnitude smaller compared to accessing a networked service like a database.\nSince often the same small percentage of data are accessed frequently,\nthis pattern can greatly reduce the latency for the application to get data\nand, at the same time, the load in the database side.\nMoreover there are many datasets where items change very infrequently.\nFor instance, most user posts in a social network are either immutable or\nrarely edited by the user. Adding to this the fact that usually a small\npercentage of the posts are very popular, either because a small set of users\nhave a lot of followers and/or because recent posts have a lot more\nvisibility, it is clear why such a pattern can be very useful.\nUsually the two key advantages of client-side caching are:\n\nData is available with a very small latency.\nThe database system receives less queries, allowing it to serve the same dataset with a smaller number of nodes.\n\nThere are two hard problems in computer science...\nA problem with the above pattern is how to invalidate the information that\nthe application is holding, in order to avoid presenting stale data to the\nuser. For example after the application above locally cached the information\nfor user:1234, Alice may update her username to Flora. Yet the application\nmay continue to serve the old username for user:1234.\nSometimes, depending on the exact application we are modeling, this isn't a\nbig deal, so the client will just use a fixed maximum \"time to live\" for the\ncached information. Once a given amount of time has elapsed, the information\nwill no longer be considered valid. More complex patterns, when using Redis,\nleverage the Pub/Sub system in order to send invalidation messages to\nlistening clients. This can be made to work but is tricky and costly from\nthe point of view of the bandwidth used, because often such patterns involve\nsending the invalidation messages to every client in the application, even\nif certain clients may not have any copy of the invalidated data. Moreover\nevery application query altering the data requires to use the `PUBLISH`\ncommand, costing the database more CPU time to process this command.\nRegardless of what schema is used, there is a simple fact: many very large\napplications implement some form of client-side caching, because it is the\nnext logical step to having a fast store or a fast cache server. For this\nreason Redis 6 implements direct support for client-side caching, in order\nto make this pattern much simpler to implement, more accessible, reliable,\nand efficient.\nThe Redis implementation of client-side caching\nThe Redis client-side caching support is called Tracking, and has two modes:\n\nIn the default mode, the server remembers what keys a given client accessed, and sends invalidation messages when the same keys are modified. This costs memory in the server side, but sends invalidation messages only for the set of keys that the client might have in memory.\nIn the broadcasting mode, the server does not attempt to remember what keys a given client accessed, so this mode costs no memory at all in the server side. Instead clients subscribe to key prefixes such as `object:` or `user:`, and receive a notification message every time a key matching a subscribed prefix is touched.\n\nTo recap, for now let's forget for a moment about the broadcasting mode, to\nfocus on the first mode. We'll describe broadcasting in more detail later.\n\nClients can enable tracking if they want. Connections start without tracking enabled.\nWhen tracking is enabled, the server remembers what keys each client requested during the connection lifetime (by sending read commands about such keys).\nWhen a key is modified by some client, or is evicted because it has an associated expire time, or evicted because of a maxmemory policy, all the clients with tracking enabled that may have the key cached, are notified with an invalidation message.\nWhen clients receive invalidation messages, they are required to remove the corresponding keys, in order to avoid serving stale data.\n\nThis is an example of the protocol:\n\nClient 1 `->` Server: CLIENT TRACKING ON\nClient 1 `->` Server: GET foo\n(The server remembers that Client 1 may have the key \"foo\" cached)\n(Client 1 may remember the value of \"foo\" inside its local memory)\nClient 2 `->` Server: SET foo SomeOtherValue\nServer `->` Client 1: INVALIDATE \"foo\"\n\nThis looks great superficially, but if you imagine 10k connected clients all\nasking for millions of keys over long living connection, the server ends up\nstoring too much information. For this reason Redis uses two key ideas in\norder to limit the amount of memory used server-side and the CPU cost of\nhandling the data structures implementing the feature:\n\nThe server remembers the list of clients that may have cached a given key in a single global table. This table is called the Invalidation Table. The invalidation table can contain a maximum number of entries. If a new key is inserted, the server may evict an older entry by pretending that such key was modified (even if it was not), and sending an invalidation message to the clients. Doing so, it can reclaim the memory used for this key, even if this will force the clients having a local copy of the key to evict it.\nInside the invalidation table we don't really need to store pointers to clients' structures, that would force a garbage collection procedure when the client disconnects: instead what we do is just store client IDs (each Redis client has a unique numerical ID). If a client disconnects, the information will be incrementally garbage collected as caching slots are invalidated.\nThere is a single keys namespace, not divided by database numbers. So if a client is caching the key `foo` in database 2, and some other client changes the value of the key `foo` in database 3, an invalidation message will still be sent. This way we can ignore database numbers reducing both the memory usage and the implementation complexity.\n\nTwo connections mode\nUsing the new version of the Redis protocol, RESP3, supported by Redis 6, it is possible to run the data queries and receive the invalidation messages in the same connection. However many client implementations may prefer to implement client-side caching using two separated connections: one for data, and one for invalidation messages. For this reason when a client enables tracking, it can specify to redirect the invalidation messages to another connection by specifying the \"client ID\" of a different connection. Many data connections can redirect invalidation messages to the same connection, this is useful for clients implementing connection pooling. The two connections model is the only one that is also supported for RESP2 (which lacks the ability to multiplex different kind of information in the same connection).\nHere's an example of a complete session using the Redis protocol in the old RESP2 mode involving the following steps: enabling tracking redirecting to another connection, asking for a key, and getting an invalidation message once the key gets modified.\nTo start, the client opens a first connection that will be used for invalidations, requests the connection ID, and subscribes via Pub/Sub to the special channel that is used to get invalidation messages when in RESP2 modes (remember that RESP2 is the usual Redis protocol, and not the more advanced protocol that you can use, optionally, with Redis 6 using the `HELLO` command):\n`(Connection 1 -- used for invalidations)\nCLIENT ID\n:4\nSUBSCRIBE __redis__:invalidate\n*3\n$9\nsubscribe\n$20\n__redis__:invalidate\n:1`\nNow we can enable tracking from the data connection:\n```\n(Connection 2 -- data connection)\nCLIENT TRACKING on REDIRECT 4\n+OK\nGET foo\n$3\nbar\n```\nThe client may decide to cache `\"foo\" => \"bar\"` in the local memory.\nA different client will now modify the value of the \"foo\" key:\n`(Some other unrelated connection)\nSET foo bar\n+OK`\nAs a result, the invalidations connection will receive a message that invalidates the specified key.\n`(Connection 1 -- used for invalidations)\n*3\n$7\nmessage\n$20\n__redis__:invalidate\n*1\n$3\nfoo`\nThe client will check if there are cached keys in this caching slot, and will evict the information that is no longer valid.\nNote that the third element of the Pub/Sub message is not a single key but\nis a Redis array with just a single element. Since we send an array, if there\nare groups of keys to invalidate, we can do that in a single message.\nIn case of a flush (`FLUSHALL` or `FLUSHDB`), a `null` message will be sent.\nA very important thing to understand about client-side caching used with\nRESP2 and a Pub/Sub connection in order to read the invalidation messages,\nis that using Pub/Sub is entirely a trick in order to reuse old client\nimplementations, but actually the message is not really sent to a channel\nand received by all the clients subscribed to it. Only the connection we\nspecified in the `REDIRECT` argument of the `CLIENT` command will actually\nreceive the Pub/Sub message, making the feature a lot more scalable.\nWhen RESP3 is used instead, invalidation messages are sent (either in the\nsame connection, or in the secondary connection when redirection is used)\nas `push` messages (read the RESP3 specification for more information).\nWhat tracking tracks\nAs you can see clients do not need, by default, to tell the server what keys\nthey are caching. Every key that is mentioned in the context of a read-only\ncommand is tracked by the server, because it could be cached.\nThis has the obvious advantage of not requiring the client to tell the server\nwhat it is caching. Moreover in many clients implementations, this is what\nyou want, because a good solution could be to just cache everything that is not\nalready cached, using a first-in first-out approach: we may want to cache a\nfixed number of objects, every new data we retrieve, we could cache it,\ndiscarding the oldest cached object. More advanced implementations may instead\ndrop the least used object or alike.\nNote that anyway if there is write traffic on the server, caching slots\nwill get invalidated during the course of the time. In general when the\nserver assumes that what we get we also cache, we are making a tradeoff:\n\nIt is more efficient when the client tends to cache many things with a policy that welcomes new objects.\nThe server will be forced to retain more data about the client keys.\nThe client will receive useless invalidation messages about objects it did not cache.\n\nSo there is an alternative described in the next section.\nOpt-in caching\nClients implementations may want to cache only selected keys, and communicate\nexplicitly to the server what they'll cache and what they will not. This will\nrequire more bandwidth when caching new objects, but at the same time reduces\nthe amount of data that the server has to remember and the amount of\ninvalidation messages received by the client.\nIn order to do this, tracking must be enabled using the OPTIN option:\n\n\n```CLIENT TRACKING on REDIRECT 1234 OPTIN\n```\n\n\nIn this mode, by default, keys mentioned in read queries are not supposed to be cached, instead when a client wants to cache something, it must send a special command immediately before the actual command to retrieve the data:\n\n\n```CLIENT CACHING YES\n+OK\nGET foo\n\"bar\"\n```\n\n\nThe `CACHING` command affects the command executed immediately after it,\nhowever in case the next command is `MULTI`, all the commands in the\ntransaction will be tracked. Similarly in case of Lua scripts, all the\ncommands executed by the script will be tracked.\nBroadcasting mode\nSo far we described the first client-side caching model that Redis implements.\nThere is another one, called broadcasting, that sees the problem from the\npoint of view of a different tradeoff, does not consume any memory on the\nserver side, but instead sends more invalidation messages to clients.\nIn this mode we have the following main behaviors:\n\nClients enable client-side caching using the `BCAST` option, specifying one or more prefixes using the `PREFIX` option. For instance: `CLIENT TRACKING on REDIRECT 10 BCAST PREFIX object: PREFIX user:`. If no prefix is specified at all, the prefix is assumed to be the empty string, so the client will receive invalidation messages for every key that gets modified. Instead if one or more prefixes are used, only keys matching one of the specified prefixes will be sent in the invalidation messages.\nThe server does not store anything in the invalidation table. Instead it uses a different Prefixes Table, where each prefix is associated to a list of clients.\nNo two prefixes can track overlapping parts of the keyspace. For instance, having the prefix \"foo\" and \"foob\" would not be allowed, since they would both trigger an invalidation for the key \"foobar\". However, just using the prefix \"foo\" is sufficient.\nEvery time a key matching any of the prefixes is modified, all the clients subscribed to that prefix, will receive the invalidation message.\nThe server will consume CPU proportional to the number of registered prefixes. If you have just a few, it is hard to see any difference. With a big number of prefixes the CPU cost can become quite large.\nIn this mode the server can perform the optimization of creating a single reply for all the clients subscribed to a given prefix, and send the same reply to all. This helps to lower the CPU usage.\n\nThe NOLOOP option\nBy default client-side tracking will send invalidation messages to the\nclient that modified the key. Sometimes clients want this, since they\nimplement very basic logic that does not involve automatically caching\nwrites locally. However, more advanced clients may want to cache even the\nwrites they are doing in the local in-memory table. In such case receiving\nan invalidation message immediately after the write is a problem, since it\nwill force the client to evict the value it just cached.\nIn this case it is possible to use the `NOLOOP` option: it works both\nin normal and broadcasting mode. Using this option, clients are able to\ntell the server they don't want to receive invalidation messages for keys\nthat they modified.\nAvoiding race conditions\nWhen implementing client-side caching redirecting the invalidation messages\nto a different connection, you should be aware that there is a possible\nrace condition. See the following example interaction, where we'll call\nthe data connection \"D\" and the invalidation connection \"I\":\n\n\n```[D] client -> server: GET foo\n[I] server -> client: Invalidate foo (somebody else touched it)\n[D] server -> client: \"bar\" (the reply of \"GET foo\")\n```\n\n\nAs you can see, because the reply to the GET was slower to reach the\nclient, we received the invalidation message before the actual data that\nis already no longer valid. So we'll keep serving a stale version of the\nfoo key. To avoid this problem, it is a good idea to populate the cache\nwhen we send the command with a placeholder:\n\n\n```Client cache: set the local copy of \"foo\" to \"caching-in-progress\"\n[D] client-> server: GET foo.\n[I] server -> client: Invalidate foo (somebody else touched it)\nClient cache: delete \"foo\" from the local cache.\n[D] server -> client: \"bar\" (the reply of \"GET foo\")\nClient cache: don't set \"bar\" since the entry for \"foo\" is missing.\n```\n\n\nSuch a race condition is not possible when using a single connection for both\ndata and invalidation messages, since the order of the messages is always known\nin that case.\nWhat to do when losing connection with the server\nSimilarly, if we lost the connection with the socket we use in order to\nget the invalidation messages, we may end with stale data. In order to avoid\nthis problem, we need to do the following things:\n\nMake sure that if the connection is lost, the local cache is flushed.\nBoth when using RESP2 with Pub/Sub, or RESP3, ping the invalidation channel periodically (you can send PING commands even when the connection is in Pub/Sub mode!). If the connection looks broken and we are not able to receive ping backs, after a maximum amount of time, close the connection and flush the cache.\n\nWhat to cache\nClients may want to run internal statistics about the number of times\na given cached key was actually served in a request, to understand in the\nfuture what is good to cache. In general:\n\nWe don't want to cache many keys that change continuously.\nWe don't want to cache many keys that are requested very rarely.\nWe want to cache keys that are requested often and change at a reasonable rate. For an example of key not changing at a reasonable rate, think of a global counter that is continuously `INCR`emented.\n\nHowever simpler clients may just evict data using some random sampling just\nremembering the last time a given cached value was served, trying to evict\nkeys that were not served recently.\nOther hints for implementing client libraries\n\nHandling TTLs: make sure you also request the key TTL and set the TTL in the local cache if you want to support caching keys with a TTL.\nPutting a max TTL on every key is a good idea, even if it has no TTL. This protects against bugs or connection issues that would make the client have old data in the local copy.\nLimiting the amount of memory used by clients is absolutely needed. There must be a way to evict old keys when new ones are added.\n\nLimiting the amount of memory used by Redis\nBe sure to configure a suitable value for the maximum number of keys remembered by Redis or alternatively use the BCAST mode that consumes no memory at all on the Redis side. Note that the memory consumed by Redis when BCAST is not used, is proportional both to the number of keys tracked and the number of clients requesting such keys.",
    "tag": "redis"
  },
  {
    "title": "Usage",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/transactions.md",
    "content": "\ntitle: Transactions\nlinkTitle: Transactions\nweight: 5\ndescription: How transactions work in Redis\naliases:\n  - /topics/transactions\n\nRedis Transactions allow the execution of a group of commands\nin a single step, they are centered around the commands \n`MULTI`, `EXEC`, `DISCARD` and `WATCH`.\nRedis Transactions make two important guarantees:\n\n\nAll the commands in a transaction are serialized and executed\nsequentially. A request sent by another client will never be\nserved in the middle of the execution of a Redis Transaction.\nThis guarantees that the commands are executed as a single\nisolated operation.\n\n\nThe `EXEC` command\ntriggers the execution of all the commands in the transaction, so\nif a client loses the connection to the server in the context of a\ntransaction before calling the `EXEC` command none of the operations\nare performed, instead if the `EXEC` command is called, all the\noperations are performed. When using the\nappend-only file Redis makes sure\nto use a single write(2) syscall to write the transaction on disk.\nHowever if the Redis server crashes or is killed by the system administrator\nin some hard way it is possible that only a partial number of operations\nare registered. Redis will detect this condition at restart, and will exit with an error.\nUsing the `redis-check-aof` tool it is possible to fix the\nappend only file that will remove the partial transaction so that the\nserver can start again.\n\n\nStarting with version 2.2, Redis allows for an extra guarantee to the\nabove two, in the form of optimistic locking in a way very similar to a\ncheck-and-set (CAS) operation.\nThis is documented later on this page.\nUsage\nA Redis Transaction is entered using the `MULTI` command. The command\nalways replies with `OK`. At this point the user can issue multiple\ncommands. Instead of executing these commands, Redis will queue\nthem. All the commands are executed once `EXEC` is called.\nCalling `DISCARD` instead will flush the transaction queue and will exit\nthe transaction.\nThe following example increments keys `foo` and `bar` atomically.\n```\n\nMULTI\nOK\nINCR foo\nQUEUED\nINCR bar\nQUEUED\nEXEC\n1) (integer) 1\n2) (integer) 1\n```\n\nAs is clear from the session above, `EXEC` returns an\narray of replies, where every element is the reply of a single command\nin the transaction, in the same order the commands were issued.\nWhen a Redis connection is in the context of a `MULTI` request,\nall commands will reply with the string `QUEUED` (sent as a Status Reply\nfrom the point of view of the Redis protocol). A queued command is\nsimply scheduled for execution when `EXEC` is called.\nErrors inside a transaction\nDuring a transaction it is possible to encounter two kind of command errors:\n\nA command may fail to be queued, so there may be an error before `EXEC` is called.\nFor instance the command may be syntactically wrong (wrong number of arguments,\nwrong command name, ...), or there may be some critical condition like an out of\nmemory condition (if the server is configured to have a memory limit using the `maxmemory` directive).\nA command may fail after `EXEC` is called, for instance since we performed\nan operation against a key with the wrong value (like calling a list operation against a string value).\n\nStarting with Redis 2.6.5, the server will detect an error during the accumulation of commands.\nIt will then refuse to execute the transaction returning an error during `EXEC`, discarding the transaction.\n\nNote for Redis < 2.6.5: Prior to Redis 2.6.5 clients needed to detect errors occurring prior to `EXEC` by checking\nthe return value of the queued command: if the command replies with QUEUED it was\nqueued correctly, otherwise Redis returns an error.\nIf there is an error while queueing a command, most clients\nwill abort and discard the transaction. Otherwise, if the client elected to proceed with the transaction\nthe `EXEC` command would execute all commands queued successfully regardless of previous errors.\n\nErrors happening after `EXEC` instead are not handled in a special way:\nall the other commands will be executed even if some command fails during the transaction.\nThis is more clear on the protocol level. In the following example one\ncommand will fail when executed even if the syntax is right:\n`Trying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\nMULTI\n+OK\nSET a abc\n+QUEUED\nLPOP a\n+QUEUED\nEXEC\n*2\n+OK\n-ERR Operation against a key holding the wrong kind of value`\n`EXEC` returned two-element bulk string reply where one is an `OK` code and\nthe other an `-ERR` reply. It's up to the client library to find a\nsensible way to provide the error to the user.\nIt's important to note that\neven when a command fails, all the other commands in the queue are processed \u2013 Redis will not stop the\nprocessing of commands.\nAnother example, again using the wire protocol with `telnet`, shows how\nsyntax errors are reported ASAP instead:\n`MULTI\n+OK\nINCR a b c\n-ERR wrong number of arguments for 'incr' command`\nThis time due to the syntax error the bad `INCR` command is not queued\nat all.\nWhat about rollbacks?\nRedis does not support rollbacks of transactions since supporting rollbacks\nwould have a significant impact on the simplicity and performance of Redis.\nDiscarding the command queue\n`DISCARD` can be used in order to abort a transaction. In this case, no\ncommands are executed and the state of the connection is restored to\nnormal.\n```\n\nSET foo 1\nOK\nMULTI\nOK\nINCR foo\nQUEUED\nDISCARD\nOK\nGET foo\n\"1\"\n```\n\n\nOptimistic locking using check-and-set\n`WATCH` is used to provide a check-and-set (CAS) behavior to Redis\ntransactions.\n`WATCH`ed keys are monitored in order to detect changes against them. If\nat least one watched key is modified before the `EXEC` command, the\nwhole transaction aborts, and `EXEC` returns a Null reply to notify that\nthe transaction failed.\nFor example, imagine we have the need to atomically increment the value\nof a key by 1 (let's suppose Redis doesn't have `INCR`).\nThe first try may be the following:\n`val = GET mykey\nval = val + 1\nSET mykey $val`\nThis will work reliably only if we have a single client performing the\noperation in a given time. If multiple clients try to increment the key\nat about the same time there will be a race condition. For instance,\nclient A and B will read the old value, for instance, 10. The value will\nbe incremented to 11 by both the clients, and finally `SET` as the value\nof the key. So the final value will be 11 instead of 12.\nThanks to `WATCH` we are able to model the problem very well:\n`WATCH mykey\nval = GET mykey\nval = val + 1\nMULTI\nSET mykey $val\nEXEC`\nUsing the above code, if there are race conditions and another client\nmodifies the result of `val` in the time between our call to `WATCH` and\nour call to `EXEC`, the transaction will fail.\nWe just have to repeat the operation hoping this time we'll not get a\nnew race. This form of locking is called optimistic locking.\nIn many use cases, multiple clients will be accessing different keys,\nso collisions are unlikely \u2013 usually there's no need to repeat the operation.\nWATCH explained\nSo what is `WATCH` really about? It is a command that will\nmake the `EXEC` conditional: we are asking Redis to perform\nthe transaction only if none of the `WATCH`ed keys were modified. This includes\nmodifications made by the client, like write commands, and by Redis itself,\nlike expiration or eviction. If keys were modified between when they were\n`WATCH`ed and when the `EXEC` was received, the entire transaction will be aborted\ninstead.\nNOTE\n* In Redis versions before 6.0.9, an expired key would not cause a transaction\nto be aborted. More on this\n* Commands within a transaction won't trigger the `WATCH` condition since they\nare only queued until the `EXEC` is sent.\n`WATCH` can be called multiple times. Simply all the `WATCH` calls will\nhave the effects to watch for changes starting from the call, up to\nthe moment `EXEC` is called. You can also send any number of keys to a\nsingle `WATCH` call.\nWhen `EXEC` is called, all keys are `UNWATCH`ed, regardless of whether\nthe transaction was aborted or not.  Also when a client connection is\nclosed, everything gets `UNWATCH`ed.\nIt is also possible to use the `UNWATCH` command (without arguments)\nin order to flush all the watched keys. Sometimes this is useful as we\noptimistically lock a few keys, since possibly we need to perform a\ntransaction to alter those keys, but after reading the current content\nof the keys we don't want to proceed.  When this happens we just call\n`UNWATCH` so that the connection can already be used freely for new\ntransactions.\nUsing WATCH to implement ZPOP\nA good example to illustrate how `WATCH` can be used to create new\natomic operations otherwise not supported by Redis is to implement ZPOP\n(`ZPOPMIN`, `ZPOPMAX` and their blocking variants have only been added\nin version 5.0), that is a command that pops the element with the lower\nscore from a sorted set in an atomic way. This is the simplest\nimplementation:\n`WATCH zset\nelement = ZRANGE zset 0 0\nMULTI\nZREM zset element\nEXEC`\nIf `EXEC` fails (i.e. returns a Null reply) we just repeat the operation.\nRedis scripting and transactions\nSomething else to consider for transaction like operations in redis are\nredis scripts which are transactional. Everything\nyou can do with a Redis Transaction, you can also do with a script, and",
    "tag": "redis"
  },
  {
    "title": "twitter-clone.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/patterns/twitter-clone.md",
    "content": "\ntitle: \"Redis patterns example\"\nlinkTitle: \"Patterns example\"\ndescription: Learn several Redis patterns by building a Twitter clone\nweight: 20\naliases: [\n    /docs/reference/patterns/twitter-clone\n]\n\nThis article describes the design and implementation of a very simple Twitter clone written using PHP with Redis as the only database. The programming community has traditionally considered key-value stores as a special purpose database that couldn't be used as a drop-in replacement for a relational database for the development of web applications. This article will try to show that Redis data structures on top of a key-value layer are an effective data model to implement many kinds of applications.\nNote: the original version of this article was written in 2009 when Redis was\nreleased. It was not exactly clear at that time that the Redis data model was\nsuitable to write entire applications. Now after 5 years there are many cases of\napplications using Redis as their main store, so the goal of the article today\nis to be a tutorial for Redis newcomers. You'll learn how to design a simple\ndata layout using Redis, and how to apply different data structures.\nOur Twitter clone, called Retwis, is structurally simple, has very good performance, and can be distributed among any number of web and Redis servers with little efforts. View the Retwis source code.\nI used PHP for the example since it can be read by everybody. The same (or better) results can be obtained using Ruby, Python, Erlang, and so on.\nA few clones exist (however not all the clones use the same data layout as the\ncurrent version of this tutorial, so please, stick with the official PHP\nimplementation for the sake of following the article better).\n\nRetwis-RB is a port of Retwis to Ruby and Sinatra written by Daniel Lucraft.\nRetwis-J is a port of Retwis to Java, using the Spring Data Framework, written by Costin Leau. Its source code can be found on GitHub, and there is comprehensive documentation available at springsource.org.\n\nWhat is a key-value store?\nThe essence of a key-value store is the ability to store some data, called a value, inside a key. The value can be retrieved later only if we know the specific key it was stored in. There is no direct way to search for a key by value. In some sense, it is like a very large hash/dictionary, but it is persistent, i.e. when your application ends, the data doesn't go away. So, for example, I can use the command `SET` to store the value bar in the key foo:\n\n\n```SET foo bar\n```\n\n\nRedis stores data permanently, so if I later ask \"What is the value stored in key foo?\" Redis will reply with bar:\n\n\n```GET foo => bar\n```\n\n\nOther common operations provided by key-value stores are `DEL`, to delete a given key and its associated value, SET-if-not-exists (called `SETNX` on Redis), to assign a value to a key only if the key does not already exist, and `INCR`, to atomically increment a number stored in a given key:\n\n\n```SET foo 10\nINCR foo => 11\nINCR foo => 12\nINCR foo => 13\n```\n\n\nAtomic operations\nThere is something special about `INCR`. You may wonder why Redis provides such an operation if we can do it ourselves with a bit of code? After all, it is as simple as:\n\n\n```x = GET foo\nx = x + 1\nSET foo x\n```\n\n\nThe problem is that incrementing this way will work as long as there is only one client working with the key foo at one time. See what happens if two clients are accessing this key at the same time:\n\n\n```x = GET foo (yields 10)\ny = GET foo (yields 10)\nx = x + 1 (x is now 11)\ny = y + 1 (y is now 11)\nSET foo x (foo is now 11)\nSET foo y (foo is now 11)\n```\n\n\nSomething is wrong! We incremented the value two times, but instead of going from 10 to 12, our key holds 11. This is because the increment done with `GET / increment / SET` is not an atomic operation. Instead the INCR provided by Redis, Memcached, ..., are atomic implementations, and the server will take care of protecting the key during the time needed to complete the increment in order to prevent simultaneous accesses.\nWhat makes Redis different from other key-value stores is that it provides other operations similar to INCR that can be used to model complex problems. This is why you can use Redis to write whole web applications without using another database like an SQL database, and without going crazy.\nBeyond key-value stores: lists\nIn this section we will see which Redis features we need to build our Twitter clone. The first thing to know is that Redis values can be more than strings. Redis supports Lists, Sets, Hashes, Sorted Sets, Bitmaps, and HyperLogLog types as values, and there are atomic operations to operate on them so we are safe even with multiple accesses to the same key. Let's start with Lists:\n\n\n```LPUSH mylist a (now mylist holds 'a')\nLPUSH mylist b (now mylist holds 'b','a')\nLPUSH mylist c (now mylist holds 'c','b','a')\n```\n\n\n`LPUSH` means Left Push, that is, add an element to the left (or to the head) of the list stored in mylist. If the key mylist does not exist it is automatically created as an empty list before the PUSH operation. As you can imagine, there is also an `RPUSH` operation that adds the element to the right of the list (on the tail). This is very useful for our Twitter clone. User updates can be added to a list stored in `username:updates`, for instance.\nThere are operations to get data from Lists, of course. For instance, LRANGE returns a range from the list, or the whole list.\n\n\n```LRANGE mylist 0 1 => c,b\n```\n\n\nLRANGE uses zero-based indexes - that is the first element is 0, the second 1, and so on. The command arguments are `LRANGE key first-index last-index`. The last-index argument can be negative, with a special meaning: -1 is the last element of the list, -2 the penultimate, and so on. So, to get the whole list use:\n\n\n```LRANGE mylist 0 -1 => c,b,a\n```\n\n\nOther important operations are LLEN that returns the number of elements in the list, and LTRIM that is like LRANGE but instead of returning the specified range trims the list, so it is like Get range from mylist, Set this range as new value but does so atomically.\nThe Set data type\nCurrently we don't use the Set type in this tutorial, but since we use\nSorted Sets, which are kind of a more capable version of Sets, it is better\nto start introducing Sets first (which are a very useful data structure\nper se), and later Sorted Sets.\nThere are more data types than just Lists. Redis also supports Sets, which are unsorted collections of elements. It is possible to add, remove, and test for existence of members, and perform the intersection between different Sets. Of course it is possible to get the elements of a Set. Some examples will make it more clear. Keep in mind that `SADD` is the add to set operation, `SREM` is the remove from set operation, `SISMEMBER` is the test if member operation, and `SINTER` is the perform intersection operation. Other operations are `SCARD` to get the cardinality (the number of elements) of a Set, and `SMEMBERS` to return all the members of a Set.\n\n\n```SADD myset a\nSADD myset b\nSADD myset foo\nSADD myset bar\nSCARD myset => 4\nSMEMBERS myset => bar,a,foo,b\n```\n\n\nNote that `SMEMBERS` does not return the elements in the same order we added them since Sets are unsorted collections of elements. When you want to store in order it is better to use Lists instead. Some more operations against Sets:\n\n\n```SADD mynewset b\nSADD mynewset foo\nSADD mynewset hello\nSINTER myset mynewset => foo,b\n```\n\n\n`SINTER` can return the intersection between Sets but it is not limited to two Sets. You may ask for the intersection of 4,5, or 10000 Sets. Finally let's check how `SISMEMBER` works:\n\n\n```SISMEMBER myset foo => 1\nSISMEMBER myset notamember => 0\n```\n\n\nThe Sorted Set data type\nSorted Sets are similar to Sets: collection of elements. However in Sorted\nSets each element is associated with a floating point value, called the\nelement score. Because of the score, elements inside a Sorted Set are\nordered, since we can always compare two elements by score (and if the score\nhappens to be the same, we compare the two elements as strings).\nLike Sets in Sorted Sets it is not possible to add repeated elements, every\nelement is unique. However it is possible to update an element's score.\nSorted Set commands are prefixed with `Z`. The following is an example\nof Sorted Sets usage:\n\n\n```ZADD zset 10 a\nZADD zset 5 b\nZADD zset 12.55 c\nZRANGE zset 0 -1 => b,a,c\n```\n\n\nIn the above example we added a few elements with `ZADD`, and later retrieved\nthe elements with `ZRANGE`. As you can see the elements are returned in order\naccording to their score. In order to check if a given element exists, and\nalso to retrieve its score if it exists, we use the `ZSCORE` command:\n\n\n```ZSCORE zset a => 10\nZSCORE zset non_existing_element => NULL\n```\n\n\nSorted Sets are a very powerful data structure, you can query elements by\nscore range, lexicographically, in reverse order, and so forth.\nTo know more please check the Sorted Set sections in the official Redis commands documentation.\nThe Hash data type\nThis is the last data structure we use in our program, and is extremely easy\nto gasp since there is an equivalent in almost every programming language out\nthere: Hashes. Redis Hashes are basically like Ruby or Python hashes, a\ncollection of fields associated with values:\n\n\n```HMSET myuser name Salvatore surname Sanfilippo country Italy\nHGET myuser surname => Sanfilippo\n```\n\n\n`HMSET` can be used to set fields in the hash, that can be retrieved with\n`HGET` later. It is possible to check if a field exists with `HEXISTS`, or\nto increment a hash field with `HINCRBY` and so forth.\nHashes are the ideal data structure to represent objects. For example we\nuse Hashes in order to represent Users and Updates in our Twitter clone.\nOkay, we just exposed the basics of the Redis main data structures,\nwe are ready to start coding!\nPrerequisites\nIf you haven't downloaded the Retwis source code already please grab it now. It contains a few PHP files, and also a copy of Predis, the PHP client library we use in this example.\nAnother thing you probably want is a working Redis server. Just get the source, build with `make`, run with `./redis-server`, and you're ready to go. No configuration is required at all in order to play with or run Retwis on your computer.\nData layout\nWhen working with a relational database, a database schema must be designed so that we'd know the tables, indexes, and so on that the database will contain. We don't have tables in Redis, so what do we need to design? We need to identify what keys are needed to represent our objects and what kind of values these keys need to hold.\nLet's start with Users. We need to represent users, of course, with their username, userid, password, the set of users following a given user, the set of users a given user follows, and so on. The first question is, how should we identify a user? Like in a relational DB, a good solution is to identify different users with different numbers, so we can associate a unique ID with every user. Every other reference to this user will be done by id. Creating unique IDs is very simple to do by using our atomic `INCR` operation. When we create a new user we can do something like this, assuming the user is called \"antirez\":\n\n\n```INCR next_user_id => 1000\nHMSET user:1000 username antirez password p1pp0\n```\n\n\nNote: you should use a hashed password in a real application, for simplicity\nwe store the password in clear text.\nWe use the `next_user_id` key in order to always get a unique ID for every new user. Then we use this unique ID to name the key holding a Hash with user's data. This is a common design pattern with key-values stores! Keep it in mind.\nBesides the fields already defined, we need some more stuff in order to fully define a User. For example, sometimes it can be useful to be able to get the user ID from the username, so every time we add a user, we also populate the `users` key, which is a Hash, with the username as field, and its ID as value.\n\n\n```HSET users antirez 1000\n```\n\n\nThis may appear strange at first, but remember that we are only able to access data in a direct way, without secondary indexes. It's not possible to tell Redis to return the key that holds a specific value. This is also our strength. This new paradigm is forcing us to organize data so that everything is accessible by primary key, speaking in relational DB terms.\nFollowers, following, and updates\nThere is another central need in our system. A user might have users who follow them, which we'll call their followers. A user might follow other users, which we'll call a following. We have a perfect data structure for this. That is... Sets.\nThe uniqueness of Sets elements, and the fact we can test in constant time for\nexistence, are two interesting features. However what about also remembering\nthe time at which a given user started following another one? In an enhanced\nversion of our simple Twitter clone this may be useful, so instead of using\na simple Set, we use a Sorted Set, using the user ID of the following or follower\nuser as element, and the unix time at which the relation between the users\nwas created, as our score.\nSo let's define our keys:\n\n\n```followers:1000 => Sorted Set of uids of all the followers users\nfollowing:1000 => Sorted Set of uids of all the following users\n```\n\n\nWe can add new followers with:\n\n\n```ZADD followers:1000 1401267618 1234 => Add user 1234 with time 1401267618\n```\n\n\nAnother important thing we need is a place were we can add the updates to display in the user's home page. We'll need to access this data in chronological order later, from the most recent update to the oldest, so the perfect kind of data structure for this is a List. Basically every new update will be `LPUSH`ed in the user updates key, and thanks to `LRANGE`, we can implement pagination and so on. Note that we use the words updates and posts interchangeably, since updates are actually \"little posts\" in some way.\n\n\n```posts:1000 => a List of post ids - every new post is LPUSHed here.\n```\n\n\nThis list is basically the User timeline. We'll push the IDs of her/his own\nposts, and, the IDs of all the posts of created by the following users.\nBasically, we'll implement a write fanout.\nAuthentication\nOK, we have more or less everything about the user except for authentication. We'll handle authentication in a simple but robust way: we don't want to use PHP sessions, as our system must be ready to be distributed among different web servers easily, so we'll keep the whole state in our Redis database. All we need is a random unguessable string to set as the cookie of an authenticated user, and a key that will contain the user ID of the client holding the string.\nWe need two things in order to make this thing work in a robust way.\nFirst: the current authentication secret (the random unguessable string)\nshould be part of the User object, so when the user is created we also set\nan `auth` field in its Hash:\n\n\n```HSET user:1000 auth fea5e81ac8ca77622bed1c2132a021f9\n```\n\n\nMoreover, we need a way to map authentication secrets to user IDs, so\nwe also take an `auths` key, which has as value a Hash type mapping\nauthentication secrets to user IDs.\n\n\n```HSET auths fea5e81ac8ca77622bed1c2132a021f9 1000\n```\n\n\nIn order to authenticate a user we'll do these simple steps (see the `login.php` file in the Retwis source code):\n\nGet the username and password via the login form.\nCheck if the `username` field actually exists in the `users` Hash.\nIf it exists we have the user id, (i.e. 1000).\nCheck if user:1000 password matches, if not, return an error message.\nOk authenticated! Set \"fea5e81ac8ca77622bed1c2132a021f9\" (the value of user:1000 `auth` field) as the \"auth\" cookie.\n\nThis is the actual code:\n\n\n```include(\"retwis.php\");\n\n# Form sanity checks\nif (!gt(\"username\") || !gt(\"password\"))\n    goback(\"You need to enter both username and password to login.\");\n\n# The form is ok, check if the username is available\n$username = gt(\"username\");\n$password = gt(\"password\");\n$r = redisLink();\n$userid = $r->hget(\"users\",$username);\nif (!$userid)\n    goback(\"Wrong username or password\");\n$realpassword = $r->hget(\"user:$userid\",\"password\");\nif ($realpassword != $password)\n    goback(\"Wrong username or password\");\n\n# Username / password OK, set the cookie and redirect to index.php\n$authsecret = $r->hget(\"user:$userid\",\"auth\");\nsetcookie(\"auth\",$authsecret,time()+3600*24*365);\nheader(\"Location: index.php\");\n```\n\n\nThis happens every time a user logs in, but we also need a function `isLoggedIn` in order to check if a given user is already authenticated or not. These are the logical steps preformed by the `isLoggedIn` function:\n\nGet the \"auth\" cookie from the user. If there is no cookie, the user is not logged in, of course. Let's call the value of the cookie `<authcookie>`.\nCheck if `<authcookie>` field in the `auths` Hash exists, and what the value (the user ID) is (1000 in the example).\nIn order for the system to be more robust, also verify that user:1000 auth field also matches.\nOK the user is authenticated, and we loaded a bit of information in the `$User` global variable.\n\nThe code is simpler than the description, possibly:\n\n\n```function isLoggedIn() {\n    global $User, $_COOKIE;\n\n    if (isset($User)) return true;\n\n    if (isset($_COOKIE['auth'])) {\n        $r = redisLink();\n        $authcookie = $_COOKIE['auth'];\n        if ($userid = $r->hget(\"auths\",$authcookie)) {\n            if ($r->hget(\"user:$userid\",\"auth\") != $authcookie) return false;\n            loadUserInfo($userid);\n            return true;\n        }\n    }\n    return false;\n}\n\nfunction loadUserInfo($userid) {\n    global $User;\n\n    $r = redisLink();\n    $User['id'] = $userid;\n    $User['username'] = $r->hget(\"user:$userid\",\"username\");\n    return true;\n}\n```\n\n\nHaving `loadUserInfo` as a separate function is overkill for our application, but it's a good approach in a complex application. The only thing that's missing from all the authentication is the logout. What do we do on logout? That's simple, we'll just change the random string in user:1000 `auth` field, remove the old authentication secret from the `auths` Hash, and add the new one.\nImportant: the logout procedure explains why we don't just authenticate the user after looking up the authentication secret in the `auths` Hash, but double check it against user:1000 `auth` field. The true authentication string is the latter, while the `auths` Hash is just an authentication field that may even be volatile, or, if there are bugs in the program or a script gets interrupted, we may even end with multiple entries in the `auths` key pointing to the same user ID. The logout code is the following (`logout.php`):\n\n\n```include(\"retwis.php\");\n\nif (!isLoggedIn()) {\n    header(\"Location: index.php\");\n    exit;\n}\n\n$r = redisLink();\n$newauthsecret = getrand();\n$userid = $User['id'];\n$oldauthsecret = $r->hget(\"user:$userid\",\"auth\");\n\n$r->hset(\"user:$userid\",\"auth\",$newauthsecret);\n$r->hset(\"auths\",$newauthsecret,$userid);\n$r->hdel(\"auths\",$oldauthsecret);\n\nheader(\"Location: index.php\");\n```\n\n\nThat is just what we described and should be simple to understand.\nUpdates\nUpdates, also known as posts, are even simpler. In order to create a new post in the database we do something like this:\n\n\n```INCR next_post_id => 10343\nHMSET post:10343 user_id $owner_id time $time body \"I'm having fun with Retwis\"\n```\n\n\nAs you can see each post is just represented by a Hash with three fields. The ID of the user owning the post, the time at which the post was published, and finally, the body of the post, which is, the actual status message.\nAfter we create a post and we obtain the post ID, we need to LPUSH the ID in the timeline of every user that is following the author of the post, and of course in the list of posts of the author itself (everybody is virtually following herself/himself). This is the file `post.php` that shows how this is performed:\n\n\n```include(\"retwis.php\");\n\nif (!isLoggedIn() || !gt(\"status\")) {\n    header(\"Location:index.php\");\n    exit;\n}\n\n$r = redisLink();\n$postid = $r->incr(\"next_post_id\");\n$status = str_replace(\"\\n\",\" \",gt(\"status\"));\n$r->hmset(\"post:$postid\",\"user_id\",$User['id'],\"time\",time(),\"body\",$status);\n$followers = $r->zrange(\"followers:\".$User['id'],0,-1);\n$followers[] = $User['id']; /* Add the post to our own posts too */\n\nforeach($followers as $fid) {\n    $r->lpush(\"posts:$fid\",$postid);\n}\n# Push the post on the timeline, and trim the timeline to the\n# newest 1000 elements.\n$r->lpush(\"timeline\",$postid);\n$r->ltrim(\"timeline\",0,1000);\n\nheader(\"Location: index.php\");\n```\n\n\nThe core of the function is the `foreach` loop. We use `ZRANGE` to get all the followers of the current user, then the loop will `LPUSH` the push the post in every follower timeline List.\nNote that we also maintain a global timeline for all the posts, so that in the Retwis home page we can show everybody's updates easily. This requires just doing an `LPUSH` to the `timeline` List. Let's face it, aren't you starting to think it was a bit strange to have to sort things added in chronological order using `ORDER BY` with SQL? I think so.\nThere is an interesting thing to notice in the code above: we used a new\ncommand called `LTRIM` after we perform the `LPUSH` operation in the global\ntimeline. This is used in order to trim the list to just 1000 elements. The\nglobal timeline is actually only used in order to show a few posts in the\nhome page, there is no need to have the full history of all the posts.\nBasically `LTRIM` + `LPUSH` is a way to create a capped collection in Redis.\nPaginating updates\nNow it should be pretty clear how we can use `LRANGE` in order to get ranges of posts, and render these posts on the screen. The code is simple:\n\n\n```function showPost($id) {\n    $r = redisLink();\n    $post = $r->hgetall(\"post:$id\");\n    if (empty($post)) return false;\n\n    $userid = $post['user_id'];\n    $username = $r->hget(\"user:$userid\",\"username\");\n    $elapsed = strElapsed($post['time']);\n    $userlink = \"<a class=\\\"username\\\" href=\\\"profile.php?u=\".urlencode($username).\"\\\">\".utf8entities($username).\"</a>\";\n\n    echo('<div class=\"post\">'.$userlink.' '.utf8entities($post['body']).\"<br>\");\n    echo('<i>posted '.$elapsed.' ago via web</i></div>');\n    return true;\n}\n\nfunction showUserPosts($userid,$start,$count) {\n    $r = redisLink();\n    $key = ($userid == -1) ? \"timeline\" : \"posts:$userid\";\n    $posts = $r->lrange($key,$start,$start+$count);\n    $c = 0;\n    foreach($posts as $p) {\n        if (showPost($p)) $c++;\n        if ($c == $count) break;\n    }\n    return count($posts) == $count+1;\n}\n```\n\n\n`showPost` will simply convert and print a Post in HTML while `showUserPosts` gets a range of posts and then passes them to `showPosts`.\nNote: `LRANGE` is not very efficient if the list of posts start to be very\nbig, and we want to access elements which are in the middle of the list, since Redis Lists are backed by linked lists. If a system is designed for\ndeep pagination of million of items, it is better to resort to Sorted Sets\ninstead.\nFollowing users\nIt is not hard, but we did not yet check how we create following / follower relationships. If user ID 1000 (antirez) wants to follow user ID 5000 (pippo), we need to create both a following and a follower relationship. We just need to `ZADD` calls:\n\n\n```    ZADD following:1000 5000\n    ZADD followers:5000 1000\n```\n\n\nNote the same pattern again and again. In theory with a relational database, the list of following and followers would be contained in a single table with fields like `following_id` and `follower_id`. You can extract the followers or following of every user using an SQL query. With a key-value DB things are a bit different since we need to set both the `1000 is following 5000` and `5000 is followed by 1000` relations. This is the price to pay, but on the other hand accessing the data is simpler and extremely fast. Having these things as separate sets allows us to do interesting stuff. For example, using `ZINTERSTORE` we can have the intersection of `following` of two different users, so we may add a feature to our Twitter clone so that it is able to tell you very quickly when you visit somebody else's profile, \"you and Alice have 34 followers in common\", and things like that.\nYou can find the code that sets or removes a following / follower relation in the `follow.php` file.\nMaking it horizontally scalable\nGentle reader, if you read till this point you are already a hero. Thank you. Before talking about scaling horizontally it is worth checking performance on a single server. Retwis is extremely fast, without any kind of cache. On a very slow and loaded server, an Apache benchmark with 100 parallel clients issuing 100000 requests measured the average pageview to take 5 milliseconds. This means you can serve millions of users every day with just a single Linux box, and this one was monkey ass slow... Imagine the results with more recent hardware.\nHowever you can't go with a single server forever, how do you scale a key-value\nstore?\nRetwis does not perform any multi-keys operation, so making it scalable is\nsimple: you may use client-side sharding, or something like a sharding proxy\nlike Twemproxy, or the upcoming Redis Cluster.\nTo know more about those topics please read\nour documentation about sharding. However, the point here\nto stress is that in a key-value store, if you design with care, the data set\nis split among many independent small keys. To distribute those keys\nto multiple nodes is more straightforward and predictable compared to using",
    "tag": "redis"
  },
  {
    "title": "Implementations",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/patterns/distributed-locks.md",
    "content": "\ntitle: \"Distributed Locks with Redis\"\nlinkTitle: \"Distributed locks\"\nweight: 1\ndescription: >\n    A distributed lock pattern with Redis\naliases: [\n    /topics/distlock,\n    /docs/reference/patterns/distributed-locks,\n    /docs/reference/patterns/distributed-locks.md\n]\n\nDistributed locks are a very useful primitive in many environments where\ndifferent processes must operate with shared resources in a mutually\nexclusive way.\nThere are a number of libraries and blog posts describing how to implement\na DLM (Distributed Lock Manager) with Redis, but every library uses a different\napproach, and many use a simple approach with lower guarantees compared to\nwhat can be achieved with slightly more complex designs.\nThis page describes a more canonical algorithm to implement\ndistributed locks with Redis. We propose an algorithm, called Redlock,\nwhich implements a DLM which we believe to be safer than the vanilla single\ninstance approach. We hope that the community will analyze it, provide\nfeedback, and use it as a starting point for the implementations or more\ncomplex or alternative designs.\nImplementations\nBefore describing the algorithm, here are a few links to implementations\nalready available that can be used for reference.\n\nRedlock-rb (Ruby implementation). There is also a fork of Redlock-rb that adds a gem for easy distribution.\nRedlock-py (Python implementation).\nPottery (Python implementation).\nAioredlock (Asyncio Python implementation).\nRedlock-php (PHP implementation).\nPHPRedisMutex (further PHP implementation).\ncheprasov/php-redis-lock (PHP library for locks).\nrtckit/react-redlock (Async PHP implementation).\nRedsync (Go implementation).\nRedisson (Java implementation).\nRedis::DistLock (Perl implementation).\nRedlock-cpp (C++ implementation).\nRedis-plus-plus (C++ implementation).\nRedlock-cs (C#/.NET implementation).\nRedLock.net (C#/.NET implementation). Includes async and lock extension support.\nScarletLock (C# .NET implementation with configurable datastore).\nRedlock4Net (C# .NET implementation).\nnode-redlock (NodeJS implementation). Includes support for lock extension.\nDeno DLM (Deno implementation)\n\nSafety and Liveness Guarantees\nWe are going to model our design with just three properties that, from our point of view, are the minimum guarantees needed to use distributed locks in an effective way.\n\nSafety property: Mutual exclusion. At any given moment, only one client can hold a lock.\nLiveness property A: Deadlock free. Eventually it is always possible to acquire a lock, even if the client that locked a resource crashes or gets partitioned.\nLiveness property B: Fault tolerance. As long as the majority of Redis nodes are up, clients are able to acquire and release locks.\n\nWhy Failover-based Implementations Are Not Enough\nTo understand what we want to improve, let\u2019s analyze the current state of affairs with most Redis-based distributed lock libraries.\nThe simplest way to use Redis to lock a resource is to create a key in an instance. The key is usually created with a limited time to live, using the Redis expires feature, so that eventually it will get released (property 2 in our list). When the client needs to release the resource, it deletes the key.\nSuperficially this works well, but there is a problem: this is a single point of failure in our architecture. What happens if the Redis master goes down?\nWell, let\u2019s add a replica! And use it if the master is unavailable. This is unfortunately not viable. By doing so we can\u2019t implement our safety property of mutual exclusion, because Redis replication is asynchronous.\nThere is a race condition with this model:\n\nClient A acquires the lock in the master.\nThe master crashes before the write to the key is transmitted to the replica.\nThe replica gets promoted to master.\nClient B acquires the lock to the same resource A already holds a lock for. SAFETY VIOLATION!\n\nSometimes it is perfectly fine that, under special circumstances, for example during a failure, multiple clients can hold the lock at the same time.\nIf this is the case, you can use your replication based solution. Otherwise we suggest to implement the solution described in this document.\nCorrect Implementation with a Single Instance\nBefore trying to overcome the limitation of the single instance setup described above, let\u2019s check how to do it correctly in this simple case, since this is actually a viable solution in applications where a race condition from time to time is acceptable, and because locking into a single instance is the foundation we\u2019ll use for the distributed algorithm described here.\nTo acquire the lock, the way to go is the following:\n\n\n```    SET resource_name my_random_value NX PX 30000\n```\n\n\nThe command will set the key only if it does not already exist (`NX` option), with an expire of 30000 milliseconds (`PX` option).\nThe key is set to a value \u201cmy_random_value\u201d. This value must be unique across all clients and all lock requests.\nBasically the random value is used in order to release the lock in a safe way, with a script that tells Redis: remove the key only if it exists and the value stored at the key is exactly the one I expect to be. This is accomplished by the following Lua script:\n\n\n```if redis.call(\"get\",KEYS[1]) == ARGV[1] then\n    return redis.call(\"del\",KEYS[1])\nelse\n    return 0\nend\n```\n\n\nThis is important in order to avoid removing a lock that was created by another client. For example a client may acquire the lock, get blocked performing some operation for longer than the lock validity time (the time at which the key will expire), and later remove the lock, that was already acquired by some other client.\nUsing just `DEL` is not safe as a client may remove another client's lock. With the above script instead every lock is \u201csigned\u201d with a random string, so the lock will be removed only if it is still the one that was set by the client trying to remove it.\nWhat should this random string be? We assume it\u2019s 20 bytes from `/dev/urandom`, but you can find cheaper ways to make it unique enough for your tasks.\nFor example a safe pick is to seed RC4 with `/dev/urandom`, and generate a pseudo random stream from that.\nA simpler solution is to use a UNIX timestamp with microsecond precision, concatenating the timestamp with a client ID. It is not as safe, but probably sufficient for most environments.\nThe \"lock validity time\" is the time we use as the key's time to live. It is both the auto release time, and the time the client has in order to perform the operation required before another client may be able to acquire the lock again, without technically violating the mutual exclusion guarantee, which is only limited to a given window of time from the moment the lock is acquired.\nSo now we have a good way to acquire and release the lock. With this system, reasoning about a non-distributed system composed of a single, always available, instance, is safe. Let\u2019s extend the concept to a distributed system where we don\u2019t have such guarantees.\nThe Redlock Algorithm\nIn the distributed version of the algorithm we assume we have N Redis masters. Those nodes are totally independent, so we don\u2019t use replication or any other implicit coordination system. We already described how to acquire and release the lock safely in a single instance. We take for granted that the algorithm will use this method to acquire and release the lock in a single instance. In our examples we set N=5, which is a reasonable value, so we need to run 5 Redis masters on different computers or virtual machines in order to ensure that they\u2019ll fail in a mostly independent way.\nIn order to acquire the lock, the client performs the following operations:\n\nIt gets the current time in milliseconds.\nIt tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP.\nThe client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired.\nIf the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3.\nIf the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).\n\nIs the Algorithm Asynchronous?\nThe algorithm relies on the assumption that while there is no synchronized clock across the processes, the local time in every process updates at approximately at the same rate, with a small margin of error compared to the auto-release time of the lock. This assumption closely resembles a real-world computer: every computer has a local clock and we can usually rely on different computers to have a clock drift which is small.\nAt this point we need to better specify our mutual exclusion rule: it is guaranteed only as long as the client holding the lock terminates its work within the lock validity time (as obtained in step 3), minus some time (just a few milliseconds in order to compensate for clock drift between processes).\nThis paper contains more information about similar systems requiring a bound clock drift: Leases: an efficient fault-tolerant mechanism for distributed file cache consistency.\nRetry on Failure\nWhen a client is unable to acquire the lock, it should try again after a random delay in order to try to desynchronize multiple clients trying to acquire the lock for the same resource at the same time (this may result in a split brain condition where nobody wins). Also the faster a client tries to acquire the lock in the majority of Redis instances, the smaller the window for a split brain condition (and the need for a retry), so ideally the client should try to send the `SET` commands to the N instances at the same time using multiplexing.\nIt is worth stressing how important it is for clients that fail to acquire the majority of locks, to release the (partially) acquired locks ASAP, so that there is no need to wait for key expiry in order for the lock to be acquired again (however if a network partition happens and the client is no longer able to communicate with the Redis instances, there is an availability penalty to pay as it waits for key expiration).\nReleasing the Lock\nReleasing the lock is simple, and can be performed whether or not the client believes it was able to successfully lock a given instance.\nSafety Arguments\nIs the algorithm safe? Let's examine what happens in different scenarios.\nTo start let\u2019s assume that a client is able to acquire the lock in the majority of instances. All the instances will contain a key with the same time to live. However, the key was set at different times, so the keys will also expire at different times. But if the first key was set at worst at time T1 (the time we sample before contacting the first server) and the last key was set at worst at time T2 (the time we obtained the reply from the last server), we are sure that the first key to expire in the set will exist for at least `MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT`. All the other keys will expire later, so we are sure that the keys will be simultaneously set for at least this time.\nDuring the time that the majority of keys are set, another client will not be able to acquire the lock, since N/2+1 SET NX operations can\u2019t succeed if N/2+1 keys already exist. So if a lock was acquired, it is not possible to re-acquire it at the same time (violating the mutual exclusion property).\nHowever we want to also make sure that multiple clients trying to acquire the lock at the same time can\u2019t simultaneously succeed.\nIf a client locked the majority of instances using a time near, or greater, than the lock maximum validity time (the TTL we use for SET basically), it will consider the lock invalid and will unlock the instances, so we only need to consider the case where a client was able to lock the majority of instances in a time which is less than the validity time. In this case for the argument already expressed above, for `MIN_VALIDITY` no client should be able to re-acquire the lock. So multiple clients will be able to lock N/2+1 instances at the same time (with \"time\" being the end of Step 2) only when the time to lock the majority was greater than the TTL time, making the lock invalid.\nLiveness Arguments\nThe system liveness is based on three main features:\n\nThe auto release of the lock (since keys expire): eventually keys are available again to be locked.\nThe fact that clients, usually, will cooperate removing the locks when the lock was not acquired, or when the lock was acquired and the work terminated, making it likely that we don\u2019t have to wait for keys to expire to re-acquire the lock.\nThe fact that when a client needs to retry a lock, it waits a time which is comparably greater than the time needed to acquire the majority of locks, in order to probabilistically make split brain conditions during resource contention unlikely.\n\nHowever, we pay an availability penalty equal to `TTL` time on network partitions, so if there are continuous partitions, we can pay this penalty indefinitely.\nThis happens every time a client acquires a lock and gets partitioned away before being able to remove the lock.\nBasically if there are infinite continuous network partitions, the system may become not available for an infinite amount of time.\nPerformance, Crash Recovery and fsync\nMany users using Redis as a lock server need high performance in terms of both latency to acquire and release a lock, and number of acquire / release operations that it is possible to perform per second. In order to meet this requirement, the strategy to talk with the N Redis servers to reduce latency is definitely multiplexing (putting the socket in non-blocking mode, send all the commands, and read all the commands later, assuming that the RTT between the client and each instance is similar).\nHowever there is another consideration around persistence if we want to target a crash-recovery system model.\nBasically to see the problem here, let\u2019s assume we configure Redis without persistence at all. A client acquires the lock in 3 of 5 instances. One of the instances where the client was able to acquire the lock is restarted, at this point there are again 3 instances that we can lock for the same resource, and another client can lock it again, violating the safety property of exclusivity of lock.\nIf we enable AOF persistence, things will improve quite a bit. For example we can upgrade a server by sending it a `SHUTDOWN` command and restarting it. Because Redis expires are semantically implemented so that time still elapses when the server is off, all our requirements are fine.\nHowever everything is fine as long as it is a clean shutdown. What about a power outage? If Redis is configured, as by default, to fsync on disk every second, it is possible that after a restart our key is missing. In theory, if we want to guarantee the lock safety in the face of any kind of instance restart, we need to enable `fsync=always` in the persistence settings. This will affect performance due to the additional sync overhead.\nHowever things are better than they look like at a first glance. Basically,\nthe algorithm safety is retained as long as when an instance restarts after a\ncrash, it no longer participates to any currently active lock.  This means that the\nset of currently active locks when the instance restarts were all obtained\nby locking instances other than the one which is rejoining the system.\nTo guarantee this we just need to make an instance, after a crash, unavailable\nfor at least a bit more than the max `TTL` we use.  This is the time needed\nfor all the keys about the locks that existed when the instance crashed to\nbecome invalid and be automatically released.\nUsing delayed restarts it is basically possible to achieve safety even\nwithout any kind of Redis persistence available, however note that this may\ntranslate into an availability penalty. For example if a majority of instances\ncrash, the system will become globally unavailable for `TTL` (here globally means\nthat no resource at all will be lockable during this time).\nMaking the algorithm more reliable: Extending the lock\nIf the work performed by clients consists of small steps, it is possible to\nuse smaller lock validity times by default, and extend the algorithm implementing\na lock extension mechanism. Basically the client, if in the middle of the\ncomputation while the lock validity is approaching a low value, may extend the\nlock by sending a Lua script to all the instances that extends the TTL of the key\nif the key exists and its value is still the random value the client assigned\nwhen the lock was acquired.\nThe client should only consider the lock re-acquired if it was able to extend\nthe lock into the majority of instances, and within the validity time\n(basically the algorithm to use is very similar to the one used when acquiring\nthe lock).\nHowever this does not technically change the algorithm, so the maximum number\nof lock reacquisition attempts should be limited, otherwise one of the liveness\nproperties is violated.\nDisclaimer about consistency\nPlease consider thoroughly reviewing the Analysis of Redlock section at the end of this page.\nMartin Kleppman's article and antirez's answer to it are very relevant.\nIf you are concerned about consistency and correctness, you should pay attention to the following topics:\n\nYou should implement fencing tokens.\n  This is especially important for processes that can take significant time and applies to any distributed locking system.\n  Extending locks' lifetime is also an option, but don\u00b4t assume that a lock is retained as long as the process that had acquired it is alive.\nRedis is not using monotonic clock for TTL expiration mechanism.\n  That means that a wall-clock shift may result in a lock being acquired by more than one process.\n  Even though the problem can be mitigated by preventing admins from manually setting the server's time and setting up NTP properly, there's still a chance of this issue occurring in real life and compromising consistency.\n\nWant to help?\nIf you are into distributed systems, it would be great to have your opinion / analysis. Also reference implementations in other languages could be great.\nThanks in advance!\nAnalysis of Redlock\n",
    "tag": "redis"
  },
  {
    "title": "Bulk loading using the Redis protocol",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/patterns/bulk-loading.md",
    "content": "\ntitle: \"Bulk loading\"\nlinkTitle: \"Bulk loading\"\nweight: 1\ndescription: >\n    Writing data in bulk using the Redis protocol\naliases: [\n    /topics/mass-insertion,\n    /docs/reference/patterns/bulk-loading\n]\n\nBulk loading is the process of loading Redis with a large amount of pre-existing data. Ideally, you want to perform this operation quickly and efficiently. This document describes some strategies for bulk loading data in Redis.\nBulk loading using the Redis protocol\nUsing a normal Redis client to perform bulk loading is not a good idea\nfor a few reasons: the naive approach of sending one command after the other\nis slow because you have to pay for the round trip time for every command.\nIt is possible to use pipelining, but for bulk loading of many records\nyou need to write new commands while you read replies at the same time to\nmake sure you are inserting as fast as possible.\nOnly a small percentage of clients support non-blocking I/O, and not all the\nclients are able to parse the replies in an efficient way in order to maximize\nthroughput. For all of these reasons the preferred way to mass import data into\nRedis is to generate a text file containing the Redis protocol, in raw format,\nin order to call the commands needed to insert the required data.\nFor instance if I need to generate a large data set where there are billions\nof keys in the form: `keyN -> ValueN' I will create a file containing the\nfollowing commands in the Redis protocol format:\n\n\n```SET Key0 Value0\nSET Key1 Value1\n...\nSET KeyN ValueN\n```\n\n\nOnce this file is created, the remaining action is to feed it to Redis\nas fast as possible. In the past the way to do this was to use the\n`netcat` with the following command:\n\n\n```(cat data.txt; sleep 10) | nc localhost 6379 > /dev/null\n```\n\n\nHowever this is not a very reliable way to perform mass import because netcat\ndoes not really know when all the data was transferred and can't check for\nerrors. In 2.6 or later versions of Redis the `redis-cli` utility\nsupports a new mode called pipe mode that was designed in order to perform\nbulk loading.\nUsing the pipe mode the command to run looks like the following:\n\n\n```cat data.txt | redis-cli --pipe\n```\n\n\nThat will produce an output similar to this:\n\n\n```All data transferred. Waiting for the last reply...\nLast reply received from server.\nerrors: 0, replies: 1000000\n```\n\n\nThe redis-cli utility will also make sure to only redirect errors received\nfrom the Redis instance to the standard output.\nGenerating Redis Protocol\nThe Redis protocol is extremely simple to generate and parse, and is\nDocumented here. However in order to generate protocol for\nthe goal of bulk loading you don't need to understand every detail of the\nprotocol, but just that every command is represented in the following way:\n\n\n```*<args><cr><lf>\n$<len><cr><lf>\n<arg0><cr><lf>\n<arg1><cr><lf>\n...\n<argN><cr><lf>\n```\n\n\nWhere `<cr>` means \"\\r\" (or ASCII character 13) and `<lf>` means \"\\n\" (or ASCII character 10).\nFor instance the command SET key value is represented by the following protocol:\n\n\n```*3<cr><lf>\n$3<cr><lf>\nSET<cr><lf>\n$3<cr><lf>\nkey<cr><lf>\n$5<cr><lf>\nvalue<cr><lf>\n```\n\n\nOr represented as a quoted string:\n\n\n```\"*3\\r\\n$3\\r\\nSET\\r\\n$3\\r\\nkey\\r\\n$5\\r\\nvalue\\r\\n\"\n```\n\n\nThe file you need to generate for bulk loading is just composed of commands\nrepresented in the above way, one after the other.\nThe following Ruby function generates valid protocol:\n\n\n```def gen_redis_proto(*cmd)\n    proto = \"\"\n    proto << \"*\"+cmd.length.to_s+\"\\r\\n\"\n    cmd.each{|arg|\n        proto << \"$\"+arg.to_s.bytesize.to_s+\"\\r\\n\"\n        proto << arg.to_s+\"\\r\\n\"\n    }\n    proto\nend\n\nputs gen_redis_proto(\"SET\",\"mykey\",\"Hello World!\").inspect\n```\n\n\nUsing the above function it is possible to easily generate the key value pairs\nin the above example, with this program:\n\n\n```(0...1000).each{|n|\n    STDOUT.write(gen_redis_proto(\"SET\",\"Key#{n}\",\"Value#{n}\"))\n}\n```\n\n\nWe can run the program directly in pipe to redis-cli in order to perform our\nfirst mass import session.\n\n\n```$ ruby proto.rb | redis-cli --pipe\nAll data transferred. Waiting for the last reply...\nLast reply received from server.\nerrors: 0, replies: 1000\n```\n\n\nHow the pipe mode works under the hood\nThe magic needed inside the pipe mode of redis-cli is to be as fast as netcat\nand still be able to understand when the last reply was sent by the server\nat the same time.\nThis is obtained in the following way:\n\nredis-cli --pipe tries to send data as fast as possible to the server.\nAt the same time it reads data when available, trying to parse it.\nOnce there is no more data to read from stdin, it sends a special ECHO\ncommand with a random 20 byte string: we are sure this is the latest command\nsent, and we are sure we can match the reply checking if we receive the same\n20 bytes as a bulk reply.\nOnce this special final command is sent, the code receiving replies starts\nto match replies with these 20 bytes. When the matching reply is reached it\ncan exit with success.\n\nUsing this trick we don't need to parse the protocol we send to the server\nin order to understand how many commands we are sending, but just the replies.\nHowever while parsing the replies we take a counter of all the replies parsed\nso that at the end we are able to tell the user the amount of commands",
    "tag": "redis"
  },
  {
    "title": "index.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/patterns/indexes/index.md",
    "content": "\ntitle: Secondary indexing\nlinkTitle: Secondary indexing\nweight: 1\ndescription: >\n    Building secondary indexes in Redis\naliases: [\n    /topics/indexing,\n    /docs/reference/patterns/indexes\n]\n\nRedis is not exactly a key-value store, since values can be complex data structures. However it has an external key-value shell: at API level data is addressed by the key name. It is fair to say that, natively, Redis only offers primary key access. However since Redis is a data structures server, its capabilities can be used for indexing, in order to create secondary indexes of different kinds, including composite (multi-column) indexes.\nThis document explains how it is possible to create indexes in Redis using the following data structures:\n\nSorted sets to create secondary indexes by ID or other numerical fields.\nSorted sets with lexicographical ranges for creating more advanced secondary indexes, composite indexes and graph traversal indexes.\nSets for creating random indexes.\nLists for creating simple iterable indexes and last N items indexes.\n\nImplementing and maintaining indexes with Redis is an advanced topic, so most\nusers that need to perform complex queries on data should understand if they\nare better served by a relational store. However often, especially in caching\nscenarios, there is the explicit need to store indexed data into Redis in order to speedup common queries which require some form of indexing in order to be executed.\nSimple numerical indexes with sorted sets\nThe simplest secondary index you can create with Redis is by using the\nsorted set data type, which is a data structure representing a set of\nelements ordered by a floating point number which is the score of\neach element. Elements are ordered from the smallest to the highest score.\nSince the score is a double precision float, indexes you can build with\nvanilla sorted sets are limited to things where the indexing field is a number\nwithin a given range.\nThe two commands to build these kind of indexes are `ZADD` and\n`ZRANGE` with the `BYSCORE` argument to respectively add items and retrieve items within a\nspecified range.\nFor instance, it is possible to index a set of person names by their\nage by adding element to a sorted set. The element will be the name of the\nperson and the score will be the age.\n\n\n```ZADD myindex 25 Manuel\nZADD myindex 18 Anna\nZADD myindex 35 Jon\nZADD myindex 67 Helen\n```\n\n\nIn order to retrieve all persons with an age between 20 and 40, the following\ncommand can be used:\n\n\n```ZRANGE myindex 20 40 BYSCORE\n1) \"Manuel\"\n2) \"Jon\"\n```\n\n\nBy using the WITHSCORES option of `ZRANGE` it is also possible\nto obtain the scores associated with the returned elements.\nThe `ZCOUNT` command can be used in order to retrieve the number of elements\nwithin a given range, without actually fetching the elements, which is also\nuseful, especially given the fact the operation is executed in logarithmic\ntime regardless of the size of the range.\nRanges can be inclusive or exclusive, please refer to the `ZRANGE`\ncommand documentation for more information.\nNote: Using the `ZRANGE` with the `BYSCORE` and `REV` arguments, it is possible to query a range in\nreversed order, which is often useful when data is indexed in a given\ndirection (ascending or descending) but we want to retrieve information\nthe other way around.\nUsing objects IDs as associated values\nIn the above example we associated names to ages. However in general we\nmay want to index some field of an object which is stored elsewhere.\nInstead of using the sorted set value directly to store the data associated\nwith the indexed field, it is possible to store just the ID of the object.\nFor example I may have Redis hashes representing users. Each user is\nrepresented by a single key, directly accessible by ID:\n\n\n```HMSET user:1 id 1 username antirez ctime 1444809424 age 38\nHMSET user:2 id 2 username maria ctime 1444808132 age 42\nHMSET user:3 id 3 username jballard ctime 1443246218 age 33\n```\n\n\nIf I want to create an index in order to query users by their age, I\ncould do:\n\n\n```ZADD user.age.index 38 1\nZADD user.age.index 42 2\nZADD user.age.index 33 3\n```\n\n\nThis time the value associated with the score in the sorted set is the\nID of the object. So once I query the index with `ZRANGE` with the `BYSCORE` argument, I'll\nalso have to retrieve the information I need with `HGETALL` or similar\ncommands. The obvious advantage is that objects can change without touching\nthe index, as long as we don't change the indexed field.\nIn the next examples we'll almost always use IDs as values associated with\nthe index, since this is usually the more sounding design, with a few\nexceptions.\nUpdating simple sorted set indexes\nOften we index things which change over time. In the above\nexample, the age of the user changes every year. In such a case it would\nmake sense to use the birth date as index instead of the age itself,\nbut there are other cases where we simply want some field to change from\ntime to time, and the index to reflect this change.\nThe `ZADD` command makes updating simple indexes a very trivial operation\nsince re-adding back an element with a different score and the same value\nwill simply update the score and move the element at the right position,\nso if the user `antirez` turned 39 years old, in order to update the\ndata in the hash representing the user, and in the index as well, we need\nto execute the following two commands:\n\n\n```HSET user:1 age 39\nZADD user.age.index 39 1\n```\n\n\nThe operation may be wrapped in a `MULTI`/`EXEC` transaction in order to\nmake sure both fields are updated or none.\nTurning multi dimensional data into linear data\nIndexes created with sorted sets are able to index only a single numerical\nvalue. Because of this you may think it is impossible to index something\nwhich has multiple dimensions using this kind of indexes, but actually this\nis not always true. If you can efficiently represent something\nmulti-dimensional in a linear way, they it is often possible to use a simple\nsorted set for indexing.\nFor example the Redis geo indexing API uses a sorted\nset to index places by latitude and longitude using a technique called\nGeo hash. The sorted set score\nrepresents alternating bits of longitude and latitude, so that we map the\nlinear score of a sorted set to many small squares in the earth surface.\nBy doing an 8+1 style center plus neighborhoods search it is possible to\nretrieve elements by radius.\nLimits of the score\nSorted set elements scores are double precision floats. It means that\nthey can represent different decimal or integer values with different\nerrors, because they use an exponential representation internally.\nHowever what is interesting for indexing purposes is that the score is\nalways able to represent without any error numbers between -9007199254740992\nand 9007199254740992, which is `-/+ 2^53`.\nWhen representing much larger numbers, you need a different form of indexing\nthat is able to index numbers at any precision, called a lexicographical\nindex.\nLexicographical indexes\nRedis sorted sets have an interesting property. When elements are added\nwith the same score, they are sorted lexicographically, comparing the\nstrings as binary data with the `memcmp()` function.\nFor people that don't know the C language nor the `memcmp` function, what\nit means is that elements with the same score are sorted comparing the\nraw values of their bytes, byte after byte. If the first byte is the same,\nthe second is checked and so forth. If the common prefix of two strings is\nthe same then the longer string is considered the greater of the two,\nso \"foobar\" is greater than \"foo\".\nThere are commands such as `ZRANGE` and `ZLEXCOUNT` that\nare able to query and count ranges in a lexicographically fashion, assuming\nthey are used with sorted sets where all the elements have the same score.\nThis Redis feature is basically equivalent to a `b-tree` data structure which\nis often used in order to implement indexes with traditional databases.\nAs you can guess, because of this, it is possible to use this Redis data\nstructure in order to implement pretty fancy indexes.\nBefore we dive into using lexicographical indexes, let's check how\nsorted sets behave in this special mode of operation. Since we need to\nadd elements with the same score, we'll always use the special score of\nzero.\n\n\n```ZADD myindex 0 baaa\nZADD myindex 0 abbb\nZADD myindex 0 aaaa\nZADD myindex 0 bbbb\n```\n\n\nFetching all the elements from the sorted set immediately reveals that they\nare ordered lexicographically.\n\n\n```ZRANGE myindex 0 -1\n1) \"aaaa\"\n2) \"abbb\"\n3) \"baaa\"\n4) \"bbbb\"\n```\n\n\nNow we can use `ZRANGE` with the `BYLEX` argument in order to perform range queries.\n\n\n```ZRANGE myindex [a (b BYLEX\n1) \"aaaa\"\n2) \"abbb\"\n```\n\n\nNote that in the range queries we prefixed the `min` and `max` elements\nidentifying the range with the special characters `[` and `(`.\nThis prefixes are mandatory, and they specify if the elements\nof the range are inclusive or exclusive. So the range `[a (b` means give me\nall the elements lexicographically between `a` inclusive and `b` exclusive,\nwhich are all the elements starting with `a`.\nThere are also two more special characters indicating the infinitely negative\nstring and the infinitely positive string, which are `-` and `+`.\n\n\n```ZRANGE myindex [b + BYLEX\n1) \"baaa\"\n2) \"bbbb\"\n```\n\n\nThat's it basically. Let's see how to use these features to build indexes.\nA first example: completion\nAn interesting application of indexing is completion. Completion is what\nhappens when you start typing your query into a search engine: the user\ninterface will anticipate what you are likely typing, providing common\nqueries that start with the same characters.\nA naive approach to completion is to just add every single query we\nget from the user into the index. For example if the user searches `banana`\nwe'll just do:\n\n\n```ZADD myindex 0 banana\n```\n\n\nAnd so forth for each search query ever encountered. Then when we want to\ncomplete the user input, we execute a range query using `ZRANGE` with the `BYLEX` argument.\nImagine the user is typing \"bit\" inside the search form, and we want to\noffer possible search keywords starting for \"bit\". We send Redis a command\nlike that:\n\n\n```ZRANGE myindex \"[bit\" \"[bit\\xff\" BYLEX\n```\n\n\nBasically we create a range using the string the user is typing right now\nas start, and the same string plus a trailing byte set to 255, which is `\\xff` in the example, as the end of the range. This way we get all the strings that start for the string the user is typing.\nNote that we don't want too many items returned, so we may use the LIMIT option in order to reduce the number of results.\nAdding frequency into the mix\nThe above approach is a bit naive, because all the user searches are the same\nin this way. In a real system we want to complete strings according to their\nfrequency: very popular searches will be proposed with a higher probability\ncompared to search strings typed very rarely.\nIn order to implement something which depends on the frequency, and at the\nsame time automatically adapts to future inputs, by purging searches that\nare no longer popular, we can use a very simple streaming algorithm.\nTo start, we modify our index in order to store not just the search term,\nbut also the frequency the term is associated with. So instead of just adding\n`banana` we add `banana:1`, where 1 is the frequency.\n\n\n```ZADD myindex 0 banana:1\n```\n\n\nWe also need logic in order to increment the index if the search term\nalready exists in the index, so what we'll actually do is something like\nthat:\n\n\n```ZRANGE myindex \"[banana:\" + BYLEX LIMIT 0 1\n1) \"banana:1\"\n```\n\n\nThis will return the single entry of `banana` if it exists. Then we\ncan increment the associated frequency and send the following two\ncommands:\n\n\n```ZREM myindex 0 banana:1\nZADD myindex 0 banana:2\n```\n\n\nNote that because it is possible that there are concurrent updates, the\nabove three commands should be send via a Lua script\ninstead, so that the Lua script will atomically get the old count and\nre-add the item with incremented score.\nSo the result will be that, every time a user searches for `banana` we'll\nget our entry updated.\nThere is more: our goal is to just have items searched very frequently.\nSo we need some form of purging. When we actually query the index\nin order to complete the user input, we may see something like that:\n\n\n```ZRANGE myindex \"[banana:\" + BYLEX LIMIT 0 10\n1) \"banana:123\"\n2) \"banaooo:1\"\n3) \"banned user:49\"\n4) \"banning:89\"\n```\n\n\nApparently nobody searches for \"banaooo\", for example, but the query was\nperformed a single time, so we end presenting it to the user.\nThis is what we can do. Out of the returned items, we pick a random one,\ndecrement its score by one, and re-add it with the new score.\nHowever if the score reaches 0, we simply remove the item from the list.\nYou can use much more advanced systems, but the idea is that the index in\nthe long run will contain top searches, and if top searches will change over\nthe time it will adapt automatically.\nA refinement to this algorithm is to pick entries in the list according to\ntheir weight: the higher the score, the less likely entries are picked\nin order to decrement its score, or evict them.\nNormalizing strings for case and accents\nIn the completion examples we always used lowercase strings. However\nreality is much more complex than that: languages have capitalized names,\naccents, and so forth.\nOne simple way do deal with this issues is to actually normalize the\nstring the user searches. Whatever the user searches for \"Banana\",\n\"BANANA\" or \"Ba'nana\" we may always turn it into \"banana\".\nHowever sometimes we may like to present the user with the original\nitem typed, even if we normalize the string for indexing. In order to\ndo this, what we do is to change the format of the index so that instead\nof just storing `term:frequency` we store `normalized:frequency:original`\nlike in the following example:\n\n\n```ZADD myindex 0 banana:273:Banana\n```\n\n\nBasically we add another field that we'll extract and use only for\nvisualization. Ranges will always be computed using the normalized strings\ninstead. This is a common trick which has multiple applications.\nAdding auxiliary information in the index\nWhen using a sorted set in a direct way, we have two different attributes\nfor each object: the score, which we use as an index, and an associated\nvalue. When using lexicographical indexes instead, the score is always\nset to 0 and basically not used at all. We are left with a single string,\nwhich is the element itself.\nLike we did in the previous completion examples, we are still able to\nstore associated data using separators. For example we used the colon in\norder to add the frequency and the original word for completion.\nIn general we can add any kind of associated value to our indexing key.\nIn order to use a lexicographical index to implement a simple key-value store\nwe just store the entry as `key:value`:\n\n\n```ZADD myindex 0 mykey:myvalue\n```\n\n\nAnd search for the key with:\n\n\n```ZRANGE myindex [mykey: + BYLEX LIMIT 0 1\n1) \"mykey:myvalue\"\n```\n\n\nThen we extract the part after the colon to retrieve the value.\nHowever a problem to solve in this case is collisions. The colon character\nmay be part of the key itself, so it must be chosen in order to never\ncollide with the key we add.\nSince lexicographical ranges in Redis are binary safe you can use any\nbyte or any sequence of bytes. However if you receive untrusted user\ninput, it is better to use some form of escaping in order to guarantee\nthat the separator will never happen to be part of the key.\nFor example if you use two null bytes as separator `\"\\0\\0\"`, you may\nwant to always escape null bytes into two bytes sequences in your strings.\nNumerical padding\nLexicographical indexes may look like good only when the problem at hand\nis to index strings. Actually it is very simple to use this kind of index\nin order to perform indexing of arbitrary precision numbers.\nIn the ASCII character set, digits appear in the order from 0 to 9, so\nif we left-pad numbers with leading zeroes, the result is that comparing\nthem as strings will order them by their numerical value.\n\n\n```ZADD myindex 0 00324823481:foo\nZADD myindex 0 12838349234:bar\nZADD myindex 0 00000000111:zap\n\nZRANGE myindex 0 -1\n1) \"00000000111:zap\"\n2) \"00324823481:foo\"\n3) \"12838349234:bar\"\n```\n\n\nWe effectively created an index using a numerical field which can be as\nbig as we want. This also works with floating point numbers of any precision\nby making sure we left pad the numerical part with leading zeroes and the\ndecimal part with trailing zeroes like in the following list of numbers:\n\n\n```    01000000000000.11000000000000\n    01000000000000.02200000000000\n    00000002121241.34893482930000\n    00999999999999.00000000000000\n```\n\n\nUsing numbers in binary form\nStoring numbers in decimal may use too much memory. An alternative approach\nis just to store numbers, for example 128 bit integers, directly in their\nbinary form. However for this to work, you need to store the numbers in\nbig endian format, so that the most significant bytes are stored before\nthe least significant bytes. This way when Redis compares the strings with\n`memcmp()`, it will effectively sort the numbers by their value.\nKeep in mind that data stored in binary format is less observable for\ndebugging, harder to parse and export. So it is definitely a trade off.\nComposite indexes\nSo far we explored ways to index single fields. However we all know that\nSQL stores are able to create indexes using multiple fields. For example\nI may index products in a very large store by room number and price.\nI need to run queries in order to retrieve all the products in a given\nroom having a given price range. What I can do is to index each product\nin the following way:\n\n\n```ZADD myindex 0 0056:0028.44:90\nZADD myindex 0 0034:0011.00:832\n```\n\n\nHere the fields are `room:price:product_id`. I used just four digits padding\nin the example for simplicity. The auxiliary data (the product ID) does not\nneed any padding.\nWith an index like that, to get all the products in room 56 having a price\nbetween 10 and 30 dollars is very easy. We can just run the following\ncommand:\n\n\n```ZRANGE myindex [0056:0010.00 [0056:0030.00 BYLEX\n```\n\n\nThe above is called a composed index. Its effectiveness depends on the\norder of the fields and the queries I want to run. For example the above\nindex cannot be used efficiently in order to get all the products having\na specific price range regardless of the room number. However I can use\nthe primary key in order to run queries regardless of the price, like\ngive me all the products in room 44.\nComposite indexes are very powerful, and are used in traditional stores\nin order to optimize complex queries. In Redis they could be useful both\nto implement a very fast in-memory Redis index of something stored into\na traditional data store, or in order to directly index Redis data.\nUpdating lexicographical indexes\nThe value of the index in a lexicographical index can get pretty fancy\nand hard or slow to rebuild from what we store about the object. So one\napproach to simplify the handling of the index, at the cost of using more\nmemory, is to also take alongside to the sorted set representing the index\na hash mapping the object ID to the current index value.\nSo for example, when we index we also add to a hash:\n\n\n```MULTI\nZADD myindex 0 0056:0028.44:90\nHSET index.content 90 0056:0028.44:90\nEXEC\n```\n\n\nThis is not always needed, but simplifies the operations of updating\nthe index. In order to remove the old information we indexed for the object\nID 90, regardless of the current fields values of the object, we just\nhave to retrieve the hash value by object ID and `ZREM` it in the sorted\nset view.\nRepresenting and querying graphs using a hexastore\nOne cool thing about composite indexes is that they are handy in order\nto represent graphs, using a data structure which is called\nHexastore.\nThe hexastore provides a representation for relations between objects,\nformed by a subject, a predicate and an object.\nA simple relation between objects could be:\n\n\n```antirez is-friend-of matteocollina\n```\n\n\nIn order to represent this relation I can store the following element\nin my lexicographical index:\n\n\n```ZADD myindex 0 spo:antirez:is-friend-of:matteocollina\n```\n\n\nNote that I prefixed my item with the string spo. It means that\nthe item represents a subject,predicate,object relation.\nIn can add 5 more entries for the same relation, but in a different order:\n\n\n```ZADD myindex 0 sop:antirez:matteocollina:is-friend-of\nZADD myindex 0 ops:matteocollina:is-friend-of:antirez\nZADD myindex 0 osp:matteocollina:antirez:is-friend-of\nZADD myindex 0 pso:is-friend-of:antirez:matteocollina\nZADD myindex 0 pos:is-friend-of:matteocollina:antirez\n```\n\n\nNow things start to be interesting, and I can query the graph in many\ndifferent ways. For example, who are all the people `antirez`\nis friend of?\n\n\n```ZRANGE myindex \"[spo:antirez:is-friend-of:\" \"[spo:antirez:is-friend-of:\\xff\" BYLEX\n1) \"spo:antirez:is-friend-of:matteocollina\"\n2) \"spo:antirez:is-friend-of:wonderwoman\"\n3) \"spo:antirez:is-friend-of:spiderman\"\n```\n\n\nOr, what are all the relationships `antirez` and `matteocollina` have where\nthe first is the subject and the second is the object?\n\n\n```ZRANGE myindex \"[sop:antirez:matteocollina:\" \"[sop:antirez:matteocollina:\\xff\" BYLEX\n1) \"sop:antirez:matteocollina:is-friend-of\"\n2) \"sop:antirez:matteocollina:was-at-conference-with\"\n3) \"sop:antirez:matteocollina:talked-with\"\n```\n\n\nBy combining different queries, I can ask fancy questions. For example:\nWho are all my friends that, like beer, live in Barcelona, and matteocollina consider friends as well?\nTo get this information I start with an `spo` query to find all the people\nI'm friend with. Then for each result I get I perform an `spo` query\nto check if they like beer, removing the ones for which I can't find\nthis relation. I do it again to filter by city. Finally I perform an `ops`\nquery to find, of the list I obtained, who is considered friend by\nmatteocollina.\nMake sure to check Matteo Collina's slides about Levelgraph in order to better understand these ideas.\nMulti dimensional indexes\nA more complex type of index is an index that allows you to perform queries\nwhere two or more variables are queried at the same time for specific\nranges. For example I may have a data set representing persons age and\nsalary, and I want to retrieve all the people between 50 and 55 years old\nhaving a salary between 70000 and 85000.\nThis query may be performed with a multi column index, but this requires\nus to select the first variable and then scan the second, which means we\nmay do a lot more work than needed. It is possible to perform these kinds of\nqueries involving multiple variables using different data structures.\nFor example, multi-dimensional trees such as k-d trees or r-trees are\nsometimes used. Here we'll describe a different way to index data into\nmultiple dimensions, using a representation trick that allows us to perform\nthe query in a very efficient way using Redis lexicographical ranges.\nLet's say we have points in the space, which represent our data samples, where `x` and `y` are our coordinates. The max value of both variables is 400.\nIn the next figure, the blue box represents our query. We want all the points where `x` is between 50 and 100, and where `y` is between 100 and 300.\n\nIn order to represent data that makes these kinds of queries fast to perform,\nwe start by padding our numbers with 0. So for example imagine we want to\nadd the point 10,25 (x,y) to our index. Given that the maximum range in the\nexample is 400 we can just pad to three digits, so we obtain:\n\n\n```x = 010\ny = 025\n```\n\n\nNow what we do is to interleave the digits, taking the leftmost digit\nin x, and the leftmost digit in y, and so forth, in order to create a single\nnumber:\n\n\n```001205\n```\n\n\nThis is our index, however in order to more easily reconstruct the original\nrepresentation, if we want (at the cost of space), we may also add the\noriginal values as additional columns:\n\n\n```001205:10:25\n```\n\n\nNow, let's reason about this representation and why it is useful in the\ncontext of range queries. For example let's take the center of our blue\nbox, which is at `x=75` and `y=200`. We can encode this number as we did\nearlier by interleaving the digits, obtaining:\n\n\n```027050\n```\n\n\nWhat happens if we substitute the last two digits respectively with 00 and 99?\nWe obtain a range which is lexicographically continuous:\n\n\n```027000 to 027099\n```\n\n\nWhat this maps to is to a square representing all values where the `x`\nvariable is between 70 and 79, and the `y` variable is between 200 and 209.\nTo identify this specific area, we can write random points in that interval.\n\nSo the above lexicographic query allows us to easily query for points in\na specific square in the picture. However the square may be too small for\nthe box we are searching, so that too many queries are needed.\nSo we can do the same but instead of replacing the last two digits with 00\nand 99, we can do it for the last four digits, obtaining the following\nrange:\n\n\n```020000 029999\n```\n\n\nThis time the range represents all the points where `x` is between 0 and 99\nand `y` is between 200 and 299. Drawing random points in this interval\nshows us this larger area.\n\nSo now our area is too big for our query, and still our search box is\nnot completely included. We need more granularity, but we can easily obtain\nit by representing our numbers in binary form. This time, when we replace\ndigits instead of getting squares which are ten times bigger, we get squares\nwhich are just two times bigger.\nOur numbers in binary form, assuming we need just 9 bits for each variable\n(in order to represent numbers up to 400 in value) would be:\n\n\n```x = 75  -> 001001011\ny = 200 -> 011001000\n```\n\n\nSo by interleaving digits, our representation in the index would be:\n\n\n```000111000011001010:75:200\n```\n\n\nLet's see what are our ranges as we substitute the last 2, 4, 6, 8, ...\nbits with 0s ad 1s in the interleaved representation:\n\n\n```2 bits: x between 74 and 75, y between 200 and 201 (range=2)\n4 bits: x between 72 and 75, y between 200 and 203 (range=4)\n6 bits: x between 72 and 79, y between 200 and 207 (range=8)\n8 bits: x between 64 and 79, y between 192 and 207 (range=16)\n```\n\n\nAnd so forth. Now we have definitely better granularity!\nAs you can see substituting N bits from the index gives us\nsearch boxes of side `2^(N/2)`.\nSo what we do is check the dimension where our search box is smaller,\nand check the nearest power of two to this number. Our search box\nwas 50,100 to 100,300, so it has a width of 50 and a height of 200.\nWe take the smaller of the two, 50, and check the nearest power of two\nwhich is 64. 64 is 2^6, so we would work with indexes obtained replacing\nthe latest 12 bits from the interleaved representation (so that we end\nreplacing just 6 bits of each variable).\nHowever single squares may not cover all our search, so we may need more.\nWhat we do is to start with the left bottom corner of our search box,\nwhich is 50,100, and find the first range by substituting the last 6 bits\nin each number with 0. Then we do the same with the right top corner.\nWith two trivial nested for loops where we increment only the significant\nbits, we can find all the squares between these two. For each square we\nconvert the two numbers into our interleaved representation, and create\nthe range using the converted representation as our start, and the same\nrepresentation but with the latest 12 bits turned on as end range.\nFor each square found we perform our query and get the elements inside,\nremoving the elements which are outside our search box.\nTurning this into code is simple. Here is a Ruby example:\n\n\n```def spacequery(x0,y0,x1,y1,exp)\n    bits=exp*2\n    x_start = x0/(2**exp)\n    x_end = x1/(2**exp)\n    y_start = y0/(2**exp)\n    y_end = y1/(2**exp)\n    (x_start..x_end).each{|x|\n        (y_start..y_end).each{|y|\n            x_range_start = x*(2**exp)\n            x_range_end = x_range_start | ((2**exp)-1)\n            y_range_start = y*(2**exp)\n            y_range_end = y_range_start | ((2**exp)-1)\n            puts \"#{x},#{y} x from #{x_range_start} to #{x_range_end}, y from #{y_range_start} to #{y_range_end}\"\n\n            # Turn it into interleaved form for ZRANGE query.\n            # We assume we need 9 bits for each integer, so the final\n            # interleaved representation will be 18 bits.\n            xbin = x_range_start.to_s(2).rjust(9,'0')\n            ybin = y_range_start.to_s(2).rjust(9,'0')\n            s = xbin.split(\"\").zip(ybin.split(\"\")).flatten.compact.join(\"\")\n            # Now that we have the start of the range, calculate the end\n            # by replacing the specified number of bits from 0 to 1.\n            e = s[0..-(bits+1)]+(\"1\"*bits)\n            puts \"ZRANGE myindex [#{s} [#{e} BYLEX\"\n        }\n    }\nend\n\nspacequery(50,100,100,300,6)\n```\n\n\nWhile non immediately trivial this is a very useful indexing strategy that\nin the future may be implemented in Redis in a native way.\nFor now, the good thing is that the complexity may be easily encapsulated\ninside a library that can be used in order to perform indexing and queries.\nOne example of such library is Redimension, a proof of concept Ruby library which indexes N-dimensional data inside Redis using the technique described here.\nMulti dimensional indexes with negative or floating point numbers\nThe simplest way to represent negative values is just to work with unsigned\nintegers and represent them using an offset, so that when you index, before\ntranslating numbers in the indexed representation, you add the absolute value\nof your smaller negative integer.\nFor floating point numbers, the simplest approach is probably to convert them\nto integers by multiplying the integer for a power of ten proportional to the\nnumber of digits after the dot you want to retain.\nNon range indexes\nSo far we checked indexes which are useful to query by range or by single\nitem. However other Redis data structures such as Sets or Lists can be used\nin order to build other kind of indexes. They are very commonly used but\nmaybe we don't always realize they are actually a form of indexing.\nFor instance I can index object IDs into a Set data type in order to use\nthe get random elements operation via `SRANDMEMBER` in order to retrieve\na set of random objects. Sets can also be used to check for existence when\nall I need is to test if a given item exists or not or has a single boolean\nproperty or not.\nSimilarly lists can be used in order to index items into a fixed order.\nI can add all my items into a Redis list and rotate the list with\n`RPOPLPUSH` using the same key name as source and destination. This is useful\nwhen I want to process a given set of items again and again forever in the\nsame order. Think of an RSS feed system that needs to refresh the local copy\nperiodically.\nAnother popular index often used with Redis is a capped list, where items\nare added with `LPUSH` and trimmed with `LTRIM`, in order to create a view\nwith just the latest N items encountered, in the same order they were\nseen.\nIndex inconsistency\nKeeping the index updated may be challenging, in the course of months\nor years it is possible that inconsistencies are added because of software\nbugs, network partitions or other events.\nDifferent strategies could be used. If the index data is outside Redis\nread repair can be a solution, where data is fixed in a lazy way when\nit is requested. When we index data which is stored in Redis itself\nthe `SCAN` family of commands can be used in order to verify, update or",
    "tag": "redis"
  },
  {
    "title": "Request/Response protocols and round-trip time (RTT)",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/pipelining/index.md",
    "content": "\ntitle: \"Redis pipelining\"\nlinkTitle: \"Pipelining\"\nweight: 2\ndescription: How to optimize round-trip times by batching Redis commands\naliases:\n  - /topics/pipelining\n\nRedis pipelining is a technique for improving performance by issuing multiple commands at once without waiting for the response to each individual command. Pipelining is supported by most Redis clients. This document describes the problem that pipelining is designed to solve and how pipelining works in Redis.\nRequest/Response protocols and round-trip time (RTT)\nRedis is a TCP server using the client-server model and what is called a Request/Response protocol.\nThis means that usually a request is accomplished with the following steps:\n\nThe client sends a query to the server, and reads from the socket, usually in a blocking way, for the server response.\nThe server processes the command and sends the response back to the client.\n\nSo for instance a four commands sequence is something like this:\n\nClient: INCR X\nServer: 1\nClient: INCR X\nServer: 2\nClient: INCR X\nServer: 3\nClient: INCR X\nServer: 4\n\nClients and Servers are connected via a network link.\nSuch a link can be very fast (a loopback interface) or very slow (a connection established over the Internet with many hops between the two hosts).\nWhatever the network latency is, it takes time for the packets to travel from the client to the server, and back from the server to the client to carry the reply.\nThis time is called RTT (Round Trip Time).\nIt's easy to see how this can affect performance when a client needs to perform many requests in a row (for instance adding many elements to the same list, or populating a database with many keys).\nFor instance if the RTT time is 250 milliseconds (in the case of a very slow link over the Internet), even if the server is able to process 100k requests per second, we'll be able to process at max four requests per second.\nIf the interface used is a loopback interface, the RTT is much shorter, typically sub-millisecond, but even this will add up to a lot if you need to perform many writes in a row.\nFortunately there is a way to improve this use case.\nRedis Pipelining\nA Request/Response server can be implemented so that it is able to process new requests even if the client hasn't already read the old responses.\nThis way it is possible to send multiple commands to the server without waiting for the replies at all, and finally read the replies in a single step.\nThis is called pipelining, and is a technique widely in use for many decades.\nFor instance many POP3 protocol implementations already support this feature, dramatically speeding up the process of downloading new emails from the server.\nRedis has supported pipelining since its early days, so whatever version you are running, you can use pipelining with Redis.\nThis is an example using the raw netcat utility:\n`bash \n$ (printf \"PING\\r\\nPING\\r\\nPING\\r\\n\"; sleep 1) | nc localhost 6379\n+PONG\n+PONG\n+PONG`\nThis time we don't pay the cost of RTT for every call, but just once for the three commands.\nTo be explicit, with pipelining the order of operations of our very first example will be the following:\n\nClient: INCR X\nClient: INCR X\nClient: INCR X\nClient: INCR X\nServer: 1\nServer: 2\nServer: 3\nServer: 4\n\n\nIMPORTANT NOTE: While the client sends commands using pipelining, the server will be forced to queue the replies, using memory. So if you need to send a lot of commands with pipelining, it is better to send them as batches each containing a reasonable number, for instance 10k commands, read the replies, and then send another 10k commands again, and so forth. The speed will be nearly the same, but the additional memory used will be at most the amount needed to queue the replies for these 10k commands.\n\nIt's not just a matter of RTT\nPipelining is not just a way to reduce the latency cost associated with the\nround trip time, it actually greatly improves the number of operations\nyou can perform per second in a given Redis server.\nThis is because without using pipelining, serving each command is very cheap from\nthe point of view of accessing the data structures and producing the reply,\nbut it is very costly from the point of view of doing the socket I/O. This\ninvolves calling the `read()` and `write()` syscall, that means going from user\nland to kernel land.\nThe context switch is a huge speed penalty.\nWhen pipelining is used, many commands are usually read with a single `read()`\nsystem call, and multiple replies are delivered with a single `write()` system\ncall. Consequently, the number of total queries performed per second\ninitially increases almost linearly with longer pipelines, and eventually\nreaches 10 times the baseline obtained without pipelining, as shown in this figure.\n\nA real world code example\nIn the following benchmark we'll use the Redis Ruby client, supporting pipelining, to test the speed improvement due to pipelining:\n```ruby\nrequire 'rubygems'\nrequire 'redis'\ndef bench(descr)\n  start = Time.now\n  yield\n  puts \"#{descr} #{Time.now - start} seconds\"\nend\ndef without_pipelining\n  r = Redis.new\n  10_000.times do\n    r.ping\n  end\nend\ndef with_pipelining\n  r = Redis.new\n  r.pipelined do\n    10_000.times do\n      r.ping\n    end\n  end\nend\nbench('without pipelining') do\n  without_pipelining\nend\nbench('with pipelining') do\n  with_pipelining\nend\n```\nRunning the above simple script yields the following figures on my Mac OS X system, running over the loopback interface, where pipelining will provide the smallest improvement as the RTT is already pretty low:\n`without pipelining 1.185238 seconds\nwith pipelining 0.250783 seconds`\nAs you can see, using pipelining, we improved the transfer by a factor of five.\nPipelining vs Scripting\nUsing Redis scripting, available since Redis 2.6, a number of use cases for pipelining can be addressed more efficiently using scripts that perform a lot of the work needed at the server side.\nA big advantage of scripting is that it is able to both read and write data with minimal latency, making operations like read, compute, write very fast (pipelining can't help in this scenario since the client needs the reply of the read command before it can call the write command).\nSometimes the application may also want to send `EVAL` or `EVALSHA` commands in a pipeline. \nThis is entirely possible and Redis explicitly supports it with the SCRIPT LOAD command (it guarantees that `EVALSHA` can be called without the risk of failing).\nAppendix: Why are busy loops slow even on the loopback interface?\nEven with all the background covered in this page, you may still wonder why\na Redis benchmark like the following (in pseudo code), is slow even when\nexecuted in the loopback interface, when the server and the client are running\nin the same physical machine:\n`sh\nFOR-ONE-SECOND:\n    Redis.SET(\"foo\",\"bar\")\nEND`\nAfter all, if both the Redis process and the benchmark are running in the same\nbox, isn't it just copying messages in memory from one place to another without\nany actual latency or networking involved?\nThe reason is that processes in a system are not always running, actually it is\nthe kernel scheduler that lets the process run. \nSo, for instance, when the benchmark is allowed to run, it reads the reply from the Redis server (related to the last command executed), and writes a new command.\nThe command is now in the loopback interface buffer, but in order to be read by the server, the kernel should schedule the server process (currently blocked in a system call)\nto run, and so forth.\nSo in practical terms the loopback interface still involves network-like latency, because of how the kernel scheduler works.\nBasically a busy loop benchmark is the silliest thing that can be done when\nmetering performances on a networked server. The wise thing is just avoiding",
    "tag": "redis"
  },
  {
    "title": "Prologue (or, what's wrong with Eval Scripts?)",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/programmability/functions-intro.md",
    "content": "\ntitle: \"Redis functions\"\nlinkTitle: \"Functions\"\nweight: 1\ndescription: >\n   Scripting with Redis 7 and beyond\naliases:\n    - /topics/functions-intro\n\nRedis Functions is an API for managing code to be executed on the server. This feature, which became available in Redis 7, supersedes the use of EVAL in prior versions of Redis.\nPrologue (or, what's wrong with Eval Scripts?)\nPrior versions of Redis made scripting available only via the `EVAL` command, which allows a Lua script to be sent for execution by the server.\nThe core use cases for Eval Scripts is executing part of your application logic inside Redis, efficiently and atomically.\nSuch script can perform conditional updates across multiple keys, possibly combining several different data types.\nUsing `EVAL` requires that the application sends the entire script for execution every time.\nBecause this results in network and script compilation overheads, Redis provides an optimization in the form of the `EVALSHA` command. By first calling `SCRIPT LOAD` to obtain the script's SHA1, the application can invoke it repeatedly afterward with its digest alone.\nBy design, Redis only caches the loaded scripts.\nThat means that the script cache can become lost at any time, such as after calling `SCRIPT FLUSH`, after restarting the server, or when failing over to a replica.\nThe application is responsible for reloading scripts during runtime if any are missing.\nThe underlying assumption is that scripts are a part of the application and not maintained by the Redis server.\nThis approach suits many light-weight scripting use cases, but introduces several difficulties once an application becomes complex and relies more heavily on scripting, namely:\n\nAll client application instances must maintain a copy of all scripts. That means having some mechanism that applies script updates to all of the application's instances.\nCalling cached scripts within the context of a transaction increases the probability of the transaction failing because of a missing script. Being more likely to fail makes using cached scripts as building blocks of workflows less attractive.\nSHA1 digests are meaningless, making debugging the system extremely hard (e.g., in a `MONITOR` session).\nWhen used naively, `EVAL` promotes an anti-pattern in which scripts the client application renders verbatim scripts instead of responsibly using the !KEYS and ARGV Lua APIs.\nBecause they are ephemeral, a script can't call another script. This makes sharing and reusing code between scripts nearly impossible, short of client-side preprocessing (see the first point).\n\nTo address these needs while avoiding breaking changes to already-established and well-liked ephemeral scripts, Redis v7.0 introduces Redis Functions.\nWhat are Redis Functions?\nRedis functions are an evolutionary step from ephemeral scripting.\nFunctions provide the same core functionality as scripts but are first-class software artifacts of the database.\nRedis manages functions as an integral part of the database and ensures their availability via data persistence and replication.\nBecause functions are part of the database and therefore declared before use, applications aren't required to load them during runtime nor risk aborted transactions.\nAn application that uses functions depends only on their APIs rather than on the embedded script logic in the database.\nWhereas ephemeral scripts are considered a part of the application's domain, functions extend the database server itself with user-provided logic.\nThey can be used to expose a richer API composed of core Redis commands, similar to modules, developed once, loaded at startup, and used repeatedly by various applications / clients.\nEvery function has a unique user-defined name, making it much easier to call and trace its execution.\nThe design of Redis Functions also attempts to demarcate between the programming language used for writing functions and their management by the server.\nLua, the only language interpreter that Redis presently support as an embedded execution engine, is meant to be simple and easy to learn.\nHowever, the choice of Lua as a language still presents many Redis users with a challenge.\nThe Redis Functions feature makes no assumptions about the implementation's language.\nAn execution engine that is part of the definition of the function handles running it.\nAn engine can theoretically execute functions in any language as long as it respects several rules (such as the ability to terminate an executing function).\nPresently, as noted above, Redis ships with a single embedded Lua 5.1 engine.\nThere are plans to support additional engines in the future.\nRedis functions can use all of Lua's available capabilities to ephemeral scripts,\nwith the only exception being the Redis Lua scripts debugger.\nFunctions also simplify development by enabling code sharing.\nEvery function belongs to a single library, and any given library can consist of multiple functions.\nThe library's contents are immutable, and selective updates of its functions aren't allowed.\nInstead, libraries are updated as a whole with all of their functions together in one operation.\nThis allows calling functions from other functions within the same library, or sharing code between functions by using a common code in library-internal methods, that can also take language native arguments.\nFunctions are intended to better support the use case of maintaining a consistent view for data entities through a logical schema, as mentioned above.\nAs such, functions are stored alongside the data itself.\nFunctions are also persisted to the AOF file and replicated from master to replicas, so they are as durable as the data itself.\nWhen Redis is used as an ephemeral cache, additional mechanisms (described below) are required to make functions more durable.\nLike all other operations in Redis, the execution of a function is atomic.\nA function's execution blocks all server activities during its entire time, similarly to the semantics of transactions.\nThese semantics mean that all of the script's effects either have yet to happen or had already happened.\nThe blocking semantics of an executed function apply to all connected clients at all times.\nBecause running a function blocks the Redis server, functions are meant to finish executing quickly, so you should avoid using long-running functions.\nLoading libraries and functions\nLet's explore Redis Functions via some tangible examples and Lua snippets.\nAt this point, if you're unfamiliar with Lua in general and specifically in Redis, you may benefit from reviewing some of the examples in Introduction to Eval Scripts and Lua API pages for a better grasp of the language.\nEvery Redis function belongs to a single library that's loaded to Redis.\nLoading a library to the database is done with the `FUNCTION LOAD` command.\nThe command gets the library payload as input,\nthe library payload must start with Shebang statement that provides a metadata about the library (like the engine to use and the library name).\nThe Shebang format is:\n```\n! name=\n```\nLet's try loading an empty library:\n`redis> FUNCTION LOAD \"#!lua name=mylib\\n\"\n(error) ERR No functions registered`\nThe error is expected, as there are no functions in the loaded library. Every library needs to include at least one registered function to load successfully.\nA registered function is named and acts as an entry point to the library.\nWhen the target execution engine handles the `FUNCTION LOAD` command, it registers the library's functions.\nThe Lua engine compiles and evaluates the library source code when loaded, and expects functions to be registered by calling the `redis.register_function()` API.\nThe following snippet demonstrates a simple library registering a single function named knockknock, returning a string reply:\n```lua\n!lua name=mylib\nredis.register_function(\n  'knockknock',\n  function() return 'Who\\'s there?' end\n)\n```\nIn the example above, we provide two arguments about the function to Lua's `redis.register_function()` API: its registered name and a callback.\nWe can load our library and use `FCALL` to call the registered function:\n`redis> FUNCTION LOAD \"#!lua name=mylib\\nredis.register_function('knockknock', function() return 'Who\\\\'s there?' end)\"\nmylib\nredis> FCALL knockknock 0\n\"Who's there?\"`\nNotice that the `FUNCTION LOAD` command returns the name of the loaded library, this name can later be used `FUNCTION LIST` and `FUNCTION DELETE`.\nWe've provided `FCALL` with two arguments: the function's registered name and the numeric value `0`. This numeric value indicates the number of key names that follow it (the same way `EVAL` and `EVALSHA` work).\nWe'll explain immediately how key names and additional arguments are available to the function. As this simple example doesn't involve keys, we simply use 0 for now.\nInput keys and regular arguments\nBefore we move to the following example, it is vital to understand the distinction Redis makes between arguments that are names of keys and those that aren't.\nWhile key names in Redis are just strings, unlike any other string values, these represent keys in the database.\nThe name of a key is a fundamental concept in Redis and is the basis for operating the Redis Cluster.\nImportant:\nTo ensure the correct execution of Redis Functions, both in standalone and clustered deployments, all names of keys that a function accesses must be explicitly provided as input key arguments.\nAny input to the function that isn't the name of a key is a regular input argument.\nNow, let's pretend that our application stores some of its data in Redis Hashes.\nWe want an `HSET`-like way to set and update fields in said Hashes and store the last modification time in a new field named `_last_modified_`.\nWe can implement a function to do all that.\nOur function will call `TIME` to get the server's clock reading and update the target Hash with the new fields' values and the modification's timestamp.\nThe function we'll implement accepts the following input arguments: the Hash's key name and the field-value pairs to update.\nThe Lua API for Redis Functions makes these inputs accessible as the first and second arguments to the function's callback.\nThe callback's first argument is a Lua table populated with all key names inputs to the function.\nSimilarly, the callback's second argument consists of all regular arguments.\nThe following is a possible implementation for our function and its library registration:\n```lua\n!lua name=mylib\nlocal function my_hset(keys, args)\n  local hash = keys[1]\n  local time = redis.call('TIME')[1]\n  return redis.call('HSET', hash, 'last_modified', time, unpack(args))\nend\nredis.register_function('my_hset', my_hset)\n```\nIf we create a new file named mylib.lua that consists of the library's definition, we can load it like so (without stripping the source code of helpful whitespaces):\n`bash\n$ cat mylib.lua | redis-cli -x FUNCTION LOAD REPLACE`\nWe've added the `REPLACE` modifier to the call to `FUNCTION LOAD` to tell Redis that we want to overwrite the existing library definition.\nOtherwise, we would have gotten an error from Redis complaining that the library already exists.\nNow that the library's updated code is loaded to Redis, we can proceed and call our function:\n`redis> FCALL my_hset 1 myhash myfield \"some value\" another_field \"another value\"\n(integer) 3\nredis> HGETALL myhash\n1) \"_last_modified_\"\n2) \"1640772721\"\n3) \"myfield\"\n4) \"some value\"\n5) \"another_field\"\n6) \"another value\"`\nIn this case, we had invoked `FCALL` with 1 as the number of key name arguments.\nThat means that the function's first input argument is a name of a key (and is therefore included in the callback's `keys` table).\nAfter that first argument, all following input arguments are considered regular arguments and constitute the `args` table passed to the callback as its second argument.\nExpanding the library\nWe can add more functions to our library to benefit our application.\nThe additional metadata field we've added to the Hash shouldn't be included in responses when accessing the Hash's data.\nOn the other hand, we do want to provide the means to obtain the modification timestamp for a given Hash key.\nWe'll add two new functions to our library to accomplish these objectives:\n\nThe `my_hgetall` Redis Function will return all fields and their respective values from a given Hash key name, excluding the metadata (i.e., the `_last_modified_` field).\nThe `my_hlastmodified` Redis Function will return the modification timestamp for a given Hash key name.\n\nThe library's source code could look something like the following:\n```lua\n!lua name=mylib\nlocal function my_hset(keys, args)\n  local hash = keys[1]\n  local time = redis.call('TIME')[1]\n  return redis.call('HSET', hash, 'last_modified', time, unpack(args))\nend\nlocal function my_hgetall(keys, args)\n  redis.setresp(3)\n  local hash = keys[1]\n  local res = redis.call('HGETALL', hash)\n  res['map']['last_modified'] = nil\n  return res\nend\nlocal function my_hlastmodified(keys, args)\n  local hash = keys[1]\n  return redis.call('HGET', hash, 'last_modified')\nend\nredis.register_function('my_hset', my_hset)\nredis.register_function('my_hgetall', my_hgetall)\nredis.register_function('my_hlastmodified', my_hlastmodified)\n```\nWhile all of the above should be straightforward, note that the `my_hgetall` also calls redis.setresp(3).\nThat means that the function expects RESP3 replies after calling `redis.call()`, which, unlike the default RESP2 protocol, provides dictionary (associative arrays) replies.\nDoing so allows the function to delete (or set to `nil` as is the case with Lua tables) specific fields from the reply, and in our case, the `_last_modified_` field.\nAssuming you've saved the library's implementation in the mylib.lua file, you can replace it with:\n`bash\n$ cat mylib.lua | redis-cli -x FUNCTION LOAD REPLACE`\nOnce loaded, you can call the library's functions with `FCALL`:\n`redis> FCALL my_hgetall 1 myhash\n1) \"myfield\"\n2) \"some value\"\n3) \"another_field\"\n4) \"another value\"\nredis> FCALL my_hlastmodified 1 myhash\n\"1640772721\"`\nYou can also get the library's details with the `FUNCTION LIST` command:\n`redis> FUNCTION LIST\n1) 1) \"library_name\"\n   2) \"mylib\"\n   3) \"engine\"\n   4) \"LUA\"\n   5) \"functions\"\n   6) 1) 1) \"name\"\n         2) \"my_hset\"\n         3) \"description\"\n         4) (nil)\n      2) 1) \"name\"\n         2) \"my_hgetall\"\n         3) \"description\"\n         4) (nil)\n      3) 1) \"name\"\n         2) \"my_hlastmodified\"\n         3) \"description\"\n         4) (nil)`\nYou can see that it is easy to update our library with new capabilities.\nReusing code in the library\nOn top of bundling functions together into database-managed software artifacts, libraries also facilitate code sharing.\nWe can add to our library an error handling helper function called from other functions.\nThe helper function `check_keys()` verifies that the input keys table has a single key.\nUpon success it returns `nil`, otherwise it returns an error reply.\nThe updated library's source code would be:\n```lua\n!lua name=mylib\nlocal function check_keys(keys)\n  local error = nil\n  local nkeys = table.getn(keys)\n  if nkeys == 0 then\n    error = 'Hash key name not provided'\n  elseif nkeys > 1 then\n    error = 'Only one key name is allowed'\n  end\nif error ~= nil then\n    redis.log(redis.LOG_WARNING, error);\n    return redis.error_reply(error)\n  end\n  return nil\nend\nlocal function my_hset(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\nlocal hash = keys[1]\n  local time = redis.call('TIME')[1]\n  return redis.call('HSET', hash, 'last_modified', time, unpack(args))\nend\nlocal function my_hgetall(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\nredis.setresp(3)\n  local hash = keys[1]\n  local res = redis.call('HGETALL', hash)\n  res['map']['last_modified'] = nil\n  return res\nend\nlocal function my_hlastmodified(keys, args)\n  local error = check_keys(keys)\n  if error ~= nil then\n    return error\n  end\nlocal hash = keys[1]\n  return redis.call('HGET', keys[1], 'last_modified')\nend\nredis.register_function('my_hset', my_hset)\nredis.register_function('my_hgetall', my_hgetall)\nredis.register_function('my_hlastmodified', my_hlastmodified)\n```\nAfter you've replaced the library in Redis with the above, you can immediately try out the new error handling mechanism:\n`127.0.0.1:6379> FCALL my_hset 0 myhash nope nope\n(error) Hash key name not provided\n127.0.0.1:6379> FCALL my_hgetall 2 myhash anotherone\n(error) Only one key name is allowed`\nAnd your Redis log file should have lines in it that are similar to:\n`...\n20075:M 1 Jan 2022 16:53:57.688 # Hash key name not provided\n20075:M 1 Jan 2022 16:54:01.309 # Only one key name is allowed`\nFunctions in cluster\nAs noted above, Redis automatically handles propagation of loaded functions to replicas.\nIn a Redis Cluster, it is also necessary to load functions to all cluster nodes. This is not handled automatically by Redis Cluster, and needs to be handled by the cluster administrator (like module loading, configuration setting, etc.).\nAs one of the goals of functions is to live separately from the client application, this should not be part of the Redis client library responsibilities. Instead, `redis-cli --cluster-only-masters --cluster call host:port FUNCTION LOAD ...` can be used to execute the load command on all master nodes.\nAlso, note that `redis-cli --cluster add-node` automatically takes care to propagate the loaded functions from one of the existing nodes to the new node.\nFunctions and ephemeral Redis instances\nIn some cases there may be a need to start a fresh Redis server with a set of functions pre-loaded. Common reasons for that could be:\n\nStarting Redis in a new environment\nRe-starting an ephemeral (cache-only) Redis, that uses functions\n\nIn such cases, we need to make sure that the pre-loaded functions are available before Redis accepts inbound user connections and commands.\nTo do that, it is possible to use `redis-cli --functions-rdb` to extract the functions from an existing server. This generates an RDB file that can be loaded by Redis at startup.\nFunction flags\nRedis needs to have some information about how a function is going to behave when executed, in order to properly enforce resource usage policies and maintain data consistency.\nFor example, Redis needs to know that a certain function is read-only before permitting it to execute using `FCALL_RO` on a read-only replica.\nBy default, Redis assumes that all functions may perform arbitrary read or write operations. Function Flags make it possible to declare more specific function behavior at the time of registration. Let's see how this works.\nIn our previous example, we defined two functions that only read data. We can try executing them using `FCALL_RO` against a read-only replica.\n`redis > FCALL_RO my_hgetall 1 myhash\n(error) ERR Can not execute a function with write flag using fcall_ro.`\nRedis returns this error because a function can, in theory, perform both read and write operations on the database.\nAs a safeguard and by default, Redis assumes that the function does both, so it blocks its execution.\nThe server will reply with this error in the following cases:\n\nExecuting a function with `FCALL` against a read-only replica.\nUsing `FCALL_RO` to execute a function.\nA disk error was detected (Redis is unable to persist so it rejects writes).\n\nIn these cases, you can add the `no-writes` flag to the function's registration, disable the safeguard and allow them to run.\nTo register a function with flags use the named arguments variant of `redis.register_function`.\nThe updated registration code snippet from the library looks like this:\n`lua\nredis.register_function('my_hset', my_hset)\nredis.register_function{\n  function_name='my_hgetall',\n  callback=my_hgetall,\n  flags={ 'no-writes' }\n}\nredis.register_function{\n  function_name='my_hlastmodified',\n  callback=my_hlastmodified,\n  flags={ 'no-writes' }\n}`\nOnce we've replaced the library, Redis allows running both `my_hgetall` and `my_hlastmodified` with `FCALL_RO` against a read-only replica:\n`redis> FCALL_RO my_hgetall 1 myhash\n1) \"myfield\"\n2) \"some value\"\n3) \"another_field\"\n4) \"another value\"\nredis> FCALL_RO my_hlastmodified 1 myhash\n\"1640772721\"`",
    "tag": "redis"
  },
  {
    "title": "Quick start",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/programmability/lua-debugging.md",
    "content": "\ntitle: Debugging Lua scripts in Redis\nlinkTitle: Debugging Lua\ndescription: How to use the built-in Lua debugger\nweight: 4\naliases:\n  - /topics/ldb\n\nStarting with version 3.2 Redis includes a complete Lua debugger, that can be\nused in order to make the task of writing complex Redis scripts much simpler.\nThe Redis Lua debugger, codenamed LDB, has the following important features:\n\nIt uses a server-client model, so it's a remote debugger.\nThe Redis server acts as the debugging server, while the default client is `redis-cli`. \nHowever other clients can be developed by following the simple protocol implemented by the server.\nBy default every new debugging session is a forked session.\nIt means that while the Redis Lua script is being debugged, the server does not block and is usable for development or in order to execute multiple debugging sessions in parallel.\nThis also means that changes are rolled back after the script debugging session finished, so that's possible to restart a new debugging session again, using exactly the same Redis data set as the previous debugging session.\nAn alternative synchronous (non forked) debugging model is available on demand, so that changes to the dataset can be retained.\nIn this mode the server blocks for the time the debugging session is active.\nSupport for step by step execution.\nSupport for static and dynamic breakpoints.\nSupport from logging the debugged script into the debugger console.\nInspection of Lua variables.\nTracing of Redis commands executed by the script.\nPretty printing of Redis and Lua values.\nInfinite loops and long execution detection, which simulates a breakpoint.\n\nQuick start\nA simple way to get started with the Lua debugger is to watch this video\nintroduction:\n\n\nImportant Note:  please make sure to avoid debugging Lua scripts using your Redis production server.\nUse a development server instead.\nAlso note that using the synchronous debugging mode (which is NOT the default) results in the Redis server blocking for all the time the debugging session lasts.\n\nTo start a new debugging session using `redis-cli` do the following:\n\nCreate your script in some file with your preferred editor. Let's assume you are editing your Redis Lua script located at `/tmp/script.lua`.\n\nStart a debugging session with:\n./redis-cli --ldb --eval /tmp/script.lua\n\n\nNote that with the `--eval` option of `redis-cli` you can pass key names and arguments to the script, separated by a comma, like in the following example:\n`./redis-cli --ldb --eval /tmp/script.lua mykey somekey , arg1 arg2`\nYou'll enter a special mode where `redis-cli` no longer accepts its normal\ncommands, but instead prints a help screen and passes the unmodified debugging\ncommands directly to Redis.\nThe only commands which are not passed to the Redis debugger are:\n\n`quit` -- this will terminate the debugging session.\nIt's like removing all the breakpoints and using the `continue` debugging command.\nMoreover the command will exit from `redis-cli`.\n`restart` -- the debugging session will restart from scratch, reloading the new version of the script from the file.\nSo a normal debugging cycle involves modifying the script after some debugging, and calling `restart` in order to start debugging again with the new script changes.\n`help` -- this command is passed to the Redis Lua debugger, that will print a list of commands like the following:\n\n```\nlua debugger> help\nRedis Lua debugger help:\n[h]elp               Show this help.\n[s]tep               Run current line and stop again.\n[n]ext               Alias for step.\n[c]continue          Run till next breakpoint.\n[l]list              List source code around current line.\n[l]list [line]       List source code around [line].\n                     line = 0 means: current position.\n[l]list [line] [ctx] In this form [ctx] specifies how many lines\n                     to show before/after [line].\n[w]hole              List all source code. Alias for 'list 1 1000000'.\n[p]rint              Show all the local variables.\n[p]rint         Show the value of the specified variable.\n                     Can also show global vars KEYS and ARGV.\n[b]reak              Show all breakpoints.\n[b]reak        Add a breakpoint to the specified line.\n[b]reak -      Remove breakpoint from the specified line.\n[b]reak 0            Remove all breakpoints.\n[t]race              Show a backtrace.\n[e]eval `       Execute some Lua code (in a different callframe).\n[r]edis         Execute a Redis command.\n[m]axlen [len]       Trim logged Redis replies and Lua var dumps to len.\n                     Specifying zero as  means unlimited.\n[a]abort             Stop the execution of the script. In sync\n                     mode dataset changes will be retained.`\nDebugger functions you can call from Lua scripts:\nredis.debug()        Produce logs in the debugger console.\nredis.breakpoint()   Stop execution as if there was a breakpoint in the\n                     next line of code.\n```\nNote that when you start the debugger it will start in stepping mode.\nIt will stop at the first line of the script that actually does something before executing it.\nFrom this point you usually call `step` in order to execute the line and go to the next line.\nWhile you step Redis will show all the commands executed by the server like in the following example:\n`* Stopped at 1, stop reason = step over\n-> 1   redis.call('ping')\nlua debugger> step\n<redis> ping\n<reply> \"+PONG\"\n* Stopped at 2, stop reason = step over`\nThe `<redis>` and `<reply>` lines show the command executed by the line just\nexecuted, and the reply from the server. Note that this happens only in stepping mode.\nIf you use `continue` in order to execute the script till the next breakpoint, commands will not be dumped on the screen to prevent too much output.\nTermination of the debugging session\nWhen the scripts terminates naturally, the debugging session ends and\n`redis-cli` returns in its normal non-debugging mode. You can restart the\nsession using the `restart` command as usual.\nAnother way to stop a debugging session is just interrupting `redis-cli`\nmanually by pressing `Ctrl+C`. Note that also any event breaking the\nconnection between `redis-cli` and the `redis-server` will interrupt the\ndebugging session.\nAll the forked debugging sessions are terminated when the server is shut\ndown.\nAbbreviating debugging commands\nDebugging can be a very repetitive task. For this reason every Redis\ndebugger command starts with a different character, and you can use the single\ninitial character in order to refer to the command.\nSo for example instead of typing `step` you can just type `s`.\nBreakpoints\nAdding and removing breakpoints is trivial as described in the online help.\nJust use `b 1 2 3 4` to add a breakpoint in line 1, 2, 3, 4.\nThe command `b 0` removes all the breakpoints. Selected breakpoints can be\nremoved using as argument the line where the breakpoint we want to remove is, but prefixed by a minus sign. \nSo for example `b -3` removes the breakpoint from line 3.\nNote that adding breakpoints to lines that Lua never executes, like declaration of local variables or comments, will not work.\nThe breakpoint will be added but since this part of the script will never be executed, the program will never stop.\nDynamic breakpoints\nUsing the `breakpoint` command it is possible to add breakpoints into specific\nlines. However sometimes we want to stop the execution of the program only\nwhen something special happens. In order to do so, you can use the\n`redis.breakpoint()` function inside your Lua script. When called it simulates\na breakpoint in the next line that will be executed.\n`if counter > 10 then redis.breakpoint() end`\nThis feature is extremely useful when debugging, so that we can avoid\ncontinuing the script execution manually multiple times until a given condition\nis encountered.\nSynchronous mode\nAs explained previously, but default LDB uses forked sessions with rollback\nof all the data changes operated by the script while it has being debugged.\nDeterminism is usually a good thing to have during debugging, so that successive\ndebugging sessions can be started without having to reset the database content\nto its original state.\nHowever for tracking certain bugs, you may want to retain the changes performed\nto the key space by each debugging session. When this is a good idea you\nshould start the debugger using a special option, `ldb-sync-mode`, in `redis-cli`.\n`./redis-cli --ldb-sync-mode --eval /tmp/script.lua`\n\nNote: Redis server will be unreachable during the debugging session in this mode, so use with care.\n\nIn this special mode, the `abort` command can stop the script half-way taking the changes operated to the dataset.\nNote that this is different compared to ending the debugging session normally. \nIf you just interrupt `redis-cli` the script will be fully executed and then the session terminated.\nInstead with `abort` you can interrupt the script execution in the middle and start a new debugging session if needed.\nLogging from scripts\nThe `redis.debug()` command is a powerful debugging facility that can be\ncalled inside the Redis Lua script in order to log things into the debug\nconsole:\n`lua debugger> list\n-> 1   local a = {1,2,3}\n   2   local b = false\n   3   redis.debug(a,b)\nlua debugger> continue\n<debug> line 3: {1; 2; 3}, false`\nIf the script is executed outside of a debugging session, `redis.debug()` has no effects at all.\nNote that the function accepts multiple arguments, that are separated by a comma and a space in the output.\nTables and nested tables are displayed correctly in order to make values simple to observe for the programmer debugging the script.\nInspecting the program state with `print` and `eval`\nWhile the `redis.debug()` function can be used in order to print values\ndirectly from within the Lua script, often it is useful to observe the local\nvariables of a program while stepping or when stopped into a breakpoint.\nThe `print` command does just that, and performs lookup in the call frames\nstarting from the current one back to the previous ones, up to top-level.\nThis means that even if we are into a nested function inside a Lua script,\nwe can still use `print foo` to look at the value of `foo` in the context\nof the calling function. When called without a variable name, `print` will\nprint all variables and their respective values.\nThe `eval` command executes small pieces of Lua scripts outside the context of the current call frame (evaluating inside the context of the current call frame is not possible with the current Lua internals).\nHowever you can use this command in order to test Lua functions.\n`lua debugger> e redis.sha1hex('foo')\n<retval> \"0beec7b5ea3f0fdbc95d0dd47f3c5bc275da8a33\"`\nDebugging clients\nLDB uses the client-server model where the Redis server acts as a debugging server that communicates using RESP. While `redis-cli` is the default debug client, any client can be used for debugging as long as it meets one of the following conditions:\n\nThe client provides a native interface for setting the debug mode and controlling the debug session.\nThe client provides an interface for sending arbitrary commands over RESP.\nThe client allows sending raw messages to the Redis server.\n\nFor example, the Redis plugin for ZeroBrane Studio integrates with LDB using redis-lua. The following Lua code is a simplified example of how the plugin achieves that:\n```Lua\nlocal redis = require 'redis'\n-- add LDB's Continue command\nredis.commands['ldbcontinue'] = redis.command('C')\n-- script to be debugged\nlocal script = [[\n  local x, y = tonumber(ARGV[1]), tonumber(ARGV[2])\n  local result = x * y\n  return result\n]]\nlocal client = redis.connect('127.0.0.1', 6379)\nclient:script(\"DEBUG\", \"YES\")\nprint(unpack(client:eval(script, 0, 6, 9)))\nclient:ldbcontinue()",
    "tag": "redis"
  },
  {
    "title": "Getting started",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/programmability/eval-intro.md",
    "content": "\ntitle: \"Scripting with Lua\"\nlinkTitle: \"Lua scripting\"\nweight: 2\ndescription: >\n   Executing Lua in Redis\naliases:\n    - /topics/eval-intro\n\nRedis lets users upload and execute Lua scripts on the server.\nScripts can employ programmatic control structures and use most of the commands while executing to access the database.\nBecause scripts execute in the server, reading and writing data from scripts is very efficient.\nRedis guarantees the script's atomic execution.\nWhile executing the script, all server activities are blocked during its entire runtime.\nThese semantics mean that all of the script's effects either have yet to happen or had already happened.\nScripting offers several properties that can be valuable in many cases.\nThese include:\n\nProviding locality by executing logic where data lives. Data locality reduces overall latency and saves networking resources.\nBlocking semantics that ensure the script's atomic execution.\nEnabling the composition of simple capabilities that are either missing from Redis or are too niche to a part of it.\n\nLua lets you run part of your application logic inside Redis.\nSuch scripts can perform conditional updates across multiple keys, possibly combining several different data types atomically.\nScripts are executed in Redis by an embedded execution engine.\nPresently, Redis supports a single scripting engine, the Lua 5.1 interpreter.\nPlease refer to the Redis Lua API Reference page for complete documentation.\nAlthough the server executes them, Eval scripts are regarded as a part of the client-side application, which is why they're not named, versioned, or persisted.\nSo all scripts may need to be reloaded by the application at any time if missing (after a server restart, fail-over to a replica, etc.).\nAs of version 7.0, Redis Functions offer an alternative approach to programmability which allow the server itself to be extended with additional programmed logic.\nGetting started\nWe'll start scripting with Redis by using the `EVAL` command.\nHere's our first example:\n```\n\nEVAL \"return 'Hello, scripting!'\" 0\n\"Hello, scripting!\"\n```\n\nIn this example, `EVAL` takes two arguments.\nThe first argument is a string that consists of the script's Lua source code.\nThe script doesn't need to include any definitions of Lua function.\nIt is just a Lua program that will run in the Redis engine's context.\nThe second argument is the number of arguments that follow the script's body, starting from the third argument, representing Redis key names.\nIn this example, we used the value 0 because we didn't provide the script with any arguments, whether the names of keys or not.\nScript parameterization\nIt is possible, although highly ill-advised, to have the application dynamically generate script source code per its needs.\nFor example, the application could send these two entirely different, but at the same time perfectly identical scripts:\n`redis> EVAL \"return 'Hello'\" 0\n\"Hello\"\nredis> EVAL \"return 'Scripting!'\" 0\n\"Scripting!\"`\nAlthough this mode of operation isn't blocked by Redis, it is an anti-pattern due to script cache considerations (more on the topic below).\nInstead of having your application generate subtle variations of the same scripts, you can parametrize them and pass any arguments needed for to execute them.\nThe following example demonstrates how to achieve the same effects as above, but via parameterization:\n`redis> EVAL \"return ARGV[1]\" 0 Hello\n\"Hello\"\nredis> EVAL \"return ARGV[1]\" 0 Parameterization!\n\"Parameterization!\"`\nAt this point, it is essential to understand the distinction Redis makes between input arguments that are names of keys and those that aren't.\nWhile key names in Redis are just strings, unlike any other string values, these represent keys in the database.\nThe name of a key is a fundamental concept in Redis and is the basis for operating the Redis Cluster.\nImportant:\nto ensure the correct execution of scripts, both in standalone and clustered deployments, all names of keys that a script accesses must be explicitly provided as input key arguments.\nThe script should only access keys whose names are given as input arguments.\nScripts should never access keys with programmatically-generated names or based on the contents of data structures stored in the database.\nAny input to the function that isn't the name of a key is a regular input argument.\nIn the example above, both Hello and Parameterization! regular input arguments for the script.\nBecause the script doesn't touch any keys, we use the numerical argument 0 to specify there are no key name arguments.\nThe execution context makes arguments available to the script through KEYS and ARGV global runtime variables.\nThe KEYS table is pre-populated with all key name arguments provided to the script before its execution, whereas the ARGV table serves a similar purpose but for regular arguments.\nThe following attempts to demonstrate the distribution of input arguments between the scripts KEYS and ARGV runtime global variables:\n`redis> EVAL \"return { KEYS[1], KEYS[2], ARGV[1], ARGV[2], ARGV[3] }\" 2 key1 key2 arg1 arg2 arg3\n1) \"key1\"\n2) \"key2\"\n3) \"arg1\"\n4) \"arg2\"\n5) \"arg3\"`\nNote:\nas can been seen above, Lua's table arrays are returned as RESP2 array replies, so it is likely that your client's library will convert it to the native array data type in your programming language.\nPlease refer to the rules that govern data type conversion for more pertinent information.\nInteracting with Redis from a script\nIt is possible to call Redis commands from a Lua script either via redis.call() or redis.pcall().\nThe two are nearly identical.\nBoth execute a Redis command along with its provided arguments, if these represent a well-formed command.\nHowever, the difference between the two functions lies in the manner in which runtime errors (such as syntax errors, for example) are handled.\nErrors raised from calling `redis.call()` function are returned directly to the client that had executed it.\nConversely, errors encountered when calling the `redis.pcall()` function are returned to the script's execution context instead for possible handling.\nFor example, consider the following:\n```\n\nEVAL \"return redis.call('SET', KEYS[1], ARGV[1])\" 1 foo bar\nOK\n```\nThe above script accepts one key name and one value as its input arguments.\nWhen executed, the script calls the`SET` command to set the input key, foo, with the string value \"bar\".\n\nScript cache\nUntil this point, we've used the `EVAL` command to run our script.\nWhenever we call `EVAL`, we also include the script's source code with the request.\nRepeatedly calling `EVAL` to execute the same set of parameterized scripts, wastes both network bandwidth and also has some overheads in Redis.\nNaturally, saving on network and compute resources is key, so, instead, Redis provides a caching mechanism for scripts.\nEvery script you execute with `EVAL` is stored in a dedicated cache that the server keeps.\nThe cache's contents are organized by the scripts' SHA1 digest sums, so the SHA1 digest sum of a script uniquely identifies it in the cache.\nYou can verify this behavior by running `EVAL` and calling `INFO` afterward.\nYou'll notice that the used_memory_scripts_eval and number_of_cached_scripts metrics grow with every new script that's executed.\nAs mentioned above, dynamically-generated scripts are an anti-pattern.\nGenerating scripts during the application's runtime may, and probably will, exhaust the host's memory resources for caching them.\nInstead, scripts should be as generic as possible and provide customized execution via their arguments.\nA script is loaded to the server's cache by calling the `SCRIPT LOAD` command and providing its source code.\nThe server doesn't execute the script, but instead just compiles and loads it to the server's cache.\nOnce loaded, you can execute the cached script with the SHA1 digest returned from the server.\nHere's an example of loading and then executing a cached script:\n`redis> SCRIPT LOAD \"return 'Immabe a cached script'\"\n\"c664a3bf70bd1d45c4284ffebb65a6f2299bfc9f\"\nredis> EVALSHA c664a3bf70bd1d45c4284ffebb65a6f2299bfc9f 0\n\"Immabe a cached script\"`\nCache volatility\nThe Redis script cache is always volatile.\nIt isn't considered as a part of the database and is not persisted.\nThe cache may be cleared when the server restarts, during fail-over when a replica assumes the master role, or explicitly by `SCRIPT FLUSH`.\nThat means that cached scripts are ephemeral, and the cache's contents can be lost at any time.\nApplications that use scripts should always call `EVALSHA` to execute them.\nThe server returns an error if the script's SHA1 digest is not in the cache.\nFor example:\n`redis> EVALSHA ffffffffffffffffffffffffffffffffffffffff 0\n(error) NOSCRIPT No matching script`\nIn this case, the application should first load it with `SCRIPT LOAD` and then call `EVALSHA` once more to run the cached script by its SHA1 sum.\nMost of Redis' clients already provide utility APIs for doing that automatically.\nPlease consult your client's documentation regarding the specific details.\n`EVALSHA` in the context of pipelining\nSpecial care should be given executing `EVALSHA` in the context of a pipelined request.\nThe commands in a pipelined request run in the order they are sent, but other clients' commands may be interleaved for execution between these.\nBecause of that, the `NOSCRIPT` error can return from a pipelined request but can't be handled.\nTherefore, a client library's implementation should revert to using plain `EVAL` of parameterized in the context of a pipeline.\nScript cache semantics\nDuring normal operation, an application's scripts are meant to stay indefinitely in the cache (that is, until the server is restarted or the cache being flushed).\nThe underlying reasoning is that the script cache contents of a well-written application are unlikely to grow continuously.\nEven large applications that use hundreds of cached scripts shouldn't be an issue in terms of cache memory usage. \nThe only way to flush the script cache is by explicitly calling the `SCRIPT FLUSH` command.\nRunning the command will completely flush the scripts cache, removing all the scripts executed so far.\nTypically, this is only needed when the instance is going to be instantiated for another customer or application in a cloud environment.\nAlso, as already mentioned, restarting a Redis instance flushes the non-persistent script cache.\nHowever, from the point of view of the Redis client, there are only two ways to make sure that a Redis instance was not restarted between two different commands:\n\nThe connection we have with the server is persistent and was never closed so far.\nThe client explicitly checks the `run_id` field in the `INFO` command to ensure the server was not restarted and is still the same process.\n\nPractically speaking, it is much simpler for the client to assume that in the context of a given connection, cached scripts are guaranteed to be there unless the administrator explicitly invoked the `SCRIPT FLUSH` command.\nThe fact that the user can count on Redis to retain cached scripts is semantically helpful in the context of pipelining.\nThe `SCRIPT` command\nThe Redis `SCRIPT` provides several ways for controlling the scripting subsystem.\nThese are:\n\n\n`SCRIPT FLUSH`: this command is the only way to force Redis to flush the scripts cache.\n  It is most useful in environments where the same Redis instance is reassigned to different uses.\n  It is also helpful for testing client libraries' implementations of the scripting feature.\n\n\n`SCRIPT EXISTS`: given one or more SHA1 digests as arguments, this command returns an array of 1's and 0's.\n  1 means the specific SHA1 is recognized as a script already present in the scripting cache. 0's meaning is that a script with this SHA1 wasn't loaded before (or at least never since the latest call to `SCRIPT FLUSH`).\n\n\n`SCRIPT LOAD script`: this command registers the specified script in the Redis script cache. \n  It is a useful command in all the contexts where we want to ensure that `EVALSHA` doesn't not fail (for instance, in a pipeline or when called from a MULTI/EXEC transaction), without the need to execute the script.\n\n\n`SCRIPT KILL`: this command is the only way to interrupt a long-running script (a.k.a slow script), short of shutting down the server.\n  A script is deemed as slow once its execution's duration exceeds the configured maximum execution time threshold.\n  The `SCRIPT KILL` command can be used only with scripts that did not modify the dataset during their execution (since stopping a read-only script does not violate the scripting engine's guaranteed atomicity).\n\n\n`SCRIPT DEBUG`: controls use of the built-in Redis Lua scripts debugger.\n\n\nScript replication\nIn standalone deployments, a single Redis instance called master manages the entire database.\nA clustered deployment has at least three masters managing the sharded database.\nRedis uses replication to maintain one or more replicas, or exact copies, for any given master.\nBecause scripts can modify the data, Redis ensures all write operations performed by a script are also sent to replicas to maintain consistency.\nThere are two conceptual approaches when it comes to script replication:\n\nVerbatim replication: the master sends the script's source code to the replicas.\n   Replicas then execute the script and apply the write effects.\n   This mode can save on replication bandwidth in cases where short scripts generate many commands (for example, a for loop).\n   However, this replication mode means that replicas redo the same work done by the master, which is wasteful.\n   More importantly, it also requires all write scripts to be deterministic.\nEffects replication: only the script's data-modifying commands are replicated.\n   Replicas then run the commands without executing any scripts.\n   While potentially lengthier in terms of network traffic, this replication mode is deterministic by definition and therefore doesn't require special consideration.\n\nVerbatim script replication was the only mode supported until Redis 3.2, in which effects replication was added.\nThe lua-replicate-commands configuration directive and redis.replicate_commands() Lua API can be used to enable it.\nIn Redis 5.0, effects replication became the default mode.\nAs of Redis 7.0, verbatim replication is no longer supported.\nReplicating commands instead of scripts\nStarting with Redis 3.2, it is possible to select an alternative replication method.\nInstead of replicating whole scripts, we can replicate the write commands generated by the script.\nWe call this script effects replication.\nNote:\nstarting with Redis 5.0, script effects replication is the default mode and does not need to be explicitly enabled.\nIn this replication mode, while Lua scripts are executed, Redis collects all the commands executed by the Lua scripting engine that actually modify the dataset.\nWhen the script execution finishes, the sequence of commands that the script generated are wrapped into a MULTI/EXEC transaction and are sent to the replicas and AOF.\nThis is useful in several ways depending on the use case:\n\nWhen the script is slow to compute, but the effects can be summarized by a few write commands, it is a shame to re-compute the script on the replicas or when reloading the AOF.\n  In this case, it is much better to replicate just the effects of the script.\nWhen script effects replication is enabled, the restrictions on non-deterministic functions are removed.\n  You can, for example, use the `TIME` or `SRANDMEMBER` commands inside your scripts freely at any place.\nThe Lua PRNG in this mode is seeded randomly on every call.\n\nUnless already enabled by the server's configuration or defaults (before Redis 7.0), you need to issue the following Lua command before the script performs a write:\n`lua\nredis.replicate_commands()`\nThe redis.replicate_commands() function returns true) if script effects replication was enabled;\notherwise, if the function was called after the script already called a write command,\nit returns _false, and normal whole script replication is used.\nThis function is deprecated as of Redis 7.0, and while you can still call it, it will always succeed. \nScripts with deterministic writes\nNote:\nStarting with Redis 5.0, script replication is by default effect-based rather than verbatim.\nIn Redis 7.0, verbatim script replication had been removed entirely.\nThe following section only applies to versions lower than Redis 7.0 when not using effect-based script replication.\nAn important part of scripting is writing scripts that only change the database in a deterministic way.\nScripts executed in a Redis instance are, by default until version 5.0, propagated to replicas and to the AOF file by sending the script itself -- not the resulting commands.\nSince the script will be re-run on the remote host (or when reloading the AOF file), its changes to the database must be reproducible.\nThe reason for sending the script is that it is often much faster than sending the multiple commands that the script generates.\nIf the client is sending many scripts to the master, converting the scripts into individual commands for the replica / AOF would result in too much bandwidth for the replication link or the Append Only File (and also too much CPU since dispatching a command received via the network is a lot more work for Redis compared to dispatching a command invoked by Lua scripts).\nNormally replicating scripts instead of the effects of the scripts makes sense, however not in all the cases.\nSo starting with Redis 3.2, the scripting engine is able to, alternatively, replicate the sequence of write commands resulting from the script execution, instead of replication the script itself.\nIn this section, we'll assume that scripts are replicated verbatim by sending the whole script.\nLet's call this replication mode verbatim scripts replication.\nThe main drawback with the whole scripts replication approach is that scripts are required to have the following property:\nthe script always must execute the same Redis write commands with the same arguments given the same input data set.\nOperations performed by the script can't depend on any hidden (non-explicit) information or state that may change as the script execution proceeds or between different executions of the script.\nNor can it depend on any external input from I/O devices.\nActs such as using the system time, calling Redis commands that return random values (e.g., `RANDOMKEY`), or using Lua's random number generator, could result in scripts that will not evaluate consistently.\nTo enforce the deterministic behavior of scripts, Redis does the following:\n\nLua does not export commands to access the system time or other external states.\nRedis will block the script with an error if a script calls a Redis command able to alter the data set after a Redis random command like `RANDOMKEY`, `SRANDMEMBER`, `TIME`.\n  That means that read-only scripts that don't modify the dataset can call those commands.\n  Note that a random command does not necessarily mean a command that uses random numbers: any non-deterministic command is considered as a random command (the best example in this regard is the `TIME` command).\nIn Redis version 4.0, commands that may return elements in random order, such as `SMEMBERS` (because Redis Sets are unordered), exhibit a different behavior when called from Lua,\nand undergo a silent lexicographical sorting filter before returning data to Lua scripts.\n  So `redis.call(\"SMEMBERS\",KEYS[1])` will always return the Set elements in the same order, while the same command invoked by normal clients may return different results even if the key contains exactly the same elements.\n  However, starting with Redis 5.0, this ordering is no longer performed because replicating effects circumvents this type of non-determinism.\n  In general, even when developing for Redis 4.0, never assume that certain commands in Lua will be ordered, but instead rely on the documentation of the original command you call to see the properties it provides.\nLua's pseudo-random number generation function `math.random` is modified and always uses the same seed for every execution.\n  This means that calling math.random will always generate the same sequence of numbers every time a script is executed (unless `math.randomseed` is used).\n\nAll that said, you can still use commands that write and random behavior with a simple trick.\nImagine that you want to write a Redis script that will populate a list with N random integers.\nThe initial implementation in Ruby could look like this:\n```\nrequire 'rubygems'\nrequire 'redis'\nr = Redis.new\nRandomPushScript = < 0) do\n        res = redis.call('LPUSH',KEYS[1],math.random())\n        i = i-1\n    end\n    return res\nEOF\nr.del(:mylist)\nputs r.eval(RandomPushScript,[:mylist],[10,rand(2**32)])\n```\nEvery time this code runs, the resulting list will have exactly the\nfollowing elements:\n`redis> LRANGE mylist 0 -1\n 1) \"0.74509509873814\"\n 2) \"0.87390407681181\"\n 3) \"0.36876626981831\"\n 4) \"0.6921941534114\"\n 5) \"0.7857992587545\"\n 6) \"0.57730350670279\"\n 7) \"0.87046522734243\"\n 8) \"0.09637165539729\"\n 9) \"0.74990198051087\"\n10) \"0.17082803611217\"`\nTo make the script both deterministic and still have it produce different random elements,\nwe can add an extra argument to the script that's the seed to Lua's pseudo-random number generator.\nThe new script is as follows:\n```\nRandomPushScript = < 0) do\n        res = redis.call('LPUSH',KEYS[1],math.random())\n        i = i-1\n    end\n    return res\nEOF\nr.del(:mylist)\nputs r.eval(RandomPushScript,1,:mylist,10,rand(2**32))\n```\nWhat we are doing here is sending the seed of the PRNG as one of the arguments.\nThe script output will always be the same given the same arguments (our requirement) but we are changing one of the arguments at every invocation,\ngenerating the random seed client-side.\nThe seed will be propagated as one of the arguments both in the replication link and in the Append Only File,\nguaranteeing that the same changes will be generated when the AOF is reloaded or when the replica processes the script.\nNote: an important part of this behavior is that the PRNG that Redis implements as `math.random` and `math.randomseed` is guaranteed to have the same output regardless of the architecture of the system running Redis.\n32-bit, 64-bit, big-endian and little-endian systems will all produce the same output.\nDebugging Eval scripts\nStarting with Redis 3.2, Redis has support for native Lua debugging.\nThe Redis Lua debugger is a remote debugger consisting of a server, which is Redis itself, and a client, which is by default redis-cli.\nThe Lua debugger is described in the Lua scripts debugging section of the Redis documentation.\nExecution under low memory conditions\nWhen memory usage in Redis exceeds the `maxmemory` limit, the first write command encountered in the script that uses additional memory will cause the script to abort (unless redis.pcall was used).\nHowever, an exception to the above is when the script's first write command does not use additional memory, as is the case with  (for example, `DEL` and `LREM`).\nIn this case, Redis will allow all commands in the script to run to ensure atomicity.\nIf subsequent writes in the script consume additional memory, Redis' memory usage can exceed the threshold set by the `maxmemory` configuration directive.\nAnother scenario in which a script can cause memory usage to cross the `maxmemory` threshold is when the execution begins when Redis is slightly below `maxmemory`, so the script's first write command is allowed.\nAs the script executes, subsequent write commands consume more memory leading to the server using more RAM than the configured `maxmemory` directive.\nIn those scenarios, you should consider setting the `maxmemory-policy` configuration directive to any values other than `noeviction`.\nIn addition, Lua scripts should be as fast as possible so that eviction can kick in between executions.\nNote that you can change this behaviour by using flags\nEval flags\nNormally, when you run an Eval script, the server does not know how it accesses the database.\nBy default, Redis assumes that all scripts read and write data.\nHowever, starting with Redis 7.0, there's a way to declare flags when creating a script in order to tell Redis how it should behave.\nThe way to do that is by using a Shebang statement on the first line of the script like so:\n```\n!lua flags=no-writes,allow-stale\nlocal x = redis.call('get','x')\nreturn x\n```\nNote that as soon as Redis sees the `#!` comment, it'll treat the script as if it declares flags, even if no flags are defined,\nit still has a different set of defaults compared to a script without a `#!` line.\nAnother difference is that scripts without `#!` can run commands that access keys belonging to different cluster hash slots, but ones with `#!` inherit the default flags, so they cannot.",
    "tag": "redis"
  },
  {
    "title": "Sandbox context",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/programmability/lua-api.md",
    "content": "\ntitle: \"Redis Lua API reference\"\nlinkTitle: \"Lua API\"\nweight: 3\ndescription: >\n   Executing Lua in Redis\naliases:\n    - /topics/lua-api\n\nRedis includes an embedded Lua 5.1 interpreter.\nThe interpreter runs user-defined ephemeral scripts and functions. Scripts run in a sandboxed context and can only access specific Lua packages. This page describes the packages and APIs available inside the execution's context.\nSandbox context\nThe sandboxed Lua context attempts to prevent accidental misuse and reduce potential threats from the server's environment.\nScripts should never try to access the Redis server's underlying host systems.\nThat includes the file system, network, and any other attempt to perform a system call other than those supported by the API.\nScripts should operate solely on data stored in Redis and data provided as arguments to their execution.\nGlobal variables and functions\nThe sandboxed Lua execution context blocks the declaration of global variables and functions.\nThe blocking of global variables is in place to ensure that scripts and functions don't attempt to maintain any runtime context other than the data stored in Redis.\nIn the (somewhat uncommon) use case that a context needs to be maintain between executions,\nyou should store the context in Redis' keyspace.\nRedis will return a \"Script attempted to create global variable 'my_global_variable\" error when trying to execute the following snippet:\n`lua\nmy_global_variable = 'some value'`\nAnd similarly for the following global function declaration:\n`lua\nfunction my_global_function()\n  -- Do something amazing\nend`\nYou'll also get a similar error when your script attempts to access any global variables that are undefined in the runtime's context:\n`lua\n-- The following will surely raise an error\nreturn an_undefined_global_variable`\nInstead, all variable and function definitions are required to be declared as local.\nTo do so, you'll need to prepend the local keyword to your declarations.\nFor example, the following snippet will be considered perfectly valid by Redis:\n```lua\nlocal my_local_variable = 'some value'\nlocal function my_local_function()\n  -- Do something else, but equally amazing\nend\n```\nNote:\nthe sandbox attempts to prevent the use of globals.\nUsing Lua's debugging functionality or other approaches such as altering the meta table used for implementing the globals' protection to circumvent the sandbox isn't hard.\nHowever, it is difficult to circumvent the protection by accident.\nIf the user messes with the Lua global state, the consistency of AOF and replication can't be guaranteed.\nIn other words, just don't do it.\nImported Lua modules\nUsing imported Lua modules is not supported inside the sandboxed execution context.\nThe sandboxed execution context prevents the loading modules by disabling Lua's require function.\nThe only libraries that Redis ships with and that you can use in scripts are listed under the Runtime libraries section.\nRuntime globals\nWhile the sandbox prevents users from declaring globals, the execution context is pre-populated with several of these.\nThe redis singleton\nThe redis singleton is an object instance that's accessible from all scripts.\nIt provides the API to interact with Redis from scripts.\nIts description follows below.\nThe KEYS global variable\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: no\n\nImportant:\nto ensure the correct execution of scripts, both in standalone and clustered deployments, all names of keys that a function accesses must be explicitly provided as input key arguments.\nThe script should only access keys whose names are given as input arguments.\nScripts should never access keys with programmatically-generated names or based on the contents of data structures stored in the database.\nThe KEYS global variable is available only for ephemeral scripts.\nIt is pre-populated with all key name input arguments.\nThe ARGV global variable\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: no\n\nThe ARGV global variable is available only in ephemeral scripts.\nIt is pre-populated with all regular input arguments.\nredis object\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThe Redis Lua execution context always provides a singleton instance of an object named redis.\nThe redis instance enables the script to interact with the Redis server that's running it.\nFollowing is the API provided by the redis object instance.\n `redis.call(command [,arg...])`\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThe `redis.call()` function calls a given Redis command and returns its reply.\nIts inputs are the command and arguments, and once called, it executes the command in Redis and returns the reply.\nFor example, we can call the `ECHO` command from a script and return its reply like so:\n`lua\nreturn redis.call('ECHO', 'Echo, echo... eco... o...')`\nIf and when `redis.call()` triggers a runtime exception, the raw exception is raised back to the user as an error, automatically.\nTherefore, attempting to execute the following ephemeral script will fail and generate a runtime exception because `ECHO` accepts exactly zero or one argument:\n`lua\nredis> EVAL \"return redis.call('ECHO', 'Echo,', 'echo... ', 'eco... ', 'o...')\" 0\n(error) ERR Error running script (call to b0345693f4b77517a711221050e76d24ae60b7f7): @user_script:1: @user_script: 1: Wrong number of args calling Redis command from script`\nNote that the call can fail due to various reasons, see Execution under low memory conditions and Script flags\nTo handle Redis runtime errors use `redis.pcall() instead.\n `redis.pcall(command [,arg...])`\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThis function enables handling runtime errors raised by the Redis server.\nThe `redis.pcall()` function  behaves exactly like redis.call(), except that it:\n\nAlways returns a reply.\nNever throws a runtime exception, and returns in its stead a redis.error_reply in case that a runtime exception is thrown by the server.\n\nThe following demonstrates how to use `redis.pcall()` to intercept and handle runtime exceptions from within the context of an ephemeral script.\n`lua\nlocal reply = redis.pcall('ECHO', unpack(ARGV))\nif reply['err'] ~= nil then\n  -- Handle the error sometime, but for now just log it\n  redis.log(redis.LOG_WARNING, reply['err'])\n  reply['err'] = 'Something is wrong, but no worries, everything is under control'\nend\nreturn reply`\nEvaluating this script with more than one argument will return:\n`redis> EVAL \"...\" 0 hello world\n(error) Something is wrong, but no worries, everything is under control`\n `redis.error_reply(x)`\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThis is a helper function that returns an error reply.\nThe helper accepts a single string argument and returns a Lua table with the err field set to that string.\nThe outcome of the following code is that error1 and error2 are identical for all intents and purposes:\n`lua\nlocal text = 'My very special error'\nlocal reply1 = { err = text }\nlocal reply2 = redis.error_reply(text)`\nTherefore, both forms are valid as means for returning an error reply from scripts:\n`redis> EVAL \"return { err = 'My very special table error' }\" 0\n(error) My very special table error\nredis> EVAL \"return redis.error_reply('My very special reply error')\" 0\n(error) My very special reply error`\nFor returning Redis status replies refer to redis.status_reply().\nRefer to the Data type conversion for returning other response types.\n `redis.status_reply(x)`\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThis is a helper function that returns a simple string reply.\n\"OK\" is an example of a standard Redis status reply.\nThe Lua API represents status replies as tables with a single field, ok, set with a simple status string.\nThe outcome of the following code is that status1 and status2 are identical for all intents and purposes:\n`lua\nlocal text = 'Frosty'\nlocal status1 = { ok = text }\nlocal status2 = redis.status_reply(text)`\nTherefore, both forms are valid as means for returning status replies from scripts:\n`redis> EVAL \"return { ok = 'TICK' }\" 0\nTICK\nredis> EVAL \"return redis.status_reply('TOCK')\" 0\nTOCK`\nFor returning Redis error replies refer to redis.error_reply().\nRefer to the Data type conversion for returning other response types.\n `redis.sha1hex(x)`\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThis function returns the SHA1 hexadecimal digest of its single string argument.\nYou can, for example, obtain the empty string's SHA1 digest:\n`redis> EVAL \"return redis.sha1hex('')\" 0\n\"da39a3ee5e6b4b0d3255bfef95601890afd80709\"`\n `redis.log(level, message)`\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThis function writes to the Redis server log.\nIt expects two input arguments: the log level and a message.\nThe message is a string to write to the log file.\nLog level can be on of these:\n\n`redis.LOG_DEBUG`\n`redis.LOG_VERBOSE`\n`redis.LOG_NOTICE`\n`redis.LOG_WARNING`\n\nThese levels map to the server's log levels.\nThe log only records messages equal or greater in level than the server's `loglevel` configuration directive.\nThe following snippet:\n`lua\nredis.log(redis.LOG_WARNING, 'Something is terribly wrong')`\nwill produce a line similar to the following in your server's log:\n`[32343] 22 Mar 15:21:39 # Something is terribly wrong`\n `redis.setresp(x)`\n\nSince version: 6.0.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThis function allows the executing script to switch between Redis Serialization Protocol (RESP) versions for the replies returned by redis.call() and redis.pcall().\nIt expects a single numerical argument as the protocol's version.\nThe default protocol version is 2, but it can be switched to version 3.\nHere's an example of switching to RESP3 replies:\n`lua\nredis.setresp(3)`\nPlease refer to the Data type conversion for more information about type conversions.\n `redis.set_repl(x)`\n\nSince version: 3.2.0\nAvailable in scripts: yes\nAvailable in functions: no\n\nNote:\nthis feature is only available when script effects replication is employed.\nCalling it when using verbatim script replication will result in an error.\nAs of Redis version 2.6.0, scripts were replicated verbatim, meaning that the scripts' source code was sent for execution by replicas and stored in the AOF.\nAn alternative replication mode added in version 3.2.0 allows replicating only the scripts' effects.\nAs of Redis version 7.0, script replication is no longer supported, and the only replication mode available is script effects replication.\nWarning:\nthis is an advanced feature. Misuse can cause damage by violating the contract that binds the Redis master, its replicas, and AOF contents to hold the same logical content.\nThis function allows a script to assert control over how its effects are propagated to replicas and the AOF afterward.\nA script's effects are the Redis write commands that it calls.\nBy default, all write commands that a script executes are replicated.\nSometimes, however, better control over this behavior can be helpful.\nThis can be the case, for example, when storing intermediate values in the master alone.\nConsider a script that intersects two sets and stores the result in a temporary key with `SUNIONSTORE`.\nIt then picks five random elements (`SRANDMEMBER`) from the intersection and stores (`SADD`) them in another set.\nFinally, before returning, it deletes the temporary key that stores the intersection of the two source sets.\nIn this case, only the new set with its five randomly-chosen elements needs to be replicated.\nReplicating the `SUNIONSTORE` command and the `DEL'ition of the temporary key is unnecessary and wasteful.\nThe `redis.set_repl()` function instructs the server how to treat subsequent write commands in terms of replication.\nIt accepts a single input argument that only be one of the following:\n\n`redis.REPL_ALL`: replicates the effects to the AOF and replicas.\n`redis.REPL_AOF`: replicates the effects to the AOF alone.\n`redis.REPL_REPLICA`: replicates the effects to the replicas alone.\n`redis.REPL_SLAVE`: same as `REPL_REPLICA`, maintained for backward compatibility.\n`redis.REPL_NONE`: disables effect replication entirely.\n\nBy default, the scripting engine is initialized to the `redis.REPL_ALL` setting when a script begins its execution.\nYou can call the `redis.set_repl()` function at any time during the script's execution to switch between the different replication modes.\nA simple example follows:\n`lua\nredis.replicate_commands() -- Enable effects replication in versions lower than Redis v7.0\nredis.call('SET', KEYS[1], ARGV[1])\nredis.set_repl(redis.REPL_NONE)\nredis.call('SET', KEYS[2], ARGV[2])\nredis.set_repl(redis.REPL_ALL)\nredis.call('SET', KEYS[3], ARGV[3])`\nIf you run this script by calling `EVAL \"...\" 3 A B C 1 2 3`, the result will be that only the keys A and C are created on the replicas and AOF.\n `redis.replicate_commands()`\n\nSince version: 3.2.0\nUntil version: 7.0.0\nAvailable in scripts: yes\nAvailable in functions: no\n\nThis function switches the script's replication mode from verbatim replication to effects replication.\nYou can use it to override the default verbatim script replication mode used by Redis until version 7.0.\nNote:\nas of Redis v7.0, verbatim script replication is no longer supported.\nThe default, and only script replication mode supported, is script effects' replication.\nFor more information, please refer to Replicating commands instead of scripts\n `redis.breakpoint()`\n\nSince version: 3.2.0\nAvailable in scripts: yes\nAvailable in functions: no\n\nThis function triggers a breakpoint when using the Redis Lua debugger](/topics/ldb).\n `redis.debug(x)`\n\nSince version: 3.2.0\nAvailable in scripts: yes\nAvailable in functions: no\n\nThis function prints its argument in the Redis Lua debugger console.\n `redis.acl_check_cmd(command [,arg...])`\n\nSince version: 7.0.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThis function is used for checking if the current user running the script has ACL permissions to execute the given command with the given arguments.\nThe return value is a boolean `true` in case the current user has permissions to execute the command (via a call to redis.call or redis.pcall) or `false` in case they don't.\nThe function will raise an error if the passed command or its arguments are invalid.\n `redis.register_function`\n\nSince version: 7.0.0\nAvailable in scripts: no\nAvailable in functions: yes\n\nThis function is only available from the context of the `FUNCTION LOAD` command.\nWhen called, it registers a function to the loaded library.\nThe function can be called either with positional or named arguments.\n positional arguments: `redis.register_function(name, callback)`\nThe first argument to `redis.register_function` is a Lua string representing the function name.\nThe second argument to `redis.register_function` is a Lua function.\nUsage example:\n`redis> FUNCTION LOAD \"#!lua name=mylib\\n redis.register_function('noop', function() end)\"`\n Named arguments:  `redis.register_function{function_name=name, callback=callback, flags={flag1, flag2, ..}, description=description}`\nThe named arguments variant accepts the following arguments:\n\nfunction_name: the function's name.\ncallback: the function's callback.\nflags: an array of strings, each a function flag (optional).\ndescription: function's description (optional).\n\nBoth function_name and callback are mandatory.\nUsage example:\n`redis> FUNCTION LOAD \"#!lua name=mylib\\n redis.register_function{function_name='noop', callback=function() end, flags={ 'no-writes' }, description='Does nothing'}\"`\n Script flags\nImportant:\nUse script flags with care, which may negatively impact if misused.\nNote that the default for Eval scripts are different than the default for functions that are mentioned below, see Eval Flags\nWhen you register a function or load an Eval script, the server does not know how it accesses the database.\nBy default, Redis assumes that all scripts read and write data.\nThis results in the following behavior:\n\nThey can read and write data.\nThey can run in cluster mode, and are not able to run commands accessing keys of different hash slots.\nExecution against a stale replica is denied to avoid inconsistent reads.\nExecution under low memory is denied to avoid exceeding the configured threshold.\n\nYou can use the following flags and instruct the server to treat the scripts' execution differently:\n\n\n`no-writes`: this flag indicates that the script only reads data but never writes.\nBy default, Redis will deny the execution of flagged scripts (Functions and Eval scripts with shebang) against read-only replicas, as they may attempt to perform writes.\nSimilarly, the server will not allow calling scripts with `FCALL_RO` / `EVAL_RO`.\nLastly, when data persistence is at risk due to a disk error, execution is blocked as well.\nUsing this flag allows executing the script:\n1. With `FCALL_RO` / `EVAL_RO`\n2. On read-only replicas.\n3. Even if there's a disk error (Redis is unable to persist so it rejects writes).\n4. When over the memory limit since it implies the script doesn't increase memory consumption (see `allow-oom` below)\nHowever, note that the server will return an error if the script attempts to call a write command.\nAlso note that currently `PUBLISH`, `SPUBLISH` and `PFCOUNT` are also considered write commands in scripts, because they could attempt to propagate commands to replicas and AOF file.\nFor more information please refer to Read-only scripts\n\n\n`allow-oom`: use this flag to allow a script to execute when the server is out of memory (OOM).\nUnless used, Redis will deny the execution of flagged scripts (Functions and Eval scripts with shebang) when in an OOM state.\nFurthermore, when you use this flag, the script can call any Redis command, including commands that aren't usually allowed in this state.\nSpecifying `no-writes` or using `FCALL_RO` / `EVAL_RO` also implies the script can run in OOM state (without specifying `allow-oom`)\n\n\n`allow-stale`: a flag that enables running the flagged scripts (Functions and Eval scripts with shebang) against a stale replica when the `replica-serve-stale-data` config is set to `no` .\nRedis can be set to prevent data consistency problems from using old data by having stale replicas return a runtime error.\nFor scripts that do not access the data, this flag can be set to allow stale Redis replicas to run the script.\nNote however that the script will still be unable to execute any command that accesses stale data.\n\n\n`no-cluster`: the flag causes the script to return an error in Redis cluster mode.\nRedis allows scripts to be executed both in standalone and cluster modes.\nSetting this flag prevents executing the script against nodes in the cluster.\n\n\n`allow-cross-slot-keys`: The flag that allows a script to access keys from multiple slots.\nRedis typically prevents any single command from accessing keys that hash to multiple slots.\nThis flag allows scripts to break this rule and access keys within the script that access multiple slots.\nDeclared keys to the script are still always required to hash to a single slot.\nAccessing keys from multiple slots is discouraged as applications should be designed to only access keys from a single slot at a time, allowing slots to move between Redis servers.\nThis flag has no effect when cluster mode is disabled.\n\n\nPlease refer to Function Flags and Eval Flags for a detailed example.\n `redis.REDIS_VERSION`\n\nSince version: 7.0.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nReturns the current Redis server version as a Lua string.\nThe reply's format is `MM.mm.PP`, where:\n\nMM: is the major version.\nmm: is the minor version.\nPP: is the patch level.\n\n `redis.REDIS_VERSION_NUM`\n\nSince version: 7.0.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nReturns the current Redis server version as a number.\nThe reply is a hexadecimal value structured as `0x00MMmmPP`, where:\n\nMM: is the major version.\nmm: is the minor version.\nPP: is the patch level.\n\nData type conversion\nUnless a runtime exception is raised, `redis.call()` and `redis.pcall()` return the reply from the executed command to the Lua script.\nRedis' replies from these functions are converted automatically into Lua's native data types.\nSimilarly, when a Lua script returns a reply with the `return` keyword,\nthat reply is automatically converted to Redis' protocol.\nPut differently; there's a one-to-one mapping between Redis' replies and Lua's data types and a one-to-one mapping between Lua's data types and the Redis Protocol data types.\nThe underlying design is such that if a Redis type is converted into a Lua type and converted back into a Redis type, the result is the same as the initial value.\nType conversion from Redis protocol replies (i.e., the replies from `redis.call()` and `redis.pcall()` to Lua data types depends on the Redis Serialization Protocol version used by the script.\nThe default protocol version during script executions is RESP2.\nThe script may switch the replies' protocol versions by calling the `redis.setresp()` function.\nType conversion from a script's returned Lua data type depends on the user's choice of protocol (see the `HELLO` command).\nThe following sections describe the type conversion rules between Lua and Redis per the protocol's version.\nRESP2 to Lua type conversion\nThe following type conversion rules apply to the execution's context by default as well as after calling `redis.setresp(2)`:\n\nRESP2 integer reply -> Lua number\nRESP2 bulk string reply -> Lua string\nRESP2 array reply -> Lua table (may have other Redis data types nested)\nRESP2 status reply -> Lua table with a single ok field containing the status string\nRESP2 error reply -> Lua table with a single err field containing the error string\nRESP2 null bulk reply and null multi bulk reply -> Lua false boolean type\n\nLua to RESP2 type conversion\nThe following type conversion rules apply by default as well as after the user had called `HELLO 2`:\n\nLua number -> RESP2 integer reply (the number is converted into an integer)\nLua string -> RESP bulk string reply\nLua table (indexed, non-associative array) -> RESP2 array reply (truncated at the first Lua `nil` value encountered in the table, if any)\nLua table with a single ok field -> RESP2 status reply\nLua table with a single err field -> RESP2 error reply\nLua boolean false -> RESP2 null bulk reply\n\nThere is an additional Lua-to-Redis conversion rule that has no corresponding Redis-to-Lua conversion rule:\n\nLua Boolean `true` -> RESP2 integer reply with value of 1.\n\nThere are three additional rules to note about converting Lua to Redis data types:\n\nLua has a single numerical type, Lua numbers. \n  There is no distinction between integers and floats.\n  So we always convert Lua numbers into integer replies, removing the decimal part of the number, if any.\n  If you want to return a Lua float, it should be returned as a string,\n  exactly like Redis itself does (see, for instance, the `ZSCORE` command).\nThere's no simple way to have nils inside Lua arrays due \n  to Lua's table semantics.\n  Therefore, when Redis converts a Lua array to RESP, the conversion stops when it encounters a Lua `nil` value.\nWhen a Lua table is an associative array that contains keys and their respective values, the converted Redis reply will not include them.\n\nLua to RESP2 type conversion examples:\n```\nredis> EVAL \"return 10\" 0\n(integer) 10\nredis> EVAL \"return { 1, 2, { 3, 'Hello World!' } }\" 0\n1) (integer) 1\n2) (integer) 2\n3) 1) (integer) 3\n   1) \"Hello World!\"\nredis> EVAL \"return redis.call('get','foo')\" 0\n\"bar\"\n```\nThe last example demonstrates receiving and returning the exact return value of `redis.call()` (or `redis.pcall()`) in Lua as it would be returned if the command had been called directly.\nThe following example shows how floats and arrays that cont nils and keys are handled:\n`redis> EVAL \"return { 1, 2, 3.3333, somekey = 'somevalue', 'foo', nil , 'bar' }\" 0\n1) (integer) 1\n2) (integer) 2\n3) (integer) 3\n4) \"foo\"`\nAs you can see, the float value of 3.333 gets converted to an integer 3, the somekey key and its value are omitted, and the string \"bar\" isn't returned as there is a `nil` value that precedes it.\nRESP3 to Lua type conversion\nRESP3 is a newer version of the Redis Serialization Protocol.\nIt is available as an opt-in choice as of Redis v6.0.\nAn executing script may call the redis.setresp function during its execution and switch the protocol version that's used for returning replies from Redis' commands (that can be invoked via redis.call() or redis.pcall()).\nOnce Redis' replies are in RESP3 protocol, all of the RESP2 to Lua conversion rules apply, with the following additions:\n\nRESP3 map reply -> Lua table with a single map field containing a Lua table representing the fields and values of the map.\nRESP set reply -> Lua table with a single set field containing a Lua table representing the elements of the set as fields, each with the Lua Boolean value of `true`.\nRESP3 null -> Lua `nil`.\nRESP3 true reply -> Lua true boolean value.\nRESP3 false reply -> Lua false boolean value.\nRESP3 double reply -> Lua table with a single score field containing a Lua number representing the double value.\nRESP3 big number reply -> Lua table with a single big_number field containing a Lua string representing the big number value.\nRedis verbatim string reply -> Lua table with a single verbatim_string field containing a Lua table with two fields, string and format, representing the verbatim string and its format, respectively.\n\nNote:\nthe RESP3 big number and verbatim strings replies are only supported as of Redis v7.0 and greater. \nAlso, presently, RESP3's attributes, streamed strings and streamed aggregate data types are not supported by the Redis Lua API.\nLua to RESP3 type conversion\nRegardless of the script's choice of protocol version set for replies with the [`redis.setresp()` function] when it calls `redis.call()` or `redis.pcall()`, the user may opt-in to using RESP3 (with the `HELLO 3` command) for the connection.\nAlthough the default protocol for incoming client connections is RESP2, the script should honor the user's preference and return adequately-typed RESP3 replies, so the following rules apply on top of those specified in the Lua to RESP2 type conversion section when that is the case.\n\nLua Boolean -> RESP3 Boolean reply (note that this is a change compared to the RESP2, in which returning a Boolean Lua `true` returned the number 1 to the Redis client, and returning a `false` used to return a `null`.\nLua table with a single map field set to an associative Lua table -> RESP3 map reply.\nLua table with a single _set field set to an associative Lua table -> RESP3 set reply. Values can be set to anything and are discarded anyway.\nLua table with a single double field to an associative Lua table -> RESP3 double reply.\nLua nil -> RESP3 null.\n\nHowever, if the connection is set use the RESP2 protocol, and even if the script replies with RESP3-typed responses, Redis will automatically perform a RESP3 to RESP2 conversion of the reply as is the case for regular commands.\nThat means, for example, that returning the RESP3 map type to a RESP2 connection will result in the repy being converted to a flat RESP2 array that consists of alternating field names and their values, rather than a RESP3 map.\nAdditional notes about scripting\nUsing `SELECT` inside scripts\nYou can call the `SELECT` command from your Lua scripts, like you can with any normal client connection.\nHowever, one subtle aspect of the behavior changed between Redis versions 2.8.11 and 2.8.12.\nPrior to Redis version 2.8.12, the database selected by the Lua script was set as the current database for the client connection that had called it.\nAs of Redis version 2.8.12, the database selected by the Lua script only affects the execution context of the script, and does not modify the database that's selected by the client calling the script.\nThis semantic change between patch level releases was required since the old behavior was inherently incompatible with Redis' replication and introduced bugs.\nRuntime libraries\nThe Redis Lua runtime context always comes with several pre-imported libraries.\nThe following standard Lua libraries are available to use:\n\nThe String Manipulation (string) library\nThe Table Manipulation (table) library\nThe Mathematical Functions (math) library\n\nIn addition, the following external libraries are loaded and accessible to scripts:\n\nThe struct library\nThe cjson library\nThe cmsgpack library\nThe bitop library\n\n struct library\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nstruct is a library for packing and unpacking C-like structures in Lua.\nIt provides the following functions:\n\nstruct.pack()\nstruct.unpack()\nstruct.size()\n\nAll of struct's functions expect their first argument to be a format string.\n struct formats\nThe following are valid format strings for struct's functions:\n\n`>`: big endian\n`<`: little endian\n`![num]`: alignment\n`x`: padding\n`b/B`: signed/unsigned byte\n`h/H`: signed/unsigned short\n`l/L`: signed/unsigned long\n`T`: size_t\n`i/In`: signed/unsigned integer with size n (defaults to the size of int)\n`cn`: sequence of n chars (from/to a string); when packing, n == 0 means the\n  whole string; when unpacking, n == 0 means use the previously read number as\n  the string's length.\n`s`: zero-terminated string\n`f`: float\n`d`: double\n`` (space): ignored\n\n `struct.pack(x)`\nThis function returns a struct-encoded string from values.\nIt accepts a struct format string as its first argument, followed by the values that are to be encoded.\nUsage example:\n`redis> EVAL \"return struct.pack('HH', 1, 2)\" 0\n\"\\x01\\x00\\x02\\x00\"`\n `struct.unpack(x)`\nThis function returns the decoded values from a struct.\nIt accepts a struct format string as its first argument, followed by encoded struct's string.\nUsage example:\n`redis> EVAL \"return { struct.unpack('HH', ARGV[1]) }\" 0 \"\\x01\\x00\\x02\\x00\"\n1) (integer) 1\n2) (integer) 2\n3) (integer) 5`\n `struct.size(x)`\nThis function returns the size, in bytes, of a struct.\nIt accepts a struct format string as its only argument.\nUsage example:\n`redis> EVAL \"return struct.size('HH')\" 0\n(integer) 4`\n cjson library\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThe cjson library provides fast JSON encoding and decoding from Lua.\nIt provides these functions.\n `cjson.encode(x)`\nThis function returns a JSON-encoded string for the Lua data type provided as its argument.\nUsage example:\n`redis> EVAL \"return cjson.encode({ ['foo'] = 'bar' })\" 0\n\"{\\\"foo\\\":\\\"bar\\\"}\"`\n `cjson.decode(x)`\nThis function returns a Lua data type from the JSON-encoded string provided as its argument.\nUsage example:\n`redis> EVAL \"return cjson.decode(ARGV[1])['foo']\" 0 '{\"foo\":\"bar\"}'\n\"bar\"`\n cmsgpack library\n\nSince version: 2.6.0\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThe cmsgpack library provides fast MessagePack encoding and decoding from Lua.\nIt provides these functions.\n `cmsgpack.pack(x)`\nThis function returns the packed string encoding of the Lua data type it is given as an argument.\nUsage example:\n`redis> EVAL \"return cmsgpack.pack({'foo', 'bar', 'baz'})\" 0\n\"\\x93\\xa3foo\\xa3bar\\xa3baz\"`\n `cmsgpack.unpack(x)`\nThis function returns the unpacked values from decoding its input string argument.\nUsage example:\n`redis> EVAL \"return cmsgpack.unpack(ARGV[1])\" 0 \"\\x93\\xa3foo\\xa3bar\\xa3baz\"\n1) \"foo\"\n2) \"bar\"\n3) \"baz\"`\n bit library\n\nSince version: 2.8.18\nAvailable in scripts: yes\nAvailable in functions: yes\n\nThe bit library provides bitwise operations on numbers.\nIts documentation resides at Lua BitOp documentation\nIt provides the following functions.\n `bit.tobit(x)`\nNormalizes a number to the numeric range for bit operations and returns it.\nUsage example:\n`redis> EVAL 'return bit.tobit(1)' 0\n(integer) 1`\n `bit.tohex(x [,n])`\nConverts its first argument to a hex string. The number of hex digits is given by the absolute value of the optional second argument.\nUsage example:\n`redis> EVAL 'return bit.tohex(422342)' 0\n\"000671c6\"`\n `bit.bnot(x)`\nReturns the bitwise not of its argument.\n `bit.bnot(x)` `bit.bor(x1 [,x2...])`, `bit.band(x1 [,x2...])` and `bit.bxor(x1 [,x2...])`\nReturns either the bitwise or, bitwise and, or bitwise xor of all of its arguments.\nNote that more than two arguments are allowed.\nUsage example:\n`redis> EVAL 'return bit.bor(1,2,4,8,16,32,64,128)' 0\n(integer) 255`\n `bit.lshift(x, n)`, `bit.rshift(x, n)` and `bit.arshift(x, n)`\nReturns either the bitwise logical left-shift, bitwise logical right-shift, or bitwise arithmetic right-shift of its first argument by the number of bits given by the second argument.\n `bit.rol(x, n)` and `bit.ror(x, n)`\nReturns either the bitwise left rotation, or bitwise right rotation of its first argument by the number of bits given by the second argument.\nBits shifted out on one side are shifted back in on the other side.\n `bit.bswap(x)`\nSwaps the bytes of its argument and returns it.",
    "tag": "redis"
  },
  {
    "title": "Background",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/manual/programmability/_index.md",
    "content": "\ntitle: \"Redis programmability\"\nlinkTitle: \"Programmability\"\nweight: 7\ndescription: >\n   Extending Redis with Lua and Redis Functions\naliases:\n    - /topics/programmability\n\nRedis provides a programming interface that lets you execute custom scripts on the server itself. In Redis 7 and beyond, you can use Redis Functions to manage and run your scripts. In Redis 6.2 and below, you use Lua scripting with the EVAL command to program the server.\nBackground\nRedis is, by definition, a \"domain-specific language for abstract data types\".\nThe language that Redis speaks consists of its commands.\nMost the commands specialize at manipulating core data types in different ways.\nIn many cases, these commands provide all the functionality that a developer requires for managing application data in Redis.\nThe term programmability in Redis means having the ability to execute arbitrary user-defined logic by the server.\nWe refer to such pieces of logic as scripts.\nIn our case, scripts enable processing the data where it lives, a.k.a data locality.\nFurthermore, the responsible embedding of programmatic workflows in the Redis server can help in reducing network traffic and improving overall performance.\nDevelopers can use this capability for implementing robust, application-specific APIs.\nSuch APIs can encapsulate business logic and maintain a data model across multiple keys and different data structures.\nUser scripts are executed in Redis by an embedded, sandboxed scripting engine.\nPresently, Redis supports a single scripting engine, the Lua 5.1 interpreter.\nPlease refer to the Redis Lua API Reference page for complete documentation.\nRunning scripts\nRedis provides two means for running scripts.\nFirstly, and ever since Redis 2.6.0, the `EVAL` command enables running server-side scripts.\nEval scripts provide a quick and straightforward way to have Redis run your scripts ad-hoc.\nHowever, using them means that the scripted logic is a part of your application (not an extension of the Redis server).\nEvery applicative instance that runs a script must have the script's source code readily available for loading at any time.\nThat is because scripts are only cached by the server and are volatile.\nAs your application grows, this approach can become harder to develop and maintain.\nSecondly, added in v7.0, Redis Functions are essentially scripts that are first-class database elements.\nAs such, functions decouple scripting from application logic and enable independent development, testing, and deployment of scripts.\nTo use functions, they need to be loaded first, and then they are available for use by all connected clients.\nIn this case, loading a function to the database becomes an administrative deployment task (such as loading a Redis module, for example), which separates the script from the application.\nPlease refer to the following pages for more information:\n\nRedis Eval Scripts\nRedis Functions\n\nWhen running a script or a function, Redis guarantees its atomic execution.\nThe script's execution blocks all server activities during its entire time, similarly to the semantics of transactions.\nThese semantics mean that all of the script's effects either have yet to happen or had already happened.\nThe blocking semantics of an executed script apply to all connected clients at all times.\nNote that the potential downside of this blocking approach is that executing slow scripts is not a good idea.\nIt is not hard to create fast scripts because scripting's overhead is very low.\nHowever, if you intend to use a slow script in your application, be aware that all other clients are blocked and can't execute any command while it is running.\nRead-only scripts\nA read-only script is a script that only executes commands that don't modify any keys within Redis.\nRead-only scripts can be executed either by adding the `no-writes` flag to the script or by executing the script with one of the read-only script command variants: `EVAL_RO`, `EVALSHA_RO`, or `FCALL_RO`.\nThey have the following properties:\n\nThey can always be executed on replicas.\nThey can always be killed by the `SCRIPT KILL` command. \nThey never fail with OOM error when redis is over the memory limit.\nThey are not blocked during write pauses, such as those that occur during coordinated failovers.\nThey cannot execute any command that may modify the data set.\nCurrently `PUBLISH`, `SPUBLISH` and `PFCOUNT` are also considered write commands in scripts, because they could attempt to propagate commands to replicas and AOF file.\n\nIn addition to the benefits provided by all read-only scripts, the read-only script commands have the following advantages:\n\nThey can be used to configure an ACL user to only be able to execute read-only scripts.\nMany clients also better support routing the read-only script commands to replicas for applications that want to use replicas for read scaling.\n\nRead-only script history\nRead-only scripts and read-only script commands were introduced in Redis 7.0\n\nBefore Redis 7.0.1 `PUBLISH`, `SPUBLISH` and `PFCOUNT` were not considered write commands in scripts\nBefore Redis 7.0.1 the `no-writes` flag did not imply `allow-oom`\nBefore Redis 7.0.1 the `no-writes` flag did not permit the script to run during write pauses.\n\nThe recommended approach is to use the standard scripting commands with the `no-writes` flag unless you need one of the previously mentioned features.\nSandboxed script context\nRedis places the engine that executes user scripts inside a sandbox.\nThe sandbox attempts to prevent accidental misuse and reduce potential threats from the server's environment.\nScripts should never try to access the Redis server's underlying host systems, such as the file system, network, or attempt to perform any other system call other than those supported by the API.\nScripts should operate solely on data stored in Redis and data provided as arguments to their execution.\nMaximum execution time\nScripts are subject to a maximum execution time (set by default to five seconds).\nThis default timeout is enormous since a script usually runs in less than a millisecond.\nThe limit is in place to handle accidental infinite loops created during development.\nIt is possible to modify the maximum time a script can be executed with millisecond precision,\neither via `redis.conf` or by using the `CONFIG SET` command.\nThe configuration parameter affecting max execution time is called `busy-reply-threshold`.\nWhen a script reaches the timeout threshold, it isn't terminated by Redis automatically.\nDoing so would violate the contract between Redis and the scripting engine that ensures that scripts are atomic.\nInterrupting the execution of a script has the potential of leaving the dataset with half-written changes.\nTherefore, when a script executes longer than the configured timeout, the following happens:\n\nRedis logs that a script is running for too long.\nIt starts accepting commands again from other clients but will reply with a BUSY error to all the clients sending normal commands. The only commands allowed in this state are `SCRIPT KILL`, `FUNCTION KILL`, and `SHUTDOWN NOSAVE`.\nIt is possible to terminate a script that only executes read-only commands using the `SCRIPT KILL` and `FUNCTION KILL` commands. These commands do not violate the scripting semantic as no data was written to the dataset by the script yet.\n",
    "tag": "redis"
  },
  {
    "title": "How is Redis different from other key-value stores?",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/getting-started/faq.md",
    "content": "\ntitle: \"Redis FAQ\"\nlinkTitle: \"FAQ\"\nweight: 100\ndescription: >\n    Commonly asked questions when getting started with Redis\naliases:\n    - /docs/getting-started/faq\n\nHow is Redis different from other key-value stores?\n\nRedis has a different evolution path in the key-value DBs where values can contain more complex data types, with atomic operations defined on those data types. Redis data types are closely related to fundamental data structures and are exposed to the programmer as such, without additional abstraction layers.\nRedis is an in-memory but persistent on disk database, so it represents a different trade off where very high write and read speed is achieved with the limitation of data sets that can't be larger than memory. Another advantage of\nin-memory databases is that the memory representation of complex data structures\nis much simpler to manipulate compared to the same data structures on disk, so\nRedis can do a lot with little internal complexity. At the same time the\ntwo on-disk storage formats (RDB and AOF) don't need to be suitable for random\naccess, so they are compact and always generated in an append-only fashion\n(Even the AOF log rotation is an append-only operation, since the new version\nis generated from the copy of data in memory). However this design also involves\ndifferent challenges compared to traditional on-disk stores. Being the main data\nrepresentation on memory, Redis operations must be carefully handled to make sure\nthere is always an updated version of the data set on disk.\n\nWhat's the Redis memory footprint?\nTo give you a few examples (all obtained using 64-bit instances):\n\nAn empty instance uses ~ 3MB of memory.\n1 Million small Keys -> String Value pairs use ~ 85MB of memory.\n1 Million Keys -> Hash value, representing an object with 5 fields, use ~ 160 MB of memory.\n\nTesting your use case is trivial. Use the `redis-benchmark` utility to generate random data sets then check the space used with the `INFO memory` command.\n64-bit systems will use considerably more memory than 32-bit systems to store the same keys, especially if the keys and values are small. This is because pointers take 8 bytes in 64-bit systems. But of course the advantage is that you can\nhave a lot of memory in 64-bit systems, so in order to run large Redis servers a 64-bit system is more or less required. The alternative is sharding.\nWhy does Redis keep its entire dataset in memory?\nIn the past the Redis developers experimented with Virtual Memory and other systems in order to allow larger than RAM datasets, but after all we are very happy if we can do one thing well: data served from memory, disk used for storage. So for now there are no plans to create an on disk backend for Redis. Most of what\nRedis is, after all, a direct result of its current design.\nIf your real problem is not the total RAM needed, but the fact that you need\nto split your data set into multiple Redis instances, please read the\npartitioning page in this documentation for more info.\nRedis Ltd., the company sponsoring Redis development, has developed a\n\"Redis on Flash\" solution that uses a mixed RAM/flash approach for\nlarger data sets with a biased access pattern. You may check their offering\nfor more information, however this feature is not part of the open source Redis\ncode base.\nCan you use Redis with a disk-based database?\nYes, a common design pattern involves taking very write-heavy small data\nin Redis (and data you need the Redis data structures to model your problem\nin an efficient way), and big blobs of data into an SQL or eventually\nconsistent on-disk database. Similarly sometimes Redis is used in order to\ntake in memory another copy of a subset of the same data stored in the on-disk\ndatabase. This may look similar to caching, but actually is a more advanced model\nsince normally the Redis dataset is updated together with the on-disk DB dataset,\nand not refreshed on cache misses.\nHow can I reduce Redis' overall memory usage?\nIf you can, use Redis 32 bit instances. Also make good use of small hashes,\nlists, sorted sets, and sets of integers, since Redis is able to represent\nthose data types in the special case of a few elements in a much more compact\nway. There is more info in the Memory Optimization page.\nWhat happens if Redis runs out of memory?\nRedis has built-in protections allowing the users to set a max limit on memory\nusage, using the `maxmemory` option in the configuration file to put a limit\nto the memory Redis can use. If this limit is reached, Redis will start to reply\nwith an error to write commands (but will continue to accept read-only\ncommands).\nYou can also configure Redis to evict keys when the max memory limit\nis reached. See the eviction policy docs for more information on this.\nBackground saving fails with a fork() error on Linux?\nShort answer: `echo 1 > /proc/sys/vm/overcommit_memory` :)\nAnd now the long one:\nThe Redis background saving schema relies on the copy-on-write semantic of the `fork` system call in\nmodern operating systems: Redis forks (creates a child process) that is an\nexact copy of the parent. The child process dumps the DB on disk and finally\nexits. In theory the child should use as much memory as the parent being a\ncopy, but actually thanks to the copy-on-write semantic implemented by most\nmodern operating systems the parent and child process will share the common\nmemory pages. A page will be duplicated only when it changes in the child or in\nthe parent. Since in theory all the pages may change while the child process is\nsaving, Linux can't tell in advance how much memory the child will take, so if\nthe `overcommit_memory` setting is set to zero the fork will fail unless there is\nas much free RAM as required to really duplicate all the parent memory pages.\nIf you have a Redis dataset of 3 GB and just 2 GB of free\nmemory it will fail.\nSetting `overcommit_memory` to 1 tells Linux to relax and perform the fork in a\nmore optimistic allocation fashion, and this is indeed what you want for Redis.\nYou can refer to the proc(5) man page for explanations of the\navailable values.\nAre Redis on-disk snapshots atomic?\nYes, the Redis background saving process is always forked when the server is\noutside of the execution of a command, so every command reported to be atomic\nin RAM is also atomic from the point of view of the disk snapshot.\nHow can Redis use multiple CPUs or cores?\nIt's not very frequent that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound.\nFor instance, when using pipelining a Redis instance running on an average Linux system can deliver 1 million requests per second, so if your application mainly uses O(N) or O(log(N)) commands, it is hardly going to use too much CPU.\nHowever, to maximize CPU usage you can start multiple instances of Redis in\nthe same box and treat them as different servers. At some point a single\nbox may not be enough anyway, so if you want to use multiple CPUs you can\nstart thinking of some way to shard earlier.\nYou can find more information about using multiple Redis instances in the Partitioning page.\nAs of version 4.0, Redis has started implementing threaded actions. For now this is limited to deleting objects in the background and blocking commands implemented via Redis modules. For subsequent releases, the plan is to make Redis more and more threaded.\nWhat is the maximum number of keys a single Redis instance can hold? What is the maximum number of elements in a Hash, List, Set, and Sorted Set?\nRedis can handle up to 2^32 keys, and was tested in practice to\nhandle at least 250 million keys per instance.\nEvery hash, list, set, and sorted set, can hold 2^32 elements.\nIn other words your limit is likely the available memory in your system.\nWhy does my replica have a different number of keys its master instance?\nIf you use keys with limited time to live (Redis expires) this is normal behavior. This is what happens:\n\nThe primary generates an RDB file on the first synchronization with the replica.\nThe RDB file will not include keys already expired in the primary but which are still in memory.\nThese keys are still in the memory of the Redis primary, even if logically expired. They'll be considered non-existent, and their memory will be reclaimed later, either incrementally or explicitly on access. While these keys are not logically part of the dataset, they are accounted for in the `INFO` output and in the `DBSIZE` command.\nWhen the replica reads the RDB file generated by the primary, this set of keys will not be loaded.\n\nBecause of this, it's common for users with many expired keys to see fewer keys in the replicas. However, logically, the primary and replica will have the same content.\nWhere does the name \"Redis\" come from?\nRedis is an acronym that stands for REmote DIctionary Server.\nWhy did Salvatore Sanfilippo start the Redis project?\nSalvatore originally created Redis to scale LLOOGG, a real-time log analysis tool. But after getting the basic Redis server working, he decided to share the work with other people and turn Redis into an open source project.\nHow is Redis pronounced?",
    "tag": "redis"
  },
  {
    "title": "Install Redis",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/getting-started/_index.md",
    "content": "\ufeff---\ntitle: \"Getting started with Redis\"\nlinkTitle: \"Getting started\"\nweight: 20\ndescription: >\n    How to get up and running with Redis\naliases:\n    - /docs/getting-started/tutorial\n\nThis is a guide to getting started with Redis. You'll learn how to install, run, and experiment with the Redis server process.\nInstall Redis\nHow you install Redis depends on your operating system and whether you'd like to install it bundled with Redis Stack and Redis UI. See the guide below that best fits your needs:\n\nInstall Redis from Source\nInstall Redis on Linux\nInstall Redis on macOS\nInstall Redis on Windows\nInstall Redis with Redis Stack and RedisInsight\n\nOnce you have Redis up and running, and can connect using `redis-cli`, you can continue with the steps below.\nExplore Redis using the CLI\nExternal programs talk to Redis using a TCP socket and a Redis specific protocol. This protocol is implemented in the Redis client libraries for the different programming languages. However to make hacking with Redis simpler Redis provides a command line utility that can be used to send commands to Redis. This program is called redis-cli.\nThe first thing to do in order to check if Redis is working properly is sending a PING command using redis-cli:\n\n\n```$ redis-cli ping\nPONG\n```\n\n\nRunning redis-cli followed by a command name and its arguments will send this command to the Redis instance running on localhost at port 6379. You can change the host and port used by `redis-cli` - just try the `--help` option to check the usage information.\nAnother interesting way to run `redis-cli` is without arguments: the program will start in interactive mode. You can type different commands and see their replies.\n\n\n```$ redis-cli\nredis 127.0.0.1:6379> ping\nPONG\nredis 127.0.0.1:6379> set mykey somevalue\nOK\nredis 127.0.0.1:6379> get mykey\n\"somevalue\"\n```\n\n\nAt this point you are able to talk with Redis. It is the right time to pause a bit with this tutorial and start the fifteen minutes introduction to Redis data types in order to learn a few Redis commands. Otherwise if you already know a few basic Redis commands you can keep reading.\nSecuring Redis\nBy default Redis binds to all the interfaces and has no authentication at\nall. If you use Redis in a very controlled environment, separated from the\nexternal internet and in general from attackers, that's fine. However if an unhardened Redis\nis exposed to the internet, it is a big security concern. If you are not 100% sure your environment is secured properly, please check the following steps in order to make Redis more secure, which are enlisted in order of increased security.\n\nMake sure the port Redis uses to listen for connections (by default 6379 and additionally 16379 if you run Redis in cluster mode, plus 26379 for Sentinel) is firewalled, so that it is not possible to contact Redis from the outside world.\nUse a configuration file where the `bind` directive is set in order to guarantee that Redis listens on only the network interfaces you are using. For example only the loopback interface (127.0.0.1) if you are accessing Redis just locally from the same computer, and so forth.\nUse the `requirepass` option in order to add an additional layer of security so that clients will require to authenticate using the `AUTH` command.\nUse spiped or another SSL tunneling software in order to encrypt traffic between Redis servers and Redis clients if your environment requires encryption.\n\nNote that a Redis instance exposed to the internet without any security is very simple to exploit, so make sure you understand the above and apply at least a firewall layer. After the firewall is in place, try to connect with `redis-cli` from an external host in order to prove yourself the instance is actually not reachable.\nUse Redis from your application\nOf course using Redis just from the command line interface is not enough as\nthe goal is to use it from your application. In order to do so you need to\ndownload and install a Redis client library for your programming language.\nYou'll find a full list of clients for different languages in this page.\nFor instance if you happen to use the Ruby programming language our best advice\nis to use the Redis-rb client.\nYou can install it using the command gem install redis.\nThese instructions are Ruby specific but actually many library clients for\npopular languages look quite similar: you create a Redis object and execute\ncommands calling methods. A short interactive example using Ruby:\n\n\n```>> require 'rubygems'\n=> false\n>> require 'redis'\n=> true\n>> r = Redis.new\n=> #<Redis client v4.5.1 for redis://127.0.0.1:6379/0>\n>> r.ping\n=> \"PONG\"\n>> r.set('foo','bar')\n=> \"OK\"\n>> r.get('foo')\n=> \"bar\"\n```\n\n\nRedis persistence\nYou can learn how Redis persistence works on this page, however what is important to understand for a quick start is that by default, if you start Redis with the default configuration, Redis will spontaneously save the dataset only from time to time (for instance after at least five minutes if you have at least 100 changes in your data), so if you want your database to persist and be reloaded after a restart make sure to call the SAVE command manually every time you want to force a data set snapshot. Otherwise make sure to shutdown the database using the SHUTDOWN command:\n\n\n```$ redis-cli shutdown\n```\n\n\nThis way Redis will make sure to save the data on disk before quitting.\nReading the persistence page is strongly suggested in order to better understand how Redis persistence works.\nInstall Redis more properly\nRunning Redis from the command line is fine just to hack a bit or for development. However, at some point you'll have some actual application to run on a real server. For this kind of usage you have two different choices:\n\nRun Redis using screen.\nInstall Redis in your Linux box in a proper way using an init script, so that after a restart everything will start again properly.\n\nA proper install using an init script is strongly suggested.\nThe following instructions can be used to perform a proper installation using the init script shipped with Redis version 2.4 or higher in a Debian or Ubuntu based distribution.\nWe assume you already copied redis-server and redis-cli executables under /usr/local/bin.\n\n\nCreate a directory in which to store your Redis config files and your data:\n\n\n```sudo mkdir /etc/redis\nsudo mkdir /var/redis\n```\n\n\n\n\nCopy the init script that you'll find in the Redis distribution under the utils directory into `/etc/init.d`. We suggest calling it with the name of the port where you are running this instance of Redis. For example:\n\n\n```sudo cp utils/redis_init_script /etc/init.d/redis_6379\n```\n\n\n\n\nEdit the init script.\n\n\n```sudo vi /etc/init.d/redis_6379\n```\n\n\n\n\nMake sure to modify REDISPORT accordingly to the port you are using.\nBoth the pid file path and the configuration file name depend on the port number.\n\n\nCopy the template configuration file you'll find in the root directory of the Redis distribution into `/etc/redis/` using the port number as name, for instance:\n\n\n```sudo cp redis.conf /etc/redis/6379.conf\n```\n\n\n\n\nCreate a directory inside `/var/redis` that will work as data and working directory for this Redis instance:\n\n\n```sudo mkdir /var/redis/6379\n```\n\n\n\n\nEdit the configuration file, making sure to perform the following changes:\n\nSet daemonize to yes (by default it is set to no).\nSet the pidfile to `/var/run/redis_6379.pid` (modify the port if needed).\nChange the port accordingly. In our example it is not needed as the default port is already 6379.\nSet your preferred loglevel.\nSet the logfile to `/var/log/redis_6379.log`\nSet the dir to `/var/redis/6379` (very important step!)\n\n\nFinally add the new Redis init script to all the default runlevels using the following command:\n\n```sudo update-rc.d redis_6379 defaults\n```\n\n\n\n\nYou are done! Now you can try running your instance with:\n\n\n```sudo /etc/init.d/redis_6379 start\n```\n\n\nMake sure that everything is working as expected:\n\nTry pinging your instance with redis-cli.\nDo a test save with `redis-cli save` and check that the dump file is correctly stored into `/var/redis/6379/` (you should find a file called `dump.rdb`).\nCheck that your Redis instance is correctly logging in the log file.\nIf it's a new machine where you can try it without problems make sure that after a reboot everything is still working.\n\nNote: The above instructions don't include all of the Redis configuration parameters that you could change, for instance, to use AOF persistence instead of RDB persistence, or to set up replication, and so forth.",
    "tag": "redis"
  },
  {
    "title": "Prerequisites",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/getting-started/installation/install-redis-on-mac-os.md",
    "content": "\ntitle: \"Install Redis on macOS\"\nlinkTitle: \"Install on macOS\"\nweight: 1\ndescription: Use Homebrew to install and start Redis on macOS\n\nThis guide shows you how to install Redis on macOS using Homebrew. Homebrew is the easiest way to install Redis on macOS. If you'd prefer to build Redis from the source files on macOS, see Installing Redis from Source.\nPrerequisites\nFirst, make sure you have Homebrew installed. From the terminal, run:\n{{< highlight bash  >}}\n$ brew --version\n{{< / highlight >}}\nIf this command fails, you'll need to follow the Homebrew installation instructions.\nInstallation\nFrom the terminal, run:\n{{< highlight bash  >}}\nbrew install redis\n{{< / highlight >}}\nThis will install Redis on your system.\nStarting and stopping Redis in the foreground\nTo test your Redis installation, you can run the `redis-server` executable from the command line:\n{{< highlight bash  >}}\nredis-server\n{{< / highlight >}}\nIf successful, you'll see the startup logs for Redis, and Redis will be running in the foreground.\nTo stop Redis, enter `Ctrl-C`.\nStarting and stopping Redis using launchd\nAs an alternative to running Redis in the foreground, you can also use `launchd` to start the process in the background:\n{{< highlight bash  >}}\nbrew services start redis\n{{< / highlight >}}\nThis launches Redis and restarts it at login. You can check the status of a `launchd` managed Redis by running the following:\n{{< highlight bash  >}}\nbrew services info redis\n{{< / highlight >}}\nIf the service is running, you'll see output like the following:\n{{< highlight bash  >}}\nredis (homebrew.mxcl.redis)\nRunning: \u2714\nLoaded: \u2714\nUser: miranda\nPID: 67975\n{{< / highlight >}}\nTo stop the service, run:\n{{< highlight bash  >}}\nbrew services stop redis\n{{< / highlight >}}\nConnect to Redis\nOnce Redis is running, you can test it by running `redis-cli`:\n{{< highlight bash  >}}\nredis-cli\n{{< / highlight >}}\nThis will open the Redis REPL. Try running some commands:\n{{< highlight bash >}}\n127.0.0.1:6379> lpush demos redis-macOS-demo\nOK\n127.0.0.1:6379> rpop demos\n\"redis-macOS-demo\"\n{{< / highlight >}}\nNext steps\nOnce you have a running Redis instance, you may want to:\n\nTry the Redis CLI tutorial\n",
    "tag": "redis"
  },
  {
    "title": "Install on Ubuntu/Debian",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/getting-started/installation/install-redis-on-linux.md",
    "content": "\ntitle: \"Install Redis on Linux\"\nlinkTitle: \"Install on Linux\"\nweight: 1\ndescription: >\n    How to install Redis on Linux\n\nMost major Linux distributions provide packages for Redis.\nInstall on Ubuntu/Debian\nYou can install recent stable versions of Redis from the official `packages.redis.io` APT repository.\n{{% alert title=\"Prerequisites\" color=\"warning\" %}}\nIf you're running a very minimal distribution (such as a Docker container) you may need to install `lsb-release` first:\n{{< highlight bash  >}}\nsudo apt install lsb-release\n{{< / highlight  >}}\n{{% /alert  %}}\nAdd the repository to the `apt` index, update it, and then install:\n{{< highlight bash  >}}\ncurl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\nsudo apt-get update\nsudo apt-get install redis\n{{< / highlight  >}}\nInstall from Snapcraft\nThe Snapcraft store provides Redis packages that can be installed on platforms that support snap.\nSnap is supported and available on most major Linux distributions.\nTo install via snap, run:\n{{< highlight bash  >}}\nsudo snap install redis\n{{< / highlight  >}}",
    "tag": "redis"
  },
  {
    "title": "Install or enable WSL2",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/getting-started/installation/install-redis-on-windows.md",
    "content": "\ntitle: \"Install Redis on Windows\"\nlinkTitle: \"Install on Windows\"\nweight: 1\ndescription: Use Redis on Windows for development\n\nRedis is not officially supported on Windows. However, you can install Redis on Windows for development by following the instructions below.\nTo install Redis on Windows, you'll first need to enable WSL2 (Windows Subsystem for Linux). WSL2 lets you run Linux binaries natively on Windows. For this method to work, you'll need to be running Windows 10 version 2004 and higher or Windows 11.\nInstall or enable WSL2\nMicrosoft provides detailed instructions for installing WSL. Follow these instructions, and take note of the default Linux distribution it installs. This guide assumes Ubuntu.\nInstall Redis\nOnce you're running Ubuntu on Windows, you can follow the steps detailed at Install on Ubuntu/Debian to install recent stable versions of Redis from the official `packages.redis.io` APT repository.\nAdd the repository to the `apt` index, update it, and then install:\n{{< highlight bash  >}}\ncurl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\nsudo apt-get update\nsudo apt-get install redis\n{{< / highlight  >}}\nLastly, start the Redis server like so:\n{{< highlight bash  >}}\nsudo service redis-server start\n{{< / highlight  >}}\nConnect to Redis\nYou can test that your Redis server is running by connecting with the Redis CLI:\n{{< highlight bash  >}}\nredis-cli \n127.0.0.1:6379> ping\nPONG",
    "tag": "redis"
  },
  {
    "title": "Downloading the source files",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/getting-started/installation/install-redis-from-source.md",
    "content": "\ntitle: \"Install Redis from Source\"\nlinkTitle: \"Install from Source\"\nweight: 5\ndescription: >\n    Compile and install Redis from source\n\nYou can compile and install Redis from source on variety of platforms and operating systems including Linux and macOS. Redis has no dependencies other than a C  compiler and `libc`.\nDownloading the source files\nThe Redis source files are available on this site's Download page. You can verify the integrity of these downloads by checking them against the digests in the redis-hashes git repository.\nTo obtain the source files for the latest stable version of Redis from the Redis downloads site, run:\n{{< highlight bash >}}\nwget https://download.redis.io/redis-stable.tar.gz\n{{< / highlight >}}\nCompiling Redis\nTo compile Redis, first the tarball, change to the root directory, and then run `make`:\n{{< highlight bash >}}\ntar -xzvf redis-stable.tar.gz\ncd redis-stable\nmake\n{{< / highlight >}}\nIf the compile succeeds, you'll find several Redis binaries in the `src` directory, including:\n\nredis-server: the Redis Server itself\nredis-cli is the command line interface utility to talk with Redis.\n\nTo install these binaries in `/usr/local/bin`, run:\n{{< highlight bash  >}}\nmake install\n{{< / highlight >}}\nStarting and stopping Redis in the foreground\nOnce installed, you can start Redis by running\n{{< highlight bash  >}}\nredis-server\n{{< / highlight >}}\nIf successful, you'll see the startup logs for Redis, and Redis will be running in the foreground.",
    "tag": "redis"
  },
  {
    "title": "Accepting Client Connections",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/clients.md",
    "content": "\ntitle: \"Redis client handling\"\nlinkTitle: \"Client handling\"\nweight: 5\ndescription: >\n    How the Redis server manages client connections\naliases:\n    - /topics/clients\n\nThis document provides information about how Redis handles clients at the network layer level: connections, timeouts, buffers, and other similar topics are covered here.\nThe information contained in this document is only applicable to Redis version 2.6 or greater.\nAccepting Client Connections\nRedis accepts clients connections on the configured TCP port and on the Unix socket if enabled. When a new client connection is accepted the following operations are performed:\n\nThe client socket is put in the non-blocking state since Redis uses multiplexing and non-blocking I/O.\nThe `TCP_NODELAY` option is set in order to ensure that there are no delays to the connection.\nA readable file event is created so that Redis is able to collect the client queries as soon as new data is available to read on the socket.\n\nAfter the client is initialized, Redis checks if it is already at the limit\nconfigured for the number of simultaneous clients (configured using the `maxclients` configuration directive, see the next section of this document for further information).\nWhen Redis can't accept a new client connection because the maximum number of clients\nhas been reached, it tries to send an error to the client in order to\nmake it aware of this condition, closing the connection immediately.\nThe error message will reach the client even if the connection is\nclosed immediately by Redis because the new socket output buffer is usually\nbig enough to contain the error, so the kernel will handle transmission\nof the error.\nWhat Order are Client Requests Served In?\nThe order is determined by a combination of the client socket file descriptor\nnumber and order in which the kernel reports events, so the order should be \nconsidered as unspecified.\nHowever, Redis does the following two things when serving clients:\n\nIt only performs a single `read()` system call every time there is something new to read from the client socket. This ensures that if we have multiple clients connected, and a few send queries at a high rate, other clients are not penalized and will not experience latency issues.\nHowever once new data is read from a client, all the queries contained in the current buffers are processed sequentially. This improves locality and does not need iterating a second time to see if there are clients that need some processing time.\n\nMaximum Concurrent Connected Clients\nIn Redis 2.4 there was a hard-coded limit for the maximum number of clients\nthat could be handled simultaneously.\nIn Redis 2.6 and newer, this limit is dynamic: by default it is set to 10000 clients, unless\notherwise stated by the `maxclients` directive in `redis.conf`.\nHowever, Redis checks with the kernel what the maximum number of file\ndescriptors that we are able to open is (the soft limit is checked). If the\nlimit is less than the maximum number of clients we want to handle, plus\n32 (that is the number of file descriptors Redis reserves for internal uses),\nthen the maximum number of clients is updated to match the number\nof clients it is really able to handle under the current operating system\nlimit.\nWhen `maxclients` is set to a number greater than Redis can support, a message is logged at startup:\n`$ ./redis-server --maxclients 100000\n[41422] 23 Jan 11:28:33.179 # Unable to set the max number of files limit to 100032 (Invalid argument), setting the max clients configuration to 10112.`\nWhen Redis is configured in order to handle a specific number of clients it\nis a good idea to make sure that the operating system limit for the maximum\nnumber of file descriptors per process is also set accordingly.\nUnder Linux these limits can be set both in the current session and as a\nsystem-wide setting with the following commands:\n\n`ulimit -Sn 100000 # This will only work if hard limit is big enough.`\n`sysctl -w fs.file-max=100000`\n\nOutput Buffer Limits\nRedis needs to handle a variable-length output buffer for every client, since\na command can produce a large amount of data that needs to be transferred to the\nclient.\nHowever it is possible that a client sends more commands producing more output\nto serve at a faster rate than that which Redis can send the existing output to the\nclient. This is especially true with Pub/Sub clients in case a client is not\nable to process new messages fast enough.\nBoth conditions will cause the client output buffer to grow and consume\nmore and more memory. For this reason by default Redis sets limits to the\noutput buffer size for different kind of clients. When the limit is reached\nthe client connection is closed and the event logged in the Redis log file.\nThere are two kind of limits Redis uses:\n\nThe hard limit is a fixed limit that when reached will make Redis close the client connection as soon as possible.\nThe soft limit instead is a limit that depends on the time, for instance a soft limit of 32 megabytes per 10 seconds means that if the client has an output buffer bigger than 32 megabytes for, continuously, 10 seconds, the connection gets closed.\n\nDifferent kind of clients have different default limits:\n\nNormal clients have a default limit of 0, that means, no limit at all, because most normal clients use blocking implementations sending a single command and waiting for the reply to be completely read before sending the next command, so it is always not desirable to close the connection in case of a normal client.\nPub/Sub clients have a default hard limit of 32 megabytes and a soft limit of 8 megabytes per 60 seconds.\nReplicas have a default hard limit of 256 megabytes and a soft limit of 64 megabyte per 60 seconds.\n\nIt is possible to change the limit at runtime using the `CONFIG SET` command or in a permanent way using the Redis configuration file `redis.conf`. See the example `redis.conf` in the Redis distribution for more information about how to set the limit.\nQuery Buffer Hard Limit\nEvery client is also subject to a query buffer limit. This is a non-configurable hard limit that will close the connection when the client query buffer (that is the buffer we use to accumulate commands from the client) reaches 1 GB, and is actually only an extreme limit to avoid a server crash in case of client or server software bugs.\nClient Eviction\nRedis is built to handle a very large number of client connections.\nClient connections tend to consume memory, and when there are many of them, the aggregate memory consumption can be extremely high, leading to data eviction or out-of-memory errors.\nThese cases can be mitigated to an extent using output buffer limits, but Redis allows us a more robust configuration to limit the aggregate memory used by all clients' connections.\nThis mechanism is called client eviction, and it's essentially a safety mechanism that will disconnect clients once the aggregate memory usage of all clients is above a threshold.\nThe mechanism first attempts to disconnect clients that use the most memory.\nIt disconnects the minimal number of clients needed to return below the `maxmemory-clients` threshold.\n`maxmemory-clients` defines the maximum aggregate memory usage of all clients connected to Redis.\nThe aggregation takes into account all the memory used by the client connections: the query buffer, the output buffer, and other intermediate buffers.\nNote that replica and master connections aren't affected by the client eviction mechanism. Therefore, such connections are never evicted.\n`maxmemory-clients` can be set permanently in the configuration file (`redis.conf`) or via the `CONFIG SET` command.\nThis setting can either be 0 (meaning no limit), a size in bytes (possibly with `mb`/`gb` suffix),\nor a percentage of `maxmemory` by using the `%` suffix (e.g. setting it to `10%` would mean 10% of the `maxmemory` configuration).\nThe default setting is 0, meaning client eviction is turned off by default.\nHowever, for any large production deployment, it is highly recommended to configure some non-zero `maxmemory-clients` value.\nA value `5%`, for example, can be a good place to start.\nIt is possible to flag a specific client connection to be excluded from the client eviction mechanism.\nThis is useful for control path connections.\nIf, for example, you have an application that monitors the server via the `INFO` command and alerts you in case of a problem, you might want to make sure this connection isn't evicted.\nYou can do so using the following command (from the relevant client's connection):\n`CLIENT NO-EVICT` `on`\nAnd you can revert that with:\n`CLIENT NO-EVICT` `off`\nFor more information and an example refer to the `maxmemory-clients` section in the default `redis.conf` file.\nClient eviction is available from Redis 7.0.\nClient Timeouts\nBy default recent versions of Redis don't close the connection with the client\nif the client is idle for many seconds: the connection will remain open forever.\nHowever if you don't like this behavior, you can configure a timeout, so that\nif the client is idle for more than the specified number of seconds, the client connection will be closed.\nYou can configure this limit via `redis.conf` or simply using `CONFIG SET timeout <value>`.\nNote that the timeout only applies to normal clients and it does not apply to Pub/Sub clients, since a Pub/Sub connection is a push style connection so a client that is idle is the norm.\nEven if by default connections are not subject to timeout, there are two conditions when it makes sense to set a timeout:\n\nMission critical applications where a bug in the client software may saturate the Redis server with idle connections, causing service disruption.\nAs a debugging mechanism in order to be able to connect with the server if a bug in the client software saturates the server with idle connections, making it impossible to interact with the server.\n\nTimeouts are not to be considered very precise: Redis avoids setting timer events or running O(N) algorithms in order to check idle clients, so the check is performed incrementally from time to time. This means that it is possible that while the timeout is set to 10 seconds, the client connection will be closed, for instance, after 12 seconds if many clients are connected at the same time.\nThe CLIENT Command\nThe Redis `CLIENT` command allows you to inspect the state of every connected client, to kill a specific client, and to name connections. It is a very powerful debugging tool if you use Redis at scale.\n`CLIENT LIST` is used in order to obtain a list of connected clients and their state:\n`redis 127.0.0.1:6379> client list\naddr=127.0.0.1:52555 fd=5 name= age=855 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client\naddr=127.0.0.1:52787 fd=6 name= age=6 idle=5 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=ping`\nIn the above example two clients are connected to the Redis server. Let's look at what some of the data returned represents:\n\naddr: The client address, that is, the client IP and the remote port number it used to connect with the Redis server.\nfd: The client socket file descriptor number.\nname: The client name as set by `CLIENT SETNAME`.\nage: The number of seconds the connection existed for.\nidle: The number of seconds the connection is idle.\nflags: The kind of client (N means normal client, check the full list of flags).\nomem: The amount of memory used by the client for the output buffer.\ncmd: The last executed command.\n\nSee the CLIENT LIST documentation for the full listing of fields and their purpose.\nOnce you have the list of clients, you can close a client's connection using the `CLIENT KILL` command, specifying the client address as its argument.\nThe commands `CLIENT SETNAME` and `CLIENT GETNAME` can be used to set and get the connection name. Starting with Redis 4.0, the client name is shown in the\n`SLOWLOG` output, to help identify clients that create latency issues.\nTCP keepalive",
    "tag": "redis"
  },
  {
    "title": "Redis service discovery via Sentinel",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/sentinel-clients.md",
    "content": "\ntitle: \"Sentinel client spec\"\nlinkTitle: \"Sentinel clients\"\nweight: 2\ndescription: How to build clients for Redis Sentinel\naliases:\n  - /topics/sentinel-clients\n\nRedis Sentinel is a monitoring solution for Redis instances that handles\nautomatic failover of Redis masters and service discovery (who is the current\nmaster for a given group of instances?). Since Sentinel is both responsible\nfor reconfiguring instances during failovers, and providing configurations to\nclients connecting to Redis masters or replicas, clients are required to have\nexplicit support for Redis Sentinel.\nThis document is targeted at Redis clients developers that want to support Sentinel in their clients implementation with the following goals:\n\nAutomatic configuration of clients via Sentinel.\nImproved safety of Redis Sentinel automatic failover.\n\nFor details about how Redis Sentinel works, please check the Redis Documentation, as this document only contains information needed for Redis client developers, and it is expected that readers are familiar with the way Redis Sentinel works.\nRedis service discovery via Sentinel\nRedis Sentinel identifies every master with a name like \"stats\" or \"cache\".\nEvery name actually identifies a group of instances, composed of a master\nand a variable number of replicas.\nThe address of the Redis master that is used for a specific purpose inside a network may change after events like an automatic failover, a manually triggered failover (for instance in order to upgrade a Redis instance), and other reasons.\nNormally Redis clients have some kind of hard-coded configuration that specifies the address of a Redis master instance within a network as IP address and port number. However if the master address changes, manual intervention in every client is needed.\nA Redis client supporting Sentinel can automatically discover the address of a Redis master from the master name using Redis Sentinel. So instead of a hard coded IP address and port, a client supporting Sentinel should optionally be able to take as input:\n\nA list of ip:port pairs pointing to known Sentinel instances.\nThe name of the service, like \"cache\" or \"timelines\".\n\nThis is the procedure a client should follow in order to obtain the master address starting from the list of Sentinels and the service name.\nStep 1: connecting to the first Sentinel\nThe client should iterate the list of Sentinel addresses. For every address it should try to connect to the Sentinel, using a short timeout (in the order of a few hundreds of milliseconds). On errors or timeouts the next Sentinel address should be tried.\nIf all the Sentinel addresses were tried without success, an error should be returned to the client.\nThe first Sentinel replying to the client request should be put at the start of the list, so that at the next reconnection, we'll try first the Sentinel that was reachable in the previous connection attempt, minimizing latency.\nStep 2: ask for master address\nOnce a connection with a Sentinel is established, the client should retry to execute the following command on the Sentinel:\n\n\n```SENTINEL get-master-addr-by-name master-name\n```\n\n\nWhere master-name should be replaced with the actual service name specified by the user.\nThe result from this call can be one of the following two replies:\n\nAn ip:port pair.\nA null reply. This means Sentinel does not know this master.\n\nIf an ip:port pair is received, this address should be used to connect to the Redis master. Otherwise if a null reply is received, the client should try the next Sentinel in the list.\nStep 3: call the ROLE command in the target instance\nOnce the client discovered the address of the master instance, it should\nattempt a connection with the master, and call the `ROLE` command in order\nto verify the role of the instance is actually a master.\nIf the `ROLE` commands is not available (it was introduced in Redis 2.8.12), a client may resort to the `INFO replication` command parsing the `role:` field of the output.\nIf the instance is not a master as expected, the client should wait a short amount of time (a few hundreds of milliseconds) and should try again starting from Step 1.\nHandling reconnections\nOnce the service name is resolved into the master address and a connection is established with the Redis master instance, every time a reconnection is needed, the client should resolve again the address using Sentinels restarting from Step 1. For instance Sentinel should contacted again the following cases:\n\nIf the client reconnects after a timeout or socket error.\nIf the client reconnects because it was explicitly closed or reconnected by the user.\n\nIn the above cases and any other case where the client lost the connection with the Redis server, the client should resolve the master address again.\nSentinel failover disconnection\nStarting with Redis 2.8.12, when Redis Sentinel changes the configuration of\nan instance, for example promoting a replica to a master, demoting a master to\nreplicate to the new master after a failover, or simply changing the master\naddress of a stale replica instance, it sends a `CLIENT KILL type normal`\ncommand to the instance in order to make sure all the clients are disconnected\nfrom the reconfigured instance. This will force clients to resolve the master\naddress again.\nIf the client will contact a Sentinel with yet not updated information, the verification of the Redis instance role via the `ROLE` command will fail, allowing the client to detect that the contacted Sentinel provided stale information, and will try again.\nNote: it is possible that a stale master returns online at the same time a client contacts a stale Sentinel instance, so the client may connect with a stale master, and yet the ROLE output will match. However when the master is back again Sentinel will try to demote it to replica, triggering a new disconnection. The same reasoning applies to connecting to stale replicas that will get reconfigured to replicate with a different master.\nConnecting to replicas\nSometimes clients are interested to connect to replicas, for example in order to scale read requests. This protocol supports connecting to replicas by modifying step 2 slightly. Instead of calling the following command:\n\n\n```SENTINEL get-master-addr-by-name master-name\n```\n\n\nThe clients should call instead:\n\n\n```SENTINEL replicas master-name\n```\n\n\nIn order to retrieve a list of replica instances.\nSymmetrically the client should verify with the `ROLE` command that the\ninstance is actually a replica, in order to avoid scaling read queries with\nthe master.\nConnection pools\nFor clients implementing connection pools, on reconnection of a single connection, the Sentinel should be contacted again, and in case of a master address change all the existing connections should be closed and connected to the new address.\nError reporting\nThe client should correctly return the information to the user in case of errors. Specifically:\n\nIf no Sentinel can be contacted (so that the client was never able to get the reply to `SENTINEL get-master-addr-by-name`), an error that clearly states that Redis Sentinel is unreachable should be returned.\nIf all the Sentinels in the pool replied with a null reply, the user should be informed with an error that Sentinels don't know this master name.\n\nSentinels list automatic refresh\nOptionally once a successful reply to `get-master-addr-by-name` is received, a client may update its internal list of Sentinel nodes following this procedure:\n\nObtain a list of other Sentinels for this master using the command `SENTINEL sentinels <master-name>`.\nAdd every ip:port pair not already existing in our list at the end of the list.\n\nIt is not needed for a client to be able to make the list persistent updating its own configuration. The ability to upgrade the in-memory representation of the list of Sentinels can be already useful to improve reliability.\nSubscribe to Sentinel events to improve responsiveness\nThe Sentinel documentation shows how clients can connect to\nSentinel instances using Pub/Sub in order to subscribe to changes in the\nRedis instances configurations.\nThis mechanism can be used in order to speedup the reconfiguration of clients,\nthat is, clients may listen to Pub/Sub in order to know when a configuration\nchange happened in order to run the three steps protocol explained in this\ndocument in order to resolve the new Redis master (or replica) address.\nHowever update messages received via Pub/Sub should not substitute the\nabove procedure, since there is no guarantee that a client is able to\nreceive all the update messages.\nAdditional information",
    "tag": "redis"
  },
  {
    "title": "Redis /proc/cpu/alignment requirements",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/arm.md",
    "content": "\ntitle: \"ARM support\"\nlinkTitle: \"ARM support\"\nweight: 11\ndescription: >\n    Exploring Redis on the ARM CPU Architecture\naliases:\n    - /topics/ARM\n\nRedis versions 4.0 and above support the ARM processor in general, and\nthe Raspberry Pi specifically, as a main platform. Every new release of Redis is tested on the Pi\nenvironment, and we update this documentation page with information about supported devices and other useful information. While Redis does run on Android, in the future we look forward to extend our testing efforts to Android\nto also make it an officially supported platform.\nWe believe that Redis is ideal for IoT and embedded devices for several\nreasons:\n\nRedis has a very small memory footprint and CPU requirements. It can run in small devices like the Raspberry Pi Zero without impacting the overall performance, using a small amount of memory while delivering good performance for many use cases.\nThe data structures of Redis are often an ideal way to model IoT/embedded use cases. Some examples include accumulating time series data, receiving or queuing commands to execute or respond to send back to the remote servers, and so forth.\nModeling data inside Redis can be very useful in order to make in-device decisions for appliances that must respond very quickly or when the remote servers are offline.\nRedis can be used as a communication system between the processes running in the device.\nThe append-only file storage of Redis is well suited for SSD cards.\nThe stream data structure included in Redis versions 5.0 and higher was specifically designed for time series applications and has a very low memory overhead.\n\nRedis /proc/cpu/alignment requirements\nLinux on ARM allows to trap unaligned accesses and fix them inside the kernel\nin order to continue the execution of the offending program instead of\ngenerating a `SIGBUS`. Redis 4.0 and greater are fixed in order to avoid any kind\nof unaligned access, so there is no need to have a specific value for this\nkernel configuration. Even when kernel alignment fixing set as disabled Redis should\nrun as expected.\nBuilding Redis in the Pi\n\nDownload Redis version 4.0 or higher.\nUse `make` as usual to create the executable.\n\nThere is nothing special in the process. The only difference is that by\ndefault, Redis uses the `libc` allocator instead of defaulting to `jemalloc`\nas it does in other Linux based environments. This is because we believe\nthat for the small use cases inside embedded devices, memory fragmentation\nis unlikely to be a problem. Moreover `jemalloc` on ARM may not be as tested\nas the `libc` allocator.\nPerformance\nPerformance testing of Redis was performed on the Raspberry Pi 3 and Pi 1 model B. The difference between the two Pis in terms of delivered performance is quite big. The benchmarks were performed via the\nloopback interface, since most use cases will probably use Redis from within\nthe device and not via the network. The following numbers were obtained using\nRedis 4.0.\nRaspberry Pi 3:\n\nTest 1 : 5 millions writes with 1 million keys (even distribution among keys).  No persistence, no pipelining. 28,000 ops/sec.\nTest 2: Like test 1 but with pipelining using groups of 8 operations: 80,000 ops/sec.\nTest 3: Like test 1 but with AOF enabled, fsync 1 sec: 23,000 ops/sec\nTest 4: Like test 3, but with an AOF rewrite in progress: 21,000 ops/sec\n\nRaspberry Pi 1 model B:\n\nTest 1 : 5 millions writes with 1 million keys (even distribution among keys).  No persistence, no pipelining.  2,200 ops/sec.\nTest 2: Like test 1 but with pipelining using groups of 8 operations: 8,500 ops/sec.\nTest 3: Like test 1 but with AOF enabled, fsync 1 sec: 1,820 ops/sec\nTest 4: Like test 3, but with an AOF rewrite in progress: 1,000 ops/sec\n",
    "tag": "redis"
  },
  {
    "title": "nondeterministic_output",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/command-tips.md",
    "content": "\ntitle: \"Redis command tips\"\nlinkTitle: \"Command tips\"\nweight: 1\ndescription: Get additional information about a command\naliases:\n    - /topics/command-tips\n\nCommand tips are an array of strings.\nThese provide Redis clients with additional information about the command.\nThe information can instruct Redis Cluster clients as to how the command should be executed and its output processed in a clustered deployment.\nUnlike the command's flags (see the 3rd element of `COMMAND`'s reply), which are strictly internal to the server's operation, tips don't serve any purpose other than being reported to clients.\nCommand tips are arbitrary strings.\nHowever, the following sections describe proposed tips and demonstrate the conventions they are likely to adhere to.\nnondeterministic_output\nThis tip indicates that the command's output isn't deterministic.\nThat means that calls to the command may yield different results with the same arguments and data.\nThat difference could be the result of the command's random nature (e.g., `RANDOMKEY` and `SPOP`); the call's timing (e.g., `TTL`); or generic differences that relate to the server's state (e.g., `INFO` and `CLIENT LIST`).\nNote:\nPrior to Redis 7.0, this tip was the random command flag.\nnondeterministic_output_order\nThe existence of this tip indicates that the command's output is deterministic, but its ordering is random (e.g., `HGETALL` and `SMEMBERS`).\nNote:\nPrior to Redis 7.0, this tip was the sort_for_script flag.\nrequest_policy\nThis tip can help clients determine the shards to send the command in clustering mode.\nThe default behavior a client should implement for commands without the request_policy tip is as follows:\n\nThe command doesn't accept key name arguments: the client can execute the command on an arbitrary shard.\nFor commands that accept one or more key name arguments: the client should route the command to a single shard, as determined by the hash slot of the input keys.\n\nIn cases where the client should adopt a behavior different than the default, the request_policy tip can be one of:\n\nall_nodes: the client should execute the command on all nodes - masters and replicas alike.\n  An example is the `CONFIG SET` command. \n  This tip is in-use by commands that don't accept key name arguments.\n  The command operates atomically per shard.\nall_shards: the client should execute the command on all master shards (e.g., the `DBSIZE` command).\n  This tip is in-use by commands that don't accept key name arguments.\n  The command operates atomically per shard.\nmulti_shard: the client should execute the command on several shards.\n  The shards that execute the command are determined by the hash slots of its input key name arguments.\n  Examples for such commands include `MSET`, `MGET` and `DEL`.\n  However, note that `SUNIONSTORE` isn't considered as multi_shard because all of its keys must belong to the same hash slot.\nspecial: indicates a non-trivial form of the client's request policy, such as the `SCAN` command.\n\nresponse_policy\nThis tip can help clients determine the aggregate they need to compute from the replies of multiple shards in a cluster.\nThe default behavior for commands without a request_policy tip only applies to replies with of nested types (i.e., an array, a set, or a map).\nThe client's implementation for the default behavior should be as follows:\n\nThe command doesn't accept key name arguments: the client can aggregate all replies within a single nested data structure.\nFor example, the array replies we get from calling `KEYS` against all shards.\nThese should be packed in a single in no particular order.\nFor commands that accept one or more key name arguments: the client needs to retain the same order of replies as the input key names.\nFor example, `MGET`'s aggregated reply.\n\nThe response_policy tip is set for commands that reply with scalar data types, or when it's expected that clients implement a non-default aggregate.\nThis tip can be one of:\n\none_succeeded: the clients should return success if at least one shard didn't reply with an error.\n  The client should reply with the first non-error reply it obtains.\n  If all shards return an error, the client can reply with any one of these.\n  For example, consider a `SCRIPT KILL` command that's sent to all shards.\n  Although the script should be loaded in all of the cluster's shards, the `SCRIPT KILL` will typically run only on one at a given time.\nall_succeeded: the client should return successfully only if there are no error replies.\n  Even a single error reply should disqualify the aggregate and be returned.\n  Otherwise, the client should return one of the non-error replies.\n  As an example, consider the `CONFIG SET`, `SCRIPT FLUSH` and `SCRIPT LOAD` commands.\nagg_logical_and: the client should return the result of a logical AND operation on all replies (only applies to integer replies, usually from commands that return either 0 or 1).\n  Consider the `SCRIPT EXISTS` command as an example.\n  It returns an array of 0's and 1's that denote the existence of its given SHA1 sums in the script cache.\n  The aggregated response should be 1 only when all shards had reported that a given script SHA1 sum is in their respective cache.\nagg_logical_or: the client should return the result of a logical AND operation on all replies (only applies to integer replies, usually from commands that return either 0 or 1).\nagg_min: the client should return the minimal value from the replies (only applies to numerical replies).\n  The aggregate reply from a cluster-wide `WAIT` command, for example, should be the minimal value (number of synchronized replicas) from all shards.\nagg_max: the client should return the maximal value from the replies (only applies to numerical replies).\nagg_sum: the client should return the sum of replies (only applies to numerical replies).\n  Example: `DBSIZE`.\nspecial: this type of tip indicates a non-trivial form of reply policy.\n  `INFO` is an excellent example of that.\n\nExample\n```\nredis> command info ping\n1)  1) \"ping\"\n    2) (integer) -1\n    3) 1) fast\n    4) (integer) 0\n    5) (integer) 0\n    6) (integer) 0\n    7) 1) @fast\n       2) @connection\n    8) 1) \"request_policy:all_shards\"\n       2) \"response_policy:all_succeeded\"\n    9) (empty array)\n   10) (empty array)",
    "tag": "redis"
  },
  {
    "title": "How it works",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/gopher.md",
    "content": "\ntitle: \"Redis and the Gopher protocol\"\nlinkTitle: \"Gopher protocol\"\nweight: 10\ndescription: The Redis Gopher protocol implementation\naliases:\n  - /topics/gopher\n\n Note: Support for Gopher was removed in Redis 7.0 \nRedis contains an implementation of the Gopher protocol, as specified in\nthe RFC 1436.\nThe Gopher protocol was very popular in the late '90s. It is an alternative\nto the web, and the implementation both server and client side is so simple\nthat the Redis server has just 100 lines of code in order to implement this\nsupport.\nWhat do you do with Gopher nowadays? Well Gopher never really died, and\nlately there is a movement in order for the Gopher more hierarchical content\ncomposed of just plain text documents to be resurrected. Some want a simpler\ninternet, others believe that the mainstream internet became too much\ncontrolled, and it's cool to create an alternative space for people that\nwant a bit of fresh air.\nAnyway, for the 10th birthday of the Redis, we gave it the Gopher protocol\nas a gift.\nHow it works\nThe Redis Gopher support uses the inline protocol of Redis, and specifically\ntwo kind of inline requests that were anyway illegal: an empty request\nor any request that starts with \"/\" (there are no Redis commands starting\nwith such a slash). Normal RESP2/RESP3 requests are completely out of the\npath of the Gopher protocol implementation and are served as usually as well.\nIf you open a connection to Redis when Gopher is enabled and send it\na string like \"/foo\", if there is a key named \"/foo\" it is served via the\nGopher protocol.\nIn order to create a real Gopher \"hole\" (the name of a Gopher site in Gopher\ntalking), you likely need a script such as the one in https://github.com/antirez/gopher2redis.\nSECURITY WARNING\nIf you plan to put Redis on the internet in a publicly accessible address\nto server Gopher pages make sure to set a password to the instance.\nOnce a password is set:\n\nThe Gopher server (when enabled, not by default) will kill serve content via Gopher.\nHowever other commands cannot be called before the client will authenticate.\n\nSo use the `requirepass` option to protect your instance.\nTo enable Gopher support use the following configuration line.\n\n\n```gopher-enabled yes\n```\n\n\nAccessing keys that are not strings or do not exit will generate",
    "tag": "redis"
  },
  {
    "title": "SIGTERM and SIGINT",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/signals.md",
    "content": "\ntitle: \"Redis signal handling\"\nlinkTitle: \"Signal handling\"\nweight: 8\ndescription: How Redis handles common Unix signals\naliases:\n    - /topics/signals\n\nThis document provides information about how Redis reacts to different POSIX signals such as `SIGTERM` and `SIGSEGV`.\nThe information in this document only applies to Redis version 2.6 or greater.\nSIGTERM and SIGINT\nThe `SIGTERM` and `SIGINT` signals tell Redis to shut down gracefully. When the server receives this signal,\nit does not immediately exit. Instead, it schedules\na shutdown similar to the one performed by the `SHUTDOWN` command. The scheduled shutdown starts as soon as possible, specifically as long as the\ncurrent command in execution terminates (if any), with a possible additional\ndelay of 0.1 seconds or less.\nIf the server is blocked by a long-running Lua script,\nkill the script with `SCRIPT KILL` if possible. The scheduled shutdown will\nrun just after the script is killed or terminates spontaneously.\nThis shutdown process includes the following actions:\n\nIf there are any replicas lagging behind in replication:\nPause clients attempting to write with `CLIENT PAUSE` and the `WRITE` option.\nWait up to the configured `shutdown-timeout` (default 10 seconds) for replicas to catch up with the master's replication offset.\nIf a background child is saving the RDB file or performing an AOF rewrite, the child process is killed.\nIf the AOF is active, Redis calls the `fsync` system call on the AOF file descriptor to flush the buffers on disk.\nIf Redis is configured to persist on disk using RDB files, a synchronous (blocking) save is performed. Since the save is synchronous, it doesn't use any additional memory.\nIf the server is daemonized, the PID file is removed.\nIf the Unix domain socket is enabled, it gets removed.\nThe server exits with an exit code of zero.\n\nIF the RDB file can't be saved, the shutdown fails, and the server continues to run in order to ensure no data loss.\nLikewise, if the user just turned on AOF, and the server triggered the first AOF rewrite in order to create the initial AOF file but this file can't be saved, the shutdown fails and the server continues to run.\nSince Redis 2.6.11, no further attempt to shut down will be made unless a new `SIGTERM` is received or the `SHUTDOWN` command is issued.\nSince Redis 7.0, the server waits for lagging replicas up to a configurable `shutdown-timeout`, 10 seconds by default, before shutting down.\nThis provides a best effort to minimize the risk of data loss in a situation where no save points are configured and AOF is deactivated.\nBefore version 7.0, shutting down a heavily loaded master node in a diskless setup was more likely to result in data loss.\nTo minimize the risk of data loss in such setups, trigger a manual `FAILOVER` (or `CLUSTER FAILOVER`) to demote the master to a replica and promote one of the replicas to a new master before shutting down a master node.\nSIGSEGV, SIGBUS, SIGFPE and SIGILL\nThe following signals are handled as a Redis crash:\n\nSIGSEGV\nSIGBUS\nSIGFPE\nSIGILL\n\nOnce one of these signals is trapped, Redis stops any current operation and performs the following actions:\n\nAdds a bug report to the log file. This includes a stack trace, dump of registers, and information about the state of clients.\nSince Redis 2.8, a fast memory test is performed as a first check of the reliability of the crashing system.\nIf the server was daemonized, the PID file is removed.\nFinally the server unregisters its own signal handler for the received signal and resends the same signal to itself to make sure that the default action is performed, such as dumping the core on the file system.\n\nWhat happens when a child process gets killed\nWhen the child performing the Append Only File rewrite gets killed by a signal,\nRedis handles this as an error and discards the (probably partial or corrupted)\nAOF file. It will attempt the rewrite again later.\nWhen the child performing an RDB save is killed, Redis handles the\ncondition as a more severe error. While the failure of an\nAOF file rewrite can cause AOF file enlargement, failed RDB file\ncreation reduces durability.\nAs a result of the child producing the RDB file being killed by a signal,\nor when the child exits with an error (non zero exit code), Redis enters\na special error condition where no further write command is accepted.\n\nRedis will continue to reply to read commands.\nRedis will reply to all write commands with a `MISCONFIG` error.\n\nThis error condition will persist until it becomes possible to create an RDB file successfully.\nKill the RDB file without errors\nSometimes the user may want to kill the RDB-saving child process without\ngenerating an error. Since Redis version 2.6.10, this can be done using the signal `SIGUSR1`. This signal is handled in a special way:\nit kills the child process like any other signal, but the parent process will\nnot detect this as a critical error and will continue to serve write",
    "tag": "redis"
  },
  {
    "title": "Main properties and rationales of the design",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/cluster-spec.md",
    "content": "\ntitle: Redis cluster specification\nlinkTitle: Cluster spec\nweight: 9\ndescription: >\n    Detailed specification for Redis cluster\naliases:\n  - /topics/cluster-spec\n\nWelcome to the Redis Cluster Specification. Here you'll find information\nabout the algorithms and design rationales of Redis Cluster. This document is a work\nin progress as it is continuously synchronized with the actual implementation\nof Redis.\nMain properties and rationales of the design\nRedis Cluster goals\nRedis Cluster is a distributed implementation of Redis with the following goals in order of importance in the design:\n\nHigh performance and linear scalability up to 1000 nodes. There are no proxies, asynchronous replication is used, and no merge operations are performed on values.\nAcceptable degree of write safety: the system tries (in a best-effort way) to retain all the writes originating from clients connected with the majority of the master nodes. Usually there are small windows where acknowledged writes can be lost. Windows to lose acknowledged writes are larger when clients are in a minority partition.\nAvailability: Redis Cluster is able to survive partitions where the majority of the master nodes are reachable and there is at least one reachable replica for every master node that is no longer reachable. Moreover using replicas migration, masters no longer replicated by any replica will receive one from a master which is covered by multiple replicas.\n\nWhat is described in this document is implemented in Redis 3.0 or greater.\nImplemented subset\nRedis Cluster implements all the single key commands available in the\nnon-distributed version of Redis. Commands performing complex multi-key\noperations like set unions and intersections are implemented for cases where\nall of the keys involved in the operation hash to the same slot.\nRedis Cluster implements a concept called hash tags that can be used\nto force certain keys to be stored in the same hash slot. However, during\nmanual resharding, multi-key operations may become unavailable for some time\nwhile single-key operations are always available.\nRedis Cluster does not support multiple databases like the standalone version\nof Redis. We only support database `0`; the `SELECT` command is not allowed.\nClient and Server roles in the Redis cluster protocol\nIn Redis Cluster, nodes are responsible for holding the data,\nand taking the state of the cluster, including mapping keys to the right nodes.\nCluster nodes are also able to auto-discover other nodes, detect non-working\nnodes, and promote replica nodes to master when needed in order\nto continue to operate when a failure occurs.\nTo perform their tasks all the cluster nodes are connected using a\nTCP bus and a binary protocol, called the Redis Cluster Bus.\nEvery node is connected to every other node in the cluster using the cluster\nbus. Nodes use a gossip protocol to propagate information about the cluster\nin order to discover new nodes, to send ping packets to make sure all the\nother nodes are working properly, and to send cluster messages needed to\nsignal specific conditions. The cluster bus is also used in order to\npropagate Pub/Sub messages across the cluster and to orchestrate manual\nfailovers when requested by users (manual failovers are failovers which\nare not initiated by the Redis Cluster failure detector, but by the\nsystem administrator directly).\nSince cluster nodes are not able to proxy requests, clients may be redirected\nto other nodes using redirection errors `-MOVED` and `-ASK`.\nThe client is in theory free to send requests to all the nodes in the cluster,\ngetting redirected if needed, so the client is not required to hold the\nstate of the cluster. However clients that are able to cache the map between\nkeys and nodes can improve the performance in a sensible way.\nWrite safety\nRedis Cluster uses asynchronous replication between nodes, and last failover wins implicit merge function. This means that the last elected master dataset eventually replaces all the other replicas. There is always a window of time when it is possible to lose writes during partitions. However these windows are very different in the case of a client that is connected to the majority of masters, and a client that is connected to the minority of masters.\nRedis Cluster tries harder to retain writes that are performed by clients connected to the majority of masters, compared to writes performed in the minority side.\nThe following are examples of scenarios that lead to loss of acknowledged\nwrites received in the majority partitions during failures:\n\n\nA write may reach a master, but while the master may be able to reply to the client, the write may not be propagated to replicas via the asynchronous replication used between master and replica nodes. If the master dies without the write reaching the replicas, the write is lost forever if the master is unreachable for a long enough period that one of its replicas is promoted. This is usually hard to observe in the case of a total, sudden failure of a master node since masters try to reply to clients (with the acknowledge of the write) and replicas (propagating the write) at about the same time. However it is a real world failure mode.\n\n\nAnother theoretically possible failure mode where writes are lost is the following:\n\n\nA master is unreachable because of a partition.\n\nIt gets failed over by one of its replicas.\nAfter some time it may be reachable again.\nA client with an out-of-date routing table may write to the old master before it is converted into a replica (of the new master) by the cluster.\n\nThe second failure mode is unlikely to happen because master nodes unable to communicate with the majority of the other masters for enough time to be failed over will no longer accept writes, and when the partition is fixed writes are still refused for a small amount of time to allow other nodes to inform about configuration changes. This failure mode also requires that the client's routing table has not yet been updated.\nWrites targeting the minority side of a partition have a larger window in which to get lost. For example, Redis Cluster loses a non-trivial number of writes on partitions where there is a minority of masters and at least one or more clients, since all the writes sent to the masters may potentially get lost if the masters are failed over in the majority side.\nSpecifically, for a master to be failed over it must be unreachable by the majority of masters for at least `NODE_TIMEOUT`, so if the partition is fixed before that time, no writes are lost. When the partition lasts for more than `NODE_TIMEOUT`, all the writes performed in the minority side up to that point may be lost. However the minority side of a Redis Cluster will start refusing writes as soon as `NODE_TIMEOUT` time has elapsed without contact with the majority, so there is a maximum window after which the minority becomes no longer available. Hence, no writes are accepted or lost after that time.\nAvailability\nRedis Cluster is not available in the minority side of the partition. In the majority side of the partition assuming that there are at least the majority of masters and a replica for every unreachable master, the cluster becomes available again after `NODE_TIMEOUT` time plus a few more seconds required for a replica to get elected and failover its master (failovers are usually executed in a matter of 1 or 2 seconds).\nThis means that Redis Cluster is designed to survive failures of a few nodes in the cluster, but it is not a suitable solution for applications that require availability in the event of large net splits.\nIn the example of a cluster composed of N master nodes where every node has a single replica, the majority side of the cluster will remain available as long as a single node is partitioned away, and will remain available with a probability of `1-(1/(N*2-1))` when two nodes are partitioned away (after the first node fails we are left with `N*2-1` nodes in total, and the probability of the only master without a replica to fail is `1/(N*2-1))`.\nFor example, in a cluster with 5 nodes and a single replica per node, there is a `1/(5*2-1) = 11.11%` probability that after two nodes are partitioned away from the majority, the cluster will no longer be available.\nThanks to a Redis Cluster feature called replicas migration the Cluster\navailability is improved in many real world scenarios by the fact that\nreplicas migrate to orphaned masters (masters no longer having replicas).\nSo at every successful failure event, the cluster may reconfigure the replicas\nlayout in order to better resist the next failure.\nPerformance\nIn Redis Cluster nodes don't proxy commands to the right node in charge for a given key, but instead they redirect clients to the right nodes serving a given portion of the key space.\nEventually clients obtain an up-to-date representation of the cluster and which node serves which subset of keys, so during normal operations clients directly contact the right nodes in order to send a given command.\nBecause of the use of asynchronous replication, nodes do not wait for other nodes' acknowledgment of writes (if not explicitly requested using the `WAIT` command).\nAlso, because multi-key commands are only limited to near keys, data is never moved between nodes except when resharding.\nNormal operations are handled exactly as in the case of a single Redis instance. This means that in a Redis Cluster with N master nodes you can expect the same performance as a single Redis instance multiplied by N as the design scales linearly. At the same time the query is usually performed in a single round trip, since clients usually retain persistent connections with the nodes, so latency figures are also the same as the single standalone Redis node case.\nVery high performance and scalability while preserving weak but\nreasonable forms of data safety and availability is the main goal of\nRedis Cluster.\nWhy merge operations are avoided\nThe Redis Cluster design avoids conflicting versions of the same key-value pair in multiple nodes as in the case of the Redis data model this is not always desirable. Values in Redis are often very large; it is common to see lists or sorted sets with millions of elements. Also data types are semantically complex. Transferring and merging these kind of values can be a major bottleneck and/or may require the non-trivial involvement of application-side logic, additional memory to store meta-data, and so forth.\nThere are no strict technological limits here. CRDTs or synchronously replicated\nstate machines can model complex data types similar to Redis. However, the\nactual run time behavior of such systems would not be similar to Redis Cluster.\nRedis Cluster was designed in order to cover the exact use cases of the\nnon-clustered Redis version.\nOverview of Redis Cluster main components\nKey distribution model\nThe cluster's key space is split into 16384 slots, effectively setting an upper limit\nfor the cluster size of 16384 master nodes (however, the suggested max size of\nnodes is on the order of ~ 1000 nodes).\nEach master node in a cluster handles a subset of the 16384 hash slots.\nThe cluster is stable when there is no cluster reconfiguration in\nprogress (i.e. where hash slots are being moved from one node to another).\nWhen the cluster is stable, a single hash slot will be served by a single node\n(however the serving node can have one or more replicas that will replace it in the case of net splits or failures,\nand that can be used in order to scale read operations where reading stale data is acceptable).\nThe base algorithm used to map keys to hash slots is the following\n(read the next paragraph for the hash tag exception to this rule):\n\n\n```HASH_SLOT = CRC16(key) mod 16384\n```\n\n\nThe CRC16 is specified as follows:\n\nName: XMODEM (also known as ZMODEM or CRC-16/ACORN)\nWidth: 16 bit\nPoly: 1021 (That is actually x^16 + x^12 + x^5 + 1)\nInitialization: 0000\nReflect Input byte: False\nReflect Output CRC: False\nXor constant to output CRC: 0000\nOutput for \"123456789\": 31C3\n\n14 out of 16 CRC16 output bits are used (this is why there is\na modulo 16384 operation in the formula above).\nIn our tests CRC16 behaved remarkably well in distributing different kinds of\nkeys evenly across the 16384 slots.\nNote: A reference implementation of the CRC16 algorithm used is available in the Appendix A of this document.\nHash tags\nThere is an exception for the computation of the hash slot that is used in order\nto implement hash tags. Hash tags are a way to ensure that multiple keys\nare allocated in the same hash slot. This is used in order to implement\nmulti-key operations in Redis Cluster.\nTo implement hash tags, the hash slot for a key is computed in a\nslightly different way in certain conditions.\nIf the key contains a \"{...}\" pattern only the substring between\n`{` and `}` is hashed in order to obtain the hash slot. However since it is\npossible that there are multiple occurrences of `{` or `}` the algorithm is\nwell specified by the following rules:\n\nIF the key contains a `{` character.\nAND IF there is a `}` character to the right of `{`.\nAND IF there are one or more characters between the first occurrence of `{` and the first occurrence of `}`.\n\nThen instead of hashing the key, only what is between the first occurrence of `{` and the following first occurrence of `}` is hashed.\nExamples:\n\nThe two keys `{user1000}.following` and `{user1000}.followers` will hash to the same hash slot since only the substring `user1000` will be hashed in order to compute the hash slot.\nFor the key `foo{}{bar}` the whole key will be hashed as usually since the first occurrence of `{` is followed by `}` on the right without characters in the middle.\nFor the key `foo{{bar}}zap` the substring `{bar` will be hashed, because it is the substring between the first occurrence of `{` and the first occurrence of `}` on its right.\nFor the key `foo{bar}{zap}` the substring `bar` will be hashed, since the algorithm stops at the first valid or invalid (without bytes inside) match of `{` and `}`.\nWhat follows from the algorithm is that if the key starts with `{}`, it is guaranteed to be hashed as a whole. This is useful when using binary data as key names.\n\nAdding the hash tags exception, the following is an implementation of the `HASH_SLOT` function in Ruby and C language.\nRuby example code:\n\n\n```def HASH_SLOT(key)\n    s = key.index \"{\"\n    if s\n        e = key.index \"}\",s+1\n        if e && e != s+1\n            key = key[s+1..e-1]\n        end\n    end\n    crc16(key) % 16384\nend\n```\n\n\nC example code:\n\n\n```unsigned int HASH_SLOT(char *key, int keylen) {\n    int s, e; /* start-end indexes of { and } */\n\n    /* Search the first occurrence of '{'. */\n    for (s = 0; s < keylen; s++)\n        if (key[s] == '{') break;\n\n    /* No '{' ? Hash the whole key. This is the base case. */\n    if (s == keylen) return crc16(key,keylen) & 16383;\n\n    /* '{' found? Check if we have the corresponding '}'. */\n    for (e = s+1; e < keylen; e++)\n        if (key[e] == '}') break;\n\n    /* No '}' or nothing between {} ? Hash the whole key. */\n    if (e == keylen || e == s+1) return crc16(key,keylen) & 16383;\n\n    /* If we are here there is both a { and a } on its right. Hash\n     * what is in the middle between { and }. */\n    return crc16(key+s+1,e-s-1) & 16383;\n}\n```\n\n\nCluster node attributes\nEvery node has a unique name in the cluster. The node name is the\nhex representation of a 160 bit random number, obtained the first time a\nnode is started (usually using /dev/urandom).\nThe node will save its ID in the node configuration file, and will use the\nsame ID forever, or at least as long as the node configuration file is not\ndeleted by the system administrator, or a hard reset is requested\nvia the `CLUSTER RESET` command.\nThe node ID is used to identify every node across the whole cluster.\nIt is possible for a given node to change its IP address without any need\nto also change the node ID. The cluster is also able to detect the change\nin IP/port and reconfigure using the gossip protocol running over the cluster\nbus.\nThe node ID is not the only information associated with each node, but is\nthe only one that is always globally consistent. Every node has also the\nfollowing set of information associated. Some information is about the\ncluster configuration detail of this specific node, and is eventually\nconsistent across the cluster. Some other information, like the last time\na node was pinged, is instead local to each node.\nEvery node maintains the following information about other nodes that it is\naware of in the cluster: The node ID, IP and port of the node, a set of\nflags, what is the master of the node if it is flagged as `replica`, last time\nthe node was pinged and the last time the pong was received, the current\nconfiguration epoch of the node (explained later in this specification),\nthe link state and finally the set of hash slots served.\nA detailed explanation of all the node fields is described in the `CLUSTER NODES` documentation.\nThe `CLUSTER NODES` command can be sent to any node in the cluster and provides the state of the cluster and the information for each node according to the local view the queried node has of the cluster.\nThe following is sample output of the `CLUSTER NODES` command sent to a master\nnode in a small cluster of three nodes.\n\n\n```$ redis-cli cluster nodes\nd1861060fe6a534d42d8a19aeb36600e18785e04 127.0.0.1:6379 myself - 0 1318428930 1 connected 0-1364\n3886e65cc906bfd9b1f7e7bde468726a052d1dae 127.0.0.1:6380 master - 1318428930 1318428931 2 connected 1365-2729\nd289c575dcbc4bdd2931585fd4339089e461a27d 127.0.0.1:6381 master - 1318428931 1318428931 3 connected 2730-4095\n```\n\n\nIn the above listing the different fields are in order: node id, address:port, flags, last ping sent, last pong received, configuration epoch, link state, slots. Details about the above fields will be covered as soon as we talk of specific parts of Redis Cluster.\nThe cluster bus\nEvery Redis Cluster node has an additional TCP port for receiving\nincoming connections from other Redis Cluster nodes. This port will be derived by adding 10000 to the data port or it can be specified with the cluster-port config. \nExample 1:\nIf a Redis node is listening for client connections on port 6379, \nand you do not add cluster-port parameter in redis.conf,\nthe Cluster bus port 16379 will be opened.\nExample 2:\nIf a Redis node is listening for client connections on port 6379, \nand you set cluster-port 20000 in redis.conf,\nthe Cluster bus port 20000 will be opened.\nNode-to-node communication happens exclusively using the Cluster bus and\nthe Cluster bus protocol: a binary protocol composed of frames\nof different types and sizes. The Cluster bus binary protocol is not\npublicly documented since it is not intended for external software devices\nto talk with Redis Cluster nodes using this protocol. However you can\nobtain more details about the Cluster bus protocol by reading the\n`cluster.h` and `cluster.c` files in the Redis Cluster source code.\nCluster topology\nRedis Cluster is a full mesh where every node is connected with every other node using a TCP connection.\nIn a cluster of N nodes, every node has N-1 outgoing TCP connections, and N-1 incoming connections.\nThese TCP connections are kept alive all the time and are not created on demand.\nWhen a node expects a pong reply in response to a ping in the cluster bus, before waiting long enough to mark the node as unreachable, it will try to\nrefresh the connection with the node by reconnecting from scratch.\nWhile Redis Cluster nodes form a full mesh, nodes use a gossip protocol and\na configuration update mechanism in order to avoid exchanging too many\nmessages between nodes during normal conditions, so the number of messages\nexchanged is not exponential.\nNode handshake\nNodes always accept connections on the cluster bus port, and even reply to\npings when received, even if the pinging node is not trusted.\nHowever, all other packets will be discarded by the receiving node if the\nsending node is not considered part of the cluster.\nA node will accept another node as part of the cluster only in two ways:\n\n\nIf a node presents itself with a `MEET` message (`CLUSTER MEET` command). A meet message is exactly\nlike a `PING` message, but forces the receiver to accept the node as part of\nthe cluster. Nodes will send `MEET` messages to other nodes only if the system administrator requests this via the following command:\nCLUSTER MEET ip port\n\n\nA node will also register another node as part of the cluster if a node that is already trusted will gossip about this other node. So if A knows B, and B knows C, eventually B will send gossip messages to A about C. When this happens, A will register C as part of the network, and will try to connect with C.\n\n\nThis means that as long as we join nodes in any connected graph, they'll eventually form a fully connected graph automatically. This means that the cluster is able to auto-discover other nodes, but only if there is a trusted relationship that was forced by the system administrator.\nThis mechanism makes the cluster more robust but prevents different Redis clusters from accidentally mixing after change of IP addresses or other network related events.\nRedirection and resharding\nMOVED Redirection\nA Redis client is free to send queries to every node in the cluster, including\nreplica nodes. The node will analyze the query, and if it is acceptable\n(that is, only a single key is mentioned in the query, or the multiple keys\nmentioned are all to the same hash slot) it will lookup what\nnode is responsible for the hash slot where the key or keys belong.\nIf the hash slot is served by the node, the query is simply processed, otherwise\nthe node will check its internal hash slot to node map, and will reply\nto the client with a MOVED error, like in the following example:\n\n\n```GET x\n-MOVED 3999 127.0.0.1:6381\n```\n\n\nThe error includes the hash slot of the key (3999) and the endpoint:port of the instance that can serve the query.\nThe client needs to reissue the query to the specified node's endpoint address and port. \nThe endpoint can be either an IP address, a hostname, or it can be empty (e.g. `-MOVED 3999 :6380`). \nAn empty endpoint indicates that the server node has an unknown endpoint, and the client should send the next request to the same endpoint as the current request but with the provided port. \nNote that even if the client waits a long time before reissuing the query,\nand in the meantime the cluster configuration changed, the destination node\nwill reply again with a MOVED error if the hash slot 3999 is now served by\nanother node. The same happens if the contacted node had no updated information.\nSo while from the point of view of the cluster nodes are identified by\nIDs we try to simplify our interface with the client just exposing a map\nbetween hash slots and Redis nodes identified by endpoint:port pairs.\nThe client is not required to, but should try to memorize that hash slot\n3999 is served by 127.0.0.1:6381. This way once a new command needs to\nbe issued it can compute the hash slot of the target key and have a\ngreater chance of choosing the right node.\nAn alternative is to just refresh the whole client-side cluster layout\nusing the `CLUSTER SHARDS`, or the deprecated `CLUSTER SLOTS`, command\nwhen a MOVED redirection is received. When a redirection is encountered, it\nis likely multiple slots were reconfigured rather than just one, so updating\nthe client configuration as soon as possible is often the best strategy.\nNote that when the Cluster is stable (no ongoing changes in the configuration),\neventually all the clients will obtain a map of hash slots -> nodes, making\nthe cluster efficient, with clients directly addressing the right nodes\nwithout redirections, proxies or other single point of failure entities.\nA client must be also able to handle -ASK redirections that are described\nlater in this document, otherwise it is not a complete Redis Cluster client.\nLive reconfiguration\nRedis Cluster supports the ability to add and remove nodes while the cluster\nis running. Adding or removing a node is abstracted into the same\noperation: moving a hash slot from one node to another. This means\nthat the same basic mechanism can be used in order to rebalance the cluster, add\nor remove nodes, and so forth.\n\nTo add a new node to the cluster an empty node is added to the cluster and some set of hash slots are moved from existing nodes to the new node.\nTo remove a node from the cluster the hash slots assigned to that node are moved to other existing nodes.\nTo rebalance the cluster a given set of hash slots are moved between nodes.\n\nThe core of the implementation is the ability to move hash slots around.\nFrom a practical point of view a hash slot is just a set of keys, so\nwhat Redis Cluster really does during resharding is to move keys from\nan instance to another instance. Moving a hash slot means moving all the keys\nthat happen to hash into this hash slot.\nTo understand how this works we need to show the `CLUSTER` subcommands\nthat are used to manipulate the slots translation table in a Redis Cluster node.\nThe following subcommands are available (among others not useful in this case):\n\n`CLUSTER ADDSLOTS` slot1 [slot2] ... [slotN]\n`CLUSTER DELSLOTS` slot1 [slot2] ... [slotN]\n`CLUSTER ADDSLOTSRANGE` start-slot1 end-slot1 [start-slot2 end-slot2] ... [start-slotN end-slotN]\n`CLUSTER DELSLOTSRANGE` start-slot1 end-slot1 [start-slot2 end-slot2] ... [start-slotN end-slotN]\n`CLUSTER SETSLOT` slot NODE node\n`CLUSTER SETSLOT` slot MIGRATING node\n`CLUSTER SETSLOT` slot IMPORTING node\n\nThe first four commands, `ADDSLOTS`, `DELSLOTS`, `ADDSLOTSRANGE` and `DELSLOTSRANGE`, are simply used to assign\n(or remove) slots to a Redis node. Assigning a slot means to tell a given\nmaster node that it will be in charge of storing and serving content for\nthe specified hash slot.\nAfter the hash slots are assigned they will propagate across the cluster\nusing the gossip protocol, as specified later in the\nconfiguration propagation section.\nThe `ADDSLOTS` and `ADDSLOTSRANGE` commands are usually used when a new cluster is created\nfrom scratch to assign each master node a subset of all the 16384 hash\nslots available.\nThe `DELSLOTS`  and `DELSLOTSRANGE` are mainly used for manual modification of a cluster configuration\nor for debugging tasks: in practice it is rarely used.\nThe `SETSLOT` subcommand is used to assign a slot to a specific node ID if\nthe `SETSLOT <slot> NODE` form is used. Otherwise the slot can be set in the\ntwo special states `MIGRATING` and `IMPORTING`. Those two special states\nare used in order to migrate a hash slot from one node to another.\n\nWhen a slot is set as MIGRATING, the node will accept all queries that\nare about this hash slot, but only if the key in question\nexists, otherwise the query is forwarded using a `-ASK` redirection to the\nnode that is target of the migration.\nWhen a slot is set as IMPORTING, the node will accept all queries that\nare about this hash slot, but only if the request is\npreceded by an `ASKING` command. If the `ASKING` command was not given\nby the client, the query is redirected to the real hash slot owner via\na `-MOVED` redirection error, as would happen normally.\n\nLet's make this clearer with an example of hash slot migration.\nAssume that we have two Redis master nodes, called A and B.\nWe want to move hash slot 8 from A to B, so we issue commands like this:\n\nWe send B: CLUSTER SETSLOT 8 IMPORTING A\nWe send A: CLUSTER SETSLOT 8 MIGRATING B\n\nAll the other nodes will continue to point clients to node \"A\" every time\nthey are queried with a key that belongs to hash slot 8, so what happens\nis that:\n\nAll queries about existing keys are processed by \"A\".\nAll queries about non-existing keys in A are processed by \"B\", because \"A\" will redirect clients to \"B\".\n\nThis way we no longer create new keys in \"A\".\nIn the meantime, `redis-cli` used during reshardings\nand Redis Cluster configuration will migrate existing keys in\nhash slot 8 from A to B.\nThis is performed using the following command:\n\n\n```CLUSTER GETKEYSINSLOT slot count\n```\n\n\nThe above command will return `count` keys in the specified hash slot.\nFor keys returned, `redis-cli` sends node \"A\" a `MIGRATE` command, that\nwill migrate the specified keys from A to B in an atomic way (both instances\nare locked for the time (usually very small time) needed to migrate keys so\nthere are no race conditions). This is how `MIGRATE` works:\n\n\n```MIGRATE target_host target_port \"\" target_database id timeout KEYS key1 key2 ...\n```\n\n\n`MIGRATE` will connect to the target instance, send a serialized version of\nthe key, and once an OK code is received, the old key from its own dataset\nwill be deleted. From the point of view of an external client a key exists\neither in A or B at any given time.\nIn Redis Cluster there is no need to specify a database other than 0, but\n`MIGRATE` is a general command that can be used for other tasks not\ninvolving Redis Cluster.\n`MIGRATE` is optimized to be as fast as possible even when moving complex\nkeys such as long lists, but in Redis Cluster reconfiguring the\ncluster where big keys are present is not considered a wise procedure if\nthere are latency constraints in the application using the database.\nWhen the migration process is finally finished, the `SETSLOT <slot> NODE <node-id>` command is sent to the two nodes involved in the migration in order to\nset the slots to their normal state again. The same command is usually\nsent to all other nodes to avoid waiting for the natural\npropagation of the new configuration across the cluster.\nASK redirection\nIn the previous section, we briefly talked about ASK redirection. Why can't\nwe simply use MOVED redirection? Because while MOVED means that\nwe think the hash slot is permanently served by a different node and the\nnext queries should be tried against the specified node. ASK means to\nsend only the next query to the specified node.\nThis is needed because the next query about hash slot 8 can be about a\nkey that is still in A, so we always want the client to try A and\nthen B if needed. Since this happens only for one hash slot out of 16384\navailable, the performance hit on the cluster is acceptable.\nWe need to force that client behavior, so to make sure\nthat clients will only try node B after A was tried, node B will only\naccept queries of a slot that is set as IMPORTING if the client sends the\nASKING command before sending the query.\nBasically the ASKING command sets a one-time flag on the client that forces\na node to serve a query about an IMPORTING slot.\nThe full semantics of ASK redirection from the point of view of the client is as follows:\n\nIf ASK redirection is received, send only the query that was redirected to the specified node but continue sending subsequent queries to the old node.\nStart the redirected query with the ASKING command.\nDon't yet update local client tables to map hash slot 8 to B.\n\nOnce hash slot 8 migration is completed, A will send a MOVED message and\nthe client may permanently map hash slot 8 to the new endpoint and port pair.\nNote that if a buggy client performs the map earlier this is not\na problem since it will not send the ASKING command before issuing the query,\nso B will redirect the client to A using a MOVED redirection error.\nSlots migration is explained in similar terms but with different wording\n(for the sake of redundancy in the documentation) in the `CLUSTER SETSLOT`\ncommand documentation.\nClient connections and redirection handling\nTo be efficient, Redis Cluster clients maintain a map of the current slot\nconfiguration. However, this configuration is not required to be up to date.\nWhen contacting the wrong node results in a redirection, the client\ncan update its internal slot map accordingly.\nClients usually need to fetch a complete list of slots and mapped node\naddresses in two different situations:\n\nAt startup, to populate the initial slots configuration\nWhen the client receives a `MOVED` redirection\n\nNote that a client may handle the `MOVED` redirection by updating just the\nmoved slot in its table; however this is usually not efficient because often\nthe configuration of multiple slots will be modified at once. For example, if a\nreplica is promoted to master, all of the slots served by the old master will\nbe remapped). It is much simpler to react to a `MOVED` redirection by\nfetching the full map of slots to nodes from scratch.\nClient can issue a `CLUSTER SLOTS` command to retrieve an array of slot\nranges and the associated master and replica nodes serving the specified ranges.\nThe following is an example of output of `CLUSTER SLOTS`:\n`127.0.0.1:7000> cluster slots\n1) 1) (integer) 5461\n   2) (integer) 10922\n   3) 1) \"127.0.0.1\"\n      2) (integer) 7001\n   4) 1) \"127.0.0.1\"\n      2) (integer) 7004\n2) 1) (integer) 0\n   2) (integer) 5460\n   3) 1) \"127.0.0.1\"\n      2) (integer) 7000\n   4) 1) \"127.0.0.1\"\n      2) (integer) 7003\n3) 1) (integer) 10923\n   2) (integer) 16383\n   3) 1) \"127.0.0.1\"\n      2) (integer) 7002\n   4) 1) \"127.0.0.1\"\n      2) (integer) 7005`\nThe first two sub-elements of every element of the returned array are the\nstart and end slots of the range. The additional elements represent address-port\npairs. The first address-port pair is the master serving the slot, and the\nadditional address-port pairs are the replicas serving the same slot. Replicas\nwill be listed only when not in an error condition (i.e., when their FAIL flag is not set).\nThe first element in the output above says that slots from 5461 to 10922\n(start and end included) are served by 127.0.0.1:7001, and it is possible\nto scale read-only load contacting the replica at 127.0.0.1:7004.\n`CLUSTER SLOTS` is not guaranteed to return ranges that cover the full\n16384 slots if the cluster is misconfigured, so clients should initialize the\nslots configuration map filling the target nodes with NULL objects, and\nreport an error if the user tries to execute commands about keys\nthat belong to unassigned slots.\nBefore returning an error to the caller when a slot is found to\nbe unassigned, the client should try to fetch the slots configuration\nagain to check if the cluster is now configured properly.\nMulti-keys operations\nUsing hash tags, clients are free to use multi-key operations.\nFor example the following operation is valid:\n\n\n```MSET {user:1000}.name Angela {user:1000}.surname White\n```\n\n\nMulti-key operations may become unavailable when a resharding of the\nhash slot the keys belong to is in progress.\nMore specifically, even during a resharding the multi-key operations targeting\nkeys that all exist and all still hash to the same slot (either the source or\ndestination node) are still available.\nOperations on keys that don't exist or are - during the resharding - split\nbetween the source and destination nodes, will generate a `-TRYAGAIN` error.\nThe client can try the operation after some time, or report back the error.\nAs soon as migration of the specified hash slot has terminated, all\nmulti-key operations are available again for that hash slot.\nScaling reads using replica nodes\nNormally replica nodes will redirect clients to the authoritative master for\nthe hash slot involved in a given command, however clients can use replicas\nin order to scale reads using the `READONLY` command.\n`READONLY` tells a Redis Cluster replica node that the client is ok reading\npossibly stale data and is not interested in running write queries.\nWhen the connection is in readonly mode, the cluster will send a redirection\nto the client only if the operation involves keys not served\nby the replica's master node. This may happen because:\n\nThe client sent a command about hash slots never served by the master of this replica.\nThe cluster was reconfigured (for example resharded) and the replica is no longer able to serve commands for a given hash slot.\n\nWhen this happens the client should update its hash slot map as explained in\nthe previous sections.\nThe readonly state of the connection can be cleared using the `READWRITE` command.\nFault Tolerance\nHeartbeat and gossip messages\nRedis Cluster nodes continuously exchange ping and pong packets. Those two kinds of packets have the same structure, and both carry important configuration information. The only actual difference is the message type field. We'll refer to the sum of ping and pong packets as heartbeat packets.\nUsually nodes send ping packets that will trigger the receivers to reply with pong packets. However this is not necessarily true. It is possible for nodes to just send pong packets to send information to other nodes about their configuration, without triggering a reply. This is useful, for example, in order to broadcast a new configuration as soon as possible.\nUsually a node will ping a few random nodes every second so that the total number of ping packets sent (and pong packets received) by each node is a constant amount regardless of the number of nodes in the cluster.\nHowever every node makes sure to ping every other node that hasn't sent a ping or received a pong for longer than half the `NODE_TIMEOUT` time. Before `NODE_TIMEOUT` has elapsed, nodes also try to reconnect the TCP link with another node to make sure nodes are not believed to be unreachable only because there is a problem in the current TCP connection.\nThe number of messages globally exchanged can be sizable if `NODE_TIMEOUT` is set to a small figure and the number of nodes (N) is very large, since every node will try to ping every other node for which they don't have fresh information every half the `NODE_TIMEOUT` time.\nFor example in a 100 node cluster with a node timeout set to 60 seconds, every node will try to send 99 pings every 30 seconds, with a total amount of pings of 3.3 per second. Multiplied by 100 nodes, this is 330 pings per second in the total cluster.\nThere are ways to lower the number of messages, however there have been no\nreported issues with the bandwidth currently used by Redis Cluster failure\ndetection, so for now the obvious and direct design is used. Note that even\nin the above example, the 330 packets per second exchanged are evenly\ndivided among 100 different nodes, so the traffic each node receives\nis acceptable.\nHeartbeat packet content\nPing and pong packets contain a header that is common to all types of packets (for instance packets to request a failover vote), and a special gossip section that is specific to Ping and Pong packets.\nThe common header has the following information:\n\nNode ID, a 160 bit pseudorandom string that is assigned the first time a node is created and remains the same for all the life of a Redis Cluster node.\nThe `currentEpoch` and `configEpoch` fields of the sending node that are used to mount the distributed algorithms used by Redis Cluster (this is explained in detail in the next sections). If the node is a replica the `configEpoch` is the last known `configEpoch` of its master.\nThe node flags, indicating if the node is a replica, a master, and other single-bit node information.\nA bitmap of the hash slots served by the sending node, or if the node is a replica, a bitmap of the slots served by its master.\nThe sender TCP base port that is the port used by Redis to accept client commands.\nThe cluster port that is the port used by Redis for node-to-node communication.\nThe state of the cluster from the point of view of the sender (down or ok).\nThe master node ID of the sending node, if it is a replica.\n\nPing and pong packets also contain a gossip section. This section offers to the receiver a view of what the sender node thinks about other nodes in the cluster. The gossip section only contains information about a few random nodes among the set of nodes known to the sender. The number of nodes mentioned in a gossip section is proportional to the cluster size.\nFor every node added in the gossip section the following fields are reported:\n\nNode ID.\nIP and port of the node.\nNode flags.\n\nGossip sections allow receiving nodes to get information about the state of other nodes from the point of view of the sender. This is useful both for failure detection and to discover other nodes in the cluster.\nFailure detection\nRedis Cluster failure detection is used to recognize when a master or replica node is no longer reachable by the majority of nodes and then respond by promoting a replica to the role of master. When replica promotion is not possible the cluster is put in an error state to stop receiving queries from clients.\nAs already mentioned, every node takes a list of flags associated with other known nodes. There are two flags that are used for failure detection that are called `PFAIL` and `FAIL`. `PFAIL` means Possible failure, and is a non-acknowledged failure type. `FAIL` means that a node is failing and that this condition was confirmed by a majority of masters within a fixed amount of time.\nPFAIL flag:\nA node flags another node with the `PFAIL` flag when the node is not reachable for more than `NODE_TIMEOUT` time. Both master and replica nodes can flag another node as `PFAIL`, regardless of its type.\nThe concept of non-reachability for a Redis Cluster node is that we have an active ping (a ping that we sent for which we have yet to get a reply) pending for longer than `NODE_TIMEOUT`. For this mechanism to work the `NODE_TIMEOUT` must be large compared to the network round trip time. In order to add reliability during normal operations, nodes will try to reconnect with other nodes in the cluster as soon as half of the `NODE_TIMEOUT` has elapsed without a reply to a ping. This mechanism ensures that connections are kept alive so broken connections usually won't result in false failure reports between nodes.\nFAIL flag:\nThe `PFAIL` flag alone is just local information every node has about other nodes, but it is not sufficient to trigger a replica promotion. For a node to be considered down the `PFAIL` condition needs to be escalated to a `FAIL` condition.\nAs outlined in the node heartbeats section of this document, every node sends gossip messages to every other node including the state of a few random known nodes. Every node eventually receives a set of node flags for every other node. This way every node has a mechanism to signal other nodes about failure conditions they have detected.\nA `PFAIL` condition is escalated to a `FAIL` condition when the following set of conditions are met:\n\nSome node, that we'll call A, has another node B flagged as `PFAIL`.\nNode A collected, via gossip sections, information about the state of B from the point of view of the majority of masters in the cluster.\nThe majority of masters signaled the `PFAIL` or `FAIL` condition within `NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT` time. (The validity factor is set to 2 in the current implementation, so this is just two times the `NODE_TIMEOUT` time).\n\nIf all the above conditions are true, Node A will:\n\nMark the node as `FAIL`.\nSend a `FAIL` message (as opposed to a `FAIL` condition within a heartbeat message) to all the reachable nodes.\n\nThe `FAIL` message will force every receiving node to mark the node in `FAIL` state, whether or not it already flagged the node in `PFAIL` state.\nNote that the FAIL flag is mostly one way. That is, a node can go from `PFAIL` to `FAIL`, but a `FAIL` flag can only be cleared in the following situations:\n\nThe node is already reachable and is a replica. In this case the `FAIL` flag can be cleared as replicas are not failed over.\nThe node is already reachable and is a master not serving any slot. In this case the `FAIL` flag can be cleared as masters without slots do not really participate in the cluster and are waiting to be configured in order to join the cluster.\nThe node is already reachable and is a master, but a long time (N times the `NODE_TIMEOUT`) has elapsed without any detectable replica promotion. It's better for it to rejoin the cluster and continue in this case.\n\nIt is useful to note that while the `PFAIL` -> `FAIL` transition uses a form of agreement, the agreement used is weak:\n\nNodes collect views of other nodes over some time period, so even if the majority of master nodes need to \"agree\", actually this is just state that we collected from different nodes at different times and we are not sure, nor we require, that at a given moment the majority of masters agreed. However we discard failure reports which are old, so the failure was signaled by the majority of masters within a window of time.\nWhile every node detecting the `FAIL` condition will force that condition on other nodes in the cluster using the `FAIL` message, there is no way to ensure the message will reach all the nodes. For instance a node may detect the `FAIL` condition and because of a partition will not be able to reach any other node.\n\nHowever the Redis Cluster failure detection has a liveness requirement: eventually all the nodes should agree about the state of a given node. There are two cases that can originate from split brain conditions. Either some minority of nodes believe the node is in `FAIL` state, or a minority of nodes believe the node is not in `FAIL` state. In both the cases eventually the cluster will have a single view of the state of a given node:\nCase 1: If a majority of masters have flagged a node as `FAIL`, because of failure detection and the chain effect it generates, every other node will eventually flag the master as `FAIL`, since in the specified window of time enough failures will be reported.\nCase 2: When only a minority of masters have flagged a node as `FAIL`, the replica promotion will not happen (as it uses a more formal algorithm that makes sure everybody knows about the promotion eventually) and every node will clear the `FAIL` state as per the `FAIL` state clearing rules above (i.e. no promotion after N times the `NODE_TIMEOUT` has elapsed).\nThe `FAIL` flag is only used as a trigger to run the safe part of the algorithm for the replica promotion. In theory a replica may act independently and start a replica promotion when its master is not reachable, and wait for the masters to refuse to provide the acknowledgment if the master is actually reachable by the majority. However the added complexity of the `PFAIL -> FAIL` state, the weak agreement, and the `FAIL` message forcing the propagation of the state in the shortest amount of time in the reachable part of the cluster, have practical advantages. Because of these mechanisms, usually all the nodes will stop accepting writes at about the same time if the cluster is in an error state. This is a desirable feature from the point of view of applications using Redis Cluster. Also erroneous election attempts initiated by replicas that can't reach its master due to local problems (the master is otherwise reachable by the majority of other master nodes) are avoided.\nConfiguration handling, propagation, and failovers\nCluster current epoch\nRedis Cluster uses a concept similar to the Raft algorithm \"term\". In Redis Cluster the term is called epoch instead, and it is used in order to give incremental versioning to events. When multiple nodes provide conflicting information, it becomes possible for another node to understand which state is the most up to date.\nThe `currentEpoch` is a 64 bit unsigned number.\nAt node creation every Redis Cluster node, both replicas and master nodes, set the `currentEpoch` to 0.\nEvery time a packet is received from another node, if the epoch of the sender (part of the cluster bus messages header) is greater than the local node epoch, the `currentEpoch` is updated to the sender epoch.\nBecause of these semantics, eventually all the nodes will agree to the greatest `currentEpoch` in the cluster.\nThis information is used when the state of the cluster is changed and a node seeks agreement in order to perform some action.\nCurrently this happens only during replica promotion, as described in the next section. Basically the epoch is a logical clock for the cluster and dictates that given information wins over one with a smaller epoch.\nConfiguration epoch\nEvery master always advertises its `configEpoch` in ping and pong packets along with a bitmap advertising the set of slots it serves.\nThe `configEpoch` is set to zero in masters when a new node is created.\nA new `configEpoch` is created during replica election. replicas trying to replace\nfailing masters increment their epoch and try to get authorization from\na majority of masters. When a replica is authorized, a new unique `configEpoch`\nis created and the replica turns into a master using the new `configEpoch`.\nAs explained in the next sections the `configEpoch` helps to resolve conflicts when different nodes claim divergent configurations (a condition that may happen because of network partitions and node failures).\nreplica nodes also advertise the `configEpoch` field in ping and pong packets, but in the case of replicas the field represents the `configEpoch` of its master as of the last time they exchanged packets. This allows other instances to detect when a replica has an old configuration that needs to be updated (master nodes will not grant votes to replicas with an old configuration).\nEvery time the `configEpoch` changes for some known node, it is permanently stored in the nodes.conf file by all the nodes that receive this information. The same also happens for the `currentEpoch` value. These two variables are guaranteed to be saved and `fsync-ed` to disk when updated before a node continues its operations.\nThe `configEpoch` values generated using a simple algorithm during failovers\nare guaranteed to be new, incremental, and unique.\nReplica election and promotion\nReplica election and promotion is handled by replica nodes, with the help of master nodes that vote for the replica to promote.\nA replica election happens when a master is in `FAIL` state from the point of view of at least one of its replicas that has the prerequisites in order to become a master.\nIn order for a replica to promote itself to master, it needs to start an election and win it. All the replicas for a given master can start an election if the master is in `FAIL` state, however only one replica will win the election and promote itself to master.\nA replica starts an election when the following conditions are met:\n\nThe replica's master is in `FAIL` state.\nThe master was serving a non-zero number of slots.\nThe replica replication link was disconnected from the master for no longer than a given amount of time, in order to ensure the promoted replica's data is reasonably fresh. This time is user configurable.\n\nIn order to be elected, the first step for a replica is to increment its `currentEpoch` counter, and request votes from master instances.\nVotes are requested by the replica by broadcasting a `FAILOVER_AUTH_REQUEST` packet to every master node of the cluster. Then it waits for a maximum time of two times the `NODE_TIMEOUT` for replies to arrive (but always for at least 2 seconds).\nOnce a master has voted for a given replica, replying positively with a `FAILOVER_AUTH_ACK`, it can no longer vote for another replica of the same master for a period of `NODE_TIMEOUT * 2`. In this period it will not be able to reply to other authorization requests for the same master. This is not needed to guarantee safety, but useful for preventing multiple replicas from getting elected (even if with a different `configEpoch`) at around the same time, which is usually not wanted.\nA replica discards any `AUTH_ACK` replies with an epoch that is less than the `currentEpoch` at the time the vote request was sent. This ensures it doesn't count votes intended for a previous election.\nOnce the replica receives ACKs from the majority of masters, it wins the election.\nOtherwise if the majority is not reached within the period of two times `NODE_TIMEOUT` (but always at least 2 seconds), the election is aborted and a new one will be tried again after `NODE_TIMEOUT * 4` (and always at least 4 seconds).\nReplica rank\nAs soon as a master is in `FAIL` state, a replica waits a short period of time before trying to get elected. That delay is computed as follows:\n\n\n```DELAY = 500 milliseconds + random delay between 0 and 500 milliseconds +\n        REPLICA_RANK * 1000 milliseconds.\n```\n\n\nThe fixed delay ensures that we wait for the `FAIL` state to propagate across the cluster, otherwise the replica may try to get elected while the masters are still unaware of the `FAIL` state, refusing to grant their vote.\nThe random delay is used to desynchronize replicas so they're unlikely to start an election at the same time.\nThe `REPLICA_RANK` is the rank of this replica regarding the amount of replication data it has processed from the master.\nReplicas exchange messages when the master is failing in order to establish a (best effort) rank:\nthe replica with the most updated replication offset is at rank 0, the second most updated at rank 1, and so forth.\nIn this way the most updated replicas try to get elected before others.\nRank order is not strictly enforced; if a replica of higher rank fails to be\nelected, the others will try shortly.\nOnce a replica wins the election, it obtains a new unique and incremental `configEpoch` which is higher than that of any other existing master. It starts advertising itself as master in ping and pong packets, providing the set of served slots with a `configEpoch` that will win over the past ones.\nIn order to speedup the reconfiguration of other nodes, a pong packet is broadcast to all the nodes of the cluster. Currently unreachable nodes will eventually be reconfigured when they receive a ping or pong packet from another node or will receive an `UPDATE` packet from another node if the information it publishes via heartbeat packets are detected to be out of date.\nThe other nodes will detect that there is a new master serving the same slots served by the old master but with a greater `configEpoch`, and will upgrade their configuration. Replicas of the old master (or the failed over master if it rejoins the cluster) will not just upgrade the configuration but will also reconfigure to replicate from the new master. How nodes rejoining the cluster are configured is explained in the next sections.\nMasters reply to replica vote request\nIn the previous section, we discussed how replicas try to get elected. This section explains what happens from the point of view of a master that is requested to vote for a given replica.\nMasters receive requests for votes in form of `FAILOVER_AUTH_REQUEST` requests from replicas.\nFor a vote to be granted the following conditions need to be met:\n\nA master only votes a single time for a given epoch, and refuses to vote for older epochs: every master has a lastVoteEpoch field and will refuse to vote again as long as the `currentEpoch` in the auth request packet is not greater than the lastVoteEpoch. When a master replies positively to a vote request, the lastVoteEpoch is updated accordingly, and safely stored on disk.\nA master votes for a replica only if the replica's master is flagged as `FAIL`.\nAuth requests with a `currentEpoch` that is less than the master `currentEpoch` are ignored. Because of this the master reply will always have the same `currentEpoch` as the auth request. If the same replica asks again to be voted, incrementing the `currentEpoch`, it is guaranteed that an old delayed reply from the master can not be accepted for the new vote.\n\nExample of the issue caused by not using rule number 3:\nMaster `currentEpoch` is 5, lastVoteEpoch is 1 (this may happen after a few failed elections)\n\nReplica `currentEpoch` is 3.\nReplica tries to be elected with epoch 4 (3+1), master replies with an ok with `currentEpoch` 5, however the reply is delayed.\n\nReplica will try to be elected again, at a later time, with epoch 5 (4+1), the delayed reply reaches the replica with `currentEpoch` 5, and is accepted as valid.\n\n\nMasters don't vote for a replica of the same master before `NODE_TIMEOUT * 2` has elapsed if a replica of that master was already voted for. This is not strictly required as it is not possible for two replicas to win the election in the same epoch. However, in practical terms it ensures that when a replica is elected it has plenty of time to inform the other replicas and avoid the possibility that another replica will win a new election, performing an unnecessary second failover.\n\nMasters make no effort to select the best replica in any way. If the replica's master is in `FAIL` state and the master did not vote in the current term, a positive vote is granted. The best replica is the most likely to start an election and win it before the other replicas, since it will usually be able to start the voting process earlier because of its higher rank as explained in the previous section.\nWhen a master refuses to vote for a given replica there is no negative response, the request is simply ignored.\nMasters don't vote for replicas sending a `configEpoch` that is less than any `configEpoch` in the master table for the slots claimed by the replica. Remember that the replica sends the `configEpoch` of its master, and the bitmap of the slots served by its master. This means that the replica requesting the vote must have a configuration for the slots it wants to failover that is newer or equal the one of the master granting the vote.\n\nPractical example of configuration epoch usefulness during partitions\nThis section illustrates how the epoch concept is used to make the replica promotion process more resistant to partitions.\n\nA master is no longer reachable indefinitely. The master has three replicas A, B, C.\nReplica A wins the election and is promoted to master.\nA network partition makes A not available for the majority of the cluster.\nReplica B wins the election and is promoted as master.\nA partition makes B not available for the majority of the cluster.\nThe previous partition is fixed, and A is available again.\n\nAt this point B is down and A is available again with a role of master (actually `UPDATE` messages would reconfigure it promptly, but here we assume all `UPDATE` messages were lost). At the same time, replica C will try to get elected in order to fail over B. This is what happens:\n\nC will try to get elected and will succeed, since for the majority of masters its master is actually down. It will obtain a new incremental `configEpoch`.\nA will not be able to claim to be the master for its hash slots, because the other nodes already have the same hash slots associated with a higher configuration epoch (the one of B) compared to the one published by A.\nSo, all the nodes will upgrade their table to assign the hash slots to C, and the cluster will continue its operations.\n\nAs you'll see in the next sections, a stale node rejoining a cluster\nwill usually get notified as soon as possible about the configuration change\nbecause as soon as it pings any other node, the receiver will detect it\nhas stale information and will send an `UPDATE` message.\nHash slots configuration propagation\nAn important part of Redis Cluster is the mechanism used to propagate the information about which cluster node is serving a given set of hash slots. This is vital to both the startup of a fresh cluster and the ability to upgrade the configuration after a replica was promoted to serve the slots of its failing master.\nThe same mechanism allows nodes partitioned away for an indefinite amount of\ntime to rejoin the cluster in a sensible way.\nThere are two ways hash slot configurations are propagated:\n\nHeartbeat messages. The sender of a ping or pong packet always adds information about the set of hash slots it (or its master, if it is a replica) serves.\n`UPDATE` messages. Since in every heartbeat packet there is information about the sender `configEpoch` and set of hash slots served, if a receiver of a heartbeat packet finds the sender information is stale, it will send a packet with new information, forcing the stale node to update its info.\n\nThe receiver of a heartbeat or `UPDATE` message uses certain simple rules in\norder to update its table mapping hash slots to nodes. When a new Redis Cluster node is created, its local hash slot table is simply initialized to `NULL` entries so that each hash slot is not bound or linked to any node. This looks similar to the following:\n`0 -> NULL\n1 -> NULL\n2 -> NULL\n...\n16383 -> NULL`\nThe first rule followed by a node in order to update its hash slot table is the following:\nRule 1: If a hash slot is unassigned (set to `NULL`), and a known node claims it, I'll modify my hash slot table and associate the claimed hash slots to it.\nSo if we receive a heartbeat from node A claiming to serve hash slots 1 and 2 with a configuration epoch value of 3, the table will be modified to:\n`0 -> NULL\n1 -> A [3]\n2 -> A [3]\n...\n16383 -> NULL`\nWhen a new cluster is created, a system administrator needs to manually assign (using the `CLUSTER ADDSLOTS` command, via the redis-cli command line tool, or by any other means) the slots served by each master node only to the node itself, and the information will rapidly propagate across the cluster.\nHowever this rule is not enough. We know that hash slot mapping can change\nduring two events:\n\nA replica replaces its master during a failover.\nA slot is resharded from a node to a different one.\n\nFor now let's focus on failovers. When a replica fails over its master, it obtains\na configuration epoch which is guaranteed to be greater than the one of its\nmaster (and more generally greater than any other configuration epoch\ngenerated previously). For example node B, which is a replica of A, may failover\nA with configuration epoch of 4. It will start to send heartbeat packets\n(the first time mass-broadcasting cluster-wide) and because of the following\nsecond rule, receivers will update their hash slot tables:\nRule 2: If a hash slot is already assigned, and a known node is advertising it using a `configEpoch` that is greater than the `configEpoch` of the master currently associated with the slot, I'll rebind the hash slot to the new node.\nSo after receiving messages from B that claim to serve hash slots 1 and 2 with configuration epoch of 4, the receivers will update their table in the following way:\n`0 -> NULL\n1 -> B [4]\n2 -> B [4]\n...\n16383 -> NULL`\nLiveness property: because of the second rule, eventually all nodes in the cluster will agree that the owner of a slot is the one with the greatest `configEpoch` among the nodes advertising it.\nThis mechanism in Redis Cluster is called last failover wins.\nThe same happens during resharding. When a node importing a hash slot completes\nthe import operation, its configuration epoch is incremented to make sure the\nchange will be propagated throughout the cluster.\nUPDATE messages, a closer look\nWith the previous section in mind, it is easier to see how update messages\nwork. Node A may rejoin the cluster after some time. It will send heartbeat\npackets where it claims it serves hash slots 1 and 2 with configuration epoch\nof 3. All the receivers with updated information will instead see that\nthe same hash slots are associated with node B having a higher configuration\nepoch. Because of this they'll send an `UPDATE` message to A with the new\nconfiguration for the slots. A will update its configuration because of the\nrule 2 above.\nHow nodes rejoin the cluster\nThe same basic mechanism is used when a node rejoins a cluster.\nContinuing with the example above, node A will be notified\nthat hash slots 1 and 2 are now served by B. Assuming that these two were\nthe only hash slots served by A, the count of hash slots served by A will\ndrop to 0! So A will reconfigure to be a replica of the new master.\nThe actual rule followed is a bit more complex than this. In general it may\nhappen that A rejoins after a lot of time, in the meantime it may happen that\nhash slots originally served by A are served by multiple nodes, for example\nhash slot 1 may be served by B, and hash slot 2 by C.\nSo the actual Redis Cluster node role switch rule is: A master node will change its configuration to replicate (be a replica of) the node that stole its last hash slot.\nDuring reconfiguration, eventually the number of served hash slots will drop to zero, and the node will reconfigure accordingly. Note that in the base case this just means that the old master will be a replica of the replica that replaced it after a failover. However in the general form the rule covers all possible cases.\nReplicas do exactly the same: they reconfigure to replicate the node that\nstole the last hash slot of its former master.\nReplica migration\nRedis Cluster implements a concept called replica migration in order to\nimprove the availability of the system. The idea is that in a cluster with\na master-replica setup, if the map between replicas and masters is fixed\navailability is limited over time if multiple independent failures of single\nnodes happen.\nFor example in a cluster where every master has a single replica, the cluster\ncan continue operations as long as either the master or the replica fail, but not\nif both fail the same time. However there is a class of failures that are\nthe independent failures of single nodes caused by hardware or software issues\nthat can accumulate over time. For example:\n\nMaster A has a single replica A1.\nMaster A fails. A1 is promoted as new master.\nThree hours later A1 fails in an independent manner (unrelated to the failure of A). No other replica is available for promotion since node A is still down. The cluster cannot continue normal operations.\n\nIf the map between masters and replicas is fixed, the only way to make the cluster\nmore resistant to the above scenario is to add replicas to every master, however\nthis is costly as it requires more instances of Redis to be executed, more\nmemory, and so forth.\nAn alternative is to create an asymmetry in the cluster, and let the cluster\nlayout automatically change over time. For example the cluster may have three\nmasters A, B, C. A and B have a single replica each, A1 and B1. However the master\nC is different and has two replicas: C1 and C2.\nReplica migration is the process of automatic reconfiguration of a replica\nin order to migrate to a master that has no longer coverage (no working\nreplicas). With replica migration the scenario mentioned above turns into the\nfollowing:\n\nMaster A fails. A1 is promoted.\nC2 migrates as replica of A1, that is otherwise not backed by any replica.\nThree hours later A1 fails as well.\nC2 is promoted as new master to replace A1.\nThe cluster can continue the operations.\n\nReplica migration algorithm\nThe migration algorithm does not use any form of agreement since the replica\nlayout in a Redis Cluster is not part of the cluster configuration that needs\nto be consistent and/or versioned with config epochs. Instead it uses an\nalgorithm to avoid mass-migration of replicas when a master is not backed.\nThe algorithm guarantees that eventually (once the cluster configuration is\nstable) every master will be backed by at least one replica.\nThis is how the algorithm works. To start we need to define what is a\ngood replica in this context: a good replica is a replica not in `FAIL` state\nfrom the point of view of a given node.\nThe execution of the algorithm is triggered in every replica that detects that\nthere is at least a single master without good replicas. However among all the\nreplicas detecting this condition, only a subset should act. This subset is\nactually often a single replica unless different replicas have in a given moment\na slightly different view of the failure state of other nodes.\nThe acting replica is the replica among the masters with the maximum number\nof attached replicas, that is not in FAIL state and has the smallest node ID.\nSo for example if there are 10 masters with 1 replica each, and 2 masters with\n5 replicas each, the replica that will try to migrate is - among the 2 masters\nhaving 5 replicas - the one with the lowest node ID. Given that no agreement\nis used, it is possible that when the cluster configuration is not stable,\na race condition occurs where multiple replicas believe themselves to be\nthe non-failing replica with the lower node ID (it is unlikely for this to happen\nin practice). If this happens, the result is multiple replicas migrating to the\nsame master, which is harmless. If the race happens in a way that will leave\nthe ceding master without replicas, as soon as the cluster is stable again\nthe algorithm will be re-executed again and will migrate a replica back to\nthe original master.\nEventually every master will be backed by at least one replica. However,\nthe normal behavior is that a single replica migrates from a master with\nmultiple replicas to an orphaned master.\nThe algorithm is controlled by a user-configurable parameter called\n`cluster-migration-barrier`: the number of good replicas a master\nmust be left with before a replica can migrate away. For example, if this\nparameter is set to 2, a replica can try to migrate only if its master remains\nwith two working replicas.\nconfigEpoch conflicts resolution algorithm\nWhen new `configEpoch` values are created via replica promotion during\nfailovers, they are guaranteed to be unique.\nHowever there are two distinct events where new configEpoch values are\ncreated in an unsafe way, just incrementing the local `currentEpoch` of\nthe local node and hoping there are no conflicts at the same time.\nBoth the events are system-administrator triggered:\n\n`CLUSTER FAILOVER` command with `TAKEOVER` option is able to manually promote a replica node into a master without the majority of masters being available. This is useful, for example, in multi data center setups.\nMigration of slots for cluster rebalancing also generates new configuration epochs inside the local node without agreement for performance reasons.\n\nSpecifically, during manual resharding, when a hash slot is migrated from\na node A to a node B, the resharding program will force B to upgrade\nits configuration to an epoch which is the greatest found in the cluster,\nplus 1 (unless the node is already the one with the greatest configuration\nepoch), without requiring agreement from other nodes.\nUsually a real world resharding involves moving several hundred hash slots\n(especially in small clusters). Requiring an agreement to generate new\nconfiguration epochs during resharding, for each hash slot moved, is\ninefficient. Moreover it requires a fsync in each of the cluster nodes\nevery time in order to store the new configuration. Because of the way it is\nperformed instead, we only need a new config epoch when the first hash slot is moved,\nmaking it much more efficient in production environments.\nHowever because of the two cases above, it is possible (though unlikely) to end\nwith multiple nodes having the same configuration epoch. A resharding operation\nperformed by the system administrator, and a failover happening at the same\ntime (plus a lot of bad luck) could cause `currentEpoch` collisions if\nthey are not propagated fast enough.\nMoreover, software bugs and filesystem corruptions can also contribute\nto multiple nodes having the same configuration epoch.\nWhen masters serving different hash slots have the same `configEpoch`, there\nare no issues. It is more important that replicas failing over a master have\nunique configuration epochs.\nThat said, manual interventions or resharding may change the cluster\nconfiguration in different ways. The Redis Cluster main liveness property\nrequires that slot configurations always converge, so under every circumstance\nwe really want all the master nodes to have a different `configEpoch`.\nIn order to enforce this, a conflict resolution algorithm is used in the\nevent that two nodes end up with the same `configEpoch`.\n\nIF a master node detects another master node is advertising itself with\nthe same `configEpoch`.\nAND IF the node has a lexicographically smaller Node ID compared to the other node claiming the same `configEpoch`.\nTHEN it increments its `currentEpoch` by 1, and uses it as the new `configEpoch`.\n\nIf there are any set of nodes with the same `configEpoch`, all the nodes but the one with the greatest Node ID will move forward, guaranteeing that, eventually, every node will pick a unique configEpoch regardless of what happened.\nThis mechanism also guarantees that after a fresh cluster is created, all\nnodes start with a different `configEpoch` (even if this is not actually\nused) since `redis-cli` makes sure to use `CLUSTER SET-CONFIG-EPOCH` at startup.\nHowever if for some reason a node is left misconfigured, it will update\nits configuration to a different configuration epoch automatically.\nNode resets\nNodes can be software reset (without restarting them) in order to be reused\nin a different role or in a different cluster. This is useful in normal\noperations, in testing, and in cloud environments where a given node can\nbe reprovisioned to join a different set of nodes to enlarge or create a new\ncluster.\nIn Redis Cluster nodes are reset using the `CLUSTER RESET` command. The\ncommand is provided in two variants:\n\n`CLUSTER RESET SOFT`\n`CLUSTER RESET HARD`\n\nThe command must be sent directly to the node to reset. If no reset type is\nprovided, a soft reset is performed.\nThe following is a list of operations performed by a reset:\n\nSoft and hard reset: If the node is a replica, it is turned into a master, and its dataset is discarded. If the node is a master and contains keys the reset operation is aborted.\nSoft and hard reset: All the slots are released, and the manual failover state is reset.\nSoft and hard reset: All the other nodes in the nodes table are removed, so the node no longer knows any other node.\nHard reset only: `currentEpoch`, `configEpoch`, and `lastVoteEpoch` are set to 0.\nHard reset only: the Node ID is changed to a new random ID.\n\nMaster nodes with non-empty data sets can't be reset (since normally you want to reshard data to the other nodes). However, under special conditions when this is appropriate (e.g. when a cluster is totally destroyed with the intent of creating a new one), `FLUSHALL` must be executed before proceeding with the reset.\nRemoving nodes from a cluster\nIt is possible to practically remove a node from an existing cluster by\nresharding all its data to other nodes (if it is a master node) and\nshutting it down. However, the other nodes will still remember its node\nID and address, and will attempt to connect with it.\nFor this reason, when a node is removed we want to also remove its entry\nfrom all the other nodes tables. This is accomplished by using the\n`CLUSTER FORGET <node-id>` command.\nThe command does two things:\n\nIt removes the node with the specified node ID from the nodes table.\nIt sets a 60 second ban which prevents a node with the same node ID from being re-added.\n\nThe second operation is needed because Redis Cluster uses gossip in order to auto-discover nodes, so removing the node X from node A, could result in node B gossiping about node X to A again. Because of the 60 second ban, the Redis Cluster administration tools have 60 seconds in order to remove the node from all the nodes, preventing the re-addition of the node due to auto discovery.\nFurther information is available in the `CLUSTER FORGET` documentation.\nPublish/Subscribe\nIn a Redis Cluster, clients can subscribe to every node, and can also\npublish to every other node. The cluster will make sure that published\nmessages are forwarded as needed.\nThe clients can send SUBSCRIBE to any node and can also send PUBLISH to any node. \nIt will simply broadcast each published message to all other nodes.\nRedis 7.0 and later features sharded pub/sub, in which shard channels are assigned to slots by the same algorithm used to assign keys to slots. \nA shard message must be sent to a node that owns the slot the shard channel is hashed to. \nThe cluster makes sure the published shard messages are forwarded to all nodes in the shard, so clients can subscribe to a shard channel by connecting to either the master responsible for the slot, or to any of its replicas.\nAppendix\nAppendix A: CRC16 reference implementation in ANSI C\n\n\n```/*\n * Copyright 2001-2010 Georges Menie (www.menie.org)\n * Copyright 2010 Salvatore Sanfilippo (adapted to Redis coding style)\n * All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n *     * Redistributions of source code must retain the above copyright\n *       notice, this list of conditions and the following disclaimer.\n *     * Redistributions in binary form must reproduce the above copyright\n *       notice, this list of conditions and the following disclaimer in the\n *       documentation and/or other materials provided with the distribution.\n *     * Neither the name of the University of California, Berkeley nor the\n *       names of its contributors may be used to endorse or promote products\n *       derived from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND ANY\n * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY\n * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n/* CRC16 implementation according to CCITT standards.\n *\n * Note by @antirez: this is actually the XMODEM CRC 16 algorithm, using the\n * following parameters:\n *\n * Name                       : \"XMODEM\", also known as \"ZMODEM\", \"CRC-16/ACORN\"\n * Width                      : 16 bit\n * Poly                       : 1021 (That is actually x^16 + x^12 + x^5 + 1)\n * Initialization             : 0000\n * Reflect Input byte         : False\n * Reflect Output CRC         : False\n * Xor constant to output CRC : 0000\n * Output for \"123456789\"     : 31C3\n */\n\nstatic const uint16_t crc16tab[256]= {\n    0x0000,0x1021,0x2042,0x3063,0x4084,0x50a5,0x60c6,0x70e7,\n    0x8108,0x9129,0xa14a,0xb16b,0xc18c,0xd1ad,0xe1ce,0xf1ef,\n    0x1231,0x0210,0x3273,0x2252,0x52b5,0x4294,0x72f7,0x62d6,\n    0x9339,0x8318,0xb37b,0xa35a,0xd3bd,0xc39c,0xf3ff,0xe3de,\n    0x2462,0x3443,0x0420,0x1401,0x64e6,0x74c7,0x44a4,0x5485,\n    0xa56a,0xb54b,0x8528,0x9509,0xe5ee,0xf5cf,0xc5ac,0xd58d,\n    0x3653,0x2672,0x1611,0x0630,0x76d7,0x66f6,0x5695,0x46b4,\n    0xb75b,0xa77a,0x9719,0x8738,0xf7df,0xe7fe,0xd79d,0xc7bc,\n    0x48c4,0x58e5,0x6886,0x78a7,0x0840,0x1861,0x2802,0x3823,\n    0xc9cc,0xd9ed,0xe98e,0xf9af,0x8948,0x9969,0xa90a,0xb92b,\n    0x5af5,0x4ad4,0x7ab7,0x6a96,0x1a71,0x0a50,0x3a33,0x2a12,\n    0xdbfd,0xcbdc,0xfbbf,0xeb9e,0x9b79,0x8b58,0xbb3b,0xab1a,\n    0x6ca6,0x7c87,0x4ce4,0x5cc5,0x2c22,0x3c03,0x0c60,0x1c41,\n    0xedae,0xfd8f,0xcdec,0xddcd,0xad2a,0xbd0b,0x8d68,0x9d49,\n    0x7e97,0x6eb6,0x5ed5,0x4ef4,0x3e13,0x2e32,0x1e51,0x0e70,\n    0xff9f,0xefbe,0xdfdd,0xcffc,0xbf1b,0xaf3a,0x9f59,0x8f78,\n    0x9188,0x81a9,0xb1ca,0xa1eb,0xd10c,0xc12d,0xf14e,0xe16f,\n    0x1080,0x00a1,0x30c2,0x20e3,0x5004,0x4025,0x7046,0x6067,\n    0x83b9,0x9398,0xa3fb,0xb3da,0xc33d,0xd31c,0xe37f,0xf35e,\n    0x02b1,0x1290,0x22f3,0x32d2,0x4235,0x5214,0x6277,0x7256,\n    0xb5ea,0xa5cb,0x95a8,0x8589,0xf56e,0xe54f,0xd52c,0xc50d,\n    0x34e2,0x24c3,0x14a0,0x0481,0x7466,0x6447,0x5424,0x4405,\n    0xa7db,0xb7fa,0x8799,0x97b8,0xe75f,0xf77e,0xc71d,0xd73c,\n    0x26d3,0x36f2,0x0691,0x16b0,0x6657,0x7676,0x4615,0x5634,\n    0xd94c,0xc96d,0xf90e,0xe92f,0x99c8,0x89e9,0xb98a,0xa9ab,\n    0x5844,0x4865,0x7806,0x6827,0x18c0,0x08e1,0x3882,0x28a3,\n    0xcb7d,0xdb5c,0xeb3f,0xfb1e,0x8bf9,0x9bd8,0xabbb,0xbb9a,\n    0x4a75,0x5a54,0x6a37,0x7a16,0x0af1,0x1ad0,0x2ab3,0x3a92,\n    0xfd2e,0xed0f,0xdd6c,0xcd4d,0xbdaa,0xad8b,0x9de8,0x8dc9,\n    0x7c26,0x6c07,0x5c64,0x4c45,0x3ca2,0x2c83,0x1ce0,0x0cc1,\n    0xef1f,0xff3e,0xcf5d,0xdf7c,0xaf9b,0xbfba,0x8fd9,0x9ff8,\n    0x6e17,0x7e36,0x4e55,0x5e74,0x2e93,0x3eb2,0x0ed1,0x1ef0\n};\n\nuint16_t crc16(const char *buf, int len) {\n    int counter;\n    uint16_t crc = 0;\n    for (counter = 0; counter < len; counter++)\n            crc = (crc<<8) ^ crc16tab[((crc>>8) ^ *buf++)&0x00FF];\n    return crc;\n```\n\n",
    "tag": "redis"
  },
  {
    "title": "begin_search",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/key-specs.md",
    "content": "\ntitle: \"Command key specifications\"\n linkTitle: \"Command key specifications\"\n weight: 3\n description: What are command key specification and how to use them in your client\n aliases:\n   - /topics/key-specs\n\nMany of the commands in Redis accept key names as input arguments.\nThe 9th element in the reply of `COMMAND` (and `COMMAND INFO`) is an array that consists of the command's key specifications.\nA key specification describes a rule for extracting the names of one or more keys from the arguments of a given command.\nKey specifications provide a robust and flexible mechanism, compared to the first key, last key and step scheme employed until Redis 7.0.\nBefore introducing these specifications, Redis clients had no trivial programmatic means to extract key names for all commands.\nCluster-aware Redis clients had to have the keys' extraction logic hard-coded in the cases of commands such as `EVAL` and `ZUNIONSTORE` that rely on a numkeys argument or `SORT` and its many clauses.\nAlternatively, the `COMMAND GETKEYS` can be used to achieve a similar extraction effect but at a higher latency.\nA Redis client isn't obligated to support key specifications.\nIt can continue using the legacy first key, last key and step scheme along with the movablekeys flag that remain unchanged.\nHowever, a Redis client that implements key specifications support can consolidate most of its keys' extraction logic.\nEven if the client encounters an unfamiliar type of key specification, it can always revert to the `COMMAND GETKEYS` command.\nThat said, most cluster-aware clients only require a single key name to perform correct command routing, so it is possible that although a command features one unfamiliar specification, its other specification may still be usable by the client.\nKey specifications are maps with three keys:\n\nbegin_search:: the starting index for keys' extraction.\nfind_keys: the rule for identifying the keys relative to the BS.\nnotes: notes about this key spec, if there are any.\nflags: indicate the type of data access.\n\nbegin_search\nThe begin_search value of a specification informs the client of the extraction's beginning.\nThe value is a map.\nThere are three types of `begin_search`:\n\nindex: key name arguments begin at a constant index.\nkeyword: key names start after a specific keyword (token).\nunknown: an unknown type of specification - see the incomplete flag section for more details.\n\nindex\nThe index type of `begin_search` indicates that input keys appear at a constant index.\nIt is a map under the spec key with a single key:\n\nindex: the 0-based index from which the client should start extracting key names.\n\nkeyword\nThe keyword type of `begin_search` means a literal token precedes key name arguments.\nIt is a map under the spec with two keys:\n\nkeyword: the keyword (token) that marks the beginning of key name arguments.\nstartfrom: an index to the arguments array from which the client should begin searching. \n  This can be a negative value, which means the search should start from the end of the arguments' array, in reverse order.\n  For example, -2's meaning is to search reverse from the penultimate argument.\n\nMore examples of the keyword search type include:\n\n`SET` has a `begin_search` specification of type index with a value of 1.\n`XREAD` has a `begin_search` specification of type keyword with the values \"STREAMS\" and 1 as keyword and startfrom, respectively.\n`MIGRATE` has a start_search specification of type keyword with the values of \"KEYS\" and -2.\n\nfind_keys\nThe `find_keys` value of a key specification tells the client how to continue the search for key names.\n`find_keys` has three possible types:\n\nrange: keys stop at a specific index or relative to the last argument.\nkeynum: an additional argument specifies the number of input keys.\nunknown: an unknown type of specification - see the incomplete flag section for more details.\n\nrange\nThe range type of `find_keys` is a map under the spec key with three keys:\n\nlastkey: the index, relative to `begin_search`, of the last key argument.\n  This can be a negative value, in which case it isn't relative.\n  For example, -1 indicates to keep extracting keys until the last argument, -2 until one before the last, and so on.\nkeystep: the number of arguments that should be skipped, after finding a key, to find the next one.\nlimit: if lastkey is has the value of -1, we use the limit to stop the search by a factor.\n  0 and 1 mean no limit.\n  2 means half of the remaining arguments, 3 means a third, and so on.\n\nkeynum\nThe keynum type of `find_keys` is a map under the spec key with three keys:\n\nkeynumidx: the index, relative to `begin_search`, of the argument containing the number of keys.\nfirstkey: the index, relative to `begin_search`, of the first key.\n  This is usually the next argument after keynumidx, and its value, in this case, is greater by one.\nkeystep: Tthe number of arguments that should be skipped, after finding a key, to find the next one.\n\nExamples:\n\nThe `SET` command has a range of 0, 1 and 0.\nThe `MSET` command has a range of -1, 2 and 0.\nThe `XREAD` command has a range of -1, 1 and 2.\nThe `ZUNION` command has a start_search type index with the value 1, and `find_keys` of type keynum with values of 0, 1 and 1.\nThe AI.DAGRUN command has a start_search of type keyword with values of \"LOAD\" and 1, and `find_keys` of type keynum with values of 0, 1 and 1.\n\nNote:\nthis isn't a perfect solution as the module writers can come up with anything.\nHowever, this mechanism should allow the extraction of key name arguments for the vast majority of commands.\nnotes\nNotes about non-obvious key specs considerations, if applicable.\nflags\nA key specification can have additional flags that provide more details about the key.\nThese flags are divided into three groups, as described below.\nAccess type flags\nThe following flags declare the type of access the command uses to a key's value or its metadata.\nA key's metadata includes LRU/LFU counters, type, and cardinality.\nThese flags do not relate to the reply sent back to the client.\nEvery key specification has precisely one of the following flags:\n\nRW: the read-write flag.\n  The command modifies the data stored in the value of the key or its metadata.\n  This flag marks every operation that isn't distinctly a delete, an overwrite, or read-only.\nRO: the read-only flag.\n  The command only reads the value of the key (although it doesn't necessarily return it).\nOW: the overwrite flag.\n  The command overwrites the data stored in the value of the key.\nRM: the remove flag.\n  The command deletes the key.\n\nLogical operation flags\nThe following flags declare the type of operations performed on the data stored as the key's value and its TTL (if any), not the metadata.\nThese flags describe the logical operation that the command executes on data, driven by the input arguments.\nThe flags do not relate to modifying or returning metadata (such as a key's type, cardinality, or existence).\nEvery key specification may include the following flag:\n\naccess: the access flag.\n  This flag indicates that the command returns, copies, or somehow uses the user's data that's stored in the key.\n\nIn addition, the specification may include precisely one of the following:\n\nupdate: the update flag.\n  The command updates the data stored in the key's value.\n  The new value may depend on the old value.\n  This flag marks every operation that isn't distinctly an insert or a delete.\ninsert: the insert flag.\n  The command only adds data to the value; existing data isn't modified or deleted.\ndelete: the delete flag.\n  The command explicitly deletes data from the value stored at the key.\n\nMiscellaneous flags\nKey specifications may have the following flags:\n\nnot_key: this flag indicates that the specified argument isn't a key.\n  This argument is treated the same as a key when computing which slot a command should be assigned to for Redis cluster. \n  For all other purposes this argument should not be considered a key.\nincomplete: this flag is explained below.\nvariable_flags: this flag is explained below.\n\nincomplete\nSome commands feature exotic approaches when it comes to specifying their keys, which makes extraction difficult.\nConsider, for example, what would happen with a call to `MIGRATE` that includes the literal string \"KEYS\" as an argument to its AUTH clause.\nOur key specifications would miss the mark, and extraction would begin at the wrong index.\nThus, we recognize that key specifications are incomplete and may fail to extract all keys.\nHowever, we assure that even incomplete specifications never yield the wrong names of keys, providing that the command is syntactically correct.\nIn the case of `MIGRATE`, the search begins at the end (startfrom has the value of -1).\nIf and when we encounter a key named \"KEYS\", we'll only extract the subset of the key name arguments after it.\nThat's why `MIGRATE` has the incomplete flag in its key specification.\nAnother case of incompleteness is the `SORT` command.\nHere, the `begin_search` and `find_keys` are of type unknown.\nThe client should revert to calling the `COMMAND GETKEYS` command to extract key names from the arguments, short of implementing it natively.\nThe difficulty arises, for example, because the string \"STORE\" is both a keyword (token) and a valid literal argument for `SORT`.\nNote:\nthe only commands with incomplete key specifications are `SORT` and `MIGRATE`.\nWe don't expect the addition of such commands in the future.\nvariable_flags\nIn some commands, the flags for the same key name argument can depend on other arguments.\nFor example, consider the `SET` command and its optional  GET argument.\nWithout the GET argument, `SET` is write-only, but it becomes a read and write command with it.\nWhen this flag is present, it means that the key specification flags cover all possible options, but the effective flags depend on other arguments.\nExamples\n`SET`'s key specifications\n`1) 1) \"flags\"\n     2) 1) RW\n        2) access\n        3) update\n     3) \"begin_search\"\n     4) 1) \"type\"\n        2) \"index\"\n        3) \"spec\"\n        4) 1) \"index\"\n           2) (integer) 1\n     5) \"find_keys\"\n     6) 1) \"type\"\n        2) \"range\"\n        3) \"spec\"\n        4) 1) \"lastkey\"\n           2) (integer) 0\n           3) \"keystep\"\n           4) (integer) 1\n           5) \"limit\"\n           6) (integer) 0`\n`ZUNION`'s key specifications\n```\n  1) 1) \"flags\"\n     2) 1) RO\n        2) access\n     3) \"begin_search\"\n     4) 1) \"type\"\n        2) \"index\"\n        3) \"spec\"\n        4) 1) \"index\"\n           2) (integer) 1\n     5) \"find_keys\"\n     6) 1) \"type\"\n        2) \"keynum\"\n        3) \"spec\"\n        4) 1) \"keynumidx\"\n           2) (integer) 0\n           3) \"firstkey\"\n           4) (integer) 1\n           5) \"keystep\"\n           6) (integer) 1",
    "tag": "redis"
  },
  {
    "title": "Network layer",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/protocol-spec.md",
    "content": "\ntitle: \"RESP protocol spec\"\nlinkTitle: \"Protocol spec\"\nweight: 4\ndescription: Redis serialization protocol (RESP) specification\naliases:\n    - /topics/protocol\n\nRedis clients use a protocol called RESP (REdis Serialization Protocol) to communicate with the Redis server. While the protocol was designed specifically for Redis, it can be used for other client-server software projects.\nRESP is a compromise between the following things:\n\nSimple to implement.\nFast to parse.\nHuman readable.\n\nRESP can serialize different data types like integers, strings, and arrays. There is also a specific type for errors. Requests are sent from the client to the Redis server as arrays of strings that represent the arguments of the command to execute. Redis replies with a command-specific data type.\nRESP is binary-safe and does not require processing of bulk data transferred from one process to another because it uses prefixed-length to transfer bulk data.\nNote: the protocol outlined here is only used for client-server communication. Redis Cluster uses a different binary protocol in order to exchange messages between nodes.\nNetwork layer\nA client connects to a Redis server by creating a TCP connection to the port 6379.\nWhile RESP is technically non-TCP specific, the protocol is only used with TCP connections (or equivalent stream-oriented connections like Unix sockets) in the context of Redis.\nRequest-Response model\nRedis accepts commands composed of different arguments.\nOnce a command is received, it is processed and a reply is sent back to the client.\nThis is the simplest model possible; however, there are two exceptions:\n\nRedis supports pipelining (covered later in this document). So it is possible for clients to send multiple commands at once and wait for replies later.\nWhen a Redis client subscribes to a Pub/Sub channel, the protocol changes semantics and becomes a push protocol. The client no longer requires sending commands because the server will automatically send new messages to the client (for the channels the client is subscribed to) as soon as they are received.\n\nExcluding these two exceptions, the Redis protocol is a simple request-response protocol.\nRESP protocol description\nThe RESP protocol was introduced in Redis 1.2, but it became the\nstandard way for talking with the Redis server in Redis 2.0.\nThis is the protocol you should implement in your Redis client.\nRESP is actually a serialization protocol that supports the following\ndata types: Simple Strings, Errors, Integers, Bulk Strings, and Arrays.\nRedis uses RESP as a request-response protocol in the\nfollowing way:\n\nClients send commands to a Redis server as a RESP Array of Bulk Strings.\nThe server replies with one of the RESP types according to the command implementation.\n\nIn RESP, the first byte determines the data type:\n\nFor Simple Strings, the first byte of the reply is \"+\"\nFor Errors, the first byte of the reply is \"-\"\nFor Integers, the first byte of the reply is \":\"\nFor Bulk Strings, the first byte of the reply is \"$\"\nFor Arrays, the first byte of the reply is \"`*`\"\n\nRESP can represent a Null value using a special variation of Bulk Strings or Array as specified later.\nIn RESP, different parts of the protocol are always terminated with \"\\r\\n\" (CRLF).\n\nRESP Simple Strings\nSimple Strings are encoded as follows: a plus character, followed by a string that cannot contain a CR or LF character (no newlines are allowed), and terminated by CRLF (that is \"\\r\\n\").\nSimple Strings are used to transmit non binary-safe strings with minimal overhead. For example, many Redis commands reply with just \"OK\" on success. The RESP Simple String is encoded with the following 5 bytes:\n\n\n```\"+OK\\r\\n\"\n```\n\n\nIn order to send binary-safe strings, use RESP Bulk Strings instead.\nWhen Redis replies with a Simple String, a client library should respond with a string composed of the first character after the '+'\nup to the end of the string, excluding the final CRLF bytes.\n\nRESP Errors\nRESP has a specific data type for errors. They are similar to\nRESP Simple Strings, but the first character is a minus '-' character instead\nof a plus. The real difference between Simple Strings and Errors in RESP is that clients treat errors\nas exceptions, and the string that composes\nthe Error type is the error message itself.\nThe basic format is:\n\n\n```\"-Error message\\r\\n\"\n```\n\n\nError replies are only sent when something goes wrong, for instance if\nyou try to perform an operation against the wrong data type, or if the command\ndoes not exist. The client should raise an exception when it receives an Error reply.\nThe following are examples of error replies:\n\n\n```-ERR unknown command 'helloworld'\n-WRONGTYPE Operation against a key holding the wrong kind of value\n```\n\n\nThe first word after the \"-\", up to the first space or newline, represents\nthe kind of error returned. This is just a convention used by Redis and is not\npart of the RESP Error format.\nFor example, `ERR` is the generic error, while `WRONGTYPE` is a more specific\nerror that implies that the client tried to perform an operation against the\nwrong data type. This is called an Error Prefix and is a way to allow\nthe client to understand the kind of error returned by the server without checking the exact error message.\nA client implementation may return different types of exceptions for different\nerrors or provide a generic way to trap errors by directly providing\nthe error name to the caller as a string.\nHowever, such a feature should not be considered vital as it is rarely useful, and a limited client implementation may simply return a generic error condition, such as `false`.\n\nRESP Integers\nThis type is just a CRLF-terminated string that represents an integer,\nprefixed by a \":\" byte. For example, \":0\\r\\n\" and \":1000\\r\\n\" are integer replies.\nMany Redis commands return RESP Integers, like `INCR`, `LLEN`, and `LASTSAVE`.\nThere is no special meaning for the returned integer. It is just an\nincremental number for `INCR`, a UNIX time for `LASTSAVE`, and so forth. However,\nthe returned integer is guaranteed to be in the range of a signed 64-bit integer.\nInteger replies are also used in order to return true or false.\nFor instance, commands like `EXISTS` or `SISMEMBER` will return 1 for true\nand 0 for false.\nOther commands like `SADD`, `SREM`, and `SETNX` will return 1 if the operation\nwas actually performed and 0 otherwise.\nThe following commands will reply with an integer: `SETNX`, `DEL`,\n`EXISTS`, `INCR`, `INCRBY`, `DECR`, `DECRBY`, `DBSIZE`, `LASTSAVE`,\n`RENAMENX`, `MOVE`, `LLEN`, `SADD`, `SREM`, `SISMEMBER`, `SCARD`.\n\n\nRESP Bulk Strings\nBulk Strings are used in order to represent a single binary-safe\nstring up to 512 MB in length.\nBulk Strings are encoded in the following way:\n\nA \"$\" byte followed by the number of bytes composing the string (a prefixed length), terminated by CRLF.\nThe actual string data.\nA final CRLF.\n\nSo the string \"hello\" is encoded as follows:\n\n\n```\"$5\\r\\nhello\\r\\n\"\n```\n\n\nAn empty string is encoded as:\n\n\n```\"$0\\r\\n\\r\\n\"\n```\n\n\nRESP Bulk Strings can also be used in order to signal non-existence of a value\nusing a special format to represent a Null value. In this\nformat, the length is -1, and there is no data. Null is represented as:\n\n\n```\"$-1\\r\\n\"\n```\n\n\nThis is called a Null Bulk String.\nThe client library API should not return an empty string, but a nil object,\nwhen the server replies with a Null Bulk String.\nFor example, a Ruby library should return 'nil' while a C library should\nreturn NULL (or set a special flag in the reply object).\n\nRESP Arrays\nClients send commands to the Redis server using RESP Arrays. Similarly,\ncertain Redis commands, that return collections of elements to the client,\nuse RESP Arrays as their replies. An example is the `LRANGE` command that\nreturns elements of a list.\nRESP Arrays are sent using the following format:\n\nA `*` character as the first byte, followed by the number of elements in the array as a decimal number, followed by CRLF.\nAn additional RESP type for every element of the Array.\n\nSo an empty Array is just the following:\n\n\n```\"*0\\r\\n\"\n```\n\n\nWhile an array of two RESP Bulk Strings \"hello\" and \"world\" is encoded as:\n\n\n```\"*2\\r\\n$5\\r\\nhello\\r\\n$5\\r\\nworld\\r\\n\"\n```\n\n\nAs you can see after the `*<count>CRLF` part prefixing the array, the other\ndata types composing the array are just concatenated one after the other.\nFor example, an Array of three integers is encoded as follows:\n\n\n```\"*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\"\n```\n\n\nArrays can contain mixed types, so it's not necessary for the\nelements to be of the same type. For instance, a list of four\nintegers and a bulk string can be encoded as follows:\n\n\n```*5\\r\\n\n:1\\r\\n\n:2\\r\\n\n:3\\r\\n\n:4\\r\\n\n$5\\r\\n\nhello\\r\\n\n```\n\n\n(The reply was split into multiple lines for clarity).\nThe first line the server sent is `*5\\r\\n` in order to specify that five\nreplies will follow. Then every reply constituting the items of the\nMulti Bulk reply are transmitted.\nNull Arrays exist as well and are an alternative way to\nspecify a Null value (usually the Null Bulk String is used, but for historical\nreasons we have two formats).\nFor instance, when the `BLPOP` command times out, it returns a Null Array\nthat has a count of `-1` as in the following example:\n\n\n```\"*-1\\r\\n\"\n```\n\n\nA client library API should return a null object and not an empty Array when\nRedis replies with a Null Array. This is necessary to distinguish\nbetween an empty list and a different condition (for instance the timeout\ncondition of the `BLPOP` command).\nNested arrays are possible in RESP. For example a nested array of two arrays\nis encoded as follows:\n\n\n```*2\\r\\n\n*3\\r\\n\n:1\\r\\n\n:2\\r\\n\n:3\\r\\n\n*2\\r\\n\n+Hello\\r\\n\n-World\\r\\n\n```\n\n\n(The format was split into multiple lines to make it easier to read).\nThe above RESP data type encodes a two-element Array consisting of an Array that contains three Integers (1, 2, 3) and an array of a Simple String and an Error.\nNull elements in Arrays\nSingle elements of an Array may be Null. This is used in Redis replies to signal that these elements are missing and not empty strings. This\ncan happen with the SORT command when used with the GET pattern option\nif the specified key is missing. Example of an Array reply containing a\nNull element:\n\n\n```*3\\r\\n\n$5\\r\\n\nhello\\r\\n\n$-1\\r\\n\n$5\\r\\n\nworld\\r\\n\n```\n\n\nThe second element is a Null. The client library should return something\nlike this:\n\n\n```[\"hello\",nil,\"world\"]\n```\n\n\nNote that this is not an exception to what was said in the previous sections, but \nan example to further specify the protocol.\nSend commands to a Redis server\nNow that you are familiar with the RESP serialization format, you can use it to help write a Redis client library. We can further specify\nhow the interaction between the client and the server works:\n\nA client sends the Redis server a RESP Array consisting of only Bulk Strings.\nA Redis server replies to clients, sending any valid RESP data type as a reply.\n\nSo for example a typical interaction could be the following.\nThe client sends the command LLEN mylist in order to get the length of the list stored at key mylist. Then the server replies with an Integer reply as in the following example (C: is the client, S: the server).\n\n\n```C: *2\\r\\n\nC: $4\\r\\n\nC: LLEN\\r\\n\nC: $6\\r\\n\nC: mylist\\r\\n\n\nS: :48293\\r\\n\n```\n\n\nAs usual, we separate different parts of the protocol with newlines for simplicity, but the actual interaction is the client sending `*2\\r\\n$4\\r\\nLLEN\\r\\n$6\\r\\nmylist\\r\\n` as a whole.\nMultiple commands and pipelining\nA client can use the same connection in order to issue multiple commands.\nPipelining is supported so multiple commands can be sent with a single\nwrite operation by the client, without the need to read the server reply\nof the previous command before issuing the next one.\nAll the replies can be read at the end.\nFor more information, see Pipelining.\nInline commands\nSometimes you may need to send a command\nto the Redis server but only have `telnet` available. While the Redis protocol is simple to implement, it is\nnot ideal to use in interactive sessions, and `redis-cli` may not always be\navailable. For this reason, Redis also accepts commands in the inline command format.\nThe following is an example of a server/client chat using an inline command\n(the server chat starts with S:, the client chat with C:)\n\n\n```C: PING\nS: +PONG\n```\n\n\nThe following is an example of an inline command that returns an integer:\n\n\n```C: EXISTS somekey\nS: :0\n```\n\n\nBasically, you write space-separated arguments in a telnet session.\nSince no command starts with `*` that is instead used in the unified request\nprotocol, Redis is able to detect this condition and parse your command.\nHigh performance parser for the Redis protocol\nWhile the Redis protocol is human readable and easy to implement, it can\nbe implemented with a performance similar to that of a binary protocol.\nRESP uses prefixed lengths to transfer bulk data, so there is\nnever a need to scan the payload for special characters, like with JSON, nor to quote the payload that needs to be sent to the\nserver.\nThe Bulk and Multi Bulk lengths can be processed with code that performs\na single operation per character while at the same time scanning for the\nCR character, like the following C code:\n```\ninclude \nint main(void) {\n    unsigned char *p = \"$123\\r\\n\";\n    int len = 0;\n\n\n```p++;\nwhile(*p != '\\r') {\n    len = (len*10)+(*p - '0');\n    p++;\n}\n\n/* Now p points at '\\r', and the len is in bulk_len. */\nprintf(\"%d\\n\", len);\nreturn 0;\n```\n\n\n}\n```\nAfter the first CR is identified, it can be skipped along with the following\nLF without any processing. Then the bulk data can be read using a single\nread operation that does not inspect the payload in any way. Finally,\nthe remaining CR and LF characters are discarded without any processing.\nWhile comparable in performance to a binary protocol, the Redis protocol is\nsignificantly simpler to implement in most high-level languages,",
    "tag": "redis"
  },
  {
    "title": "Example",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/command-arguments.md",
    "content": "\ntitle: \"Redis command arguments\"\nlinkTitle: \"Command arguments\"\nweight: 7\ndescription: How Redis commands expose their documentation programmatically\naliases:\n    - /topics/command-arguments\n\nThe `COMMAND DOCS` command returns documentation-focused information about available Redis commands.\nThe map reply that the command returns includes the arguments key.\nThis key stores an array that describes the command's arguments.\nEvery element in the arguments array is a map with the following fields:\n\nname: the argument's name, always present.\n  The name of an argument is given for identification purposes alone.\n  It isn't displayed during the command's syntax rendering.\n  The same name can appear more than once in the entire argument tree, but it is unique compared to other sibling arguments' names.\n  This allows obtaining a unique identifier for each argument (the concatenation of all names in the path from the root to any argument).\ndisplay_text: the argument's display string, present in arguments that have a displayable representation (all arguments that aren't oneof/block).\n  This is the string used in the command's syntax rendering.\ntype: the argument's type, always present.\n  An argument must have one of the following types:\nstring: a string argument.\ninteger: an integer argument.\ndouble: a double-precision argument.\nkey: a string that represents the name of a key.\npattern: a string that represents a glob-like pattern.\nunix-time: an integer that represents a Unix timestamp.\npure-token: an argument is a token, meaning a reserved keyword, which may or may not be provided. \n    Not to be confused with free-text user input.\noneof: the argument is a container for nested arguments.\n    This type enables choice among several nested arguments (see the `XADD` example below).\nblock: the argument is a container for nested arguments.\n    This type enables grouping arguments and applying a property (such as optional) to all (see the `XADD` example below).\nkey_spec_index: this value is available for every argument of the key type.\n  It is a 0-based index of the specification in the command's key specifications that corresponds to the argument.\ntoken: a constant literal that precedes the argument (user input) itself.\nsummary: a short description of the argument.\nsince: the debut Redis version of the argument (or for module commands, the module version).\ndeprecated_since: the Redis version that deprecated the command (or for module commands, the module version).\nflags: an array of argument flags.\n  Possible flags are:\noptional: denotes that the argument is optional (for example, the GET clause of the  `SET` command).\nmultiple: denotes that the argument may be repeated (such as the key argument of `DEL`).\nmultiple-token: denotes the possible repetition of the argument with its preceding token (see `SORT`'s `GET pattern` clause).\nvalue: the argument's value.\n  For arguments types other than oneof and block, this is a string that describes the value in the command's syntax.\n  For the oneof and block types, this is an array of nested arguments, each being a map as described in this section.\n\nExample\nThe trimming clause of `XADD`, i.e., `[MAXLEN|MINID [=|~] threshold [LIMIT count]]`, is represented at the top-level as block-typed argument.\nIt consists of four nested arguments:\n\ntrimming strategy: this nested argument has an oneof type with two nested arguments.\n  Each of the nested arguments, MAXLEN and MINID, is typed as pure-token.\ntrimming operator: this nested argument is an optional oneof type with two nested arguments.\n  Each of the nested arguments, = and ~, is a pure-token.\nthreshold: this nested argument is a string.\ncount: this nested argument is an optional integer with a token (LIMIT).\n\nHere's `XADD`'s arguments array:\n```\n1) 1) \"name\"\n   2) \"key\"\n   3) \"type\"\n   4) \"key\"\n   5) \"value\"\n   6) \"key\"\n2)  1) \"name\"\n    2) \"nomkstream\"\n    3) \"type\"\n    4) \"pure-token\"\n    5) \"token\"\n    6) \"NOMKSTREAM\"\n    7) \"since\"\n    8) \"6.2\"\n    9) \"flags\"\n   10) 1) optional\n3) 1) \"name\"\n   2) \"trim\"\n   3) \"type\"\n   4) \"block\"\n   5) \"flags\"\n   6) 1) optional\n   7) \"value\"\n   8) 1) 1) \"name\"\n         2) \"strategy\"\n         3) \"type\"\n         4) \"oneof\"\n         5) \"value\"\n         6) 1) 1) \"name\"\n               2) \"maxlen\"\n               3) \"type\"\n               4) \"pure-token\"\n               5) \"token\"\n               6) \"MAXLEN\"\n            2) 1) \"name\"\n               2) \"minid\"\n               3) \"type\"\n               4) \"pure-token\"\n               5) \"token\"\n               6) \"MINID\"\n               7) \"since\"\n               8) \"6.2\"\n      2) 1) \"name\"\n         2) \"operator\"\n         3) \"type\"\n         4) \"oneof\"\n         5) \"flags\"\n         6) 1) optional\n         7) \"value\"\n         8) 1) 1) \"name\"\n               2) \"equal\"\n               3) \"type\"\n               4) \"pure-token\"\n               5) \"token\"\n               6) \"=\"\n            2) 1) \"name\"\n               2) \"approximately\"\n               3) \"type\"\n               4) \"pure-token\"\n               5) \"token\"\n               6) \"~\"\n      3) 1) \"name\"\n         2) \"threshold\"\n         3) \"type\"\n         4) \"string\"\n         5) \"value\"\n         6) \"threshold\"\n      4)  1) \"name\"\n          2) \"count\"\n          3) \"type\"\n          4) \"integer\"\n          5) \"token\"\n          6) \"LIMIT\"\n          7) \"since\"\n          8) \"6.2\"\n          9) \"flags\"\n         10) 1) optional\n         11) \"value\"\n         12) \"count\"\n4) 1) \"name\"\n   2) \"id_or_auto\"\n   3) \"type\"\n   4) \"oneof\"\n   5) \"value\"\n   6) 1) 1) \"name\"\n         2) \"auto_id\"\n         3) \"type\"\n         4) \"pure-token\"\n         5) \"token\"\n         6) \"*\"\n      2) 1) \"name\"\n         2) \"id\"\n         3) \"type\"\n         4) \"string\"\n         5) \"value\"\n         6) \"id\"\n5) 1) \"name\"\n   2) \"field_value\"\n   3) \"type\"\n   4) \"block\"\n   5) \"flags\"\n   6) 1) multiple\n   7) \"value\"\n   8) 1) 1) \"name\"\n         2) \"field\"\n         3) \"type\"\n         4) \"string\"\n         5) \"value\"\n         6) \"field\"\n      2) 1) \"name\"\n         2) \"value\"\n         3) \"type\"\n         4) \"string\"\n         5) \"value\"\n         6) \"value\"",
    "tag": "redis"
  },
  {
    "title": "internals-sds.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/internals/internals-sds.md",
    "content": "\ntitle: \"String internals\"\nlinkTitle: \"String internals\"\nweight: 1\ndescription: Guide to the original implementation of Redis strings\naliases:\n  - /topics/internals-sds\n\nNote: this document was written by the creator of Redis, Salvatore Sanfilippo, early in the development of Redis (c. 2010). Virtual Memory has been deprecated since Redis 2.6, so this documentation\nis here only for historical interest.\nThe implementation of Redis strings is contained in `sds.c` (`sds` stands for\nSimple Dynamic Strings). The implementation is available as a standalone library\nat https://github.com/antirez/sds.\nThe C structure `sdshdr` declared in `sds.h` represents a Redis string:\n\n\n```struct sdshdr {\n    long len;\n    long free;\n    char buf[];\n};\n```\n\n\nThe `buf` character array stores the actual string.\nThe `len` field stores the length of `buf`. This makes obtaining the length\nof a Redis string an O(1) operation.\nThe `free` field stores the number of additional bytes available for use.\nTogether the `len` and `free` field can be thought of as holding the metadata of the `buf` character array.\nCreating Redis Strings\nA new data type named `sds` is defined in `sds.h` to be a synonym for a character pointer:\n\n\n```typedef char *sds;\n```\n\n\n`sdsnewlen` function defined in `sds.c` creates a new Redis String:\n\n\n```sds sdsnewlen(const void *init, size_t initlen) {\n    struct sdshdr *sh;\n\n    sh = zmalloc(sizeof(struct sdshdr)+initlen+1);\n#ifdef SDS_ABORT_ON_OOM\n    if (sh == NULL) sdsOomAbort();\n#else\n    if (sh == NULL) return NULL;\n#endif\n    sh->len = initlen;\n    sh->free = 0;\n    if (initlen) {\n        if (init) memcpy(sh->buf, init, initlen);\n        else memset(sh->buf,0,initlen);\n    }\n    sh->buf[initlen] = '\\0';\n    return (char*)sh->buf;\n}\n```\n\n\nRemember a Redis string is a variable of type `struct sdshdr`. But `sdsnewlen` returns a character pointer!!\nThat's a trick and needs some explanation.\nSuppose I create a Redis string using `sdsnewlen` like below:\n\n\n```sdsnewlen(\"redis\", 5);\n```\n\n\nThis creates a new variable of type `struct sdshdr` allocating memory for `len` and `free`\nfields as well as for the `buf` character array.\n\n\n```sh = zmalloc(sizeof(struct sdshdr)+initlen+1); // initlen is length of init argument.\n```\n\n\nAfter `sdsnewlen` successfully creates a Redis string the result is something like:\n\n\n```-----------\n|5|0|redis|\n-----------\n^   ^\nsh  sh->buf\n```\n\n\n`sdsnewlen` returns `sh->buf` to the caller.\nWhat do you do if you need to free the Redis string pointed by `sh`?\nYou want the pointer `sh` but you only have the pointer `sh->buf`.\nCan you get the pointer `sh` from `sh->buf`?\nYes. Pointer arithmetic. Notice from the above ASCII art that if you subtract\nthe size of two longs from `sh->buf` you get the pointer `sh`.\nThe `sizeof` two longs happens to be the size of `struct sdshdr`.\nLook at `sdslen` function and see this trick at work:\n\n\n```size_t sdslen(const sds s) {\n    struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr)));\n    return sh->len;\n}\n```\n\n\nKnowing this trick you could easily go through the rest of the functions in `sds.c`.",
    "tag": "redis"
  },
  {
    "title": "internals-vm.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/internals/internals-vm.md",
    "content": "\ntitle: \"Virtual memory (deprecated)\"\nlinkTitle: \"Virtual memory\"\nweight: 1\ndescription: A description of the Redis virtual memory system that was deprecated in 2.6. This document exists for historical interest.\naliases:\n  - /topics/internals-vm\n  - /topics/virtual-memory\n\nNote: this document was written by the creator of Redis, Salvatore Sanfilippo, early in the development of Redis (c. 2010). Virtual Memory has been deprecated since Redis 2.6, so this documentation\nis here only for historical interest.\nThis document details the internals of the Redis Virtual Memory subsystem prior to Redis 2.6. The intended audience is not the final user but programmers willing to understand or modify the Virtual Memory implementation.\nKeys vs Values: what is swapped out?\nThe goal of the VM subsystem is to free memory transferring Redis Objects from memory to disk. This is a very generic command, but specifically, Redis transfers only objects associated with values. In order to understand better this concept we'll show, using the DEBUG command, how a key holding a value looks from the point of view of the Redis internals:\n\n\n```redis> set foo bar\nOK\nredis> debug object foo\nKey at:0x100101d00 refcount:1, value at:0x100101ce0 refcount:1 encoding:raw serializedlength:4\n```\n\n\nAs you can see from the above output, the Redis top level hash table maps Redis Objects (keys) to other Redis Objects (values). The Virtual Memory is only able to swap values on disk, the objects associated to keys are always taken in memory: this trade off guarantees very good lookup performances, as one of the main design goals of the Redis VM is to have performances similar to Redis with VM disabled when the part of the dataset frequently used fits in RAM.\nHow does a swapped value looks like internally\nWhen an object is swapped out, this is what happens in the hash table entry:\n\nThe key continues to hold a Redis Object representing the key.\nThe value is set to NULL\n\nSo you may wonder where we store the information that a given value (associated to a given key) was swapped out. Just in the key object!\nThis is how the Redis Object structure robj looks like:\n\n\n```/* The actual Redis Object */\ntypedef struct redisObject {\n    void *ptr;\n    unsigned char type;\n    unsigned char encoding;\n    unsigned char storage;  /* If this object is a key, where is the value?\n                             * REDIS_VM_MEMORY, REDIS_VM_SWAPPED, ... */\n    unsigned char vtype; /* If this object is a key, and value is swapped out,\n                          * this is the type of the swapped out object. */\n    int refcount;\n    /* VM fields, this are only allocated if VM is active, otherwise the\n     * object allocation function will just allocate\n     * sizeof(redisObject) minus sizeof(redisObjectVM), so using\n     * Redis without VM active will not have any overhead. */\n    struct redisObjectVM vm;\n} robj;\n```\n\n\nAs you can see there are a few fields about VM. The most important one is storage, that can be one of this values:\n\n`REDIS_VM_MEMORY`: the associated value is in memory.\n`REDIS_VM_SWAPPED`: the associated values is swapped, and the value entry of the hash table is just set to NULL.\n`REDIS_VM_LOADING`: the value is swapped on disk, the entry is NULL, but there is a job to load the object from the swap to the memory (this field is only used when threaded VM is active).\n`REDIS_VM_SWAPPING`: the value is in memory, the entry is a pointer to the actual Redis Object, but there is an I/O job in order to transfer this value to the swap file.\n\nIf an object is swapped on disk (`REDIS_VM_SWAPPED` or `REDIS_VM_LOADING`), how do we know where it is stored, what type it is, and so forth? That's simple: the vtype field is set to the original type of the Redis object swapped, while the vm field (that is a redisObjectVM structure) holds information about the location of the object. This is the definition of this additional structure:\n\n\n```/* The VM object structure */\nstruct redisObjectVM {\n    off_t page;         /* the page at which the object is stored on disk */\n    off_t usedpages;    /* number of pages used on disk */\n    time_t atime;       /* Last access time */\n} vm;\n```\n\n\nAs you can see the structure contains the page at which the object is located in the swap file, the number of pages used, and the last access time of the object (this is very useful for the algorithm that select what object is a good candidate for swapping, as we want to transfer on disk objects that are rarely accessed).\nAs you can see, while all the other fields are using unused bytes in the old Redis Object structure (we had some free bit due to natural memory alignment concerns), the vm field is new, and indeed uses additional memory. Should we pay such a memory cost even when VM is disabled? No! This is the code to create a new Redis Object:\n\n\n```... some code ...\n        if (server.vm_enabled) {\n            pthread_mutex_unlock(&server.obj_freelist_mutex);\n            o = zmalloc(sizeof(*o));\n        } else {\n            o = zmalloc(sizeof(*o)-sizeof(struct redisObjectVM));\n        }\n... some code ...\n```\n\n\nAs you can see if the VM system is not enabled we allocate just `sizeof(*o)-sizeof(struct redisObjectVM)` of memory. Given that the vm field is the last in the object structure, and that this fields are never accessed if VM is disabled, we are safe and Redis without VM does not pay the memory overhead.\nThe Swap File\nThe next step in order to understand how the VM subsystem works is understanding how objects are stored inside the swap file. The good news is that's not some kind of special format, we just use the same format used to store the objects in .rdb files, that are the usual dump files produced by Redis using the `SAVE` command.\nThe swap file is composed of a given number of pages, where every page size is a given number of bytes. This parameters can be changed in redis.conf, since different Redis instances may work better with different values: it depends on the actual data you store inside it. The following are the default values:\n\n\n```vm-page-size 32\nvm-pages 134217728\n```\n\n\nRedis takes a \"bitmap\" (a contiguous array of bits set to zero or one) in memory, every bit represent a page of the swap file on disk: if a given bit is set to 1, it represents a page that is already used (there is some Redis Object stored there), while if the corresponding bit is zero, the page is free.\nTaking this bitmap (that will call the page table) in memory is a huge win in terms of performances, and the memory used is small: we just need 1 bit for every page on disk. For instance in the example below 134217728 pages of 32 bytes each (4GB swap file) is using just 16 MB of RAM for the page table.\nTransferring objects from memory to swap\nIn order to transfer an object from memory to disk we need to perform the following steps (assuming non threaded VM, just a simple blocking approach):\n\nFind how many pages are needed in order to store this object on the swap file. This is trivially accomplished just calling the function `rdbSavedObjectPages` that returns the number of pages used by an object on disk. Note that this function does not duplicate the .rdb saving code just to understand what will be the length after an object will be saved on disk, we use the trick of opening /dev/null and writing the object there, finally calling `ftello` in order check the amount of bytes required. What we do basically is to save the object on a virtual very fast file, that is, /dev/null.\nNow that we know how many pages are required in the swap file, we need to find this number of contiguous free pages inside the swap file. This task is accomplished by the `vmFindContiguousPages` function. As you can guess this function may fail if the swap is full, or so fragmented that we can't easily find the required number of contiguous free pages. When this happens we just abort the swapping of the object, that will continue to live in memory.\nFinally we can write the object on disk, at the specified position, just calling the function `vmWriteObjectOnSwap`.\n\nAs you can guess once the object was correctly written in the swap file, it is freed from memory, the storage field in the associated key is set to `REDIS_VM_SWAPPED`, and the used pages are marked as used in the page table.\nLoading objects back in memory\nLoading an object from swap to memory is simpler, as we already know where the object is located and how many pages it is using. We also know the type of the object (the loading functions are required to know this information, as there is no header or any other information about the object type on disk), but this is stored in the vtype field of the associated key as already seen above.\nCalling the function `vmLoadObject` passing the key object associated to the value object we want to load back is enough. The function will also take care of fixing the storage type of the key (that will be `REDIS_VM_MEMORY`), marking the pages as freed in the page table, and so forth.\nThe return value of the function is the loaded Redis Object itself, that we'll have to set again as value in the main hash table (instead of the NULL value we put in place of the object pointer when the value was originally swapped out).\nHow blocking VM works\nNow we have all the building blocks in order to describe how the blocking VM works. First of all, an important detail about configuration. In order to enable blocking VM in Redis `server.vm_max_threads` must be set to zero.\nWe'll see later how this max number of threads info is used in the threaded VM, for now all it's needed to now is that Redis reverts to fully blocking VM when this is set to zero.\nWe also need to introduce another important VM parameter, that is, `server.vm_max_memory`. This parameter is very important as it is used in order to trigger swapping: Redis will try to swap objects only if it is using more memory than the max memory setting, otherwise there is no need to swap as we are matching the user requested memory usage.\nBlocking VM swapping\nSwapping of object from memory to disk happens in the cron function. This function used to be called every second, while in the recent Redis versions on git it is called every 100 milliseconds (that is, 10 times per second).\nIf this function detects we are out of memory, that is, the memory used is greater than the vm-max-memory setting, it starts transferring objects from memory to disk in a loop calling the function `vmSwapOneObect`. This function takes just one argument, if 0 it will swap objects in a blocking way, otherwise if it is 1, I/O threads are used. In the blocking scenario we just call it with zero as argument.\nvmSwapOneObject acts performing the following steps:\n\nThe key space in inspected in order to find a good candidate for swapping (we'll see later what a good candidate for swapping is).\nThe associated value is transferred to disk, in a blocking way.\nThe key storage field is set to `REDIS_VM_SWAPPED`, while the vm fields of the object are set to the right values (the page index where the object was swapped, and the number of pages used to swap it).\nFinally the value object is freed and the value entry of the hash table is set to NULL.\n\nThe function is called again and again until one of the following happens: there is no way to swap more objects because either the swap file is full or nearly all the objects are already transferred on disk, or simply the memory usage is already under the vm-max-memory parameter.\nWhat values to swap when we are out of memory?\nUnderstanding what's a good candidate for swapping is not too hard. A few objects at random are sampled, and for each their swappability is commuted as:\n\n\n```swappability = age*log(size_in_memory)\n```\n\n\nThe age is the number of seconds the key was not requested, while size_in_memory is a fast estimation of the amount of memory (in bytes) used by the object in memory. So we try to swap out objects that are rarely accessed, and we try to swap bigger objects over smaller one, but the latter is a less important factor (because of the logarithmic function used). This is because we don't want bigger objects to be swapped out and in too often as the bigger the object the more I/O and CPU is required in order to transfer it.\nBlocking VM loading\nWhat happens if an operation against a key associated with a swapped out object is requested? For instance Redis may just happen to process the following command:\n\n\n```GET foo\n```\n\n\nIf the value object of the `foo` key is swapped we need to load it back in memory before processing the operation. In Redis the key lookup process is centralized in the `lookupKeyRead` and `lookupKeyWrite` functions, this two functions are used in the implementation of all the Redis commands accessing the keyspace, so we have a single point in the code where to handle the loading of the key from the swap file to memory.\nSo this is what happens:\n\nThe user calls some command having as argument a swapped key\nThe command implementation calls the lookup function\nThe lookup function search for the key in the top level hash table. If the value associated with the requested key is swapped (we can see that checking the storage field of the key object), we load it back in memory in a blocking way before to return to the user.\n\nThis is pretty straightforward, but things will get more interesting with the threads. From the point of view of the blocking VM the only real problem is the saving of the dataset using another process, that is, handling `BGSAVE` and `BGREWRITEAOF` commands.\nBackground saving when VM is active\nThe default Redis way to persist on disk is to create .rdb files using a child process. Redis calls the fork() system call in order to create a child, that has the exact copy of the in memory dataset, since fork duplicates the whole program memory space (actually thanks to a technique called Copy on Write memory pages are shared between the parent and child process, so the fork() call will not require too much memory).\nIn the child process we have a copy of the dataset in a given point in the time. Other commands issued by clients will just be served by the parent process and will not modify the child data.\nThe child process will just store the whole dataset into the dump.rdb file and finally will exit. But what happens when the VM is active? Values can be swapped out so we don't have all the data in memory, and we need to access the swap file in order to retrieve the swapped values. While child process is saving the swap file is shared between the parent and child process, since:\n\nThe parent process needs to access the swap file in order to load values back into memory if an operation against swapped out values are performed.\nThe child process needs to access the swap file in order to retrieve the full dataset while saving the data set on disk.\n\nIn order to avoid problems while both the processes are accessing the same swap file we do a simple thing, that is, not allowing values to be swapped out in the parent process while a background saving is in progress. This way both the processes will access the swap file in read only. This approach has the problem that while the child process is saving no new values can be transferred on the swap file even if Redis is using more memory than the max memory parameters dictates. This is usually not a problem as the background saving will terminate in a short amount of time and if still needed a percentage of values will be swapped on disk ASAP.\nAn alternative to this scenario is to enable the Append Only File that will have this problem only when a log rewrite is performed using the `BGREWRITEAOF` command.\nThe problem with the blocking VM\nThe problem of blocking VM is that... it's blocking :)\nThis is not a problem when Redis is used in batch processing activities, but for real-time usage one of the good points of Redis is the low latency. The blocking VM will have bad latency behaviors as when a client is accessing a swapped out value, or when Redis needs to swap out values, no other clients will be served in the meantime.\nSwapping out keys should happen in background. Similarly when a client is accessing a swapped out value other clients accessing in memory values should be served mostly as fast as when VM is disabled. Only the clients dealing with swapped out keys should be delayed.\nAll this limitations called for a non-blocking VM implementation.\nThreaded VM\nThere are basically three main ways to turn the blocking VM into a non blocking one.\n* 1: One way is obvious, and in my opinion, not a good idea at all, that is, turning Redis itself into a threaded server: if every request is served by a different thread automatically other clients don't need to wait for blocked ones. Redis is fast, exports atomic operations, has no locks, and is just 10k lines of code, because it is single threaded, so this was not an option for me.\n* 2: Using non-blocking I/O against the swap file. After all you can think Redis already event-loop based, why don't just handle disk I/O in a non-blocking fashion? I also discarded this possibility because of two main reasons. One is that non blocking file operations, unlike sockets, are an incompatibility nightmare. It's not just like calling select, you need to use OS-specific things. The other problem is that the I/O is just one part of the time consumed to handle VM, another big part is the CPU used in order to encode/decode data to/from the swap file. This is I picked option three, that is...\n* 3: Using I/O threads, that is, a pool of threads handling the swap I/O operations. This is what the Redis VM is using, so let's detail how this works.\nI/O Threads\nThe threaded VM design goals where the following, in order of importance:\n\nSimple implementation, little room for race conditions, simple locking, VM system more or less completely decoupled from the rest of Redis code.\nGood performances, no locks for clients accessing values in memory.\nAbility to decode/encode objects in the I/O threads.\n\nThe above goals resulted in an implementation where the Redis main thread (the one serving actual clients) and the I/O threads communicate using a queue of jobs, with a single mutex.\nBasically when main thread requires some work done in the background by some I/O thread, it pushes an I/O job structure in the `server.io_newjobs` queue (that is, just a linked list). If there are no active I/O threads, one is started. At this point some I/O thread will process the I/O job, and the result of the processing is pushed in the `server.io_processed` queue. The I/O thread will send a byte using an UNIX pipe to the main thread in order to signal that a new job was processed and the result is ready to be processed.\nThis is how the `iojob` structure looks like:\n\n\n```typedef struct iojob {\n    int type;   /* Request type, REDIS_IOJOB_* */\n    redisDb *db;/* Redis database */\n    robj *key;  /* This I/O request is about swapping this key */\n    robj *val;  /* the value to swap for REDIS_IOREQ_*_SWAP, otherwise this\n                 * field is populated by the I/O thread for REDIS_IOREQ_LOAD. */\n    off_t page; /* Swap page where to read/write the object */\n    off_t pages; /* Swap pages needed to save object. PREPARE_SWAP return val */\n    int canceled; /* True if this command was canceled by blocking side of VM */\n    pthread_t thread; /* ID of the thread processing this entry */\n} iojob;\n```\n\n\nThere are just three type of jobs that an I/O thread can perform (the type is specified by the `type` field of the structure):\n\n`REDIS_IOJOB_LOAD`: load the value associated to a given key from swap to memory. The object offset inside the swap file is `page`, the object type is `key->vtype`. The result of this operation will populate the `val` field of the structure.\n`REDIS_IOJOB_PREPARE_SWAP`: compute the number of pages needed in order to save the object pointed by `val` into the swap. The result of this operation will populate the `pages` field.\n`REDIS_IOJOB_DO_SWAP`: Transfer the object pointed by `val` to the swap file, at page offset `page`.\n\nThe main thread delegates just the above three tasks. All the rest is handled by the I/O thread itself, for instance finding a suitable range of free pages in the swap file page table (that is a fast operation), deciding what object to swap, altering the storage field of a Redis object to reflect the current state of a value.\nNon blocking VM as probabilistic enhancement of blocking VM\nSo now we have a way to request background jobs dealing with slow VM operations. How to add this to the mix of the rest of the work done by the main thread? While blocking VM was aware that an object was swapped out just when the object was looked up, this is too late for us: in C it is not trivial to start a background job in the middle of the command, leave the function, and re-enter in the same point the computation when the I/O thread finished what we requested (that is, no co-routines or continuations or alike).\nFortunately there was a much, much simpler way to do this. And we love simple things: basically consider the VM implementation a blocking one, but add an optimization (using non the no blocking VM operations we are able to perform) to make the blocking very unlikely.\nThis is what we do:\n\nEvery time a client sends us a command, before the command is executed, we examine the argument vector of the command in search for swapped keys. After all we know for every command what arguments are keys, as the Redis command format is pretty simple.\nIf we detect that at least a key in the requested command is swapped on disk, we block the client instead of really issuing the command. For every swapped value associated to a requested key, an I/O job is created, in order to bring the values back in memory. The main thread continues the execution of the event loop, without caring about the blocked client.\nIn the meanwhile, I/O threads are loading values in memory. Every time an I/O thread finished loading a value, it sends a byte to the main thread using an UNIX pipe. The pipe file descriptor has a readable event associated in the main thread event loop, that is the function `vmThreadedIOCompletedJob`. If this function detects that all the values needed for a blocked client were loaded, the client is restarted and the original command called.\n\nSo you can think of this as a blocked VM that almost always happen to have the right keys in memory, since we pause clients that are going to issue commands about swapped out values until this values are loaded.\nIf the function checking what argument is a key fails in some way, there is no problem: the lookup function will see that a given key is associated to a swapped out value and will block loading it. So our non blocking VM reverts to a blocking one when it is not possible to anticipate what keys are touched.\nFor instance in the case of the `SORT` command used together with the `GET` or `BY` options, it is not trivial to know beforehand what keys will be requested, so at least in the first implementation, `SORT BY/GET` resorts to the blocking VM implementation.\nBlocking clients on swapped keys\nHow to block clients? To suspend a client in an event-loop based server is pretty trivial. All we do is canceling its read handler. Sometimes we do something different (for instance for BLPOP) that is just marking the client as blocked, but not processing new data (just accumulating the new data into input buffers).\nAborting I/O jobs\nThere is something hard to solve about the interactions between our blocking and non blocking VM, that is, what happens if a blocking operation starts about a key that is also \"interested\" by a non blocking operation at the same time?\nFor instance while SORT BY is executed, a few keys are being loaded in a blocking manner by the sort command. At the same time, another client may request the same keys with a simple GET key command, that will trigger the creation of an I/O job to load the key in background.\nThe only simple way to deal with this problem is to be able to kill I/O jobs in the main thread, so that if a key that we want to load or swap in a blocking way is in the `REDIS_VM_LOADING` or `REDIS_VM_SWAPPING` state (that is, there is an I/O job about this key), we can just kill the I/O job about this key, and go ahead with the blocking operation we want to perform.\nThis is not as trivial as it is. In a given moment an I/O job can be in one of the following three queues:\n\nserver.io_newjobs: the job was already queued but no thread is handling it.\nserver.io_processing: the job is being processed by an I/O thread.\nserver.io_processed: the job was already processed.\nThe function able to kill an I/O job is `vmCancelThreadedIOJob`, and this is what it does:\nIf the job is in the newjobs queue, that's simple, removing the iojob structure from the queue is enough as no thread is still executing any operation.\nIf the job is in the processing queue, a thread is messing with our job (and possibly with the associated object!). The only thing we can do is waiting for the item to move to the next queue in a blocking way. Fortunately this condition happens very rarely so it's not a performance problem.\nIf the job is in the processed queue, we just mark it as canceled marking setting the `canceled` field to 1 in the iojob structure. The function processing completed jobs will just ignored and free the job instead of really processing it.\n\nQuestions?\nThis document is in no way complete, the only way to get the whole picture is reading the source code, but it should be a good introduction in order to make the code review / understanding a lot simpler.",
    "tag": "redis"
  },
  {
    "title": "Why is an Event Library needed at all?",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/internals/internals-rediseventlib.md",
    "content": "\ufeff---\ntitle: \"Event library\"\nlinkTitle: \"Event library\"\nweight: 1\ndescription: What's an event library, and how was the original Redis event library implemented?\naliases:\n  - /topics/internals-eventlib\n  - /topics/internals-rediseventlib\n\nNote: this document was written by the creator of Redis, Salvatore Sanfilippo, early in the development of Redis (c. 2010), and does not necessarily reflect the latest Redis implementation.\nWhy is an Event Library needed at all?\nLet us figure it out through a series of Q&As.\nQ: What do you expect a network server to be doing all the time? \nA: Watch for inbound connections on the port its listening and accept them.\nQ: Calling accept yields a descriptor. What do I do with it?\nA: Save the descriptor and do a non-blocking read/write operation on it.\nQ: Why does the read/write have to be non-blocking?\nA: If the file operation ( even a socket in Unix is a file ) is blocking how could the server for example accept other connection requests when its blocked in a file I/O operation.\nQ: I guess I have to do many such non-blocking operations on the socket to see when it's ready. Am I right?\nA: Yes. That is what an event library does for you. Now you get it.\nQ: How do Event Libraries do what they do?\nA: They use the operating system's polling facility along with timers.\nQ: So are there any open source event libraries that do what you just described? \nA: Yes. `libevent` and `libev` are two such event libraries that I can recall off the top of my head.\nQ: Does Redis use such open source event libraries for handling socket I/O?\nA: No. For various reasons Redis uses its own event library.\nThe Redis event library\nRedis implements its own event library. The event library is implemented in `ae.c`.\nThe best way to understand how the Redis event library works is to understand how Redis uses it.\nEvent Loop Initialization\n`initServer` function defined in `redis.c` initializes the numerous fields of the `redisServer` structure variable. One such field is the Redis event loop `el`:\n\n\n```aeEventLoop *el\n```\n\n\n`initServer` initializes `server.el` field by calling `aeCreateEventLoop` defined in `ae.c`. The definition of `aeEventLoop` is below:\n\n\n```typedef struct aeEventLoop\n{\n    int maxfd;\n    long long timeEventNextId;\n    aeFileEvent events[AE_SETSIZE]; /* Registered events */\n    aeFiredEvent fired[AE_SETSIZE]; /* Fired events */\n    aeTimeEvent *timeEventHead;\n    int stop;\n    void *apidata; /* This is used for polling API specific data */\n    aeBeforeSleepProc *beforesleep;\n} aeEventLoop;\n```\n\n\n`aeCreateEventLoop`\n`aeCreateEventLoop` first `malloc`s `aeEventLoop` structure then calls `ae_epoll.c:aeApiCreate`.\n`aeApiCreate` `malloc`s `aeApiState` that has two fields - `epfd` that holds the `epoll` file descriptor returned by a call from epoll_create and `events` that is of type `struct epoll_event` define by the Linux `epoll` library. The use of the `events` field will be  described later.\nNext is `ae.c:aeCreateTimeEvent`. But before that `initServer` call `anet.c:anetTcpServer` that creates and returns a listening descriptor. The descriptor listens on port 6379 by default. The returned  listening descriptor is stored in `server.fd` field.\n`aeCreateTimeEvent`\n`aeCreateTimeEvent` accepts the following as parameters:\n\n`eventLoop`: This is `server.el` in `redis.c`\nmilliseconds: The number of milliseconds from the current time after which the timer expires.\n`proc`: Function pointer. Stores the address of the function that has to be called after the timer expires.\n`clientData`: Mostly `NULL`.\n`finalizerProc`: Pointer to the function that has to be called before the timed event is removed from the list of timed events.\n\n`initServer` calls `aeCreateTimeEvent` to add a timed event to `timeEventHead` field of `server.el`. `timeEventHead` is a pointer to a list of such timed events. The call to `aeCreateTimeEvent` from `redis.c:initServer` function is given below:\n\n\n```aeCreateTimeEvent(server.el /*eventLoop*/, 1 /*milliseconds*/, serverCron /*proc*/, NULL /*clientData*/, NULL /*finalizerProc*/);\n```\n\n\n`redis.c:serverCron` performs many operations that helps keep Redis running properly.\n`aeCreateFileEvent`\nThe essence of `aeCreateFileEvent` function is to execute epoll_ctl system call which adds a watch for `EPOLLIN` event on the listening descriptor create by `anetTcpServer` and associate it with the `epoll` descriptor created by a call to `aeCreateEventLoop`.\nFollowing is an explanation of what precisely `aeCreateFileEvent` does when called from `redis.c:initServer`.\n`initServer` passes the following arguments to `aeCreateFileEvent`:\n\n`server.el`: The event loop created by `aeCreateEventLoop`. The `epoll` descriptor is got from `server.el`.\n`server.fd`: The listening descriptor that also serves as an index to access the relevant file event structure from the `eventLoop->events` table and store extra information like the callback function.\n`AE_READABLE`: Signifies that `server.fd` has to be watched for `EPOLLIN` event.\n`acceptHandler`: The function that has to be executed when the event being watched for is ready. This function pointer is stored in `eventLoop->events[server.fd]->rfileProc`.\n\nThis completes the initialization of Redis event loop.\nEvent Loop Processing\n`ae.c:aeMain` called from `redis.c:main` does the job of processing the event loop that is initialized in the previous phase.\n`ae.c:aeMain` calls `ae.c:aeProcessEvents` in a while loop that processes pending time and file events.\n`aeProcessEvents`\n`ae.c:aeProcessEvents` looks for the time event that will be pending in the smallest amount of time by calling `ae.c:aeSearchNearestTimer` on the event loop. In our case there is only one timer event in the event loop that was created by `ae.c:aeCreateTimeEvent`.\nRemember, that the timer event created by `aeCreateTimeEvent` has probably elapsed by now because it had an expiry time of one millisecond. Since the timer has already expired, the seconds and microseconds fields of the `tvp` `timeval` structure variable is initialized to zero.\nThe `tvp` structure variable along with the event loop variable is passed to `ae_epoll.c:aeApiPoll`.\n`aeApiPoll` functions does an epoll_wait on the `epoll` descriptor and populates the `eventLoop->fired` table with the details:\n\n`fd`: The descriptor that is now ready to do a read/write operation depending on the mask value.\n`mask`: The read/write event that can now be performed on the corresponding descriptor.\n\n`aeApiPoll` returns the number of such file events ready for operation. Now to put things in context, if any client has requested for a connection then `aeApiPoll` would have noticed it and populated the `eventLoop->fired` table with an entry of the descriptor being the listening descriptor and mask being `AE_READABLE`.\nNow, `aeProcessEvents` calls the `redis.c:acceptHandler` registered as the callback. `acceptHandler` executes accept on the listening descriptor returning a connected descriptor with the client. `redis.c:createClient` adds a file event on the connected descriptor through a call to `ae.c:aeCreateFileEvent` like below:\n\n\n```if (aeCreateFileEvent(server.el, c->fd, AE_READABLE,\n    readQueryFromClient, c) == AE_ERR) {\n    freeClient(c);\n    return NULL;\n}\n```\n\n\n`c` is the `redisClient` structure variable and `c->fd` is the connected descriptor.\nNext the `ae.c:aeProcessEvent` calls `ae.c:processTimeEvents`\n`processTimeEvents`\n`ae.processTimeEvents` iterates over list of time events starting at `eventLoop->timeEventHead`.\nFor every timed event that has elapsed `processTimeEvents` calls the registered callback. In this case it calls the only timed event callback registered, that is, `redis.c:serverCron`. The callback returns the time in milliseconds after which the callback must be called again. This change is recorded via a call to `ae.c:aeAddMilliSeconds` and will be handled on the next iteration of `ae.c:aeMain` while loop.",
    "tag": "redis"
  },
  {
    "title": "Redis Design Draft 2 -- RDB version 7 info fields",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/internals/rdd.md",
    "content": "\ntitle: \"Redis design draft #2 (historical)\"\nlinkTitle: \"Redis design draft\"\nweight: 2\ndescription: A design for the RDB format written in the early days of Redis\naliases:\n  - /topics/rdd\n  - /topics/rdd-1\n  - /topics/rdd-2\n\nNote: this document was written by the creator of Redis, Salvatore Sanfilippo, early in the development of Redis (c. 2013), as part of a series of design drafts. This is preserved for historical interest.\nRedis Design Draft 2 -- RDB version 7 info fields\n\nAuthor: Salvatore Sanfilippo `antirez@gmail.com`\nGitHub issue #1048\n\nHistory of revisions\n1.0, 10 April 2013 - Initial draft.\nOverview\nThe Redis RDB format lacks a simple way to add info fields to an RDB file\nwithout causing a backward compatibility issue even if the added meta data\nis not required in order to load data from the RDB file.\nFor example thanks to the info fields specified in this document it will\nbe possible to add to RDB information like file creation time, Redis version\ngenerating the file, and any other useful information, in a way that not\nevery field is required for an RDB version 7 file to be correctly processed.\nAlso with minimal changes it will be possible to add RDB version 7 support to\nRedis 2.6 without actually supporting the additional fields but just skipping\nthem when loading an RDB file.\nRDB info fields may have semantic meaning if needed, so that the presence\nof the field may add information about the data set specified in the RDB\nfile format, however when an info field is required to be correctly decoded\nin order to understand and load the data set content of the RDB file, the\nRDB file format must be increased so that previous versions of Redis will not\nattempt to load it.\nHowever currently the info fields are designed to only hold additional\ninformation that are not useful to load the dataset, but can better specify\nhow the RDB file was created.\nInfo fields representation\nThe RDB format 6 has the following layout:\n\nA 9 bytes magic \"REDIS0006\"\nkey-value pairs\nAn EOF opcode\nCRC64 checksum\n\nThe proposal for RDB format 7 is to add the optional fields immediately\nafter the first 9 bytes magic, so that the new format will be:\n\nA 9 bytes magic \"REDIS0007\"\nInfo field 1\nInfo field 2\n...\nInfo field N\nInfo field end-of-fields\nkey-value pairs\nAn EOF opcode\nCRC64 checksum\n\nEvery single info field has the following structure:\n\nA 16 bit identifier\nA 64 bit data length\nA data section of the exact length as specified\n\nBoth the identifier and the data length are stored in little endian byte\nordering.\nThe special identifier 0 means that there are no other info fields, and that\nthe remaining of the RDB file contains the key-value pairs.\nHandling of info fields\nA program can simply skip every info field it does not understand, as long\nas the RDB version matches the one that it is capable to load.\nSpecification of info fields IDs and content.\nInfo field 0 -- End of info fields\nThis just means there are no longer info fields to process.\nInfo field 1 -- Creation date\nThis field represents the unix time at which the RDB file was created.\nThe format of the unix time is a 64 bit little endian integer representing\nseconds since 1th January 1970.\nInfo field 2 -- Redis version\nThis field represents a null-terminated string containing the Redis version",
    "tag": "redis"
  },
  {
    "title": "Sections",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/modules/modules-api-ref.md",
    "content": "\ntitle: \"Modules API reference\"\nlinkTitle: \"API reference\"\nweight: 1\ndescription: >\n    Reference for the Redis Modules API\naliases:\n    - /topics/modules-api-ref\n\n\nSections\n\nHeap allocation raw functions\nCommands API\nModule information and time measurement\nAutomatic memory management for modules\nString objects APIs\nReply APIs\nCommands replication API\nDB and Key APIs \u2013 Generic API\nKey API for String type\nKey API for List type\nKey API for Sorted Set type\nKey API for Sorted Set iterator\nKey API for Hash type\nKey API for Stream type\nCalling Redis commands from modules\nModules data types\nRDB loading and saving functions\nKey digest API (DEBUG DIGEST interface for modules types)\nAOF API for modules data types\nIO context handling\nLogging\nBlocking clients from modules\nThread Safe Contexts\nModule Keyspace Notifications API\nModules Cluster API\nModules Timers API\nModules EventLoop API\nModules ACL API\nModules Dictionary API\nModules Info fields\nModules utility APIs\nModules API exporting / importing\nModule Command Filter API\nScanning keyspace and hashes\nModule fork API\nServer hooks implementation\nModule Configurations API\nKey eviction API\nMiscellaneous APIs\nDefrag API\nFunction index\n\n\nHeap allocation raw functions\nMemory allocated with these functions are taken into account by Redis key\neviction algorithms and are reported in Redis memory usage information.\n\n`RedisModule_Alloc`\n\n\n```void *RedisModule_Alloc(size_t bytes);\n```\n\n\nAvailable since: 4.0.0\nUse like `malloc()`. Memory allocated with this function is reported in\nRedis INFO memory, used for keys eviction according to maxmemory settings\nand in general is taken into account as memory allocated by Redis.\nYou should avoid using `malloc()`.\nThis function panics if unable to allocate enough memory.\n\n`RedisModule_TryAlloc`\n\n\n```void *RedisModule_TryAlloc(size_t bytes);\n```\n\n\nAvailable since: 7.0.0\nSimilar to RedisModule_Alloc, but returns NULL in case of allocation failure, instead\nof panicking.\n\n`RedisModule_Calloc`\n\n\n```void *RedisModule_Calloc(size_t nmemb, size_t size);\n```\n\n\nAvailable since: 4.0.0\nUse like `calloc()`. Memory allocated with this function is reported in\nRedis INFO memory, used for keys eviction according to maxmemory settings\nand in general is taken into account as memory allocated by Redis.\nYou should avoid using `calloc()` directly.\n\n`RedisModule_Realloc`\n\n\n```void* RedisModule_Realloc(void *ptr, size_t bytes);\n```\n\n\nAvailable since: 4.0.0\nUse like `realloc()` for memory obtained with RedisModule_Alloc().\n\n`RedisModule_Free`\n\n\n```void RedisModule_Free(void *ptr);\n```\n\n\nAvailable since: 4.0.0\nUse like `free()` for memory obtained by RedisModule_Alloc() and\nRedisModule_Realloc(). However you should never try to free with\nRedisModule_Free() memory allocated with `malloc()` inside your module.\n\n`RedisModule_Strdup`\n\n\n```char *RedisModule_Strdup(const char *str);\n```\n\n\nAvailable since: 4.0.0\nLike `strdup()` but returns memory allocated with RedisModule_Alloc().\n\n`RedisModule_PoolAlloc`\n\n\n```void *RedisModule_PoolAlloc(RedisModuleCtx *ctx, size_t bytes);\n```\n\n\nAvailable since: 4.0.0\nReturn heap allocated memory that will be freed automatically when the\nmodule callback function returns. Mostly suitable for small allocations\nthat are short living and must be released when the callback returns\nanyway. The returned memory is aligned to the architecture word size\nif at least word size bytes are requested, otherwise it is just\naligned to the next power of two, so for example a 3 bytes request is\n4 bytes aligned while a 2 bytes request is 2 bytes aligned.\nThere is no realloc style function since when this is needed to use the\npool allocator is not a good idea.\nThe function returns NULL if `bytes` is 0.\n\nCommands API\nThese functions are used to implement custom Redis commands.\nFor examples, see https://redis.io/topics/modules-intro.\n\n`RedisModule_IsKeysPositionRequest`\n\n\n```int RedisModule_IsKeysPositionRequest(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nReturn non-zero if a module command, that was declared with the\nflag \"getkeys-api\", is called in a special way to get the keys positions\nand not to get executed. Otherwise zero is returned.\n\n`RedisModule_KeyAtPosWithFlags`\n\n\n```void RedisModule_KeyAtPosWithFlags(RedisModuleCtx *ctx, int pos, int flags);\n```\n\n\nAvailable since: 7.0.0\nWhen a module command is called in order to obtain the position of\nkeys, since it was flagged as \"getkeys-api\" during the registration,\nthe command implementation checks for this special call using the\nRedisModule_IsKeysPositionRequest() API and uses this function in\norder to report keys.\nThe supported flags are the ones used by RedisModule_SetCommandInfo, see `REDISMODULE_CMD_KEY_`*.\nThe following is an example of how it could be used:\n\n\n```if (RedisModule_IsKeysPositionRequest(ctx)) {\n    RedisModule_KeyAtPosWithFlags(ctx, 2, REDISMODULE_CMD_KEY_RO | REDISMODULE_CMD_KEY_ACCESS);\n    RedisModule_KeyAtPosWithFlags(ctx, 1, REDISMODULE_CMD_KEY_RW | REDISMODULE_CMD_KEY_UPDATE | REDISMODULE_CMD_KEY_ACCESS);\n}\n```\n\n\nNote: in the example above the get keys API could have been handled by key-specs (preferred).\n Implementing the getkeys-api is required only when is it not possible to declare key-specs that cover all keys.\n\n`RedisModule_KeyAtPos`\n\n\n```void RedisModule_KeyAtPos(RedisModuleCtx *ctx, int pos);\n```\n\n\nAvailable since: 4.0.0\nThis API existed before RedisModule_KeyAtPosWithFlags was added, now deprecated and\ncan be used for compatibility with older versions, before key-specs and flags\nwere introduced.\n\n`RedisModule_IsChannelsPositionRequest`\n\n\n```int RedisModule_IsChannelsPositionRequest(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nReturn non-zero if a module command, that was declared with the\nflag \"getchannels-api\", is called in a special way to get the channel positions\nand not to get executed. Otherwise zero is returned.\n\n`RedisModule_ChannelAtPosWithFlags`\n\n\n```void RedisModule_ChannelAtPosWithFlags(RedisModuleCtx *ctx,\n                                       int pos,\n                                       int flags);\n```\n\n\nAvailable since: 7.0.0\nWhen a module command is called in order to obtain the position of\nchannels, since it was flagged as \"getchannels-api\" during the\nregistration, the command implementation checks for this special call\nusing the RedisModule_IsChannelsPositionRequest() API and uses this\nfunction in order to report the channels.\nThe supported flags are:\n* `REDISMODULE_CMD_CHANNEL_SUBSCRIBE`: This command will subscribe to the channel.\n* `REDISMODULE_CMD_CHANNEL_UNSUBSCRIBE`: This command will unsubscribe from this channel.\n* `REDISMODULE_CMD_CHANNEL_PUBLISH`: This command will publish to this channel.\n* `REDISMODULE_CMD_CHANNEL_PATTERN`: Instead of acting on a specific channel, will act on any \n                                   channel specified by the pattern. This is the same access\n                                   used by the PSUBSCRIBE and PUNSUBSCRIBE commands available \n                                   in Redis. Not intended to be used with PUBLISH permissions.\nThe following is an example of how it could be used:\n\n\n```if (RedisModule_IsChannelsPositionRequest(ctx)) {\n    RedisModule_ChannelAtPosWithFlags(ctx, 1, REDISMODULE_CMD_CHANNEL_SUBSCRIBE | REDISMODULE_CMD_CHANNEL_PATTERN);\n    RedisModule_ChannelAtPosWithFlags(ctx, 1, REDISMODULE_CMD_CHANNEL_PUBLISH);\n}\n```\n\n\nNote: One usage of declaring channels is for evaluating ACL permissions. In this context,\nunsubscribing is always allowed, so commands will only be checked against subscribe and\npublish permissions. This is preferred over using RedisModule_ACLCheckChannelPermissions, since\nit allows the ACLs to be checked before the command is executed.\n\n`RedisModule_CreateCommand`\n\n\n```int RedisModule_CreateCommand(RedisModuleCtx *ctx,\n                              const char *name,\n                              RedisModuleCmdFunc cmdfunc,\n                              const char *strflags,\n                              int firstkey,\n                              int lastkey,\n                              int keystep);\n```\n\n\nAvailable since: 4.0.0\nRegister a new command in the Redis server, that will be handled by\ncalling the function pointer 'cmdfunc' using the RedisModule calling\nconvention. The function returns `REDISMODULE_ERR` if the specified command\nname is already busy or a set of invalid flags were passed, otherwise\n`REDISMODULE_OK` is returned and the new command is registered.\nThis function must be called during the initialization of the module\ninside the `RedisModule_OnLoad()` function. Calling this function outside\nof the initialization function is not defined.\nThe command function type is the following:\n\n\n``` int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);\n```\n\n\nAnd is supposed to always return `REDISMODULE_OK`.\nThe set of flags 'strflags' specify the behavior of the command, and should\nbe passed as a C string composed of space separated words, like for\nexample \"write deny-oom\". The set of flags are:\n\n\"write\":     The command may modify the data set (it may also read\n                   from it).\n\"readonly\":  The command returns data from keys but never writes.\n\"admin\":     The command is an administrative command (may change\n                   replication or perform similar tasks).\n\"deny-oom\":  The command may use additional memory and should be\n                   denied during out of memory conditions.\n\"deny-script\":   Don't allow this command in Lua scripts.\n\"allow-loading\": Allow this command while the server is loading data.\n                       Only commands not interacting with the data set\n                       should be allowed to run in this mode. If not sure\n                       don't use this flag.\n\"pubsub\":    The command publishes things on Pub/Sub channels.\n\"random\":    The command may have different outputs even starting\n                   from the same input arguments and key values.\n                   Starting from Redis 7.0 this flag has been deprecated.\n                   Declaring a command as \"random\" can be done using\n                   command tips, see https://redis.io/topics/command-tips.\n\"allow-stale\": The command is allowed to run on slaves that don't\n                     serve stale data. Don't use if you don't know what\n                     this means.\n\"no-monitor\": Don't propagate the command on monitor. Use this if\n                    the command has sensitive data among the arguments.\n\"no-slowlog\": Don't log this command in the slowlog. Use this if\n                    the command has sensitive data among the arguments.\n\"fast\":      The command time complexity is not greater\n                   than O(log(N)) where N is the size of the collection or\n                   anything else representing the normal scalability\n                   issue with the command.\n\"getkeys-api\": The command implements the interface to return\n                     the arguments that are keys. Used when start/stop/step\n                     is not enough because of the command syntax.\n\"no-cluster\": The command should not register in Redis Cluster\n                    since is not designed to work with it because, for\n                    example, is unable to report the position of the\n                    keys, programmatically creates key names, or any\n                    other reason.\n\"no-auth\":    This command can be run by an un-authenticated client.\n                    Normally this is used by a command that is used\n                    to authenticate a client.\n\"may-replicate\": This command may generate replication traffic, even\n                       though it's not a write command.\n\"no-mandatory-keys\": All the keys this command may take are optional\n\"blocking\": The command has the potential to block the client.\n\"allow-busy\": Permit the command while the server is blocked either by\n                    a script or by a slow module command, see\n                    RedisModule_Yield.\n\"getchannels-api\": The command implements the interface to return\n                         the arguments that are channels.\n\nThe last three parameters specify which arguments of the new command are\nRedis keys. See https://redis.io/commands/command for more information.\n\n`firstkey`: One-based index of the first argument that's a key.\n              Position 0 is always the command name itself.\n              0 for commands with no keys.\n`lastkey`:  One-based index of the last argument that's a key.\n              Negative numbers refer to counting backwards from the last\n              argument (-1 means the last argument provided)\n              0 for commands with no keys.\n`keystep`:  Step between first and last key indexes.\n              0 for commands with no keys.\n\nThis information is used by ACL, Cluster and the `COMMAND` command.\nNOTE: The scheme described above serves a limited purpose and can\nonly be used to find keys that exist at constant indices.\nFor non-trivial key arguments, you may pass 0,0,0 and use\nRedisModule_SetCommandInfo to set key specs using a more advanced scheme.\n\n`RedisModule_GetCommand`\n\n\n```RedisModuleCommand *RedisModule_GetCommand(RedisModuleCtx *ctx,\n                                           const char *name);\n```\n\n\nAvailable since: 7.0.0\nGet an opaque structure, representing a module command, by command name.\nThis structure is used in some of the command-related APIs.\nNULL is returned in case of the following errors:\n\nCommand not found\nThe command is not a module command\nThe command doesn't belong to the calling module\n\n\n`RedisModule_CreateSubcommand`\n\n\n```int RedisModule_CreateSubcommand(RedisModuleCommand *parent,\n                                 const char *name,\n                                 RedisModuleCmdFunc cmdfunc,\n                                 const char *strflags,\n                                 int firstkey,\n                                 int lastkey,\n                                 int keystep);\n```\n\n\nAvailable since: 7.0.0\nVery similar to RedisModule_CreateCommand except that it is used to create\na subcommand, associated with another, container, command.\nExample: If a module has a configuration command, MODULE.CONFIG, then\nGET and SET should be individual subcommands, while MODULE.CONFIG is\na command, but should not be registered with a valid `funcptr`:\n\n\n``` if (RedisModule_CreateCommand(ctx,\"module.config\",NULL,\"\",0,0,0) == REDISMODULE_ERR)\n     return REDISMODULE_ERR;\n\n RedisModuleCommand *parent = RedisModule_GetCommand(ctx,,\"module.config\");\n\n if (RedisModule_CreateSubcommand(parent,\"set\",cmd_config_set,\"\",0,0,0) == REDISMODULE_ERR)\n    return REDISMODULE_ERR;\n\n if (RedisModule_CreateSubcommand(parent,\"get\",cmd_config_get,\"\",0,0,0) == REDISMODULE_ERR)\n    return REDISMODULE_ERR;\n```\n\n\nReturns `REDISMODULE_OK` on success and `REDISMODULE_ERR` in case of the following errors:\n\nError while parsing `strflags`\nCommand is marked as `no-cluster` but cluster mode is enabled\n`parent` is already a subcommand (we do not allow more than one level of command nesting)\n`parent` is a command with an implementation (`RedisModuleCmdFunc`) (A parent command should be a pure container of subcommands)\n`parent` already has a subcommand called `name`\n\n\n`RedisModule_SetCommandInfo`\n\n\n```int RedisModule_SetCommandInfo(RedisModuleCommand *command,\n                               const RedisModuleCommandInfo *info);\n```\n\n\nAvailable since: 7.0.0\nSet additional command information.\nAffects the output of `COMMAND`, `COMMAND INFO` and `COMMAND DOCS`, Cluster,\nACL and is used to filter commands with the wrong number of arguments before\nthe call reaches the module code.\nThis function can be called after creating a command using RedisModule_CreateCommand\nand fetching the command pointer using RedisModule_GetCommand. The information can\nonly be set once for each command and has the following structure:\n\n\n```typedef struct RedisModuleCommandInfo {\n    const RedisModuleCommandInfoVersion *version;\n    const char *summary;\n    const char *complexity;\n    const char *since;\n    RedisModuleCommandHistoryEntry *history;\n    const char *tips;\n    int arity;\n    RedisModuleCommandKeySpec *key_specs;\n    RedisModuleCommandArg *args;\n} RedisModuleCommandInfo;\n```\n\n\nAll fields except `version` are optional. Explanation of the fields:\n\n\n`version`: This field enables compatibility with different Redis versions.\n  Always set this field to `REDISMODULE_COMMAND_INFO_VERSION`.\n\n\n`summary`: A short description of the command (optional).\n\n\n`complexity`: Complexity description (optional).\n\n\n`since`: The version where the command was introduced (optional).\n  Note: The version specified should be the module's, not Redis version.\n\n\n`history`: An array of `RedisModuleCommandHistoryEntry` (optional), which is\n  a struct with the following fields:\n\n\n```const char *since;\nconst char *changes;\n```\n\n\n`since` is a version string and `changes` is a string describing the\nchanges. The array is terminated by a zeroed entry, i.e. an entry with\nboth strings set to NULL.\n\n\n`tips`: A string of space-separated tips regarding this command, meant for\n  clients and proxies. See https://redis.io/topics/command-tips.\n\n\n`arity`: Number of arguments, including the command name itself. A positive\n  number specifies an exact number of arguments and a negative number\n  specifies a minimum number of arguments, so use -N to say >= N. Redis\n  validates a call before passing it to a module, so this can replace an\n  arity check inside the module command implementation. A value of 0 (or an\n  omitted arity field) is equivalent to -2 if the command has sub commands\n  and -1 otherwise.\n\n\n`key_specs`: An array of `RedisModuleCommandKeySpec`, terminated by an\n  element memset to zero. This is a scheme that tries to describe the\n  positions of key arguments better than the old RedisModule_CreateCommand arguments\n  `firstkey`, `lastkey`, `keystep` and is needed if those three are not\n  enough to describe the key positions. There are two steps to retrieve key\n  positions: begin search (BS) in which index should find the first key and\n  find keys (FK) which, relative to the output of BS, describes how can we\n  will which arguments are keys. Additionally, there are key specific flags.\nKey-specs cause the triplet (firstkey, lastkey, keystep) given in\nRedisModule_CreateCommand to be recomputed, but it is still useful to provide\nthese three parameters in RedisModule_CreateCommand, to better support old Redis\nversions where RedisModule_SetCommandInfo is not available.\nNote that key-specs don't fully replace the \"getkeys-api\" (see\nRedisModule_CreateCommand, RedisModule_IsKeysPositionRequest and RedisModule_KeyAtPosWithFlags) so\nit may be a good idea to supply both key-specs and implement the\ngetkeys-api.\nA key-spec has the following structure:\n\n\n```typedef struct RedisModuleCommandKeySpec {\n    const char *notes;\n    uint64_t flags;\n    RedisModuleKeySpecBeginSearchType begin_search_type;\n    union {\n        struct {\n            int pos;\n        } index;\n        struct {\n            const char *keyword;\n            int startfrom;\n        } keyword;\n    } bs;\n    RedisModuleKeySpecFindKeysType find_keys_type;\n    union {\n        struct {\n            int lastkey;\n            int keystep;\n            int limit;\n        } range;\n        struct {\n            int keynumidx;\n            int firstkey;\n            int keystep;\n        } keynum;\n    } fk;\n} RedisModuleCommandKeySpec;\n```\n\n\nExplanation of the fields of RedisModuleCommandKeySpec:\n\n\n`notes`: Optional notes or clarifications about this key spec.\n\n\n`flags`: A bitwise or of key-spec flags described below.\n\n\n`begin_search_type`: This describes how the first key is discovered.\n  There are two ways to determine the first key:\n\n`REDISMODULE_KSPEC_BS_UNKNOWN`: There is no way to tell where the\n  key args start.\n`REDISMODULE_KSPEC_BS_INDEX`: Key args start at a constant index.\n`REDISMODULE_KSPEC_BS_KEYWORD`: Key args start just after a\n  specific keyword.\n\n\n\n`bs`: This is a union in which the `index` or `keyword` branch is used\n  depending on the value of the `begin_search_type` field.\n\n\n`bs.index.pos`: The index from which we start the search for keys.\n  (`REDISMODULE_KSPEC_BS_INDEX` only.)\n\n\n`bs.keyword.keyword`: The keyword (string) that indicates the\n  beginning of key arguments. (`REDISMODULE_KSPEC_BS_KEYWORD` only.)\n\n\n`bs.keyword.startfrom`: An index in argv from which to start\n  searching. Can be negative, which means start search from the end,\n  in reverse. Example: -2 means to start in reverse from the\n  penultimate argument. (`REDISMODULE_KSPEC_BS_KEYWORD` only.)\n\n\n\n\n`find_keys_type`: After the \"begin search\", this describes which\n  arguments are keys. The strategies are:\n\n`REDISMODULE_KSPEC_BS_UNKNOWN`: There is no way to tell where the\n  key args are located.\n`REDISMODULE_KSPEC_FK_RANGE`: Keys end at a specific index (or\n  relative to the last argument).\n`REDISMODULE_KSPEC_FK_KEYNUM`: There's an argument that contains\n  the number of key args somewhere before the keys themselves.\n\n\n\n`find_keys_type` and `fk` can be omitted if this keyspec describes\n  exactly one key.\n\n\n`fk`: This is a union in which the `range` or `keynum` branch is used\n  depending on the value of the `find_keys_type` field.\n\n\n`fk.range` (for `REDISMODULE_KSPEC_FK_RANGE`): A struct with the\n  following fields:\n\n\n`lastkey`: Index of the last key relative to the result of the\n  begin search step. Can be negative, in which case it's not\n  relative. -1 indicates the last argument, -2 one before the\n  last and so on.\n\n\n`keystep`: How many arguments should we skip after finding a\n  key, in order to find the next one?\n\n\n`limit`: If `lastkey` is -1, we use `limit` to stop the search\n  by a factor. 0 and 1 mean no limit. 2 means 1/2 of the\n  remaining args, 3 means 1/3, and so on.\n\n\n\n\n`fk.keynum` (for `REDISMODULE_KSPEC_FK_KEYNUM`): A struct with the\n  following fields:\n\n\n`keynumidx`: Index of the argument containing the number of\n  keys to come, relative to the result of the begin search step.\n\n\n`firstkey`: Index of the fist key relative to the result of the\n  begin search step. (Usually it's just after `keynumidx`, in\n  which case it should be set to `keynumidx + 1`.)\n\n\n`keystep`: How many arguments should we skip after finding a\n  key, in order to find the next one?\n\n\n\n\n\n\nKey-spec flags:\nThe first four refer to what the command actually does with the value or\nmetadata of the key, and not necessarily the user data or how it affects\nit. Each key-spec may must have exactly one of these. Any operation\nthat's not distinctly deletion, overwrite or read-only would be marked as\nRW.\n\n\n`REDISMODULE_CMD_KEY_RO`: Read-Only. Reads the value of the key, but\n  doesn't necessarily return it.\n\n\n`REDISMODULE_CMD_KEY_RW`: Read-Write. Modifies the data stored in the\n  value of the key or its metadata.\n\n\n`REDISMODULE_CMD_KEY_OW`: Overwrite. Overwrites the data stored in the\n  value of the key.\n\n\n`REDISMODULE_CMD_KEY_RM`: Deletes the key.\n\n\nThe next four refer to user data inside the value of the key, not the\nmetadata like LRU, type, cardinality. It refers to the logical operation\non the user's data (actual input strings or TTL), being\nused/returned/copied/changed. It doesn't refer to modification or\nreturning of metadata (like type, count, presence of data). ACCESS can be\ncombined with one of the write operations INSERT, DELETE or UPDATE. Any\nwrite that's not an INSERT or a DELETE would be UPDATE.\n\n\n`REDISMODULE_CMD_KEY_ACCESS`: Returns, copies or uses the user data\n  from the value of the key.\n\n\n`REDISMODULE_CMD_KEY_UPDATE`: Updates data to the value, new value may\n  depend on the old value.\n\n\n`REDISMODULE_CMD_KEY_INSERT`: Adds data to the value with no chance of\n  modification or deletion of existing data.\n\n\n`REDISMODULE_CMD_KEY_DELETE`: Explicitly deletes some content from the\n  value of the key.\n\n\nOther flags:\n\n\n`REDISMODULE_CMD_KEY_NOT_KEY`: The key is not actually a key, but \n  should be routed in cluster mode as if it was a key.\n\n\n`REDISMODULE_CMD_KEY_INCOMPLETE`: The keyspec might not point out all\n  the keys it should cover.\n\n\n`REDISMODULE_CMD_KEY_VARIABLE_FLAGS`: Some keys might have different\n  flags depending on arguments.\n\n\n\n\n`args`: An array of `RedisModuleCommandArg`, terminated by an element memset\n  to zero. `RedisModuleCommandArg` is a structure with at the fields described\n  below.\n\n\n```typedef struct RedisModuleCommandArg {\n    const char *name;\n    RedisModuleCommandArgType type;\n    int key_spec_index;\n    const char *token;\n    const char *summary;\n    const char *since;\n    int flags;\n    struct RedisModuleCommandArg *subargs;\n} RedisModuleCommandArg;\n```\n\n\nExplanation of the fields:\n\n\n`name`: Name of the argument.\n\n\n`type`: The type of the argument. See below for details. The types\n  `REDISMODULE_ARG_TYPE_ONEOF` and `REDISMODULE_ARG_TYPE_BLOCK` require\n  an argument to have sub-arguments, i.e. `subargs`.\n\n\n`key_spec_index`: If the `type` is `REDISMODULE_ARG_TYPE_KEY` you must\n  provide the index of the key-spec associated with this argument. See\n  `key_specs` above. If the argument is not a key, you may specify -1.\n\n\n`token`: The token preceding the argument (optional). Example: the\n  argument `seconds` in `SET` has a token `EX`. If the argument consists\n  of only a token (for example `NX` in `SET`) the type should be\n  `REDISMODULE_ARG_TYPE_PURE_TOKEN` and `value` should be NULL.\n\n\n`summary`: A short description of the argument (optional).\n\n\n`since`: The first version which included this argument (optional).\n\n\n`flags`: A bitwise or of the macros `REDISMODULE_CMD_ARG_*`. See below.\n\n\n`value`: The display-value of the argument. This string is what should\n  be displayed when creating the command syntax from the output of\n  `COMMAND`. If `token` is not NULL, it should also be displayed.\n\n\nExplanation of `RedisModuleCommandArgType`:\n\n`REDISMODULE_ARG_TYPE_STRING`: String argument.\n`REDISMODULE_ARG_TYPE_INTEGER`: Integer argument.\n`REDISMODULE_ARG_TYPE_DOUBLE`: Double-precision float argument.\n`REDISMODULE_ARG_TYPE_KEY`: String argument representing a keyname.\n`REDISMODULE_ARG_TYPE_PATTERN`: String, but regex pattern.\n`REDISMODULE_ARG_TYPE_UNIX_TIME`: Integer, but Unix timestamp.\n`REDISMODULE_ARG_TYPE_PURE_TOKEN`: Argument doesn't have a placeholder.\n  It's just a token without a value. Example: the `KEEPTTL` option of the\n  `SET` command.\n`REDISMODULE_ARG_TYPE_ONEOF`: Used when the user can choose only one of\n  a few sub-arguments. Requires `subargs`. Example: the `NX` and `XX`\n  options of `SET`.\n`REDISMODULE_ARG_TYPE_BLOCK`: Used when one wants to group together\n  several sub-arguments, usually to apply something on all of them, like\n  making the entire group \"optional\". Requires `subargs`. Example: the\n  `LIMIT offset count` parameters in `ZRANGE`.\n\nExplanation of the command argument flags:\n\n`REDISMODULE_CMD_ARG_OPTIONAL`: The argument is optional (like GET in\n  the SET command).\n`REDISMODULE_CMD_ARG_MULTIPLE`: The argument may repeat itself (like\n  key in DEL).\n`REDISMODULE_CMD_ARG_MULTIPLE_TOKEN`: The argument may repeat itself,\n  and so does its token (like `GET pattern` in SORT).\n\n\n\nOn success `REDISMODULE_OK` is returned. On error `REDISMODULE_ERR` is returned\nand `errno` is set to EINVAL if invalid info was provided or EEXIST if info\nhas already been set. If the info is invalid, a warning is logged explaining\nwhich part of the info is invalid and why.\n\nModule information and time measurement\n\n`RedisModule_IsModuleNameBusy`\n\n\n```int RedisModule_IsModuleNameBusy(const char *name);\n```\n\n\nAvailable since: 4.0.3\nReturn non-zero if the module name is busy.\nOtherwise zero is returned.\n\n`RedisModule_Milliseconds`\n\n\n```long long RedisModule_Milliseconds(void);\n```\n\n\nAvailable since: 4.0.0\nReturn the current UNIX time in milliseconds.\n\n`RedisModule_MonotonicMicroseconds`\n\n\n```uint64_t RedisModule_MonotonicMicroseconds(void);\n```\n\n\nAvailable since: 7.0.0\nReturn counter of micro-seconds relative to an arbitrary point in time.\n\n`RedisModule_BlockedClientMeasureTimeStart`\n\n\n```int RedisModule_BlockedClientMeasureTimeStart(RedisModuleBlockedClient *bc);\n```\n\n\nAvailable since: 6.2.0\nMark a point in time that will be used as the start time to calculate\nthe elapsed execution time when RedisModule_BlockedClientMeasureTimeEnd() is called.\nWithin the same command, you can call multiple times\nRedisModule_BlockedClientMeasureTimeStart() and RedisModule_BlockedClientMeasureTimeEnd()\nto accumulate independent time intervals to the background duration.\nThis method always return `REDISMODULE_OK`.\n\n`RedisModule_BlockedClientMeasureTimeEnd`\n\n\n```int RedisModule_BlockedClientMeasureTimeEnd(RedisModuleBlockedClient *bc);\n```\n\n\nAvailable since: 6.2.0\nMark a point in time that will be used as the end time\nto calculate the elapsed execution time.\nOn success `REDISMODULE_OK` is returned.\nThis method only returns `REDISMODULE_ERR` if no start time was\npreviously defined ( meaning RedisModule_BlockedClientMeasureTimeStart was not called ).\n\n`RedisModule_Yield`\n\n\n```void RedisModule_Yield(RedisModuleCtx *ctx, int flags, const char *busy_reply);\n```\n\n\nAvailable since: 7.0.0\nThis API allows modules to let Redis process background tasks, and some\ncommands during long blocking execution of a module command.\nThe module can call this API periodically.\nThe flags is a bit mask of these:\n\n`REDISMODULE_YIELD_FLAG_NONE`: No special flags, can perform some background\n                                 operations, but not process client commands.\n`REDISMODULE_YIELD_FLAG_CLIENTS`: Redis can also process client commands.\n\nThe `busy_reply` argument is optional, and can be used to control the verbose\nerror string after the `-BUSY` error code.\nWhen the `REDISMODULE_YIELD_FLAG_CLIENTS` is used, Redis will only start\nprocessing client commands after the time defined by the\n`busy-reply-threshold` config, in which case Redis will start rejecting most\ncommands with `-BUSY` error, but allow the ones marked with the `allow-busy`\nflag to be executed.\nThis API can also be used in thread safe context (while locked), and during\nloading (in the `rdb_load` callback, in which case it'll reject commands with\nthe -LOADING error)\n\n`RedisModule_SetModuleOptions`\n\n\n```void RedisModule_SetModuleOptions(RedisModuleCtx *ctx, int options);\n```\n\n\nAvailable since: 6.0.0\nSet flags defining capabilities or behavior bit flags.\n`REDISMODULE_OPTIONS_HANDLE_IO_ERRORS`:\nGenerally, modules don't need to bother with this, as the process will just\nterminate if a read error happens, however, setting this flag would allow\nrepl-diskless-load to work if enabled.\nThe module should use RedisModule_IsIOError after reads, before using the\ndata that was read, and in case of error, propagate it upwards, and also be\nable to release the partially populated value and all it's allocations.\n`REDISMODULE_OPTION_NO_IMPLICIT_SIGNAL_MODIFIED`:\nSee RedisModule_SignalModifiedKey().\n`REDISMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD`:\nSetting this flag indicates module awareness of diskless async replication (repl-diskless-load=swapdb)\nand that redis could be serving reads during replication instead of blocking with LOADING status.\n\n`RedisModule_SignalModifiedKey`\n\n\n```int RedisModule_SignalModifiedKey(RedisModuleCtx *ctx,\n                                  RedisModuleString *keyname);\n```\n\n\nAvailable since: 6.0.0\nSignals that the key is modified from user's perspective (i.e. invalidate WATCH\nand client side caching).\nThis is done automatically when a key opened for writing is closed, unless\nthe option `REDISMODULE_OPTION_NO_IMPLICIT_SIGNAL_MODIFIED` has been set using\nRedisModule_SetModuleOptions().\n\nAutomatic memory management for modules\n\n`RedisModule_AutoMemory`\n\n\n```void RedisModule_AutoMemory(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nEnable automatic memory management.\nThe function must be called as the first function of a command implementation\nthat wants to use automatic memory.\nWhen enabled, automatic memory management tracks and automatically frees\nkeys, call replies and Redis string objects once the command returns. In most\ncases this eliminates the need of calling the following functions:\n\nRedisModule_CloseKey()\nRedisModule_FreeCallReply()\nRedisModule_FreeString()\n\nThese functions can still be used with automatic memory management enabled,\nto optimize loops that make numerous allocations for example.\n\nString objects APIs\n\n`RedisModule_CreateString`\n\n\n```RedisModuleString *RedisModule_CreateString(RedisModuleCtx *ctx,\n                                            const char *ptr,\n                                            size_t len);\n```\n\n\nAvailable since: 4.0.0\nCreate a new module string object. The returned string must be freed\nwith RedisModule_FreeString(), unless automatic memory is enabled.\nThe string is created by copying the `len` bytes starting\nat `ptr`. No reference is retained to the passed buffer.\nThe module context 'ctx' is optional and may be NULL if you want to create\na string out of the context scope. However in that case, the automatic\nmemory management will not be available, and the string memory must be\nmanaged manually.\n\n`RedisModule_CreateStringPrintf`\n\n\n```RedisModuleString *RedisModule_CreateStringPrintf(RedisModuleCtx *ctx,\n                                                  const char *fmt,\n                                                  ...);\n```\n\n\nAvailable since: 4.0.0\nCreate a new module string object from a printf format and arguments.\nThe returned string must be freed with RedisModule_FreeString(), unless\nautomatic memory is enabled.\nThe string is created using the sds formatter function `sdscatvprintf()`.\nThe passed context 'ctx' may be NULL if necessary, see the\nRedisModule_CreateString() documentation for more info.\n\n`RedisModule_CreateStringFromLongLong`\n\n\n```RedisModuleString *RedisModule_CreateStringFromLongLong(RedisModuleCtx *ctx,\n                                                        long long ll);\n```\n\n\nAvailable since: 4.0.0\nLike RedisModule_CreateString(), but creates a string starting from a `long long`\ninteger instead of taking a buffer and its length.\nThe returned string must be released with RedisModule_FreeString() or by\nenabling automatic memory management.\nThe passed context 'ctx' may be NULL if necessary, see the\nRedisModule_CreateString() documentation for more info.\n\n`RedisModule_CreateStringFromULongLong`\n\n\n```RedisModuleString *RedisModule_CreateStringFromULongLong(RedisModuleCtx *ctx,\n                                                         unsigned long long ull);\n```\n\n\nAvailable since: 7.0.3\nLike RedisModule_CreateString(), but creates a string starting from a `unsigned long long`\ninteger instead of taking a buffer and its length.\nThe returned string must be released with RedisModule_FreeString() or by\nenabling automatic memory management.\nThe passed context 'ctx' may be NULL if necessary, see the\nRedisModule_CreateString() documentation for more info.\n\n`RedisModule_CreateStringFromDouble`\n\n\n```RedisModuleString *RedisModule_CreateStringFromDouble(RedisModuleCtx *ctx,\n                                                      double d);\n```\n\n\nAvailable since: 6.0.0\nLike RedisModule_CreateString(), but creates a string starting from a double\ninstead of taking a buffer and its length.\nThe returned string must be released with RedisModule_FreeString() or by\nenabling automatic memory management.\n\n`RedisModule_CreateStringFromLongDouble`\n\n\n```RedisModuleString *RedisModule_CreateStringFromLongDouble(RedisModuleCtx *ctx,\n                                                          long double ld,\n                                                          int humanfriendly);\n```\n\n\nAvailable since: 6.0.0\nLike RedisModule_CreateString(), but creates a string starting from a long\ndouble.\nThe returned string must be released with RedisModule_FreeString() or by\nenabling automatic memory management.\nThe passed context 'ctx' may be NULL if necessary, see the\nRedisModule_CreateString() documentation for more info.\n\n`RedisModule_CreateStringFromString`\n\n\n```RedisModuleString *RedisModule_CreateStringFromString(RedisModuleCtx *ctx,\n                                                      const RedisModuleString *str);\n```\n\n\nAvailable since: 4.0.0\nLike RedisModule_CreateString(), but creates a string starting from another\n`RedisModuleString`.\nThe returned string must be released with RedisModule_FreeString() or by\nenabling automatic memory management.\nThe passed context 'ctx' may be NULL if necessary, see the\nRedisModule_CreateString() documentation for more info.\n\n`RedisModule_CreateStringFromStreamID`\n\n\n```RedisModuleString *RedisModule_CreateStringFromStreamID(RedisModuleCtx *ctx,\n                                                        const RedisModuleStreamID *id);\n```\n\n\nAvailable since: 6.2.0\nCreates a string from a stream ID. The returned string must be released with\nRedisModule_FreeString(), unless automatic memory is enabled.\nThe passed context `ctx` may be NULL if necessary. See the\nRedisModule_CreateString() documentation for more info.\n\n`RedisModule_FreeString`\n\n\n```void RedisModule_FreeString(RedisModuleCtx *ctx, RedisModuleString *str);\n```\n\n\nAvailable since: 4.0.0\nFree a module string object obtained with one of the Redis modules API calls\nthat return new string objects.\nIt is possible to call this function even when automatic memory management\nis enabled. In that case the string will be released ASAP and removed\nfrom the pool of string to release at the end.\nIf the string was created with a NULL context 'ctx', it is also possible to\npass ctx as NULL when releasing the string (but passing a context will not\ncreate any issue). Strings created with a context should be freed also passing\nthe context, so if you want to free a string out of context later, make sure\nto create it using a NULL context.\n\n`RedisModule_RetainString`\n\n\n```void RedisModule_RetainString(RedisModuleCtx *ctx, RedisModuleString *str);\n```\n\n\nAvailable since: 4.0.0\nEvery call to this function, will make the string 'str' requiring\nan additional call to RedisModule_FreeString() in order to really\nfree the string. Note that the automatic freeing of the string obtained\nenabling modules automatic memory management counts for one\nRedisModule_FreeString() call (it is just executed automatically).\nNormally you want to call this function when, at the same time\nthe following conditions are true:\n\nYou have automatic memory management enabled.\nYou want to create string objects.\nThose string objects you create need to live after the callback\n   function(for example a command implementation) creating them returns.\n\nUsually you want this in order to store the created string object\ninto your own data structure, for example when implementing a new data\ntype.\nNote that when memory management is turned off, you don't need\nany call to RetainString() since creating a string will always result\ninto a string that lives after the callback function returns, if\nno FreeString() call is performed.\nIt is possible to call this function with a NULL context.\nWhen strings are going to be retained for an extended duration, it is good\npractice to also call RedisModule_TrimStringAllocation() in order to\noptimize memory usage.\nThreaded modules that reference retained strings from other threads must\nexplicitly trim the allocation as soon as the string is retained. Not doing\nso may result with automatic trimming which is not thread safe.\n\n`RedisModule_HoldString`\n\n\n```RedisModuleString* RedisModule_HoldString(RedisModuleCtx *ctx,\n                                          RedisModuleString *str);\n```\n\n\nAvailable since: 6.0.7\nThis function can be used instead of RedisModule_RetainString().\nThe main difference between the two is that this function will always\nsucceed, whereas RedisModule_RetainString() may fail because of an\nassertion.\nThe function returns a pointer to `RedisModuleString`, which is owned\nby the caller. It requires a call to RedisModule_FreeString() to free\nthe string when automatic memory management is disabled for the context.\nWhen automatic memory management is enabled, you can either call\nRedisModule_FreeString() or let the automation free it.\nThis function is more efficient than RedisModule_CreateStringFromString()\nbecause whenever possible, it avoids copying the underlying\n`RedisModuleString`. The disadvantage of using this function is that it\nmight not be possible to use RedisModule_StringAppendBuffer() on the\nreturned `RedisModuleString`.\nIt is possible to call this function with a NULL context.\nWhen strings are going to be held for an extended duration, it is good\npractice to also call RedisModule_TrimStringAllocation() in order to\noptimize memory usage.\nThreaded modules that reference held strings from other threads must\nexplicitly trim the allocation as soon as the string is held. Not doing\nso may result with automatic trimming which is not thread safe.\n\n`RedisModule_StringPtrLen`\n\n\n```const char *RedisModule_StringPtrLen(const RedisModuleString *str,\n                                     size_t *len);\n```\n\n\nAvailable since: 4.0.0\nGiven a string module object, this function returns the string pointer\nand length of the string. The returned pointer and length should only\nbe used for read only accesses and never modified.\n\n`RedisModule_StringToLongLong`\n\n\n```int RedisModule_StringToLongLong(const RedisModuleString *str, long long *ll);\n```\n\n\nAvailable since: 4.0.0\nConvert the string into a `long long` integer, storing it at `*ll`.\nReturns `REDISMODULE_OK` on success. If the string can't be parsed\nas a valid, strict `long long` (no spaces before/after), `REDISMODULE_ERR`\nis returned.\n\n`RedisModule_StringToULongLong`\n\n\n```int RedisModule_StringToULongLong(const RedisModuleString *str,\n                                  unsigned long long *ull);\n```\n\n\nAvailable since: 7.0.3\nConvert the string into a `unsigned long long` integer, storing it at `*ull`.\nReturns `REDISMODULE_OK` on success. If the string can't be parsed\nas a valid, strict `unsigned long long` (no spaces before/after), `REDISMODULE_ERR`\nis returned.\n\n`RedisModule_StringToDouble`\n\n\n```int RedisModule_StringToDouble(const RedisModuleString *str, double *d);\n```\n\n\nAvailable since: 4.0.0\nConvert the string into a double, storing it at `*d`.\nReturns `REDISMODULE_OK` on success or `REDISMODULE_ERR` if the string is\nnot a valid string representation of a double value.\n\n`RedisModule_StringToLongDouble`\n\n\n```int RedisModule_StringToLongDouble(const RedisModuleString *str,\n                                   long double *ld);\n```\n\n\nAvailable since: 6.0.0\nConvert the string into a long double, storing it at `*ld`.\nReturns `REDISMODULE_OK` on success or `REDISMODULE_ERR` if the string is\nnot a valid string representation of a double value.\n\n`RedisModule_StringToStreamID`\n\n\n```int RedisModule_StringToStreamID(const RedisModuleString *str,\n                                 RedisModuleStreamID *id);\n```\n\n\nAvailable since: 6.2.0\nConvert the string into a stream ID, storing it at `*id`.\nReturns `REDISMODULE_OK` on success and returns `REDISMODULE_ERR` if the string\nis not a valid string representation of a stream ID. The special IDs \"+\" and\n\"-\" are allowed.\n\n`RedisModule_StringCompare`\n\n\n```int RedisModule_StringCompare(RedisModuleString *a, RedisModuleString *b);\n```\n\n\nAvailable since: 4.0.0\nCompare two string objects, returning -1, 0 or 1 respectively if\na < b, a == b, a > b. Strings are compared byte by byte as two\nbinary blobs without any encoding care / collation attempt.\n\n`RedisModule_StringAppendBuffer`\n\n\n```int RedisModule_StringAppendBuffer(RedisModuleCtx *ctx,\n                                   RedisModuleString *str,\n                                   const char *buf,\n                                   size_t len);\n```\n\n\nAvailable since: 4.0.0\nAppend the specified buffer to the string 'str'. The string must be a\nstring created by the user that is referenced only a single time, otherwise\n`REDISMODULE_ERR` is returned and the operation is not performed.\n\n`RedisModule_TrimStringAllocation`\n\n\n```void RedisModule_TrimStringAllocation(RedisModuleString *str);\n```\n\n\nAvailable since: 7.0.0\nTrim possible excess memory allocated for a `RedisModuleString`.\nSometimes a `RedisModuleString` may have more memory allocated for\nit than required, typically for argv arguments that were constructed\nfrom network buffers. This function optimizes such strings by reallocating\ntheir memory, which is useful for strings that are not short lived but\nretained for an extended duration.\nThis operation is not thread safe and should only be called when\nno concurrent access to the string is guaranteed. Using it for an argv\nstring in a module command before the string is potentially available\nto other threads is generally safe.\nCurrently, Redis may also automatically trim retained strings when a\nmodule command returns. However, doing this explicitly should still be\na preferred option:\n\nFuture versions of Redis may abandon auto-trimming.\nAuto-trimming as currently implemented is not thread safe.\n   A background thread manipulating a recently retained string may end up\n   in a race condition with the auto-trim, which could result with\n   data corruption.\n\n\nReply APIs\nThese functions are used for sending replies to the client.\nMost functions always return `REDISMODULE_OK` so you can use it with\n'return' in order to return from the command implementation with:\n\n\n```if (... some condition ...)\n    return RedisModule_ReplyWithLongLong(ctx,mycount);\n```\n\n\nReply with collection functions\nAfter starting a collection reply, the module must make calls to other\n`ReplyWith*` style functions in order to emit the elements of the collection.\nCollection types include: Array, Map, Set and Attribute.\nWhen producing collections with a number of elements that is not known\nbeforehand, the function can be called with a special flag\n`REDISMODULE_POSTPONED_LEN` (`REDISMODULE_POSTPONED_ARRAY_LEN` in the past),\nand the actual number of elements can be later set with `RedisModule_ReplySet`*Length()\ncall (which will set the latest \"open\" count if there are multiple ones).\n\n`RedisModule_WrongArity`\n\n\n```int RedisModule_WrongArity(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nSend an error about the number of arguments given to the command,\nciting the command name in the error message. Returns `REDISMODULE_OK`.\nExample:\n\n\n```if (argc != 3) return RedisModule_WrongArity(ctx);\n```\n\n\n\n`RedisModule_ReplyWithLongLong`\n\n\n```int RedisModule_ReplyWithLongLong(RedisModuleCtx *ctx, long long ll);\n```\n\n\nAvailable since: 4.0.0\nSend an integer reply to the client, with the specified `long long` value.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithError`\n\n\n```int RedisModule_ReplyWithError(RedisModuleCtx *ctx, const char *err);\n```\n\n\nAvailable since: 4.0.0\nReply with the error 'err'.\nNote that 'err' must contain all the error, including\nthe initial error code. The function only provides the initial \"-\", so\nthe usage is, for example:\n\n\n```RedisModule_ReplyWithError(ctx,\"ERR Wrong Type\");\n```\n\n\nand not just:\n\n\n```RedisModule_ReplyWithError(ctx,\"Wrong Type\");\n```\n\n\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithSimpleString`\n\n\n```int RedisModule_ReplyWithSimpleString(RedisModuleCtx *ctx, const char *msg);\n```\n\n\nAvailable since: 4.0.0\nReply with a simple string (`+... \\r\\n` in RESP protocol). This replies\nare suitable only when sending a small non-binary string with small\noverhead, like \"OK\" or similar replies.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithArray`\n\n\n```int RedisModule_ReplyWithArray(RedisModuleCtx *ctx, long len);\n```\n\n\nAvailable since: 4.0.0\nReply with an array type of 'len' elements.\nAfter starting an array reply, the module must make `len` calls to other\n`ReplyWith*` style functions in order to emit the elements of the array.\nSee Reply APIs section for more details.\nUse RedisModule_ReplySetArrayLength() to set deferred length.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithMap`\n\n\n```int RedisModule_ReplyWithMap(RedisModuleCtx *ctx, long len);\n```\n\n\nAvailable since: 7.0.0\nReply with a RESP3 Map type of 'len' pairs.\nVisit https://github.com/antirez/RESP3/blob/master/spec.md for more info about RESP3.\nAfter starting a map reply, the module must make `len*2` calls to other\n`ReplyWith*` style functions in order to emit the elements of the map.\nSee Reply APIs section for more details.\nIf the connected client is using RESP2, the reply will be converted to a flat\narray.\nUse RedisModule_ReplySetMapLength() to set deferred length.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithSet`\n\n\n```int RedisModule_ReplyWithSet(RedisModuleCtx *ctx, long len);\n```\n\n\nAvailable since: 7.0.0\nReply with a RESP3 Set type of 'len' elements.\nVisit https://github.com/antirez/RESP3/blob/master/spec.md for more info about RESP3.\nAfter starting a set reply, the module must make `len` calls to other\n`ReplyWith*` style functions in order to emit the elements of the set.\nSee Reply APIs section for more details.\nIf the connected client is using RESP2, the reply will be converted to an\narray type.\nUse RedisModule_ReplySetSetLength() to set deferred length.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithAttribute`\n\n\n```int RedisModule_ReplyWithAttribute(RedisModuleCtx *ctx, long len);\n```\n\n\nAvailable since: 7.0.0\nAdd attributes (metadata) to the reply. Should be done before adding the\nactual reply. see https://github.com/antirez/RESP3/blob/master/spec.md#attribute-type\nAfter starting an attribute's reply, the module must make `len*2` calls to other\n`ReplyWith*` style functions in order to emit the elements of the attribute map.\nSee Reply APIs section for more details.\nUse RedisModule_ReplySetAttributeLength() to set deferred length.\nNot supported by RESP2 and will return `REDISMODULE_ERR`, otherwise\nthe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithNullArray`\n\n\n```int RedisModule_ReplyWithNullArray(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.0.0\nReply to the client with a null array, simply null in RESP3,\nnull array in RESP2.\nNote: In RESP3 there's no difference between Null reply and\nNullArray reply, so to prevent ambiguity it's better to avoid\nusing this API and use RedisModule_ReplyWithNull instead.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithEmptyArray`\n\n\n```int RedisModule_ReplyWithEmptyArray(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.0.0\nReply to the client with an empty array.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplySetArrayLength`\n\n\n```void RedisModule_ReplySetArrayLength(RedisModuleCtx *ctx, long len);\n```\n\n\nAvailable since: 4.0.0\nWhen RedisModule_ReplyWithArray() is used with the argument\n`REDISMODULE_POSTPONED_LEN`, because we don't know beforehand the number\nof items we are going to output as elements of the array, this function\nwill take care to set the array length.\nSince it is possible to have multiple array replies pending with unknown\nlength, this function guarantees to always set the latest array length\nthat was created in a postponed way.\nFor example in order to output an array like [1,[10,20,30]] we\ncould write:\n\n\n``` RedisModule_ReplyWithArray(ctx,REDISMODULE_POSTPONED_LEN);\n RedisModule_ReplyWithLongLong(ctx,1);\n RedisModule_ReplyWithArray(ctx,REDISMODULE_POSTPONED_LEN);\n RedisModule_ReplyWithLongLong(ctx,10);\n RedisModule_ReplyWithLongLong(ctx,20);\n RedisModule_ReplyWithLongLong(ctx,30);\n RedisModule_ReplySetArrayLength(ctx,3); // Set len of 10,20,30 array.\n RedisModule_ReplySetArrayLength(ctx,2); // Set len of top array\n```\n\n\nNote that in the above example there is no reason to postpone the array\nlength, since we produce a fixed number of elements, but in the practice\nthe code may use an iterator or other ways of creating the output so\nthat is not easy to calculate in advance the number of elements.\n\n`RedisModule_ReplySetMapLength`\n\n\n```void RedisModule_ReplySetMapLength(RedisModuleCtx *ctx, long len);\n```\n\n\nAvailable since: 7.0.0\nVery similar to RedisModule_ReplySetArrayLength except `len` should\nexactly half of the number of `ReplyWith*` functions called in the\ncontext of the map.\nVisit https://github.com/antirez/RESP3/blob/master/spec.md for more info about RESP3.\n\n`RedisModule_ReplySetSetLength`\n\n\n```void RedisModule_ReplySetSetLength(RedisModuleCtx *ctx, long len);\n```\n\n\nAvailable since: 7.0.0\nVery similar to RedisModule_ReplySetArrayLength\nVisit https://github.com/antirez/RESP3/blob/master/spec.md for more info about RESP3.\n\n`RedisModule_ReplySetAttributeLength`\n\n\n```void RedisModule_ReplySetAttributeLength(RedisModuleCtx *ctx, long len);\n```\n\n\nAvailable since: 7.0.0\nVery similar to RedisModule_ReplySetMapLength\nVisit https://github.com/antirez/RESP3/blob/master/spec.md for more info about RESP3.\nMust not be called if RedisModule_ReplyWithAttribute returned an error.\n\n`RedisModule_ReplyWithStringBuffer`\n\n\n```int RedisModule_ReplyWithStringBuffer(RedisModuleCtx *ctx,\n                                      const char *buf,\n                                      size_t len);\n```\n\n\nAvailable since: 4.0.0\nReply with a bulk string, taking in input a C buffer pointer and length.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithCString`\n\n\n```int RedisModule_ReplyWithCString(RedisModuleCtx *ctx, const char *buf);\n```\n\n\nAvailable since: 5.0.6\nReply with a bulk string, taking in input a C buffer pointer that is\nassumed to be null-terminated.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithString`\n\n\n```int RedisModule_ReplyWithString(RedisModuleCtx *ctx, RedisModuleString *str);\n```\n\n\nAvailable since: 4.0.0\nReply with a bulk string, taking in input a `RedisModuleString` object.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithEmptyString`\n\n\n```int RedisModule_ReplyWithEmptyString(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.0.0\nReply with an empty string.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithVerbatimStringType`\n\n\n```int RedisModule_ReplyWithVerbatimStringType(RedisModuleCtx *ctx,\n                                            const char *buf,\n                                            size_t len,\n                                            const char *ext);\n```\n\n\nAvailable since: 7.0.0\nReply with a binary safe string, which should not be escaped or filtered\ntaking in input a C buffer pointer, length and a 3 character type/extension.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithVerbatimString`\n\n\n```int RedisModule_ReplyWithVerbatimString(RedisModuleCtx *ctx,\n                                        const char *buf,\n                                        size_t len);\n```\n\n\nAvailable since: 6.0.0\nReply with a binary safe string, which should not be escaped or filtered\ntaking in input a C buffer pointer and length.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithNull`\n\n\n```int RedisModule_ReplyWithNull(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nReply to the client with a NULL.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithBool`\n\n\n```int RedisModule_ReplyWithBool(RedisModuleCtx *ctx, int b);\n```\n\n\nAvailable since: 7.0.0\nReply with a RESP3 Boolean type.\nVisit https://github.com/antirez/RESP3/blob/master/spec.md for more info about RESP3.\nIn RESP3, this is boolean type\nIn RESP2, it's a string response of \"1\" and \"0\" for true and false respectively.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithCallReply`\n\n\n```int RedisModule_ReplyWithCallReply(RedisModuleCtx *ctx,\n                                   RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 4.0.0\nReply exactly what a Redis command returned us with RedisModule_Call().\nThis function is useful when we use RedisModule_Call() in order to\nexecute some command, as we want to reply to the client exactly the\nsame reply we obtained by the command.\nReturn:\n- `REDISMODULE_OK` on success.\n- `REDISMODULE_ERR` if the given reply is in RESP3 format but the client expects RESP2.\n  In case of an error, it's the module writer responsibility to translate the reply\n  to RESP2 (or handle it differently by returning an error). Notice that for\n  module writer convenience, it is possible to pass `0` as a parameter to the fmt\n  argument of RedisModule_Call so that the `RedisModuleCallReply` will return in the same\n  protocol (RESP2 or RESP3) as set in the current client's context.\n\n`RedisModule_ReplyWithDouble`\n\n\n```int RedisModule_ReplyWithDouble(RedisModuleCtx *ctx, double d);\n```\n\n\nAvailable since: 4.0.0\nReply with a RESP3 Double type.\nVisit https://github.com/antirez/RESP3/blob/master/spec.md for more info about RESP3.\nSend a string reply obtained converting the double 'd' into a bulk string.\nThis function is basically equivalent to converting a double into\na string into a C buffer, and then calling the function\nRedisModule_ReplyWithStringBuffer() with the buffer and length.\nIn RESP3 the string is tagged as a double, while in RESP2 it's just a plain string \nthat the user will have to parse.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithBigNumber`\n\n\n```int RedisModule_ReplyWithBigNumber(RedisModuleCtx *ctx,\n                                   const char *bignum,\n                                   size_t len);\n```\n\n\nAvailable since: 7.0.0\nReply with a RESP3 BigNumber type.\nVisit https://github.com/antirez/RESP3/blob/master/spec.md for more info about RESP3.\nIn RESP3, this is a string of length `len` that is tagged as a BigNumber, \nhowever, it's up to the caller to ensure that it's a valid BigNumber.\nIn RESP2, this is just a plain bulk string response.\nThe function always returns `REDISMODULE_OK`.\n\n`RedisModule_ReplyWithLongDouble`\n\n\n```int RedisModule_ReplyWithLongDouble(RedisModuleCtx *ctx, long double ld);\n```\n\n\nAvailable since: 6.0.0\nSend a string reply obtained converting the long double 'ld' into a bulk\nstring. This function is basically equivalent to converting a long double\ninto a string into a C buffer, and then calling the function\nRedisModule_ReplyWithStringBuffer() with the buffer and length.\nThe double string uses human readable formatting (see\n`addReplyHumanLongDouble` in networking.c).\nThe function always returns `REDISMODULE_OK`.\n\nCommands replication API\n\n`RedisModule_Replicate`\n\n\n```int RedisModule_Replicate(RedisModuleCtx *ctx,\n                          const char *cmdname,\n                          const char *fmt,\n                          ...);\n```\n\n\nAvailable since: 4.0.0\nReplicate the specified command and arguments to slaves and AOF, as effect\nof execution of the calling command implementation.\nThe replicated commands are always wrapped into the MULTI/EXEC that\ncontains all the commands replicated in a given module command\nexecution. However the commands replicated with RedisModule_Call()\nare the first items, the ones replicated with RedisModule_Replicate()\nwill all follow before the EXEC.\nModules should try to use one interface or the other.\nThis command follows exactly the same interface of RedisModule_Call(),\nso a set of format specifiers must be passed, followed by arguments\nmatching the provided format specifiers.\nPlease refer to RedisModule_Call() for more information.\nUsing the special \"A\" and \"R\" modifiers, the caller can exclude either\nthe AOF or the replicas from the propagation of the specified command.\nOtherwise, by default, the command will be propagated in both channels.\nNote about calling this function from a thread safe context:\nNormally when you call this function from the callback implementing a\nmodule command, or any other callback provided by the Redis Module API,\nRedis will accumulate all the calls to this function in the context of\nthe callback, and will propagate all the commands wrapped in a MULTI/EXEC\ntransaction. However when calling this function from a threaded safe context\nthat can live an undefined amount of time, and can be locked/unlocked in\nat will, the behavior is different: MULTI/EXEC wrapper is not emitted\nand the command specified is inserted in the AOF and replication stream\nimmediately.\nReturn value\nThe command returns `REDISMODULE_ERR` if the format specifiers are invalid\nor the command name does not belong to a known command.\n\n`RedisModule_ReplicateVerbatim`\n\n\n```int RedisModule_ReplicateVerbatim(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nThis function will replicate the command exactly as it was invoked\nby the client. Note that this function will not wrap the command into\na MULTI/EXEC stanza, so it should not be mixed with other replication\ncommands.\nBasically this form of replication is useful when you want to propagate\nthe command to the slaves and AOF file exactly as it was called, since\nthe command can just be re-executed to deterministically re-create the\nnew state starting from the old one.\nThe function always returns `REDISMODULE_OK`.\n\nDB and Key APIs \u2013 Generic API\n\n`RedisModule_GetClientId`\n\n\n```unsigned long long RedisModule_GetClientId(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nReturn the ID of the current client calling the currently active module\ncommand. The returned ID has a few guarantees:\n\nThe ID is different for each different client, so if the same client\n   executes a module command multiple times, it can be recognized as\n   having the same ID, otherwise the ID will be different.\nThe ID increases monotonically. Clients connecting to the server later\n   are guaranteed to get IDs greater than any past ID previously seen.\n\nValid IDs are from 1 to 2^64 - 1. If 0 is returned it means there is no way\nto fetch the ID in the context the function was currently called.\nAfter obtaining the ID, it is possible to check if the command execution\nis actually happening in the context of AOF loading, using this macro:\n\n\n``` if (RedisModule_IsAOFClient(RedisModule_GetClientId(ctx)) {\n     // Handle it differently.\n }\n```\n\n\n\n`RedisModule_GetClientUserNameById`\n\n\n```RedisModuleString *RedisModule_GetClientUserNameById(RedisModuleCtx *ctx,\n                                                     uint64_t id);\n```\n\n\nAvailable since: 6.2.1\nReturn the ACL user name used by the client with the specified client ID.\nClient ID can be obtained with RedisModule_GetClientId() API. If the client does not\nexist, NULL is returned and errno is set to ENOENT. If the client isn't\nusing an ACL user, NULL is returned and errno is set to ENOTSUP\n\n`RedisModule_GetClientInfoById`\n\n\n```int RedisModule_GetClientInfoById(void *ci, uint64_t id);\n```\n\n\nAvailable since: 6.0.0\nReturn information about the client with the specified ID (that was\npreviously obtained via the RedisModule_GetClientId() API). If the\nclient exists, `REDISMODULE_OK` is returned, otherwise `REDISMODULE_ERR`\nis returned.\nWhen the client exist and the `ci` pointer is not NULL, but points to\na structure of type `RedisModuleClientInfoV`1, previously initialized with\nthe correct `REDISMODULE_CLIENTINFO_INITIALIZER_V1`, the structure is populated\nwith the following fields:\n\n\n``` uint64_t flags;         // REDISMODULE_CLIENTINFO_FLAG_*\n uint64_t id;            // Client ID\n char addr[46];          // IPv4 or IPv6 address.\n uint16_t port;          // TCP port.\n uint16_t db;            // Selected DB.\n```\n\n\nNote: the client ID is useless in the context of this call, since we\n      already know, however the same structure could be used in other\n      contexts where we don't know the client ID, yet the same structure\n      is returned.\nWith flags having the following meaning:\n\n\n```REDISMODULE_CLIENTINFO_FLAG_SSL          Client using SSL connection.\nREDISMODULE_CLIENTINFO_FLAG_PUBSUB       Client in Pub/Sub mode.\nREDISMODULE_CLIENTINFO_FLAG_BLOCKED      Client blocked in command.\nREDISMODULE_CLIENTINFO_FLAG_TRACKING     Client with keys tracking on.\nREDISMODULE_CLIENTINFO_FLAG_UNIXSOCKET   Client using unix domain socket.\nREDISMODULE_CLIENTINFO_FLAG_MULTI        Client in MULTI state.\n```\n\n\nHowever passing NULL is a way to just check if the client exists in case\nwe are not interested in any additional information.\nThis is the correct usage when we want the client info structure\nreturned:\n\n\n``` RedisModuleClientInfo ci = REDISMODULE_CLIENTINFO_INITIALIZER;\n int retval = RedisModule_GetClientInfoById(&ci,client_id);\n if (retval == REDISMODULE_OK) {\n     printf(\"Address: %s\\n\", ci.addr);\n }\n```\n\n\n\n`RedisModule_GetClientNameById`\n\n\n```RedisModuleString *RedisModule_GetClientNameById(RedisModuleCtx *ctx,\n                                                 uint64_t id);\n```\n\n\nAvailable since: 7.0.3\nReturns the name of the client connection with the given ID.\nIf the client ID does not exist or if the client has no name associated with\nit, NULL is returned.\n\n`RedisModule_SetClientNameById`\n\n\n```int RedisModule_SetClientNameById(uint64_t id, RedisModuleString *name);\n```\n\n\nAvailable since: 7.0.3\nSets the name of the client with the given ID. This is equivalent to the client calling\n`CLIENT SETNAME name`.\nReturns `REDISMODULE_OK` on success. On failure, `REDISMODULE_ERR` is returned\nand errno is set as follows:\n\nENOENT if the client does not exist\nEINVAL if the name contains invalid characters\n\n\n`RedisModule_PublishMessage`\n\n\n```int RedisModule_PublishMessage(RedisModuleCtx *ctx,\n                               RedisModuleString *channel,\n                               RedisModuleString *message);\n```\n\n\nAvailable since: 6.0.0\nPublish a message to subscribers (see PUBLISH command).\n\n`RedisModule_PublishMessageShard`\n\n\n```int RedisModule_PublishMessageShard(RedisModuleCtx *ctx,\n                                    RedisModuleString *channel,\n                                    RedisModuleString *message);\n```\n\n\nAvailable since: 7.0.0\nPublish a message to shard-subscribers (see SPUBLISH command).\n\n`RedisModule_GetSelectedDb`\n\n\n```int RedisModule_GetSelectedDb(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nReturn the currently selected DB.\n\n`RedisModule_GetContextFlags`\n\n\n```int RedisModule_GetContextFlags(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.3\nReturn the current context's flags. The flags provide information on the\ncurrent request context (whether the client is a Lua script or in a MULTI),\nand about the Redis instance in general, i.e replication and persistence.\nIt is possible to call this function even with a NULL context, however\nin this case the following flags will not be reported:\n\nLUA, MULTI, REPLICATED, DIRTY (see below for more info).\n\nAvailable flags and their meaning:\n\n\n`REDISMODULE_CTX_FLAGS_LUA`: The command is running in a Lua script\n\n\n`REDISMODULE_CTX_FLAGS_MULTI`: The command is running inside a transaction\n\n\n`REDISMODULE_CTX_FLAGS_REPLICATED`: The command was sent over the replication\n   link by the MASTER\n\n\n`REDISMODULE_CTX_FLAGS_MASTER`: The Redis instance is a master\n\n\n`REDISMODULE_CTX_FLAGS_SLAVE`: The Redis instance is a slave\n\n\n`REDISMODULE_CTX_FLAGS_READONLY`: The Redis instance is read-only\n\n\n`REDISMODULE_CTX_FLAGS_CLUSTER`: The Redis instance is in cluster mode\n\n\n`REDISMODULE_CTX_FLAGS_AOF`: The Redis instance has AOF enabled\n\n\n`REDISMODULE_CTX_FLAGS_RDB`: The instance has RDB enabled\n\n\n`REDISMODULE_CTX_FLAGS_MAXMEMORY`:  The instance has Maxmemory set\n\n\n`REDISMODULE_CTX_FLAGS_EVICT`:  Maxmemory is set and has an eviction\n   policy that may delete keys\n\n\n`REDISMODULE_CTX_FLAGS_OOM`: Redis is out of memory according to the\n   maxmemory setting.\n\n\n`REDISMODULE_CTX_FLAGS_OOM_WARNING`: Less than 25% of memory remains before\n                                      reaching the maxmemory level.\n\n\n`REDISMODULE_CTX_FLAGS_LOADING`: Server is loading RDB/AOF\n\n\n`REDISMODULE_CTX_FLAGS_REPLICA_IS_STALE`: No active link with the master.\n\n\n`REDISMODULE_CTX_FLAGS_REPLICA_IS_CONNECTING`: The replica is trying to\n                                                connect with the master.\n\n\n`REDISMODULE_CTX_FLAGS_REPLICA_IS_TRANSFERRING`: Master -> Replica RDB\n                                                  transfer is in progress.\n\n\n`REDISMODULE_CTX_FLAGS_REPLICA_IS_ONLINE`: The replica has an active link\n                                            with its master. This is the\n                                            contrary of STALE state.\n\n\n`REDISMODULE_CTX_FLAGS_ACTIVE_CHILD`: There is currently some background\n                                       process active (RDB, AUX or module).\n\n\n`REDISMODULE_CTX_FLAGS_MULTI_DIRTY`: The next EXEC will fail due to dirty\n                                      CAS (touched keys).\n\n\n`REDISMODULE_CTX_FLAGS_IS_CHILD`: Redis is currently running inside\n                                   background child process.\n\n\n`REDISMODULE_CTX_FLAGS_RESP3`: Indicate the that client attached to this\n                                context is using RESP3.\n\n\n\n`RedisModule_AvoidReplicaTraffic`\n\n\n```int RedisModule_AvoidReplicaTraffic();\n```\n\n\nAvailable since: 6.0.0\nReturns true if a client sent the CLIENT PAUSE command to the server or\nif Redis Cluster does a manual failover, pausing the clients.\nThis is needed when we have a master with replicas, and want to write,\nwithout adding further data to the replication channel, that the replicas\nreplication offset, match the one of the master. When this happens, it is\nsafe to failover the master without data loss.\nHowever modules may generate traffic by calling RedisModule_Call() with\nthe \"!\" flag, or by calling RedisModule_Replicate(), in a context outside\ncommands execution, for instance in timeout callbacks, threads safe\ncontexts, and so forth. When modules will generate too much traffic, it\nwill be hard for the master and replicas offset to match, because there\nis more data to send in the replication channel.\nSo modules may want to try to avoid very heavy background work that has\nthe effect of creating data to the replication channel, when this function\nreturns true. This is mostly useful for modules that have background\ngarbage collection tasks, or that do writes and replicate such writes\nperiodically in timer callbacks or other periodic callbacks.\n\n`RedisModule_SelectDb`\n\n\n```int RedisModule_SelectDb(RedisModuleCtx *ctx, int newid);\n```\n\n\nAvailable since: 4.0.0\nChange the currently selected DB. Returns an error if the id\nis out of range.\nNote that the client will retain the currently selected DB even after\nthe Redis command implemented by the module calling this function\nreturns.\nIf the module command wishes to change something in a different DB and\nreturns back to the original one, it should call RedisModule_GetSelectedDb()\nbefore in order to restore the old DB number before returning.\n\n`RedisModule_KeyExists`\n\n\n```int RedisModule_KeyExists(RedisModuleCtx *ctx, robj *keyname);\n```\n\n\nAvailable since: 7.0.0\nCheck if a key exists, without affecting its last access time.\nThis is equivalent to calling RedisModule_OpenKey with the mode `REDISMODULE_READ` |\n`REDISMODULE_OPEN_KEY_NOTOUCH`, then checking if NULL was returned and, if not,\ncalling RedisModule_CloseKey on the opened key.\n\n`RedisModule_OpenKey`\n\n\n```RedisModuleKey *RedisModule_OpenKey(RedisModuleCtx *ctx,\n                                    robj *keyname,\n                                    int mode);\n```\n\n\nAvailable since: 4.0.0\nReturn a handle representing a Redis key, so that it is possible\nto call other APIs with the key handle as argument to perform\noperations on the key.\nThe return value is the handle representing the key, that must be\nclosed with RedisModule_CloseKey().\nIf the key does not exist and WRITE mode is requested, the handle\nis still returned, since it is possible to perform operations on\na yet not existing key (that will be created, for example, after\na list push operation). If the mode is just READ instead, and the\nkey does not exist, NULL is returned. However it is still safe to\ncall RedisModule_CloseKey() and RedisModule_KeyType() on a NULL\nvalue.\n\n`RedisModule_CloseKey`\n\n\n```void RedisModule_CloseKey(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nClose a key handle.\n\n`RedisModule_KeyType`\n\n\n```int RedisModule_KeyType(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nReturn the type of the key. If the key pointer is NULL then\n`REDISMODULE_KEYTYPE_EMPTY` is returned.\n\n`RedisModule_ValueLength`\n\n\n```size_t RedisModule_ValueLength(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nReturn the length of the value associated with the key.\nFor strings this is the length of the string. For all the other types\nis the number of elements (just counting keys for hashes).\nIf the key pointer is NULL or the key is empty, zero is returned.\n\n`RedisModule_DeleteKey`\n\n\n```int RedisModule_DeleteKey(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nIf the key is open for writing, remove it, and setup the key to\naccept new writes as an empty key (that will be created on demand).\nOn success `REDISMODULE_OK` is returned. If the key is not open for\nwriting `REDISMODULE_ERR` is returned.\n\n`RedisModule_UnlinkKey`\n\n\n```int RedisModule_UnlinkKey(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.7\nIf the key is open for writing, unlink it (that is delete it in a\nnon-blocking way, not reclaiming memory immediately) and setup the key to\naccept new writes as an empty key (that will be created on demand).\nOn success `REDISMODULE_OK` is returned. If the key is not open for\nwriting `REDISMODULE_ERR` is returned.\n\n`RedisModule_GetExpire`\n\n\n```mstime_t RedisModule_GetExpire(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nReturn the key expire value, as milliseconds of remaining TTL.\nIf no TTL is associated with the key or if the key is empty,\n`REDISMODULE_NO_EXPIRE` is returned.\n\n`RedisModule_SetExpire`\n\n\n```int RedisModule_SetExpire(RedisModuleKey *key, mstime_t expire);\n```\n\n\nAvailable since: 4.0.0\nSet a new expire for the key. If the special expire\n`REDISMODULE_NO_EXPIRE` is set, the expire is cancelled if there was\none (the same as the PERSIST command).\nNote that the expire must be provided as a positive integer representing\nthe number of milliseconds of TTL the key should have.\nThe function returns `REDISMODULE_OK` on success or `REDISMODULE_ERR` if\nthe key was not open for writing or is an empty key.\n\n`RedisModule_GetAbsExpire`\n\n\n```mstime_t RedisModule_GetAbsExpire(RedisModuleKey *key);\n```\n\n\nAvailable since: 6.2.2\nReturn the key expire value, as absolute Unix timestamp.\nIf no TTL is associated with the key or if the key is empty,\n`REDISMODULE_NO_EXPIRE` is returned.\n\n`RedisModule_SetAbsExpire`\n\n\n```int RedisModule_SetAbsExpire(RedisModuleKey *key, mstime_t expire);\n```\n\n\nAvailable since: 6.2.2\nSet a new expire for the key. If the special expire\n`REDISMODULE_NO_EXPIRE` is set, the expire is cancelled if there was\none (the same as the PERSIST command).\nNote that the expire must be provided as a positive integer representing\nthe absolute Unix timestamp the key should have.\nThe function returns `REDISMODULE_OK` on success or `REDISMODULE_ERR` if\nthe key was not open for writing or is an empty key.\n\n`RedisModule_ResetDataset`\n\n\n```void RedisModule_ResetDataset(int restart_aof, int async);\n```\n\n\nAvailable since: 6.0.0\nPerforms similar operation to FLUSHALL, and optionally start a new AOF file (if enabled)\nIf `restart_aof` is true, you must make sure the command that triggered this call is not\npropagated to the AOF file.\nWhen async is set to true, db contents will be freed by a background thread.\n\n`RedisModule_DbSize`\n\n\n```unsigned long long RedisModule_DbSize(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.0.0\nReturns the number of keys in the current db.\n\n`RedisModule_RandomKey`\n\n\n```RedisModuleString *RedisModule_RandomKey(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.0.0\nReturns a name of a random key, or NULL if current db is empty.\n\n`RedisModule_GetKeyNameFromOptCtx`\n\n\n```const RedisModuleString *RedisModule_GetKeyNameFromOptCtx(RedisModuleKeyOptCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nReturns the name of the key currently being processed.\n\n`RedisModule_GetToKeyNameFromOptCtx`\n\n\n```const RedisModuleString *RedisModule_GetToKeyNameFromOptCtx(RedisModuleKeyOptCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nReturns the name of the target key currently being processed.\n\n`RedisModule_GetDbIdFromOptCtx`\n\n\n```int RedisModule_GetDbIdFromOptCtx(RedisModuleKeyOptCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nReturns the dbid currently being processed.\n\n`RedisModule_GetToDbIdFromOptCtx`\n\n\n```int RedisModule_GetToDbIdFromOptCtx(RedisModuleKeyOptCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nReturns the target dbid currently being processed.\n\nKey API for String type\nSee also RedisModule_ValueLength(), which returns the length of a string.\n\n`RedisModule_StringSet`\n\n\n```int RedisModule_StringSet(RedisModuleKey *key, RedisModuleString *str);\n```\n\n\nAvailable since: 4.0.0\nIf the key is open for writing, set the specified string 'str' as the\nvalue of the key, deleting the old value if any.\nOn success `REDISMODULE_OK` is returned. If the key is not open for\nwriting or there is an active iterator, `REDISMODULE_ERR` is returned.\n\n`RedisModule_StringDMA`\n\n\n```char *RedisModule_StringDMA(RedisModuleKey *key, size_t *len, int mode);\n```\n\n\nAvailable since: 4.0.0\nPrepare the key associated string value for DMA access, and returns\na pointer and size (by reference), that the user can use to read or\nmodify the string in-place accessing it directly via pointer.\nThe 'mode' is composed by bitwise OR-ing the following flags:\n\n\n```REDISMODULE_READ -- Read access\nREDISMODULE_WRITE -- Write access\n```\n\n\nIf the DMA is not requested for writing, the pointer returned should\nonly be accessed in a read-only fashion.\nOn error (wrong type) NULL is returned.\nDMA access rules:\n\n\nNo other key writing function should be called since the moment\nthe pointer is obtained, for all the time we want to use DMA access\nto read or modify the string.\n\n\nEach time RedisModule_StringTruncate() is called, to continue with the DMA\naccess, RedisModule_StringDMA() should be called again to re-obtain\na new pointer and length.\n\n\nIf the returned pointer is not NULL, but the length is zero, no\nbyte can be touched (the string is empty, or the key itself is empty)\nso a RedisModule_StringTruncate() call should be used if there is to enlarge\nthe string, and later call StringDMA() again to get the pointer.\n\n\n\n`RedisModule_StringTruncate`\n\n\n```int RedisModule_StringTruncate(RedisModuleKey *key, size_t newlen);\n```\n\n\nAvailable since: 4.0.0\nIf the key is open for writing and is of string type, resize it, padding\nwith zero bytes if the new length is greater than the old one.\nAfter this call, RedisModule_StringDMA() must be called again to continue\nDMA access with the new pointer.\nThe function returns `REDISMODULE_OK` on success, and `REDISMODULE_ERR` on\nerror, that is, the key is not open for writing, is not a string\nor resizing for more than 512 MB is requested.\nIf the key is empty, a string key is created with the new string value\nunless the new length value requested is zero.\n\nKey API for List type\nMany of the list functions access elements by index. Since a list is in\nessence a doubly-linked list, accessing elements by index is generally an\nO(N) operation. However, if elements are accessed sequentially or with\nindices close together, the functions are optimized to seek the index from\nthe previous index, rather than seeking from the ends of the list.\nThis enables iteration to be done efficiently using a simple for loop:\n\n\n```long n = RedisModule_ValueLength(key);\nfor (long i = 0; i < n; i++) {\n    RedisModuleString *elem = RedisModule_ListGet(key, i);\n    // Do stuff...\n}\n```\n\n\nNote that after modifying a list using RedisModule_ListPop, RedisModule_ListSet or\nRedisModule_ListInsert, the internal iterator is invalidated so the next operation\nwill require a linear seek.\nModifying a list in any another way, for example using RedisModule_Call(), while a key\nis open will confuse the internal iterator and may cause trouble if the key\nis used after such modifications. The key must be reopened in this case.\nSee also RedisModule_ValueLength(), which returns the length of a list.\n\n`RedisModule_ListPush`\n\n\n```int RedisModule_ListPush(RedisModuleKey *key,\n                         int where,\n                         RedisModuleString *ele);\n```\n\n\nAvailable since: 4.0.0\nPush an element into a list, on head or tail depending on 'where' argument\n(`REDISMODULE_LIST_HEAD` or `REDISMODULE_LIST_TAIL`). If the key refers to an\nempty key opened for writing, the key is created. On success, `REDISMODULE_OK`\nis returned. On failure, `REDISMODULE_ERR` is returned and `errno` is set as\nfollows:\n\nEINVAL if key or ele is NULL.\nENOTSUP if the key is of another type than list.\nEBADF if the key is not opened for writing.\n\nNote: Before Redis 7.0, `errno` was not set by this function.\n\n`RedisModule_ListPop`\n\n\n```RedisModuleString *RedisModule_ListPop(RedisModuleKey *key, int where);\n```\n\n\nAvailable since: 4.0.0\nPop an element from the list, and returns it as a module string object\nthat the user should be free with RedisModule_FreeString() or by enabling\nautomatic memory. The `where` argument specifies if the element should be\npopped from the beginning or the end of the list (`REDISMODULE_LIST_HEAD` or\n`REDISMODULE_LIST_TAIL`). On failure, the command returns NULL and sets\n`errno` as follows:\n\nEINVAL if key is NULL.\nENOTSUP if the key is empty or of another type than list.\nEBADF if the key is not opened for writing.\n\nNote: Before Redis 7.0, `errno` was not set by this function.\n\n`RedisModule_ListGet`\n\n\n```RedisModuleString *RedisModule_ListGet(RedisModuleKey *key, long index);\n```\n\n\nAvailable since: 7.0.0\nReturns the element at index `index` in the list stored at `key`, like the\nLINDEX command. The element should be free'd using RedisModule_FreeString() or using\nautomatic memory management.\nThe index is zero-based, so 0 means the first element, 1 the second element\nand so on. Negative indices can be used to designate elements starting at the\ntail of the list. Here, -1 means the last element, -2 means the penultimate\nand so forth.\nWhen no value is found at the given key and index, NULL is returned and\n`errno` is set as follows:\n\nEINVAL if key is NULL.\nENOTSUP if the key is not a list.\nEBADF if the key is not opened for reading.\nEDOM if the index is not a valid index in the list.\n\n\n`RedisModule_ListSet`\n\n\n```int RedisModule_ListSet(RedisModuleKey *key,\n                        long index,\n                        RedisModuleString *value);\n```\n\n\nAvailable since: 7.0.0\nReplaces the element at index `index` in the list stored at `key`.\nThe index is zero-based, so 0 means the first element, 1 the second element\nand so on. Negative indices can be used to designate elements starting at the\ntail of the list. Here, -1 means the last element, -2 means the penultimate\nand so forth.\nOn success, `REDISMODULE_OK` is returned. On failure, `REDISMODULE_ERR` is\nreturned and `errno` is set as follows:\n\nEINVAL if key or value is NULL.\nENOTSUP if the key is not a list.\nEBADF if the key is not opened for writing.\nEDOM if the index is not a valid index in the list.\n\n\n`RedisModule_ListInsert`\n\n\n```int RedisModule_ListInsert(RedisModuleKey *key,\n                           long index,\n                           RedisModuleString *value);\n```\n\n\nAvailable since: 7.0.0\nInserts an element at the given index.\nThe index is zero-based, so 0 means the first element, 1 the second element\nand so on. Negative indices can be used to designate elements starting at the\ntail of the list. Here, -1 means the last element, -2 means the penultimate\nand so forth. The index is the element's index after inserting it.\nOn success, `REDISMODULE_OK` is returned. On failure, `REDISMODULE_ERR` is\nreturned and `errno` is set as follows:\n\nEINVAL if key or value is NULL.\nENOTSUP if the key of another type than list.\nEBADF if the key is not opened for writing.\nEDOM if the index is not a valid index in the list.\n\n\n`RedisModule_ListDelete`\n\n\n```int RedisModule_ListDelete(RedisModuleKey *key, long index);\n```\n\n\nAvailable since: 7.0.0\nRemoves an element at the given index. The index is 0-based. A negative index\ncan also be used, counting from the end of the list.\nOn success, `REDISMODULE_OK` is returned. On failure, `REDISMODULE_ERR` is\nreturned and `errno` is set as follows:\n\nEINVAL if key or value is NULL.\nENOTSUP if the key is not a list.\nEBADF if the key is not opened for writing.\nEDOM if the index is not a valid index in the list.\n\n\nKey API for Sorted Set type\nSee also RedisModule_ValueLength(), which returns the length of a sorted set.\n\n`RedisModule_ZsetAdd`\n\n\n```int RedisModule_ZsetAdd(RedisModuleKey *key,\n                        double score,\n                        RedisModuleString *ele,\n                        int *flagsptr);\n```\n\n\nAvailable since: 4.0.0\nAdd a new element into a sorted set, with the specified 'score'.\nIf the element already exists, the score is updated.\nA new sorted set is created at value if the key is an empty open key\nsetup for writing.\nAdditional flags can be passed to the function via a pointer, the flags\nare both used to receive input and to communicate state when the function\nreturns. 'flagsptr' can be NULL if no special flags are used.\nThe input flags are:\n\n\n```REDISMODULE_ZADD_XX: Element must already exist. Do nothing otherwise.\nREDISMODULE_ZADD_NX: Element must not exist. Do nothing otherwise.\nREDISMODULE_ZADD_GT: If element exists, new score must be greater than the current score. \n                     Do nothing otherwise. Can optionally be combined with XX.\nREDISMODULE_ZADD_LT: If element exists, new score must be less than the current score.\n                     Do nothing otherwise. Can optionally be combined with XX.\n```\n\n\nThe output flags are:\n\n\n```REDISMODULE_ZADD_ADDED: The new element was added to the sorted set.\nREDISMODULE_ZADD_UPDATED: The score of the element was updated.\nREDISMODULE_ZADD_NOP: No operation was performed because XX or NX flags.\n```\n\n\nOn success the function returns `REDISMODULE_OK`. On the following errors\n`REDISMODULE_ERR` is returned:\n\nThe key was not opened for writing.\nThe key is of the wrong type.\n'score' double value is not a number (NaN).\n\n\n`RedisModule_ZsetIncrby`\n\n\n```int RedisModule_ZsetIncrby(RedisModuleKey *key,\n                           double score,\n                           RedisModuleString *ele,\n                           int *flagsptr,\n                           double *newscore);\n```\n\n\nAvailable since: 4.0.0\nThis function works exactly like RedisModule_ZsetAdd(), but instead of setting\na new score, the score of the existing element is incremented, or if the\nelement does not already exist, it is added assuming the old score was\nzero.\nThe input and output flags, and the return value, have the same exact\nmeaning, with the only difference that this function will return\n`REDISMODULE_ERR` even when 'score' is a valid double number, but adding it\nto the existing score results into a NaN (not a number) condition.\nThis function has an additional field 'newscore', if not NULL is filled\nwith the new score of the element after the increment, if no error\nis returned.\n\n`RedisModule_ZsetRem`\n\n\n```int RedisModule_ZsetRem(RedisModuleKey *key,\n                        RedisModuleString *ele,\n                        int *deleted);\n```\n\n\nAvailable since: 4.0.0\nRemove the specified element from the sorted set.\nThe function returns `REDISMODULE_OK` on success, and `REDISMODULE_ERR`\non one of the following conditions:\n\nThe key was not opened for writing.\nThe key is of the wrong type.\n\nThe return value does NOT indicate the fact the element was really\nremoved (since it existed) or not, just if the function was executed\nwith success.\nIn order to know if the element was removed, the additional argument\n'deleted' must be passed, that populates the integer by reference\nsetting it to 1 or 0 depending on the outcome of the operation.\nThe 'deleted' argument can be NULL if the caller is not interested\nto know if the element was really removed.\nEmpty keys will be handled correctly by doing nothing.\n\n`RedisModule_ZsetScore`\n\n\n```int RedisModule_ZsetScore(RedisModuleKey *key,\n                          RedisModuleString *ele,\n                          double *score);\n```\n\n\nAvailable since: 4.0.0\nOn success retrieve the double score associated at the sorted set element\n'ele' and returns `REDISMODULE_OK`. Otherwise `REDISMODULE_ERR` is returned\nto signal one of the following conditions:\n\nThere is no such element 'ele' in the sorted set.\nThe key is not a sorted set.\nThe key is an open empty key.\n\n\nKey API for Sorted Set iterator\n\n`RedisModule_ZsetRangeStop`\n\n\n```void RedisModule_ZsetRangeStop(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nStop a sorted set iteration.\n\n`RedisModule_ZsetRangeEndReached`\n\n\n```int RedisModule_ZsetRangeEndReached(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nReturn the \"End of range\" flag value to signal the end of the iteration.\n\n`RedisModule_ZsetFirstInScoreRange`\n\n\n```int RedisModule_ZsetFirstInScoreRange(RedisModuleKey *key,\n                                      double min,\n                                      double max,\n                                      int minex,\n                                      int maxex);\n```\n\n\nAvailable since: 4.0.0\nSetup a sorted set iterator seeking the first element in the specified\nrange. Returns `REDISMODULE_OK` if the iterator was correctly initialized\notherwise `REDISMODULE_ERR` is returned in the following conditions:\n\nThe value stored at key is not a sorted set or the key is empty.\n\nThe range is specified according to the two double values 'min' and 'max'.\nBoth can be infinite using the following two macros:\n\n`REDISMODULE_POSITIVE_INFINITE` for positive infinite value\n`REDISMODULE_NEGATIVE_INFINITE` for negative infinite value\n\n'minex' and 'maxex' parameters, if true, respectively setup a range\nwhere the min and max value are exclusive (not included) instead of\ninclusive.\n\n`RedisModule_ZsetLastInScoreRange`\n\n\n```int RedisModule_ZsetLastInScoreRange(RedisModuleKey *key,\n                                     double min,\n                                     double max,\n                                     int minex,\n                                     int maxex);\n```\n\n\nAvailable since: 4.0.0\nExactly like RedisModule_ZsetFirstInScoreRange() but the last element of\nthe range is selected for the start of the iteration instead.\n\n`RedisModule_ZsetFirstInLexRange`\n\n\n```int RedisModule_ZsetFirstInLexRange(RedisModuleKey *key,\n                                    RedisModuleString *min,\n                                    RedisModuleString *max);\n```\n\n\nAvailable since: 4.0.0\nSetup a sorted set iterator seeking the first element in the specified\nlexicographical range. Returns `REDISMODULE_OK` if the iterator was correctly\ninitialized otherwise `REDISMODULE_ERR` is returned in the\nfollowing conditions:\n\nThe value stored at key is not a sorted set or the key is empty.\nThe lexicographical range 'min' and 'max' format is invalid.\n\n'min' and 'max' should be provided as two `RedisModuleString` objects\nin the same format as the parameters passed to the ZRANGEBYLEX command.\nThe function does not take ownership of the objects, so they can be released\nASAP after the iterator is setup.\n\n`RedisModule_ZsetLastInLexRange`\n\n\n```int RedisModule_ZsetLastInLexRange(RedisModuleKey *key,\n                                   RedisModuleString *min,\n                                   RedisModuleString *max);\n```\n\n\nAvailable since: 4.0.0\nExactly like RedisModule_ZsetFirstInLexRange() but the last element of\nthe range is selected for the start of the iteration instead.\n\n`RedisModule_ZsetRangeCurrentElement`\n\n\n```RedisModuleString *RedisModule_ZsetRangeCurrentElement(RedisModuleKey *key,\n                                                       double *score);\n```\n\n\nAvailable since: 4.0.0\nReturn the current sorted set element of an active sorted set iterator\nor NULL if the range specified in the iterator does not include any\nelement.\n\n`RedisModule_ZsetRangeNext`\n\n\n```int RedisModule_ZsetRangeNext(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nGo to the next element of the sorted set iterator. Returns 1 if there was\na next element, 0 if we are already at the latest element or the range\ndoes not include any item at all.\n\n`RedisModule_ZsetRangePrev`\n\n\n```int RedisModule_ZsetRangePrev(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nGo to the previous element of the sorted set iterator. Returns 1 if there was\na previous element, 0 if we are already at the first element or the range\ndoes not include any item at all.\n\nKey API for Hash type\nSee also RedisModule_ValueLength(), which returns the number of fields in a hash.\n\n`RedisModule_HashSet`\n\n\n```int RedisModule_HashSet(RedisModuleKey *key, int flags, ...);\n```\n\n\nAvailable since: 4.0.0\nSet the field of the specified hash field to the specified value.\nIf the key is an empty key open for writing, it is created with an empty\nhash value, in order to set the specified field.\nThe function is variadic and the user must specify pairs of field\nnames and values, both as `RedisModuleString` pointers (unless the\nCFIELD option is set, see later). At the end of the field/value-ptr pairs,\nNULL must be specified as last argument to signal the end of the arguments\nin the variadic function.\nExample to set the hash argv[1] to the value argv[2]:\n\n\n``` RedisModule_HashSet(key,REDISMODULE_HASH_NONE,argv[1],argv[2],NULL);\n```\n\n\nThe function can also be used in order to delete fields (if they exist)\nby setting them to the specified value of `REDISMODULE_HASH_DELETE`:\n\n\n``` RedisModule_HashSet(key,REDISMODULE_HASH_NONE,argv[1],\n                     REDISMODULE_HASH_DELETE,NULL);\n```\n\n\nThe behavior of the command changes with the specified flags, that can be\nset to `REDISMODULE_HASH_NONE` if no special behavior is needed.\n\n\n```REDISMODULE_HASH_NX: The operation is performed only if the field was not\n                     already existing in the hash.\nREDISMODULE_HASH_XX: The operation is performed only if the field was\n                     already existing, so that a new value could be\n                     associated to an existing filed, but no new fields\n                     are created.\nREDISMODULE_HASH_CFIELDS: The field names passed are null terminated C\n                          strings instead of RedisModuleString objects.\nREDISMODULE_HASH_COUNT_ALL: Include the number of inserted fields in the\n                            returned number, in addition to the number of\n                            updated and deleted fields. (Added in Redis\n                            6.2.)\n```\n\n\nUnless NX is specified, the command overwrites the old field value with\nthe new one.\nWhen using `REDISMODULE_HASH_CFIELDS`, field names are reported using\nnormal C strings, so for example to delete the field \"foo\" the following\ncode can be used:\n\n\n``` RedisModule_HashSet(key,REDISMODULE_HASH_CFIELDS,\"foo\",\n                     REDISMODULE_HASH_DELETE,NULL);\n```\n\n\nReturn value:\nThe number of fields existing in the hash prior to the call, which have been\nupdated (its old value has been replaced by a new value) or deleted. If the\nflag `REDISMODULE_HASH_COUNT_ALL` is set, inserted fields not previously\nexisting in the hash are also counted.\nIf the return value is zero, `errno` is set (since Redis 6.2) as follows:\n\nEINVAL if any unknown flags are set or if key is NULL.\nENOTSUP if the key is associated with a non Hash value.\nEBADF if the key was not opened for writing.\nENOENT if no fields were counted as described under Return value above.\n  This is not actually an error. The return value can be zero if all fields\n  were just created and the `COUNT_ALL` flag was unset, or if changes were held\n  back due to the NX and XX flags.\n\nNOTICE: The return value semantics of this function are very different\nbetween Redis 6.2 and older versions. Modules that use it should determine\nthe Redis version and handle it accordingly.\n\n`RedisModule_HashGet`\n\n\n```int RedisModule_HashGet(RedisModuleKey *key, int flags, ...);\n```\n\n\nAvailable since: 4.0.0\nGet fields from a hash value. This function is called using a variable\nnumber of arguments, alternating a field name (as a `RedisModuleString`\npointer) with a pointer to a `RedisModuleString` pointer, that is set to the\nvalue of the field if the field exists, or NULL if the field does not exist.\nAt the end of the field/value-ptr pairs, NULL must be specified as last\nargument to signal the end of the arguments in the variadic function.\nThis is an example usage:\n\n\n``` RedisModuleString *first, *second;\n RedisModule_HashGet(mykey,REDISMODULE_HASH_NONE,argv[1],&first,\n                     argv[2],&second,NULL);\n```\n\n\nAs with RedisModule_HashSet() the behavior of the command can be specified\npassing flags different than `REDISMODULE_HASH_NONE`:\n`REDISMODULE_HASH_CFIELDS`: field names as null terminated C strings.\n`REDISMODULE_HASH_EXISTS`: instead of setting the value of the field\nexpecting a `RedisModuleString` pointer to pointer, the function just\nreports if the field exists or not and expects an integer pointer\nas the second element of each pair.\nExample of `REDISMODULE_HASH_CFIELDS`:\n\n\n``` RedisModuleString *username, *hashedpass;\n RedisModule_HashGet(mykey,REDISMODULE_HASH_CFIELDS,\"username\",&username,\"hp\",&hashedpass, NULL);\n```\n\n\nExample of `REDISMODULE_HASH_EXISTS`:\n\n\n``` int exists;\n RedisModule_HashGet(mykey,REDISMODULE_HASH_EXISTS,argv[1],&exists,NULL);\n```\n\n\nThe function returns `REDISMODULE_OK` on success and `REDISMODULE_ERR` if\nthe key is not a hash value.\nMemory management:\nThe returned `RedisModuleString` objects should be released with\nRedisModule_FreeString(), or by enabling automatic memory management.\n\nKey API for Stream type\nFor an introduction to streams, see https://redis.io/topics/streams-intro.\nThe type `RedisModuleStreamID`, which is used in stream functions, is a struct\nwith two 64-bit fields and is defined as\n\n\n```typedef struct RedisModuleStreamID {\n    uint64_t ms;\n    uint64_t seq;\n} RedisModuleStreamID;\n```\n\n\nSee also RedisModule_ValueLength(), which returns the length of a stream, and the\nconversion functions RedisModule_StringToStreamID() and RedisModule_CreateStringFromStreamID().\n\n`RedisModule_StreamAdd`\n\n\n```int RedisModule_StreamAdd(RedisModuleKey *key,\n                          int flags,\n                          RedisModuleStreamID *id,\n                          RedisModuleString **argv,\n                          long numfields);\n```\n\n\nAvailable since: 6.2.0\nAdds an entry to a stream. Like XADD without trimming.\n\n`key`: The key where the stream is (or will be) stored\n`flags`: A bit field of\n`REDISMODULE_STREAM_ADD_AUTOID`: Assign a stream ID automatically, like\n    `*` in the XADD command.\n`id`: If the `AUTOID` flag is set, this is where the assigned ID is\n  returned. Can be NULL if `AUTOID` is set, if you don't care to receive the\n  ID. If `AUTOID` is not set, this is the requested ID.\n`argv`: A pointer to an array of size `numfields * 2` containing the\n  fields and values.\n`numfields`: The number of field-value pairs in `argv`.\n\nReturns `REDISMODULE_OK` if an entry has been added. On failure,\n`REDISMODULE_ERR` is returned and `errno` is set as follows:\n\nEINVAL if called with invalid arguments\nENOTSUP if the key refers to a value of a type other than stream\nEBADF if the key was not opened for writing\nEDOM if the given ID was 0-0 or not greater than all other IDs in the\n  stream (only if the AUTOID flag is unset)\nEFBIG if the stream has reached the last possible ID\nERANGE if the elements are too large to be stored.\n\n\n`RedisModule_StreamDelete`\n\n\n```int RedisModule_StreamDelete(RedisModuleKey *key, RedisModuleStreamID *id);\n```\n\n\nAvailable since: 6.2.0\nDeletes an entry from a stream.\n\n`key`: A key opened for writing, with no stream iterator started.\n`id`: The stream ID of the entry to delete.\n\nReturns `REDISMODULE_OK` on success. On failure, `REDISMODULE_ERR` is returned\nand `errno` is set as follows:\n\nEINVAL if called with invalid arguments\nENOTSUP if the key refers to a value of a type other than stream or if the\n  key is empty\nEBADF if the key was not opened for writing or if a stream iterator is\n  associated with the key\nENOENT if no entry with the given stream ID exists\n\nSee also RedisModule_StreamIteratorDelete() for deleting the current entry while\niterating using a stream iterator.\n\n`RedisModule_StreamIteratorStart`\n\n\n```int RedisModule_StreamIteratorStart(RedisModuleKey *key,\n                                    int flags,\n                                    RedisModuleStreamID *start,\n                                    RedisModuleStreamID *end);\n```\n\n\nAvailable since: 6.2.0\nSets up a stream iterator.\n\n`key`: The stream key opened for reading using RedisModule_OpenKey().\n`flags`:\n`REDISMODULE_STREAM_ITERATOR_EXCLUSIVE`: Don't include `start` and `end`\n    in the iterated range.\n`REDISMODULE_STREAM_ITERATOR_REVERSE`: Iterate in reverse order, starting\n    from the `end` of the range.\n`start`: The lower bound of the range. Use NULL for the beginning of the\n  stream.\n`end`: The upper bound of the range. Use NULL for the end of the stream.\n\nReturns `REDISMODULE_OK` on success. On failure, `REDISMODULE_ERR` is returned\nand `errno` is set as follows:\n\nEINVAL if called with invalid arguments\nENOTSUP if the key refers to a value of a type other than stream or if the\n  key is empty\nEBADF if the key was not opened for writing or if a stream iterator is\n  already associated with the key\nEDOM if `start` or `end` is outside the valid range\n\nReturns `REDISMODULE_OK` on success and `REDISMODULE_ERR` if the key doesn't\nrefer to a stream or if invalid arguments were given.\nThe stream IDs are retrieved using RedisModule_StreamIteratorNextID() and\nfor each stream ID, the fields and values are retrieved using\nRedisModule_StreamIteratorNextField(). The iterator is freed by calling\nRedisModule_StreamIteratorStop().\nExample (error handling omitted):\n\n\n```RedisModule_StreamIteratorStart(key, 0, startid_ptr, endid_ptr);\nRedisModuleStreamID id;\nlong numfields;\nwhile (RedisModule_StreamIteratorNextID(key, &id, &numfields) ==\n       REDISMODULE_OK) {\n    RedisModuleString *field, *value;\n    while (RedisModule_StreamIteratorNextField(key, &field, &value) ==\n           REDISMODULE_OK) {\n        //\n        // ... Do stuff ...\n        //\n        RedisModule_FreeString(ctx, field);\n        RedisModule_FreeString(ctx, value);\n    }\n}\nRedisModule_StreamIteratorStop(key);\n```\n\n\n\n`RedisModule_StreamIteratorStop`\n\n\n```int RedisModule_StreamIteratorStop(RedisModuleKey *key);\n```\n\n\nAvailable since: 6.2.0\nStops a stream iterator created using RedisModule_StreamIteratorStart() and\nreclaims its memory.\nReturns `REDISMODULE_OK` on success. On failure, `REDISMODULE_ERR` is returned\nand `errno` is set as follows:\n\nEINVAL if called with a NULL key\nENOTSUP if the key refers to a value of a type other than stream or if the\n  key is empty\nEBADF if the key was not opened for writing or if no stream iterator is\n  associated with the key\n\n\n`RedisModule_StreamIteratorNextID`\n\n\n```int RedisModule_StreamIteratorNextID(RedisModuleKey *key,\n                                     RedisModuleStreamID *id,\n                                     long *numfields);\n```\n\n\nAvailable since: 6.2.0\nFinds the next stream entry and returns its stream ID and the number of\nfields.\n\n`key`: Key for which a stream iterator has been started using\n  RedisModule_StreamIteratorStart().\n`id`: The stream ID returned. NULL if you don't care.\n`numfields`: The number of fields in the found stream entry. NULL if you\n  don't care.\n\nReturns `REDISMODULE_OK` and sets `*id` and `*numfields` if an entry was found.\nOn failure, `REDISMODULE_ERR` is returned and `errno` is set as follows:\n\nEINVAL if called with a NULL key\nENOTSUP if the key refers to a value of a type other than stream or if the\n  key is empty\nEBADF if no stream iterator is associated with the key\nENOENT if there are no more entries in the range of the iterator\n\nIn practice, if RedisModule_StreamIteratorNextID() is called after a successful call\nto RedisModule_StreamIteratorStart() and with the same key, it is safe to assume that\nan `REDISMODULE_ERR` return value means that there are no more entries.\nUse RedisModule_StreamIteratorNextField() to retrieve the fields and values.\nSee the example at RedisModule_StreamIteratorStart().\n\n`RedisModule_StreamIteratorNextField`\n\n\n```int RedisModule_StreamIteratorNextField(RedisModuleKey *key,\n                                        RedisModuleString **field_ptr,\n                                        RedisModuleString **value_ptr);\n```\n\n\nAvailable since: 6.2.0\nRetrieves the next field of the current stream ID and its corresponding value\nin a stream iteration. This function should be called repeatedly after calling\nRedisModule_StreamIteratorNextID() to fetch each field-value pair.\n\n`key`: Key where a stream iterator has been started.\n`field_ptr`: This is where the field is returned.\n`value_ptr`: This is where the value is returned.\n\nReturns `REDISMODULE_OK` and points `*field_ptr` and `*value_ptr` to freshly\nallocated `RedisModuleString` objects. The string objects are freed\nautomatically when the callback finishes if automatic memory is enabled. On\nfailure, `REDISMODULE_ERR` is returned and `errno` is set as follows:\n\nEINVAL if called with a NULL key\nENOTSUP if the key refers to a value of a type other than stream or if the\n  key is empty\nEBADF if no stream iterator is associated with the key\nENOENT if there are no more fields in the current stream entry\n\nIn practice, if RedisModule_StreamIteratorNextField() is called after a successful\ncall to RedisModule_StreamIteratorNextID() and with the same key, it is safe to assume\nthat an `REDISMODULE_ERR` return value means that there are no more fields.\nSee the example at RedisModule_StreamIteratorStart().\n\n`RedisModule_StreamIteratorDelete`\n\n\n```int RedisModule_StreamIteratorDelete(RedisModuleKey *key);\n```\n\n\nAvailable since: 6.2.0\nDeletes the current stream entry while iterating.\nThis function can be called after RedisModule_StreamIteratorNextID() or after any\ncalls to RedisModule_StreamIteratorNextField().\nReturns `REDISMODULE_OK` on success. On failure, `REDISMODULE_ERR` is returned\nand `errno` is set as follows:\n\nEINVAL if key is NULL\nENOTSUP if the key is empty or is of another type than stream\nEBADF if the key is not opened for writing, if no iterator has been started\nENOENT if the iterator has no current stream entry\n\n\n`RedisModule_StreamTrimByLength`\n\n\n```long long RedisModule_StreamTrimByLength(RedisModuleKey *key,\n                                         int flags,\n                                         long long length);\n```\n\n\nAvailable since: 6.2.0\nTrim a stream by length, similar to XTRIM with MAXLEN.\n\n`key`: Key opened for writing.\n`flags`: A bitfield of\n`REDISMODULE_STREAM_TRIM_APPROX`: Trim less if it improves performance,\n    like XTRIM with `~`.\n`length`: The number of stream entries to keep after trimming.\n\nReturns the number of entries deleted. On failure, a negative value is\nreturned and `errno` is set as follows:\n\nEINVAL if called with invalid arguments\nENOTSUP if the key is empty or of a type other than stream\nEBADF if the key is not opened for writing\n\n\n`RedisModule_StreamTrimByID`\n\n\n```long long RedisModule_StreamTrimByID(RedisModuleKey *key,\n                                     int flags,\n                                     RedisModuleStreamID *id);\n```\n\n\nAvailable since: 6.2.0\nTrim a stream by ID, similar to XTRIM with MINID.\n\n`key`: Key opened for writing.\n`flags`: A bitfield of\n`REDISMODULE_STREAM_TRIM_APPROX`: Trim less if it improves performance,\n    like XTRIM with `~`.\n`id`: The smallest stream ID to keep after trimming.\n\nReturns the number of entries deleted. On failure, a negative value is\nreturned and `errno` is set as follows:\n\nEINVAL if called with invalid arguments\nENOTSUP if the key is empty or of a type other than stream\nEBADF if the key is not opened for writing\n\n\nCalling Redis commands from modules\nRedisModule_Call() sends a command to Redis. The remaining functions handle the reply.\n\n`RedisModule_FreeCallReply`\n\n\n```void RedisModule_FreeCallReply(RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 4.0.0\nFree a Call reply and all the nested replies it contains if it's an\narray.\n\n`RedisModule_CallReplyType`\n\n\n```int RedisModule_CallReplyType(RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 4.0.0\nReturn the reply type as one of the following:\n\n`REDISMODULE_REPLY_UNKNOWN`\n`REDISMODULE_REPLY_STRING`\n`REDISMODULE_REPLY_ERROR`\n`REDISMODULE_REPLY_INTEGER`\n`REDISMODULE_REPLY_ARRAY`\n`REDISMODULE_REPLY_NULL`\n`REDISMODULE_REPLY_MAP`\n`REDISMODULE_REPLY_SET`\n`REDISMODULE_REPLY_BOOL`\n`REDISMODULE_REPLY_DOUBLE`\n`REDISMODULE_REPLY_BIG_NUMBER`\n`REDISMODULE_REPLY_VERBATIM_STRING`\n`REDISMODULE_REPLY_ATTRIBUTE`\n\n\n`RedisModule_CallReplyLength`\n\n\n```size_t RedisModule_CallReplyLength(RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 4.0.0\nReturn the reply type length, where applicable.\n\n`RedisModule_CallReplyArrayElement`\n\n\n```RedisModuleCallReply *RedisModule_CallReplyArrayElement(RedisModuleCallReply *reply,\n                                                        size_t idx);\n```\n\n\nAvailable since: 4.0.0\nReturn the 'idx'-th nested call reply element of an array reply, or NULL\nif the reply type is wrong or the index is out of range.\n\n`RedisModule_CallReplyInteger`\n\n\n```long long RedisModule_CallReplyInteger(RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 4.0.0\nReturn the `long long` of an integer reply.\n\n`RedisModule_CallReplyDouble`\n\n\n```double RedisModule_CallReplyDouble(RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 7.0.0\nReturn the double value of a double reply.\n\n`RedisModule_CallReplyBigNumber`\n\n\n```const char *RedisModule_CallReplyBigNumber(RedisModuleCallReply *reply,\n                                           size_t *len);\n```\n\n\nAvailable since: 7.0.0\nReturn the big number value of a big number reply.\n\n`RedisModule_CallReplyVerbatim`\n\n\n```const char *RedisModule_CallReplyVerbatim(RedisModuleCallReply *reply,\n                                          size_t *len,\n                                          const char **format);\n```\n\n\nAvailable since: 7.0.0\nReturn the value of a verbatim string reply,\nAn optional output argument can be given to get verbatim reply format.\n\n`RedisModule_CallReplyBool`\n\n\n```int RedisModule_CallReplyBool(RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 7.0.0\nReturn the Boolean value of a Boolean reply.\n\n`RedisModule_CallReplySetElement`\n\n\n```RedisModuleCallReply *RedisModule_CallReplySetElement(RedisModuleCallReply *reply,\n                                                      size_t idx);\n```\n\n\nAvailable since: 7.0.0\nReturn the 'idx'-th nested call reply element of a set reply, or NULL\nif the reply type is wrong or the index is out of range.\n\n`RedisModule_CallReplyMapElement`\n\n\n```int RedisModule_CallReplyMapElement(RedisModuleCallReply *reply,\n                                    size_t idx,\n                                    RedisModuleCallReply **key,\n                                    RedisModuleCallReply **val);\n```\n\n\nAvailable since: 7.0.0\nRetrieve the 'idx'-th key and value of a map reply.\nReturns:\n- `REDISMODULE_OK` on success.\n- `REDISMODULE_ERR` if idx out of range or if the reply type is wrong.\nThe `key` and `value` arguments are used to return by reference, and may be\nNULL if not required.\n\n`RedisModule_CallReplyAttribute`\n\n\n```RedisModuleCallReply *RedisModule_CallReplyAttribute(RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 7.0.0\nReturn the attribute of the given reply, or NULL if no attribute exists.\n\n`RedisModule_CallReplyAttributeElement`\n\n\n```int RedisModule_CallReplyAttributeElement(RedisModuleCallReply *reply,\n                                          size_t idx,\n                                          RedisModuleCallReply **key,\n                                          RedisModuleCallReply **val);\n```\n\n\nAvailable since: 7.0.0\nRetrieve the 'idx'-th key and value of an attribute reply.\nReturns:\n- `REDISMODULE_OK` on success.\n- `REDISMODULE_ERR` if idx out of range or if the reply type is wrong.\nThe `key` and `value` arguments are used to return by reference, and may be\nNULL if not required.\n\n`RedisModule_CallReplyStringPtr`\n\n\n```const char *RedisModule_CallReplyStringPtr(RedisModuleCallReply *reply,\n                                           size_t *len);\n```\n\n\nAvailable since: 4.0.0\nReturn the pointer and length of a string or error reply.\n\n`RedisModule_CreateStringFromCallReply`\n\n\n```RedisModuleString *RedisModule_CreateStringFromCallReply(RedisModuleCallReply *reply);\n```\n\n\nAvailable since: 4.0.0\nReturn a new string object from a call reply of type string, error or\ninteger. Otherwise (wrong reply type) return NULL.\n\n`RedisModule_SetContextUser`\n\n\n```void RedisModule_SetContextUser(RedisModuleCtx *ctx,\n                                const RedisModuleUser *user);\n```\n\n\nAvailable since: 7.0.6\nModifies the user that RedisModule_Call will use (e.g. for ACL checks)\n\n`RedisModule_Call`\n\n\n```RedisModuleCallReply *RedisModule_Call(RedisModuleCtx *ctx,\n                                       const char *cmdname,\n                                       const char *fmt,\n                                       ...);\n```\n\n\nAvailable since: 4.0.0\nExported API to call any Redis command from modules.\n\ncmdname: The Redis command to call.\n\nfmt: A format specifier string for the command's arguments. Each\n  of the arguments should be specified by a valid type specification. The\n  format specifier can also contain the modifiers `!`, `A`, `3` and `R` which\n  don't have a corresponding argument.\n\n`b` -- The argument is a buffer and is immediately followed by another\n         argument that is the buffer's length.\n`c` -- The argument is a pointer to a plain C string (null-terminated).\n`l` -- The argument is a `long long` integer.\n`s` -- The argument is a RedisModuleString.\n`v` -- The argument(s) is a vector of RedisModuleString.\n`!` -- Sends the Redis command and its arguments to replicas and AOF.\n`A` -- Suppress AOF propagation, send only to replicas (requires `!`).\n`R` -- Suppress replicas propagation, send only to AOF (requires `!`).\n`3` -- Return a RESP3 reply. This will change the command reply.\n         e.g., HGETALL returns a map instead of a flat array.\n`0` -- Return the reply in auto mode, i.e. the reply format will be the\n         same as the client attached to the given RedisModuleCtx. This will\n         probably used when you want to pass the reply directly to the client.\n`C` -- Run a command as the user attached to the context.\n         User is either attached automatically via the client that directly\n         issued the command and created the context or via RedisModule_SetContextUser.\n         If the context is not directly created by an issued command (such as a\n         background context and no user was set on it via RedisModule_SetContextUser,\n         RedisModule_Call will fail.\n         Checks if the command can be executed according to ACL rules and causes\n         the command to run as the determined user, so that any future user\n         dependent activity, such as ACL checks within scripts will proceed as\n         expected.\n         Otherwise, the command will run as the Redis unrestricted user.\n`S` -- Run the command in a script mode, this means that it will raise\n         an error if a command which are not allowed inside a script\n         (flagged with the `deny-script` flag) is invoked (like SHUTDOWN).\n         In addition, on script mode, write commands are not allowed if there are\n         not enough good replicas (as configured with `min-replicas-to-write`)\n         or when the server is unable to persist to the disk.\n`W` -- Do not allow to run any write command (flagged with the `write` flag).\n`M` -- Do not allow `deny-oom` flagged commands when over the memory limit.\n`E` -- Return error as RedisModuleCallReply. If there is an error before\n         invoking the command, the error is returned using errno mechanism.\n         This flag allows to get the error also as an error CallReply with\n         relevant error message.\n...: The actual arguments to the Redis command.\n\n\n\nOn success a `RedisModuleCallReply` object is returned, otherwise\nNULL is returned and errno is set to the following values:\n\nEBADF: wrong format specifier.\nEINVAL: wrong command arity.\nENOENT: command does not exist.\nEPERM: operation in Cluster instance with key in non local slot.\nEROFS: operation in Cluster instance when a write command is sent\n         in a readonly state.\nENETDOWN: operation in Cluster instance when cluster is down.\nENOTSUP: No ACL user for the specified module context\nEACCES: Command cannot be executed, according to ACL rules\nENOSPC: Write or deny-oom command is not allowed\nESPIPE: Command not allowed on script mode\n\nExample code fragment:\n\n\n``` reply = RedisModule_Call(ctx,\"INCRBY\",\"sc\",argv[1],\"10\");\n if (RedisModule_CallReplyType(reply) == REDISMODULE_REPLY_INTEGER) {\n   long long myval = RedisModule_CallReplyInteger(reply);\n   // Do something with myval.\n }\n```\n\n\nThis API is documented here: https://redis.io/topics/modules-intro\n\n`RedisModule_CallReplyProto`\n\n\n```const char *RedisModule_CallReplyProto(RedisModuleCallReply *reply,\n                                       size_t *len);\n```\n\n\nAvailable since: 4.0.0\nReturn a pointer, and a length, to the protocol returned by the command\nthat returned the reply object.\n\nModules data types\nWhen String DMA or using existing data structures is not enough, it is\npossible to create new data types from scratch and export them to\nRedis. The module must provide a set of callbacks for handling the\nnew values exported (for example in order to provide RDB saving/loading,\nAOF rewrite, and so forth). In this section we define this API.\n\n`RedisModule_CreateDataType`\n\n\n```moduleType *RedisModule_CreateDataType(RedisModuleCtx *ctx,\n                                       const char *name,\n                                       int encver,\n                                       void *typemethods_ptr);\n```\n\n\nAvailable since: 4.0.0\nRegister a new data type exported by the module. The parameters are the\nfollowing. Please for in depth documentation check the modules API\ndocumentation, especially https://redis.io/topics/modules-native-types.\n\nname: A 9 characters data type name that MUST be unique in the Redis\n  Modules ecosystem. Be creative... and there will be no collisions. Use\n  the charset A-Z a-z 9-0, plus the two \"-_\" characters. A good\n  idea is to use, for example `<typename>-<vendor>`. For example\n  \"tree-AntZ\" may mean \"Tree data structure by @antirez\". To use both\n  lower case and upper case letters helps in order to prevent collisions.\n\nencver: Encoding version, which is, the version of the serialization\n  that a module used in order to persist data. As long as the \"name\"\n  matches, the RDB loading will be dispatched to the type callbacks\n  whatever 'encver' is used, however the module can understand if\n  the encoding it must load are of an older version of the module.\n  For example the module \"tree-AntZ\" initially used encver=0. Later\n  after an upgrade, it started to serialize data in a different format\n  and to register the type with encver=1. However this module may\n  still load old data produced by an older version if the `rdb_load`\n  callback is able to check the encver value and act accordingly.\n  The encver must be a positive value between 0 and 1023.\n\n\ntypemethods_ptr is a pointer to a `RedisModuleTypeMethods` structure\n  that should be populated with the methods callbacks and structure\n  version, like in the following example:\n\n\n```RedisModuleTypeMethods tm = {\n    .version = REDISMODULE_TYPE_METHOD_VERSION,\n    .rdb_load = myType_RDBLoadCallBack,\n    .rdb_save = myType_RDBSaveCallBack,\n    .aof_rewrite = myType_AOFRewriteCallBack,\n    .free = myType_FreeCallBack,\n\n    // Optional fields\n    .digest = myType_DigestCallBack,\n    .mem_usage = myType_MemUsageCallBack,\n    .aux_load = myType_AuxRDBLoadCallBack,\n    .aux_save = myType_AuxRDBSaveCallBack,\n    .free_effort = myType_FreeEffortCallBack,\n    .unlink = myType_UnlinkCallBack,\n    .copy = myType_CopyCallback,\n    .defrag = myType_DefragCallback\n\n    // Enhanced optional fields\n    .mem_usage2 = myType_MemUsageCallBack2,\n    .free_effort2 = myType_FreeEffortCallBack2,\n    .unlink2 = myType_UnlinkCallBack2,\n    .copy2 = myType_CopyCallback2,\n}\n```\n\n\n\n\nrdb_load: A callback function pointer that loads data from RDB files.\n\nrdb_save: A callback function pointer that saves data to RDB files.\naof_rewrite: A callback function pointer that rewrites data as commands.\ndigest: A callback function pointer that is used for `DEBUG DIGEST`.\nfree: A callback function pointer that can free a type value.\naux_save: A callback function pointer that saves out of keyspace data to RDB files.\n  'when' argument is either `REDISMODULE_AUX_BEFORE_RDB` or `REDISMODULE_AUX_AFTER_RDB`.\naux_load: A callback function pointer that loads out of keyspace data from RDB files.\n  Similar to `aux_save`, returns `REDISMODULE_OK` on success, and ERR otherwise.\nfree_effort: A callback function pointer that used to determine whether the module's\n  memory needs to be lazy reclaimed. The module should return the complexity involved by\n  freeing the value. for example: how many pointers are gonna be freed. Note that if it \n  returns 0, we'll always do an async free.\nunlink: A callback function pointer that used to notifies the module that the key has \n  been removed from the DB by redis, and may soon be freed by a background thread. Note that \n  it won't be called on FLUSHALL/FLUSHDB (both sync and async), and the module can use the \n  `RedisModuleEvent_FlushDB` to hook into that.\n\ncopy: A callback function pointer that is used to make a copy of the specified key.\n  The module is expected to perform a deep copy of the specified value and return it.\n  In addition, hints about the names of the source and destination keys is provided.\n  A NULL return value is considered an error and the copy operation fails.\n  Note: if the target key exists and is being overwritten, the copy callback will be\n  called first, followed by a free callback to the value that is being replaced.\n\n\ndefrag: A callback function pointer that is used to request the module to defrag\n  a key. The module should then iterate pointers and call the relevant `RedisModule_Defrag*()`\n  functions to defragment pointers or complex types. The module should continue\n  iterating as long as RedisModule_DefragShouldStop() returns a zero value, and return a\n  zero value if finished or non-zero value if more work is left to be done. If more work\n  needs to be done, RedisModule_DefragCursorSet() and RedisModule_DefragCursorGet() can be used to track\n  this work across different calls.\n  Normally, the defrag mechanism invokes the callback without a time limit, so\n  RedisModule_DefragShouldStop() always returns zero. The \"late defrag\" mechanism which has\n  a time limit and provides cursor support is used only for keys that are determined\n  to have significant internal complexity. To determine this, the defrag mechanism\n  uses the `free_effort` callback and the 'active-defrag-max-scan-fields' config directive.\n  NOTE: The value is passed as a `void**` and the function is expected to update the\n  pointer if the top-level value pointer is defragmented and consequently changes.\n\n\nmem_usage2: Similar to `mem_usage`, but provides the `RedisModuleKeyOptCtx` parameter\n  so that meta information such as key name and db id can be obtained, and\n  the `sample_size` for size estimation (see MEMORY USAGE command).\n\nfree_effort2: Similar to `free_effort`, but provides the `RedisModuleKeyOptCtx` parameter\n  so that meta information such as key name and db id can be obtained.\nunlink2: Similar to `unlink`, but provides the `RedisModuleKeyOptCtx` parameter\n  so that meta information such as key name and db id can be obtained.\ncopy2: Similar to `copy`, but provides the `RedisModuleKeyOptCtx` parameter\n  so that meta information such as key names and db ids can be obtained.\n\nNote: the module name \"AAAAAAAAA\" is reserved and produces an error, it\nhappens to be pretty lame as well.\nIf there is already a module registering a type with the same name,\nand if the module name or encver is invalid, NULL is returned.\nOtherwise the new type is registered into Redis, and a reference of\ntype `RedisModuleType` is returned: the caller of the function should store\nthis reference into a global variable to make future use of it in the\nmodules type API, since a single module may register multiple types.\nExample code fragment:\n\n\n``` static RedisModuleType *BalancedTreeType;\n\n int RedisModule_OnLoad(RedisModuleCtx *ctx) {\n     // some code here ...\n     BalancedTreeType = RedisModule_CreateDataType(...);\n }\n```\n\n\n\n`RedisModule_ModuleTypeSetValue`\n\n\n```int RedisModule_ModuleTypeSetValue(RedisModuleKey *key,\n                                   moduleType *mt,\n                                   void *value);\n```\n\n\nAvailable since: 4.0.0\nIf the key is open for writing, set the specified module type object\nas the value of the key, deleting the old value if any.\nOn success `REDISMODULE_OK` is returned. If the key is not open for\nwriting or there is an active iterator, `REDISMODULE_ERR` is returned.\n\n`RedisModule_ModuleTypeGetType`\n\n\n```moduleType *RedisModule_ModuleTypeGetType(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nAssuming RedisModule_KeyType() returned `REDISMODULE_KEYTYPE_MODULE` on\nthe key, returns the module type pointer of the value stored at key.\nIf the key is NULL, is not associated with a module type, or is empty,\nthen NULL is returned instead.\n\n`RedisModule_ModuleTypeGetValue`\n\n\n```void *RedisModule_ModuleTypeGetValue(RedisModuleKey *key);\n```\n\n\nAvailable since: 4.0.0\nAssuming RedisModule_KeyType() returned `REDISMODULE_KEYTYPE_MODULE` on\nthe key, returns the module type low-level value stored at key, as\nit was set by the user via RedisModule_ModuleTypeSetValue().\nIf the key is NULL, is not associated with a module type, or is empty,\nthen NULL is returned instead.\n\nRDB loading and saving functions\n\n`RedisModule_IsIOError`\n\n\n```int RedisModule_IsIOError(RedisModuleIO *io);\n```\n\n\nAvailable since: 6.0.0\nReturns true if any previous IO API failed.\nfor `Load*` APIs the `REDISMODULE_OPTIONS_HANDLE_IO_ERRORS` flag must be set with\nRedisModule_SetModuleOptions first.\n\n`RedisModule_SaveUnsigned`\n\n\n```void RedisModule_SaveUnsigned(RedisModuleIO *io, uint64_t value);\n```\n\n\nAvailable since: 4.0.0\nSave an unsigned 64 bit value into the RDB file. This function should only\nbe called in the context of the `rdb_save` method of modules implementing new\ndata types.\n\n`RedisModule_LoadUnsigned`\n\n\n```uint64_t RedisModule_LoadUnsigned(RedisModuleIO *io);\n```\n\n\nAvailable since: 4.0.0\nLoad an unsigned 64 bit value from the RDB file. This function should only\nbe called in the context of the `rdb_load` method of modules implementing\nnew data types.\n\n`RedisModule_SaveSigned`\n\n\n```void RedisModule_SaveSigned(RedisModuleIO *io, int64_t value);\n```\n\n\nAvailable since: 4.0.0\nLike RedisModule_SaveUnsigned() but for signed 64 bit values.\n\n`RedisModule_LoadSigned`\n\n\n```int64_t RedisModule_LoadSigned(RedisModuleIO *io);\n```\n\n\nAvailable since: 4.0.0\nLike RedisModule_LoadUnsigned() but for signed 64 bit values.\n\n`RedisModule_SaveString`\n\n\n```void RedisModule_SaveString(RedisModuleIO *io, RedisModuleString *s);\n```\n\n\nAvailable since: 4.0.0\nIn the context of the `rdb_save` method of a module type, saves a\nstring into the RDB file taking as input a `RedisModuleString`.\nThe string can be later loaded with RedisModule_LoadString() or\nother Load family functions expecting a serialized string inside\nthe RDB file.\n\n`RedisModule_SaveStringBuffer`\n\n\n```void RedisModule_SaveStringBuffer(RedisModuleIO *io,\n                                  const char *str,\n                                  size_t len);\n```\n\n\nAvailable since: 4.0.0\nLike RedisModule_SaveString() but takes a raw C pointer and length\nas input.\n\n`RedisModule_LoadString`\n\n\n```RedisModuleString *RedisModule_LoadString(RedisModuleIO *io);\n```\n\n\nAvailable since: 4.0.0\nIn the context of the `rdb_load` method of a module data type, loads a string\nfrom the RDB file, that was previously saved with RedisModule_SaveString()\nfunctions family.\nThe returned string is a newly allocated `RedisModuleString` object, and\nthe user should at some point free it with a call to RedisModule_FreeString().\nIf the data structure does not store strings as `RedisModuleString` objects,\nthe similar function RedisModule_LoadStringBuffer() could be used instead.\n\n`RedisModule_LoadStringBuffer`\n\n\n```char *RedisModule_LoadStringBuffer(RedisModuleIO *io, size_t *lenptr);\n```\n\n\nAvailable since: 4.0.0\nLike RedisModule_LoadString() but returns a heap allocated string that\nwas allocated with RedisModule_Alloc(), and can be resized or freed with\nRedisModule_Realloc() or RedisModule_Free().\nThe size of the string is stored at '*lenptr' if not NULL.\nThe returned string is not automatically NULL terminated, it is loaded\nexactly as it was stored inside the RDB file.\n\n`RedisModule_SaveDouble`\n\n\n```void RedisModule_SaveDouble(RedisModuleIO *io, double value);\n```\n\n\nAvailable since: 4.0.0\nIn the context of the `rdb_save` method of a module data type, saves a double\nvalue to the RDB file. The double can be a valid number, a NaN or infinity.\nIt is possible to load back the value with RedisModule_LoadDouble().\n\n`RedisModule_LoadDouble`\n\n\n```double RedisModule_LoadDouble(RedisModuleIO *io);\n```\n\n\nAvailable since: 4.0.0\nIn the context of the `rdb_save` method of a module data type, loads back the\ndouble value saved by RedisModule_SaveDouble().\n\n`RedisModule_SaveFloat`\n\n\n```void RedisModule_SaveFloat(RedisModuleIO *io, float value);\n```\n\n\nAvailable since: 4.0.0\nIn the context of the `rdb_save` method of a module data type, saves a float\nvalue to the RDB file. The float can be a valid number, a NaN or infinity.\nIt is possible to load back the value with RedisModule_LoadFloat().\n\n`RedisModule_LoadFloat`\n\n\n```float RedisModule_LoadFloat(RedisModuleIO *io);\n```\n\n\nAvailable since: 4.0.0\nIn the context of the `rdb_save` method of a module data type, loads back the\nfloat value saved by RedisModule_SaveFloat().\n\n`RedisModule_SaveLongDouble`\n\n\n```void RedisModule_SaveLongDouble(RedisModuleIO *io, long double value);\n```\n\n\nAvailable since: 6.0.0\nIn the context of the `rdb_save` method of a module data type, saves a long double\nvalue to the RDB file. The double can be a valid number, a NaN or infinity.\nIt is possible to load back the value with RedisModule_LoadLongDouble().\n\n`RedisModule_LoadLongDouble`\n\n\n```long double RedisModule_LoadLongDouble(RedisModuleIO *io);\n```\n\n\nAvailable since: 6.0.0\nIn the context of the `rdb_save` method of a module data type, loads back the\nlong double value saved by RedisModule_SaveLongDouble().\n\nKey digest API (DEBUG DIGEST interface for modules types)\n\n`RedisModule_DigestAddStringBuffer`\n\n\n```void RedisModule_DigestAddStringBuffer(RedisModuleDigest *md,\n                                       const char *ele,\n                                       size_t len);\n```\n\n\nAvailable since: 4.0.0\nAdd a new element to the digest. This function can be called multiple times\none element after the other, for all the elements that constitute a given\ndata structure. The function call must be followed by the call to\nRedisModule_DigestEndSequence eventually, when all the elements that are\nalways in a given order are added. See the Redis Modules data types\ndocumentation for more info. However this is a quick example that uses Redis\ndata types as an example.\nTo add a sequence of unordered elements (for example in the case of a Redis\nSet), the pattern to use is:\n\n\n```foreach element {\n    AddElement(element);\n    EndSequence();\n}\n```\n\n\nBecause Sets are not ordered, so every element added has a position that\ndoes not depend from the other. However if instead our elements are\nordered in pairs, like field-value pairs of a Hash, then one should\nuse:\n\n\n```foreach key,value {\n    AddElement(key);\n    AddElement(value);\n    EndSequence();\n}\n```\n\n\nBecause the key and value will be always in the above order, while instead\nthe single key-value pairs, can appear in any position into a Redis hash.\nA list of ordered elements would be implemented with:\n\n\n```foreach element {\n    AddElement(element);\n}\nEndSequence();\n```\n\n\n\n`RedisModule_DigestAddLongLong`\n\n\n```void RedisModule_DigestAddLongLong(RedisModuleDigest *md, long long ll);\n```\n\n\nAvailable since: 4.0.0\nLike RedisModule_DigestAddStringBuffer() but takes a `long long` as input\nthat gets converted into a string before adding it to the digest.\n\n`RedisModule_DigestEndSequence`\n\n\n```void RedisModule_DigestEndSequence(RedisModuleDigest *md);\n```\n\n\nAvailable since: 4.0.0\nSee the documentation for `RedisModule_DigestAddElement()`.\n\n`RedisModule_LoadDataTypeFromStringEncver`\n\n\n```void *RedisModule_LoadDataTypeFromStringEncver(const RedisModuleString *str,\n                                               const moduleType *mt,\n                                               int encver);\n```\n\n\nAvailable since: 7.0.0\nDecode a serialized representation of a module data type 'mt', in a specific encoding version 'encver'\nfrom string 'str' and return a newly allocated value, or NULL if decoding failed.\nThis call basically reuses the '`rdb_load`' callback which module data types\nimplement in order to allow a module to arbitrarily serialize/de-serialize\nkeys, similar to how the Redis 'DUMP' and 'RESTORE' commands are implemented.\nModules should generally use the `REDISMODULE_OPTIONS_HANDLE_IO_ERRORS` flag and\nmake sure the de-serialization code properly checks and handles IO errors\n(freeing allocated buffers and returning a NULL).\nIf this is NOT done, Redis will handle corrupted (or just truncated) serialized\ndata by producing an error message and terminating the process.\n\n`RedisModule_LoadDataTypeFromString`\n\n\n```void *RedisModule_LoadDataTypeFromString(const RedisModuleString *str,\n                                         const moduleType *mt);\n```\n\n\nAvailable since: 6.0.0\nSimilar to RedisModule_LoadDataTypeFromStringEncver, original version of the API, kept\nfor backward compatibility.\n\n`RedisModule_SaveDataTypeToString`\n\n\n```RedisModuleString *RedisModule_SaveDataTypeToString(RedisModuleCtx *ctx,\n                                                    void *data,\n                                                    const moduleType *mt);\n```\n\n\nAvailable since: 6.0.0\nEncode a module data type 'mt' value 'data' into serialized form, and return it\nas a newly allocated `RedisModuleString`.\nThis call basically reuses the '`rdb_save`' callback which module data types\nimplement in order to allow a module to arbitrarily serialize/de-serialize\nkeys, similar to how the Redis 'DUMP' and 'RESTORE' commands are implemented.\n\n`RedisModule_GetKeyNameFromDigest`\n\n\n```const RedisModuleString *RedisModule_GetKeyNameFromDigest(RedisModuleDigest *dig);\n```\n\n\nAvailable since: 7.0.0\nReturns the name of the key currently being processed.\n\n`RedisModule_GetDbIdFromDigest`\n\n\n```int RedisModule_GetDbIdFromDigest(RedisModuleDigest *dig);\n```\n\n\nAvailable since: 7.0.0\nReturns the database id of the key currently being processed.\n\nAOF API for modules data types\n\n`RedisModule_EmitAOF`\n\n\n```void RedisModule_EmitAOF(RedisModuleIO *io,\n                         const char *cmdname,\n                         const char *fmt,\n                         ...);\n```\n\n\nAvailable since: 4.0.0\nEmits a command into the AOF during the AOF rewriting process. This function\nis only called in the context of the `aof_rewrite` method of data types exported\nby a module. The command works exactly like RedisModule_Call() in the way\nthe parameters are passed, but it does not return anything as the error\nhandling is performed by Redis itself.\n\nIO context handling\n\n`RedisModule_GetKeyNameFromIO`\n\n\n```const RedisModuleString *RedisModule_GetKeyNameFromIO(RedisModuleIO *io);\n```\n\n\nAvailable since: 5.0.5\nReturns the name of the key currently being processed.\nThere is no guarantee that the key name is always available, so this may return NULL.\n\n`RedisModule_GetKeyNameFromModuleKey`\n\n\n```const RedisModuleString *RedisModule_GetKeyNameFromModuleKey(RedisModuleKey *key);\n```\n\n\nAvailable since: 6.0.0\nReturns a `RedisModuleString` with the name of the key from `RedisModuleKey`.\n\n`RedisModule_GetDbIdFromModuleKey`\n\n\n```int RedisModule_GetDbIdFromModuleKey(RedisModuleKey *key);\n```\n\n\nAvailable since: 7.0.0\nReturns a database id of the key from `RedisModuleKey`.\n\n`RedisModule_GetDbIdFromIO`\n\n\n```int RedisModule_GetDbIdFromIO(RedisModuleIO *io);\n```\n\n\nAvailable since: 7.0.0\nReturns the database id of the key currently being processed.\nThere is no guarantee that this info is always available, so this may return -1.\n\nLogging\n\n`RedisModule_Log`\n\n\n```void RedisModule_Log(RedisModuleCtx *ctx,\n                     const char *levelstr,\n                     const char *fmt,\n                     ...);\n```\n\n\nAvailable since: 4.0.0\nProduces a log message to the standard Redis log, the format accepts\nprintf-alike specifiers, while level is a string describing the log\nlevel to use when emitting the log, and must be one of the following:\n\n\"debug\" (`REDISMODULE_LOGLEVEL_DEBUG`)\n\"verbose\" (`REDISMODULE_LOGLEVEL_VERBOSE`)\n\"notice\" (`REDISMODULE_LOGLEVEL_NOTICE`)\n\"warning\" (`REDISMODULE_LOGLEVEL_WARNING`)\n\nIf the specified log level is invalid, verbose is used by default.\nThere is a fixed limit to the length of the log line this function is able\nto emit, this limit is not specified but is guaranteed to be more than\na few lines of text.\nThe ctx argument may be NULL if cannot be provided in the context of the\ncaller for instance threads or callbacks, in which case a generic \"module\"\nwill be used instead of the module name.\n\n`RedisModule_LogIOError`\n\n\n```void RedisModule_LogIOError(RedisModuleIO *io,\n                            const char *levelstr,\n                            const char *fmt,\n                            ...);\n```\n\n\nAvailable since: 4.0.0\nLog errors from RDB / AOF serialization callbacks.\nThis function should be used when a callback is returning a critical\nerror to the caller since cannot load or save the data for some\ncritical reason.\n\n`RedisModule__Assert`\n\n\n```void RedisModule__Assert(const char *estr, const char *file, int line);\n```\n\n\nAvailable since: 6.0.0\nRedis-like assert function.\nThe macro `RedisModule_Assert(expression)` is recommended, rather than\ncalling this function directly.\nA failed assertion will shut down the server and produce logging information\nthat looks identical to information generated by Redis itself.\n\n`RedisModule_LatencyAddSample`\n\n\n```void RedisModule_LatencyAddSample(const char *event, mstime_t latency);\n```\n\n\nAvailable since: 6.0.0\nAllows adding event to the latency monitor to be observed by the LATENCY\ncommand. The call is skipped if the latency is smaller than the configured\nlatency-monitor-threshold.\n\nBlocking clients from modules\nFor a guide about blocking commands in modules, see\nRedis modules and blocking commands.\n\n`RedisModule_BlockClient`\n\n\n```RedisModuleBlockedClient *RedisModule_BlockClient(RedisModuleCtx *ctx,\n                                                  RedisModuleCmdFunc reply_callback,\n                                                  RedisModuleCmdFunc timeout_callback,\n                                                  void (*free_privdata)(RedisModuleCtx*, void*),\n                                                  long long timeout_ms);\n```\n\n\nAvailable since: 4.0.0\nBlock a client in the context of a blocking command, returning a handle that will be used later to unblock the client with a call to\nRedisModule_UnblockClient(). The arguments specify callback functions\nand a timeout after which the client is unblocked.\nThe callbacks are called in the following contexts:\n\n\n`reply_callback`: called after a successful `RedisModule_UnblockClient()` call to reply to the client and unblock it.\n\n\n`timeout_callback`: called to send an error to the client when the timeout is reached or if `CLIENT UNBLOCK` is invoked.\n\n\n`free_privdata`: called to free the private data that is passed by `RedisModule_UnblockClient()` call.\n\n\nNote: RedisModule_UnblockClient should be called for every blocked client, even if client was killed, timed-out or disconnected. \nFailing to do so results in memory leaks.\nThere are some cases where RedisModule_BlockClient() cannot be used:\n\nIf the client is a Lua script.\nIf the client is executing a MULTI block.\n\nIn these cases, a call to RedisModule_BlockClient() will not block the\nclient, but instead produce a specific error reply.\nA module that registers a `timeout_callback` function can also be unblocked\nusing the `CLIENT UNBLOCK` command, which will trigger the timeout callback.\nIf a callback function is not registered, then the blocked client will be\ntreated as if it is not in a blocked state and `CLIENT UNBLOCK` will return\na zero value.\nMeasuring background time: By default the time spent in the blocked command\nis not account for the total command duration. To include such time you should\nuse RedisModule_BlockedClientMeasureTimeStart() and RedisModule_BlockedClientMeasureTimeEnd() one,\nor multiple times within the blocking command background work.\n\n`RedisModule_BlockClientOnKeys`\n\n\n```RedisModuleBlockedClient *RedisModule_BlockClientOnKeys(RedisModuleCtx *ctx,\n                                                        RedisModuleCmdFunc reply_callback,\n                                                        RedisModuleCmdFunc timeout_callback,\n                                                        void (*free_privdata)(RedisModuleCtx*, void*),\n                                                        long long timeout_ms,\n                                                        RedisModuleString **keys,\n                                                        int numkeys,\n                                                        void *privdata);\n```\n\n\nAvailable since: 6.0.0\nThis call is similar to RedisModule_BlockClient(), however in this case we\ndon't just block the client, but also ask Redis to unblock it automatically\nonce certain keys become \"ready\", that is, contain more data.\nBasically this is similar to what a typical Redis command usually does,\nlike BLPOP or BZPOPMAX: the client blocks if it cannot be served ASAP,\nand later when the key receives new data (a list push for instance), the\nclient is unblocked and served.\nHowever in the case of this module API, when the client is unblocked?\n\nIf you block on a key of a type that has blocking operations associated,\n   like a list, a sorted set, a stream, and so forth, the client may be\n   unblocked once the relevant key is targeted by an operation that normally\n   unblocks the native blocking operations for that type. So if we block\n   on a list key, an RPUSH command may unblock our client and so forth.\nIf you are implementing your native data type, or if you want to add new\n   unblocking conditions in addition to \"1\", you can call the modules API\n   RedisModule_SignalKeyAsReady().\n\nAnyway we can't be sure if the client should be unblocked just because the\nkey is signaled as ready: for instance a successive operation may change the\nkey, or a client in queue before this one can be served, modifying the key\nas well and making it empty again. So when a client is blocked with\nRedisModule_BlockClientOnKeys() the reply callback is not called after\nRedisModule_UnblockClient() is called, but every time a key is signaled as ready:\nif the reply callback can serve the client, it returns `REDISMODULE_OK`\nand the client is unblocked, otherwise it will return `REDISMODULE_ERR`\nand we'll try again later.\nThe reply callback can access the key that was signaled as ready by\ncalling the API RedisModule_GetBlockedClientReadyKey(), that returns\njust the string name of the key as a `RedisModuleString` object.\nThanks to this system we can setup complex blocking scenarios, like\nunblocking a client only if a list contains at least 5 items or other\nmore fancy logics.\nNote that another difference with RedisModule_BlockClient(), is that here\nwe pass the private data directly when blocking the client: it will\nbe accessible later in the reply callback. Normally when blocking with\nRedisModule_BlockClient() the private data to reply to the client is\npassed when calling RedisModule_UnblockClient() but here the unblocking\nis performed by Redis itself, so we need to have some private data before\nhand. The private data is used to store any information about the specific\nunblocking operation that you are implementing. Such information will be\nfreed using the `free_privdata` callback provided by the user.\nHowever the reply callback will be able to access the argument vector of\nthe command, so the private data is often not needed.\nNote: Under normal circumstances RedisModule_UnblockClient should not be\n      called for clients that are blocked on keys (Either the key will\n      become ready or a timeout will occur). If for some reason you do want\n      to call RedisModule_UnblockClient it is possible: Client will be\n      handled as if it were timed-out (You must implement the timeout\n      callback in that case).\n\n`RedisModule_SignalKeyAsReady`\n\n\n```void RedisModule_SignalKeyAsReady(RedisModuleCtx *ctx, RedisModuleString *key);\n```\n\n\nAvailable since: 6.0.0\nThis function is used in order to potentially unblock a client blocked\non keys with RedisModule_BlockClientOnKeys(). When this function is called,\nall the clients blocked for this key will get their `reply_callback` called.\nNote: The function has no effect if the signaled key doesn't exist.\n\n`RedisModule_UnblockClient`\n\n\n```int RedisModule_UnblockClient(RedisModuleBlockedClient *bc, void *privdata);\n```\n\n\nAvailable since: 4.0.0\nUnblock a client blocked by `RedisModule_BlockedClient`. This will trigger\nthe reply callbacks to be called in order to reply to the client.\nThe 'privdata' argument will be accessible by the reply callback, so\nthe caller of this function can pass any value that is needed in order to\nactually reply to the client.\nA common usage for 'privdata' is a thread that computes something that\nneeds to be passed to the client, included but not limited some slow\nto compute reply or some reply obtained via networking.\nNote 1: this function can be called from threads spawned by the module.\nNote 2: when we unblock a client that is blocked for keys using the API RedisModule_BlockClientOnKeys(), the `privdata` argument here is not used.\nUnblocking a client that was blocked for keys using this API will still require the client to get some reply, so the function will use the \"timeout\" handler in order to do so. \nThe `privdata` provided in RedisModule_BlockClientOnKeys() is accessible from the timeout\ncallback via RedisModule_GetBlockedClientPrivateData).\n\n`RedisModule_AbortBlock`\n\n\n```int RedisModule_AbortBlock(RedisModuleBlockedClient *bc);\n```\n\n\nAvailable since: 4.0.0\nAbort a blocked client blocking operation: the client will be unblocked\nwithout firing any callback.\n\n`RedisModule_SetDisconnectCallback`\n\n\n```void RedisModule_SetDisconnectCallback(RedisModuleBlockedClient *bc,\n                                       RedisModuleDisconnectFunc callback);\n```\n\n\nAvailable since: 5.0.0\nSet a callback that will be called if a blocked client disconnects\nbefore the module has a chance to call RedisModule_UnblockClient()\nUsually what you want to do there, is to cleanup your module state\nso that you can call RedisModule_UnblockClient() safely, otherwise\nthe client will remain blocked forever if the timeout is large.\nNotes:\n\n\nIt is not safe to call Reply* family functions here, it is also\n   useless since the client is gone.\n\n\nThis callback is not called if the client disconnects because of\n   a timeout. In such a case, the client is unblocked automatically\n   and the timeout callback is called.\n\n\n\n`RedisModule_IsBlockedReplyRequest`\n\n\n```int RedisModule_IsBlockedReplyRequest(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nReturn non-zero if a module command was called in order to fill the\nreply for a blocked client.\n\n`RedisModule_IsBlockedTimeoutRequest`\n\n\n```int RedisModule_IsBlockedTimeoutRequest(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nReturn non-zero if a module command was called in order to fill the\nreply for a blocked client that timed out.\n\n`RedisModule_GetBlockedClientPrivateData`\n\n\n```void *RedisModule_GetBlockedClientPrivateData(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nGet the private data set by RedisModule_UnblockClient()\n\n`RedisModule_GetBlockedClientReadyKey`\n\n\n```RedisModuleString *RedisModule_GetBlockedClientReadyKey(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.0.0\nGet the key that is ready when the reply callback is called in the context\nof a client blocked by RedisModule_BlockClientOnKeys().\n\n`RedisModule_GetBlockedClientHandle`\n\n\n```RedisModuleBlockedClient *RedisModule_GetBlockedClientHandle(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 5.0.0\nGet the blocked client associated with a given context.\nThis is useful in the reply and timeout callbacks of blocked clients,\nbefore sometimes the module has the blocked client handle references\naround, and wants to cleanup it.\n\n`RedisModule_BlockedClientDisconnected`\n\n\n```int RedisModule_BlockedClientDisconnected(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 5.0.0\nReturn true if when the free callback of a blocked client is called,\nthe reason for the client to be unblocked is that it disconnected\nwhile it was blocked.\n\nThread Safe Contexts\n\n`RedisModule_GetThreadSafeContext`\n\n\n```RedisModuleCtx *RedisModule_GetThreadSafeContext(RedisModuleBlockedClient *bc);\n```\n\n\nAvailable since: 4.0.0\nReturn a context which can be used inside threads to make Redis context\ncalls with certain modules APIs. If 'bc' is not NULL then the module will\nbe bound to a blocked client, and it will be possible to use the\n`RedisModule_Reply*` family of functions to accumulate a reply for when the\nclient will be unblocked. Otherwise the thread safe context will be\ndetached by a specific client.\nTo call non-reply APIs, the thread safe context must be prepared with:\n\n\n```RedisModule_ThreadSafeContextLock(ctx);\n... make your call here ...\nRedisModule_ThreadSafeContextUnlock(ctx);\n```\n\n\nThis is not needed when using `RedisModule_Reply*` functions, assuming\nthat a blocked client was used when the context was created, otherwise\nno `RedisModule_Reply`* call should be made at all.\nNOTE: If you're creating a detached thread safe context (bc is NULL),\nconsider using RedisModule_GetDetachedThreadSafeContext which will also retain\nthe module ID and thus be more useful for logging.\n\n`RedisModule_GetDetachedThreadSafeContext`\n\n\n```RedisModuleCtx *RedisModule_GetDetachedThreadSafeContext(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.0.9\nReturn a detached thread safe context that is not associated with any\nspecific blocked client, but is associated with the module's context.\nThis is useful for modules that wish to hold a global context over\na long term, for purposes such as logging.\n\n`RedisModule_FreeThreadSafeContext`\n\n\n```void RedisModule_FreeThreadSafeContext(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nRelease a thread safe context.\n\n`RedisModule_ThreadSafeContextLock`\n\n\n```void RedisModule_ThreadSafeContextLock(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nAcquire the server lock before executing a thread safe API call.\nThis is not needed for `RedisModule_Reply*` calls when there is\na blocked client connected to the thread safe context.\n\n`RedisModule_ThreadSafeContextTryLock`\n\n\n```int RedisModule_ThreadSafeContextTryLock(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.0.8\nSimilar to RedisModule_ThreadSafeContextLock but this function\nwould not block if the server lock is already acquired.\nIf successful (lock acquired) `REDISMODULE_OK` is returned,\notherwise `REDISMODULE_ERR` is returned and errno is set\naccordingly.\n\n`RedisModule_ThreadSafeContextUnlock`\n\n\n```void RedisModule_ThreadSafeContextUnlock(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 4.0.0\nRelease the server lock after a thread safe API call was executed.\n\nModule Keyspace Notifications API\n\n`RedisModule_SubscribeToKeyspaceEvents`\n\n\n```int RedisModule_SubscribeToKeyspaceEvents(RedisModuleCtx *ctx,\n                                          int types,\n                                          RedisModuleNotificationFunc callback);\n```\n\n\nAvailable since: 4.0.9\nSubscribe to keyspace notifications. This is a low-level version of the\nkeyspace-notifications API. A module can register callbacks to be notified\nwhen keyspace events occur.\nNotification events are filtered by their type (string events, set events,\netc), and the subscriber callback receives only events that match a specific\nmask of event types.\nWhen subscribing to notifications with RedisModule_SubscribeToKeyspaceEvents\nthe module must provide an event type-mask, denoting the events the subscriber\nis interested in. This can be an ORed mask of any of the following flags:\n\n`REDISMODULE_NOTIFY_GENERIC`: Generic commands like DEL, EXPIRE, RENAME\n`REDISMODULE_NOTIFY_STRING`: String events\n`REDISMODULE_NOTIFY_LIST`: List events\n`REDISMODULE_NOTIFY_SET`: Set events\n`REDISMODULE_NOTIFY_HASH`: Hash events\n`REDISMODULE_NOTIFY_ZSET`: Sorted Set events\n`REDISMODULE_NOTIFY_EXPIRED`: Expiration events\n`REDISMODULE_NOTIFY_EVICTED`: Eviction events\n`REDISMODULE_NOTIFY_STREAM`: Stream events\n`REDISMODULE_NOTIFY_MODULE`: Module types events\n`REDISMODULE_NOTIFY_KEYMISS`: Key-miss events\n`REDISMODULE_NOTIFY_ALL`: All events (Excluding `REDISMODULE_NOTIFY_KEYMISS`)\n`REDISMODULE_NOTIFY_LOADED`: A special notification available only for modules,\n                              indicates that the key was loaded from persistence.\n                              Notice, when this event fires, the given key\n                              can not be retained, use RedisModule_CreateStringFromString\n                              instead.\n\nWe do not distinguish between key events and keyspace events, and it is up\nto the module to filter the actions taken based on the key.\nThe subscriber signature is:\n\n\n```int (*RedisModuleNotificationFunc) (RedisModuleCtx *ctx, int type,\n                                    const char *event,\n                                    RedisModuleString *key);\n```\n\n\n`type` is the event type bit, that must match the mask given at registration\ntime. The event string is the actual command being executed, and key is the\nrelevant Redis key.\nNotification callback gets executed with a redis context that can not be\nused to send anything to the client, and has the db number where the event\noccurred as its selected db number.\nNotice that it is not necessary to enable notifications in redis.conf for\nmodule notifications to work.\nWarning: the notification callbacks are performed in a synchronous manner,\nso notification callbacks must to be fast, or they would slow Redis down.\nIf you need to take long actions, use threads to offload them.\nSee https://redis.io/topics/notifications for more information.\n\n`RedisModule_GetNotifyKeyspaceEvents`\n\n\n```int RedisModule_GetNotifyKeyspaceEvents();\n```\n\n\nAvailable since: 6.0.0\nGet the configured bitmap of notify-keyspace-events (Could be used\nfor additional filtering in `RedisModuleNotificationFunc`)\n\n`RedisModule_NotifyKeyspaceEvent`\n\n\n```int RedisModule_NotifyKeyspaceEvent(RedisModuleCtx *ctx,\n                                    int type,\n                                    const char *event,\n                                    RedisModuleString *key);\n```\n\n\nAvailable since: 6.0.0\nExpose notifyKeyspaceEvent to modules\n\nModules Cluster API\n\n`RedisModule_RegisterClusterMessageReceiver`\n\n\n```void RedisModule_RegisterClusterMessageReceiver(RedisModuleCtx *ctx,\n                                                uint8_t type,\n                                                RedisModuleClusterMessageReceiver callback);\n```\n\n\nAvailable since: 5.0.0\nRegister a callback receiver for cluster messages of type 'type'. If there\nwas already a registered callback, this will replace the callback function\nwith the one provided, otherwise if the callback is set to NULL and there\nis already a callback for this function, the callback is unregistered\n(so this API call is also used in order to delete the receiver).\n\n`RedisModule_SendClusterMessage`\n\n\n```int RedisModule_SendClusterMessage(RedisModuleCtx *ctx,\n                                   const char *target_id,\n                                   uint8_t type,\n                                   const char *msg,\n                                   uint32_t len);\n```\n\n\nAvailable since: 5.0.0\nSend a message to all the nodes in the cluster if `target` is NULL, otherwise\nat the specified target, which is a `REDISMODULE_NODE_ID_LEN` bytes node ID, as\nreturned by the receiver callback or by the nodes iteration functions.\nThe function returns `REDISMODULE_OK` if the message was successfully sent,\notherwise if the node is not connected or such node ID does not map to any\nknown cluster node, `REDISMODULE_ERR` is returned.\n\n`RedisModule_GetClusterNodesList`\n\n\n```char **RedisModule_GetClusterNodesList(RedisModuleCtx *ctx, size_t *numnodes);\n```\n\n\nAvailable since: 5.0.0\nReturn an array of string pointers, each string pointer points to a cluster\nnode ID of exactly `REDISMODULE_NODE_ID_LEN` bytes (without any null term).\nThe number of returned node IDs is stored into `*numnodes`.\nHowever if this function is called by a module not running an a Redis\ninstance with Redis Cluster enabled, NULL is returned instead.\nThe IDs returned can be used with RedisModule_GetClusterNodeInfo() in order\nto get more information about single node.\nThe array returned by this function must be freed using the function\nRedisModule_FreeClusterNodesList().\nExample:\n\n\n```size_t count, j;\nchar **ids = RedisModule_GetClusterNodesList(ctx,&count);\nfor (j = 0; j < count; j++) {\n    RedisModule_Log(ctx,\"notice\",\"Node %.*s\",\n        REDISMODULE_NODE_ID_LEN,ids[j]);\n}\nRedisModule_FreeClusterNodesList(ids);\n```\n\n\n\n`RedisModule_FreeClusterNodesList`\n\n\n```void RedisModule_FreeClusterNodesList(char **ids);\n```\n\n\nAvailable since: 5.0.0\nFree the node list obtained with RedisModule_GetClusterNodesList.\n\n`RedisModule_GetMyClusterID`\n\n\n```const char *RedisModule_GetMyClusterID(void);\n```\n\n\nAvailable since: 5.0.0\nReturn this node ID (`REDISMODULE_CLUSTER_ID_LEN` bytes) or NULL if the cluster\nis disabled.\n\n`RedisModule_GetClusterSize`\n\n\n```size_t RedisModule_GetClusterSize(void);\n```\n\n\nAvailable since: 5.0.0\nReturn the number of nodes in the cluster, regardless of their state\n(handshake, noaddress, ...) so that the number of active nodes may actually\nbe smaller, but not greater than this number. If the instance is not in\ncluster mode, zero is returned.\n\n`RedisModule_GetClusterNodeInfo`\n\n\n```int RedisModule_GetClusterNodeInfo(RedisModuleCtx *ctx,\n                                   const char *id,\n                                   char *ip,\n                                   char *master_id,\n                                   int *port,\n                                   int *flags);\n```\n\n\nAvailable since: 5.0.0\nPopulate the specified info for the node having as ID the specified 'id',\nthen returns `REDISMODULE_OK`. Otherwise if the format of node ID is invalid\nor the node ID does not exist from the POV of this local node, `REDISMODULE_ERR`\nis returned.\nThe arguments `ip`, `master_id`, `port` and `flags` can be NULL in case we don't\nneed to populate back certain info. If an `ip` and `master_id` (only populated\nif the instance is a slave) are specified, they point to buffers holding\nat least `REDISMODULE_NODE_ID_LEN` bytes. The strings written back as `ip`\nand `master_id` are not null terminated.\nThe list of flags reported is the following:\n\n`REDISMODULE_NODE_MYSELF`:       This node\n`REDISMODULE_NODE_MASTER`:       The node is a master\n`REDISMODULE_NODE_SLAVE`:        The node is a replica\n`REDISMODULE_NODE_PFAIL`:        We see the node as failing\n`REDISMODULE_NODE_FAIL`:         The cluster agrees the node is failing\n`REDISMODULE_NODE_NOFAILOVER`:   The slave is configured to never failover\n\n\n`RedisModule_SetClusterFlags`\n\n\n```void RedisModule_SetClusterFlags(RedisModuleCtx *ctx, uint64_t flags);\n```\n\n\nAvailable since: 5.0.0\nSet Redis Cluster flags in order to change the normal behavior of\nRedis Cluster, especially with the goal of disabling certain functions.\nThis is useful for modules that use the Cluster API in order to create\na different distributed system, but still want to use the Redis Cluster\nmessage bus. Flags that can be set:\n\n`CLUSTER_MODULE_FLAG_NO_FAILOVER`\n`CLUSTER_MODULE_FLAG_NO_REDIRECTION`\n\nWith the following effects:\n\n\n`NO_FAILOVER`: prevent Redis Cluster slaves from failing over a dead master.\n               Also disables the replica migration feature.\n\n\n`NO_REDIRECTION`: Every node will accept any key, without trying to perform\n                  partitioning according to the Redis Cluster algorithm.\n                  Slots information will still be propagated across the\n                  cluster, but without effect.\n\n\n\nModules Timers API\nModule timers are a high precision \"green timers\" abstraction where\nevery module can register even millions of timers without problems, even if\nthe actual event loop will just have a single timer that is used to awake the\nmodule timers subsystem in order to process the next event.\nAll the timers are stored into a radix tree, ordered by expire time, when\nthe main Redis event loop timer callback is called, we try to process all\nthe timers already expired one after the other. Then we re-enter the event\nloop registering a timer that will expire when the next to process module\ntimer will expire.\nEvery time the list of active timers drops to zero, we unregister the\nmain event loop timer, so that there is no overhead when such feature is\nnot used.\n\n`RedisModule_CreateTimer`\n\n\n```RedisModuleTimerID RedisModule_CreateTimer(RedisModuleCtx *ctx,\n                                           mstime_t period,\n                                           RedisModuleTimerProc callback,\n                                           void *data);\n```\n\n\nAvailable since: 5.0.0\nCreate a new timer that will fire after `period` milliseconds, and will call\nthe specified function using `data` as argument. The returned timer ID can be\nused to get information from the timer or to stop it before it fires.\nNote that for the common use case of a repeating timer (Re-registration\nof the timer inside the `RedisModuleTimerProc` callback) it matters when\nthis API is called:\nIf it is called at the beginning of 'callback' it means\nthe event will triggered every 'period'.\nIf it is called at the end of 'callback' it means\nthere will 'period' milliseconds gaps between events.\n(If the time it takes to execute 'callback' is negligible the two\nstatements above mean the same)\n\n`RedisModule_StopTimer`\n\n\n```int RedisModule_StopTimer(RedisModuleCtx *ctx,\n                          RedisModuleTimerID id,\n                          void **data);\n```\n\n\nAvailable since: 5.0.0\nStop a timer, returns `REDISMODULE_OK` if the timer was found, belonged to the\ncalling module, and was stopped, otherwise `REDISMODULE_ERR` is returned.\nIf not NULL, the data pointer is set to the value of the data argument when\nthe timer was created.\n\n`RedisModule_GetTimerInfo`\n\n\n```int RedisModule_GetTimerInfo(RedisModuleCtx *ctx,\n                             RedisModuleTimerID id,\n                             uint64_t *remaining,\n                             void **data);\n```\n\n\nAvailable since: 5.0.0\nObtain information about a timer: its remaining time before firing\n(in milliseconds), and the private data pointer associated with the timer.\nIf the timer specified does not exist or belongs to a different module\nno information is returned and the function returns `REDISMODULE_ERR`, otherwise\n`REDISMODULE_OK` is returned. The arguments remaining or data can be NULL if\nthe caller does not need certain information.\n\nModules EventLoop API\n\n`RedisModule_EventLoopAdd`\n\n\n```int RedisModule_EventLoopAdd(int fd,\n                             int mask,\n                             RedisModuleEventLoopFunc func,\n                             void *user_data);\n```\n\n\nAvailable since: 7.0.0\nAdd a pipe / socket event to the event loop.\n\n\n`mask` must be one of the following values:\n\n`REDISMODULE_EVENTLOOP_READABLE`\n`REDISMODULE_EVENTLOOP_WRITABLE`\n`REDISMODULE_EVENTLOOP_READABLE | REDISMODULE_EVENTLOOP_WRITABLE`\n\n\n\nOn success `REDISMODULE_OK` is returned, otherwise\n`REDISMODULE_ERR` is returned and errno is set to the following values:\n\nERANGE: `fd` is negative or higher than `maxclients` Redis config.\nEINVAL: `callback` is NULL or `mask` value is invalid.\n\n`errno` might take other values in case of an internal error.\nExample:\n\n\n```void onReadable(int fd, void *user_data, int mask) {\n    char buf[32];\n    int bytes = read(fd,buf,sizeof(buf));\n    printf(\"Read %d bytes \\n\", bytes);\n}\nRedisModule_EventLoopAdd(fd, REDISMODULE_EVENTLOOP_READABLE, onReadable, NULL);\n```\n\n\n\n`RedisModule_EventLoopDel`\n\n\n```int RedisModule_EventLoopDel(int fd, int mask);\n```\n\n\nAvailable since: 7.0.0\nDelete a pipe / socket event from the event loop.\n\n\n`mask` must be one of the following values:\n\n`REDISMODULE_EVENTLOOP_READABLE`\n`REDISMODULE_EVENTLOOP_WRITABLE`\n`REDISMODULE_EVENTLOOP_READABLE | REDISMODULE_EVENTLOOP_WRITABLE`\n\n\n\nOn success `REDISMODULE_OK` is returned, otherwise\n`REDISMODULE_ERR` is returned and errno is set to the following values:\n\nERANGE: `fd` is negative or higher than `maxclients` Redis config.\nEINVAL: `mask` value is invalid.\n\n\n`RedisModule_EventLoopAddOneShot`\n\n\n```int RedisModule_EventLoopAddOneShot(RedisModuleEventLoopOneShotFunc func,\n                                    void *user_data);\n```\n\n\nAvailable since: 7.0.0\nThis function can be called from other threads to trigger callback on Redis\nmain thread. On success `REDISMODULE_OK` is returned. If `func` is NULL\n`REDISMODULE_ERR` is returned and errno is set to EINVAL.\n\nModules ACL API\nImplements a hook into the authentication and authorization within Redis.\n\n`RedisModule_CreateModuleUser`\n\n\n```RedisModuleUser *RedisModule_CreateModuleUser(const char *name);\n```\n\n\nAvailable since: 6.0.0\nCreates a Redis ACL user that the module can use to authenticate a client.\nAfter obtaining the user, the module should set what such user can do\nusing the `RedisModule_SetUserACL()` function. Once configured, the user\ncan be used in order to authenticate a connection, with the specified\nACL rules, using the `RedisModule_AuthClientWithUser()` function.\nNote that:\n\nUsers created here are not listed by the ACL command.\nUsers created here are not checked for duplicated name, so it's up to\n  the module calling this function to take care of not creating users\n  with the same name.\nThe created user can be used to authenticate multiple Redis connections.\n\nThe caller can later free the user using the function\nRedisModule_FreeModuleUser(). When this function is called, if there are\nstill clients authenticated with this user, they are disconnected.\nThe function to free the user should only be used when the caller really\nwants to invalidate the user to define a new one with different\ncapabilities.\n\n`RedisModule_FreeModuleUser`\n\n\n```int RedisModule_FreeModuleUser(RedisModuleUser *user);\n```\n\n\nAvailable since: 6.0.0\nFrees a given user and disconnects all of the clients that have been\nauthenticated with it. See RedisModule_CreateModuleUser for detailed usage.\n\n`RedisModule_SetModuleUserACL`\n\n\n```int RedisModule_SetModuleUserACL(RedisModuleUser *user, const char* acl);\n```\n\n\nAvailable since: 6.0.0\nSets the permissions of a user created through the redis module\ninterface. The syntax is the same as ACL SETUSER, so refer to the\ndocumentation in acl.c for more information. See RedisModule_CreateModuleUser\nfor detailed usage.\nReturns `REDISMODULE_OK` on success and `REDISMODULE_ERR` on failure\nand will set an errno describing why the operation failed.\n\n`RedisModule_SetModuleUserACLString`\n\n\n```int RedisModule_SetModuleUserACLString(RedisModuleCtx *ctx,\n                                       RedisModuleUser *user,\n                                       const char *acl,\n                                       RedisModuleString **error);\n```\n\n\nAvailable since: 7.0.6\nSets the permission of a user with a complete ACL string, such as one\nwould use on the redis ACL SETUSER command line API. This differs from\nRedisModule_SetModuleUserACL, which only takes single ACL operations at a time.\nReturns `REDISMODULE_OK` on success and `REDISMODULE_ERR` on failure\nif a `RedisModuleString` is provided in error, a string describing the error\nwill be returned\n\n`RedisModule_GetModuleUserACLString`\n\n\n```RedisModuleString *RedisModule_GetModuleUserACLString(RedisModuleUser *user);\n```\n\n\nAvailable since: 7.0.6\nGet the ACL string for a given user\nReturns a `RedisModuleString`\n\n`RedisModule_GetCurrentUserName`\n\n\n```RedisModuleString *RedisModule_GetCurrentUserName(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nRetrieve the user name of the client connection behind the current context.\nThe user name can be used later, in order to get a `RedisModuleUser`.\nSee more information in RedisModule_GetModuleUserFromUserName.\nThe returned string must be released with RedisModule_FreeString() or by\nenabling automatic memory management.\n\n`RedisModule_GetModuleUserFromUserName`\n\n\n```RedisModuleUser *RedisModule_GetModuleUserFromUserName(RedisModuleString *name);\n```\n\n\nAvailable since: 7.0.0\nA `RedisModuleUser` can be used to check if command, key or channel can be executed or\naccessed according to the ACLs rules associated with that user.\nWhen a Module wants to do ACL checks on a general ACL user (not created by RedisModule_CreateModuleUser),\nit can get the `RedisModuleUser` from this API, based on the user name retrieved by RedisModule_GetCurrentUserName.\nSince a general ACL user can be deleted at any time, this `RedisModuleUser` should be used only in the context\nwhere this function was called. In order to do ACL checks out of that context, the Module can store the user name,\nand call this API at any other context.\nReturns NULL if the user is disabled or the user does not exist.\nThe caller should later free the user using the function RedisModule_FreeModuleUser().\n\n`RedisModule_ACLCheckCommandPermissions`\n\n\n```int RedisModule_ACLCheckCommandPermissions(RedisModuleUser *user,\n                                           RedisModuleString **argv,\n                                           int argc);\n```\n\n\nAvailable since: 7.0.0\nChecks if the command can be executed by the user, according to the ACLs associated with it.\nOn success a `REDISMODULE_OK` is returned, otherwise\n`REDISMODULE_ERR` is returned and errno is set to the following values:\n\nENOENT: Specified command does not exist.\nEACCES: Command cannot be executed, according to ACL rules\n\n\n`RedisModule_ACLCheckKeyPermissions`\n\n\n```int RedisModule_ACLCheckKeyPermissions(RedisModuleUser *user,\n                                       RedisModuleString *key,\n                                       int flags);\n```\n\n\nAvailable since: 7.0.0\nCheck if the key can be accessed by the user according to the ACLs attached to the user\nand the flags representing the key access. The flags are the same that are used in the\nkeyspec for logical operations. These flags are documented in RedisModule_SetCommandInfo as\nthe `REDISMODULE_CMD_KEY_ACCESS`, `REDISMODULE_CMD_KEY_UPDATE`, `REDISMODULE_CMD_KEY_INSERT`,\nand `REDISMODULE_CMD_KEY_DELETE` flags.\nIf no flags are supplied, the user is still required to have some access to the key for\nthis command to return successfully.\nIf the user is able to access the key then `REDISMODULE_OK` is returned, otherwise\n`REDISMODULE_ERR` is returned and errno is set to one of the following values:\n\nEINVAL: The provided flags are invalid.\nEACCESS: The user does not have permission to access the key.\n\n\n`RedisModule_ACLCheckChannelPermissions`\n\n\n```int RedisModule_ACLCheckChannelPermissions(RedisModuleUser *user,\n                                           RedisModuleString *ch,\n                                           int flags);\n```\n\n\nAvailable since: 7.0.0\nCheck if the pubsub channel can be accessed by the user based off of the given\naccess flags. See RedisModule_ChannelAtPosWithFlags for more information about the\npossible flags that can be passed in.\nIf the user is able to access the pubsub channel then `REDISMODULE_OK` is returned, otherwise\n`REDISMODULE_ERR` is returned and errno is set to one of the following values:\n\nEINVAL: The provided flags are invalid.\nEACCESS: The user does not have permission to access the pubsub channel.\n\n\n`RedisModule_ACLAddLogEntry`\n\n\n```int RedisModule_ACLAddLogEntry(RedisModuleCtx *ctx,\n                               RedisModuleUser *user,\n                               RedisModuleString *object,\n                               RedisModuleACLLogEntryReason reason);\n```\n\n\nAvailable since: 7.0.0\nAdds a new entry in the ACL log.\nReturns `REDISMODULE_OK` on success and `REDISMODULE_ERR` on error.\nFor more information about ACL log, please refer to https://redis.io/commands/acl-log\n\n`RedisModule_AuthenticateClientWithUser`\n\n\n```int RedisModule_AuthenticateClientWithUser(RedisModuleCtx *ctx,\n                                           RedisModuleUser *module_user,\n                                           RedisModuleUserChangedFunc callback,\n                                           void *privdata,\n                                           uint64_t *client_id);\n```\n\n\nAvailable since: 6.0.0\nAuthenticate the current context's user with the provided redis acl user.\nReturns `REDISMODULE_ERR` if the user is disabled.\nSee authenticateClientWithUser for information about callback, `client_id`,\nand general usage for authentication.\n\n`RedisModule_AuthenticateClientWithACLUser`\n\n\n```int RedisModule_AuthenticateClientWithACLUser(RedisModuleCtx *ctx,\n                                              const char *name,\n                                              size_t len,\n                                              RedisModuleUserChangedFunc callback,\n                                              void *privdata,\n                                              uint64_t *client_id);\n```\n\n\nAvailable since: 6.0.0\nAuthenticate the current context's user with the provided redis acl user.\nReturns `REDISMODULE_ERR` if the user is disabled or the user does not exist.\nSee authenticateClientWithUser for information about callback, `client_id`,\nand general usage for authentication.\n\n`RedisModule_DeauthenticateAndCloseClient`\n\n\n```int RedisModule_DeauthenticateAndCloseClient(RedisModuleCtx *ctx,\n                                             uint64_t client_id);\n```\n\n\nAvailable since: 6.0.0\nDeauthenticate and close the client. The client resources will not be\nimmediately freed, but will be cleaned up in a background job. This is\nthe recommended way to deauthenticate a client since most clients can't\nhandle users becoming deauthenticated. Returns `REDISMODULE_ERR` when the\nclient doesn't exist and `REDISMODULE_OK` when the operation was successful.\nThe client ID is returned from the RedisModule_AuthenticateClientWithUser and\nRedisModule_AuthenticateClientWithACLUser APIs, but can be obtained through\nthe CLIENT api or through server events.\nThis function is not thread safe, and must be executed within the context\nof a command or thread safe context.\n\n`RedisModule_RedactClientCommandArgument`\n\n\n```int RedisModule_RedactClientCommandArgument(RedisModuleCtx *ctx, int pos);\n```\n\n\nAvailable since: 7.0.0\nRedact the client command argument specified at the given position. Redacted arguments \nare obfuscated in user facing commands such as SLOWLOG or MONITOR, as well as\nnever being written to server logs. This command may be called multiple times on the\nsame position.\nNote that the command name, position 0, can not be redacted. \nReturns `REDISMODULE_OK` if the argument was redacted and `REDISMODULE_ERR` if there \nwas an invalid parameter passed in or the position is outside the client \nargument range.\n\n`RedisModule_GetClientCertificate`\n\n\n```RedisModuleString *RedisModule_GetClientCertificate(RedisModuleCtx *ctx,\n                                                    uint64_t client_id);\n```\n\n\nAvailable since: 6.0.9\nReturn the X.509 client-side certificate used by the client to authenticate\nthis connection.\nThe return value is an allocated `RedisModuleString` that is a X.509 certificate\nencoded in PEM (Base64) format. It should be freed (or auto-freed) by the caller.\nA NULL value is returned in the following conditions:\n\nConnection ID does not exist\nConnection is not a TLS connection\nConnection is a TLS connection but no client certificate was used\n\n\nModules Dictionary API\nImplements a sorted dictionary (actually backed by a radix tree) with\nthe usual get / set / del / num-items API, together with an iterator\ncapable of going back and forth.\n\n`RedisModule_CreateDict`\n\n\n```RedisModuleDict *RedisModule_CreateDict(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 5.0.0\nCreate a new dictionary. The 'ctx' pointer can be the current module context\nor NULL, depending on what you want. Please follow the following rules:\n\nUse a NULL context if you plan to retain a reference to this dictionary\n   that will survive the time of the module callback where you created it.\nUse a NULL context if no context is available at the time you are creating\n   the dictionary (of course...).\nHowever use the current callback context as 'ctx' argument if the\n   dictionary time to live is just limited to the callback scope. In this\n   case, if enabled, you can enjoy the automatic memory management that will\n   reclaim the dictionary memory, as well as the strings returned by the\n   Next / Prev dictionary iterator calls.\n\n\n`RedisModule_FreeDict`\n\n\n```void RedisModule_FreeDict(RedisModuleCtx *ctx, RedisModuleDict *d);\n```\n\n\nAvailable since: 5.0.0\nFree a dictionary created with RedisModule_CreateDict(). You need to pass the\ncontext pointer 'ctx' only if the dictionary was created using the\ncontext instead of passing NULL.\n\n`RedisModule_DictSize`\n\n\n```uint64_t RedisModule_DictSize(RedisModuleDict *d);\n```\n\n\nAvailable since: 5.0.0\nReturn the size of the dictionary (number of keys).\n\n`RedisModule_DictSetC`\n\n\n```int RedisModule_DictSetC(RedisModuleDict *d,\n                         void *key,\n                         size_t keylen,\n                         void *ptr);\n```\n\n\nAvailable since: 5.0.0\nStore the specified key into the dictionary, setting its value to the\npointer 'ptr'. If the key was added with success, since it did not\nalready exist, `REDISMODULE_OK` is returned. Otherwise if the key already\nexists the function returns `REDISMODULE_ERR`.\n\n`RedisModule_DictReplaceC`\n\n\n```int RedisModule_DictReplaceC(RedisModuleDict *d,\n                             void *key,\n                             size_t keylen,\n                             void *ptr);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_DictSetC() but will replace the key with the new\nvalue if the key already exists.\n\n`RedisModule_DictSet`\n\n\n```int RedisModule_DictSet(RedisModuleDict *d, RedisModuleString *key, void *ptr);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_DictSetC() but takes the key as a `RedisModuleString`.\n\n`RedisModule_DictReplace`\n\n\n```int RedisModule_DictReplace(RedisModuleDict *d,\n                            RedisModuleString *key,\n                            void *ptr);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_DictReplaceC() but takes the key as a `RedisModuleString`.\n\n`RedisModule_DictGetC`\n\n\n```void *RedisModule_DictGetC(RedisModuleDict *d,\n                           void *key,\n                           size_t keylen,\n                           int *nokey);\n```\n\n\nAvailable since: 5.0.0\nReturn the value stored at the specified key. The function returns NULL\nboth in the case the key does not exist, or if you actually stored\nNULL at key. So, optionally, if the 'nokey' pointer is not NULL, it will\nbe set by reference to 1 if the key does not exist, or to 0 if the key\nexists.\n\n`RedisModule_DictGet`\n\n\n```void *RedisModule_DictGet(RedisModuleDict *d,\n                          RedisModuleString *key,\n                          int *nokey);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_DictGetC() but takes the key as a `RedisModuleString`.\n\n`RedisModule_DictDelC`\n\n\n```int RedisModule_DictDelC(RedisModuleDict *d,\n                         void *key,\n                         size_t keylen,\n                         void *oldval);\n```\n\n\nAvailable since: 5.0.0\nRemove the specified key from the dictionary, returning `REDISMODULE_OK` if\nthe key was found and deleted, or `REDISMODULE_ERR` if instead there was\nno such key in the dictionary. When the operation is successful, if\n'oldval' is not NULL, then '*oldval' is set to the value stored at the\nkey before it was deleted. Using this feature it is possible to get\na pointer to the value (for instance in order to release it), without\nhaving to call RedisModule_DictGet() before deleting the key.\n\n`RedisModule_DictDel`\n\n\n```int RedisModule_DictDel(RedisModuleDict *d,\n                        RedisModuleString *key,\n                        void *oldval);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_DictDelC() but gets the key as a `RedisModuleString`.\n\n`RedisModule_DictIteratorStartC`\n\n\n```RedisModuleDictIter *RedisModule_DictIteratorStartC(RedisModuleDict *d,\n                                                    const char *op,\n                                                    void *key,\n                                                    size_t keylen);\n```\n\n\nAvailable since: 5.0.0\nReturn an iterator, setup in order to start iterating from the specified\nkey by applying the operator 'op', which is just a string specifying the\ncomparison operator to use in order to seek the first element. The\noperators available are:\n\n`^`   \u2013 Seek the first (lexicographically smaller) key.\n`$`   \u2013 Seek the last  (lexicographically bigger) key.\n`>`   \u2013 Seek the first element greater than the specified key.\n`>=`  \u2013 Seek the first element greater or equal than the specified key.\n`<`   \u2013 Seek the first element smaller than the specified key.\n`<=`  \u2013 Seek the first element smaller or equal than the specified key.\n`==`  \u2013 Seek the first element matching exactly the specified key.\n\nNote that for `^` and `$` the passed key is not used, and the user may\njust pass NULL with a length of 0.\nIf the element to start the iteration cannot be seeked based on the\nkey and operator passed, RedisModule_DictNext() / Prev() will just return\n`REDISMODULE_ERR` at the first call, otherwise they'll produce elements.\n\n`RedisModule_DictIteratorStart`\n\n\n```RedisModuleDictIter *RedisModule_DictIteratorStart(RedisModuleDict *d,\n                                                   const char *op,\n                                                   RedisModuleString *key);\n```\n\n\nAvailable since: 5.0.0\nExactly like RedisModule_DictIteratorStartC, but the key is passed as a\n`RedisModuleString`.\n\n`RedisModule_DictIteratorStop`\n\n\n```void RedisModule_DictIteratorStop(RedisModuleDictIter *di);\n```\n\n\nAvailable since: 5.0.0\nRelease the iterator created with RedisModule_DictIteratorStart(). This call\nis mandatory otherwise a memory leak is introduced in the module.\n\n`RedisModule_DictIteratorReseekC`\n\n\n```int RedisModule_DictIteratorReseekC(RedisModuleDictIter *di,\n                                    const char *op,\n                                    void *key,\n                                    size_t keylen);\n```\n\n\nAvailable since: 5.0.0\nAfter its creation with RedisModule_DictIteratorStart(), it is possible to\nchange the currently selected element of the iterator by using this\nAPI call. The result based on the operator and key is exactly like\nthe function RedisModule_DictIteratorStart(), however in this case the\nreturn value is just `REDISMODULE_OK` in case the seeked element was found,\nor `REDISMODULE_ERR` in case it was not possible to seek the specified\nelement. It is possible to reseek an iterator as many times as you want.\n\n`RedisModule_DictIteratorReseek`\n\n\n```int RedisModule_DictIteratorReseek(RedisModuleDictIter *di,\n                                   const char *op,\n                                   RedisModuleString *key);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_DictIteratorReseekC() but takes the key as a\n`RedisModuleString`.\n\n`RedisModule_DictNextC`\n\n\n```void *RedisModule_DictNextC(RedisModuleDictIter *di,\n                            size_t *keylen,\n                            void **dataptr);\n```\n\n\nAvailable since: 5.0.0\nReturn the current item of the dictionary iterator `di` and steps to the\nnext element. If the iterator already yield the last element and there\nare no other elements to return, NULL is returned, otherwise a pointer\nto a string representing the key is provided, and the `*keylen` length\nis set by reference (if keylen is not NULL). The `*dataptr`, if not NULL\nis set to the value of the pointer stored at the returned key as auxiliary\ndata (as set by the RedisModule_DictSet API).\nUsage example:\n\n\n``` ... create the iterator here ...\n char *key;\n void *data;\n while((key = RedisModule_DictNextC(iter,&keylen,&data)) != NULL) {\n     printf(\"%.*s %p\\n\", (int)keylen, key, data);\n }\n```\n\n\nThe returned pointer is of type void because sometimes it makes sense\nto cast it to a `char*` sometimes to an unsigned `char*` depending on the\nfact it contains or not binary data, so this API ends being more\ncomfortable to use.\nThe validity of the returned pointer is until the next call to the\nnext/prev iterator step. Also the pointer is no longer valid once the\niterator is released.\n\n`RedisModule_DictPrevC`\n\n\n```void *RedisModule_DictPrevC(RedisModuleDictIter *di,\n                            size_t *keylen,\n                            void **dataptr);\n```\n\n\nAvailable since: 5.0.0\nThis function is exactly like RedisModule_DictNext() but after returning\nthe currently selected element in the iterator, it selects the previous\nelement (lexicographically smaller) instead of the next one.\n\n`RedisModule_DictNext`\n\n\n```RedisModuleString *RedisModule_DictNext(RedisModuleCtx *ctx,\n                                        RedisModuleDictIter *di,\n                                        void **dataptr);\n```\n\n\nAvailable since: 5.0.0\nLike `RedisModuleNextC()`, but instead of returning an internally allocated\nbuffer and key length, it returns directly a module string object allocated\nin the specified context 'ctx' (that may be NULL exactly like for the main\nAPI RedisModule_CreateString).\nThe returned string object should be deallocated after use, either manually\nor by using a context that has automatic memory management active.\n\n`RedisModule_DictPrev`\n\n\n```RedisModuleString *RedisModule_DictPrev(RedisModuleCtx *ctx,\n                                        RedisModuleDictIter *di,\n                                        void **dataptr);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_DictNext() but after returning the currently selected\nelement in the iterator, it selects the previous element (lexicographically\nsmaller) instead of the next one.\n\n`RedisModule_DictCompareC`\n\n\n```int RedisModule_DictCompareC(RedisModuleDictIter *di,\n                             const char *op,\n                             void *key,\n                             size_t keylen);\n```\n\n\nAvailable since: 5.0.0\nCompare the element currently pointed by the iterator to the specified\nelement given by key/keylen, according to the operator 'op' (the set of\nvalid operators are the same valid for RedisModule_DictIteratorStart).\nIf the comparison is successful the command returns `REDISMODULE_OK`\notherwise `REDISMODULE_ERR` is returned.\nThis is useful when we want to just emit a lexicographical range, so\nin the loop, as we iterate elements, we can also check if we are still\non range.\nThe function return `REDISMODULE_ERR` if the iterator reached the\nend of elements condition as well.\n\n`RedisModule_DictCompare`\n\n\n```int RedisModule_DictCompare(RedisModuleDictIter *di,\n                            const char *op,\n                            RedisModuleString *key);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_DictCompareC but gets the key to compare with the current\niterator key as a `RedisModuleString`.\n\nModules Info fields\n\n`RedisModule_InfoAddSection`\n\n\n```int RedisModule_InfoAddSection(RedisModuleInfoCtx *ctx, const char *name);\n```\n\n\nAvailable since: 6.0.0\nUsed to start a new section, before adding any fields. the section name will\nbe prefixed by `<modulename>_` and must only include A-Z,a-z,0-9.\nNULL or empty string indicates the default section (only `<modulename>`) is used.\nWhen return value is `REDISMODULE_ERR`, the section should and will be skipped.\n\n`RedisModule_InfoBeginDictField`\n\n\n```int RedisModule_InfoBeginDictField(RedisModuleInfoCtx *ctx, const char *name);\n```\n\n\nAvailable since: 6.0.0\nStarts a dict field, similar to the ones in INFO KEYSPACE. Use normal\n`RedisModule_InfoAddField`* functions to add the items to this field, and\nterminate with RedisModule_InfoEndDictField.\n\n`RedisModule_InfoEndDictField`\n\n\n```int RedisModule_InfoEndDictField(RedisModuleInfoCtx *ctx);\n```\n\n\nAvailable since: 6.0.0\nEnds a dict field, see RedisModule_InfoBeginDictField\n\n`RedisModule_InfoAddFieldString`\n\n\n```int RedisModule_InfoAddFieldString(RedisModuleInfoCtx *ctx,\n                                   const char *field,\n                                   RedisModuleString *value);\n```\n\n\nAvailable since: 6.0.0\nUsed by `RedisModuleInfoFunc` to add info fields.\nEach field will be automatically prefixed by `<modulename>_`.\nField names or values must not include `\\r\\n` or `:`.\n\n`RedisModule_InfoAddFieldCString`\n\n\n```int RedisModule_InfoAddFieldCString(RedisModuleInfoCtx *ctx,\n                                    const char *field,\n                                    const char *value);\n```\n\n\nAvailable since: 6.0.0\nSee RedisModule_InfoAddFieldString().\n\n`RedisModule_InfoAddFieldDouble`\n\n\n```int RedisModule_InfoAddFieldDouble(RedisModuleInfoCtx *ctx,\n                                   const char *field,\n                                   double value);\n```\n\n\nAvailable since: 6.0.0\nSee RedisModule_InfoAddFieldString().\n\n`RedisModule_InfoAddFieldLongLong`\n\n\n```int RedisModule_InfoAddFieldLongLong(RedisModuleInfoCtx *ctx,\n                                     const char *field,\n                                     long long value);\n```\n\n\nAvailable since: 6.0.0\nSee RedisModule_InfoAddFieldString().\n\n`RedisModule_InfoAddFieldULongLong`\n\n\n```int RedisModule_InfoAddFieldULongLong(RedisModuleInfoCtx *ctx,\n                                      const char *field,\n                                      unsigned long long value);\n```\n\n\nAvailable since: 6.0.0\nSee RedisModule_InfoAddFieldString().\n\n`RedisModule_RegisterInfoFunc`\n\n\n```int RedisModule_RegisterInfoFunc(RedisModuleCtx *ctx, RedisModuleInfoFunc cb);\n```\n\n\nAvailable since: 6.0.0\nRegisters callback for the INFO command. The callback should add INFO fields\nby calling the `RedisModule_InfoAddField*()` functions.\n\n`RedisModule_GetServerInfo`\n\n\n```RedisModuleServerInfoData *RedisModule_GetServerInfo(RedisModuleCtx *ctx,\n                                                     const char *section);\n```\n\n\nAvailable since: 6.0.0\nGet information about the server similar to the one that returns from the\nINFO command. This function takes an optional 'section' argument that may\nbe NULL. The return value holds the output and can be used with\nRedisModule_ServerInfoGetField and alike to get the individual fields.\nWhen done, it needs to be freed with RedisModule_FreeServerInfo or with the\nautomatic memory management mechanism if enabled.\n\n`RedisModule_FreeServerInfo`\n\n\n```void RedisModule_FreeServerInfo(RedisModuleCtx *ctx,\n                                RedisModuleServerInfoData *data);\n```\n\n\nAvailable since: 6.0.0\nFree data created with RedisModule_GetServerInfo(). You need to pass the\ncontext pointer 'ctx' only if the dictionary was created using the\ncontext instead of passing NULL.\n\n`RedisModule_ServerInfoGetField`\n\n\n```RedisModuleString *RedisModule_ServerInfoGetField(RedisModuleCtx *ctx,\n                                                  RedisModuleServerInfoData *data,\n                                                  const char* field);\n```\n\n\nAvailable since: 6.0.0\nGet the value of a field from data collected with RedisModule_GetServerInfo(). You\nneed to pass the context pointer 'ctx' only if you want to use auto memory\nmechanism to release the returned string. Return value will be NULL if the\nfield was not found.\n\n`RedisModule_ServerInfoGetFieldC`\n\n\n```const char *RedisModule_ServerInfoGetFieldC(RedisModuleServerInfoData *data,\n                                            const char* field);\n```\n\n\nAvailable since: 6.0.0\nSimilar to RedisModule_ServerInfoGetField, but returns a char* which should not be freed but the caller.\n\n`RedisModule_ServerInfoGetFieldSigned`\n\n\n```long long RedisModule_ServerInfoGetFieldSigned(RedisModuleServerInfoData *data,\n                                               const char* field,\n                                               int *out_err);\n```\n\n\nAvailable since: 6.0.0\nGet the value of a field from data collected with RedisModule_GetServerInfo(). If the\nfield is not found, or is not numerical or out of range, return value will be\n0, and the optional `out_err` argument will be set to `REDISMODULE_ERR`.\n\n`RedisModule_ServerInfoGetFieldUnsigned`\n\n\n```unsigned long long RedisModule_ServerInfoGetFieldUnsigned(RedisModuleServerInfoData *data,\n                                                          const char* field,\n                                                          int *out_err);\n```\n\n\nAvailable since: 6.0.0\nGet the value of a field from data collected with RedisModule_GetServerInfo(). If the\nfield is not found, or is not numerical or out of range, return value will be\n0, and the optional `out_err` argument will be set to `REDISMODULE_ERR`.\n\n`RedisModule_ServerInfoGetFieldDouble`\n\n\n```double RedisModule_ServerInfoGetFieldDouble(RedisModuleServerInfoData *data,\n                                            const char* field,\n                                            int *out_err);\n```\n\n\nAvailable since: 6.0.0\nGet the value of a field from data collected with RedisModule_GetServerInfo(). If the\nfield is not found, or is not a double, return value will be 0, and the\noptional `out_err` argument will be set to `REDISMODULE_ERR`.\n\nModules utility APIs\n\n`RedisModule_GetRandomBytes`\n\n\n```void RedisModule_GetRandomBytes(unsigned char *dst, size_t len);\n```\n\n\nAvailable since: 5.0.0\nReturn random bytes using SHA1 in counter mode with a /dev/urandom\ninitialized seed. This function is fast so can be used to generate\nmany bytes without any effect on the operating system entropy pool.\nCurrently this function is not thread safe.\n\n`RedisModule_GetRandomHexChars`\n\n\n```void RedisModule_GetRandomHexChars(char *dst, size_t len);\n```\n\n\nAvailable since: 5.0.0\nLike RedisModule_GetRandomBytes() but instead of setting the string to\nrandom bytes the string is set to random characters in the in the\nhex charset [0-9a-f].\n\nModules API exporting / importing\n\n`RedisModule_ExportSharedAPI`\n\n\n```int RedisModule_ExportSharedAPI(RedisModuleCtx *ctx,\n                                const char *apiname,\n                                void *func);\n```\n\n\nAvailable since: 5.0.4\nThis function is called by a module in order to export some API with a\ngiven name. Other modules will be able to use this API by calling the\nsymmetrical function RedisModule_GetSharedAPI() and casting the return value to\nthe right function pointer.\nThe function will return `REDISMODULE_OK` if the name is not already taken,\notherwise `REDISMODULE_ERR` will be returned and no operation will be\nperformed.\nIMPORTANT: the apiname argument should be a string literal with static\nlifetime. The API relies on the fact that it will always be valid in\nthe future.\n\n`RedisModule_GetSharedAPI`\n\n\n```void *RedisModule_GetSharedAPI(RedisModuleCtx *ctx, const char *apiname);\n```\n\n\nAvailable since: 5.0.4\nRequest an exported API pointer. The return value is just a void pointer\nthat the caller of this function will be required to cast to the right\nfunction pointer, so this is a private contract between modules.\nIf the requested API is not available then NULL is returned. Because\nmodules can be loaded at different times with different order, this\nfunction calls should be put inside some module generic API registering\nstep, that is called every time a module attempts to execute a\ncommand that requires external APIs: if some API cannot be resolved, the\ncommand should return an error.\nHere is an example:\n\n\n```int ... myCommandImplementation() {\n   if (getExternalAPIs() == 0) {\n        reply with an error here if we cannot have the APIs\n   }\n   // Use the API:\n   myFunctionPointer(foo);\n}\n```\n\n\nAnd the function registerAPI() is:\n\n\n```int getExternalAPIs(void) {\n    static int api_loaded = 0;\n    if (api_loaded != 0) return 1; // APIs already resolved.\n\n    myFunctionPointer = RedisModule_GetOtherModuleAPI(\"...\");\n    if (myFunctionPointer == NULL) return 0;\n\n    return 1;\n}\n```\n\n\n\nModule Command Filter API\n\n`RedisModule_RegisterCommandFilter`\n\n\n```RedisModuleCommandFilter *RedisModule_RegisterCommandFilter(RedisModuleCtx *ctx,\n                                                            RedisModuleCommandFilterFunc callback,\n                                                            int flags);\n```\n\n\nAvailable since: 5.0.5\nRegister a new command filter function.\nCommand filtering makes it possible for modules to extend Redis by plugging\ninto the execution flow of all commands.\nA registered filter gets called before Redis executes any command.  This\nincludes both core Redis commands and commands registered by any module.  The\nfilter applies in all execution paths including:\n\nInvocation by a client.\nInvocation through RedisModule_Call() by any module.\nInvocation through Lua `redis.call()`.\nReplication of a command from a master.\n\nThe filter executes in a special filter context, which is different and more\nlimited than a `RedisModuleCtx`.  Because the filter affects any command, it\nmust be implemented in a very efficient way to reduce the performance impact\non Redis.  All Redis Module API calls that require a valid context (such as\nRedisModule_Call(), RedisModule_OpenKey(), etc.) are not supported in a\nfilter context.\nThe `RedisModuleCommandFilterCtx` can be used to inspect or modify the\nexecuted command and its arguments.  As the filter executes before Redis\nbegins processing the command, any change will affect the way the command is\nprocessed.  For example, a module can override Redis commands this way:\n\nRegister a `MODULE.SET` command which implements an extended version of\n   the Redis `SET` command.\nRegister a command filter which detects invocation of `SET` on a specific\n   pattern of keys.  Once detected, the filter will replace the first\n   argument from `SET` to `MODULE.SET`.\nWhen filter execution is complete, Redis considers the new command name\n   and therefore executes the module's own command.\n\nNote that in the above use case, if `MODULE.SET` itself uses\nRedisModule_Call() the filter will be applied on that call as well.  If\nthat is not desired, the `REDISMODULE_CMDFILTER_NOSELF` flag can be set when\nregistering the filter.\nThe `REDISMODULE_CMDFILTER_NOSELF` flag prevents execution flows that\noriginate from the module's own RedisModule_Call() from reaching the filter.  This\nflag is effective for all execution flows, including nested ones, as long as\nthe execution begins from the module's command context or a thread-safe\ncontext that is associated with a blocking command.\nDetached thread-safe contexts are not associated with the module and cannot\nbe protected by this flag.\nIf multiple filters are registered (by the same or different modules), they\nare executed in the order of registration.\n\n`RedisModule_UnregisterCommandFilter`\n\n\n```int RedisModule_UnregisterCommandFilter(RedisModuleCtx *ctx,\n                                        RedisModuleCommandFilter *filter);\n```\n\n\nAvailable since: 5.0.5\nUnregister a command filter.\n\n`RedisModule_CommandFilterArgsCount`\n\n\n```int RedisModule_CommandFilterArgsCount(RedisModuleCommandFilterCtx *fctx);\n```\n\n\nAvailable since: 5.0.5\nReturn the number of arguments a filtered command has.  The number of\narguments include the command itself.\n\n`RedisModule_CommandFilterArgGet`\n\n\n```RedisModuleString *RedisModule_CommandFilterArgGet(RedisModuleCommandFilterCtx *fctx,\n                                                   int pos);\n```\n\n\nAvailable since: 5.0.5\nReturn the specified command argument.  The first argument (position 0) is\nthe command itself, and the rest are user-provided args.\n\n`RedisModule_CommandFilterArgInsert`\n\n\n```int RedisModule_CommandFilterArgInsert(RedisModuleCommandFilterCtx *fctx,\n                                       int pos,\n                                       RedisModuleString *arg);\n```\n\n\nAvailable since: 5.0.5\nModify the filtered command by inserting a new argument at the specified\nposition.  The specified `RedisModuleString` argument may be used by Redis\nafter the filter context is destroyed, so it must not be auto-memory\nallocated, freed or used elsewhere.\n\n`RedisModule_CommandFilterArgReplace`\n\n\n```int RedisModule_CommandFilterArgReplace(RedisModuleCommandFilterCtx *fctx,\n                                        int pos,\n                                        RedisModuleString *arg);\n```\n\n\nAvailable since: 5.0.5\nModify the filtered command by replacing an existing argument with a new one.\nThe specified `RedisModuleString` argument may be used by Redis after the\nfilter context is destroyed, so it must not be auto-memory allocated, freed\nor used elsewhere.\n\n`RedisModule_CommandFilterArgDelete`\n\n\n```int RedisModule_CommandFilterArgDelete(RedisModuleCommandFilterCtx *fctx,\n                                       int pos);\n```\n\n\nAvailable since: 5.0.5\nModify the filtered command by deleting an argument at the specified\nposition.\n\n`RedisModule_MallocSize`\n\n\n```size_t RedisModule_MallocSize(void* ptr);\n```\n\n\nAvailable since: 6.0.0\nFor a given pointer allocated via RedisModule_Alloc() or\nRedisModule_Realloc(), return the amount of memory allocated for it.\nNote that this may be different (larger) than the memory we allocated\nwith the allocation calls, since sometimes the underlying allocator\nwill allocate more memory.\n\n`RedisModule_MallocUsableSize`\n\n\n```size_t RedisModule_MallocUsableSize(void *ptr);\n```\n\n\nAvailable since: 7.0.1\nSimilar to RedisModule_MallocSize, the difference is that RedisModule_MallocUsableSize\nreturns the usable size of memory by the module.\n\n`RedisModule_MallocSizeString`\n\n\n```size_t RedisModule_MallocSizeString(RedisModuleString* str);\n```\n\n\nAvailable since: 7.0.0\nSame as RedisModule_MallocSize, except it works on `RedisModuleString` pointers.\n\n`RedisModule_MallocSizeDict`\n\n\n```size_t RedisModule_MallocSizeDict(RedisModuleDict* dict);\n```\n\n\nAvailable since: 7.0.0\nSame as RedisModule_MallocSize, except it works on `RedisModuleDict` pointers.\nNote that the returned value is only the overhead of the underlying structures,\nit does not include the allocation size of the keys and values.\n\n`RedisModule_GetUsedMemoryRatio`\n\n\n```float RedisModule_GetUsedMemoryRatio();\n```\n\n\nAvailable since: 6.0.0\nReturn the a number between 0 to 1 indicating the amount of memory\ncurrently used, relative to the Redis \"maxmemory\" configuration.\n\n0 - No memory limit configured.\nBetween 0 and 1 - The percentage of the memory used normalized in 0-1 range.\nExactly 1 - Memory limit reached.\nGreater 1 - More memory used than the configured limit.\n\n\nScanning keyspace and hashes\n\n`RedisModule_ScanCursorCreate`\n\n\n```RedisModuleScanCursor *RedisModule_ScanCursorCreate();\n```\n\n\nAvailable since: 6.0.0\nCreate a new cursor to be used with RedisModule_Scan\n\n`RedisModule_ScanCursorRestart`\n\n\n```void RedisModule_ScanCursorRestart(RedisModuleScanCursor *cursor);\n```\n\n\nAvailable since: 6.0.0\nRestart an existing cursor. The keys will be rescanned.\n\n`RedisModule_ScanCursorDestroy`\n\n\n```void RedisModule_ScanCursorDestroy(RedisModuleScanCursor *cursor);\n```\n\n\nAvailable since: 6.0.0\nDestroy the cursor struct.\n\n`RedisModule_Scan`\n\n\n```int RedisModule_Scan(RedisModuleCtx *ctx,\n                     RedisModuleScanCursor *cursor,\n                     RedisModuleScanCB fn,\n                     void *privdata);\n```\n\n\nAvailable since: 6.0.0\nScan API that allows a module to scan all the keys and value in\nthe selected db.\nCallback for scan implementation.\n\n\n```void scan_callback(RedisModuleCtx *ctx, RedisModuleString *keyname,\n                   RedisModuleKey *key, void *privdata);\n```\n\n\n\n`ctx`: the redis module context provided to for the scan.\n`keyname`: owned by the caller and need to be retained if used after this\n  function.\n`key`: holds info on the key and value, it is provided as best effort, in\n  some cases it might be NULL, in which case the user should (can) use\n  RedisModule_OpenKey() (and CloseKey too).\n  when it is provided, it is owned by the caller and will be free when the\n  callback returns.\n`privdata`: the user data provided to RedisModule_Scan().\n\nThe way it should be used:\n\n\n``` RedisModuleScanCursor *c = RedisModule_ScanCursorCreate();\n while(RedisModule_Scan(ctx, c, callback, privateData));\n RedisModule_ScanCursorDestroy(c);\n```\n\n\nIt is also possible to use this API from another thread while the lock\nis acquired during the actual call to RedisModule_Scan:\n\n\n``` RedisModuleScanCursor *c = RedisModule_ScanCursorCreate();\n RedisModule_ThreadSafeContextLock(ctx);\n while(RedisModule_Scan(ctx, c, callback, privateData)){\n     RedisModule_ThreadSafeContextUnlock(ctx);\n     // do some background job\n     RedisModule_ThreadSafeContextLock(ctx);\n }\n RedisModule_ScanCursorDestroy(c);\n```\n\n\nThe function will return 1 if there are more elements to scan and\n0 otherwise, possibly setting errno if the call failed.\nIt is also possible to restart an existing cursor using RedisModule_ScanCursorRestart.\nIMPORTANT: This API is very similar to the Redis SCAN command from the\npoint of view of the guarantees it provides. This means that the API\nmay report duplicated keys, but guarantees to report at least one time\nevery key that was there from the start to the end of the scanning process.\nNOTE: If you do database changes within the callback, you should be aware\nthat the internal state of the database may change. For instance it is safe\nto delete or modify the current key, but may not be safe to delete any\nother key.\nMoreover playing with the Redis keyspace while iterating may have the\neffect of returning more duplicates. A safe pattern is to store the keys\nnames you want to modify elsewhere, and perform the actions on the keys\nlater when the iteration is complete. However this can cost a lot of\nmemory, so it may make sense to just operate on the current key when\npossible during the iteration, given that this is safe.\n\n`RedisModule_ScanKey`\n\n\n```int RedisModule_ScanKey(RedisModuleKey *key,\n                        RedisModuleScanCursor *cursor,\n                        RedisModuleScanKeyCB fn,\n                        void *privdata);\n```\n\n\nAvailable since: 6.0.0\nScan api that allows a module to scan the elements in a hash, set or sorted set key\nCallback for scan implementation.\n\n\n```void scan_callback(RedisModuleKey *key, RedisModuleString* field, RedisModuleString* value, void *privdata);\n```\n\n\n\nkey - the redis key context provided to for the scan.\nfield - field name, owned by the caller and need to be retained if used\n  after this function.\nvalue - value string or NULL for set type, owned by the caller and need to\n  be retained if used after this function.\nprivdata - the user data provided to RedisModule_ScanKey.\n\nThe way it should be used:\n\n\n``` RedisModuleScanCursor *c = RedisModule_ScanCursorCreate();\n RedisModuleKey *key = RedisModule_OpenKey(...)\n while(RedisModule_ScanKey(key, c, callback, privateData));\n RedisModule_CloseKey(key);\n RedisModule_ScanCursorDestroy(c);\n```\n\n\nIt is also possible to use this API from another thread while the lock is acquired during\nthe actual call to RedisModule_ScanKey, and re-opening the key each time:\n\n\n``` RedisModuleScanCursor *c = RedisModule_ScanCursorCreate();\n RedisModule_ThreadSafeContextLock(ctx);\n RedisModuleKey *key = RedisModule_OpenKey(...)\n while(RedisModule_ScanKey(ctx, c, callback, privateData)){\n     RedisModule_CloseKey(key);\n     RedisModule_ThreadSafeContextUnlock(ctx);\n     // do some background job\n     RedisModule_ThreadSafeContextLock(ctx);\n     RedisModuleKey *key = RedisModule_OpenKey(...)\n }\n RedisModule_CloseKey(key);\n RedisModule_ScanCursorDestroy(c);\n```\n\n\nThe function will return 1 if there are more elements to scan and 0 otherwise,\npossibly setting errno if the call failed.\nIt is also possible to restart an existing cursor using RedisModule_ScanCursorRestart.\nNOTE: Certain operations are unsafe while iterating the object. For instance\nwhile the API guarantees to return at least one time all the elements that\nare present in the data structure consistently from the start to the end\nof the iteration (see HSCAN and similar commands documentation), the more\nyou play with the elements, the more duplicates you may get. In general\ndeleting the current element of the data structure is safe, while removing\nthe key you are iterating is not safe.\n\nModule fork API\n\n`RedisModule_Fork`\n\n\n```int RedisModule_Fork(RedisModuleForkDoneHandler cb, void *user_data);\n```\n\n\nAvailable since: 6.0.0\nCreate a background child process with the current frozen snapshot of the\nmain process where you can do some processing in the background without\naffecting / freezing the traffic and no need for threads and GIL locking.\nNote that Redis allows for only one concurrent fork.\nWhen the child wants to exit, it should call RedisModule_ExitFromChild.\nIf the parent wants to kill the child it should call RedisModule_KillForkChild\nThe done handler callback will be executed on the parent process when the\nchild existed (but not when killed)\nReturn: -1 on failure, on success the parent process will get a positive PID\nof the child, and the child process will get 0.\n\n`RedisModule_SendChildHeartbeat`\n\n\n```void RedisModule_SendChildHeartbeat(double progress);\n```\n\n\nAvailable since: 6.2.0\nThe module is advised to call this function from the fork child once in a while,\nso that it can report progress and COW memory to the parent which will be\nreported in INFO.\nThe `progress` argument should between 0 and 1, or -1 when not available.\n\n`RedisModule_ExitFromChild`\n\n\n```int RedisModule_ExitFromChild(int retcode);\n```\n\n\nAvailable since: 6.0.0\nCall from the child process when you want to terminate it.\nretcode will be provided to the done handler executed on the parent process.\n\n`RedisModule_KillForkChild`\n\n\n```int RedisModule_KillForkChild(int child_pid);\n```\n\n\nAvailable since: 6.0.0\nCan be used to kill the forked child process from the parent process.\n`child_pid` would be the return value of RedisModule_Fork.\n\nServer hooks implementation\n\n`RedisModule_SubscribeToServerEvent`\n\n\n```int RedisModule_SubscribeToServerEvent(RedisModuleCtx *ctx,\n                                       RedisModuleEvent event,\n                                       RedisModuleEventCallback callback);\n```\n\n\nAvailable since: 6.0.0\nRegister to be notified, via a callback, when the specified server event\nhappens. The callback is called with the event as argument, and an additional\nargument which is a void pointer and should be cased to a specific type\nthat is event-specific (but many events will just use NULL since they do not\nhave additional information to pass to the callback).\nIf the callback is NULL and there was a previous subscription, the module\nwill be unsubscribed. If there was a previous subscription and the callback\nis not null, the old callback will be replaced with the new one.\nThe callback must be of this type:\n\n\n```int (*RedisModuleEventCallback)(RedisModuleCtx *ctx,\n                                RedisModuleEvent eid,\n                                uint64_t subevent,\n                                void *data);\n```\n\n\nThe 'ctx' is a normal Redis module context that the callback can use in\norder to call other modules APIs. The 'eid' is the event itself, this\nis only useful in the case the module subscribed to multiple events: using\nthe 'id' field of this structure it is possible to check if the event\nis one of the events we registered with this callback. The 'subevent' field\ndepends on the event that fired.\nFinally the 'data' pointer may be populated, only for certain events, with\nmore relevant data.\nHere is a list of events you can use as 'eid' and related sub events:\n\n\n`RedisModuleEvent_ReplicationRoleChanged`:\nThis event is called when the instance switches from master\nto replica or the other way around, however the event is\nalso called when the replica remains a replica but starts to\nreplicate with a different master.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_REPLROLECHANGED_NOW_MASTER`\n`REDISMODULE_SUBEVENT_REPLROLECHANGED_NOW_REPLICA`\n\nThe 'data' field can be casted by the callback to a\n`RedisModuleReplicationInfo` structure with the following fields:\n\n\n```int master; // true if master, false if replica\nchar *masterhost; // master instance hostname for NOW_REPLICA\nint masterport; // master instance port for NOW_REPLICA\nchar *replid1; // Main replication ID\nchar *replid2; // Secondary replication ID\nuint64_t repl1_offset; // Main replication offset\nuint64_t repl2_offset; // Offset of replid2 validity\n```\n\n\n\n\n`RedisModuleEvent_Persistence`\nThis event is called when RDB saving or AOF rewriting starts\nand ends. The following sub events are available:\n\n`REDISMODULE_SUBEVENT_PERSISTENCE_RDB_START`\n`REDISMODULE_SUBEVENT_PERSISTENCE_AOF_START`\n`REDISMODULE_SUBEVENT_PERSISTENCE_SYNC_RDB_START`\n`REDISMODULE_SUBEVENT_PERSISTENCE_SYNC_AOF_START`\n`REDISMODULE_SUBEVENT_PERSISTENCE_ENDED`\n`REDISMODULE_SUBEVENT_PERSISTENCE_FAILED`\n\nThe above events are triggered not just when the user calls the\nrelevant commands like BGSAVE, but also when a saving operation\nor AOF rewriting occurs because of internal server triggers.\nThe SYNC_RDB_START sub events are happening in the foreground due to\nSAVE command, FLUSHALL, or server shutdown, and the other RDB and\nAOF sub events are executed in a background fork child, so any\naction the module takes can only affect the generated AOF or RDB,\nbut will not be reflected in the parent process and affect connected\nclients and commands. Also note that the AOF_START sub event may end\nup saving RDB content in case of an AOF with rdb-preamble.\n\n\n`RedisModuleEvent_FlushDB`\nThe FLUSHALL, FLUSHDB or an internal flush (for instance\nbecause of replication, after the replica synchronization)\nhappened. The following sub events are available:\n\n`REDISMODULE_SUBEVENT_FLUSHDB_START`\n`REDISMODULE_SUBEVENT_FLUSHDB_END`\n\nThe data pointer can be casted to a RedisModuleFlushInfo\nstructure with the following fields:\n\n\n```int32_t async;  // True if the flush is done in a thread.\n                // See for instance FLUSHALL ASYNC.\n                // In this case the END callback is invoked\n                // immediately after the database is put\n                // in the free list of the thread.\nint32_t dbnum;  // Flushed database number, -1 for all the DBs\n                // in the case of the FLUSHALL operation.\n```\n\n\nThe start event is called before the operation is initiated, thus\nallowing the callback to call DBSIZE or other operation on the\nyet-to-free keyspace.\n\n\n`RedisModuleEvent_Loading`\nCalled on loading operations: at startup when the server is\nstarted, but also after a first synchronization when the\nreplica is loading the RDB file from the master.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_LOADING_RDB_START`\n`REDISMODULE_SUBEVENT_LOADING_AOF_START`\n`REDISMODULE_SUBEVENT_LOADING_REPL_START`\n`REDISMODULE_SUBEVENT_LOADING_ENDED`\n`REDISMODULE_SUBEVENT_LOADING_FAILED`\n\nNote that AOF loading may start with an RDB data in case of\nrdb-preamble, in which case you'll only receive an AOF_START event.\n\n\n`RedisModuleEvent_ClientChange`\nCalled when a client connects or disconnects.\nThe data pointer can be casted to a RedisModuleClientInfo\nstructure, documented in RedisModule_GetClientInfoById().\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_CLIENT_CHANGE_CONNECTED`\n`REDISMODULE_SUBEVENT_CLIENT_CHANGE_DISCONNECTED`\n\n\n\n`RedisModuleEvent_Shutdown`\nThe server is shutting down. No subevents are available.\n\n\n`RedisModuleEvent_ReplicaChange`\nThis event is called when the instance (that can be both a\nmaster or a replica) get a new online replica, or lose a\nreplica since it gets disconnected.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_REPLICA_CHANGE_ONLINE`\n`REDISMODULE_SUBEVENT_REPLICA_CHANGE_OFFLINE`\n\nNo additional information is available so far: future versions\nof Redis will have an API in order to enumerate the replicas\nconnected and their state.\n\n\n`RedisModuleEvent_CronLoop`\nThis event is called every time Redis calls the serverCron()\nfunction in order to do certain bookkeeping. Modules that are\nrequired to do operations from time to time may use this callback.\nNormally Redis calls this function 10 times per second, but\nthis changes depending on the \"hz\" configuration.\nNo sub events are available.\nThe data pointer can be casted to a RedisModuleCronLoop\nstructure with the following fields:\n\n\n```int32_t hz;  // Approximate number of events per second.\n```\n\n\n\n\n`RedisModuleEvent_MasterLinkChange`\nThis is called for replicas in order to notify when the\nreplication link becomes functional (up) with our master,\nor when it goes down. Note that the link is not considered\nup when we just connected to the master, but only if the\nreplication is happening correctly.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_MASTER_LINK_UP`\n`REDISMODULE_SUBEVENT_MASTER_LINK_DOWN`\n\n\n\n`RedisModuleEvent_ModuleChange`\nThis event is called when a new module is loaded or one is unloaded.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_MODULE_LOADED`\n`REDISMODULE_SUBEVENT_MODULE_UNLOADED`\n\nThe data pointer can be casted to a RedisModuleModuleChange\nstructure with the following fields:\n\n\n```const char* module_name;  // Name of module loaded or unloaded.\nint32_t module_version;  // Module version.\n```\n\n\n\n\n`RedisModuleEvent_LoadingProgress`\nThis event is called repeatedly called while an RDB or AOF file\nis being loaded.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_LOADING_PROGRESS_RDB`\n`REDISMODULE_SUBEVENT_LOADING_PROGRESS_AOF`\n\nThe data pointer can be casted to a RedisModuleLoadingProgress\nstructure with the following fields:\n\n\n```int32_t hz;  // Approximate number of events per second.\nint32_t progress;  // Approximate progress between 0 and 1024,\n                   // or -1 if unknown.\n```\n\n\n\n\n`RedisModuleEvent_SwapDB`\nThis event is called when a SWAPDB command has been successfully\nExecuted.\nFor this event call currently there is no subevents available.\nThe data pointer can be casted to a RedisModuleSwapDbInfo\nstructure with the following fields:\n\n\n```int32_t dbnum_first;    // Swap Db first dbnum\nint32_t dbnum_second;   // Swap Db second dbnum\n```\n\n\n\n\n`RedisModuleEvent_ReplBackup`\nWARNING: Replication Backup events are deprecated since Redis 7.0 and are never fired.\nSee RedisModuleEvent_ReplAsyncLoad for understanding how Async Replication Loading events\nare now triggered when repl-diskless-load is set to swapdb.\nCalled when repl-diskless-load config is set to swapdb,\nAnd redis needs to backup the current database for the\npossibility to be restored later. A module with global data and\nmaybe with aux_load and aux_save callbacks may need to use this\nnotification to backup / restore / discard its globals.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_REPL_BACKUP_CREATE`\n`REDISMODULE_SUBEVENT_REPL_BACKUP_RESTORE`\n`REDISMODULE_SUBEVENT_REPL_BACKUP_DISCARD`\n\n\n\n`RedisModuleEvent_ReplAsyncLoad`\nCalled when repl-diskless-load config is set to swapdb and a replication with a master of same\ndata set history (matching replication ID) occurs.\nIn which case redis serves current data set while loading new database in memory from socket.\nModules must have declared they support this mechanism in order to activate it, through\nREDISMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD flag.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_REPL_ASYNC_LOAD_STARTED`\n`REDISMODULE_SUBEVENT_REPL_ASYNC_LOAD_ABORTED`\n`REDISMODULE_SUBEVENT_REPL_ASYNC_LOAD_COMPLETED`\n\n\n\n`RedisModuleEvent_ForkChild`\nCalled when a fork child (AOFRW, RDBSAVE, module fork...) is born/dies\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_FORK_CHILD_BORN`\n`REDISMODULE_SUBEVENT_FORK_CHILD_DIED`\n\n\n\n`RedisModuleEvent_EventLoop`\nCalled on each event loop iteration, once just before the event loop goes\nto sleep or just after it wakes up.\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_EVENTLOOP_BEFORE_SLEEP`\n`REDISMODULE_SUBEVENT_EVENTLOOP_AFTER_SLEEP`\n\n\n\n`RedisModule_Event_Config`\nCalled when a configuration event happens\nThe following sub events are available:\n\n`REDISMODULE_SUBEVENT_CONFIG_CHANGE`\n\nThe data pointer can be casted to a RedisModuleConfigChange\nstructure with the following fields:\n\n\n```const char **config_names; // An array of C string pointers containing the\n                           // name of each modified configuration item \nuint32_t num_changes;      // The number of elements in the config_names array\n```\n\n\n\n\nThe function returns `REDISMODULE_OK` if the module was successfully subscribed\nfor the specified event. If the API is called from a wrong context or unsupported event\nis given then `REDISMODULE_ERR` is returned.\n\n`RedisModule_IsSubEventSupported`\n\n\n```int RedisModule_IsSubEventSupported(RedisModuleEvent event, int64_t subevent);\n```\n\n\nAvailable since: 6.0.9\nFor a given server event and subevent, return zero if the\nsubevent is not supported and non-zero otherwise.\n\nModule Configurations API\n\n`RedisModule_RegisterStringConfig`\n\n\n```int RedisModule_RegisterStringConfig(RedisModuleCtx *ctx,\n                                     const char *name,\n                                     const char *default_val,\n                                     unsigned int flags,\n                                     RedisModuleConfigGetStringFunc getfn,\n                                     RedisModuleConfigSetStringFunc setfn,\n                                     RedisModuleConfigApplyFunc applyfn,\n                                     void *privdata);\n```\n\n\nAvailable since: 7.0.0\nCreate a string config that Redis users can interact with via the Redis config file,\n`CONFIG SET`, `CONFIG GET`, and `CONFIG REWRITE` commands.\nThe actual config value is owned by the module, and the `getfn`, `setfn` and optional\n`applyfn` callbacks that are provided to Redis in order to access or manipulate the\nvalue. The `getfn` callback retrieves the value from the module, while the `setfn`\ncallback provides a value to be stored into the module config.\nThe optional `applyfn` callback is called after a `CONFIG SET` command modified one or\nmore configs using the `setfn` callback and can be used to atomically apply a config\nafter several configs were changed together.\nIf there are multiple configs with `applyfn` callbacks set by a single `CONFIG SET`\ncommand, they will be deduplicated if their `applyfn` function and `privdata` pointers\nare identical, and the callback will only be run once.\nBoth the `setfn` and `applyfn` can return an error if the provided value is invalid or\ncannot be used.\nThe config also declares a type for the value that is validated by Redis and\nprovided to the module. The config system provides the following types:\n\nRedis String: Binary safe string data.\nEnum: One of a finite number of string tokens, provided during registration.\nNumeric: 64 bit signed integer, which also supports min and max values.\nBool: Yes or no value.\n\nThe `setfn` callback is expected to return `REDISMODULE_OK` when the value is successfully\napplied. It can also return `REDISMODULE_ERR` if the value can't be applied, and the\n*err pointer can be set with a `RedisModuleString` error message to provide to the client.\nThis `RedisModuleString` will be freed by redis after returning from the set callback.\nAll configs are registered with a name, a type, a default value, private data that is made\navailable in the callbacks, as well as several flags that modify the behavior of the config.\nThe name must only contain alphanumeric characters or dashes. The supported flags are:\n\n`REDISMODULE_CONFIG_DEFAULT`: The default flags for a config. This creates a config that can be modified after startup.\n`REDISMODULE_CONFIG_IMMUTABLE`: This config can only be provided loading time.\n`REDISMODULE_CONFIG_SENSITIVE`: The value stored in this config is redacted from all logging.\n`REDISMODULE_CONFIG_HIDDEN`: The name is hidden from `CONFIG GET` with pattern matching.\n`REDISMODULE_CONFIG_PROTECTED`: This config will be only be modifiable based off the value of enable-protected-configs.\n`REDISMODULE_CONFIG_DENY_LOADING`: This config is not modifiable while the server is loading data.\n`REDISMODULE_CONFIG_MEMORY`: For numeric configs, this config will convert data unit notations into their byte equivalent.\n`REDISMODULE_CONFIG_BITFLAGS`: For enum configs, this config will allow multiple entries to be combined as bit flags.\n\nDefault values are used on startup to set the value if it is not provided via the config file\nor command line. Default values are also used to compare to on a config rewrite.\nNotes:\n\nOn string config sets that the string passed to the set callback will be freed after execution and the module must retain it.\nOn string config gets the string will not be consumed and will be valid after execution.\n\nExample implementation:\n\n\n```RedisModuleString *strval;\nint adjustable = 1;\nRedisModuleString *getStringConfigCommand(const char *name, void *privdata) {\n    return strval;\n}\n\nint setStringConfigCommand(const char *name, RedisModuleString *new, void *privdata, RedisModuleString **err) {\n   if (adjustable) {\n       RedisModule_Free(strval);\n       RedisModule_RetainString(NULL, new);\n       strval = new;\n       return REDISMODULE_OK;\n   }\n   *err = RedisModule_CreateString(NULL, \"Not adjustable.\", 15);\n   return REDISMODULE_ERR;\n}\n...\nRedisModule_RegisterStringConfig(ctx, \"string\", NULL, REDISMODULE_CONFIG_DEFAULT, getStringConfigCommand, setStringConfigCommand, NULL, NULL);\n```\n\n\nIf the registration fails, `REDISMODULE_ERR` is returned and one of the following\nerrno is set:\n* EINVAL: The provided flags are invalid for the registration or the name of the config contains invalid characters.\n* EALREADY: The provided configuration name is already used.\n\n`RedisModule_RegisterBoolConfig`\n\n\n```int RedisModule_RegisterBoolConfig(RedisModuleCtx *ctx,\n                                   const char *name,\n                                   int default_val,\n                                   unsigned int flags,\n                                   RedisModuleConfigGetBoolFunc getfn,\n                                   RedisModuleConfigSetBoolFunc setfn,\n                                   RedisModuleConfigApplyFunc applyfn,\n                                   void *privdata);\n```\n\n\nAvailable since: 7.0.0\nCreate a bool config that server clients can interact with via the \n`CONFIG SET`, `CONFIG GET`, and `CONFIG REWRITE` commands. See \nRedisModule_RegisterStringConfig for detailed information about configs.\n\n`RedisModule_RegisterEnumConfig`\n\n\n```int RedisModule_RegisterEnumConfig(RedisModuleCtx *ctx,\n                                   const char *name,\n                                   int default_val,\n                                   unsigned int flags,\n                                   const char **enum_values,\n                                   const int *int_values,\n                                   int num_enum_vals,\n                                   RedisModuleConfigGetEnumFunc getfn,\n                                   RedisModuleConfigSetEnumFunc setfn,\n                                   RedisModuleConfigApplyFunc applyfn,\n                                   void *privdata);\n```\n\n\nAvailable since: 7.0.0\nCreate an enum config that server clients can interact with via the \n`CONFIG SET`, `CONFIG GET`, and `CONFIG REWRITE` commands. \nEnum configs are a set of string tokens to corresponding integer values, where \nthe string value is exposed to Redis clients but the value passed Redis and the\nmodule is the integer value. These values are defined in `enum_values`, an array\nof null-terminated c strings, and `int_vals`, an array of enum values who has an\nindex partner in `enum_values`.\nExample Implementation:\n     const char *enum_vals[3] = {\"first\", \"second\", \"third\"};\n     const int int_vals[3] = {0, 2, 4};\n     int enum_val = 0;\n\n\n``` int getEnumConfigCommand(const char *name, void *privdata) {\n     return enum_val;\n }\n\n int setEnumConfigCommand(const char *name, int val, void *privdata, const char **err) {\n     enum_val = val;\n     return REDISMODULE_OK;\n }\n ...\n RedisModule_RegisterEnumConfig(ctx, \"enum\", 0, REDISMODULE_CONFIG_DEFAULT, enum_vals, int_vals, 3, getEnumConfigCommand, setEnumConfigCommand, NULL, NULL);\n```\n\n\nNote that you can use `REDISMODULE_CONFIG_BITFLAGS` so that multiple enum string\ncan be combined into one integer as bit flags, in which case you may want to\nsort your enums so that the preferred combinations are present first.\nSee RedisModule_RegisterStringConfig for detailed general information about configs.\n\n`RedisModule_RegisterNumericConfig`\n\n\n```int RedisModule_RegisterNumericConfig(RedisModuleCtx *ctx,\n                                      const char *name,\n                                      long long default_val,\n                                      unsigned int flags,\n                                      long long min,\n                                      long long max,\n                                      RedisModuleConfigGetNumericFunc getfn,\n                                      RedisModuleConfigSetNumericFunc setfn,\n                                      RedisModuleConfigApplyFunc applyfn,\n                                      void *privdata);\n```\n\n\nAvailable since: 7.0.0\nCreate an integer config that server clients can interact with via the \n`CONFIG SET`, `CONFIG GET`, and `CONFIG REWRITE` commands. See \nRedisModule_RegisterStringConfig for detailed information about configs.\n\n`RedisModule_LoadConfigs`\n\n\n```int RedisModule_LoadConfigs(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nApplies all pending configurations on the module load. This should be called\nafter all of the configurations have been registered for the module inside of `RedisModule_OnLoad`.\nThis API needs to be called when configurations are provided in either `MODULE LOADEX`\nor provided as startup arguments.\n\nKey eviction API\n\n`RedisModule_SetLRU`\n\n\n```int RedisModule_SetLRU(RedisModuleKey *key, mstime_t lru_idle);\n```\n\n\nAvailable since: 6.0.0\nSet the key last access time for LRU based eviction. not relevant if the\nservers's maxmemory policy is LFU based. Value is idle time in milliseconds.\nreturns `REDISMODULE_OK` if the LRU was updated, `REDISMODULE_ERR` otherwise.\n\n`RedisModule_GetLRU`\n\n\n```int RedisModule_GetLRU(RedisModuleKey *key, mstime_t *lru_idle);\n```\n\n\nAvailable since: 6.0.0\nGets the key last access time.\nValue is idletime in milliseconds or -1 if the server's eviction policy is\nLFU based.\nreturns `REDISMODULE_OK` if when key is valid.\n\n`RedisModule_SetLFU`\n\n\n```int RedisModule_SetLFU(RedisModuleKey *key, long long lfu_freq);\n```\n\n\nAvailable since: 6.0.0\nSet the key access frequency. only relevant if the server's maxmemory policy\nis LFU based.\nThe frequency is a logarithmic counter that provides an indication of\nthe access frequencyonly (must be <= 255).\nreturns `REDISMODULE_OK` if the LFU was updated, `REDISMODULE_ERR` otherwise.\n\n`RedisModule_GetLFU`\n\n\n```int RedisModule_GetLFU(RedisModuleKey *key, long long *lfu_freq);\n```\n\n\nAvailable since: 6.0.0\nGets the key access frequency or -1 if the server's eviction policy is not\nLFU based.\nreturns `REDISMODULE_OK` if when key is valid.\n\nMiscellaneous APIs\n\n`RedisModule_GetContextFlagsAll`\n\n\n```int RedisModule_GetContextFlagsAll();\n```\n\n\nAvailable since: 6.0.9\nReturns the full ContextFlags mask, using the return value\nthe module can check if a certain set of flags are supported\nby the redis server version in use.\nExample:\n\n\n```   int supportedFlags = RedisModule_GetContextFlagsAll();\n   if (supportedFlags & REDISMODULE_CTX_FLAGS_MULTI) {\n         // REDISMODULE_CTX_FLAGS_MULTI is supported\n   } else{\n         // REDISMODULE_CTX_FLAGS_MULTI is not supported\n   }\n```\n\n\n\n`RedisModule_GetKeyspaceNotificationFlagsAll`\n\n\n```int RedisModule_GetKeyspaceNotificationFlagsAll();\n```\n\n\nAvailable since: 6.0.9\nReturns the full KeyspaceNotification mask, using the return value\nthe module can check if a certain set of flags are supported\nby the redis server version in use.\nExample:\n\n\n```   int supportedFlags = RedisModule_GetKeyspaceNotificationFlagsAll();\n   if (supportedFlags & REDISMODULE_NOTIFY_LOADED) {\n         // REDISMODULE_NOTIFY_LOADED is supported\n   } else{\n         // REDISMODULE_NOTIFY_LOADED is not supported\n   }\n```\n\n\n\n`RedisModule_GetServerVersion`\n\n\n```int RedisModule_GetServerVersion();\n```\n\n\nAvailable since: 6.0.9\nReturn the redis version in format of 0x00MMmmpp.\nExample for 6.0.7 the return value will be 0x00060007.\n\n`RedisModule_GetTypeMethodVersion`\n\n\n```int RedisModule_GetTypeMethodVersion();\n```\n\n\nAvailable since: 6.2.0\nReturn the current redis-server runtime value of `REDISMODULE_TYPE_METHOD_VERSION`.\nYou can use that when calling RedisModule_CreateDataType to know which fields of\n`RedisModuleTypeMethods` are gonna be supported and which will be ignored.\n\n`RedisModule_ModuleTypeReplaceValue`\n\n\n```int RedisModule_ModuleTypeReplaceValue(RedisModuleKey *key,\n                                       moduleType *mt,\n                                       void *new_value,\n                                       void **old_value);\n```\n\n\nAvailable since: 6.0.0\nReplace the value assigned to a module type.\nThe key must be open for writing, have an existing value, and have a moduleType\nthat matches the one specified by the caller.\nUnlike RedisModule_ModuleTypeSetValue() which will free the old value, this function\nsimply swaps the old value with the new value.\nThe function returns `REDISMODULE_OK` on success, `REDISMODULE_ERR` on errors\nsuch as:\n\nKey is not opened for writing.\nKey is not a module data type key.\nKey is a module datatype other than 'mt'.\n\nIf `old_value` is non-NULL, the old value is returned by reference.\n\n`RedisModule_GetCommandKeysWithFlags`\n\n\n```int *RedisModule_GetCommandKeysWithFlags(RedisModuleCtx *ctx,\n                                         RedisModuleString **argv,\n                                         int argc,\n                                         int *num_keys,\n                                         int **out_flags);\n```\n\n\nAvailable since: 7.0.0\nFor a specified command, parse its arguments and return an array that\ncontains the indexes of all key name arguments. This function is\nessentially a more efficient way to do `COMMAND GETKEYS`.\nThe `out_flags` argument is optional, and can be set to NULL.\nWhen provided it is filled with `REDISMODULE_CMD_KEY_` flags in matching\nindexes with the key indexes of the returned array.\nA NULL return value indicates the specified command has no keys, or\nan error condition. Error conditions are indicated by setting errno\nas follows:\n\nENOENT: Specified command does not exist.\nEINVAL: Invalid command arity specified.\n\nNOTE: The returned array is not a Redis Module object so it does not\nget automatically freed even when auto-memory is used. The caller\nmust explicitly call RedisModule_Free() to free it, same as the `out_flags` pointer if\nused.\n\n`RedisModule_GetCommandKeys`\n\n\n```int *RedisModule_GetCommandKeys(RedisModuleCtx *ctx,\n                                RedisModuleString **argv,\n                                int argc,\n                                int *num_keys);\n```\n\n\nAvailable since: 6.0.9\nIdentical to RedisModule_GetCommandKeysWithFlags when flags are not needed.\n\n`RedisModule_GetCurrentCommandName`\n\n\n```const char *RedisModule_GetCurrentCommandName(RedisModuleCtx *ctx);\n```\n\n\nAvailable since: 6.2.5\nReturn the name of the command currently running\n\nDefrag API\n\n`RedisModule_RegisterDefragFunc`\n\n\n```int RedisModule_RegisterDefragFunc(RedisModuleCtx *ctx,\n                                   RedisModuleDefragFunc cb);\n```\n\n\nAvailable since: 6.2.0\nRegister a defrag callback for global data, i.e. anything that the module\nmay allocate that is not tied to a specific data type.\n\n`RedisModule_DefragShouldStop`\n\n\n```int RedisModule_DefragShouldStop(RedisModuleDefragCtx *ctx);\n```\n\n\nAvailable since: 6.2.0\nWhen the data type defrag callback iterates complex structures, this\nfunction should be called periodically. A zero (false) return\nindicates the callback may continue its work. A non-zero value (true)\nindicates it should stop.\nWhen stopped, the callback may use RedisModule_DefragCursorSet() to store its\nposition so it can later use RedisModule_DefragCursorGet() to resume defragging.\nWhen stopped and more work is left to be done, the callback should\nreturn 1. Otherwise, it should return 0.\nNOTE: Modules should consider the frequency in which this function is called,\nso it generally makes sense to do small batches of work in between calls.\n\n`RedisModule_DefragCursorSet`\n\n\n```int RedisModule_DefragCursorSet(RedisModuleDefragCtx *ctx,\n                                unsigned long cursor);\n```\n\n\nAvailable since: 6.2.0\nStore an arbitrary cursor value for future re-use.\nThis should only be called if RedisModule_DefragShouldStop() has returned a non-zero\nvalue and the defrag callback is about to exit without fully iterating its\ndata type.\nThis behavior is reserved to cases where late defrag is performed. Late\ndefrag is selected for keys that implement the `free_effort` callback and\nreturn a `free_effort` value that is larger than the defrag\n'active-defrag-max-scan-fields' configuration directive.\nSmaller keys, keys that do not implement `free_effort` or the global\ndefrag callback are not called in late-defrag mode. In those cases, a\ncall to this function will return `REDISMODULE_ERR`.\nThe cursor may be used by the module to represent some progress into the\nmodule's data type. Modules may also store additional cursor-related\ninformation locally and use the cursor as a flag that indicates when\ntraversal of a new key begins. This is possible because the API makes\na guarantee that concurrent defragmentation of multiple keys will\nnot be performed.\n\n`RedisModule_DefragCursorGet`\n\n\n```int RedisModule_DefragCursorGet(RedisModuleDefragCtx *ctx,\n                                unsigned long *cursor);\n```\n\n\nAvailable since: 6.2.0\nFetch a cursor value that has been previously stored using RedisModule_DefragCursorSet().\nIf not called for a late defrag operation, `REDISMODULE_ERR` will be returned and\nthe cursor should be ignored. See RedisModule_DefragCursorSet() for more details on\ndefrag cursors.\n\n`RedisModule_DefragAlloc`\n\n\n```void *RedisModule_DefragAlloc(RedisModuleDefragCtx *ctx, void *ptr);\n```\n\n\nAvailable since: 6.2.0\nDefrag a memory allocation previously allocated by RedisModule_Alloc, RedisModule_Calloc, etc.\nThe defragmentation process involves allocating a new memory block and copying\nthe contents to it, like `realloc()`.\nIf defragmentation was not necessary, NULL is returned and the operation has\nno other effect.\nIf a non-NULL value is returned, the caller should use the new pointer instead\nof the old one and update any reference to the old pointer, which must not\nbe used again.\n\n`RedisModule_DefragRedisModuleString`\n\n\n```RedisModuleString *RedisModule_DefragRedisModuleString(RedisModuleDefragCtx *ctx,\n                                                       RedisModuleString *str);\n```\n\n\nAvailable since: 6.2.0\nDefrag a `RedisModuleString` previously allocated by RedisModule_Alloc, RedisModule_Calloc, etc.\nSee RedisModule_DefragAlloc() for more information on how the defragmentation process\nworks.\nNOTE: It is only possible to defrag strings that have a single reference.\nTypically this means strings retained with RedisModule_RetainString or RedisModule_HoldString\nmay not be defragmentable. One exception is command argvs which, if retained\nby the module, will end up with a single reference (because the reference\non the Redis side is dropped as soon as the command callback returns).\n\n`RedisModule_GetKeyNameFromDefragCtx`\n\n\n```const RedisModuleString *RedisModule_GetKeyNameFromDefragCtx(RedisModuleDefragCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nReturns the name of the key currently being processed.\nThere is no guarantee that the key name is always available, so this may return NULL.\n\n`RedisModule_GetDbIdFromDefragCtx`\n\n\n```int RedisModule_GetDbIdFromDefragCtx(RedisModuleDefragCtx *ctx);\n```\n\n\nAvailable since: 7.0.0\nReturns the database id of the key currently being processed.\nThere is no guarantee that this info is always available, so this may return -1.\n\nFunction index\n\nRedisModule_ACLAddLogEntry\nRedisModule_ACLCheckChannelPermissions\nRedisModule_ACLCheckCommandPermissions\nRedisModule_ACLCheckKeyPermissions\nRedisModule_AbortBlock\nRedisModule_Alloc\nRedisModule_AuthenticateClientWithACLUser\nRedisModule_AuthenticateClientWithUser\nRedisModule_AutoMemory\nRedisModule_AvoidReplicaTraffic\nRedisModule_BlockClient\nRedisModule_BlockClientOnKeys\nRedisModule_BlockedClientDisconnected\nRedisModule_BlockedClientMeasureTimeEnd\nRedisModule_BlockedClientMeasureTimeStart\nRedisModule_Call\nRedisModule_CallReplyArrayElement\nRedisModule_CallReplyAttribute\nRedisModule_CallReplyAttributeElement\nRedisModule_CallReplyBigNumber\nRedisModule_CallReplyBool\nRedisModule_CallReplyDouble\nRedisModule_CallReplyInteger\nRedisModule_CallReplyLength\nRedisModule_CallReplyMapElement\nRedisModule_CallReplyProto\nRedisModule_CallReplySetElement\nRedisModule_CallReplyStringPtr\nRedisModule_CallReplyType\nRedisModule_CallReplyVerbatim\nRedisModule_Calloc\nRedisModule_ChannelAtPosWithFlags\nRedisModule_CloseKey\nRedisModule_CommandFilterArgDelete\nRedisModule_CommandFilterArgGet\nRedisModule_CommandFilterArgInsert\nRedisModule_CommandFilterArgReplace\nRedisModule_CommandFilterArgsCount\nRedisModule_CreateCommand\nRedisModule_CreateDataType\nRedisModule_CreateDict\nRedisModule_CreateModuleUser\nRedisModule_CreateString\nRedisModule_CreateStringFromCallReply\nRedisModule_CreateStringFromDouble\nRedisModule_CreateStringFromLongDouble\nRedisModule_CreateStringFromLongLong\nRedisModule_CreateStringFromStreamID\nRedisModule_CreateStringFromString\nRedisModule_CreateStringFromULongLong\nRedisModule_CreateStringPrintf\nRedisModule_CreateSubcommand\nRedisModule_CreateTimer\nRedisModule_DbSize\nRedisModule_DeauthenticateAndCloseClient\nRedisModule_DefragAlloc\nRedisModule_DefragCursorGet\nRedisModule_DefragCursorSet\nRedisModule_DefragRedisModuleString\nRedisModule_DefragShouldStop\nRedisModule_DeleteKey\nRedisModule_DictCompare\nRedisModule_DictCompareC\nRedisModule_DictDel\nRedisModule_DictDelC\nRedisModule_DictGet\nRedisModule_DictGetC\nRedisModule_DictIteratorReseek\nRedisModule_DictIteratorReseekC\nRedisModule_DictIteratorStart\nRedisModule_DictIteratorStartC\nRedisModule_DictIteratorStop\nRedisModule_DictNext\nRedisModule_DictNextC\nRedisModule_DictPrev\nRedisModule_DictPrevC\nRedisModule_DictReplace\nRedisModule_DictReplaceC\nRedisModule_DictSet\nRedisModule_DictSetC\nRedisModule_DictSize\nRedisModule_DigestAddLongLong\nRedisModule_DigestAddStringBuffer\nRedisModule_DigestEndSequence\nRedisModule_EmitAOF\nRedisModule_EventLoopAdd\nRedisModule_EventLoopAddOneShot\nRedisModule_EventLoopDel\nRedisModule_ExitFromChild\nRedisModule_ExportSharedAPI\nRedisModule_Fork\nRedisModule_Free\nRedisModule_FreeCallReply\nRedisModule_FreeClusterNodesList\nRedisModule_FreeDict\nRedisModule_FreeModuleUser\nRedisModule_FreeServerInfo\nRedisModule_FreeString\nRedisModule_FreeThreadSafeContext\nRedisModule_GetAbsExpire\nRedisModule_GetBlockedClientHandle\nRedisModule_GetBlockedClientPrivateData\nRedisModule_GetBlockedClientReadyKey\nRedisModule_GetClientCertificate\nRedisModule_GetClientId\nRedisModule_GetClientInfoById\nRedisModule_GetClientNameById\nRedisModule_GetClientUserNameById\nRedisModule_GetClusterNodeInfo\nRedisModule_GetClusterNodesList\nRedisModule_GetClusterSize\nRedisModule_GetCommand\nRedisModule_GetCommandKeys\nRedisModule_GetCommandKeysWithFlags\nRedisModule_GetContextFlags\nRedisModule_GetContextFlagsAll\nRedisModule_GetCurrentCommandName\nRedisModule_GetCurrentUserName\nRedisModule_GetDbIdFromDefragCtx\nRedisModule_GetDbIdFromDigest\nRedisModule_GetDbIdFromIO\nRedisModule_GetDbIdFromModuleKey\nRedisModule_GetDbIdFromOptCtx\nRedisModule_GetDetachedThreadSafeContext\nRedisModule_GetExpire\nRedisModule_GetKeyNameFromDefragCtx\nRedisModule_GetKeyNameFromDigest\nRedisModule_GetKeyNameFromIO\nRedisModule_GetKeyNameFromModuleKey\nRedisModule_GetKeyNameFromOptCtx\nRedisModule_GetKeyspaceNotificationFlagsAll\nRedisModule_GetLFU\nRedisModule_GetLRU\nRedisModule_GetModuleUserACLString\nRedisModule_GetModuleUserFromUserName\nRedisModule_GetMyClusterID\nRedisModule_GetNotifyKeyspaceEvents\nRedisModule_GetRandomBytes\nRedisModule_GetRandomHexChars\nRedisModule_GetSelectedDb\nRedisModule_GetServerInfo\nRedisModule_GetServerVersion\nRedisModule_GetSharedAPI\nRedisModule_GetThreadSafeContext\nRedisModule_GetTimerInfo\nRedisModule_GetToDbIdFromOptCtx\nRedisModule_GetToKeyNameFromOptCtx\nRedisModule_GetTypeMethodVersion\nRedisModule_GetUsedMemoryRatio\nRedisModule_HashGet\nRedisModule_HashSet\nRedisModule_HoldString\nRedisModule_InfoAddFieldCString\nRedisModule_InfoAddFieldDouble\nRedisModule_InfoAddFieldLongLong\nRedisModule_InfoAddFieldString\nRedisModule_InfoAddFieldULongLong\nRedisModule_InfoAddSection\nRedisModule_InfoBeginDictField\nRedisModule_InfoEndDictField\nRedisModule_IsBlockedReplyRequest\nRedisModule_IsBlockedTimeoutRequest\nRedisModule_IsChannelsPositionRequest\nRedisModule_IsIOError\nRedisModule_IsKeysPositionRequest\nRedisModule_IsModuleNameBusy\nRedisModule_IsSubEventSupported\nRedisModule_KeyAtPos\nRedisModule_KeyAtPosWithFlags\nRedisModule_KeyExists\nRedisModule_KeyType\nRedisModule_KillForkChild\nRedisModule_LatencyAddSample\nRedisModule_ListDelete\nRedisModule_ListGet\nRedisModule_ListInsert\nRedisModule_ListPop\nRedisModule_ListPush\nRedisModule_ListSet\nRedisModule_LoadConfigs\nRedisModule_LoadDataTypeFromString\nRedisModule_LoadDataTypeFromStringEncver\nRedisModule_LoadDouble\nRedisModule_LoadFloat\nRedisModule_LoadLongDouble\nRedisModule_LoadSigned\nRedisModule_LoadString\nRedisModule_LoadStringBuffer\nRedisModule_LoadUnsigned\nRedisModule_Log\nRedisModule_LogIOError\nRedisModule_MallocSize\nRedisModule_MallocSizeDict\nRedisModule_MallocSizeString\nRedisModule_MallocUsableSize\nRedisModule_Milliseconds\nRedisModule_ModuleTypeGetType\nRedisModule_ModuleTypeGetValue\nRedisModule_ModuleTypeReplaceValue\nRedisModule_ModuleTypeSetValue\nRedisModule_MonotonicMicroseconds\nRedisModule_NotifyKeyspaceEvent\nRedisModule_OpenKey\nRedisModule_PoolAlloc\nRedisModule_PublishMessage\nRedisModule_PublishMessageShard\nRedisModule_RandomKey\nRedisModule_Realloc\nRedisModule_RedactClientCommandArgument\nRedisModule_RegisterBoolConfig\nRedisModule_RegisterClusterMessageReceiver\nRedisModule_RegisterCommandFilter\nRedisModule_RegisterDefragFunc\nRedisModule_RegisterEnumConfig\nRedisModule_RegisterInfoFunc\nRedisModule_RegisterNumericConfig\nRedisModule_RegisterStringConfig\nRedisModule_Replicate\nRedisModule_ReplicateVerbatim\nRedisModule_ReplySetArrayLength\nRedisModule_ReplySetAttributeLength\nRedisModule_ReplySetMapLength\nRedisModule_ReplySetSetLength\nRedisModule_ReplyWithArray\nRedisModule_ReplyWithAttribute\nRedisModule_ReplyWithBigNumber\nRedisModule_ReplyWithBool\nRedisModule_ReplyWithCString\nRedisModule_ReplyWithCallReply\nRedisModule_ReplyWithDouble\nRedisModule_ReplyWithEmptyArray\nRedisModule_ReplyWithEmptyString\nRedisModule_ReplyWithError\nRedisModule_ReplyWithLongDouble\nRedisModule_ReplyWithLongLong\nRedisModule_ReplyWithMap\nRedisModule_ReplyWithNull\nRedisModule_ReplyWithNullArray\nRedisModule_ReplyWithSet\nRedisModule_ReplyWithSimpleString\nRedisModule_ReplyWithString\nRedisModule_ReplyWithStringBuffer\nRedisModule_ReplyWithVerbatimString\nRedisModule_ReplyWithVerbatimStringType\nRedisModule_ResetDataset\nRedisModule_RetainString\nRedisModule_SaveDataTypeToString\nRedisModule_SaveDouble\nRedisModule_SaveFloat\nRedisModule_SaveLongDouble\nRedisModule_SaveSigned\nRedisModule_SaveString\nRedisModule_SaveStringBuffer\nRedisModule_SaveUnsigned\nRedisModule_Scan\nRedisModule_ScanCursorCreate\nRedisModule_ScanCursorDestroy\nRedisModule_ScanCursorRestart\nRedisModule_ScanKey\nRedisModule_SelectDb\nRedisModule_SendChildHeartbeat\nRedisModule_SendClusterMessage\nRedisModule_ServerInfoGetField\nRedisModule_ServerInfoGetFieldC\nRedisModule_ServerInfoGetFieldDouble\nRedisModule_ServerInfoGetFieldSigned\nRedisModule_ServerInfoGetFieldUnsigned\nRedisModule_SetAbsExpire\nRedisModule_SetClientNameById\nRedisModule_SetClusterFlags\nRedisModule_SetCommandInfo\nRedisModule_SetContextUser\nRedisModule_SetDisconnectCallback\nRedisModule_SetExpire\nRedisModule_SetLFU\nRedisModule_SetLRU\nRedisModule_SetModuleOptions\nRedisModule_SetModuleUserACL\nRedisModule_SetModuleUserACLString\nRedisModule_SignalKeyAsReady\nRedisModule_SignalModifiedKey\nRedisModule_StopTimer\nRedisModule_Strdup\nRedisModule_StreamAdd\nRedisModule_StreamDelete\nRedisModule_StreamIteratorDelete\nRedisModule_StreamIteratorNextField\nRedisModule_StreamIteratorNextID\nRedisModule_StreamIteratorStart\nRedisModule_StreamIteratorStop\nRedisModule_StreamTrimByID\nRedisModule_StreamTrimByLength\nRedisModule_StringAppendBuffer\nRedisModule_StringCompare\nRedisModule_StringDMA\nRedisModule_StringPtrLen\nRedisModule_StringSet\nRedisModule_StringToDouble\nRedisModule_StringToLongDouble\nRedisModule_StringToLongLong\nRedisModule_StringToStreamID\nRedisModule_StringToULongLong\nRedisModule_StringTruncate\nRedisModule_SubscribeToKeyspaceEvents\nRedisModule_SubscribeToServerEvent\nRedisModule_ThreadSafeContextLock\nRedisModule_ThreadSafeContextTryLock\nRedisModule_ThreadSafeContextUnlock\nRedisModule_TrimStringAllocation\nRedisModule_TryAlloc\nRedisModule_UnblockClient\nRedisModule_UnlinkKey\nRedisModule_UnregisterCommandFilter\nRedisModule_ValueLength\nRedisModule_WrongArity\nRedisModule_Yield\nRedisModule_ZsetAdd\nRedisModule_ZsetFirstInLexRange\nRedisModule_ZsetFirstInScoreRange\nRedisModule_ZsetIncrby\nRedisModule_ZsetLastInLexRange\nRedisModule_ZsetLastInScoreRange\nRedisModule_ZsetRangeCurrentElement\nRedisModule_ZsetRangeEndReached\nRedisModule_ZsetRangeNext\nRedisModule_ZsetRangePrev\nRedisModule_ZsetRangeStop\nRedisModule_ZsetRem\nRedisModule_ZsetScore\nRedisModule__Assert\n",
    "tag": "redis"
  },
  {
    "title": "modules-native-types.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/modules/modules-native-types.md",
    "content": "\ntitle: \"Modules API for native types\"\nlinkTitle: \"Native types API\"\nweight: 1\ndescription: >\n    How to use native types in a Redis module\naliases:\n    - /topics/modules-native-types\n\nRedis modules can access Redis built-in data structures both at high level,\nby calling Redis commands, and at low level, by manipulating the data structures\ndirectly.\nBy using these capabilities in order to build new abstractions on top of existing\nRedis data structures, or by using strings DMA in order to encode modules\ndata structures into Redis strings, it is possible to create modules that\nfeel like they are exporting new data types. However, for more complex\nproblems, this is not enough, and the implementation of new data structures\ninside the module is needed.\nWe call the ability of Redis modules to implement new data structures that\nfeel like native Redis ones native types support. This document describes\nthe API exported by the Redis modules system in order to create new data\nstructures and handle the serialization in RDB files, the rewriting process\nin AOF, the type reporting via the `TYPE` command, and so forth.\nOverview of native types\nA module exporting a native type is composed of the following main parts:\n\nThe implementation of some kind of new data structure and of commands operating on the new data structure.\nA set of callbacks that handle: RDB saving, RDB loading, AOF rewriting, releasing of a value associated with a key, calculation of a value digest (hash) to be used with the `DEBUG DIGEST` command.\nA 9 characters name that is unique to each module native data type.\nAn encoding version, used to persist into RDB files a module-specific data version, so that a module will be able to load older representations from RDB files.\n\nWhile to handle RDB loading, saving and AOF rewriting may look complex as a first glance, the modules API provide very high level function for handling all this, without requiring the user to handle read/write errors, so in practical terms, writing a new data structure for Redis is a simple task.\nA very easy to understand but complete example of native type implementation\nis available inside the Redis distribution in the `/modules/hellotype.c` file.\nThe reader is encouraged to read the documentation by looking at this example\nimplementation to see how things are applied in the practice.\nRegistering a new data type\nIn order to register a new native type into the Redis core, the module needs\nto declare a global variable that will hold a reference to the data type.\nThe API to register the data type will return a data type reference that will\nbe stored in the global variable.\n\n\n```static RedisModuleType *MyType;\n#define MYTYPE_ENCODING_VERSION 0\n\nint RedisModule_OnLoad(RedisModuleCtx *ctx) {\nRedisModuleTypeMethods tm = {\n    .version = REDISMODULE_TYPE_METHOD_VERSION,\n    .rdb_load = MyTypeRDBLoad,\n    .rdb_save = MyTypeRDBSave,\n    .aof_rewrite = MyTypeAOFRewrite,\n    .free = MyTypeFree\n};\n\n    MyType = RedisModule_CreateDataType(ctx, \"MyType-AZ\",\n    MYTYPE_ENCODING_VERSION, &tm);\n    if (MyType == NULL) return REDISMODULE_ERR;\n}\n```\n\n\nAs you can see from the example above, a single API call is needed in order to\nregister the new type. However a number of function pointers are passed as\narguments. Certain are optionals while some are mandatory. The above set\nof methods must be passed, while `.digest` and `.mem_usage` are optional\nand are currently not actually supported by the modules internals, so for\nnow you can just ignore them.\nThe `ctx` argument is the context that we receive in the `OnLoad` function.\nThe type `name` is a 9 character name in the character set that includes\nfrom `A-Z`, `a-z`, `0-9`, plus the underscore `_` and minus `-` characters.\nNote that this name must be unique for each data type in the Redis\necosystem, so be creative, use both lower-case and upper case if it makes\nsense, and try to use the convention of mixing the type name with the name\nof the author of the module, to create a 9 character unique name.\nNOTE: It is very important that the name is exactly 9 chars or the\nregistration of the type will fail. Read more to understand why.\nFor example if I'm building a b-tree data structure and my name is antirez\nI'll call my type btree1-az. The name, converted to a 64 bit integer,\nis stored inside the RDB file when saving the type, and will be used when the\nRDB data is loaded in order to resolve what module can load the data. If Redis\nfinds no matching module, the integer is converted back to a name in order to\nprovide some clue to the user about what module is missing in order to load\nthe data.\nThe type name is also used as a reply for the `TYPE` command when called\nwith a key holding the registered type.\nThe `encver` argument is the encoding version used by the module to store data\ninside the RDB file. For example I can start with an encoding version of 0,\nbut later when I release version 2.0 of my module, I can switch encoding to\nsomething better. The new module will register with an encoding version of 1,\nso when it saves new RDB files, the new version will be stored on disk. However\nwhen loading RDB files, the module `rdb_load` method will be called even if\nthere is data found for a different encoding version (and the encoding version\nis passed as argument to `rdb_load`), so that the module can still load old\nRDB files.\nThe last argument is a structure used in order to pass the type methods to the\nregistration function: `rdb_load`, `rdb_save`, `aof_rewrite`, `digest` and\n`free` and `mem_usage` are all callbacks with the following prototypes and uses:\n\n\n```typedef void *(*RedisModuleTypeLoadFunc)(RedisModuleIO *rdb, int encver);\ntypedef void (*RedisModuleTypeSaveFunc)(RedisModuleIO *rdb, void *value);\ntypedef void (*RedisModuleTypeRewriteFunc)(RedisModuleIO *aof, RedisModuleString *key, void *value);\ntypedef size_t (*RedisModuleTypeMemUsageFunc)(void *value);\ntypedef void (*RedisModuleTypeDigestFunc)(RedisModuleDigest *digest, void *value);\ntypedef void (*RedisModuleTypeFreeFunc)(void *value);\n```\n\n\n\n`rdb_load` is called when loading data from the RDB file. It loads data in the same format as `rdb_save` produces.\n`rdb_save` is called when saving data to the RDB file.\n`aof_rewrite` is called when the AOF is being rewritten, and the module needs to tell Redis what is the sequence of commands to recreate the content of a given key.\n`digest` is called when `DEBUG DIGEST` is executed and a key holding this module type is found. Currently this is not yet implemented so the function ca be left empty.\n`mem_usage` is called when the `MEMORY` command asks for the total memory consumed by a specific key, and is used in order to get the amount of bytes used by the module value.\n`free` is called when a key with the module native type is deleted via `DEL` or in any other mean, in order to let the module reclaim the memory associated with such a value.\n\nOk, but why modules types require a 9 characters name?\nOh, I understand you need to understand this, so here is a very specific\nexplanation.\nWhen Redis persists to RDB files, modules specific data types require to\nbe persisted as well. Now RDB files are sequences of key-value pairs\nlike the following:\n\n\n```[1 byte type] [key] [a type specific value]\n```\n\n\nThe 1 byte type identifies strings, lists, sets, and so forth. In the case\nof modules data, it is set to a special value of `module data`, but of\ncourse this is not enough, we need the information needed to link a specific\nvalue with a specific module type that is able to load and handle it.\nSo when we save a `type specific value` about a module, we prefix it with\na 64 bit integer. 64 bits is large enough to store the information needed\nin order to lookup the module that can handle that specific type, but is\nshort enough that we can prefix each module value we store inside the RDB\nwithout making the final RDB file too big. At the same time, this solution\nof prefixing the value with a 64 bit signature does not require to do\nstrange things like defining in the RDB header a list of modules specific\ntypes. Everything is pretty simple.\nSo, what you can store in 64 bits in order to identify a given module in\na reliable way? Well if you build a character set of 64 symbols, you can\neasily store 9 characters of 6 bits, and you are left with 10 bits, that\nare used in order to store the encoding version of the type, so that\nthe same type can evolve in the future and provide a different and more\nefficient or updated serialization format for RDB files.\nSo the 64 bit prefix stored before each module value is like the following:\n\n\n```6|6|6|6|6|6|6|6|6|10\n```\n\n\nThe first 9 elements are 6-bits characters, the final 10 bits is the\nencoding version.\nWhen the RDB file is loaded back, it reads the 64 bit value, masks the final\n10 bits, and searches for a matching module in the modules types cache.\nWhen a matching one is found, the method to load the RDB file value is called\nwith the 10 bits encoding version as argument, so that the module knows\nwhat version of the data layout to load, if it can support multiple versions.\nNow the interesting thing about all this is that, if instead the module type\ncannot be resolved, since there is no loaded module having this signature,\nwe can convert back the 64 bit value into a 9 characters name, and print\nan error to the user that includes the module type name! So that she or he\nimmediately realizes what's wrong.\nSetting and getting keys\nAfter registering our new data type in the `RedisModule_OnLoad()` function,\nwe also need to be able to set Redis keys having as value our native type.\nThis normally happens in the context of commands that write data to a key.\nThe native types API allow to set and get keys to module native data types,\nand to test if a given key is already associated to a value of a specific data\ntype.\nThe API uses the normal modules `RedisModule_OpenKey()` low level key access\ninterface in order to deal with this. This is an example of setting a\nnative type private data structure to a Redis key:\n\n\n```RedisModuleKey *key = RedisModule_OpenKey(ctx,keyname,REDISMODULE_WRITE);\nstruct some_private_struct *data = createMyDataStructure();\nRedisModule_ModuleTypeSetValue(key,MyType,data);\n```\n\n\nThe function `RedisModule_ModuleTypeSetValue()` is used with a key handle open\nfor writing, and gets three arguments: the key handle, the reference to the\nnative type, as obtained during the type registration, and finally a `void*`\npointer that contains the private data implementing the module native type.\nNote that Redis has no clues at all about what your data contains. It will\njust call the callbacks you provided during the method registration in order\nto perform operations on the type.\nSimilarly we can retrieve the private data from a key using this function:\n\n\n```struct some_private_struct *data;\ndata = RedisModule_ModuleTypeGetValue(key);\n```\n\n\nWe can also test for a key to have our native type as value:\n\n\n```if (RedisModule_ModuleTypeGetType(key) == MyType) {\n    /* ... do something ... */\n}\n```\n\n\nHowever for the calls to do the right thing, we need to check if the key\nis empty, if it contains a value of the right kind, and so forth. So\nthe idiomatic code to implement a command writing to our native type\nis along these lines:\n\n\n```RedisModuleKey *key = RedisModule_OpenKey(ctx,argv[1],\n    REDISMODULE_READ|REDISMODULE_WRITE);\nint type = RedisModule_KeyType(key);\nif (type != REDISMODULE_KEYTYPE_EMPTY &&\n    RedisModule_ModuleTypeGetType(key) != MyType)\n{\n    return RedisModule_ReplyWithError(ctx,REDISMODULE_ERRORMSG_WRONGTYPE);\n}\n```\n\n\nThen if we successfully verified the key is not of the wrong type, and\nwe are going to write to it, we usually want to create a new data structure if\nthe key is empty, or retrieve the reference to the value associated to the\nkey if there is already one:\n\n\n```/* Create an empty value object if the key is currently empty. */\nstruct some_private_struct *data;\nif (type == REDISMODULE_KEYTYPE_EMPTY) {\n    data = createMyDataStructure();\n    RedisModule_ModuleTypeSetValue(key,MyTyke,data);\n} else {\n    data = RedisModule_ModuleTypeGetValue(key);\n}\n/* Do something with 'data'... */\n```\n\n\nFree method\nAs already mentioned, when Redis needs to free a key holding a native type\nvalue, it needs help from the module in order to release the memory. This\nis the reason why we pass a `free` callback during the type registration:\n\n\n```typedef void (*RedisModuleTypeFreeFunc)(void *value);\n```\n\n\nA trivial implementation of the free method can be something like this,\nassuming our data structure is composed of a single allocation:\n\n\n```void MyTypeFreeCallback(void *value) {\n    RedisModule_Free(value);\n}\n```\n\n\nHowever a more real world one will call some function that performs a more\ncomplex memory reclaiming, by casting the void pointer to some structure\nand freeing all the resources composing the value.\nRDB load and save methods\nThe RDB saving and loading callbacks need to create (and load back) a\nrepresentation of the data type on disk. Redis offers a high level API\nthat can automatically store inside the RDB file the following types:\n\nUnsigned 64 bit integers.\nSigned 64 bit integers.\nDoubles.\nStrings.\n\nIt is up to the module to find a viable representation using the above base\ntypes. However note that while the integer and double values are stored\nand loaded in an architecture and endianness agnostic way, if you use\nthe raw string saving API to, for example, save a structure on disk, you\nhave to care those details yourself.\nThis is the list of functions performing RDB saving and loading:\n\n\n```void RedisModule_SaveUnsigned(RedisModuleIO *io, uint64_t value);\nuint64_t RedisModule_LoadUnsigned(RedisModuleIO *io);\nvoid RedisModule_SaveSigned(RedisModuleIO *io, int64_t value);\nint64_t RedisModule_LoadSigned(RedisModuleIO *io);\nvoid RedisModule_SaveString(RedisModuleIO *io, RedisModuleString *s);\nvoid RedisModule_SaveStringBuffer(RedisModuleIO *io, const char *str, size_t len);\nRedisModuleString *RedisModule_LoadString(RedisModuleIO *io);\nchar *RedisModule_LoadStringBuffer(RedisModuleIO *io, size_t *lenptr);\nvoid RedisModule_SaveDouble(RedisModuleIO *io, double value);\ndouble RedisModule_LoadDouble(RedisModuleIO *io);\n```\n\n\nThe functions don't require any error checking from the module, that can\nalways assume calls succeed.\nAs an example, imagine I've a native type that implements an array of\ndouble values, with the following structure:\n\n\n```struct double_array {\n    size_t count;\n    double *values;\n};\n```\n\n\nMy `rdb_save` method may look like the following:\n\n\n```void DoubleArrayRDBSave(RedisModuleIO *io, void *ptr) {\n    struct dobule_array *da = ptr;\n    RedisModule_SaveUnsigned(io,da->count);\n    for (size_t j = 0; j < da->count; j++)\n        RedisModule_SaveDouble(io,da->values[j]);\n}\n```\n\n\nWhat we did was to store the number of elements followed by each double\nvalue. So when later we'll have to load the structure in the `rdb_load`\nmethod we'll do something like this:\n\n\n```void *DoubleArrayRDBLoad(RedisModuleIO *io, int encver) {\n    if (encver != DOUBLE_ARRAY_ENC_VER) {\n        /* We should actually log an error here, or try to implement\n           the ability to load older versions of our data structure. */\n        return NULL;\n    }\n\n    struct double_array *da;\n    da = RedisModule_Alloc(sizeof(*da));\n    da->count = RedisModule_LoadUnsigned(io);\n    da->values = RedisModule_Alloc(da->count * sizeof(double));\n    for (size_t j = 0; j < da->count; j++)\n        da->values[j] = RedisModule_LoadDouble(io);\n    return da;\n}\n```\n\n\nThe load callback just reconstruct back the data structure from the data\nwe stored in the RDB file.\nNote that while there is no error handling on the API that writes and reads\nfrom disk, still the load callback can return NULL on errors in case what\nit reads does not look correct. Redis will just panic in that case.\nAOF rewriting\n\n\n```void RedisModule_EmitAOF(RedisModuleIO *io, const char *cmdname, const char *fmt, ...);\n```\n\n\nHandling multiple encodings\n\n\n```WORK IN PROGRESS\n```\n\n\nAllocating memory\nModules data types should try to use `RedisModule_Alloc()` functions family\nin order to allocate, reallocate and release heap memory used to implement the native data structures (see the other Redis Modules documentation for detailed information).\nThis is not just useful in order for Redis to be able to account for the memory used by the module, but there are also more advantages:\n\nRedis uses the `jemalloc` allocator, that often prevents fragmentation problems that could be caused by using the libc allocator.\nWhen loading strings from the RDB file, the native types API is able to return strings allocated directly with `RedisModule_Alloc()`, so that the module can directly link this memory into the data structure representation, avoiding a useless copy of the data.\n\nEven if you are using external libraries implementing your data structures, the\nallocation functions provided by the module API is exactly compatible with\n`malloc()`, `realloc()`, `free()` and `strdup()`, so converting the libraries\nin order to use these functions should be trivial.\nIn case you have an external library that uses libc `malloc()`, and you want\nto avoid replacing manually all the calls with the Redis Modules API calls,\nan approach could be to use simple macros in order to replace the libc calls\nwith the Redis API calls. Something like this could work:\n\n\n```#define malloc RedisModule_Alloc\n#define realloc RedisModule_Realloc\n#define free RedisModule_Free\n#define strdup RedisModule_Strdup\n```\n\n\nHowever take in mind that mixing libc calls with Redis API calls will result\ninto troubles and crashes, so if you replace calls using macros, you need to\nmake sure that all the calls are correctly replaced, and that the code with\nthe substituted calls will never, for example, attempt to call",
    "tag": "redis"
  },
  {
    "title": "modules-blocking-ops.md",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/modules/modules-blocking-ops.md",
    "content": "\ntitle: \"Redis modules and blocking commands\"\nlinkTitle: \"Blocking commands\"\nweight: 1\ndescription: >\n    How to implement blocking commands in a Redis module\naliases:\n    - /topics/modules-blocking-ops\n\nRedis has a few blocking commands among the built-in set of commands.\nOne of the most used is `BLPOP` (or the symmetric `BRPOP`) which blocks\nwaiting for elements arriving in a list.\nThe interesting fact about blocking commands is that they do not block\nthe whole server, but just the client calling them. Usually the reason to\nblock is that we expect some external event to happen: this can be\nsome change in the Redis data structures like in the `BLPOP` case, a\nlong computation happening in a thread, to receive some data from the\nnetwork, and so forth.\nRedis modules have the ability to implement blocking commands as well,\nthis documentation shows how the API works and describes a few patterns\nthat can be used in order to model blocking commands.\nNOTE: This API is currently experimental, so it can only be used if\nthe macro `REDISMODULE_EXPERIMENTAL_API` is defined. This is required because\nthese calls are still not in their final stage of design, so may change\nin the future, certain parts may be deprecated and so forth.\nTo use this part of the modules API include the modules header like that:\n\n\n```#define REDISMODULE_EXPERIMENTAL_API\n#include \"redismodule.h\"\n```\n\n\nHow blocking and resuming works.\nNote: You may want to check the `helloblock.c` example in the Redis source tree\ninside the `src/modules` directory, for a simple to understand example\non how the blocking API is applied.\nIn Redis modules, commands are implemented by callback functions that\nare invoked by the Redis core when the specific command is called\nby the user. Normally the callback terminates its execution sending\nsome reply to the client. Using the following function instead, the\nfunction implementing the module command may request that the client\nis put into the blocked state:\n\n\n```RedisModuleBlockedClient *RedisModule_BlockClient(RedisModuleCtx *ctx, RedisModuleCmdFunc reply_callback, RedisModuleCmdFunc timeout_callback, void (*free_privdata)(void*), long long timeout_ms);\n```\n\n\nThe function returns a `RedisModuleBlockedClient` object, which is later\nused in order to unblock the client. The arguments have the following\nmeaning:\n\n`ctx` is the command execution context as usually in the rest of the API.\n`reply_callback` is the callback, having the same prototype of a normal command function, that is called when the client is unblocked in order to return a reply to the client.\n`timeout_callback` is the callback, having the same prototype of a normal command function that is called when the client reached the `ms` timeout.\n`free_privdata` is the callback that is called in order to free the private data. Private data is a pointer to some data that is passed between the API used to unblock the client, to the callback that will send the reply to the client. We'll see how this mechanism works later in this document.\n`ms` is the timeout in milliseconds. When the timeout is reached, the timeout callback is called and the client is automatically aborted.\n\nOnce a client is blocked, it can be unblocked with the following API:\n\n\n```int RedisModule_UnblockClient(RedisModuleBlockedClient *bc, void *privdata);\n```\n\n\nThe function takes as argument the blocked client object returned by\nthe previous call to `RedisModule_BlockClient()`, and unblock the client.\nImmediately before the client gets unblocked, the `reply_callback` function\nspecified when the client was blocked is called: this function will\nhave access to the `privdata` pointer used here.\nIMPORTANT: The above function is thread safe, and can be called from within\na thread doing some work in order to implement the command that blocked\nthe client.\nThe `privdata` data will be freed automatically using the `free_privdata`\ncallback when the client is unblocked. This is useful since the reply\ncallback may never be called in case the client timeouts or disconnects\nfrom the server, so it's important that it's up to an external function\nto have the responsibility to free the data passed if needed.\nTo better understand how the API works, we can imagine writing a command\nthat blocks a client for one second, and then send as reply \"Hello!\".\nNote: arity checks and other non important things are not implemented\nint his command, in order to take the example simple.\n\n\n```int Example_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv,\n                         int argc)\n{\n    RedisModuleBlockedClient *bc =\n        RedisModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    pthread_create(&tid,NULL,threadmain,bc);\n\n    return REDISMODULE_OK;\n}\n\nvoid *threadmain(void *arg) {\n    RedisModuleBlockedClient *bc = arg;\n\n    sleep(1); /* Wait one second and unblock. */\n    RedisModule_UnblockClient(bc,NULL);\n}\n```\n\n\nThe above command blocks the client ASAP, spawning a thread that will\nwait a second and will unblock the client. Let's check the reply and\ntimeout callbacks, which are in our case very similar, since they\njust reply the client with a different reply type.\n\n\n```int reply_func(RedisModuleCtx *ctx, RedisModuleString **argv,\n               int argc)\n{\n    return RedisModule_ReplyWithSimpleString(ctx,\"Hello!\");\n}\n\nint timeout_func(RedisModuleCtx *ctx, RedisModuleString **argv,\n               int argc)\n{\n    return RedisModule_ReplyWithNull(ctx);\n}\n```\n\n\nThe reply callback just sends the \"Hello!\" string to the client.\nThe important bit here is that the reply callback is called when the\nclient is unblocked from the thread.\nThe timeout command returns `NULL`, as it often happens with actual\nRedis blocking commands timing out.\nPassing reply data when unblocking\nThe above example is simple to understand but lacks an important\nreal world aspect of an actual blocking command implementation: often\nthe reply function will need to know what to reply to the client,\nand this information is often provided as the client is unblocked.\nWe could modify the above example so that the thread generates a\nrandom number after waiting one second. You can think at it as an\nactually expansive operation of some kind. Then this random number\ncan be passed to the reply function so that we return it to the command\ncaller. In order to make this working, we modify the functions as follow:\n\n\n```void *threadmain(void *arg) {\n    RedisModuleBlockedClient *bc = arg;\n\n    sleep(1); /* Wait one second and unblock. */\n\n    long *mynumber = RedisModule_Alloc(sizeof(long));\n    *mynumber = rand();\n    RedisModule_UnblockClient(bc,mynumber);\n}\n```\n\n\nAs you can see, now the unblocking call is passing some private data,\nthat is the `mynumber` pointer, to the reply callback. In order to\nobtain this private data, the reply callback will use the following\nfunction:\n\n\n```void *RedisModule_GetBlockedClientPrivateData(RedisModuleCtx *ctx);\n```\n\n\nSo our reply callback is modified like that:\n\n\n```int reply_func(RedisModuleCtx *ctx, RedisModuleString **argv,\n               int argc)\n{\n    long *mynumber = RedisModule_GetBlockedClientPrivateData(ctx);\n    /* IMPORTANT: don't free mynumber here, but in the\n     * free privdata callback. */\n    return RedisModule_ReplyWithLongLong(ctx,mynumber);\n}\n```\n\n\nNote that we also need to pass a `free_privdata` function when blocking\nthe client with `RedisModule_BlockClient()`, since the allocated\nlong value must be freed. Our callback will look like the following:\n\n\n```void free_privdata(void *privdata) {\n    RedisModule_Free(privdata);\n}\n```\n\n\nNOTE: It is important to stress that the private data is best freed in the\n`free_privdata` callback because the reply function may not be called\nif the client disconnects or timeout.\nAlso note that the private data is also accessible from the timeout\ncallback, always using the `GetBlockedClientPrivateData()` API.\nAborting the blocking of a client\nOne problem that sometimes arises is that we need to allocate resources\nin order to implement the non blocking command. So we block the client,\nthen, for example, try to create a thread, but the thread creation function\nreturns an error. What to do in such a condition in order to recover? We\ndon't want to take the client blocked, nor we want to call `UnblockClient()`\nbecause this will trigger the reply callback to be called.\nIn this case the best thing to do is to use the following function:\n\n\n```int RedisModule_AbortBlock(RedisModuleBlockedClient *bc);\n```\n\n\nPractically this is how to use it:\n\n\n```int Example_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv,\n                         int argc)\n{\n    RedisModuleBlockedClient *bc =\n        RedisModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    if (pthread_create(&tid,NULL,threadmain,bc) != 0) {\n        RedisModule_AbortBlock(bc);\n        RedisModule_ReplyWithError(ctx,\"Sorry can't create a thread\");\n    }\n\n    return REDISMODULE_OK;\n}\n```\n\n\nThe client will be unblocked but the reply callback will not be called.\nImplementing the command, reply and timeout callback using a single function\nThe following functions can be used in order to implement the reply and\ncallback with the same function that implements the primary command\nfunction:\n\n\n```int RedisModule_IsBlockedReplyRequest(RedisModuleCtx *ctx);\nint RedisModule_IsBlockedTimeoutRequest(RedisModuleCtx *ctx);\n```\n\n\nSo I could rewrite the example command without using a separated\nreply and timeout callback:\n\n\n```int Example_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv,\n                         int argc)\n{\n    if (RedisModule_IsBlockedReplyRequest(ctx)) {\n        long *mynumber = RedisModule_GetBlockedClientPrivateData(ctx);\n        return RedisModule_ReplyWithLongLong(ctx,mynumber);\n    } else if (RedisModule_IsBlockedTimeoutRequest) {\n        return RedisModule_ReplyWithNull(ctx);\n    }\n\n    RedisModuleBlockedClient *bc =\n        RedisModule_BlockClient(ctx,reply_func,timeout_func,NULL,0);\n\n    pthread_t tid;\n    if (pthread_create(&tid,NULL,threadmain,bc) != 0) {\n        RedisModule_AbortBlock(bc);\n        RedisModule_ReplyWithError(ctx,\"Sorry can't create a thread\");\n    }\n\n    return REDISMODULE_OK;\n}\n```\n\n\nFunctionally is the same but there are people that will prefer the less\nverbose implementation that concentrates most of the command logic in a\nsingle function.\nWorking on copies of data inside a thread\nAn interesting pattern in order to work with threads implementing the\nslow part of a command, is to work with a copy of the data, so that\nwhile some operation is performed in a key, the user continues to see\nthe old version. However when the thread terminated its work, the\nrepresentations are swapped and the new, processed version, is used.\nAn example of this approach is the\nNeural Redis module\nwhere neural networks are trained in different threads while the\nuser can still execute and inspect their older versions.\nFuture work\nAn API is work in progress right now in order to allow Redis modules APIs\nto be called in a safe way from threads, so that the threaded command\ncan access the data space and do incremental operations.\nThere is no ETA for this feature but it may appear in the course of the",
    "tag": "redis"
  },
  {
    "title": "Passing configuration parameters to Redis modules",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/modules/_index.md",
    "content": "\ntitle: \"Redis modules API\"\nlinkTitle: \"Modules API\"\nweight: 2\ndescription: >\n    Introduction to writing Redis modules\naliases:\n    - /topics/modules-intro\n\nThe modules documentation is composed of the following pages:\n\nIntroduction to Redis modules (this file). An overview about Redis Modules system and API. It's a good idea to start your reading here.\nImplementing native data types covers the implementation of native data types into modules.\nBlocking operations shows how to write blocking commands that will not reply immediately, but will block the client, without blocking the Redis server, and will provide a reply whenever will be possible.\nRedis modules API reference is generated from module.c top comments of RedisModule functions. It is a good reference in order to understand how each function works.\n\nRedis modules make it possible to extend Redis functionality using external\nmodules, rapidly implementing new Redis commands with features\nsimilar to what can be done inside the core itself.\nRedis modules are dynamic libraries that can be loaded into Redis at\nstartup, or using the `MODULE LOAD` command. Redis exports a C API, in the\nform of a single C header file called `redismodule.h`. Modules are meant\nto be written in C, however it will be possible to use C++ or other languages\nthat have C binding functionalities.\nModules are designed in order to be loaded into different versions of Redis,\nso a given module does not need to be designed, or recompiled, in order to\nrun with a specific version of Redis. For this reason, the module will\nregister to the Redis core using a specific API version. The current API\nversion is \"1\".\nThis document is about an alpha version of Redis modules. API, functionalities\nand other details may change in the future.\nLoading modules\nIn order to test the module you are developing, you can load the module\nusing the following `redis.conf` configuration directive:\n\n\n```loadmodule /path/to/mymodule.so\n```\n\n\nIt is also possible to load a module at runtime using the following command:\n\n\n```MODULE LOAD /path/to/mymodule.so\n```\n\n\nIn order to list all loaded modules, use:\n\n\n```MODULE LIST\n```\n\n\nFinally, you can unload (and later reload if you wish) a module using the\nfollowing command:\n\n\n```MODULE UNLOAD mymodule\n```\n\n\nNote that `mymodule` above is not the filename without the `.so` suffix, but\ninstead, the name the module used to register itself into the Redis core.\nThe name can be obtained using `MODULE LIST`. However it is good practice\nthat the filename of the dynamic library is the same as the name the module\nuses to register itself into the Redis core.\nThe simplest module you can write\nIn order to show the different parts of a module, here we'll show a very\nsimple module that implements a command that outputs a random number.\n\n\n```#include \"redismodule.h\"\n#include <stdlib.h>\n\nint HelloworldRand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n    RedisModule_ReplyWithLongLong(ctx,rand());\n    return REDISMODULE_OK;\n}\n\nint RedisModule_OnLoad(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\n    if (RedisModule_Init(ctx,\"helloworld\",1,REDISMODULE_APIVER_1)\n        == REDISMODULE_ERR) return REDISMODULE_ERR;\n\n    if (RedisModule_CreateCommand(ctx,\"helloworld.rand\",\n        HelloworldRand_RedisCommand, \"fast random\",\n        0, 0, 0) == REDISMODULE_ERR)\n        return REDISMODULE_ERR;\n\n    return REDISMODULE_OK;\n}\n```\n\n\nThe example module has two functions. One implements a command called\nHELLOWORLD.RAND. This function is specific of that module. However the\nother function called `RedisModule_OnLoad()` must be present in each\nRedis module. It is the entry point for the module to be initialized,\nregister its commands, and potentially other private data structures\nit uses.\nNote that it is a good idea for modules to call commands with the\nname of the module followed by a dot, and finally the command name,\nlike in the case of `HELLOWORLD.RAND`. This way it is less likely to\nhave collisions.\nNote that if different modules have colliding commands, they'll not be\nable to work in Redis at the same time, since the function\n`RedisModule_CreateCommand` will fail in one of the modules, so the module\nloading will abort returning an error condition.\nModule initialization\nThe above example shows the usage of the function `RedisModule_Init()`.\nIt should be the first function called by the module `OnLoad` function.\nThe following is the function prototype:\n\n\n```int RedisModule_Init(RedisModuleCtx *ctx, const char *modulename,\n                     int module_version, int api_version);\n```\n\n\nThe `Init` function announces the Redis core that the module has a given\nname, its version (that is reported by `MODULE LIST`), and that is willing\nto use a specific version of the API.\nIf the API version is wrong, the name is already taken, or there are other\nsimilar errors, the function will return `REDISMODULE_ERR`, and the module\n`OnLoad` function should return ASAP with an error.\nBefore the `Init` function is called, no other API function can be called,\notherwise the module will segfault and the Redis instance will crash.\nThe second function called, `RedisModule_CreateCommand`, is used in order\nto register commands into the Redis core. The following is the prototype:\n\n\n```int RedisModule_CreateCommand(RedisModuleCtx *ctx, const char *name,\n                              RedisModuleCmdFunc cmdfunc, const char *strflags,\n                              int firstkey, int lastkey, int keystep);\n```\n\n\nAs you can see, most Redis modules API calls all take as first argument\nthe `context` of the module, so that they have a reference to the module\ncalling it, to the command and client executing a given command, and so forth.\nTo create a new command, the above function needs the context, the command's\nname, a pointer to the function implementing the command, the command's flags\nand the positions of key names in the command's arguments.\nThe function that implements the command must have the following prototype:\n\n\n```int mycommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);\n```\n\n\nThe command function arguments are just the context, that will be passed\nto all the other API calls, the command argument vector, and total number\nof arguments, as passed by the user.\nAs you can see, the arguments are provided as pointers to a specific data\ntype, the `RedisModuleString`. This is an opaque data type you have API\nfunctions to access and use, direct access to its fields is never needed.\nZooming into the example command implementation, we can find another call:\n\n\n```int RedisModule_ReplyWithLongLong(RedisModuleCtx *ctx, long long integer);\n```\n\n\nThis function returns an integer to the client that invoked the command,\nexactly like other Redis commands do, like for example `INCR` or `SCARD`.\nModule cleanup\nIn most cases, there is no need for special cleanup.\nWhen a module is unloaded, Redis will automatically unregister commands and\nunsubscribe from notifications.\nHowever in the case where a module contains some persistent memory or\nconfiguration, a module may include an optional `RedisModule_OnUnload`\nfunction.\nIf a module provides this function, it will be invoked during the module unload\nprocess.\nThe following is the function prototype:\n\n\n```int RedisModule_OnUnload(RedisModuleCtx *ctx);\n```\n\n\nThe `OnUnload` function may prevent module unloading by returning\n`REDISMODULE_ERR`.\nOtherwise, `REDISMODULE_OK` should be returned.\nSetup and dependencies of a Redis module\nRedis modules don't depend on Redis or some other library, nor they\nneed to be compiled with a specific `redismodule.h` file. In order\nto create a new module, just copy a recent version of `redismodule.h`\nin your source tree, link all the libraries you want, and create\na dynamic library having the `RedisModule_OnLoad()` function symbol\nexported.\nThe module will be able to load into different versions of Redis.\nA module can be designed to support both newer and older Redis versions where certain API functions are not available in all versions.\nIf an API function is not implemented in the currently running Redis version, the function pointer is set to NULL.\nThis allows the module to check if a function exists before using it:\n\n\n```if (RedisModule_SetCommandInfo != NULL) {\n    RedisModule_SetCommandInfo(cmd, &info);\n}\n```\n\n\nIn recent versions of `redismodule.h`, a convenience macro `RMAPI_FUNC_SUPPORTED(funcname)` is defined.\nUsing the macro or just comparing with NULL is a matter of personal preference.\nPassing configuration parameters to Redis modules\nWhen the module is loaded with the `MODULE LOAD` command, or using the\n`loadmodule` directive in the `redis.conf` file, the user is able to pass\nconfiguration parameters to the module by adding arguments after the module\nfile name:\n\n\n```loadmodule mymodule.so foo bar 1234\n```\n\n\nIn the above example the strings `foo`, `bar` and `1234` will be passed\nto the module `OnLoad()` function in the `argv` argument as an array\nof RedisModuleString pointers. The number of arguments passed is into `argc`.\nThe way you can access those strings will be explained in the rest of this\ndocument. Normally the module will store the module configuration parameters\nin some `static` global variable that can be accessed module wide, so that\nthe configuration can change the behavior of different commands.\nWorking with RedisModuleString objects\nThe command argument vector `argv` passed to module commands, and the\nreturn value of other module APIs functions, are of type `RedisModuleString`.\nUsually you directly pass module strings to other API calls, however sometimes\nyou may need to directly access the string object.\nThere are a few functions in order to work with string objects:\n\n\n```const char *RedisModule_StringPtrLen(RedisModuleString *string, size_t *len);\n```\n\n\nThe above function accesses a string by returning its pointer and setting its\nlength in `len`.\nYou should never write to a string object pointer, as you can see from the\n`const` pointer qualifier.\nHowever, if you want, you can create new string objects using the following\nAPI:\n\n\n```RedisModuleString *RedisModule_CreateString(RedisModuleCtx *ctx, const char *ptr, size_t len);\n```\n\n\nThe string returned by the above command must be freed using a corresponding\ncall to `RedisModule_FreeString()`:\n\n\n```void RedisModule_FreeString(RedisModuleString *str);\n```\n\n\nHowever if you want to avoid having to free strings, the automatic memory\nmanagement, covered later in this document, can be a good alternative, by\ndoing it for you.\nNote that the strings provided via the argument vector `argv` never need\nto be freed. You only need to free new strings you create, or new strings\nreturned by other APIs, where it is specified that the returned string must\nbe freed.\nCreating strings from numbers or parsing strings as numbers\nCreating a new string from an integer is a very common operation, so there\nis a function to do this:\n\n\n```RedisModuleString *mystr = RedisModule_CreateStringFromLongLong(ctx,10);\n```\n\n\nSimilarly in order to parse a string as a number:\n\n\n```long long myval;\nif (RedisModule_StringToLongLong(ctx,argv[1],&myval) == REDISMODULE_OK) {\n    /* Do something with 'myval' */\n}\n```\n\n\nAccessing Redis keys from modules\nMost Redis modules, in order to be useful, have to interact with the Redis\ndata space (this is not always true, for example an ID generator may\nnever touch Redis keys). Redis modules have two different APIs in order to\naccess the Redis data space, one is a low level API that provides very\nfast access and a set of functions to manipulate Redis data structures.\nThe other API is more high level, and allows to call Redis commands and\nfetch the result, similarly to how Lua scripts access Redis.\nThe high level API is also useful in order to access Redis functionalities\nthat are not available as APIs.\nIn general modules developers should prefer the low level API, because commands\nimplemented using the low level API run at a speed comparable to the speed\nof native Redis commands. However there are definitely use cases for the\nhigher level API. For example often the bottleneck could be processing the\ndata and not accessing it.\nAlso note that sometimes using the low level API is not harder compared to\nthe higher level one.\nCalling Redis commands\nThe high level API to access Redis is the sum of the `RedisModule_Call()`\nfunction, together with the functions needed in order to access the\nreply object returned by `Call()`.\n`RedisModule_Call` uses a special calling convention, with a format specifier\nthat is used to specify what kind of objects you are passing as arguments\nto the function.\nRedis commands are invoked just using a command name and a list of arguments.\nHowever when calling commands, the arguments may originate from different\nkind of strings: null-terminated C strings, RedisModuleString objects as\nreceived from the `argv` parameter in the command implementation, binary\nsafe C buffers with a pointer and a length, and so forth.\nFor example if I want to call `INCRBY` using a first argument (the key)\na string received in the argument vector `argv`, which is an array\nof RedisModuleString object pointers, and a C string representing the\nnumber \"10\" as second argument (the increment), I'll use the following\nfunction call:\n\n\n```RedisModuleCallReply *reply;\nreply = RedisModule_Call(ctx,\"INCRBY\",\"sc\",argv[1],\"10\");\n```\n\n\nThe first argument is the context, and the second is always a null terminated\nC string with the command name. The third argument is the format specifier\nwhere each character corresponds to the type of the arguments that will follow.\nIn the above case `\"sc\"` means a RedisModuleString object, and a null\nterminated C string. The other arguments are just the two arguments as\nspecified. In fact `argv[1]` is a RedisModuleString and `\"10\"` is a null\nterminated C string.\nThis is the full list of format specifiers:\n\nc -- Null terminated C string pointer.\nb -- C buffer, two arguments needed: C string pointer and `size_t` length.\ns -- RedisModuleString as received in `argv` or by other Redis module APIs returning a RedisModuleString object.\nl -- Long long integer.\nv -- Array of RedisModuleString objects.\n! -- This modifier just tells the function to replicate the command to replicas and AOF. It is ignored from the point of view of arguments parsing.\nA -- This modifier, when `!` is given, tells to suppress AOF propagation: the command will be propagated only to replicas.\nR -- This modifier, when `!` is given, tells to suppress replicas propagation: the command will be propagated only to the AOF if enabled.\n\nThe function returns a `RedisModuleCallReply` object on success, on\nerror NULL is returned.\nNULL is returned when the command name is invalid, the format specifier uses\ncharacters that are not recognized, or when the command is called with the\nwrong number of arguments. In the above cases the `errno` var is set to `EINVAL`. NULL is also returned when, in an instance with Cluster enabled, the target\nkeys are about non local hash slots. In this case `errno` is set to `EPERM`.\nWorking with RedisModuleCallReply objects.\n`RedisModuleCall` returns reply objects that can be accessed using the\n`RedisModule_CallReply*` family of functions.\nIn order to obtain the type or reply (corresponding to one of the data types\nsupported by the Redis protocol), the function `RedisModule_CallReplyType()`\nis used:\n\n\n```reply = RedisModule_Call(ctx,\"INCRBY\",\"sc\",argv[1],\"10\");\nif (RedisModule_CallReplyType(reply) == REDISMODULE_REPLY_INTEGER) {\n    long long myval = RedisModule_CallReplyInteger(reply);\n    /* Do something with myval. */\n}\n```\n\n\nValid reply types are:\n\n`REDISMODULE_REPLY_STRING` Bulk string or status replies.\n`REDISMODULE_REPLY_ERROR` Errors.\n`REDISMODULE_REPLY_INTEGER` Signed 64 bit integers.\n`REDISMODULE_REPLY_ARRAY` Array of replies.\n`REDISMODULE_REPLY_NULL` NULL reply.\n\nStrings, errors and arrays have an associated length. For strings and errors\nthe length corresponds to the length of the string. For arrays the length\nis the number of elements. To obtain the reply length the following function\nis used:\n\n\n```size_t reply_len = RedisModule_CallReplyLength(reply);\n```\n\n\nIn order to obtain the value of an integer reply, the following function is used, as already shown in the example above:\n\n\n```long long reply_integer_val = RedisModule_CallReplyInteger(reply);\n```\n\n\nCalled with a reply object of the wrong type, the above function always\nreturns `LLONG_MIN`.\nSub elements of array replies are accessed this way:\n\n\n```RedisModuleCallReply *subreply;\nsubreply = RedisModule_CallReplyArrayElement(reply,idx);\n```\n\n\nThe above function returns NULL if you try to access out of range elements.\nStrings and errors (which are like strings but with a different type) can\nbe accessed using in the following way, making sure to never write to\nthe resulting pointer (that is returned as a `const` pointer so that\nmisusing must be pretty explicit):\n\n\n```size_t len;\nchar *ptr = RedisModule_CallReplyStringPtr(reply,&len);\n```\n\n\nIf the reply type is not a string or an error, NULL is returned.\nRedisCallReply objects are not the same as module string objects\n(RedisModuleString types). However sometimes you may need to pass replies\nof type string or integer, to API functions expecting a module string.\nWhen this is the case, you may want to evaluate if using the low level\nAPI could be a simpler way to implement your command, or you can use\nthe following function in order to create a new string object from a\ncall reply of type string, error or integer:\n\n\n```RedisModuleString *mystr = RedisModule_CreateStringFromCallReply(myreply);\n```\n\n\nIf the reply is not of the right type, NULL is returned.\nThe returned string object should be released with `RedisModule_FreeString()`\nas usually, or by enabling automatic memory management (see corresponding\nsection).\nReleasing call reply objects\nReply objects must be freed using `RedisModule_FreeCallReply`. For arrays,\nyou need to free only the top level reply, not the nested replies.\nCurrently the module implementation provides a protection in order to avoid\ncrashing if you free a nested reply object for error, however this feature\nis not guaranteed to be here forever, so should not be considered part\nof the API.\nIf you use automatic memory management (explained later in this document)\nyou don't need to free replies (but you still could if you wish to release\nmemory ASAP).\nReturning values from Redis commands\nLike normal Redis commands, new commands implemented via modules must be\nable to return values to the caller. The API exports a set of functions for\nthis goal, in order to return the usual types of the Redis protocol, and\narrays of such types as elements. Also errors can be returned with any\nerror string and code (the error code is the initial uppercase letters in\nthe error message, like the \"BUSY\" string in the \"BUSY the sever is busy\" error\nmessage).\nAll the functions to send a reply to the client are called\n`RedisModule_ReplyWith<something>`.\nTo return an error, use:\n\n\n```RedisModule_ReplyWithError(RedisModuleCtx *ctx, const char *err);\n```\n\n\nThere is a predefined error string for key of wrong type errors:\n\n\n```REDISMODULE_ERRORMSG_WRONGTYPE\n```\n\n\nExample usage:\n\n\n```RedisModule_ReplyWithError(ctx,\"ERR invalid arguments\");\n```\n\n\nWe already saw how to reply with a `long long` in the examples above:\n\n\n```RedisModule_ReplyWithLongLong(ctx,12345);\n```\n\n\nTo reply with a simple string, that can't contain binary values or newlines,\n(so it's suitable to send small words, like \"OK\") we use:\n\n\n```RedisModule_ReplyWithSimpleString(ctx,\"OK\");\n```\n\n\nIt's possible to reply with \"bulk strings\" that are binary safe, using\ntwo different functions:\n\n\n```int RedisModule_ReplyWithStringBuffer(RedisModuleCtx *ctx, const char *buf, size_t len);\n\nint RedisModule_ReplyWithString(RedisModuleCtx *ctx, RedisModuleString *str);\n```\n\n\nThe first function gets a C pointer and length. The second a RedisModuleString\nobject. Use one or the other depending on the source type you have at hand.\nIn order to reply with an array, you just need to use a function to emit the\narray length, followed by as many calls to the above functions as the number\nof elements of the array are:\n\n\n```RedisModule_ReplyWithArray(ctx,2);\nRedisModule_ReplyWithStringBuffer(ctx,\"age\",3);\nRedisModule_ReplyWithLongLong(ctx,22);\n```\n\n\nTo return nested arrays is easy, your nested array element just uses another\ncall to `RedisModule_ReplyWithArray()` followed by the calls to emit the\nsub array elements.\nReturning arrays with dynamic length\nSometimes it is not possible to know beforehand the number of items of\nan array. As an example, think of a Redis module implementing a FACTOR\ncommand that given a number outputs the prime factors. Instead of\nfactorializing the number, storing the prime factors into an array, and\nlater produce the command reply, a better solution is to start an array\nreply where the length is not known, and set it later. This is accomplished\nwith a special argument to `RedisModule_ReplyWithArray()`:\n\n\n```RedisModule_ReplyWithArray(ctx, REDISMODULE_POSTPONED_LEN);\n```\n\n\nThe above call starts an array reply so we can use other `ReplyWith` calls\nin order to produce the array items. Finally in order to set the length,\nuse the following call:\n\n\n```RedisModule_ReplySetArrayLength(ctx, number_of_items);\n```\n\n\nIn the case of the FACTOR command, this translates to some code similar\nto this:\n\n\n```RedisModule_ReplyWithArray(ctx, REDISMODULE_POSTPONED_LEN);\nnumber_of_factors = 0;\nwhile(still_factors) {\n    RedisModule_ReplyWithLongLong(ctx, some_factor);\n    number_of_factors++;\n}\nRedisModule_ReplySetArrayLength(ctx, number_of_factors);\n```\n\n\nAnother common use case for this feature is iterating over the arrays of\nsome collection and only returning the ones passing some kind of filtering.\nIt is possible to have multiple nested arrays with postponed reply.\nEach call to `SetArray()` will set the length of the latest corresponding\ncall to `ReplyWithArray()`:\n\n\n```RedisModule_ReplyWithArray(ctx, REDISMODULE_POSTPONED_LEN);\n... generate 100 elements ...\nRedisModule_ReplyWithArray(ctx, REDISMODULE_POSTPONED_LEN);\n... generate 10 elements ...\nRedisModule_ReplySetArrayLength(ctx, 10);\nRedisModule_ReplySetArrayLength(ctx, 100);\n```\n\n\nThis creates a 100 items array having as last element a 10 items array.\nArity and type checks\nOften commands need to check that the number of arguments and type of the key\nis correct. In order to report a wrong arity, there is a specific function\ncalled `RedisModule_WrongArity()`. The usage is trivial:\n\n\n```if (argc != 2) return RedisModule_WrongArity(ctx);\n```\n\n\nChecking for the wrong type involves opening the key and checking the type:\n\n\n```RedisModuleKey *key = RedisModule_OpenKey(ctx,argv[1],\n    REDISMODULE_READ|REDISMODULE_WRITE);\n\nint keytype = RedisModule_KeyType(key);\nif (keytype != REDISMODULE_KEYTYPE_STRING &&\n    keytype != REDISMODULE_KEYTYPE_EMPTY)\n{\n    RedisModule_CloseKey(key);\n    return RedisModule_ReplyWithError(ctx,REDISMODULE_ERRORMSG_WRONGTYPE);\n}\n```\n\n\nNote that you often want to proceed with a command both if the key\nis of the expected type, or if it's empty.\nLow level access to keys\nLow level access to keys allow to perform operations on value objects associated\nto keys directly, with a speed similar to what Redis uses internally to\nimplement the built-in commands.\nOnce a key is opened, a key pointer is returned that will be used with all the\nother low level API calls in order to perform operations on the key or its\nassociated value.\nBecause the API is meant to be very fast, it cannot do too many run-time\nchecks, so the user must be aware of certain rules to follow:\n\nOpening the same key multiple times where at least one instance is opened for writing, is undefined and may lead to crashes.\nWhile a key is open, it should only be accessed via the low level key API. For example opening a key, then calling DEL on the same key using the `RedisModule_Call()` API will result into a crash. However it is safe to open a key, perform some operation with the low level API, closing it, then using other APIs to manage the same key, and later opening it again to do some more work.\n\nIn order to open a key the `RedisModule_OpenKey` function is used. It returns\na key pointer, that we'll use with all the next calls to access and modify\nthe value:\n\n\n```RedisModuleKey *key;\nkey = RedisModule_OpenKey(ctx,argv[1],REDISMODULE_READ);\n```\n\n\nThe second argument is the key name, that must be a `RedisModuleString` object.\nThe third argument is the mode: `REDISMODULE_READ` or `REDISMODULE_WRITE`.\nIt is possible to use `|` to bitwise OR the two modes to open the key in\nboth modes. Currently a key opened for writing can also be accessed for reading\nbut this is to be considered an implementation detail. The right mode should\nbe used in sane modules.\nYou can open non existing keys for writing, since the keys will be created\nwhen an attempt to write to the key is performed. However when opening keys\njust for reading, `RedisModule_OpenKey` will return NULL if the key does not\nexist.\nOnce you are done using a key, you can close it with:\n\n\n```RedisModule_CloseKey(key);\n```\n\n\nNote that if automatic memory management is enabled, you are not forced to\nclose keys. When the module function returns, Redis will take care to close\nall the keys which are still open.\nGetting the key type\nIn order to obtain the value of a key, use the `RedisModule_KeyType()` function:\n\n\n```int keytype = RedisModule_KeyType(key);\n```\n\n\nIt returns one of the following values:\n\n\n```REDISMODULE_KEYTYPE_EMPTY\nREDISMODULE_KEYTYPE_STRING\nREDISMODULE_KEYTYPE_LIST\nREDISMODULE_KEYTYPE_HASH\nREDISMODULE_KEYTYPE_SET\nREDISMODULE_KEYTYPE_ZSET\n```\n\n\nThe above are just the usual Redis key types, with the addition of an empty\ntype, that signals the key pointer is associated with an empty key that\ndoes not yet exists.\nCreating new keys\nTo create a new key, open it for writing and then write to it using one\nof the key writing functions. Example:\n\n\n```RedisModuleKey *key;\nkey = RedisModule_OpenKey(ctx,argv[1],REDISMODULE_WRITE);\nif (RedisModule_KeyType(key) == REDISMODULE_KEYTYPE_EMPTY) {\n    RedisModule_StringSet(key,argv[2]);\n}\n```\n\n\nDeleting keys\nJust use:\n\n\n```RedisModule_DeleteKey(key);\n```\n\n\nThe function returns `REDISMODULE_ERR` if the key is not open for writing.\nNote that after a key gets deleted, it is setup in order to be targeted\nby new key commands. For example `RedisModule_KeyType()` will return it is\nan empty key, and writing to it will create a new key, possibly of another\ntype (depending on the API used).\nManaging key expires (TTLs)\nTo control key expires two functions are provided, that are able to set,\nmodify, get, and unset the time to live associated with a key.\nOne function is used in order to query the current expire of an open key:\n\n\n```mstime_t RedisModule_GetExpire(RedisModuleKey *key);\n```\n\n\nThe function returns the time to live of the key in milliseconds, or\n`REDISMODULE_NO_EXPIRE` as a special value to signal the key has no associated\nexpire or does not exist at all (you can differentiate the two cases checking\nif the key type is `REDISMODULE_KEYTYPE_EMPTY`).\nIn order to change the expire of a key the following function is used instead:\n\n\n```int RedisModule_SetExpire(RedisModuleKey *key, mstime_t expire);\n```\n\n\nWhen called on a non existing key, `REDISMODULE_ERR` is returned, because\nthe function can only associate expires to existing open keys (non existing\nopen keys are only useful in order to create new values with data type\nspecific write operations).\nAgain the `expire` time is specified in milliseconds. If the key has currently\nno expire, a new expire is set. If the key already have an expire, it is\nreplaced with the new value.\nIf the key has an expire, and the special value `REDISMODULE_NO_EXPIRE` is\nused as a new expire, the expire is removed, similarly to the Redis\n`PERSIST` command. In case the key was already persistent, no operation is\nperformed.\nObtaining the length of values\nThere is a single function in order to retrieve the length of the value\nassociated to an open key. The returned length is value-specific, and is\nthe string length for strings, and the number of elements for the aggregated\ndata types (how many elements there is in a list, set, sorted set, hash).\n\n\n```size_t len = RedisModule_ValueLength(key);\n```\n\n\nIf the key does not exist, 0 is returned by the function:\nString type API\nSetting a new string value, like the Redis `SET` command does, is performed\nusing:\n\n\n```int RedisModule_StringSet(RedisModuleKey *key, RedisModuleString *str);\n```\n\n\nThe function works exactly like the Redis `SET` command itself, that is, if\nthere is a prior value (of any type) it will be deleted.\nAccessing existing string values is performed using DMA (direct memory\naccess) for speed. The API will return a pointer and a length, so that's\npossible to access and, if needed, modify the string directly.\n\n\n```size_t len, j;\nchar *myptr = RedisModule_StringDMA(key,&len,REDISMODULE_WRITE);\nfor (j = 0; j < len; j++) myptr[j] = 'A';\n```\n\n\nIn the above example we write directly on the string. Note that if you want\nto write, you must be sure to ask for `WRITE` mode.\nDMA pointers are only valid if no other operations are performed with the key\nbefore using the pointer, after the DMA call.\nSometimes when we want to manipulate strings directly, we need to change\ntheir size as well. For this scope, the `RedisModule_StringTruncate` function\nis used. Example:\n\n\n```RedisModule_StringTruncate(mykey,1024);\n```\n\n\nThe function truncates, or enlarges the string as needed, padding it with\nzero bytes if the previous length is smaller than the new length we request.\nIf the string does not exist since `key` is associated to an open empty key,\na string value is created and associated to the key.\nNote that every time `StringTruncate()` is called, we need to re-obtain\nthe DMA pointer again, since the old may be invalid.\nList type API\nIt's possible to push and pop values from list values:\n\n\n```int RedisModule_ListPush(RedisModuleKey *key, int where, RedisModuleString *ele);\nRedisModuleString *RedisModule_ListPop(RedisModuleKey *key, int where);\n```\n\n\nIn both the APIs the `where` argument specifies if to push or pop from tail\nor head, using the following macros:\n\n\n```REDISMODULE_LIST_HEAD\nREDISMODULE_LIST_TAIL\n```\n\n\nElements returned by `RedisModule_ListPop()` are like strings created with\n`RedisModule_CreateString()`, they must be released with\n`RedisModule_FreeString()` or by enabling automatic memory management.\nSet type API\nWork in progress.\nSorted set type API\nDocumentation missing, please refer to the top comments inside `module.c`\nfor the following functions:\n\n`RedisModule_ZsetAdd`\n`RedisModule_ZsetIncrby`\n`RedisModule_ZsetScore`\n`RedisModule_ZsetRem`\n\nAnd for the sorted set iterator:\n\n`RedisModule_ZsetRangeStop`\n`RedisModule_ZsetFirstInScoreRange`\n`RedisModule_ZsetLastInScoreRange`\n`RedisModule_ZsetFirstInLexRange`\n`RedisModule_ZsetLastInLexRange`\n`RedisModule_ZsetRangeCurrentElement`\n`RedisModule_ZsetRangeNext`\n`RedisModule_ZsetRangePrev`\n`RedisModule_ZsetRangeEndReached`\n\nHash type API\nDocumentation missing, please refer to the top comments inside `module.c`\nfor the following functions:\n\n`RedisModule_HashSet`\n`RedisModule_HashGet`\n\nIterating aggregated values\nWork in progress.\nReplicating commands\nIf you want to use module commands exactly like normal Redis commands, in the\ncontext of replicated Redis instances, or using the AOF file for persistence,\nit is important for module commands to handle their replication in a consistent\nway.\nWhen using the higher level APIs to invoke commands, replication happens\nautomatically if you use the \"!\" modifier in the format string of\n`RedisModule_Call()` as in the following example:\n\n\n```reply = RedisModule_Call(ctx,\"INCRBY\",\"!sc\",argv[1],\"10\");\n```\n\n\nAs you can see the format specifier is `\"!sc\"`. The bang is not parsed as a\nformat specifier, but it internally flags the command as \"must replicate\".\nIf you use the above programming style, there are no problems.\nHowever sometimes things are more complex than that, and you use the low level\nAPI. In this case, if there are no side effects in the command execution, and\nit consistently always performs the same work, what is possible to do is to\nreplicate the command verbatim as the user executed it. To do that, you just\nneed to call the following function:\n\n\n```RedisModule_ReplicateVerbatim(ctx);\n```\n\n\nWhen you use the above API, you should not use any other replication function\nsince they are not guaranteed to mix well.\nHowever this is not the only option. It's also possible to exactly tell\nRedis what commands to replicate as the effect of the command execution, using\nan API similar to `RedisModule_Call()` but that instead of calling the command\nsends it to the AOF / replicas stream. Example:\n\n\n```RedisModule_Replicate(ctx,\"INCRBY\",\"cl\",\"foo\",my_increment);\n```\n\n\nIt's possible to call `RedisModule_Replicate` multiple times, and each\nwill emit a command. All the sequence emitted is wrapped between a\n`MULTI/EXEC` transaction, so that the AOF and replication effects are the\nsame as executing a single command.\nNote that `Call()` replication and `Replicate()` replication have a rule,\nin case you want to mix both forms of replication (not necessarily a good\nidea if there are simpler approaches). Commands replicated with `Call()`\nare always the first emitted in the final `MULTI/EXEC` block, while all\nthe commands emitted with `Replicate()` will follow.\nAutomatic memory management\nNormally when writing programs in the C language, programmers need to manage\nmemory manually. This is why the Redis modules API has functions to release\nstrings, close open keys, free replies, and so forth.\nHowever given that commands are executed in a contained environment and\nwith a set of strict APIs, Redis is able to provide automatic memory management\nto modules, at the cost of some performance (most of the time, a very low\ncost).\nWhen automatic memory management is enabled:\n\nYou don't need to close open keys.\nYou don't need to free replies.\nYou don't need to free RedisModuleString objects.\n\nHowever you can still do it, if you want. For example, automatic memory\nmanagement may be active, but inside a loop allocating a lot of strings,\nyou may still want to free strings no longer used.\nIn order to enable automatic memory management, just call the following\nfunction at the start of the command implementation:\n\n\n```RedisModule_AutoMemory(ctx);\n```\n\n\nAutomatic memory management is usually the way to go, however experienced\nC programmers may not use it in order to gain some speed and memory usage\nbenefit.\nAllocating memory into modules\nNormal C programs use `malloc()` and `free()` in order to allocate and\nrelease memory dynamically. While in Redis modules the use of malloc is\nnot technically forbidden, it is a lot better to use the Redis Modules\nspecific functions, that are exact replacements for `malloc`, `free`,\n`realloc` and `strdup`. These functions are:\n\n\n```void *RedisModule_Alloc(size_t bytes);\nvoid* RedisModule_Realloc(void *ptr, size_t bytes);\nvoid RedisModule_Free(void *ptr);\nvoid RedisModule_Calloc(size_t nmemb, size_t size);\nchar *RedisModule_Strdup(const char *str);\n```\n\n\nThey work exactly like their `libc` equivalent calls, however they use\nthe same allocator Redis uses, and the memory allocated using these\nfunctions is reported by the `INFO` command in the memory section, is\naccounted when enforcing the `maxmemory` policy, and in general is\na first citizen of the Redis executable. On the contrary, the method\nallocated inside modules with libc `malloc()` is transparent to Redis.\nAnother reason to use the modules functions in order to allocate memory\nis that, when creating native data types inside modules, the RDB loading\nfunctions can return deserialized strings (from the RDB file) directly\nas `RedisModule_Alloc()` allocations, so they can be used directly to\npopulate data structures after loading, instead of having to copy them\nto the data structure.\nPool allocator\nSometimes in commands implementations, it is required to perform many\nsmall allocations that will be not retained at the end of the command\nexecution, but are just functional to execute the command itself.\nThis work can be more easily accomplished using the Redis pool allocator:\n\n\n```void *RedisModule_PoolAlloc(RedisModuleCtx *ctx, size_t bytes);\n```\n\n\nIt works similarly to `malloc()`, and returns memory aligned to the\nnext power of two of greater or equal to `bytes` (for a maximum alignment\nof 8 bytes). However it allocates memory in blocks, so it the overhead\nof the allocations is small, and more important, the memory allocated\nis automatically released when the command returns.\nSo in general short living allocations are a good candidates for the pool\nallocator.\nWriting commands compatible with Redis Cluster\nDocumentation missing, please check the following functions inside `module.c`:\n\n\n```RedisModule_IsKeysPositionRequest(ctx);\n```\n\n",
    "tag": "redis"
  },
  {
    "title": "`Maxmemory` configuration directive",
    "source": "https://github.com/redis/redis-doc/tree/master/docs/reference/eviction/index.md",
    "content": "\ntitle: Key eviction\nlinkTitle: Eviction\nweight: 6\ndescription: Overview of Redis key eviction policies (LRU, LFU, etc.)\naliases: [\n    /topics/lru_cache,\n    /topics/lru_cache.md,\n    /docs/manual/eviction\n]\n\nWhen Redis is used as a cache, it is often convenient to let it automatically\nevict old data as you add new data. This behavior is well known in the\ndeveloper community, since it is the default behavior for the popular\nmemcached system.\nThis page covers the more general topic of the Redis `maxmemory` directive used to limit the memory usage to a fixed amount. It also extensively covers the LRU eviction algorithm used by Redis, which is actually an approximation of\nthe exact LRU.\n`Maxmemory` configuration directive\nThe `maxmemory` configuration directive configures Redis\nto use a specified amount of memory for the data set. You can\nset the configuration directive using the `redis.conf` file, or later using\nthe `CONFIG SET` command at runtime.\nFor example, to configure a memory limit of 100 megabytes, you can use the\nfollowing directive inside the `redis.conf` file:\n\n\n```maxmemory 100mb\n```\n\n\nSetting `maxmemory` to zero results into no memory limits. This is the\ndefault behavior for 64 bit systems, while 32 bit systems use an implicit\nmemory limit of 3GB.\nWhen the specified amount of memory is reached, how eviction policies are configured determines the default behavior.\nRedis can return errors for commands that could result in more memory\nbeing used, or it can evict some old data to return back to the\nspecified limit every time new data is added.\nEviction policies\nThe exact behavior Redis follows when the `maxmemory` limit is reached is\nconfigured using the `maxmemory-policy` configuration directive.\nThe following policies are available:\n\nnoeviction: New values aren\u2019t saved when memory limit is reached. When a database uses replication, this applies to the primary database\nallkeys-lru: Keeps most recently used keys; removes least recently used (LRU) keys\nallkeys-lfu: Keeps frequently used keys; removes least frequently used (LFU) keys\nvolatile-lru: Removes least recently used keys with the `expire` field set to `true`.\nvolatile-lfu: Removes least frequently used keys with the `expire` field set to `true`.\nallkeys-random: Randomly removes keys to make space for the new data added.\nvolatile-random: Randomly removes keys with `expire` field set to `true`.\nvolatile-ttl: Removes keys with `expire` field set to `true` and the shortest remaining time-to-live (TTL) value.\n\nThe policies volatile-lru, volatile-lfu, volatile-random, and volatile-ttl behave like noeviction if there are no keys to evict matching the prerequisites.\nPicking the right eviction policy is important depending on the access pattern\nof your application, however you can reconfigure the policy at runtime while\nthe application is running, and monitor the number of cache misses and hits\nusing the Redis `INFO` output to tune your setup.\nIn general as a rule of thumb:\n\n\nUse the allkeys-lru policy when you expect a power-law distribution in the popularity of your requests. That is, you expect a subset of elements will be accessed far more often than the rest. This is a good pick if you are unsure.\n\n\nUse the allkeys-random if you have a cyclic access where all the keys are scanned continuously, or when you expect the distribution to be uniform.\n\n\nUse the volatile-ttl if you want to be able to provide hints to Redis about what are good candidate for expiration by using different TTL values when you create your cache objects.\n\n\nThe volatile-lru and volatile-random policies are mainly useful when you want to use a single instance for both caching and to have a set of persistent keys. However it is usually a better idea to run two Redis instances to solve such a problem.\nIt is also worth noting that setting an `expire` value to a key costs memory, so using a policy like allkeys-lru is more memory efficient since there is no need for an `expire` configuration for the key to be evicted under memory pressure.\nHow the eviction process works\nIt is important to understand that the eviction process works like this:\n\nA client runs a new command, resulting in more data added.\nRedis checks the memory usage, and if it is greater than the `maxmemory` limit , it evicts keys according to the policy.\nA new command is executed, and so forth.\n\nSo we continuously cross the boundaries of the memory limit, by going over it, and then by evicting keys to return back under the limits.\nIf a command results in a lot of memory being used (like a big set intersection stored into a new key) for some time, the memory limit can be surpassed by a noticeable amount.\nApproximated LRU algorithm\nRedis LRU algorithm is not an exact implementation. This means that Redis is\nnot able to pick the best candidate for eviction, that is, the key that\nwas accessed the furthest in the past. Instead it will try to run an approximation\nof the LRU algorithm, by sampling a small number of keys, and evicting the\none that is the best (with the oldest access time) among the sampled keys.\nHowever, since Redis 3.0 the algorithm was improved to also take a pool of good\ncandidates for eviction. This improved the performance of the algorithm, making\nit able to approximate more closely the behavior of a real LRU algorithm.\nWhat is important about the Redis LRU algorithm is that you are able to tune the precision of the algorithm by changing the number of samples to check for every eviction. This parameter is controlled by the following configuration directive:\n\n\n```maxmemory-samples 5\n```\n\n\nThe reason Redis does not use a true LRU implementation is because it\ncosts more memory. However, the approximation is virtually equivalent for an\napplication using Redis. This figure compares\nthe LRU approximation used by Redis with true LRU.\n\nThe test to generate the above graphs filled a Redis server with a given number of keys. The keys were accessed from the first to the last. The first keys are the best candidates for eviction using an LRU algorithm. Later more 50% of keys are added, in order to force half of the old keys to be evicted.\nYou can see three kind of dots in the graphs, forming three distinct bands.\n\nThe light gray band are objects that were evicted.\nThe gray band are objects that were not evicted.\nThe green band are objects that were added.\n\nIn a theoretical LRU implementation we expect that, among the old keys, the first half will be expired. The Redis LRU algorithm will instead only probabilistically expire the older keys.\nAs you can see Redis 3.0 does a better job with 5 samples compared to Redis 2.8, however most objects that are among the latest accessed are still retained by Redis 2.8. Using a sample size of 10 in Redis 3.0 the approximation is very close to the theoretical performance of Redis 3.0.\nNote that LRU is just a model to predict how likely a given key will be accessed in the future. Moreover, if your data access pattern closely\nresembles the power law, most of the accesses will be in the set of keys\nthe LRU approximated algorithm can handle well.\nIn simulations we found that using a power law access pattern, the difference between true LRU and Redis approximation were minimal or non-existent.\nHowever you can raise the sample size to 10 at the cost of some additional CPU\nusage to closely approximate true LRU, and check if this makes a\ndifference in your cache misses rate.\nTo experiment in production with different values for the sample size by using\nthe `CONFIG SET maxmemory-samples <count>` command, is very simple.\nThe new LFU mode\nStarting with Redis 4.0, the Least Frequently Used eviction mode is available. This mode may work better (provide a better\nhits/misses ratio) in certain cases. In LFU mode, Redis will try to track\nthe frequency of access of items, so the ones used rarely are evicted. This means\nthe keys used often have a higher chance of remaining in memory.\nTo configure the LFU mode, the following policies are available:\n\n`volatile-lfu` Evict using approximated LFU among the keys with an expire set.\n`allkeys-lfu` Evict any key using approximated LFU.\n\nLFU is approximated like LRU: it uses a probabilistic counter, called a Morris counter to estimate the object access frequency using just a few bits per object, combined with a decay period so that the counter is reduced over time. At some point we no longer want to consider keys as frequently accessed, even if they were in the past, so that the algorithm can adapt to a shift in the access pattern.\nThat information is sampled similarly to what happens for LRU (as explained in the previous section of this documentation) to select a candidate for eviction.\nHowever unlike LRU, LFU has certain tunable parameters: for example, how fast\nshould a frequent item lower in rank if it gets no longer accessed? It is also possible to tune the Morris counters range to better adapt the algorithm to specific use cases.\nBy default Redis is configured to:\n\nSaturate the counter at, around, one million requests.\nDecay the counter every one minute.\n\nThose should be reasonable values and were tested experimental, but the user may want to play with these configuration settings to pick optimal values.\nInstructions about how to tune these parameters can be found inside the example `redis.conf` file in the source distribution. Briefly, they are:\n`lfu-log-factor 10\nlfu-decay-time 1`\nThe decay time is the obvious one, it is the amount of minutes a counter should be decayed, when sampled and found to be older than that value. A special value of `0` means: we will never decay the counter.\nThe counter logarithm factor changes how many hits are needed to saturate the frequency counter, which is just in the range 0-255. The higher the factor, the more accesses are needed to reach the maximum. The lower the factor, the better is the resolution of the counter for low accesses, according to the following table:\n`+--------+------------+------------+------------+------------+------------+\n| factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |\n+--------+------------+------------+------------+------------+------------+\n| 0      | 104        | 255        | 255        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 1      | 18         | 49         | 255        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 10     | 10         | 18         | 142        | 255        | 255        |\n+--------+------------+------------+------------+------------+------------+\n| 100    | 8          | 11         | 49         | 143        | 255        |\n+--------+------------+------------+------------+------------+------------+`",
    "tag": "redis"
  },
  {
    "title": "acl-dryrun.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-dryrun.md",
    "content": "Simulate the execution of a given command by a given user.\nThis command can be used to test the permissions of a given user without having to enable the user or cause the side effects of running the command.\n@return\n@simple-string-reply: `OK` on success.\n@bulk-string-reply: An error describing why the user can't execute the command.\n@examples\n```\n\nACL SETUSER VIRGINIA +SET ~*\n\"OK\"\nACL DRYRUN VIRGINIA SET foo bar\n\"OK\"\nACL DRYRUN VIRGINIA GET foo bar\n\"This user has no permissions to run the 'GET' command\"\n",
    "tag": "redis"
  },
  {
    "title": "bitfield_ro.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bitfield_ro.md",
    "content": "Read-only variant of the `BITFIELD` command.\nIt is like the original `BITFIELD` but only accepts `!GET` subcommand and can safely be used in read-only replicas.\nSince the original `BITFIELD` has `!SET` and `!INCRBY` options it is technically flagged as a writing command in the Redis command table.\nFor this reason read-only replicas in a Redis Cluster will redirect it to the master instance even if the connection is in read-only mode (see the `READONLY` command of Redis Cluster).\nSince Redis 6.2, the `BITFIELD_RO` variant was introduced in order to allow `BITFIELD` behavior in read-only replicas without breaking compatibility on command flags.\nSee original `BITFIELD` for more details.\n@examples\n`BITFIELD_RO hello GET i8 16`\n@return",
    "tag": "redis"
  },
  {
    "title": "script-load.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/script-load.md",
    "content": "Load a script into the scripts cache, without executing it.\nAfter the specified command is loaded into the script cache it will be callable\nusing `EVALSHA` with the correct SHA1 digest of the script, exactly like after\nthe first successful invocation of `EVAL`.\nThe script is guaranteed to stay in the script cache forever (unless `SCRIPT\nFLUSH` is called).\nThe command works in the same way even if the script was already present in the\nscript cache.\nFor more information about `EVAL` scripts please refer to Introduction to Eval Scripts.\n@return\n@bulk-string-reply This command returns the SHA1 digest of the script added into the",
    "tag": "redis"
  },
  {
    "title": "lpush.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lpush.md",
    "content": "Insert all the specified values at the head of the list stored at `key`.\nIf `key` does not exist, it is created as empty list before performing the push\noperations.\nWhen `key` holds a value that is not a list, an error is returned.\nIt is possible to push multiple elements using a single command call just\nspecifying multiple arguments at the end of the command.\nElements are inserted one after the other to the head of the list, from the\nleftmost element to the rightmost element.\nSo for instance the command `LPUSH mylist a b c` will result into a list\ncontaining `c` as first element, `b` as second element and `a` as third element.\n@return\n@integer-reply: the length of the list after the push operations.\n@examples\n```cli\nLPUSH mylist \"world\"\nLPUSH mylist \"hello\"\nLRANGE mylist 0 -1",
    "tag": "redis"
  },
  {
    "title": "acl-load.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-load.md",
    "content": "When Redis is configured to use an ACL file (with the `aclfile` configuration\noption), this command will reload the ACLs from the file, replacing all\nthe current ACL rules with the ones defined in the file. The command makes\nsure to have an all or nothing behavior, that is:\n\nIf every line in the file is valid, all the ACLs are loaded.\nIf one or more line in the file is not valid, nothing is loaded, and the old ACL rules defined in the server memory continue to be used.\n\n@return\n@simple-string-reply: `OK` on success.\nThe command may fail with an error for several reasons: if the file is not readable, if there is an error inside the file, and in such case the error will be reported to the user in the error. Finally the command will fail if the server is not configured to use an external ACL file.\n@examples\n```\n\nACL LOAD\n+OK\nACL LOAD\n-ERR /tmp/foo:1: Unknown command or category name in ACL...\n",
    "tag": "redis"
  },
  {
    "title": "xinfo-consumers.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xinfo-consumers.md",
    "content": "This command returns the list of consumers that belong to the `<groupname>` consumer group of the stream stored at `<key>`.\nThe following information is provided for each consumer in the group:\n\nname: the consumer's name\npending: the number of pending messages for the client, which are messages that were delivered but are yet to be acknowledged\nidle: the number of milliseconds that have passed since the consumer last interacted with the server\n\n@reply\n@array-reply: a list of consumers.\n@examples\n```\n\nXINFO CONSUMERS mystream mygroup\n1) 1) name\n   2) \"Alice\"\n   3) pending\n   4) (integer) 1\n   5) idle\n   6) (integer) 9104628\n2) 1) name\n   2) \"Bob\"\n   3) pending\n   4) (integer) 1\n   5) idle\n   6) (integer) 83841983\n",
    "tag": "redis"
  },
  {
    "title": "pubsub-numpat.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pubsub-numpat.md",
    "content": "Returns the number of unique patterns that are subscribed to by clients (that are performed using the `PSUBSCRIBE` command).\nNote that this isn't the count of clients subscribed to patterns, but the total number of unique patterns all the clients are subscribed to.\nCluster note: in a Redis Cluster clients can subscribe to every node, and can also publish to every other node. The cluster will make sure that published messages are forwarded as needed. That said, `PUBSUB`'s replies in a cluster only report information from the node's Pub/Sub context, rather than the entire cluster.\n@return",
    "tag": "redis"
  },
  {
    "title": "Nested Result Array",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-slots.md",
    "content": "`CLUSTER SLOTS` returns details about which cluster slots map to which Redis instances. \nThe command is suitable to be used by Redis Cluster client libraries implementations in order to retrieve (or update when a redirection is received) the map associating cluster hash slots with actual nodes network information, so that when a command is received, it can be sent to what is likely the right instance for the keys specified in the command. \nThe networking information for each node is an array containing the following elements:\n\nPreferred endpoint (Either an IP address, hostname, or NULL)\nPort number\nThe node ID\nA map of additional networking metadata\n\nThe preferred endpoint, along with the port, defines the location that clients should use to send requests for a given slot.\nA NULL value for the endpoint indicates the node has an unknown endpoint and the client should connect to the same endpoint it used to send the `CLUSTER SLOTS` command but with the port returned from the command.\nThis unknown endpoint configuration is useful when the Redis nodes are behind a load balancer that Redis doesn't know the endpoint of.\nWhich endpoint is set as preferred is determined by the `cluster-preferred-endpoint-type` config.\nAdditional networking metadata is provided as a map on the fourth argument for each node. \nThe following networking metadata may be returned:\n\nIP: When the preferred endpoint is not set to IP.\nHostname: When a node has an announced hostname but the primary endpoint is not set to hostname.\n\nNested Result Array\nEach nested result is:\n\nStart slot range\nEnd slot range\nMaster for slot range represented as nested networking information\nFirst replica of master for slot range\nSecond replica\n...continues until all replicas for this master are returned.\n\nEach result includes all active replicas of the master instance\nfor the listed slot range.  Failed replicas are not returned.\nThe third nested reply is guaranteed to be the networking information of the master instance for the slot range.\nAll networking information after the third nested reply are replicas of the master.\nIf a cluster instance has non-contiguous slots (e.g. 1-400,900,1800-6000) then master and replica networking information results will be duplicated for each top-level slot range reply.\n@return\n@array-reply: nested list of slot ranges with networking information.\n@examples\n```\n\nCLUSTER SLOTS\n1) 1) (integer) 0\n   2) (integer) 5460\n   3) 1) \"127.0.0.1\"\n      2) (integer) 30001\n      3) \"09dbe9720cda62f7865eabc5fd8857c5d2678366\"\n      4) 1) hostname\n         2) \"host-1.redis.example.com\"\n   4) 1) \"127.0.0.1\"\n      2) (integer) 30004\n      3) \"821d8ca00d7ccf931ed3ffc7e3db0599d2271abf\"\n      4) 1) hostname\n         2) \"host-2.redis.example.com\"\n2) 1) (integer) 5461\n   2) (integer) 10922\n   3) 1) \"127.0.0.1\"\n      2) (integer) 30002\n      3) \"c9d93d9f2c0c524ff34cc11838c2003d8c29e013\"\n      4) 1) hostname\n         2) \"host-3.redis.example.com\"\n   4) 1) \"127.0.0.1\"\n      2) (integer) 30005\n      3) \"faadb3eb99009de4ab72ad6b6ed87634c7ee410f\"\n      4) 1) hostname\n         2) \"host-4.redis.example.com\"\n3) 1) (integer) 10923\n   2) (integer) 16383\n   3) 1) \"127.0.0.1\"\n      2) (integer) 30003\n      3) \"044ec91f325b7595e76dbcb18cc688b6a5b434a1\"\n      4) 1) hostname\n         2) \"host-5.redis.example.com\"\n   4) 1) \"127.0.0.1\"\n      2) (integer) 30006\n      3) \"58e6e48d41228013e5d9c1c37c5060693925e97e\"\n      4) 1) hostname\n         2) \"host-6.redis.example.com\"\n```\n\nWarning: In future versions there could be more elements describing the node better.\nIn general a client implementation should just rely on the fact that certain parameters are at fixed positions as specified, but more parameters may follow and should be ignored.\nSimilarly a client library should try if possible to cope with the fact that older versions may just have the primary endpoint and port parameter.\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "client-unblock.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-unblock.md",
    "content": "This command can unblock, from a different connection, a client blocked in a blocking operation, such as for instance `BRPOP` or `XREAD` or `WAIT`.\nBy default the client is unblocked as if the timeout of the command was\nreached, however if an additional (and optional) argument is passed, it is possible to specify the unblocking behavior, that can be TIMEOUT (the default) or ERROR. If ERROR is specified, the behavior is to unblock the client returning as error the fact that the client was force-unblocked. Specifically the client will receive the following error:\n\n\n```-UNBLOCKED client unblocked via CLIENT UNBLOCK\n```\n\n\nNote: of course as usually it is not guaranteed that the error text remains\nthe same, however the error code will remain `-UNBLOCKED`.\nThis command is useful especially when we are monitoring many keys with\na limited number of connections. For instance we may want to monitor multiple\nstreams with `XREAD` without using more than N connections. However at some\npoint the consumer process is informed that there is one more stream key\nto monitor. In order to avoid using more connections, the best behavior would\nbe to stop the blocking command from one of the connections in the pool, add\nthe new key, and issue the blocking command again.\nTo obtain this behavior the following pattern is used. The process uses\nan additional control connection in order to send the `CLIENT UNBLOCK` command\nif needed. In the meantime, before running the blocking operation on the other\nconnections, the process runs `CLIENT ID` in order to get the ID associated\nwith that connection. When a new key should be added, or when a key should\nno longer be monitored, the relevant connection blocking command is aborted\nby sending `CLIENT UNBLOCK` in the control connection. The blocking command\nwill return and can be finally reissued.\nThis example shows the application in the context of Redis streams, however\nthe pattern is a general one and can be applied to other cases.\n@examples\n```\nConnection A (blocking connection):\n\nCLIENT ID\n2934\nBRPOP key1 key2 key3 0\n(client is blocked)\n\n... Now we want to add a new key ...\nConnection B (control connection):\n\nCLIENT UNBLOCK 2934\n1\n\nConnection A (blocking connection):\n... BRPOP reply with timeout ...\nNULL\n\nBRPOP key1 key2 key3 key4 0\n(client is blocked again)\n```\n\n@return\n@integer-reply, specifically:\n\n`1` if the client was unblocked successfully.\n",
    "tag": "redis"
  },
  {
    "title": "sinter.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/sinter.md",
    "content": "Returns the members of the set resulting from the intersection of all the given\nsets.\nFor example:\n`key1 = {a,b,c,d}\nkey2 = {c}\nkey3 = {a,c,e}\nSINTER key1 key2 key3 = {c}`\nKeys that do not exist are considered to be empty sets.\nWith one of the keys being an empty set, the resulting set is also empty (since\nset intersection with an empty set always results in an empty set).\n@return\n@array-reply: list with members of the resulting set.\n@examples\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSINTER key1 key2",
    "tag": "redis"
  },
  {
    "title": "zrevrangebyscore.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrevrangebyscore.md",
    "content": "Returns all the elements in the sorted set at `key` with a score between `max`\nand `min` (including elements with score equal to `max` or `min`).\nIn contrary to the default ordering of sorted sets, for this command the\nelements are considered to be ordered from high to low scores.\nThe elements having the same score are returned in reverse lexicographical\norder.\nApart from the reversed ordering, `ZREVRANGEBYSCORE` is similar to\n`ZRANGEBYSCORE`.\n@return\n@array-reply: list of elements in the specified score range (optionally\nwith their scores).\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREVRANGEBYSCORE myzset +inf -inf\nZREVRANGEBYSCORE myzset 2 1\nZREVRANGEBYSCORE myzset 2 (1\nZREVRANGEBYSCORE myzset (2 (1",
    "tag": "redis"
  },
  {
    "title": "client-tracking.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-tracking.md",
    "content": "This command enables the tracking feature of the Redis server, that is used\nfor server assisted client side caching.\nWhen tracking is enabled Redis remembers the keys that the connection\nrequested, in order to send later invalidation messages when such keys are\nmodified. Invalidation messages are sent in the same connection (only available\nwhen the RESP3 protocol is used) or redirected in a different connection\n(available also with RESP2 and Pub/Sub). A special broadcasting mode is\navailable where clients participating in this protocol receive every\nnotification just subscribing to given key prefixes, regardless of the\nkeys that they requested. Given the complexity of the argument please\nrefer to the main client side caching documentation for the details. This manual page is only a reference for the options of this subcommand.\nIn order to enable tracking, use:\n\n\n```CLIENT TRACKING on ... options ...\n```\n\n\nThe feature will remain active in the current connection for all its life,\nunless tracking is turned off with `CLIENT TRACKING off` at some point.\nThe following are the list of options that modify the behavior of the\ncommand when enabling tracking:\n\n`REDIRECT <id>`: send invalidation messages to the connection with the specified ID. The connection must exist. You can get the ID of a connection using `CLIENT ID`. If the connection we are redirecting to is terminated, when in RESP3 mode the connection with tracking enabled will receive `tracking-redir-broken` push messages in order to signal the condition.\n`BCAST`: enable tracking in broadcasting mode. In this mode invalidation messages are reported for all the prefixes specified, regardless of the keys requested by the connection. Instead when the broadcasting mode is not enabled, Redis will track which keys are fetched using read-only commands, and will report invalidation messages only for such keys.\n`PREFIX <prefix>`: for broadcasting, register a given key prefix, so that notifications will be provided only for keys starting with this string. This option can be given multiple times to register multiple prefixes. If broadcasting is enabled without this option, Redis will send notifications for every key. You can't delete a single prefix, but you can delete all prefixes by disabling and re-enabling tracking. Using this option adds the additional time complexity of O(N^2), where N is the total number of prefixes tracked. \n`OPTIN`: when broadcasting is NOT active, normally don't track keys in read only commands, unless they are called immediately after a `CLIENT CACHING yes` command.\n`OPTOUT`: when broadcasting is NOT active, normally track keys in read only commands, unless they are called immediately after a `CLIENT CACHING no` command.\n`NOLOOP`: don't send notifications about keys modified by this connection itself.\n\n@return",
    "tag": "redis"
  },
  {
    "title": "Non-blocking usage",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xread.md",
    "content": "Read data from one or multiple streams, only returning entries with an\nID greater than the last received ID reported by the caller.\nThis command has an option to block if items are not available, in a similar\nfashion to `BRPOP` or `BZPOPMIN` and others.\nPlease note that before reading this page, if you are new to streams,\nwe recommend to read our introduction to Redis Streams.\nNon-blocking usage\nIf the BLOCK option is not used, the command is synchronous, and can\nbe considered somewhat related to `XRANGE`: it will return a range of items\ninside streams, however it has two fundamental differences compared to `XRANGE`\neven if we just consider the synchronous usage:\n\nThis command can be called with multiple streams if we want to read at\n  the same time from a number of keys. This is a key feature of `XREAD` because\n  especially when blocking with BLOCK, to be able to listen with a single\n  connection to multiple keys is a vital feature.\nWhile `XRANGE` returns items in a range of IDs, `XREAD` is more suited in\n  order to consume the stream starting from the first entry which is greater\n  than any other entry we saw so far. So what we pass to `XREAD` is, for each\n  stream, the ID of the last element that we received from that stream.\n\nFor example, if I have two streams `mystream` and `writers`, and I want to\nread data from both the streams starting from the first element they contain,\nI could call `XREAD` like in the following example.\nNote: we use the COUNT option in the example, so that for each stream\nthe call will return at maximum two elements per stream.\n```\n\nXREAD COUNT 2 STREAMS mystream writers 0-0 0-0\n1) 1) \"mystream\"\n   2) 1) 1) 1526984818136-0\n         2) 1) \"duration\"\n            2) \"1532\"\n            3) \"event-id\"\n            4) \"5\"\n            5) \"user-id\"\n            6) \"7782813\"\n      2) 1) 1526999352406-0\n         2) 1) \"duration\"\n            2) \"812\"\n            3) \"event-id\"\n            4) \"9\"\n            5) \"user-id\"\n            6) \"388234\"\n2) 1) \"writers\"\n   2) 1) 1) 1526985676425-0\n         2) 1) \"name\"\n            2) \"Virginia\"\n            3) \"surname\"\n            4) \"Woolf\"\n      2) 1) 1526985685298-0\n         2) 1) \"name\"\n            2) \"Jane\"\n            3) \"surname\"\n            4) \"Austen\"\n```\n\nThe STREAMS option is mandatory and MUST be the final option because\nsuch option gets a variable length of argument in the following format:\n\n\n```STREAMS key_1 key_2 key_3 ... key_N ID_1 ID_2 ID_3 ... ID_N\n```\n\n\nSo we start with a list of keys, and later continue with all the associated\nIDs, representing the last ID we received for that stream, so that the\ncall will serve us only greater IDs from the same stream.\nFor instance in the above example, the last items that we received\nfor the stream `mystream` has ID `1526999352406-0`, while for the\nstream `writers` has the ID `1526985685298-0`.\nTo continue iterating the two streams I'll call:\n```\n\nXREAD COUNT 2 STREAMS mystream writers 1526999352406-0 1526985685298-0\n1) 1) \"mystream\"\n   2) 1) 1) 1526999626221-0\n         2) 1) \"duration\"\n            2) \"911\"\n            3) \"event-id\"\n            4) \"7\"\n            5) \"user-id\"\n            6) \"9488232\"\n2) 1) \"writers\"\n   2) 1) 1) 1526985691746-0\n         2) 1) \"name\"\n            2) \"Toni\"\n            3) \"surname\"\n            4) \"Morrison\"\n      2) 1) 1526985712947-0\n         2) 1) \"name\"\n            2) \"Agatha\"\n            3) \"surname\"\n            4) \"Christie\"\n```\n\nAnd so forth. Eventually, the call will not return any item, but just an\nempty array, then we know that there is nothing more to fetch from our\nstream (and we would have to retry the operation, hence this command\nalso supports a blocking mode).\nIncomplete IDs\nTo use incomplete IDs is valid, like it is valid for `XRANGE`. However\nhere the sequence part of the ID, if missing, is always interpreted as\nzero, so the command:\n```\n\nXREAD COUNT 2 STREAMS mystream writers 0 0\n```\n\nis exactly equivalent to\n```\n\nXREAD COUNT 2 STREAMS mystream writers 0-0 0-0\n```\n\nBlocking for data\nIn its synchronous form, the command can get new data as long as there\nare more items available. However, at some point, we'll have to wait for\nproducers of data to use `XADD` to push new entries inside the streams\nwe are consuming. In order to avoid polling at a fixed or adaptive interval\nthe command is able to block if it could not return any data, according\nto the specified streams and IDs, and automatically unblock once one of\nthe requested keys accept data.\nIt is important to understand that this command fans out to all the\nclients that are waiting for the same range of IDs, so every consumer will\nget a copy of the data, unlike to what happens when blocking list pop\noperations are used.\nIn order to block, the BLOCK option is used, together with the number\nof milliseconds we want to block before timing out. Normally Redis blocking\ncommands take timeouts in seconds, however this command takes a millisecond\ntimeout, even if normally the server will have a timeout resolution near\nto 0.1 seconds. This time it is possible to block for a shorter time in\ncertain use cases, and if the server internals will improve over time, it is\npossible that the resolution of timeouts will improve.\nWhen the BLOCK command is passed, but there is data to return at\nleast in one of the streams passed, the command is executed synchronously\nexactly like if the BLOCK option would be missing.\nThis is an example of blocking invocation, where the command later returns\na null reply because the timeout has elapsed without new data arriving:\n```\n\nXREAD BLOCK 1000 STREAMS mystream 1526999626221-0\n(nil)\n```\n\nThe special `$` ID.\nWhen blocking sometimes we want to receive just entries that are added\nto the stream via `XADD` starting from the moment we block. In such a case\nwe are not interested in the history of already added entries. For\nthis use case, we would have to check the stream top element ID, and use\nsuch ID in the `XREAD` command line. This is not clean and requires to\ncall other commands, so instead it is possible to use the special `$`\nID to signal the stream that we want only the new things.\nIt is very important to understand that you should use the `$`\nID only for the first call to `XREAD`. Later the ID should be the one\nof the last reported item in the stream, otherwise you could miss all\nthe entries that are added in between.\nThis is how a typical `XREAD` call looks like in the first iteration\nof a consumer willing to consume only new entries:\n```\n\nXREAD BLOCK 5000 COUNT 100 STREAMS mystream $\n```\n\nOnce we get some replies, the next call will be something like:\n```\n\nXREAD BLOCK 5000 COUNT 100 STREAMS mystream 1526999644174-3\n```\n\nAnd so forth.\nHow multiple clients blocked on a single stream are served\nBlocking list operations on lists or sorted sets have a pop behavior.\nBasically, the element is removed from the list or sorted set in order\nto be returned to the client. In this scenario you want the items\nto be consumed in a fair way, depending on the moment clients blocked\non a given key arrived. Normally Redis uses the FIFO semantics in this\nuse cases.\nHowever note that with streams this is not a problem: stream entries\nare not removed from the stream when clients are served, so every\nclient waiting will be served as soon as an `XADD` command provides\ndata to the stream.\n@return\n@array-reply, specifically:\nThe command returns an array of results: each element of the returned\narray is an array composed of a two element containing the key name and\nthe entries reported for that key. The entries reported are full stream\nentries, having IDs and the list of all the fields and values. Field and\nvalues are guaranteed to be reported in the same order they were added\nby `XADD`.\nWhen BLOCK is used, on timeout a null reply is returned.\nReading the Redis Streams introduction is highly\nsuggested in order to understand more about the streams overall behavior",
    "tag": "redis"
  },
  {
    "title": "cluster-replicas.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-replicas.md",
    "content": "The command provides a list of replica nodes replicating from the specified\nmaster node. The list is provided in the same format used by `CLUSTER NODES` (please refer to its documentation for the specification of the format).\nThe command will fail if the specified node is not known or if it is not\na master according to the node table of the node receiving the command.\nNote that if a replica is added, moved, or removed from a given master node,\nand we ask `CLUSTER REPLICAS` to a node that has not yet received the\nconfiguration update, it may show stale information. However eventually\n(in a matter of seconds if there are no network partitions) all the nodes\nwill agree about the set of nodes associated with a given master.\n@return",
    "tag": "redis"
  },
  {
    "title": "cluster-replicate.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-replicate.md",
    "content": "The command reconfigures a node as a replica of the specified master.\nIf the node receiving the command is an empty master, as a side effect\nof the command, the node role is changed from master to replica.\nOnce a node is turned into the replica of another master node, there is no need\nto inform the other cluster nodes about the change: heartbeat packets exchanged\nbetween nodes will propagate the new configuration automatically.\nA replica will always accept the command, assuming that:\n\nThe specified node ID exists in its nodes table.\nThe specified node ID does not identify the instance we are sending the command to.\nThe specified node ID is a master.\n\nIf the node receiving the command is not already a replica, but is a master,\nthe command will only succeed, and the node will be converted into a replica,\nonly if the following additional conditions are met:\n\nThe node is not serving any hash slots.\nThe node is empty, no keys are stored at all in the key space.\n\nIf the command succeeds the new replica will immediately try to contact its master in order to replicate from it.\n@return",
    "tag": "redis"
  },
  {
    "title": "geopos.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/geopos.md",
    "content": "Return the positions (longitude,latitude) of all the specified members of the geospatial index represented by the sorted set at key.\nGiven a sorted set representing a geospatial index, populated using the `GEOADD` command, it is often useful to obtain back the coordinates of specified members. When the geospatial index is populated via `GEOADD` the coordinates are converted into a 52 bit geohash, so the coordinates returned may not be exactly the ones used in order to add the elements, but small errors may be introduced.\nThe command can accept a variable number of arguments so it always returns an array of positions even when a single element is specified.\n@return\n@array-reply, specifically:\nThe command returns an array where each element is a two elements array\nrepresenting longitude and latitude (x,y) of each member name passed as\nargument to the command.\nNon existing elements are reported as NULL elements of the array.\n@examples\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEOPOS Sicily Palermo Catania NonExisting",
    "tag": "redis"
  },
  {
    "title": "geohash.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/geohash.md",
    "content": "Return valid Geohash strings representing the position of one or more elements in a sorted set value representing a geospatial index (where elements were added using `GEOADD`).\nNormally Redis represents positions of elements using a variation of the Geohash\ntechnique where positions are encoded using 52 bit integers. The encoding is\nalso different compared to the standard because the initial min and max\ncoordinates used during the encoding and decoding process are different. This\ncommand however returns a standard Geohash in the form of a string as\ndescribed in the Wikipedia article and compatible with the geohash.org web site.\nGeohash string properties\nThe command returns 11 characters Geohash strings, so no precision is lost\ncompared to the Redis internal 52 bit representation. The returned Geohashes\nhave the following properties:\n\nThey can be shortened removing characters from the right. It will lose precision but will still point to the same area.\nIt is possible to use them in `geohash.org` URLs such as `http://geohash.org/<geohash-string>`. This is an example of such URL.\nStrings with a similar prefix are nearby, but the contrary is not true, it is possible that strings with different prefixes are nearby too.\n\n@return\n@array-reply, specifically:\nThe command returns an array where each element is the Geohash corresponding to\neach member name passed as argument to the command.\n@examples\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEOHASH Sicily Palermo Catania",
    "tag": "redis"
  },
  {
    "title": "module-loadex.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/module-loadex.md",
    "content": "Loads a module from a dynamic library at runtime with configuration directives.\nThis is an extended version of the `MODULE LOAD` command.\nIt loads and initializes the Redis module from the dynamic library specified by the `path` argument. The `path` should be the absolute path of the library, including the full filename.\nYou can use the optional `!CONFIG` argument to provide the module with configuration directives.\nAny additional arguments that follow the `ARGS` keyword are passed unmodified to the module.\nNote: modules can also be loaded at server startup with `loadmodule`\nconfiguration directive in `redis.conf`.\n@return",
    "tag": "redis"
  },
  {
    "title": "ACL rules",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-setuser.md",
    "content": "Create an ACL user with the specified rules or modify the rules of an\nexisting user. \nManipulate Redis ACL users interactively.\nIf the username does not exist, the command creates the username without any privilege.\nIt then reads from left to right all the rules provided as successive arguments, setting the user ACL rules as specified.\nIf the user already exists, the provided ACL rules are simply applied\nin addition to the rules already set. For example:\n\n\n```ACL SETUSER virginia on allkeys +set\n```\n\n\nThe above command creates a user called `virginia` who is active(the on rule), can access any key (allkeys rule), and can call the set command (+set rule).\nThen, you can use another `ACL SETUSER` call to modify the user rules:\n\n\n```ACL SETUSER virginia +get\n```\n\n\nThe above rule applies the new rule to the user `virginia`, so other than `SET`, the user `virginia` can now also use the `GET` command.\nStarting from Redis 7.0, ACL rules can also be grouped into multiple distinct sets of rules, called selectors.\nSelectors are added by wrapping the rules in parentheses and providing them just like any other rule.\nIn order to execute a command, either the root permissions (rules defined outside of parenthesis) or any of the selectors (rules defined inside parenthesis) must match the given command.\nFor example:\n\n\n```ACL SETUSER virginia on +GET allkeys (+SET ~app1*)\n```\n\n\nThis sets a user with two sets of permissions, one defined on the user and one defined with a selector.\nThe root user permissions only allow executing the get command, but can be executed on any keys.\nThe selector then grants a secondary set of permissions: access to the `SET` command to be executed on any key that starts with `app1`.\nUsing multiple selectors allows you to grant permissions that are different depending on what keys are being accessed.\nWhen we want to be sure to define a user from scratch, without caring if\nit had previously defined rules associated, we can use the special rule\n`reset` as first rule, in order to flush all the other existing rules:\n\n\n```ACL SETUSER antirez reset [... other rules ...]\n```\n\n\nAfter resetting a user, its ACL rules revert to the default: inactive, passwordless, can't execute any command nor access any key or channel:\n\n\n```> ACL SETUSER antirez reset\n+OK\n> ACL LIST\n1) \"user antirez off -@all\"\n```\n\n\nACL rules are either words like \"on\", \"off\", \"reset\", \"allkeys\", or are\nspecial rules that start with a special character, and are followed by\nanother string (without any space in between), like \"+SET\".\nThe following documentation is a reference manual about the capabilities of this command, however our ACL tutorial may be a more gentle introduction to how the ACL system works in general.\nACL rules\nRedis ACL rules are split into two categories: rules that define command permissions or command rules, and rules that define the user state or user management rules.\nThis is a list of all the supported Redis ACL rules:\nCommand rules\n\n`~<pattern>`: Adds the specified key pattern (glob style pattern, like in the `KEYS` command), to the list of key patterns accessible by the user. This grants both read and write permissions to keys that match the pattern. You can add multiple key patterns to the same user. Example: `~objects:*`\n`%R~<pattern>`: (Available in Redis 7.0 and later) Adds the specified read key pattern. This behaves similar to the regular key pattern but only grants permission to read from keys that match the given pattern. See key permissions for more information.\n`%W~<pattern>`: (Available in Redis 7.0 and later) Adds the specified write key pattern. This behaves similar to the regular key pattern but only grants permission to write to keys that match the given pattern. See key permissions for more information.\n`%RW~<pattern>`: (Available in Redis 7.0 and later) Alias for `~<pattern>`.\n`allkeys`: Alias for `~*`, it allows the user to access all the keys.\n`resetkeys`: Removes all the key patterns from the list of key patterns the user can access.\n`&<pattern>`: (Available in Redis 6.2 and later) Adds the specified glob style pattern to the list of Pub/Sub channel patterns accessible by the user. You can add multiple channel patterns to the same user. Example: `&chatroom:*`\n`allchannels`: Alias for `&*`, it allows the user to access all Pub/Sub channels.\n`resetchannels`: Removes all channel patterns from the list of Pub/Sub channel patterns the user can access.\n`+<command>`: Adds the command to the list of commands the user can call. Can be used with `|` for allowing subcommands (e.g \"+config|get\").\n`+@<category>`: Adds all the commands in the specified category to the list of commands the user is able to execute. Example: `+@string` (adds all the string commands). For a list of categories, check the `ACL CAT` command.\n`+<command>|first-arg`: Allows a specific first argument of an otherwise disabled command. It is only supported on commands with no sub-commands, and is not allowed as negative form like -SELECT|1, only additive starting with \"+\". This feature is deprecated and may be removed in the future.\n`allcommands`: Alias of `+@all`. Adds all the commands there are in the server, including future commands loaded via module, to be executed by this user.\n`-<command>`: Remove the command to the list of commands the user can call. Starting Redis 7.0, it can be used with `|` for blocking subcommands (e.g., \"-config|set\").\n`-@<category>`: Like `+@<category>` but removes all the commands in the category instead of adding them.\n`nocommands`: Alias for `-@all`. Removes all the commands, and the user is no longer able to execute anything.\n\nUser management rules\n\n`on`: Set the user as active, it will be possible to authenticate as this user using `AUTH <username> <password>`.\n`off`: Set user as not active, it will be impossible to log as this user. Please note that if a user gets disabled (set to off) after there are connections already authenticated with such a user, the connections will continue to work as expected. To also kill the old connections you can use `CLIENT KILL` with the user option. An alternative is to delete the user with `ACL DELUSER`, that will result in all the connections authenticated as the deleted user to be disconnected.\n`nopass`: The user is set as a no password user. It means that it will be possible to authenticate as such user with any password. By default, the `default` special user is set as \"nopass\". The `nopass` rule will also reset all the configured passwords for the user.\n`>password`: Adds the specified clear text password as a hashed password in the list of the users passwords. Every user can have many active passwords, so that password rotation will be simpler. The specified password is not stored as clear text inside the server. Example: `>mypassword`.\n`#<hashedpassword>`: Adds the specified hashed password to the list of user passwords. A Redis hashed password is hashed with SHA256 and translated into a hexadecimal string. Example: `#c3ab8ff13720e8ad9047dd39466b3c8974e592c2fa383d4a3960714caef0c4f2`.\n`<password`: Like `>password` but removes the password instead of adding it.\n`!<hashedpassword>`: Like `#<hashedpassword>` but removes the password instead of adding it.\n`(<rule list>)`: (Available in Redis 7.0 and later) Creates a new selector to match rules against. Selectors are evaluated after the user permissions, and are evaluated according to the order they are defined. If a command matches either the user permissions or any selector, it is allowed. See selectors for more information.\n`clearselectors`: (Available in Redis 7.0 and later) Deletes all of the selectors attached to the user.\n`reset`: Removes any capability from the user. They are set to off, without passwords, unable to execute any command, unable to access any key.\n\n@return\n@simple-string-reply: `OK` on success.\nIf the rules contain errors, the error is returned.\n@examples\n```\n\nACL SETUSER alan allkeys +@string +@set -SADD >alanpassword\n+OK\nACL SETUSER antirez heeyyyy\n(error) ERR Error in ACL SETUSER modifier 'heeyyyy': Syntax error\n",
    "tag": "redis"
  },
  {
    "title": "lolwut.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lolwut.md",
    "content": "The LOLWUT command displays the Redis version: however as a side effect of\ndoing so, it also creates a piece of generative computer art that is different\nwith each version of Redis. The command was introduced in Redis 5 and announced\nwith this blog post.\nBy default the `LOLWUT` command will display the piece corresponding to the\ncurrent Redis version, however it is possible to display a specific version\nusing the following form:\n\n\n```LOLWUT VERSION 5 ... other optional arguments ...\n```\n\n\nOf course the \"5\" above is an example. Each LOLWUT version takes a different\nset of arguments in order to change the output. The user is encouraged to\nplay with it to discover how the output changes adding more numerical\narguments.\nLOLWUT wants to be a reminder that there is more in programming than just\nputting some code together in order to create something useful. Every\nLOLWUT version should have the following properties:\n\nIt should display some computer art. There are no limits as long as the output works well in a normal terminal display. However the output should not be limited to graphics (like LOLWUT 5 and 6 actually do), but can be generative poetry and other non graphical things.\nLOLWUT output should be completely useless. Displaying some useful Redis internal metrics does not count as a valid LOLWUT.\nLOLWUT output should be fast to generate so that the command can be called in production instances without issues. It should remain fast even when the user experiments with odd parameters.\nLOLWUT implementations should be safe and carefully checked for security, and resist to untrusted inputs if they take arguments.\nLOLWUT must always display the Redis version at the end.\n\n@return",
    "tag": "redis"
  },
  {
    "title": "SCAN basic usage",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/scan.md",
    "content": "The `SCAN` command and the closely related commands `SSCAN`, `HSCAN` and `ZSCAN` are used in order to incrementally iterate over a collection of elements.\n\n`SCAN` iterates the set of keys in the currently selected Redis database.\n`SSCAN` iterates elements of Sets types.\n`HSCAN` iterates fields of Hash types and their associated values.\n`ZSCAN` iterates elements of Sorted Set types and their associated scores.\n\nSince these commands allow for incremental iteration, returning only a small number of elements per call, they can be used in production without the downside of commands like `KEYS` or `SMEMBERS` that may block the server for a long time (even several seconds) when called against big collections of keys or elements.\nHowever while blocking commands like `SMEMBERS` are able to provide all the elements that are part of a Set in a given moment, The SCAN family of commands only offer limited guarantees about the returned elements since the collection that we incrementally iterate can change during the iteration process.\nNote that `SCAN`, `SSCAN`, `HSCAN` and `ZSCAN` all work very similarly, so this documentation covers all the four commands. However an obvious difference is that in the case of `SSCAN`, `HSCAN` and `ZSCAN` the first argument is the name of the key holding the Set, Hash or Sorted Set value. The `SCAN` command does not need any key name argument as it iterates keys in the current database, so the iterated object is the database itself.\nSCAN basic usage\nSCAN is a cursor based iterator. This means that at every call of the command, the server returns an updated cursor that the user needs to use as the cursor argument in the next call.\nAn iteration starts when the cursor is set to 0, and terminates when the cursor returned by the server is 0. The following is an example of SCAN iteration:\n`redis 127.0.0.1:6379> scan 0\n1) \"17\"\n2)  1) \"key:12\"\n    2) \"key:8\"\n    3) \"key:4\"\n    4) \"key:14\"\n    5) \"key:16\"\n    6) \"key:17\"\n    7) \"key:15\"\n    8) \"key:10\"\n    9) \"key:3\"\n   10) \"key:7\"\n   11) \"key:1\"\nredis 127.0.0.1:6379> scan 17\n1) \"0\"\n2) 1) \"key:5\"\n   2) \"key:18\"\n   3) \"key:0\"\n   4) \"key:2\"\n   5) \"key:19\"\n   6) \"key:13\"\n   7) \"key:6\"\n   8) \"key:9\"\n   9) \"key:11\"`\nIn the example above, the first call uses zero as a cursor, to start the iteration. The second call uses the cursor returned by the previous call as the first element of the reply, that is, 17.\nAs you can see the SCAN return value is an array of two values: the first value is the new cursor to use in the next call, the second value is an array of elements.\nSince in the second call the returned cursor is 0, the server signaled to the caller that the iteration finished, and the collection was completely explored. Starting an iteration with a cursor value of 0, and calling `SCAN` until the returned cursor is 0 again is called a full iteration.\nScan guarantees\nThe `SCAN` command, and the other commands in the `SCAN` family, are able to provide to the user a set of guarantees associated to full iterations.\n\nA full iteration always retrieves all the elements that were present in the collection from the start to the end of a full iteration. This means that if a given element is inside the collection when an iteration is started, and is still there when an iteration terminates, then at some point `SCAN` returned it to the user.\nA full iteration never returns any element that was NOT present in the collection from the start to the end of a full iteration. So if an element was removed before the start of an iteration, and is never added back to the collection for all the time an iteration lasts, `SCAN` ensures that this element will never be returned.\n\nHowever because `SCAN` has very little state associated (just the cursor) it has the following drawbacks:\n\nA given element may be returned multiple times. It is up to the application to handle the case of duplicated elements, for example only using the returned elements in order to perform operations that are safe when re-applied multiple times.\nElements that were not constantly present in the collection during a full iteration, may be returned or not: it is undefined.\n\nNumber of elements returned at every SCAN call\n`SCAN` family functions do not guarantee that the number of elements returned per call are in a given range. The commands are also allowed to return zero elements, and the client should not consider the iteration complete as long as the returned cursor is not zero.\nHowever the number of returned elements is reasonable, that is, in practical terms SCAN may return a maximum number of elements in the order of a few tens of elements when iterating a large collection, or may return all the elements of the collection in a single call when the iterated collection is small enough to be internally represented as an encoded data structure (this happens for small sets, hashes and sorted sets).\nHowever there is a way for the user to tune the order of magnitude of the number of returned elements per call using the COUNT option.\nThe COUNT option\nWhile `SCAN` does not provide guarantees about the number of elements returned at every iteration, it is possible to empirically adjust the behavior of `SCAN` using the COUNT option. Basically with COUNT the user specified the amount of work that should be done at every call in order to retrieve elements from the collection. This is just a hint for the implementation, however generally speaking this is what you could expect most of the times from the implementation.\n\nThe default COUNT value is 10.\nWhen iterating the key space, or a Set, Hash or Sorted Set that is big enough to be represented by a hash table, assuming no MATCH option is used, the server will usually return count or a bit more than count elements per call. Please check the why SCAN may return all the elements at once section later in this document.\nWhen iterating Sets encoded as intsets (small sets composed of just integers), or Hashes and Sorted Sets encoded as ziplists (small hashes and sets composed of small individual values), usually all the elements are returned in the first `SCAN` call regardless of the COUNT value.\n\nImportant: there is no need to use the same COUNT value for every iteration. The caller is free to change the count from one iteration to the other as required, as long as the cursor passed in the next call is the one obtained in the previous call to the command.\nThe MATCH option\nIt is possible to only iterate elements matching a given glob-style pattern, similarly to the behavior of the `KEYS` command that takes a pattern as its only argument.\nTo do so, just append the `MATCH <pattern>` arguments at the end of the `SCAN` command (it works with all the SCAN family commands).\nThis is an example of iteration using MATCH:\n`redis 127.0.0.1:6379> sadd myset 1 2 3 foo foobar feelsgood\n(integer) 6\nredis 127.0.0.1:6379> sscan myset 0 match f*\n1) \"0\"\n2) 1) \"foo\"\n   2) \"feelsgood\"\n   3) \"foobar\"\nredis 127.0.0.1:6379>`\nIt is important to note that the MATCH filter is applied after elements are retrieved from the collection, just before returning data to the client. This means that if the pattern matches very little elements inside the collection, `SCAN` will likely return no elements in most iterations. An example is shown below:\n`redis 127.0.0.1:6379> scan 0 MATCH *11*\n1) \"288\"\n2) 1) \"key:911\"\nredis 127.0.0.1:6379> scan 288 MATCH *11*\n1) \"224\"\n2) (empty list or set)\nredis 127.0.0.1:6379> scan 224 MATCH *11*\n1) \"80\"\n2) (empty list or set)\nredis 127.0.0.1:6379> scan 80 MATCH *11*\n1) \"176\"\n2) (empty list or set)\nredis 127.0.0.1:6379> scan 176 MATCH *11* COUNT 1000\n1) \"0\"\n2)  1) \"key:611\"\n    2) \"key:711\"\n    3) \"key:118\"\n    4) \"key:117\"\n    5) \"key:311\"\n    6) \"key:112\"\n    7) \"key:111\"\n    8) \"key:110\"\n    9) \"key:113\"\n   10) \"key:211\"\n   11) \"key:411\"\n   12) \"key:115\"\n   13) \"key:116\"\n   14) \"key:114\"\n   15) \"key:119\"\n   16) \"key:811\"\n   17) \"key:511\"\n   18) \"key:11\"\nredis 127.0.0.1:6379>`\nAs you can see most of the calls returned zero elements, but the last call where a COUNT of 1000 was used in order to force the command to do more scanning for that iteration.\nThe TYPE option\nYou can use the `!TYPE` option to ask `SCAN` to only return objects that match a given `type`, allowing you to iterate through the database looking for keys of a specific type. The TYPE option is only available on the whole-database `SCAN`, not `HSCAN` or `ZSCAN` etc.\nThe `type` argument is the same string name that the `TYPE` command returns. Note a quirk where some Redis types, such as GeoHashes, HyperLogLogs, Bitmaps, and Bitfields, may internally be implemented using other Redis types, such as a string or zset, so can't be distinguished from other keys of that same type by `SCAN`. For example, a ZSET and GEOHASH:\n`redis 127.0.0.1:6379> GEOADD geokey 0 0 value\n(integer) 1\nredis 127.0.0.1:6379> ZADD zkey 1000 value\n(integer) 1\nredis 127.0.0.1:6379> TYPE geokey\nzset\nredis 127.0.0.1:6379> TYPE zkey\nzset\nredis 127.0.0.1:6379> SCAN 0 TYPE zset\n1) \"0\"\n2) 1) \"geokey\"\n   2) \"zkey\"`\nIt is important to note that the TYPE filter is also applied after elements are retrieved from the database, so the option does not reduce the amount of work the server has to do to complete a full iteration, and for rare types you may receive no elements in many iterations.\nMultiple parallel iterations\nIt is possible for an infinite number of clients to iterate the same collection at the same time, as the full state of the iterator is in the cursor, that is obtained and returned to the client at every call. No server side state is taken at all.\nTerminating iterations in the middle\nSince there is no state server side, but the full state is captured by the cursor, the caller is free to terminate an iteration half-way without signaling this to the server in any way. An infinite number of iterations can be started and never terminated without any issue.\nCalling SCAN with a corrupted cursor\nCalling `SCAN` with a broken, negative, out of range, or otherwise invalid cursor, will result in undefined behavior but never in a crash. What will be undefined is that the guarantees about the returned elements can no longer be ensured by the `SCAN` implementation.\nThe only valid cursors to use are:\n\nThe cursor value of 0 when starting an iteration.\nThe cursor returned by the previous call to SCAN in order to continue the iteration.\n\nGuarantee of termination\nThe `SCAN` algorithm is guaranteed to terminate only if the size of the iterated collection remains bounded to a given maximum size, otherwise iterating a collection that always grows may result into `SCAN` to never terminate a full iteration.\nThis is easy to see intuitively: if the collection grows there is more and more work to do in order to visit all the possible elements, and the ability to terminate the iteration depends on the number of calls to `SCAN` and its COUNT option value compared with the rate at which the collection grows.\nWhy SCAN may return all the items of an aggregate data type in a single call?\nIn the `COUNT` option documentation, we state that sometimes this family of commands may return all the elements of a Set, Hash or Sorted Set at once in a single call, regardless of the `COUNT` option value. The reason why this happens is that the cursor-based iterator can be implemented, and is useful, only when the aggregate data type that we are scanning is represented as a hash table. However Redis uses a memory optimization where small aggregate data types, until they reach a given amount of items or a given max size of single elements, are represented using a compact single-allocation packed encoding. When this is the case, `SCAN` has no meaningful cursor to return, and must iterate the whole data structure at once, so the only sane behavior it has is to return everything in a call.\nHowever once the data structures are bigger and are promoted to use real hash tables, the `SCAN` family of commands will resort to the normal behavior. Note that since this special behavior of returning all the elements is true only for small aggregates, it has no effects on the command complexity or latency. However the exact limits to get converted into real hash tables are user configurable, so the maximum number of elements you can see returned in a single call depends on how big an aggregate data type could be and still use the packed representation.\nAlso note that this behavior is specific of `SSCAN`, `HSCAN` and `ZSCAN`. `SCAN` itself never shows this behavior because the key space is always represented by hash tables.\nReturn value\n`SCAN`, `SSCAN`, `HSCAN` and `ZSCAN` return a two elements multi-bulk reply, where the first element is a string representing an unsigned 64 bit number (the cursor), and the second element is a multi-bulk with an array of elements.\n\n`SCAN` array of elements is a list of keys.\n`SSCAN` array of elements is a list of Set members.\n`HSCAN` array of elements contain two elements, a field and a value, for every returned element of the Hash.\n`ZSCAN` array of elements contain two elements, a member and its associated score, for every returned element of the sorted set.\n\nAdditional examples\nIteration of a Hash value.\n```\nredis 127.0.0.1:6379> hmset hash name Jack age 33\nOK\nredis 127.0.0.1:6379> hscan hash 0\n1) \"0\"\n2) 1) \"name\"\n   2) \"Jack\"\n   3) \"age\"\n   4) \"33\"",
    "tag": "redis"
  },
  {
    "title": "Behavior change history",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/psubscribe.md",
    "content": "Subscribes the client to the given patterns.\nSupported glob-style patterns:\n\n`h?llo` subscribes to `hello`, `hallo` and `hxllo`\n`h*llo` subscribes to `hllo` and `heeeello`\n`h[ae]llo` subscribes to `hello` and `hallo,` but not `hillo`\n\nUse `\\` to escape special characters if you want to match them verbatim.\nOnce the client enters the subscribed state it is not supposed to issue any other commands, except for additional `SUBSCRIBE`, `SSUBSCRIBE`, `PSUBSCRIBE`, `UNSUBSCRIBE`, `SUNSUBSCRIBE`, `PUNSUBSCRIBE`, `PING`, `RESET` and `QUIT` commands.\nHowever, if RESP3 is used (see `HELLO`) it is possible for a client to issue any commands while in subscribed state.\nFor more information, see Pub/sub.\n@return\nWhen successful, this command doesn't return anything.\nInstead, for each pattern, one message with the first element being the string \"psubscribe\" is pushed as a confirmation that the command succeeded.\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "unlink.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/unlink.md",
    "content": "This command is very similar to `DEL`: it removes the specified keys.\nJust like `DEL` a key is ignored if it does not exist. However the command\nperforms the actual memory reclaiming in a different thread, so it is not\nblocking, while `DEL` is. This is where the command name comes from: the\ncommand just unlinks the keys from the keyspace. The actual removal\nwill happen later asynchronously.\n@return\n@integer-reply: The number of keys that were unlinked.\n@examples\n```cli\nSET key1 \"Hello\"\nSET key2 \"World\"\nUNLINK key1 key2 key3",
    "tag": "redis"
  },
  {
    "title": "pubsub-shardnumsub.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pubsub-shardnumsub.md",
    "content": "Returns the number of subscribers for the specified shard channels.\nNote that it is valid to call this command without channels, in this case it will just return an empty list.\nCluster note: in a Redis Cluster, `PUBSUB`'s replies in a cluster only report information from the node's Pub/Sub context, rather than the entire cluster.\n@return\n@array-reply: a list of channels and number of subscribers for every channel.\nThe format is channel, count, channel, count, ..., so the list is flat. The order in which the channels are listed is the same as the order of the shard channels specified in the command call.\n@examples\n```\n\nPUBSUB SHARDNUMSUB orders\n1) \"orders\"\n2) (integer) 1\n",
    "tag": "redis"
  },
  {
    "title": "Understanding the low level details of entries deletion",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xdel.md",
    "content": "Removes the specified entries from a stream, and returns the number of entries\ndeleted.  This number may be less than the number of IDs passed to the command in\nthe case where some of the specified IDs do not exist in the stream.\nNormally you may think at a Redis stream as an append-only data structure,\nhowever Redis streams are represented in memory, so we are also able to \ndelete entries. This may be useful, for instance, in order to comply with\ncertain privacy policies.\nUnderstanding the low level details of entries deletion\nRedis streams are represented in a way that makes them memory efficient:\na radix tree is used in order to index macro-nodes that pack linearly tens\nof stream entries. Normally what happens when you delete an entry from a stream\nis that the entry is not really evicted, it just gets marked as deleted.\nEventually if all the entries in a macro-node are marked as deleted, the whole\nnode is destroyed and the memory reclaimed. This means that if you delete\na large amount of entries from a stream, for instance more than 50% of the\nentries appended to the stream, the memory usage per entry may increment, since\nwhat happens is that the stream will become fragmented. However the stream\nperformance will remain the same.\nIn future versions of Redis it is possible that we'll trigger a node garbage\ncollection in case a given macro-node reaches a given amount of deleted\nentries. Currently with the usage we anticipate for this data structure, it is\nnot a good idea to add such complexity.\n@return\n@integer-reply: the number of entries actually deleted.\n@examples\n```\n\nXADD mystream * a 1\n1538561698944-0\nXADD mystream * b 2\n1538561700640-0\nXADD mystream * c 3\n1538561701744-0\nXDEL mystream 1538561700640-0\n(integer) 1\n127.0.0.1:6379> XRANGE mystream - +\n1) 1) 1538561698944-0\n   2) 1) \"a\"\n      2) \"1\"\n2) 1) 1538561701744-0\n   2) 1) \"c\"\n      2) \"3\"\n",
    "tag": "redis"
  },
  {
    "title": "Behavior change history",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-pause.md",
    "content": "`CLIENT PAUSE` is a connections control command able to suspend all the Redis clients for the specified amount of time (in milliseconds).\nThe command performs the following actions:\n\nIt stops processing all the pending commands from normal and pub/sub clients for the given mode. However interactions with replicas will continue normally. Note that clients are formally paused when they try to execute a command, so no work is taken on the server side for inactive clients.\nHowever it returns OK to the caller ASAP, so the `CLIENT PAUSE` command execution is not paused by itself.\nWhen the specified amount of time has elapsed, all the clients are unblocked: this will trigger the processing of all the commands accumulated in the query buffer of every client during the pause.\n\nClient pause currently supports two modes:\n\n`ALL`: This is the default mode. All client commands are blocked.\n`WRITE`: Clients are only blocked if they attempt to execute a write command.\n\nFor the `WRITE` mode, some commands have special behavior:\n\n`EVAL`/`EVALSHA`: Will block client for all scripts.\n`PUBLISH`: Will block client.\n`PFCOUNT`: Will block client.\n`WAIT`: Acknowledgments will be delayed, so this command will appear blocked.\n\nThis command is useful as it makes able to switch clients from a Redis instance to another one in a controlled way. For example during an instance upgrade the system administrator could do the following:\n\nPause the clients using `CLIENT PAUSE`\nWait a few seconds to make sure the replicas processed the latest replication stream from the master.\nTurn one of the replicas into a master.\nReconfigure clients to connect with the new master.\n\nSince Redis 6.2, the recommended mode for client pause is `WRITE`. This mode will stop all replication traffic, can be\naborted with the `CLIENT UNPAUSE` command, and allows reconfiguring the old master without risking accepting writes after the\nfailover. This is also the mode used during cluster failover.\nFor versions before 6.2, it is possible to send `CLIENT PAUSE` in a MULTI/EXEC block together with the `INFO replication` command in order to get the current master offset at the time the clients are blocked. This way it is possible to wait for a specific offset in the replica side in order to make sure all the replication stream was processed.\nSince Redis 3.2.10 / 4.0.0, this command also prevents keys to be evicted or\nexpired during the time clients are paused. This way the dataset is guaranteed\nto be static not just from the point of view of clients not being able to write, but also from the point of view of internal operations.\n@return\n@simple-string-reply: The command returns OK or an error if the timeout is invalid.\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "function-dump.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/function-dump.md",
    "content": "Return the serialized payload of loaded libraries.\nYou can restore the serialized payload later with the `FUNCTION RESTORE` command.\nFor more information please refer to Introduction to Redis Functions.\n@return\n@bulk-string-reply: the serialized payload\n@examples\nThe following example shows how to dump loaded libraries using `FUNCTION DUMP` and then it calls `FUNCTION FLUSH` deletes all the libraries.\nThen, it restores the original libraries from the serialized payload with `FUNCTION RESTORE`.\n```\nredis> FUNCTION DUMP\n\"\\xf6\\x05mylib\\x03LUA\\x00\\xc3@D@J\\x1aredis.register_function('my@\\x0b\\x02', @\\x06`\\x12\\x11keys, args) return`\\x0c\\a[1] end)\\n\\x00@\\n)\\x11\\xc8|\\x9b\\xe4\"\nredis> FUNCTION FLUSH\nOK\nredis> FUNCTION RESTORE \"\\xf6\\x05mylib\\x03LUA\\x00\\xc3@D@J\\x1aredis.register_function('my@\\x0b\\x02', @\\x06`\\x12\\x11keys, args) return`\\x0c\\a[1] end)\\n\\x00@\\n)\\x11\\xc8|\\x9b\\xe4\"\nOK\nredis> FUNCTION LIST\n1) 1) \"library_name\"\n   2) \"mylib\"\n   3) \"engine\"\n   4) \"LUA\"\n   5) \"description\"\n   6) (nil)\n   7) \"functions\"\n   8) 1) 1) \"name\"\n         2) \"myfunc\"\n         3) \"description\"\n         4) (nil)",
    "tag": "redis"
  },
  {
    "title": "function-delete.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/function-delete.md",
    "content": "Delete a library and all its functions.\nThis command deletes the library called library-name and all functions in it.\nIf the library doesn't exist, the server returns an error.\nFor more information please refer to Introduction to Redis Functions.\n@return\n@simple-string-reply\n@examples\n```\nredis> FUNCTION LOAD Lua mylib \"redis.register_function('myfunc', function(keys, args) return 'hello' end)\"\nOK\nredis> FCALL myfunc 0\n\"hello\"\nredis> FUNCTION DELETE mylib\nOK\nredis> FCALL myfunc 0\n(error) ERR Function not found",
    "tag": "redis"
  },
  {
    "title": "Appendix: Redis expires",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/expire.md",
    "content": "Set a timeout on `key`.\nAfter the timeout has expired, the key will automatically be deleted.\nA key with an associated timeout is often said to be volatile in Redis\nterminology.\nThe timeout will only be cleared by commands that delete or overwrite the\ncontents of the key, including `DEL`, `SET`, `GETSET` and all the `*STORE`\ncommands.\nThis means that all the operations that conceptually alter the value stored at\nthe key without replacing it with a new one will leave the timeout untouched.\nFor instance, incrementing the value of a key with `INCR`, pushing a new value\ninto a list with `LPUSH`, or altering the field value of a hash with `HSET` are\nall operations that will leave the timeout untouched.\nThe timeout can also be cleared, turning the key back into a persistent key,\nusing the `PERSIST` command.\nIf a key is renamed with `RENAME`, the associated time to live is transferred to\nthe new key name.\nIf a key is overwritten by `RENAME`, like in the case of an existing key `Key_A`\nthat is overwritten by a call like `RENAME Key_B Key_A`, it does not matter if\nthe original `Key_A` had a timeout associated or not, the new key `Key_A` will\ninherit all the characteristics of `Key_B`.\nNote that calling `EXPIRE`/`PEXPIRE` with a non-positive timeout or\n`EXPIREAT`/`PEXPIREAT` with a time in the past will result in the key being\ndeleted rather than expired (accordingly, the emitted key event\nwill be `del`, not `expired`).\nOptions\nThe `EXPIRE` command supports a set of options:\n\n`NX` -- Set expiry only when the key has no expiry\n`XX` -- Set expiry only when the key has an existing expiry\n`GT` -- Set expiry only when the new expiry is greater than current one\n`LT` -- Set expiry only when the new expiry is less than current one\n\nA non-volatile key is treated as an infinite TTL for the purpose of `GT` and `LT`.\nThe `GT`, `LT` and `NX` options are mutually exclusive.\nRefreshing expires\nIt is possible to call `EXPIRE` using as argument a key that already has an\nexisting expire set.\nIn this case the time to live of a key is updated to the new value.\nThere are many useful applications for this, an example is documented in the\nNavigation session pattern section below.\nDifferences in Redis prior 2.1.3\nIn Redis versions prior 2.1.3 altering a key with an expire set using a\ncommand altering its value had the effect of removing the key entirely.\nThis semantics was needed because of limitations in the replication layer that\nare now fixed.\n`EXPIRE` would return 0 and not alter the timeout for a key with a timeout set.\n@return\n@integer-reply, specifically:\n\n`1` if the timeout was set.\n`0` if the timeout was not set. e.g. key doesn't exist, or operation skipped due to the provided arguments.\n\n@examples\n`cli\nSET mykey \"Hello\"\nEXPIRE mykey 10\nTTL mykey\nSET mykey \"Hello World\"\nTTL mykey\nEXPIRE mykey 10 XX\nTTL mykey\nEXPIRE mykey 10 NX\nTTL mykey`\nPattern: Navigation session\nImagine you have a web service and you are interested in the latest N pages\nrecently visited by your users, such that each adjacent page view was not\nperformed more than 60 seconds after the previous.\nConceptually you may consider this set of page views as a Navigation session\nof your user, that may contain interesting information about what kind of\nproducts he or she is looking for currently, so that you can recommend related\nproducts.\nYou can easily model this pattern in Redis using the following strategy: every\ntime the user does a page view you call the following commands:\n`MULTI\nRPUSH pagewviews.user:<userid> http://.....\nEXPIRE pagewviews.user:<userid> 60\nEXEC`\nIf the user will be idle more than 60 seconds, the key will be deleted and only\nsubsequent page views that have less than 60 seconds of difference will be\nrecorded.\nThis pattern is easily modified to use counters using `INCR` instead of lists\nusing `RPUSH`.\nAppendix: Redis expires\nKeys with an expire\nNormally Redis keys are created without an associated time to live.\nThe key will simply live forever, unless it is removed by the user in an\nexplicit way, for instance using the `DEL` command.\nThe `EXPIRE` family of commands is able to associate an expire to a given key,\nat the cost of some additional memory used by the key.\nWhen a key has an expire set, Redis will make sure to remove the key when the\nspecified amount of time elapsed.\nThe key time to live can be updated or entirely removed using the `EXPIRE` and\n`PERSIST` command (or other strictly related commands).\nExpire accuracy\nIn Redis 2.4 the expire might not be pin-point accurate, and it could be between\nzero to one seconds out.\nSince Redis 2.6 the expire error is from 0 to 1 milliseconds.\nExpires and persistence\nKeys expiring information is stored as absolute Unix timestamps (in milliseconds\nin case of Redis version 2.6 or greater).\nThis means that the time is flowing even when the Redis instance is not active.\nFor expires to work well, the computer time must be taken stable.\nIf you move an RDB file from two computers with a big desync in their clocks,\nfunny things may happen (like all the keys loaded to be expired at loading\ntime).\nEven running instances will always check the computer clock, so for instance if\nyou set a key with a time to live of 1000 seconds, and then set your computer\ntime 2000 seconds in the future, the key will be expired immediately, instead of\nlasting for 1000 seconds.\nHow Redis expires keys\nRedis keys are expired in two ways: a passive way, and an active way.\nA key is passively expired simply when some client tries to access it, and the\nkey is found to be timed out.\nOf course this is not enough as there are expired keys that will never be\naccessed again.\nThese keys should be expired anyway, so periodically Redis tests a few keys at\nrandom among keys with an expire set.\nAll the keys that are already expired are deleted from the keyspace.\nSpecifically this is what Redis does 10 times per second:\n\nTest 20 random keys from the set of keys with an associated expire.\nDelete all the keys found expired.\nIf more than 25% of keys were expired, start again from step 1.\n\nThis is a trivial probabilistic algorithm, basically the assumption is that our\nsample is representative of the whole key space, and we continue to expire until\nthe percentage of keys that are likely to be expired is under 25%\nThis means that at any given moment the maximum amount of keys already expired\nthat are using memory is at max equal to max amount of write operations per\nsecond divided by 4.\nHow expires are handled in the replication link and AOF file\nIn order to obtain a correct behavior without sacrificing consistency, when a\nkey expires, a `DEL` operation is synthesized in both the AOF file and gains all\nthe attached replicas nodes.\nThis way the expiration process is centralized in the master instance, and there\nis no chance of consistency errors.\nHowever while the replicas connected to a master will not expire keys\nindependently (but will wait for the `DEL` coming from the master), they'll\nstill take the full state of the expires existing in the dataset, so when a\nreplica is elected to master it will be able to expire the keys independently,",
    "tag": "redis"
  },
  {
    "title": "Specifying a Stream ID as an argument",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xadd.md",
    "content": "Appends the specified stream entry to the stream at the specified key.\nIf the key does not exist, as a side effect of running this command the\nkey is created with a stream value. The creation of stream's key can be\ndisabled with the `NOMKSTREAM` option.\nAn entry is composed of a list of field-value pairs.\nThe field-value pairs are stored in the same order they are given by the user.\nCommands that read the stream, such as `XRANGE` or `XREAD`, are guaranteed to return the fields and values exactly in the same order they were added by `XADD`.\n`XADD` is the only Redis command that can add data to a stream, but \nthere are other commands, such as `XDEL` and `XTRIM`, that are able to\nremove data from a stream.\nSpecifying a Stream ID as an argument\nA stream entry ID identifies a given entry inside a stream.\nThe `XADD` command will auto-generate a unique ID for you if the ID argument\nspecified is the `*` character (asterisk ASCII character). However, while\nuseful only in very rare cases, it is possible to specify a well-formed ID, so\nthat the new entry will be added exactly with the specified ID.\nIDs are specified by two numbers separated by a `-` character:\n\n\n```1526919030474-55\n```\n\n\nBoth quantities are 64-bit numbers. When an ID is auto-generated, the\nfirst part is the Unix time in milliseconds of the Redis instance generating\nthe ID. The second part is just a sequence number and is used in order to\ndistinguish IDs generated in the same millisecond.\nYou can also specify an incomplete ID, that consists only of the milliseconds part, which is interpreted as a zero value for sequence part.\nTo have only the sequence part automatically generated, specify the milliseconds part followed by the `-` separator and the `*` character:\n```\n\nXADD mystream 1526919030474-55 message \"Hello,\"\n\"1526919030474-55\"\nXADD mystream 1526919030474-* message \" World!\"\n\"1526919030474-56\"\n```\n\nIDs are guaranteed to be always incremental: If you compare the ID of the\nentry just inserted it will be greater than any other past ID, so entries\nare totally ordered inside a stream. In order to guarantee this property,\nif the current top ID in the stream has a time greater than the current\nlocal time of the instance, the top entry time will be used instead, and\nthe sequence part of the ID incremented. This may happen when, for instance,\nthe local clock jumps backward, or if after a failover the new master has\na different absolute time.\nWhen a user specified an explicit ID to `XADD`, the minimum valid ID is\n`0-1`, and the user must specify an ID which is greater than any other\nID currently inside the stream, otherwise the command will fail and return an error. Usually\nresorting to specific IDs is useful only if you have another system generating\nunique IDs (for instance an SQL table) and you really want the Redis stream\nIDs to match the one of this other system.\nCapped streams\n`XADD` incorporates the same semantics as the `XTRIM` command - refer to its documentation page for more information.\nThis allows adding new entries and keeping the stream's size in check with a single call to `XADD`, effectively capping the stream with an arbitrary threshold.\nAlthough exact trimming is possible and is the default, due to the internal representation of steams it is more efficient to add an entry and trim stream with `XADD` using almost exact trimming (the `~` argument).\nFor example, calling `XADD` in the following form:\n\n\n```XADD mystream MAXLEN ~ 1000 * ... entry fields here ...\n```\n\n\nWill add a new entry but will also evict old entries so that the stream will contain only 1000 entries, or at most a few tens more.\nAdditional information about streams\nFor further information about Redis streams please check our\nintroduction to Redis Streams document.\n@return\n@bulk-string-reply, specifically:\nThe command returns the ID of the added entry. The ID is the one auto-generated\nif `*` is passed as ID argument, otherwise the command just returns the same ID\nspecified by the user during insertion.\nThe command returns a @nil-reply when used with the `NOMKSTREAM` option and the\nkey doesn't exist.\n@examples\n```cli\nXADD mystream * name Sara surname OConnor\nXADD mystream * field1 value1 field2 value2 field3 value3\nXLEN mystream\nXRANGE mystream - +",
    "tag": "redis"
  },
  {
    "title": "zrank.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrank.md",
    "content": "Returns the rank of `member` in the sorted set stored at `key`, with the scores\nordered from low to high.\nThe rank (or index) is 0-based, which means that the member with the lowest\nscore has rank `0`.\nThe optional `WITHSCORE` argument supplements the command's reply with the score of the element returned.\nUse `ZREVRANK` to get the rank of an element with the scores ordered from high\nto low.\n@return\n\nIf `member` exists in the sorted set:\nusing `WITHSCORE`, @array-reply: an array containing the rank and score of `member`.\nwithout using `WITHSCORE`, @integer-reply: the rank of `member`.\nIf `member` does not exist in the sorted set or `key` does not exist:\nusing `WITHSCORE`, @array-reply: `nil`.\nwithout using `WITHSCORE`, @bulk-string-reply: `nil`.\n\nNote that in RESP3 null and nullarray are the same, but in RESP2 they are not.\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZRANK myzset \"three\"\nZRANK myzset \"four\"\nZRANK myzset \"three\" WITHSCORE\nZRANK myzset \"four\" WITHSCORE",
    "tag": "redis"
  },
  {
    "title": "cluster-saveconfig.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-saveconfig.md",
    "content": "Forces a node to save the `nodes.conf` configuration on disk. Before to return\nthe command calls `fsync(2)` in order to make sure the configuration is\nflushed on the computer disk.\nThis command is mainly used in the event a `nodes.conf` node state file\ngets lost / deleted for some reason, and we want to generate it again from\nscratch. It can also be useful in case of mundane alterations of a node cluster\nconfiguration via the `CLUSTER` command in order to ensure the new configuration\nis persisted on disk, however all the commands should normally be able to\nauto schedule to persist the configuration on disk when it is important\nto do so for the correctness of the system in the event of a restart.\n@return",
    "tag": "redis"
  },
  {
    "title": "xautoclaim.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xautoclaim.md",
    "content": "This command transfers ownership of pending stream entries that match the specified criteria. Conceptually, `XAUTOCLAIM`  is equivalent to calling `XPENDING` and then `XCLAIM`,\nbut provides a more straightforward way to deal with message delivery failures via `SCAN`-like semantics.\nLike `XCLAIM`, the command operates on the stream entries at `<key>` and in the context of the provided `<group>`.\nIt transfers ownership to `<consumer>` of messages pending for more than `<min-idle-time>` milliseconds and having an equal or greater ID than `<start>`.\nThe optional `<count>` argument, which defaults to 100, is the upper limit of the number of entries that the command attempts to claim.\nInternally, the command begins scanning the consumer group's Pending Entries List (PEL) from `<start>` and filters out entries having an idle time less than or equal to `<min-idle-time>`.\nThe maximum number of pending entries that the command scans is the product of multiplying `<count>`'s value by 10 (hard-coded).\nIt is possible, therefore, that the number of entries claimed will be less than the specified value.\nThe optional `JUSTID` argument changes the reply to return just an array of IDs of messages successfully claimed, without returning the actual message.\nUsing this option means the retry counter is not incremented.\nThe command returns the claimed entries as an array. It also returns a stream ID intended for cursor-like use as the `<start>` argument for its subsequent call.\nWhen there are no remaining PEL entries, the command returns the special `0-0` ID to signal completion.\nHowever, note that you may want to continue calling `XAUTOCLAIM` even after the scan is complete with the `0-0` as `<start>` ID, because enough time passed, so older pending entries may now be eligible for claiming.\nNote that only messages that are idle longer than `<min-idle-time>` are claimed, and claiming a message resets its idle time.\nThis ensures that only a single consumer can successfully claim a given pending message at a specific instant of time and trivially reduces the probability of processing the same message multiple times.\nWhile iterating the PEL, if `XAUTOCLAIM` stumbles upon a message which doesn't exist in the stream anymore (either trimmed or deleted by `XDEL`) it does not claim it, and deletes it from the PEL in which it was found. This feature was introduced in Redis 7.0.\nThese message IDs are returned to the caller as a part of `XAUTOCLAIM`s reply.\nLastly, claiming a message with `XAUTOCLAIM` also increments the attempted deliveries count for that message, unless the `JUSTID` option has been specified (which only delivers the message ID, not the message itself).\nMessages that cannot be processed for some reason - for example, because consumers systematically crash when processing them - will exhibit high attempted delivery counts that can be detected by monitoring.\n@return\n@array-reply, specifically:\nAn array with three elements:\n\nA stream ID to be used as the `<start>` argument for the next call to `XAUTOCLAIM`.\nAn array containing all the successfully claimed messages in the same format as `XRANGE`.\nAn array containing message IDs that no longer exist in the stream, and were deleted from the PEL in which they were found.\n\n@examples\n```\n\nXAUTOCLAIM mystream mygroup Alice 3600000 0-0 COUNT 25\n1) \"0-0\"\n2) 1) 1) \"1609338752495-0\"\n      2) 1) \"field\"\n         2) \"value\"\n3) (empty array)\n```\n\nIn the above example, we attempt to claim up to 25 entries that are pending and idle (not having been acknowledged or claimed) for at least an hour, starting at the stream's beginning.\nThe consumer \"Alice\" from the \"mygroup\" group acquires ownership of these messages.\nNote that the stream ID returned in the example is `0-0`, indicating that the entire stream was scanned.",
    "tag": "redis"
  },
  {
    "title": "dump.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/dump.md",
    "content": "Serialize the value stored at key in a Redis-specific format and return it to\nthe user.\nThe returned value can be synthesized back into a Redis key using the `RESTORE`\ncommand.\nThe serialization format is opaque and non-standard, however it has a few\nsemantic characteristics:\n\nIt contains a 64-bit checksum that is used to make sure errors will be\n  detected.\n  The `RESTORE` command makes sure to check the checksum before synthesizing a\n  key using the serialized value.\nValues are encoded in the same format used by RDB.\nAn RDB version is encoded inside the serialized value, so that different Redis\n  versions with incompatible RDB formats will refuse to process the serialized\n  value.\n\nThe serialized value does NOT contain expire information.\nIn order to capture the time to live of the current value the `PTTL` command\nshould be used.\nIf `key` does not exist a nil bulk reply is returned.\n@return\n@bulk-string-reply: the serialized value.\n@examples\n```\n\nSET mykey 10\nOK\nDUMP mykey\n\"\\x00\\xc0\\n\\n\\x00n\\x9fWE\\x0e\\xaec\\xbb\"\n",
    "tag": "redis"
  },
  {
    "title": "Specification of the behavior when count is passed",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/hrandfield.md",
    "content": "When called with just the `key` argument, return a random field from the hash value stored at `key`.\nIf the provided `count` argument is positive, return an array of distinct fields.\nThe array's length is either `count` or the hash's number of fields (`HLEN`), whichever is lower.\nIf called with a negative `count`, the behavior changes and the command is allowed to return the same field multiple times.\nIn this case, the number of returned fields is the absolute value of the specified `count`.\nThe optional `WITHVALUES` modifier changes the reply so it includes the respective values of the randomly selected hash fields.\n@return\n@bulk-string-reply: without the additional `count` argument, the command returns a Bulk Reply with the randomly selected field, or `nil` when `key` does not exist.\n@array-reply: when the additional `count` argument is passed, the command returns an array of fields, or an empty array when `key` does not exist.\nIf the `WITHVALUES` modifier is used, the reply is a list fields and their values from the hash.\n@examples\n`cli\nHMSET coin heads obverse tails reverse edge null\nHRANDFIELD coin\nHRANDFIELD coin\nHRANDFIELD coin -5 WITHVALUES`\nSpecification of the behavior when count is passed\nWhen the `count` argument is a positive value this command behaves as follows:\n\nNo repeated fields are returned.\nIf `count` is bigger than the number of fields in the hash, the command will only return the whole hash without additional fields.\nThe order of fields in the reply is not truly random, so it is up to the client to shuffle them if needed.\n\nWhen the `count` is a negative value, the behavior changes as follows:\n\nRepeating fields are possible.\nExactly `count` fields, or an empty array if the hash is empty (non-existing key), are always returned.\n",
    "tag": "redis"
  },
  {
    "title": "Non-blocking behavior",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/blpop.md",
    "content": "`BLPOP` is a blocking list pop primitive.\nIt is the blocking version of `LPOP` because it blocks the connection when there\nare no elements to pop from any of the given lists.\nAn element is popped from the head of the first list that is non-empty, with the\ngiven keys being checked in the order that they are given.\nNon-blocking behavior\nWhen `BLPOP` is called, if at least one of the specified keys contains a\nnon-empty list, an element is popped from the head of the list and returned to\nthe caller together with the `key` it was popped from.\nKeys are checked in the order that they are given.\nLet's say that the key `list1` doesn't exist and `list2` and `list3` hold\nnon-empty lists.\nConsider the following command:\n`BLPOP list1 list2 list3 0`\n`BLPOP` guarantees to return an element from the list stored at `list2` (since\nit is the first non empty list when checking `list1`, `list2` and `list3` in\nthat order).\nBlocking behavior\nIf none of the specified keys exist, `BLPOP` blocks the connection until another\nclient performs an `LPUSH` or `RPUSH` operation against one of the keys.\nOnce new data is present on one of the lists, the client returns with the name\nof the key unblocking it and the popped value.\nWhen `BLPOP` causes a client to block and a non-zero timeout is specified,\nthe client will unblock returning a `nil` multi-bulk value when the specified\ntimeout has expired without a push operation against at least one of the\nspecified keys.\nThe timeout argument is interpreted as a double value specifying the maximum number of seconds to block. A timeout of zero can be used to block indefinitely.\nWhat key is served first? What client? What element? Priority ordering details.\n\nIf the client tries to blocks for multiple keys, but at least one key contains elements, the returned key / element pair is the first key from left to right that has one or more elements. In this case the client is not blocked. So for instance `BLPOP key1 key2 key3 key4 0`, assuming that both `key2` and `key4` are non-empty, will always return an element from `key2`.\nIf multiple clients are blocked for the same key, the first client to be served is the one that was waiting for more time (the first that blocked for the key). Once a client is unblocked it does not retain any priority, when it blocks again with the next call to `BLPOP` it will be served accordingly to the number of clients already blocked for the same key, that will all be served before it (from the first to the last that blocked).\nWhen a client is blocking for multiple keys at the same time, and elements are available at the same time in multiple keys (because of a transaction or a Lua script added elements to multiple lists), the client will be unblocked using the first key that received a push operation (assuming it has enough elements to serve our client, as there may be other clients as well waiting for this key). Basically after the execution of every command Redis will run a list of all the keys that received data AND that have at least a client blocked. The list is ordered by new element arrival time, from the first key that received data to the last. For every key processed, Redis will serve all the clients waiting for that key in a FIFO fashion, as long as there are elements in this key. When the key is empty or there are no longer clients waiting for this key, the next key that received new data in the previous command / transaction / script is processed, and so forth.\n\nBehavior of `!BLPOP` when multiple elements are pushed inside a list.\nThere are times when a list can receive multiple elements in the context of the same conceptual command:\n\nVariadic push operations such as `LPUSH mylist a b c`.\nAfter an `EXEC` of a `MULTI` block with multiple push operations against the same list.\nExecuting a Lua Script with Redis 2.6 or newer.\n\nWhen multiple elements are pushed inside a list where there are clients blocking, the behavior is different for Redis 2.4 and Redis 2.6 or newer.\nFor Redis 2.6 what happens is that the command performing multiple pushes is executed, and only after the execution of the command the blocked clients are served. Consider this sequence of commands.\n\n\n```Client A:   BLPOP foo 0\nClient B:   LPUSH foo a b c\n```\n\n\nIf the above condition happens using a Redis 2.6 server or greater, Client A will be served with the `c` element, because after the `LPUSH` command the list contains `c,b,a`, so taking an element from the left means to return `c`.\nInstead Redis 2.4 works in a different way: clients are served in the context of the push operation, so as long as `LPUSH foo a b c` starts pushing the first element to the list, it will be delivered to the Client A, that will receive `a` (the first element pushed).\nThe behavior of Redis 2.4 creates a lot of problems when replicating or persisting data into the AOF file, so the much more generic and semantically simpler behavior was introduced into Redis 2.6 to prevent problems.\nNote that for the same reason a Lua script or a `MULTI/EXEC` block may push elements into a list and afterward delete the list. In this case the blocked clients will not be served at all and will continue to be blocked as long as no data is present on the list after the execution of a single command, transaction, or script.\n`!BLPOP` inside a `!MULTI` / `!EXEC` transaction\n`BLPOP` can be used with pipelining (sending multiple commands and\nreading the replies in batch), however this setup makes sense almost solely\nwhen it is the last command of the pipeline.\nUsing `BLPOP` inside a `MULTI` / `EXEC` block does not make a lot of sense\nas it would require blocking the entire server in order to execute the block\natomically, which in turn does not allow other clients to perform a push\noperation. For this reason the behavior of `BLPOP` inside `MULTI` / `EXEC` when the list is empty is to return a `nil` multi-bulk reply, which is the same\nthing that happens when the timeout is reached.\nIf you like science fiction, think of time flowing at infinite speed inside a\n`MULTI` / `EXEC` block...\n@return\n@array-reply: specifically:\n\nA `nil` multi-bulk when no element could be popped and the timeout expired.\nA two-element multi-bulk with the first element being the name of the key\n  where an element was popped and the second element being the value of the\n  popped element.\n\n@examples\n`redis> DEL list1 list2\n(integer) 0\nredis> RPUSH list1 a b c\n(integer) 3\nredis> BLPOP list1 list2 0\n1) \"list1\"\n2) \"a\"`\nReliable queues\nWhen `BLPOP` returns an element to the client, it also removes the element from the list. This means that the element only exists in the context of the client: if the client crashes while processing the returned element, it is lost forever.\nThis can be a problem with some application where we want a more reliable messaging system. When this is the case, please check the `BRPOPLPUSH` command, that is a variant of `BLPOP` that adds the returned element to a target list before returning it to the client.\nPattern: Event notification\nUsing blocking list operations it is possible to mount different blocking\nprimitives.\nFor instance for some application you may need to block waiting for elements\ninto a Redis Set, so that as far as a new element is added to the Set, it is\npossible to retrieve it without resort to polling.\nThis would require a blocking version of `SPOP` that is not available, but using\nblocking list operations we can easily accomplish this task.\nThe consumer will do:\n`LOOP forever\n    WHILE SPOP(key) returns elements\n        ... process elements ...\n    END\n    BRPOP helper_key\nEND`\nWhile in the producer side we'll use simply:\n```\nMULTI\nSADD key element\nLPUSH helper_key x\nEXEC",
    "tag": "redis"
  },
  {
    "title": "zcount.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zcount.md",
    "content": "Returns the number of elements in the sorted set at `key` with a score between\n`min` and `max`.\nThe `min` and `max` arguments have the same semantic as described for\n`ZRANGEBYSCORE`.\nNote: the command has a complexity of just O(log(N)) because it uses elements ranks (see `ZRANK`) to get an idea of the range. Because of this there is no need to do a work proportional to the size of the range.\n@return\n@integer-reply: the number of elements in the specified score range.\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZCOUNT myzset -inf +inf\nZCOUNT myzset (1 3",
    "tag": "redis"
  },
  {
    "title": "zunionstore.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zunionstore.md",
    "content": "Computes the union of `numkeys` sorted sets given by the specified keys, and\nstores the result in `destination`.\nIt is mandatory to provide the number of input keys (`numkeys`) before passing\nthe input keys and the other (optional) arguments.\nBy default, the resulting score of an element is the sum of its scores in the\nsorted sets where it exists.\nUsing the `WEIGHTS` option, it is possible to specify a multiplication factor\nfor each input sorted set.\nThis means that the score of every element in every input sorted set is\nmultiplied by this factor before being passed to the aggregation function.\nWhen `WEIGHTS` is not given, the multiplication factors default to `1`.\nWith the `AGGREGATE` option, it is possible to specify how the results of the\nunion are aggregated.\nThis option defaults to `SUM`, where the score of an element is summed across\nthe inputs where it exists.\nWhen this option is set to either `MIN` or `MAX`, the resulting set will contain\nthe minimum or maximum score of an element across the inputs where it exists.\nIf `destination` already exists, it is overwritten.\n@return\n@integer-reply: the number of elements in the resulting sorted set at\n`destination`.\n@examples\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZADD zset2 3 \"three\"\nZUNIONSTORE out 2 zset1 zset2 WEIGHTS 2 3\nZRANGE out 0 -1 WITHSCORES",
    "tag": "redis"
  },
  {
    "title": "ttl.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/ttl.md",
    "content": "Returns the remaining time to live of a key that has a timeout.\nThis introspection capability allows a Redis client to check how many seconds a\ngiven key will continue to be part of the dataset.\nIn Redis 2.6 or older the command returns `-1` if the key does not exist or if the key exist but has no associated expire.\nStarting with Redis 2.8 the return value in case of error changed:\n\nThe command returns `-2` if the key does not exist.\nThe command returns `-1` if the key exists but has no associated expire.\n\nSee also the `PTTL` command that returns the same information with milliseconds resolution (Only available in Redis 2.6 or greater).\n@return\n@integer-reply: TTL in seconds, or a negative value in order to signal an error (see the description above).\n@examples\n```cli\nSET mykey \"Hello\"\nEXPIRE mykey 10\nTTL mykey",
    "tag": "redis"
  },
  {
    "title": "acl-genpass.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-genpass.md",
    "content": "ACL users need a solid password in order to authenticate to the server without\nsecurity risks. Such password does not need to be remembered by humans, but\nonly by computers, so it can be very long and strong (unguessable by an\nexternal attacker). The `ACL GENPASS` command generates a password starting\nfrom /dev/urandom if available, otherwise (in systems without /dev/urandom) it\nuses a weaker system that is likely still better than picking a weak password\nby hand.\nBy default (if /dev/urandom is available) the password is strong and\ncan be used for other uses in the context of a Redis application, for\ninstance in order to create unique session identifiers or other kind of\nunguessable and not colliding IDs. The password generation is also very cheap\nbecause we don't really ask /dev/urandom for bits at every execution. At\nstartup Redis creates a seed using /dev/urandom, then it will use SHA256\nin counter mode, with HMAC-SHA256(seed,counter) as primitive, in order to\ncreate more random bytes as needed. This means that the application developer\nshould be feel free to abuse `ACL GENPASS` to create as many secure\npseudorandom strings as needed.\nThe command output is a hexadecimal representation of a binary string.\nBy default it emits 256 bits (so 64 hex characters). The user can provide\nan argument in form of number of bits to emit from 1 to 1024 to change\nthe output length. Note that the number of bits provided is always\nrounded to the next multiple of 4. So for instance asking for just 1\nbit password will result in 4 bits to be emitted, in the form of a single\nhex character.\n@return\n@bulk-string-reply: by default 64 bytes string representing 256 bits of pseudorandom data. Otherwise if an argument if needed, the output string length is the number of specified bits (rounded to the next multiple of 4) divided by 4.\n@examples\n```\n\nACL GENPASS\n\"dd721260bfe1b3d9601e7fbab36de6d04e2e67b0ef1c53de59d45950db0dd3cc\"\nACL GENPASS 32\n\"355ef3dd\"\nACL GENPASS 5\n\"90\"\n",
    "tag": "redis"
  },
  {
    "title": "GEOADD options",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/geoadd.md",
    "content": "Adds the specified geospatial items (longitude, latitude, name) to the specified key. Data is stored into the key as a sorted set, in a way that makes it possible to query the items with the `GEOSEARCH` command.\nThe command takes arguments in the standard format x,y so the longitude must be specified before the latitude. There are limits to the coordinates that can be indexed: areas very near to the poles are not indexable.\nThe exact limits, as specified by EPSG:900913 / EPSG:3785 / OSGEO:41001 are the following:\n\nValid longitudes are from -180 to 180 degrees.\nValid latitudes are from -85.05112878 to 85.05112878 degrees.\n\nThe command will report an error when the user attempts to index coordinates outside the specified ranges.\nNote: there is no GEODEL command because you can use `ZREM` to remove elements. The Geo index structure is just a sorted set.\nGEOADD options\n`GEOADD` also provides the following options:\n\nXX: Only update elements that already exist. Never add elements.\nNX: Don't update already existing elements. Always add new elements.\nCH: Modify the return value from the number of new elements added, to the total number of elements changed (CH is an abbreviation of changed). Changed elements are new elements added and elements already existing for which the coordinates was updated. So elements specified in the command line having the same score as they had in the past are not counted. Note: normally, the return value of `GEOADD` only counts the number of new elements added.\n\nNote: The XX and NX options are mutually exclusive.\nHow does it work?\nThe way the sorted set is populated is using a technique called\nGeohash. Latitude and Longitude\nbits are interleaved to form a unique 52-bit integer. We know\nthat a sorted set double score can represent a 52-bit integer without losing\nprecision.\nThis format allows for bounding box and radius querying by checking the 1+8 areas needed to cover the whole shape and discarding elements outside it. The areas are checked by calculating the range of the box covered, removing enough bits from the less significant part of the sorted set score, and computing the score range to query in the sorted set for each area.\nWhat Earth model does it use?\nThe model assumes that the Earth is a sphere since it uses the Haversine formula to calculate distance. This formula is only an approximation when applied to the Earth, which is not a perfect sphere.\nThe introduced errors are not an issue when used, for example, by social networks and similar applications requiring this type of querying. \nHowever, in the worst case, the error may be up to 0.5%, so you may want to consider other systems for error-critical applications.\n@return\n@integer-reply, specifically:\n\nWhen used without optional arguments, the number of elements added to the sorted set (excluding score updates).\nIf the `CH` option is specified, the number of elements that were changed (added or updated).\n\n@examples\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEODIST Sicily Palermo Catania\nGEORADIUS Sicily 15 37 100 km\nGEORADIUS Sicily 15 37 200 km",
    "tag": "redis"
  },
  {
    "title": "cluster-bumpepoch.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-bumpepoch.md",
    "content": "Advances the cluster config epoch.\nThe `CLUSTER BUMPEPOCH` command triggers an increment to the cluster's config epoch from the connected node. The epoch will be incremented if the node's config epoch is zero, or if it is less than the cluster's greatest epoch.\nNote: config epoch management is performed internally by the cluster, and relies on obtaining a consensus of nodes. The `CLUSTER BUMPEPOCH` attempts to increment the config epoch WITHOUT getting the consensus, so using it may violate the \"last failover wins\" rule. Use it with caution.\n@return",
    "tag": "redis"
  },
  {
    "title": "Command options",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xclaim.md",
    "content": "In the context of a stream consumer group, this command changes the ownership\nof a pending message, so that the new owner is the consumer specified as the\ncommand argument. Normally this is what happens:\n\nThere is a stream with an associated consumer group.\nSome consumer A reads a message via `XREADGROUP` from a stream, in the context of that consumer group.\nAs a side effect a pending message entry is created in the Pending Entries List (PEL) of the consumer group: it means the message was delivered to a given consumer, but it was not yet acknowledged via `XACK`.\nThen suddenly that consumer fails forever.\nOther consumers may inspect the list of pending messages, that are stale for quite some time, using the `XPENDING` command. In order to continue processing such messages, they use `XCLAIM` to acquire the ownership of the message and continue. Consumers can also use the `XAUTOCLAIM` command to automatically scan and claim stale pending messages.\n\nThis dynamic is clearly explained in the Stream intro documentation.\nNote that the message is claimed only if its idle time is greater than the minimum idle time we specify when calling `XCLAIM`. Because as a side effect `XCLAIM` will also reset the idle time (since this is a new attempt at processing the message), two consumers trying to claim a message at the same time will never both succeed: only one will successfully claim the message. This avoids that we process a given message multiple times in a trivial way (yet multiple processing is possible and unavoidable in the general case).\nMoreover, as a side effect, `XCLAIM` will increment the count of attempted deliveries of the message unless the `JUSTID` option has been specified (which only delivers the message ID, not the message itself). In this way messages that cannot be processed for some reason, for instance because the consumers crash attempting to process them, will start to have a larger counter and can be detected inside the system.\n`XCLAIM` will not claim a message in the following cases:\n\nThe message doesn't exist in the group PEL (i.e. it was never read by any consumer)\nThe message exists in the group PEL but not in the stream itself (i.e. the message was read but never acknowledged, and then was deleted from the stream, either by trimming or by `XDEL`)\n\nIn both cases the reply will not contain a corresponding entry to that message (i.e. the length of the reply array may be smaller than the number of IDs provided to `XCLAIM`).\nIn the latter case, the message will also be deleted from the PEL in which it was found. This feature was introduced in Redis 7.0.\nCommand options\nThe command has multiple options, however most are mainly for internal use in\norder to transfer the effects of `XCLAIM` or other commands to the AOF file\nand to propagate the same effects to the replicas, and are unlikely to be\nuseful to normal users:\n\n`IDLE <ms>`: Set the idle time (last time it was delivered) of the message. If IDLE is not specified, an IDLE of 0 is assumed, that is, the time count is reset because the message has now a new owner trying to process it.\n`TIME <ms-unix-time>`: This is the same as IDLE but instead of a relative amount of milliseconds, it sets the idle time to a specific Unix time (in milliseconds). This is useful in order to rewrite the AOF file generating `XCLAIM` commands.\n`RETRYCOUNT <count>`: Set the retry counter to the specified value. This counter is incremented every time a message is delivered again. Normally `XCLAIM` does not alter this counter, which is just served to clients when the XPENDING command is called: this way clients can detect anomalies, like messages that are never processed for some reason after a big number of delivery attempts.\n`FORCE`: Creates the pending message entry in the PEL even if certain specified IDs are not already in the PEL assigned to a different client. However the message must be exist in the stream, otherwise the IDs of non existing messages are ignored.\n`JUSTID`: Return just an array of IDs of messages successfully claimed, without returning the actual message. Using this option means the retry counter is not incremented.\n\n@return\n@array-reply, specifically:\nThe command returns all the messages successfully claimed, in the same format\nas `XRANGE`. However if the `JUSTID` option was specified, only the message\nIDs are reported, without including the actual message.\n@examples\n```\n\nXCLAIM mystream mygroup Alice 3600000 1526569498055-0\n1) 1) 1526569498055-0\n   2) 1) \"message\"\n      2) \"orange\"\n```\n",
    "tag": "redis"
  },
  {
    "title": "hmget.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/hmget.md",
    "content": "Returns the values associated with the specified `fields` in the hash stored at\n`key`.\nFor every `field` that does not exist in the hash, a `nil` value is returned.\nBecause non-existing keys are treated as empty hashes, running `HMGET` against\na non-existing `key` will return a list of `nil` values.\n@return\n@array-reply: list of values associated with the given fields, in the same\norder as they are requested.\n```cli\nHSET myhash field1 \"Hello\"\nHSET myhash field2 \"World\"\nHMGET myhash field1 field2 nofield",
    "tag": "redis"
  },
  {
    "title": "rpop.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/rpop.md",
    "content": "Removes and returns the last elements of the list stored at `key`.\nBy default, the command pops a single element from the end of the list.\nWhen provided with the optional `count` argument, the reply will consist of up\nto `count` elements, depending on the list's length.\n@return\nWhen called without the `count` argument:\n@bulk-string-reply: the value of the last element, or `nil` when `key` does not exist.\nWhen called with the `count` argument:\n@array-reply: list of popped elements, or `nil` when `key` does not exist.\n@examples\n```cli\nRPUSH mylist \"one\" \"two\" \"three\" \"four\" \"five\"\nRPOP mylist\nRPOP mylist 2\nLRANGE mylist 0 -1",
    "tag": "redis"
  },
  {
    "title": "acl-getuser.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-getuser.md",
    "content": "The command returns all the rules defined for an existing ACL user.\nSpecifically, it lists the user's ACL flags, password hashes, commands, key patterns, channel patterns (Added in version 6.2) and selectors (Added in version 7.0).\nAdditional information may be returned in the future if more metadata is added to the user.\nCommand rules are always returned in the same format as the one used in the `ACL SETUSER` command.\nBefore version 7.0, keys and channels were returned as an array of patterns, however in version 7.0 later they are now also returned in same format as the one used in the `ACL SETUSER` command.\nNote: This description of command rules reflects the user's effective permissions, so while it may not be identical to the set of rules used to configure the user, it is still functionally identical.\nSelectors are listed in the order they were applied to the user, and include information about commands, key patterns, and channel patterns.\n@array-reply: a list of ACL rule definitions for the user.\nIf `user` does not exist a @nil-reply is returned.\n@examples\nHere's an example configuration for a user\n```\n\nACL SETUSER sample on nopass +GET allkeys & (+SET ~key2)\n\"OK\"\nACL GETUSER sample\n1) \"flags\"\n2) 1) \"on\"\n   2) \"allkeys\"\n   3) \"nopass\"\n3) \"passwords\"\n4) (empty array)\n5) \"commands\"\n6) \"+@all\"\n7) \"keys\"\n8) \"~\"\n9) \"channels\"\n10) \"&\"\n11) \"selectors\"\n12) 1) 1) \"commands\"\n       6) \"+SET\"\n       7) \"keys\"\n       8) \"~key2\"\n       9) \"channels\"\n       10) \"&\"\n",
    "tag": "redis"
  },
  {
    "title": "zadd.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zadd.md",
    "content": "Adds all the specified members with the specified scores to the sorted set\nstored at `key`.\nIt is possible to specify multiple score / member pairs.\nIf a specified member is already a member of the sorted set, the score is\nupdated and the element reinserted at the right position to ensure the correct\nordering.\nIf `key` does not exist, a new sorted set with the specified members as sole\nmembers is created, like if the sorted set was empty. If the key exists but does not hold a sorted set, an error is returned.\nThe score values should be the string representation of a double precision floating point number. `+inf` and `-inf` values are valid values as well.\nZADD options\nZADD supports a list of options, specified after the name of the key and before\nthe first score argument. Options are:\n\nXX: Only update elements that already exist. Don't add new elements.\nNX: Only add new elements. Don't update already existing elements.\nLT: Only update existing elements if the new score is less than the current score. This flag doesn't prevent adding new elements.\nGT: Only update existing elements if the new score is greater than the current score. This flag doesn't prevent adding new elements.\nCH: Modify the return value from the number of new elements added, to the total number of elements changed (CH is an abbreviation of changed). Changed elements are new elements added and elements already existing for which the score was updated. So elements specified in the command line having the same score as they had in the past are not counted. Note: normally the return value of `ZADD` only counts the number of new elements added.\nINCR: When this option is specified `ZADD` acts like `ZINCRBY`. Only one score-element pair can be specified in this mode.\n\nNote: The GT, LT and NX options are mutually exclusive.\nRange of integer scores that can be expressed precisely\nRedis sorted sets use a double 64-bit floating point number to represent the score. In all the architectures we support, this is represented as an IEEE 754 floating point number, that is able to represent precisely integer numbers between `-(2^53)` and `+(2^53)` included. In more practical terms, all the integers between -9007199254740992 and 9007199254740992 are perfectly representable. Larger integers, or fractions, are internally represented in exponential form, so it is possible that you get only an approximation of the decimal number, or of the very big integer, that you set as score.\nSorted sets 101\nSorted sets are sorted by their score in an ascending way.\nThe same element only exists a single time, no repeated elements are\npermitted. The score can be modified both by `ZADD` that will update the\nelement score, and as a side effect, its position on the sorted set, and\nby `ZINCRBY` that can be used in order to update the score relatively to its\nprevious value.\nThe current score of an element can be retrieved using the `ZSCORE` command,\nthat can also be used to verify if an element already exists or not.\nFor an introduction to sorted sets, see the data types page on sorted\nsets.\nElements with the same score\nWhile the same element can't be repeated in a sorted set since every element\nis unique, it is possible to add multiple different elements having the same score. When multiple elements have the same score, they are ordered lexicographically (they are still ordered by score as a first key, however, locally, all the elements with the same score are relatively ordered lexicographically).\nThe lexicographic ordering used is binary, it compares strings as array of bytes.\nIf the user inserts all the elements in a sorted set with the same score (for example 0), all the elements of the sorted set are sorted lexicographically, and range queries on elements are possible using the command `ZRANGEBYLEX` (Note: it is also possible to query sorted sets by range of scores using `ZRANGEBYSCORE`).\n@return\n@integer-reply, specifically:\n\nWhen used without optional arguments, the number of elements added to the sorted set (excluding score updates).\nIf the `CH` option is specified, the number of elements that were changed (added or updated).\n\nIf the `INCR` option is specified, the return value will be @bulk-string-reply:\n\nThe new score of `member` (a double precision floating point number) represented as string, or `nil` if the operation was aborted (when called with either the `XX` or the `NX` option).\n\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 1 \"uno\"\nZADD myzset 2 \"two\" 3 \"three\"\nZRANGE myzset 0 -1 WITHSCORES",
    "tag": "redis"
  },
  {
    "title": "Pattern: Reliable queue",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/rpoplpush.md",
    "content": "Atomically returns and removes the last element (tail) of the list stored at\n`source`, and pushes the element at the first element (head) of the list stored\nat `destination`.\nFor example: consider `source` holding the list `a,b,c`, and `destination`\nholding the list `x,y,z`.\nExecuting `RPOPLPUSH` results in `source` holding `a,b` and `destination`\nholding `c,x,y,z`.\nIf `source` does not exist, the value `nil` is returned and no operation is\nperformed.\nIf `source` and `destination` are the same, the operation is equivalent to\nremoving the last element from the list and pushing it as first element of the\nlist, so it can be considered as a list rotation command.\n@return\n@bulk-string-reply: the element being popped and pushed.\n@examples\n`cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nRPOPLPUSH mylist myotherlist\nLRANGE mylist 0 -1\nLRANGE myotherlist 0 -1`\nPattern: Reliable queue\nRedis is often used as a messaging server to implement processing of background\njobs or other kinds of messaging tasks.\nA simple form of queue is often obtained pushing values into a list in the\nproducer side, and waiting for this values in the consumer side using `RPOP`\n(using polling), or `BRPOP` if the client is better served by a blocking\noperation.\nHowever in this context the obtained queue is not reliable as messages can\nbe lost, for example in the case there is a network problem or if the consumer\ncrashes just after the message is received but before it can be processed.\n`RPOPLPUSH` (or `BRPOPLPUSH` for the blocking variant) offers a way to avoid\nthis problem: the consumer fetches the message and at the same time pushes it\ninto a processing list.\nIt will use the `LREM` command in order to remove the message from the\nprocessing list once the message has been processed.\nAn additional client may monitor the processing list for items that remain\nthere for too much time, pushing timed out items into the queue\nagain if needed.\nPattern: Circular list\nUsing `RPOPLPUSH` with the same source and destination key, a client can visit\nall the elements of an N-elements list, one after the other, in O(N) without\ntransferring the full list from the server to the client using a single `LRANGE`\noperation.\nThe above pattern works even if one or both of the following conditions occur:\n\nThere are multiple clients rotating the list: they'll fetch different \n  elements, until all the elements of the list are visited, and the process \n  restarts.\nOther clients are actively pushing new items at the end of the list.\n\nThe above makes it very simple to implement a system where a set of items must\nbe processed by N workers continuously as fast as possible.\nAn example is a monitoring system that must check that a set of web sites are\nreachable, with the smallest delay possible, using a number of parallel workers.\nNote that this implementation of workers is trivially scalable and reliable,\nbecause even if a message is lost the item is still in the queue and will be",
    "tag": "redis"
  },
  {
    "title": "command-getkeys.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/command-getkeys.md",
    "content": "Returns @array-reply of keys from a full Redis command.\n`COMMAND GETKEYS` is a helper command to let you find the keys\nfrom a full Redis command.\n`COMMAND` provides information on how to find the key names of each command (see `firstkey`, key specifications, and `movablekeys`),\nbut in some cases it's not possible to find keys of certain commands and then the entire command must be parsed to discover some / all key names.\nYou can use `COMMAND GETKEYS` or `COMMAND GETKEYSANDFLAGS` to discover key names directly from how Redis parses the commands.\n@return\n@array-reply: list of keys from your command.\n@examples\n```cli\nCOMMAND GETKEYS MSET a b c d e f\nCOMMAND GETKEYS EVAL \"not consulted\" 3 key1 key2 key3 arg1 arg2 arg3 argN\nCOMMAND GETKEYS SORT mylist ALPHA STORE outlist",
    "tag": "redis"
  },
  {
    "title": "Implementation details",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/hincrbyfloat.md",
    "content": "Increment the specified `field` of a hash stored at `key`, and representing a\nfloating point number, by the specified `increment`. If the increment value\nis negative, the result is to have the hash field value decremented instead of incremented.\nIf the field does not exist, it is set to `0` before performing the operation.\nAn error is returned if one of the following conditions occur:\n\nThe field contains a value of the wrong type (not a string).\nThe current field content or the specified increment are not parsable as a\n  double precision floating point number.\n\nThe exact behavior of this command is identical to the one of the `INCRBYFLOAT`\ncommand, please refer to the documentation of `INCRBYFLOAT` for further\ninformation.\n@return\n@bulk-string-reply: the value of `field` after the increment.\n@examples\n`cli\nHSET mykey field 10.50\nHINCRBYFLOAT mykey field 0.1\nHINCRBYFLOAT mykey field -5\nHSET mykey field 5.0e3\nHINCRBYFLOAT mykey field 2.0e2`\nImplementation details\nThe command is always propagated in the replication link and the Append Only\nFile as a `HSET` operation, so that differences in the underlying floating point",
    "tag": "redis"
  },
  {
    "title": "xlen.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xlen.md",
    "content": "Returns the number of entries inside a stream. If the specified key does not\nexist the command returns zero, as if the stream was empty.\nHowever note that unlike other Redis types, zero-length streams are\npossible, so you should call `TYPE` or `EXISTS` in order to check if\na key exists or not.\nStreams are not auto-deleted once they have no entries inside (for instance\nafter an `XDEL` call), because the stream may have consumer groups\nassociated with it.\n@return\n@integer-reply: the number of entries of the stream at `key`.\n@examples\n```cli\nXADD mystream * item 1\nXADD mystream * item 2\nXADD mystream * item 3\nXLEN mystream",
    "tag": "redis"
  },
  {
    "title": "client-id.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-id.md",
    "content": "The command just returns the ID of the current connection. Every connection\nID has certain guarantees:\n\nIt is never repeated, so if `CLIENT ID` returns the same number, the caller can be sure that the underlying client did not disconnect and reconnect the connection, but it is still the same connection.\nThe ID is monotonically incremental. If the ID of a connection is greater than the ID of another connection, it is guaranteed that the second connection was established with the server at a later time.\n\nThis command is especially useful together with `CLIENT UNBLOCK` which was\nintroduced also in Redis 5 together with `CLIENT ID`. Check the `CLIENT UNBLOCK` command page for a pattern involving the two commands.\n@examples\n`cli\nCLIENT ID`\n@return\n@integer-reply",
    "tag": "redis"
  },
  {
    "title": "object-encoding.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/object-encoding.md",
    "content": "Returns the internal encoding for the Redis object stored at `<key>`\nRedis objects can be encoded in different ways:\n\n\nStrings can be encoded as: \n\n`raw`, normal string encoding.\n`int`, strings representing integers in a 64-bit signed interval, encoded in this way to save space.\n`embstr`, an embedded string, which is an object where the internal simple dynamic string, `sds`, is an unmodifiable string allocated in the same chuck as the object itself.\n  `embstr` can be strings with lengths up to the hardcoded limit of `OBJ_ENCODING_EMBSTR_SIZE_LIMIT` or 44 bytes. \n\n\n\nLists can be encoded as `ziplist` or `linkedlist`. The `ziplist` is the special representation that is used to save space for small lists.\n\nSets can be encoded as `intset` or `hashtable`. The `intset` is a special encoding used for small sets composed solely of integers.\nHashes can be encoded as `ziplist` or `hashtable`. The `ziplist` is a special encoding used for small hashes.\nSorted Sets can be encoded as `ziplist` or `skiplist` format. As for the List type small sorted sets can be specially encoded using `ziplist`, while the `skiplist` encoding is the one that works with sorted sets of any size.\n\nAll the specially encoded types are automatically converted to the general type once you perform an operation that makes it impossible for Redis to retain the space saving encoding.\n@return",
    "tag": "redis"
  },
  {
    "title": "restore.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/restore.md",
    "content": "Create a key associated with a value that is obtained by deserializing the\nprovided serialized value (obtained via `DUMP`).\nIf `ttl` is 0 the key is created without any expire, otherwise the specified\nexpire time (in milliseconds) is set.\nIf the `ABSTTL` modifier was used, `ttl` should represent an absolute\nUnix timestamp (in milliseconds) in which the key will expire.\nFor eviction purposes, you may use the `IDLETIME` or `FREQ` modifiers. See\n`OBJECT` for more information.\n`!RESTORE` will return a \"Target key name is busy\" error when `key` already\nexists unless you use the `REPLACE` modifier.\n`!RESTORE` checks the RDB version and data checksum.\nIf they don't match an error is returned.\n@return\n@simple-string-reply: The command returns OK on success.\n@examples\n```\nredis> DEL mykey\n0\nredis> RESTORE mykey 0 \"\\n\\x17\\x17\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x03\\x00\\\n                        x00\\xc0\\x01\\x00\\x04\\xc0\\x02\\x00\\x04\\xc0\\x03\\x00\\\n                        xff\\x04\\x00u#<\\xc0;.\\xe9\\xdd\"\nOK\nredis> TYPE mykey\nlist\nredis> LRANGE mykey 0 -1\n1) \"1\"\n2) \"2\"\n3) \"3\"",
    "tag": "redis"
  },
  {
    "title": "script-kill.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/script-kill.md",
    "content": "Kills the currently executing `EVAL` script, assuming no write operation was yet\nperformed by the script.\nThis command is mainly useful to kill a script that is running for too much\ntime(for instance, because it entered an infinite loop because of a bug).\nThe script will be killed, and the client currently blocked into EVAL will see\nthe command returning with an error.\nIf the script has already performed write operations, it can not be killed in this\nway because it would violate Lua's script atomicity contract.\nIn such a case, only `SHUTDOWN NOSAVE` can kill the script, killing\nthe Redis process in a hard way and preventing it from persisting with half-written\ninformation.\nFor more information about `EVAL` scripts please refer to Introduction to Eval Scripts.\n@return",
    "tag": "redis"
  },
  {
    "title": "zintercard.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zintercard.md",
    "content": "This command is similar to `ZINTER`, but instead of returning the result set, it returns just the cardinality of the result.\nKeys that do not exist are considered to be empty sets.\nWith one of the keys being an empty set, the resulting set is also empty (since set intersection with an empty set always results in an empty set).\nBy default, the command calculates the cardinality of the intersection of all given sets.\nWhen provided with the optional `LIMIT` argument (which defaults to 0 and means unlimited), if the intersection cardinality reaches limit partway through the computation, the algorithm will exit and yield limit as the cardinality.\nSuch implementation ensures a significant speedup for queries where the limit is lower than the actual intersection cardinality.\n@return\n@integer-reply: the number of elements in the resulting intersection.\n@examples\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZADD zset2 3 \"three\"\nZINTER 2 zset1 zset2\nZINTERCARD 2 zset1 zset2\nZINTERCARD 2 zset1 zset2 LIMIT 1",
    "tag": "redis"
  },
  {
    "title": "function-load.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/function-load.md",
    "content": "Load a library to Redis.\nThe command's gets a single mandatory parameter which is the source code that implements the library.\nThe library payload must start with Shebang statement that provides a metadata about the library (like the engine to use and the library name).\nShebang format: `#!<engine name> name=<library name>`. Currently engine name must be `lua`.\nFor the Lua engine, the implementation should declare one or more entry points to the library with the redis.register_function() API.\nOnce loaded, you can call the functions in the library with the `FCALL` (or `FCALL_RO` when applicable) command.\nWhen attempting to load a library with a name that already exists, the Redis server returns an error.\nThe `REPLACE` modifier changes this behavior and overwrites the existing library with the new contents.\nThe command will return an error in the following circumstances:\n\nAn invalid engine-name was provided.\nThe library's name already exists without the `REPLACE` modifier.\nA function in the library is created with a name that already exists in another library (even when `REPLACE` is specified).\nThe engine failed in creating the library's functions (due to a compilation error, for example).\nNo functions were declared by the library.\n\nFor more information please refer to Introduction to Redis Functions.\n@return\n@string - the library name that was loaded\n@examples\nThe following example will create a library named `mylib` with a single function, `myfunc`, that returns the first argument it gets.\n```\nredis> FUNCTION LOAD \"#!lua name=mylib \\n redis.register_function('myfunc', function(keys, args) return args[1] end)\"\nmylib\nredis> FCALL myfunc 0 hello\n\"hello\"",
    "tag": "redis"
  },
  {
    "title": "Migrating multiple keys with a single command call",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/migrate.md",
    "content": "Atomically transfer a key from a source Redis instance to a destination Redis\ninstance.\nOn success the key is deleted from the original instance and is guaranteed to\nexist in the target instance.\nThe command is atomic and blocks the two instances for the time required to\ntransfer the key, at any given time the key will appear to exist in a given\ninstance or in the other instance, unless a timeout error occurs. In 3.2 and\nabove, multiple keys can be pipelined in a single call to `MIGRATE` by passing\nthe empty string (\"\") as key and adding the `!KEYS` clause.\nThe command internally uses `DUMP` to generate the serialized version of the key\nvalue, and `RESTORE` in order to synthesize the key in the target instance.\nThe source instance acts as a client for the target instance.\nIf the target instance returns OK to the `RESTORE` command, the source instance\ndeletes the key using `DEL`.\nThe timeout specifies the maximum idle time in any moment of the communication\nwith the destination instance in milliseconds.\nThis means that the operation does not need to be completed within the specified\namount of milliseconds, but that the transfer should make progresses without\nblocking for more than the specified amount of milliseconds.\n`MIGRATE` needs to perform I/O operations and to honor the specified timeout.\nWhen there is an I/O error during the transfer or if the timeout is reached the\noperation is aborted and the special error - `IOERR` returned.\nWhen this happens the following two cases are possible:\n\nThe key may be on both the instances.\nThe key may be only in the source instance.\n\nIt is not possible for the key to get lost in the event of a timeout, but the\nclient calling `MIGRATE`, in the event of a timeout error, should check if the\nkey is also present in the target instance and act accordingly.\nWhen any other error is returned (starting with `ERR`) `MIGRATE` guarantees that\nthe key is still only present in the originating instance (unless a key with the\nsame name was also already present on the target instance).\nIf there are no keys to migrate in the source instance `NOKEY` is returned.\nBecause missing keys are possible in normal conditions, from expiry for example,\n`NOKEY` isn't an error. \nMigrating multiple keys with a single command call\nStarting with Redis 3.0.6 `MIGRATE` supports a new bulk-migration mode that\nuses pipelining in order to migrate multiple keys between instances without\nincurring in the round trip time latency and other overheads that there are\nwhen moving each key with a single `MIGRATE` call.\nIn order to enable this form, the `!KEYS` option is used, and the normal key\nargument is set to an empty string. The actual key names will be provided\nafter the `!KEYS` argument itself, like in the following example:\n\n\n```MIGRATE 192.168.1.34 6379 \"\" 0 5000 KEYS key1 key2 key3\n```\n\n\nWhen this form is used the `NOKEY` status code is only returned when none\nof the keys is present in the instance, otherwise the command is executed, even if\njust a single key exists.\nOptions\n\n`!COPY` -- Do not remove the key from the local instance.\n`REPLACE` -- Replace existing key on the remote instance.\n`!KEYS` -- If the key argument is an empty string, the command will instead migrate all the keys that follow the `!KEYS` option (see the above section for more info).\n`!AUTH` -- Authenticate with the given password to the remote instance.\n`AUTH2` -- Authenticate with the given username and password pair (Redis 6 or greater ACL auth style).\n\n@return\n@simple-string-reply: The command returns OK on success, or `NOKEY` if no keys were",
    "tag": "redis"
  },
  {
    "title": "Pattern: Reliable queue",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lmove.md",
    "content": "Atomically returns and removes the first/last element (head/tail depending on\nthe `wherefrom` argument) of the list stored at `source`, and pushes the\nelement at the first/last element (head/tail depending on the `whereto`\nargument) of the list stored at `destination`.\nFor example: consider `source` holding the list `a,b,c`, and `destination`\nholding the list `x,y,z`.\nExecuting `LMOVE source destination RIGHT LEFT` results in `source` holding\n`a,b` and `destination` holding `c,x,y,z`.\nIf `source` does not exist, the value `nil` is returned and no operation is\nperformed.\nIf `source` and `destination` are the same, the operation is equivalent to\nremoving the first/last element from the list and pushing it as first/last\nelement of the list, so it can be considered as a list rotation command (or a\nno-op if `wherefrom` is the same as `whereto`).\nThis command comes in place of the now deprecated `RPOPLPUSH`. Doing\n`LMOVE RIGHT LEFT` is equivalent.\n@return\n@bulk-string-reply: the element being popped and pushed.\n@examples\n`cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nLMOVE mylist myotherlist RIGHT LEFT\nLMOVE mylist myotherlist LEFT RIGHT\nLRANGE mylist 0 -1\nLRANGE myotherlist 0 -1`\nPattern: Reliable queue\nRedis is often used as a messaging server to implement processing of background\njobs or other kinds of messaging tasks.\nA simple form of queue is often obtained pushing values into a list in the\nproducer side, and waiting for this values in the consumer side using `RPOP`\n(using polling), or `BRPOP` if the client is better served by a blocking\noperation.\nHowever in this context the obtained queue is not reliable as messages can\nbe lost, for example in the case there is a network problem or if the consumer\ncrashes just after the message is received but it is still to process.\n`LMOVE` (or `BLMOVE` for the blocking variant) offers a way to avoid\nthis problem: the consumer fetches the message and at the same time pushes it\ninto a processing list.\nIt will use the `LREM` command in order to remove the message from the\nprocessing list once the message has been processed.\nAn additional client may monitor the processing list for items that remain\nthere for too much time, and will push those timed out items into the queue\nagain if needed.\nPattern: Circular list\nUsing `LMOVE` with the same source and destination key, a client can visit\nall the elements of an N-elements list, one after the other, in O(N) without\ntransferring the full list from the server to the client using a single `LRANGE`\noperation.\nThe above pattern works even if the following two conditions:\n\nThere are multiple clients rotating the list: they'll fetch different\n  elements, until all the elements of the list are visited, and the process\n  restarts.\nEven if other clients are actively pushing new items at the end of the list.\n\nThe above makes it very simple to implement a system where a set of items must\nbe processed by N workers continuously as fast as possible.\nAn example is a monitoring system that must check that a set of web sites are\nreachable, with the smallest delay possible, using a number of parallel workers.\nNote that this implementation of workers is trivially scalable and reliable,\nbecause even if a message is lost the item is still in the queue and will be",
    "tag": "redis"
  },
  {
    "title": "xgroup-create.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xgroup-create.md",
    "content": "Create a new consumer group uniquely identified by `<groupname>` for the stream stored at `<key>`\nEvery group has a unique name in a given stream. \nWhen a consumer group with the same name already exists, the command returns a `-BUSYGROUP` error.\nThe command's `<id>` argument specifies the last delivered entry in the stream from the new group's perspective.\nThe special ID `$` is the ID of the last entry in the stream, but you can substitute it with any valid ID.\nFor example, if you want the group's consumers to fetch the entire stream from the beginning, use zero as the starting ID for the consumer group:\n\n\n```XGROUP CREATE mystream mygroup 0\n```\n\n\nBy default, the `XGROUP CREATE` command expects that the target stream exists, and returns an error when it doesn't.\nIf a stream does not exist, you can create it automatically with length of 0 by using the optional `MKSTREAM` subcommand as the last argument after the `<id>`:\n\n\n```XGROUP CREATE mystream mygroup $ MKSTREAM\n```\n\n\nTo enable consumer group lag tracking, specify the optional `entries_read` named argument with an arbitrary ID.\nAn arbitrary ID is any ID that isn't the ID of the stream's first entry, last entry, or zero (\"0-0\") ID.\nUse it to find out how many entries are between the arbitrary ID (excluding it) and the stream's last entry.\nSet the `entries_read` the stream's `entries_added` subtracted by the number of entries.\n@return",
    "tag": "redis"
  },
  {
    "title": "pttl.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pttl.md",
    "content": "Like `TTL` this command returns the remaining time to live of a key that has an\nexpire set, with the sole difference that `TTL` returns the amount of remaining\ntime in seconds while `PTTL` returns it in milliseconds.\nIn Redis 2.6 or older the command returns `-1` if the key does not exist or if the key exist but has no associated expire.\nStarting with Redis 2.8 the return value in case of error changed:\n\nThe command returns `-2` if the key does not exist.\nThe command returns `-1` if the key exists but has no associated expire.\n\n@return\n@integer-reply: TTL in milliseconds, or a negative value in order to signal an error (see the description above).\n@examples\n```cli\nSET mykey \"Hello\"\nEXPIRE mykey 1\nPTTL mykey",
    "tag": "redis"
  },
  {
    "title": "cluster-shards.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-shards.md",
    "content": "`CLUSTER SHARDS` returns details about the shards of the cluster.\nA shard is defined as a collection of nodes that serve the same set of slots and that replicate from each other.\nA shard may only have a single master at a given time, but may have multiple or no replicas.\nIt is possible for a shard to not be serving any slots while still having replicas.\nThis command replaces the `CLUSTER SLOTS` command, by providing a more efficient and extensible representation of the cluster. \nThe command is suitable to be used by Redis Cluster client libraries in order to understand the topology of the cluster.\nA client should issue this command on startup in order to retrieve the map associating cluster hash slots with actual node information.\nThis map should be used to direct commands to the node that is likely serving the slot associated with a given command.\nIn the event the command is sent to the wrong node, in that it received a '-MOVED' redirect, this command can then be used to update the topology of the cluster.\nThe command returns an array of shards, with each shard containing two fields, 'slots' and 'nodes'. \nThe 'slots' field is a list of slot ranges served by this shard, stored as pair of integers representing the inclusive start and end slots of the ranges.\nFor example, if a node owns the slots 1, 2, 3, 5, 7, 8 and 9, the slots ranges would be stored as [1-3], [5-5], [7-9].\nThe slots field would therefore be represented by the following list of integers.\n`1) 1) \"slots\"\n   2) 1) (integer) 1\n      2) (integer) 3\n      3) (integer) 5\n      4) (integer) 5\n      5) (integer) 7\n      6) (integer) 9`\nThe 'nodes' field contains a list of all nodes within the shard.\nEach individual node is a map of attributes that describe the node. \nSome attributes are optional and more attributes may be added in the future. \nThe current list of attributes:\n\nid: The unique node id for this particular node.\nendpoint: The preferred endpoint to reach the node, see below for more information about the possible values of this field.\nip: The IP address to send requests to for this node.\nhostname (optional): The announced hostname to send requests to for this node.\nport (optional): The TCP (non-TLS) port of the node. At least one of port or tls-port will be present.\ntls-port (optional): The TLS port of the node. At least one of port or tls-port will be present.\nrole: The replication role of this node.\nreplication-offset: The replication offset of this node. This information can be used to send commands to the most up to date replicas.\nhealth: Either `online`, `failed`, or `loading`. This information should be used to determine which nodes should be sent traffic. The `loading` health state should be used to know that a node is not currently eligible to serve traffic, but may be eligible in the future. \n\nThe endpoint, along with the port, defines the location that clients should use to send requests for a given slot.\nA NULL value for the endpoint indicates the node has an unknown endpoint and the client should connect to the same endpoint it used to send the `CLUSTER SHARDS` command but with the port returned from the command.\nThis unknown endpoint configuration is useful when the Redis nodes are behind a load balancer that Redis doesn't know the endpoint of.\nWhich endpoint is set is determined by the `cluster-preferred-endpoint-type` config.\n@return\n@array-reply: nested list of a map of hash ranges and shard nodes.\n@examples\n```\n\nCLUSTER SHARDS\n1) 1) \"slots\"\n   2) 1) (integer) 0\n      2) (integer) 5460\n   3) \"nodes\"\n   4) 1)  1) \"id\"\n          2) \"e10b7051d6bf2d5febd39a2be297bbaea6084111\"\n          3) \"port\"\n          4) (integer) 30001\n          5) \"ip\"\n          6) \"127.0.0.1\"\n          7) \"endpoint\"\n          8) \"127.0.0.1\"\n          9) \"role\"\n         10) \"master\"\n         11) \"replication-offset\"\n         12) (integer) 72156\n         13) \"health\"\n         14) \"online\"\n      2)  1) \"id\"\n          2) \"1901f5962d865341e81c85f9f596b1e7160c35ce\"\n          3) \"port\"\n          4) (integer) 30006\n          5) \"ip\"\n          6) \"127.0.0.1\"\n          7) \"endpoint\"\n          8) \"127.0.0.1\"\n          9) \"role\"\n         10) \"replica\"\n         11) \"replication-offset\"\n         12) (integer) 72156\n         13) \"health\"\n         14) \"online\"\n2) 1) \"slots\"\n   2) 1) (integer) 10923\n      2) (integer) 16383\n   3) \"nodes\"\n   4) 1)  1) \"id\"\n          2) \"fd20502fe1b32fc32c15b69b0a9537551f162f1f\"\n          3) \"port\"\n          4) (integer) 30003\n          5) \"ip\"\n          6) \"127.0.0.1\"\n          7) \"endpoint\"\n          8) \"127.0.0.1\"\n          9) \"role\"\n         10) \"master\"\n         11) \"replication-offset\"\n         12) (integer) 72156\n         13) \"health\"\n         14) \"online\"\n      2)  1) \"id\"\n          2) \"6daa25c08025a0c7e4cc0d1ab255949ce6cee902\"\n          3) \"port\"\n          4) (integer) 30005\n          5) \"ip\"\n          6) \"127.0.0.1\"\n          7) \"endpoint\"\n          8) \"127.0.0.1\"\n          9) \"role\"\n         10) \"replica\"\n         11) \"replication-offset\"\n         12) (integer) 72156\n         13) \"health\"\n         14) \"online\"\n3) 1) \"slots\"\n   2) 1) (integer) 5461\n      2) (integer) 10922\n   3) \"nodes\"\n   4) 1)  1) \"id\"\n          2) \"a4a3f445ead085eb3eb9ee7d8c644ec4481ec9be\"\n          3) \"port\"\n          4) (integer) 30002\n          5) \"ip\"\n          6) \"127.0.0.1\"\n          7) \"endpoint\"\n          8) \"127.0.0.1\"\n          9) \"role\"\n         10) \"master\"\n         11) \"replication-offset\"\n         12) (integer) 72156\n         13) \"health\"\n         14) \"online\"\n      2)  1) \"id\"\n          2) \"da6d5847aa019e9b9d2a8aa24a75f856fd3456cc\"\n          3) \"port\"\n          4) (integer) 30004\n          5) \"ip\"\n          6) \"127.0.0.1\"\n          7) \"endpoint\"\n          8) \"127.0.0.1\"\n          9) \"role\"\n         10) \"replica\"\n         11) \"replication-offset\"\n         12) (integer) 72156\n         13) \"health\"\n         14) \"online\"\n",
    "tag": "redis"
  },
  {
    "title": "zremrangebyrank.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zremrangebyrank.md",
    "content": "Removes all elements in the sorted set stored at `key` with rank between `start`\nand `stop`.\nBoth `start` and `stop` are `0` -based indexes with `0` being the element with\nthe lowest score.\nThese indexes can be negative numbers, where they indicate offsets starting at\nthe element with the highest score.\nFor example: `-1` is the element with the highest score, `-2` the element with\nthe second highest score and so forth.\n@return\n@integer-reply: the number of elements removed.\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREMRANGEBYRANK myzset 0 1\nZRANGE myzset 0 -1 WITHSCORES",
    "tag": "redis"
  },
  {
    "title": "msetnx.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/msetnx.md",
    "content": "Sets the given keys to their respective values.\n`MSETNX` will not perform any operation at all even if just a single key already\nexists.\nBecause of this semantic `MSETNX` can be used in order to set different keys\nrepresenting different fields of a unique logic object in a way that ensures\nthat either all the fields or none at all are set.\n`MSETNX` is atomic, so all given keys are set at once.\nIt is not possible for clients to see that some of the keys were updated while\nothers are unchanged.\n@return\n@integer-reply, specifically:\n\n`1` if the all the keys were set.\n`0` if no key was set (at least one key already existed).\n\n@examples\n```cli\nMSETNX key1 \"Hello\" key2 \"there\"\nMSETNX key2 \"new\" key3 \"world\"\nMGET key1 key2 key3",
    "tag": "redis"
  },
  {
    "title": "lpop.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lpop.md",
    "content": "Removes and returns the first elements of the list stored at `key`.\nBy default, the command pops a single element from the beginning of the list.\nWhen provided with the optional `count` argument, the reply will consist of up\nto `count` elements, depending on the list's length.\n@return\nWhen called without the `count` argument:\n@bulk-string-reply: the value of the first element, or `nil` when `key` does not exist.\nWhen called with the `count` argument:\n@array-reply: list of popped elements, or `nil` when `key` does not exist.\n@examples\n```cli\nRPUSH mylist \"one\" \"two\" \"three\" \"four\" \"five\"\nLPOP mylist\nLPOP mylist 2\nLRANGE mylist 0 -1",
    "tag": "redis"
  },
  {
    "title": "pfcount.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pfcount.md",
    "content": "When called with a single key, returns the approximated cardinality computed by the HyperLogLog data structure stored at the specified variable, which is 0 if the variable does not exist.\nWhen called with multiple keys, returns the approximated cardinality of the union of the HyperLogLogs passed, by internally merging the HyperLogLogs stored at the provided keys into a temporary HyperLogLog.\nThe HyperLogLog data structure can be used in order to count unique elements in a set using just a small constant amount of memory, specifically 12k bytes for every HyperLogLog (plus a few bytes for the key itself).\nThe returned cardinality of the observed set is not exact, but approximated with a standard error of 0.81%.\nFor example in order to take the count of all the unique search queries performed in a day, a program needs to call `PFADD` every time a query is processed. The estimated number of unique queries can be retrieved with `PFCOUNT` at any time.\nNote: as a side effect of calling this function, it is possible that the HyperLogLog is modified, since the last 8 bytes encode the latest computed cardinality\nfor caching purposes. So `PFCOUNT` is technically a write command.\n@return\n@integer-reply, specifically:\n\nThe approximated number of unique elements observed via `PFADD`.\n\n@examples\n`cli\nPFADD hll foo bar zap\nPFADD hll zap zap zap\nPFADD hll foo bar\nPFCOUNT hll\nPFADD some-other-hll 1 2 3\nPFCOUNT hll some-other-hll`\nPerformances\nWhen `PFCOUNT` is called with a single key, performances are excellent even if\nin theory constant times to process a dense HyperLogLog are high. This is\npossible because the `PFCOUNT` uses caching in order to remember the cardinality\npreviously computed, that rarely changes because most `PFADD` operations will\nnot update any register. Hundreds of operations per second are possible.\nWhen `PFCOUNT` is called with multiple keys, an on-the-fly merge of the\nHyperLogLogs is performed, which is slow, moreover the cardinality of the union\ncan't be cached, so when used with multiple keys `PFCOUNT` may take a time in\nthe order of magnitude of the millisecond, and should be not abused.\nThe user should take in mind that single-key and multiple-keys executions of\nthis command are semantically different and have different performances.\nHyperLogLog representation\nRedis HyperLogLogs are represented using a double representation: the sparse representation suitable for HLLs counting a small number of elements (resulting in a small number of registers set to non-zero value), and a dense representation suitable for higher cardinalities. Redis automatically switches from the sparse to the dense representation when needed.\nThe sparse representation uses a run-length encoding optimized to store efficiently a big number of registers set to zero. The dense representation is a Redis string of 12288 bytes in order to store 16384 6-bit counters. The need for the double representation comes from the fact that using 12k (which is the dense representation memory requirement) to encode just a few registers for smaller cardinalities is extremely suboptimal.\nBoth representations are prefixed with a 16 bytes header, that includes a magic, an encoding / version field, and the cached cardinality estimation computed, stored in little endian format (the most significant bit is 1 if the estimation is invalid since the HyperLogLog was updated since the cardinality was computed).\nThe HyperLogLog, being a Redis string, can be retrieved with `GET` and restored with `SET`. Calling `PFADD`, `PFCOUNT` or `PFMERGE` commands with a corrupted HyperLogLog is never a problem, it may return random values but does not affect the stability of the server. Most of the times when corrupting a sparse representation, the server recognizes the corruption and returns an error.\nThe representation is neutral from the point of view of the processor word size and endianness, so the same representation is used by 32 bit and 64 bit processor, big endian or little endian.",
    "tag": "redis"
  },
  {
    "title": "client-setname.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-setname.md",
    "content": "The `CLIENT SETNAME` command assigns a name to the current connection.\nThe assigned name is displayed in the output of `CLIENT LIST` so that it is possible to identify the client that performed a given connection.\nFor instance when Redis is used in order to implement a queue, producers and consumers of messages may want to set the name of the connection according to their role.\nThere is no limit to the length of the name that can be assigned if not the usual limits of the Redis string type (512 MB). However it is not possible to use spaces in the connection name as this would violate the format of the `CLIENT LIST` reply.\nIt is possible to entirely remove the connection name setting it to the empty string, that is not a valid connection name since it serves to this specific purpose.\nThe connection name can be inspected using `CLIENT GETNAME`.\nEvery new connection starts without an assigned name.\nTip: setting names to connections is a good way to debug connection leaks due to bugs in the application using Redis.\n@return",
    "tag": "redis"
  },
  {
    "title": "cluster-links.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-links.md",
    "content": "Each node in a Redis Cluster maintains a pair of long-lived TCP link with each peer in the cluster: One for sending outbound messages towards the peer and one for receiving inbound messages from the peer.\n`CLUSTER LINKS` outputs information of all such peer links as an array, where each array element is a map that contains attributes and their values for an individual link.\n@examples\nThe following is an example output:\n```\n\nCLUSTER LINKS\n1)  1) \"direction\"\n    2) \"to\"\n    3) \"node\"\n    4) \"8149d745fa551e40764fecaf7cab9dbdf6b659ae\"\n    5) \"create-time\"\n    6) (integer) 1639442739375\n    7) \"events\"\n    8) \"rw\"\n    9) \"send-buffer-allocated\"\n   10) (integer) 4512\n   11) \"send-buffer-used\"\n   12) (integer) 0\n2)  1) \"direction\"\n    2) \"from\"\n    3) \"node\"\n    4) \"8149d745fa551e40764fecaf7cab9dbdf6b659ae\"\n    5) \"create-time\"\n    6) (integer) 1639442739411\n    7) \"events\"\n    8) \"r\"\n    9) \"send-buffer-allocated\"\n   10) (integer) 0\n   11) \"send-buffer-used\"\n   12) (integer) 0\n```\n\nEach map is composed of the following attributes of the corresponding cluster link and their values:\n\n`direction`: This link is established by the local node `to` the peer, or accepted by the local node `from` the peer.\n`node`: The node id of the peer.\n`create-time`: Creation time of the link. (In the case of a `to` link, this is the time when the TCP link is created by the local node, not the time when it is actually established.)\n`events`: Events currently registered for the link. `r` means readable event, `w` means writable event.\n`send-buffer-allocated`: Allocated size of the link's send buffer, which is used to buffer outgoing messages toward the peer.\n`send-buffer-used`: Size of the portion of the link's send buffer that is currently holding data(messages).\n\n@return",
    "tag": "redis"
  },
  {
    "title": "Options",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pexpire.md",
    "content": "This command works exactly like `EXPIRE` but the time to live of the key is\nspecified in milliseconds instead of seconds.\nOptions\nThe `PEXPIRE` command supports a set of options since Redis 7.0:\n\n`NX` -- Set expiry only when the key has no expiry\n`XX` -- Set expiry only when the key has an existing expiry\n`GT` -- Set expiry only when the new expiry is greater than current one\n`LT` -- Set expiry only when the new expiry is less than current one\n\nA non-volatile key is treated as an infinite TTL for the purpose of `GT` and `LT`.\nThe `GT`, `LT` and `NX` options are mutually exclusive.\n@return\n@integer-reply, specifically:\n\n`1` if the timeout was set.\n`0` if the timeout was not set. e.g. key doesn't exist, or operation skipped due to the provided arguments.\n\n@examples\n```cli\nSET mykey \"Hello\"\nPEXPIRE mykey 1500\nTTL mykey\nPTTL mykey\nPEXPIRE mykey 1000 XX\nTTL mykey\nPEXPIRE mykey 1000 NX\nTTL mykey",
    "tag": "redis"
  },
  {
    "title": "lmpop.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lmpop.md",
    "content": "Pops one or more elements from the first non-empty list key from the list of provided key names.\n`LMPOP` and `BLMPOP` are similar to the following, more limited, commands:\n\n`LPOP` or `RPOP` which take only one key, and can return multiple elements.\n`BLPOP` or `BRPOP` which take multiple keys, but return only one element from just one key.\n\nSee `BLMPOP` for the blocking variant of this command.\nElements are popped from either the left or right of the first non-empty list based on the passed argument.\nThe number of returned elements is limited to the lower between the non-empty list's length, and the count argument (which defaults to 1).\n@return\n@array-reply: specifically:\n\nA `nil` when no element could be popped.\nA two-element array with the first element being the name of the key from which elements were popped, and the second element is an array of elements.\n\n@examples\n```cli\nLMPOP 2 non1 non2 LEFT COUNT 10\nLPUSH mylist \"one\" \"two\" \"three\" \"four\" \"five\"\nLMPOP 1 mylist LEFT\nLRANGE mylist 0 -1\nLMPOP 1 mylist RIGHT COUNT 10\nLPUSH mylist \"one\" \"two\" \"three\" \"four\" \"five\"\nLPUSH mylist2 \"a\" \"b\" \"c\" \"d\" \"e\"\nLMPOP 2 mylist mylist2 right count 3\nLRANGE mylist 0 -1\nLMPOP 2 mylist mylist2 right count 5\nLMPOP 2 mylist mylist2 right count 10\nEXISTS mylist mylist2",
    "tag": "redis"
  },
  {
    "title": "rpush.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/rpush.md",
    "content": "Insert all the specified values at the tail of the list stored at `key`.\nIf `key` does not exist, it is created as empty list before performing the push\noperation.\nWhen `key` holds a value that is not a list, an error is returned.\nIt is possible to push multiple elements using a single command call just\nspecifying multiple arguments at the end of the command.\nElements are inserted one after the other to the tail of the list, from the\nleftmost element to the rightmost element.\nSo for instance the command `RPUSH mylist a b c` will result into a list\ncontaining `a` as first element, `b` as second element and `c` as third element.\n@return\n@integer-reply: the length of the list after the push operation.\n@examples\n```cli\nRPUSH mylist \"hello\"\nRPUSH mylist \"world\"\nLRANGE mylist 0 -1",
    "tag": "redis"
  },
  {
    "title": "sintercard.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/sintercard.md",
    "content": "This command is similar to `SINTER`, but instead of returning the result set, it returns just the cardinality of the result.\nReturns the cardinality of the set which would result from the intersection of all the given sets.\nKeys that do not exist are considered to be empty sets.\nWith one of the keys being an empty set, the resulting set is also empty (since set intersection with an empty set always results in an empty set).\nBy default, the command calculates the cardinality of the intersection of all given sets.\nWhen provided with the optional `LIMIT` argument (which defaults to 0 and means unlimited), if the intersection cardinality reaches limit partway through the computation, the algorithm will exit and yield limit as the cardinality.\nSuch implementation ensures a significant speedup for queries where the limit is lower than the actual intersection cardinality.\n@return\n@integer-reply: the number of elements in the resulting intersection.\n@examples\n```cli\nSADD key1 \"a\"\nSADD key1 \"b\"\nSADD key1 \"c\"\nSADD key1 \"d\"\nSADD key2 \"c\"\nSADD key2 \"d\"\nSADD key2 \"e\"\nSINTER key1 key2\nSINTERCARD 2 key1 key2\nSINTERCARD 2 key1 key2 LIMIT 1",
    "tag": "redis"
  },
  {
    "title": "ping.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/ping.md",
    "content": "Returns `PONG` if no argument is provided, otherwise return a copy of the\nargument as a bulk.\nThis command is useful for:\n1. Testing whether a connection is still alive.\n1. Verifying the server's ability to serve data - an error is returned when this isn't the case (e.g., during load from persistence or accessing a stale replica).\n1. Measuring latency.\nIf the client is subscribed to a channel or a pattern, it will instead return a\nmulti-bulk with a \"pong\" in the first position and an empty bulk in the second\nposition, unless an argument is provided in which case it returns a copy\nof the argument.\n@return\n@simple-string-reply, and specifically `PONG`, when no argument is provided.\n@bulk-string-reply the argument provided, when applicable.\n@examples\n```cli\nPING\nPING \"hello world\"",
    "tag": "redis"
  },
  {
    "title": "Design pattern: Locking with `!SETNX`",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/setnx.md",
    "content": "Set `key` to hold string `value` if `key` does not exist.\nIn that case, it is equal to `SET`.\nWhen `key` already holds a value, no operation is performed.\n`SETNX` is short for \"SET if Not eXists\".\n@return\n@integer-reply, specifically:\n\n`1` if the key was set\n`0` if the key was not set\n\n@examples\n`cli\nSETNX mykey \"Hello\"\nSETNX mykey \"World\"\nGET mykey`\nDesign pattern: Locking with `!SETNX`\nPlease note that:\n\nThe following pattern is discouraged in favor of the Redlock algorithm which is only a bit more complex to implement, but offers better guarantees and is fault tolerant.\nWe document the old pattern anyway because certain existing implementations link to this page as a reference. Moreover it is an interesting example of how Redis commands can be used in order to mount programming primitives.\nAnyway even assuming a single-instance locking primitive, starting with 2.6.12 it is possible to create a much simpler locking primitive, equivalent to the one discussed here, using the `SET` command to acquire the lock, and a simple Lua script to release the lock. The pattern is documented in the `SET` command page.\n\nThat said, `SETNX` can be used, and was historically used, as a locking primitive. For example, to acquire the lock of the key `foo`, the client could try the\nfollowing:\n`SETNX lock.foo <current Unix time + lock timeout + 1>`\nIf `SETNX` returns `1` the client acquired the lock, setting the `lock.foo` key\nto the Unix time at which the lock should no longer be considered valid.\nThe client will later use `DEL lock.foo` in order to release the lock.\nIf `SETNX` returns `0` the key is already locked by some other client.\nWe can either return to the caller if it's a non blocking lock, or enter a loop\nretrying to hold the lock until we succeed or some kind of timeout expires.\nHandling deadlocks\nIn the above locking algorithm there is a problem: what happens if a client\nfails, crashes, or is otherwise not able to release the lock?\nIt's possible to detect this condition because the lock key contains a UNIX\ntimestamp.\nIf such a timestamp is equal to the current Unix time the lock is no longer\nvalid.\nWhen this happens we can't just call `DEL` against the key to remove the lock\nand then try to issue a `SETNX`, as there is a race condition here, when\nmultiple clients detected an expired lock and are trying to release it.\n\nC1 and C2 read `lock.foo` to check the timestamp, because they both received\n  `0` after executing `SETNX`, as the lock is still held by C3 that crashed\n  after holding the lock.\nC1 sends `DEL lock.foo`\nC1 sends `SETNX lock.foo` and it succeeds\nC2 sends `DEL lock.foo`\nC2 sends `SETNX lock.foo` and it succeeds\nERROR: both C1 and C2 acquired the lock because of the race condition.\n\nFortunately, it's possible to avoid this issue using the following algorithm.\nLet's see how C4, our sane client, uses the good algorithm:\n\n\nC4 sends `SETNX lock.foo` in order to acquire the lock\n\n\nThe crashed client C3 still holds it, so Redis will reply with `0` to C4.\n\n\nC4 sends `GET lock.foo` to check if the lock expired.\n    If it is not, it will sleep for some time and retry from the start.\n\n\nInstead, if the lock is expired because the Unix time at `lock.foo` is older\n    than the current Unix time, C4 tries to perform:\n`GETSET lock.foo <current Unix timestamp + lock timeout + 1>`\n\n\nBecause of the `GETSET` semantic, C4 can check if the old value stored at\n    `key` is still an expired timestamp.\n    If it is, the lock was acquired.\n\n\nIf another client, for instance C5, was faster than C4 and acquired the lock\n    with the `GETSET` operation, the C4 `GETSET` operation will return a non\n    expired timestamp.\n    C4 will simply restart from the first step.\n    Note that even if C4 set the key a bit a few seconds in the future this is\n    not a problem.\n\n\nIn order to make this locking algorithm more robust, a\nclient holding a lock should always check the timeout didn't expire before\nunlocking the key with `DEL` because client failures can be complex, not just\ncrashing but also blocking a lot of time against some operations and trying\nto issue `DEL` after a lot of time (when the LOCK is already held by another",
    "tag": "redis"
  },
  {
    "title": "command-getkeysandflags.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/command-getkeysandflags.md",
    "content": "Returns @array-reply of keys from a full Redis command and their usage flags.\n`COMMAND GETKEYSANDFLAGS` is a helper command to let you find the keys from a full Redis command together with flags indicating what each key is used for.\n`COMMAND` provides information on how to find the key names of each command (see `firstkey`, key specifications, and `movablekeys`),\nbut in some cases it's not possible to find keys of certain commands and then the entire command must be parsed to discover some / all key names.\nYou can use `COMMAND GETKEYS` or `COMMAND GETKEYSANDFLAGS` to discover key names directly from how Redis parses the commands.\nRefer to key specifications for information about the meaning of the key flags.\n@return\n@array-reply: list of keys from your command.\nEach element of the array is an array containing key name in the first entry, and flags in the second.\n@examples\n```cli\nCOMMAND GETKEYS MSET a b c d e f\nCOMMAND GETKEYS EVAL \"not consulted\" 3 key1 key2 key3 arg1 arg2 arg3 argN\nCOMMAND GETKEYSANDFLAGS LMOVE mylist1 mylist2 left left",
    "tag": "redis"
  },
  {
    "title": "bzpopmax.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bzpopmax.md",
    "content": "`BZPOPMAX` is the blocking variant of the sorted set `ZPOPMAX` primitive.\nIt is the blocking version because it blocks the connection when there are no\nmembers to pop from any of the given sorted sets.\nA member with the highest score is popped from first sorted set that is\nnon-empty, with the given keys being checked in the order that they are given.\nThe `timeout` argument is interpreted as a double value specifying the maximum\nnumber of seconds to block. A timeout of zero can be used to block indefinitely.\nSee the BZPOPMIN documentation for the exact semantics, since `BZPOPMAX`\nis identical to `BZPOPMIN` with the only difference being that it pops members\nwith the highest scores instead of popping the ones with the lowest scores.\n@return\n@array-reply: specifically:\n\nA `nil` multi-bulk when no element could be popped and the timeout expired.\nA three-element multi-bulk with the first element being the name of the key\n  where a member was popped, the second element is the popped member itself,\n  and the third element is the score of the popped element.\n\n@examples\n```\nredis> DEL zset1 zset2\n(integer) 0\nredis> ZADD zset1 0 a 1 b 2 c\n(integer) 3\nredis> BZPOPMAX zset1 zset2 0\n1) \"zset1\"\n2) \"c\"\n3) \"2\"",
    "tag": "redis"
  },
  {
    "title": "srem.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/srem.md",
    "content": "Remove the specified members from the set stored at `key`.\nSpecified members that are not a member of this set are ignored.\nIf `key` does not exist, it is treated as an empty set and this command returns\n`0`.\nAn error is returned when the value stored at `key` is not a set.\n@return\n@integer-reply: the number of members that were removed from the set, not\nincluding non existing members.\n@examples\n```cli\nSADD myset \"one\"\nSADD myset \"two\"\nSADD myset \"three\"\nSREM myset \"one\"\nSREM myset \"four\"\nSMEMBERS myset",
    "tag": "redis"
  },
  {
    "title": "sunsubscribe.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/sunsubscribe.md",
    "content": "Unsubscribes the client from the given shard channels, or from all of them if none is given.\nWhen no shard channels are specified, the client is unsubscribed from all the previously subscribed shard channels. \nIn this case a message for every unsubscribed shard channel will be sent to the client. \nNote: The global channels and shard channels needs to be unsubscribed from separately.\nFor more information about sharded Pub/Sub, see Sharded Pub/Sub.\n@return\nWhen successful, this command doesn't return anything.",
    "tag": "redis"
  },
  {
    "title": "Supported subcommands and integer encoding",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bitfield.md",
    "content": "The command treats a Redis string as an array of bits, and is capable of addressing specific integer fields of varying bit widths and arbitrary non (necessary) aligned offset. In practical terms using this command you can set, for example, a signed 5 bits integer at bit offset 1234 to a specific value, retrieve a 31 bit unsigned integer from offset 4567. Similarly the command handles increments and decrements of the specified integers, providing guaranteed and well specified overflow and underflow behavior that the user can configure.\n`BITFIELD` is able to operate with multiple bit fields in the same command call. It takes a list of operations to perform, and returns an array of replies, where each array matches the corresponding operation in the list of arguments.\nFor example the following command increments a 5 bit signed integer at bit offset 100, and gets the value of the 4 bit unsigned integer at bit offset 0:\n\n\n```> BITFIELD mykey INCRBY i5 100 1 GET u4 0\n1) (integer) 1\n2) (integer) 0\n```\n\n\nNote that:\n\nAddressing with `!GET` bits outside the current string length (including the case the key does not exist at all), results in the operation to be performed like the missing part all consists of bits set to 0.\nAddressing with `!SET` or `!INCRBY` bits outside the current string length will enlarge the string, zero-padding it, as needed, for the minimal length needed, according to the most far bit touched.\n\nSupported subcommands and integer encoding\nThe following is the list of supported commands.\n\nGET `<encoding>` `<offset>` -- Returns the specified bit field.\nSET `<encoding>` `<offset>` `<value>` -- Set the specified bit field and returns its old value.\nINCRBY `<encoding>` `<offset>` `<increment>` -- Increments or decrements (if a negative increment is given) the specified bit field and returns the new value.\n\nThere is another subcommand that only changes the behavior of successive\n`!INCRBY` and `!SET` subcommands calls by setting the overflow behavior:\n\nOVERFLOW `[WRAP|SAT|FAIL]`\n\nWhere an integer encoding is expected, it can be composed by prefixing with `i` for signed integers and `u` for unsigned integers with the number of bits of our integer encoding. So for example `u8` is an unsigned integer of 8 bits and `i16` is a\nsigned integer of 16 bits.\nThe supported encodings are up to 64 bits for signed integers, and up to 63 bits for\nunsigned integers. This limitation with unsigned integers is due to the fact\nthat currently the Redis protocol is unable to return 64 bit unsigned integers\nas replies.\nBits and positional offsets\nThere are two ways in order to specify offsets in the bitfield command.\nIf a number without any prefix is specified, it is used just as a zero based\nbit offset inside the string.\nHowever if the offset is prefixed with a `#` character, the specified offset\nis multiplied by the integer encoding's width, so for example:\n\n\n```BITFIELD mystring SET i8 #0 100 SET i8 #1 200\n```\n\n\nWill set the first i8 integer at offset 0 and the second at offset 8.\nThis way you don't have to do the math yourself inside your client if what\nyou want is a plain array of integers of a given size.\nOverflow control\nUsing the `OVERFLOW` command the user is able to fine-tune the behavior of\nthe increment or decrement overflow (or underflow) by specifying one of\nthe following behaviors:\n\nWRAP: wrap around, both with signed and unsigned integers. In the case of unsigned integers, wrapping is like performing the operation modulo the maximum value the integer can contain (the C standard behavior). With signed integers instead wrapping means that overflows restart towards the most negative value and underflows towards the most positive ones, so for example if an `i8` integer is set to the value 127, incrementing it by 1 will yield `-128`.\nSAT: uses saturation arithmetic, that is, on underflows the value is set to the minimum integer value, and on overflows to the maximum integer value. For example incrementing an `i8` integer starting from value 120 with an increment of 10, will result into the value 127, and further increments will always keep the value at 127. The same happens on underflows, but towards the value is blocked at the most negative value.\nFAIL: in this mode no operation is performed on overflows or underflows detected. The corresponding return value is set to NULL to signal the condition to the caller.\n\nNote that each `OVERFLOW` statement only affects the `!INCRBY` and `!SET`\ncommands that follow it in the list of subcommands, up to the next `OVERFLOW`\nstatement.\nBy default, WRAP is used if not otherwise specified.\n\n\n```> BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1\n1) (integer) 1\n2) (integer) 1\n> BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1\n1) (integer) 2\n2) (integer) 2\n> BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1\n1) (integer) 3\n2) (integer) 3\n> BITFIELD mykey incrby u2 100 1 OVERFLOW SAT incrby u2 102 1\n1) (integer) 0\n2) (integer) 3\n```\n\n\nReturn value\nThe command returns an array with each entry being the corresponding result of\nthe sub command given at the same position. `OVERFLOW` subcommands don't count\nas generating a reply.\nThe following is an example of `OVERFLOW FAIL` returning NULL.\n\n\n```> BITFIELD mykey OVERFLOW FAIL incrby u2 102 1\n1) (nil)\n```\n\n\nMotivations\nThe motivation for this command is that the ability to store many small integers\nas a single large bitmap (or segmented over a few keys to avoid having huge keys) is extremely memory efficient, and opens new use cases for Redis to be applied, especially in the field of real time analytics. This use cases are supported by the ability to specify the overflow in a controlled way.\nFun fact: Reddit's 2017 April fools' project r/place was built using the Redis BITFIELD command in order to take an in-memory representation of the collaborative canvas.\nPerformance considerations\nUsually `BITFIELD` is a fast command, however note that addressing far bits of currently short strings will trigger an allocation that may be more costly than executing the command on bits already existing.\nOrders of bits\nThe representation used by `BITFIELD` considers the bitmap as having the\nbit number 0 to be the most significant bit of the first byte, and so forth, so\nfor example setting a 5 bits unsigned integer to value 23 at offset 7 into a\nbitmap previously set to all zeroes, will produce the following representation:\n\n\n```+--------+--------+\n|00000001|01110000|\n+--------+--------+\n```\n\n\nWhen offsets and integer sizes are aligned to bytes boundaries, this is the\nsame as big endian, however when such alignment does not exist, its important",
    "tag": "redis"
  },
  {
    "title": "Behavior change history",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/script-flush.md",
    "content": "Flush the Lua scripts cache.\nBy default, `SCRIPT FLUSH` will synchronously flush the cache.\nStarting with Redis 6.2, setting the lazyfree-lazy-user-flush configuration directive to \"yes\" changes the default flush mode to asynchronous.\nIt is possible to use one of the following modifiers to dictate the flushing mode explicitly:\n\n`ASYNC`: flushes the cache asynchronously\n`!SYNC`: flushes the cache synchronously\n\nFor more information about `EVAL` scripts please refer to Introduction to Eval Scripts.\n@return\n@simple-string-reply\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "brpop.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/brpop.md",
    "content": "`BRPOP` is a blocking list pop primitive.\nIt is the blocking version of `RPOP` because it blocks the connection when there\nare no elements to pop from any of the given lists.\nAn element is popped from the tail of the first list that is non-empty, with the\ngiven keys being checked in the order that they are given.\nSee the BLPOP documentation for the exact semantics, since `BRPOP` is\nidentical to `BLPOP` with the only difference being that it pops elements from\nthe tail of a list instead of popping from the head.\n@return\n@array-reply: specifically:\n\nA `nil` multi-bulk when no element could be popped and the timeout expired.\nA two-element multi-bulk with the first element being the name of the key\n  where an element was popped and the second element being the value of the\n  popped element.\n\n@examples\n```\nredis> DEL list1 list2\n(integer) 0\nredis> RPUSH list1 a b c\n(integer) 3\nredis> BRPOP list1 list2 0\n1) \"list1\"\n2) \"c\"",
    "tag": "redis"
  },
  {
    "title": "FORCE option: manual failover when the master is down",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-failover.md",
    "content": "This command, that can only be sent to a Redis Cluster replica node, forces\nthe replica to start a manual failover of its master instance.\nA manual failover is a special kind of failover that is usually executed when\nthere are no actual failures, but we wish to swap the current master with one\nof its replicas (which is the node we send the command to), in a safe way,\nwithout any window for data loss. It works in the following way:\n\nThe replica tells the master to stop processing queries from clients.\nThe master replies to the replica with the current replication offset.\nThe replica waits for the replication offset to match on its side, to make sure it processed all the data from the master before it continues.\nThe replica starts a failover, obtains a new configuration epoch from the majority of the masters, and broadcasts the new configuration.\nThe old master receives the configuration update: unblocks its clients and starts replying with redirection messages so that they'll continue the chat with the new master.\n\nThis way clients are moved away from the old master to the new master\natomically and only when the replica that is turning into the new master\nhas processed all of the replication stream from the old master.\nFORCE option: manual failover when the master is down\nThe command behavior can be modified by two options: FORCE and TAKEOVER.\nIf the FORCE option is given, the replica does not perform any handshake\nwith the master, that may be not reachable, but instead just starts a\nfailover ASAP starting from point 4. This is useful when we want to start\na manual failover while the master is no longer reachable.\nHowever using FORCE we still need the majority of masters to be available\nin order to authorize the failover and generate a new configuration epoch\nfor the replica that is going to become master.\nTAKEOVER option: manual failover without cluster consensus\nThere are situations where this is not enough, and we want a replica to failover\nwithout any agreement with the rest of the cluster. A real world use case\nfor this is to mass promote replicas in a different data center to masters\nin order to perform a data center switch, while all the masters are down\nor partitioned away.\nThe TAKEOVER option implies everything FORCE implies, but also does\nnot uses any cluster authorization in order to failover. A replica receiving\n`CLUSTER FAILOVER TAKEOVER` will instead:\n\nGenerate a new `configEpoch` unilaterally, just taking the current greatest epoch available and incrementing it if its local configuration epoch is not already the greatest.\nAssign itself all the hash slots of its master, and propagate the new configuration to every node which is reachable ASAP, and eventually to every other node.\n\nNote that TAKEOVER violates the last-failover-wins principle of Redis Cluster, since the configuration epoch generated by the replica violates the normal generation of configuration epochs in several ways:\n\nThere is no guarantee that it is actually the higher configuration epoch, since, for example, we can use the TAKEOVER option within a minority, nor any message exchange is performed to generate the new configuration epoch.\nIf we generate a configuration epoch which happens to collide with another instance, eventually our configuration epoch, or the one of another instance with our same epoch, will be moved away using the configuration epoch collision resolution algorithm.\n\nBecause of this the TAKEOVER option should be used with care.\nImplementation details and notes\n\n`CLUSTER FAILOVER`, unless the TAKEOVER option is specified, does not execute a failover synchronously.\n  It only schedules a manual failover, bypassing the failure detection stage.\nAn `OK` reply is no guarantee that the failover will succeed.\nA replica can only be promoted to a master if it is known as a replica by a majority of the masters in the cluster.\n  If the replica is a new node that has just been added to the cluster (for example after upgrading it), it may not yet be known to all the masters in the cluster.\n  To check that the masters are aware of a new replica, you can send `CLUSTER NODES` or `CLUSTER REPLICAS` to each of the master nodes and check that it appears as a replica, before sending `CLUSTER FAILOVER` to the replica.\nTo check that the failover has actually happened you can use `ROLE`, `INFO REPLICATION` (which indicates \"role:master\" after successful failover), or `CLUSTER NODES` to verify that the state of the cluster has changed sometime after the command was sent.\nTo check if the failover has failed, check the replica's log for \"Manual failover timed out\", which is logged if the replica has given up after a few seconds.\n\n@return",
    "tag": "redis"
  },
  {
    "title": "cluster-reset.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-reset.md",
    "content": "Reset a Redis Cluster node, in a more or less drastic way depending on the\nreset type, that can be hard or soft. Note that this command\ndoes not work for masters if they hold one or more keys, in that case\nto completely reset a master node keys must be removed first, e.g. by using `FLUSHALL` first,\nand then `CLUSTER RESET`.\nEffects on the node:\n\nAll the other nodes in the cluster are forgotten.\nAll the assigned / open slots are reset, so the slots-to-nodes mapping is totally cleared.\nIf the node is a replica it is turned into an (empty) master. Its dataset is flushed, so at the end the node will be an empty master.\nHard reset only: a new Node ID is generated.\nHard reset only: `currentEpoch` and `configEpoch` vars are set to 0.\nThe new configuration is persisted on disk in the node cluster configuration file.\n\nThis command is mainly useful to re-provision a Redis Cluster node\nin order to be used in the context of a new, different cluster. The command\nis also extensively used by the Redis Cluster testing framework in order to\nreset the state of the cluster every time a new test unit is executed.\nIf no reset type is specified, the default is soft.\n@return",
    "tag": "redis"
  },
  {
    "title": "eval.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/eval.md",
    "content": "Invoke the execution of a server-side Lua script.\nThe first argument is the script's source code.\nScripts are written in Lua and executed by the embedded Lua 5.1 interpreter in Redis.\nThe second argument is the number of input key name arguments, followed by all the keys accessed by the script.\nThese names of input keys are available to the script as the KEYS global runtime variable\nAny additional input arguments should not represent names of keys.\nImportant:\nto ensure the correct execution of scripts, both in standalone and clustered deployments, all names of keys that a script accesses must be explicitly provided as input key arguments.\nThe script should only access keys whose names are given as input arguments.\nScripts should never access keys with programmatically-generated names or based on the contents of data structures stored in the database.\nPlease refer to the Redis Programmability and Introduction to Eval Scripts for more information about Lua scripts.\n@examples\nThe following example will run a script that returns the first argument that it gets.\n```\n\nEVAL \"return ARGV[1]\" 0 hello\n\"hello\"\n",
    "tag": "redis"
  },
  {
    "title": "lrem.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lrem.md",
    "content": "Removes the first `count` occurrences of elements equal to `element` from the list\nstored at `key`.\nThe `count` argument influences the operation in the following ways:\n\n`count > 0`: Remove elements equal to `element` moving from head to tail.\n`count < 0`: Remove elements equal to `element` moving from tail to head.\n`count = 0`: Remove all elements equal to `element`.\n\nFor example, `LREM list -2 \"hello\"` will remove the last two occurrences of\n`\"hello\"` in the list stored at `list`.\nNote that non-existing keys are treated like empty lists, so when `key` does not\nexist, the command will always return `0`.\n@return\n@integer-reply: the number of removed elements.\n@examples\n```cli\nRPUSH mylist \"hello\"\nRPUSH mylist \"hello\"\nRPUSH mylist \"foo\"\nRPUSH mylist \"hello\"\nLREM mylist -2 \"hello\"\nLRANGE mylist 0 -1",
    "tag": "redis"
  },
  {
    "title": "select.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/select.md",
    "content": "Select the Redis logical database having the specified zero-based numeric index.\nNew connections always use the database 0.\nSelectable Redis databases are a form of namespacing: all databases are still persisted in the same RDB / AOF file. However different databases can have keys with the same name, and commands like `FLUSHDB`, `SWAPDB` or `RANDOMKEY` work on specific databases.\nIn practical terms, Redis databases should be used to separate different keys belonging to the same application (if needed), and not to use a single Redis instance for multiple unrelated applications.\nWhen using Redis Cluster, the `SELECT` command cannot be used, since Redis Cluster only supports database zero. In the case of a Redis Cluster, having multiple databases would be useless and an unnecessary source of complexity. Commands operating atomically on a single database would not be possible with the Redis Cluster design and goals.\nSince the currently selected database is a property of the connection, clients should track the currently selected database and re-select it on reconnection. While there is no command in order to query the selected database in the current connection, the `CLIENT LIST` output shows, for each client, the currently selected database.\n@return",
    "tag": "redis"
  },
  {
    "title": "slaveof.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/slaveof.md",
    "content": "A note about the word slave used in this man page and command name: starting with Redis version 5, if not for backward compatibility, the Redis project no longer uses the word slave. Please use the new command `REPLICAOF`. The command `SLAVEOF` will continue to work for backward compatibility.\nThe `SLAVEOF` command can change the replication settings of a replica on the fly.\nIf a Redis server is already acting as replica, the command `SLAVEOF` NO ONE will\nturn off the replication, turning the Redis server into a MASTER.\nIn the proper form `SLAVEOF` hostname port will make the server a replica of\nanother server listening at the specified hostname and port.\nIf a server is already a replica of some master, `SLAVEOF` hostname port will stop\nthe replication against the old server and start the synchronization against the\nnew one, discarding the old dataset.\nThe form `SLAVEOF` NO ONE will stop replication, turning the server into a\nMASTER, but will not discard the replication.\nSo, if the old master stops working, it is possible to turn the replica into a\nmaster and set the application to use this new master in read/write.\nLater when the other Redis server is fixed, it can be reconfigured to work as a\nreplica.\n@return",
    "tag": "redis"
  },
  {
    "title": "Specification of the behavior when count is passed",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/srandmember.md",
    "content": "When called with just the `key` argument, return a random element from the set value stored at `key`.\nIf the provided `count` argument is positive, return an array of distinct elements.\nThe array's length is either `count` or the set's cardinality (`SCARD`), whichever is lower.\nIf called with a negative `count`, the behavior changes and the command is allowed to return the same element multiple times.\nIn this case, the number of returned elements is the absolute value of the specified `count`.\n@return\n@bulk-string-reply: without the additional `count` argument, the command returns a Bulk Reply with the randomly selected element, or `nil` when `key` does not exist.\n@array-reply: when the additional `count` argument is passed, the command returns an array of elements, or an empty array when `key` does not exist.\n@examples\n`cli\nSADD myset one two three\nSRANDMEMBER myset\nSRANDMEMBER myset 2\nSRANDMEMBER myset -5`\nSpecification of the behavior when count is passed\nWhen the `count` argument is a positive value this command behaves as follows:\n\nNo repeated elements are returned.\nIf `count` is bigger than the set's cardinality, the command will only return the whole set without additional elements.\nThe order of elements in the reply is not truly random, so it is up to the client to shuffle them if needed.\n\nWhen the `count` is a negative value, the behavior changes as follows:\n\nRepeating elements are possible.\nExactly `count` elements, or an empty array if the set is empty (non-existing key), are always returned.\nThe order of elements in the reply is truly random.\n\nDistribution of returned elements\nNote: this section is relevant only for Redis 5 or below, as Redis 6 implements a fairer algorithm. \nThe distribution of the returned elements is far from perfect when the number of elements in the set is small, this is due to the fact that we used an approximated random element function that does not really guarantees good distribution.\nThe algorithm used, that is implemented inside dict.c, samples the hash table buckets to find a non-empty one. Once a non empty bucket is found, since we use chaining in our hash table implementation, the number of elements inside the bucket is checked and a random element is selected.",
    "tag": "redis"
  },
  {
    "title": "cluster-info.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-info.md",
    "content": "`CLUSTER INFO` provides `INFO` style information about Redis Cluster vital parameters.\nThe following fields are always present in the reply:\n`cluster_state:ok\ncluster_slots_assigned:16384\ncluster_slots_ok:16384\ncluster_slots_pfail:0\ncluster_slots_fail:0\ncluster_known_nodes:6\ncluster_size:3\ncluster_current_epoch:6\ncluster_my_epoch:2\ncluster_stats_messages_sent:1483972\ncluster_stats_messages_received:1483968\ntotal_cluster_links_buffer_limit_exceeded:0`\n\n`cluster_state`: State is `ok` if the node is able to receive queries. `fail` if there is at least one hash slot which is unbound (no node associated), in error state (node serving it is flagged with FAIL flag), or if the majority of masters can't be reached by this node.\n`cluster_slots_assigned`: Number of slots which are associated to some node (not unbound). This number should be 16384 for the node to work properly, which means that each hash slot should be mapped to a node.\n`cluster_slots_ok`: Number of hash slots mapping to a node not in `FAIL` or `PFAIL` state.\n`cluster_slots_pfail`: Number of hash slots mapping to a node in `PFAIL` state. Note that those hash slots still work correctly, as long as the `PFAIL` state is not promoted to `FAIL` by the failure detection algorithm. `PFAIL` only means that we are currently not able to talk with the node, but may be just a transient error.\n`cluster_slots_fail`: Number of hash slots mapping to a node in `FAIL` state. If this number is not zero the node is not able to serve queries unless `cluster-require-full-coverage` is set to `no` in the configuration.\n`cluster_known_nodes`: The total number of known nodes in the cluster, including nodes in `HANDSHAKE` state that may not currently be proper members of the cluster.\n`cluster_size`: The number of master nodes serving at least one hash slot in the cluster.\n`cluster_current_epoch`: The local `Current Epoch` variable. This is used in order to create unique increasing version numbers during fail overs.\n`cluster_my_epoch`: The `Config Epoch` of the node we are talking with. This is the current configuration version assigned to this node.\n`cluster_stats_messages_sent`: Number of messages sent via the cluster node-to-node binary bus.\n`cluster_stats_messages_received`: Number of messages received via the cluster node-to-node binary bus.\n`total_cluster_links_buffer_limit_exceeded`: Accumulated count of cluster links freed due to exceeding the `cluster-link-sendbuf-limit` configuration.\n\nThe following message-related fields may be included in the reply if the value is not 0:\nEach message type includes statistics on the number of messages sent and received.\nHere are the explanation of these fields:\n\n`cluster_stats_messages_ping_sent` and `cluster_stats_messages_ping_received`: Cluster bus PING (not to be confused with the client command `PING`).\n`cluster_stats_messages_pong_sent` and `cluster_stats_messages_pong_received`: PONG (reply to PING).\n`cluster_stats_messages_meet_sent` and `cluster_stats_messages_meet_received`: Handshake message sent to a new node, either through gossip or `CLUSTER MEET`.\n`cluster_stats_messages_fail_sent` and `cluster_stats_messages_fail_received`: Mark node xxx as failing.\n`cluster_stats_messages_publish_sent` and `cluster_stats_messages_publish_received`: Pub/Sub Publish propagation, see Pubsub.\n`cluster_stats_messages_auth-req_sent` and `cluster_stats_messages_auth-req_received`: Replica initiated leader election to replace its master.\n`cluster_stats_messages_auth-ack_sent` and `cluster_stats_messages_auth-ack_received`: Message indicating a vote during leader election.\n`cluster_stats_messages_update_sent` and `cluster_stats_messages_update_received`: Another node slots configuration.\n`cluster_stats_messages_mfstart_sent` and `cluster_stats_messages_mfstart_received`: Pause clients for manual failover.\n`cluster_stats_messages_module_sent` and `cluster_stats_messages_module_received`: Module cluster API message.\n`cluster_stats_messages_publishshard_sent` and `cluster_stats_messages_publishshard_received`: Pub/Sub Publish shard propagation, see Sharded Pubsub.\n\nMore information about the Current Epoch and Config Epoch variables are available in the Redis Cluster specification document.\n@return",
    "tag": "redis"
  },
  {
    "title": "zrevrangebylex.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrevrangebylex.md",
    "content": "When all the elements in a sorted set are inserted with the same score, in order to force lexicographical ordering, this command returns all the elements in the sorted set at `key` with a value between `max` and `min`.\nApart from the reversed ordering, `ZREVRANGEBYLEX` is similar to `ZRANGEBYLEX`.\n@return\n@array-reply: list of elements in the specified score range.\n@examples\n```cli\nZADD myzset 0 a 0 b 0 c 0 d 0 e 0 f 0 g\nZREVRANGEBYLEX myzset [c -\nZREVRANGEBYLEX myzset (c -\nZREVRANGEBYLEX myzset (g [aaa",
    "tag": "redis"
  },
  {
    "title": "eval_ro.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/eval_ro.md",
    "content": "This is a read-only variant of the `EVAL` command that cannot execute commands that modify data.\nFor more information about when to use this command vs `EVAL`, please refer to Read-only scripts.\nFor more information about `EVAL` scripts please refer to Introduction to Eval Scripts.\n@examples\n```\n\nSET mykey \"Hello\"\nOK\nEVAL_RO \"return redis.call('GET', KEYS[1])\" 1 mykey\n\"Hello\"\nEVAL_RO \"return redis.call('DEL', KEYS[1])\" 1 mykey\n(error) ERR Error running script (call to b0d697da25b13e49157b2c214a4033546aba2104): @user_script:1: @user_script: 1: Write commands are not allowed from read-only scripts.\n",
    "tag": "redis"
  },
  {
    "title": "client-reply.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-reply.md",
    "content": "Sometimes it can be useful for clients to completely disable replies from the Redis server. For example when the client sends fire and forget commands or performs a mass loading of data, or in caching contexts where new data is streamed constantly. In such contexts to use server time and bandwidth in order to send back replies to clients, which are going to be ignored, is considered wasteful.\nThe `CLIENT REPLY` command controls whether the server will reply the client's commands. The following modes are available:\n\n`ON`. This is the default mode in which the server returns a reply to every command.\n`OFF`. In this mode the server will not reply to client commands.\n`SKIP`. This mode skips the reply of command immediately after it.\n\n@return\nWhen called with either `OFF` or `SKIP` subcommands, no reply is made. When called with `ON`:",
    "tag": "redis"
  },
  {
    "title": "xack.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xack.md",
    "content": "The `XACK` command removes one or multiple messages from the\nPending Entries List (PEL) of a stream consumer group. A message is pending,\nand as such stored inside the PEL, when it was delivered to some consumer,\nnormally as a side effect of calling `XREADGROUP`, or when a consumer took\nownership of a message calling `XCLAIM`. The pending message was delivered to\nsome consumer but the server is yet not sure it was processed at least once.\nSo new calls to `XREADGROUP` to grab the messages history for a consumer\n(for instance using an ID of 0), will return such message.\nSimilarly the pending message will be listed by the `XPENDING` command,\nthat inspects the PEL.\nOnce a consumer successfully processes a message, it should call `XACK`\nso that such message does not get processed again, and as a side effect,\nthe PEL entry about this message is also purged, releasing memory from the\nRedis server.\n@return\n@integer-reply, specifically:\nThe command returns the number of messages successfully acknowledged.\nCertain message IDs may no longer be part of the PEL (for example because\nthey have already been acknowledged), and XACK will not count them as\nsuccessfully acknowledged.\n@examples\n```\nredis> XACK mystream mygroup 1526569495631-0\n(integer) 1",
    "tag": "redis"
  },
  {
    "title": "zmpop.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zmpop.md",
    "content": "Pops one or more elements, that are member-score pairs, from the first non-empty sorted set in the provided list of key names.\n`ZMPOP` and `BZMPOP` are similar to the following, more limited, commands:\n\n`ZPOPMIN` or `ZPOPMAX` which take only one key, and can return multiple elements.\n`BZPOPMIN` or `BZPOPMAX` which take multiple keys, but return only one element from just one key.\n\nSee `BZMPOP` for the blocking variant of this command.\nWhen the `MIN` modifier is used, the elements popped are those with the lowest scores from the first non-empty sorted set. The `MAX` modifier causes elements with the highest scores to be popped.\nThe optional `COUNT` can be used to specify the number of elements to pop, and is set to 1 by default.\nThe number of popped elements is the minimum from the sorted set's cardinality and `COUNT`'s value.\n@return\n@array-reply: specifically:\n\nA `nil` when no element could be popped.\nA two-element array with the first element being the name of the key from which elements were popped, and the second element is an array of the popped elements. Every entry in the elements array is also an array that contains the member and its score.\n\n@examples\n```cli\nZMPOP 1 notsuchkey MIN\nZADD myzset 1 \"one\" 2 \"two\" 3 \"three\"\nZMPOP 1 myzset MIN\nZRANGE myzset 0 -1 WITHSCORES\nZMPOP 1 myzset MAX COUNT 10\nZADD myzset2 4 \"four\" 5 \"five\" 6 \"six\"\nZMPOP 2 myzset myzset2 MIN COUNT 10\nZRANGE myzset 0 -1 WITHSCORES\nZMPOP 2 myzset myzset2 MAX COUNT 10\nZRANGE myzset2 0 -1 WITHSCORES\nEXISTS myzset myzset2",
    "tag": "redis"
  },
  {
    "title": "Distribution of returned elements",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/spop.md",
    "content": "Removes and returns one or more random members from the set value store at `key`.\nThis operation is similar to `SRANDMEMBER`, that returns one or more random elements from a set but does not remove it.\nBy default, the command pops a single member from the set. When provided with\nthe optional `count` argument, the reply will consist of up to `count` members,\ndepending on the set's cardinality.\n@return\nWhen called without the `count` argument:\n@bulk-string-reply: the removed member, or `nil` when `key` does not exist.\nWhen called with the `count` argument:\n@array-reply: the removed members, or an empty array when `key` does not exist.\n@examples\n`cli\nSADD myset \"one\"\nSADD myset \"two\"\nSADD myset \"three\"\nSPOP myset\nSMEMBERS myset\nSADD myset \"four\"\nSADD myset \"five\"\nSPOP myset 3\nSMEMBERS myset`\nDistribution of returned elements",
    "tag": "redis"
  },
  {
    "title": "ssubscribe.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/ssubscribe.md",
    "content": "Subscribes the client to the specified shard channels.\nIn a Redis cluster, shard channels are assigned to slots by the same algorithm used to assign keys to slots. \nClient(s) can subscribe to a node covering a slot (primary/replica) to receive the messages published. \nAll the specified shard channels needs to belong to a single slot to subscribe in a given `SSUBSCRIBE` call,\nA client can subscribe to channels across different slots over separate `SSUBSCRIBE` call.\nFor more information about sharded Pub/Sub, see Sharded Pub/Sub.\n@return\nWhen successful, this command doesn't return anything.\nInstead, for each shard channel, one message with the first element being the string \"ssubscribe\" is pushed as a confirmation that the command succeeded.\nNote that this command can also return a -MOVED redirect.\n@examples\n```\n\nssubscribe orders\nReading messages... (press Ctrl-C to quit)\n1) \"ssubscribe\"\n2) \"orders\"\n3) (integer) 1\n1) \"smessage\"\n2) \"orders\"\n3) \"hello\"\n",
    "tag": "redis"
  },
  {
    "title": "zpopmax.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zpopmax.md",
    "content": "Removes and returns up to `count` members with the highest scores in the sorted\nset stored at `key`.\nWhen left unspecified, the default value for `count` is 1. Specifying a `count`\nvalue that is higher than the sorted set's cardinality will not produce an\nerror. When returning multiple elements, the one with the highest score will\nbe the first, followed by the elements with lower scores.\n@return\n@array-reply: list of popped elements and scores.\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZPOPMAX myzset",
    "tag": "redis"
  },
  {
    "title": "Pattern: Counter",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/incr.md",
    "content": "Increments the number stored at `key` by one.\nIf the key does not exist, it is set to `0` before performing the operation.\nAn error is returned if the key contains a value of the wrong type or contains a\nstring that can not be represented as integer.\nThis operation is limited to 64 bit signed integers.\nNote: this is a string operation because Redis does not have a dedicated\ninteger type.\nThe string stored at the key is interpreted as a base-10 64 bit signed\ninteger to execute the operation.\nRedis stores integers in their integer representation, so for string values\nthat actually hold an integer, there is no overhead for storing the string\nrepresentation of the integer.\n@return\n@integer-reply: the value of `key` after the increment\n@examples\n`cli\nSET mykey \"10\"\nINCR mykey\nGET mykey`\nPattern: Counter\nThe counter pattern is the most obvious thing you can do with Redis atomic\nincrement operations.\nThe idea is simply send an `INCR` command to Redis every time an operation\noccurs.\nFor instance in a web application we may want to know how many page views this\nuser did every day of the year.\nTo do so the web application may simply increment a key every time the user\nperforms a page view, creating the key name concatenating the User ID and a\nstring representing the current date.\nThis simple pattern can be extended in many ways:\n\nIt is possible to use `INCR` and `EXPIRE` together at every page view to have\n  a counter counting only the latest N page views separated by less than the\n  specified amount of seconds.\nA client may use GETSET in order to atomically get the current counter value\n  and reset it to zero.\nUsing other atomic increment/decrement commands like `DECR` or `INCRBY` it\n  is possible to handle values that may get bigger or smaller depending on the\n  operations performed by the user.\n  Imagine for instance the score of different users in an online game.\n\nPattern: Rate limiter\nThe rate limiter pattern is a special counter that is used to limit the rate at\nwhich an operation can be performed.\nThe classical materialization of this pattern involves limiting the number of\nrequests that can be performed against a public API.\nWe provide two implementations of this pattern using `INCR`, where we assume\nthat the problem to solve is limiting the number of API calls to a maximum of\nten requests per second per IP address.\nPattern: Rate limiter 1\nThe more simple and direct implementation of this pattern is the following:\n`FUNCTION LIMIT_API_CALL(ip)\nts = CURRENT_UNIX_TIME()\nkeyname = ip+\":\"+ts\nMULTI\n    INCR(keyname)\n    EXPIRE(keyname,10)\nEXEC\ncurrent = RESPONSE_OF_INCR_WITHIN_MULTI\nIF current > 10 THEN\n    ERROR \"too many requests per second\"\nELSE\n    PERFORM_API_CALL()\nEND`\nBasically we have a counter for every IP, for every different second.\nBut this counters are always incremented setting an expire of 10 seconds so that\nthey'll be removed by Redis automatically when the current second is a different\none.\nNote the used of `MULTI` and `EXEC` in order to make sure that we'll both\nincrement and set the expire at every API call.\nPattern: Rate limiter 2\nAn alternative implementation uses a single counter, but is a bit more complex\nto get it right without race conditions.\nWe'll examine different variants.\n`FUNCTION LIMIT_API_CALL(ip):\ncurrent = GET(ip)\nIF current != NULL AND current > 10 THEN\n    ERROR \"too many requests per second\"\nELSE\n    value = INCR(ip)\n    IF value == 1 THEN\n        EXPIRE(ip,1)\n    END\n    PERFORM_API_CALL()\nEND`\nThe counter is created in a way that it only will survive one second, starting\nfrom the first request performed in the current second.\nIf there are more than 10 requests in the same second the counter will reach a\nvalue greater than 10, otherwise it will expire and start again from 0.\nIn the above code there is a race condition.\nIf for some reason the client performs the `INCR` command but does not perform\nthe `EXPIRE` the key will be leaked until we'll see the same IP address again.\nThis can be fixed easily turning the `INCR` with optional `EXPIRE` into a Lua\nscript that is send using the `EVAL` command (only available since Redis version\n2.6).\n`local current\ncurrent = redis.call(\"incr\",KEYS[1])\nif current == 1 then\n    redis.call(\"expire\",KEYS[1],1)\nend`\nThere is a different way to fix this issue without using scripting, by using\nRedis lists instead of counters.\nThe implementation is more complex and uses more advanced features but has the\nadvantage of remembering the IP addresses of the clients currently performing an\nAPI call, that may be useful or not depending on the application.\n`FUNCTION LIMIT_API_CALL(ip)\ncurrent = LLEN(ip)\nIF current > 10 THEN\n    ERROR \"too many requests per second\"\nELSE\n    IF EXISTS(ip) == FALSE\n        MULTI\n            RPUSH(ip,ip)\n            EXPIRE(ip,1)\n        EXEC\n    ELSE\n        RPUSHX(ip,ip)\n    END\n    PERFORM_API_CALL()\nEND`\nThe `RPUSHX` command only pushes the element if the key already exists.\nNote that we have a race here, but it is not a problem: `EXISTS` may return\nfalse but the key may be created by another client before we create it inside\nthe `MULTI` / `EXEC` block.\nHowever this race will just miss an API call under rare conditions, so the rate",
    "tag": "redis"
  },
  {
    "title": "Implementation details",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/incrbyfloat.md",
    "content": "Increment the string representing a floating point number stored at `key` by the\nspecified `increment`. By using a negative `increment` value, the result is\nthat the value stored at the key is decremented (by the obvious properties\nof addition).\nIf the key does not exist, it is set to `0` before performing the operation.\nAn error is returned if one of the following conditions occur:\n\nThe key contains a value of the wrong type (not a string).\nThe current key content or the specified increment are not parsable as a\n  double precision floating point number.\n\nIf the command is successful the new incremented value is stored as the new\nvalue of the key (replacing the old one), and returned to the caller as a\nstring.\nBoth the value already contained in the string key and the increment argument\ncan be optionally provided in exponential notation, however the value computed\nafter the increment is stored consistently in the same format, that is, an\ninteger number followed (if needed) by a dot, and a variable number of digits\nrepresenting the decimal part of the number.\nTrailing zeroes are always removed.\nThe precision of the output is fixed at 17 digits after the decimal point\nregardless of the actual internal precision of the computation.\n@return\n@bulk-string-reply: the value of `key` after the increment.\n@examples\n`cli\nSET mykey 10.50\nINCRBYFLOAT mykey 0.1\nINCRBYFLOAT mykey -5\nSET mykey 5.0e3\nINCRBYFLOAT mykey 2.0e2`\nImplementation details\nThe command is always propagated in the replication link and the Append Only\nFile as a `SET` operation, so that differences in the underlying floating point",
    "tag": "redis"
  },
  {
    "title": "Notes",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/info.md",
    "content": "The `INFO` command returns information and statistics about the server in a\nformat that is simple to parse by computers and easy to read by humans.\nThe optional parameter can be used to select a specific section of information:\n\n`server`: General information about the Redis server\n`clients`: Client connections section\n`memory`: Memory consumption related information\n`persistence`: RDB and AOF related information\n`stats`: General statistics\n`replication`: Master/replica replication information\n`cpu`: CPU consumption statistics\n`commandstats`: Redis command statistics\n`latencystats`: Redis command latency percentile distribution statistics\n`sentinel`: Redis Sentinel section (only applicable to Sentinel instances)\n`cluster`: Redis Cluster section\n`modules`: Modules section\n`keyspace`: Database related statistics\n`modules`: Module related sections\n`errorstats`: Redis error statistics\n\nIt can also take the following values:\n\n`all`: Return all sections (excluding module generated ones)\n`default`: Return only the default set of sections\n`everything`: Includes `all` and `modules`\n\nWhen no parameter is provided, the `default` option is assumed.\n@return\n@bulk-string-reply: as a collection of text lines.\nLines can contain a section name (starting with a # character) or a property.\nAll the properties are in the form of `field:value` terminated by `\\r\\n`.\n`cli\nINFO`\nNotes\nPlease note depending on the version of Redis some of the fields have been\nadded or removed. A robust client application should therefore parse the\nresult of this command by skipping unknown properties, and gracefully handle\nmissing fields.\nHere is the description of fields for Redis >= 2.4.\nHere is the meaning of all fields in the server section:\n\n`redis_version`: Version of the Redis server\n`redis_git_sha1`:  Git SHA1\n`redis_git_dirty`: Git dirty flag\n`redis_build_id`: The build id\n`redis_mode`: The server's mode (\"standalone\", \"sentinel\" or \"cluster\")\n`os`: Operating system hosting the Redis server\n`arch_bits`: Architecture (32 or 64 bits)\n`multiplexing_api`: Event loop mechanism used by Redis\n`atomicvar_api`: Atomicvar API used by Redis\n`gcc_version`: Version of the GCC compiler used to compile the Redis server\n`process_id`: PID of the server process\n`process_supervised`: Supervised system (\"upstart\", \"systemd\", \"unknown\" or \"no\")\n`run_id`: Random value identifying the Redis server (to be used by Sentinel\n     and Cluster)\n`tcp_port`: TCP/IP listen port\n`server_time_usec`: Epoch-based system time with microsecond precision\n`uptime_in_seconds`: Number of seconds since Redis server start\n`uptime_in_days`: Same value expressed in days\n`hz`: The server's current frequency setting\n`configured_hz`: The server's configured frequency setting\n`lru_clock`: Clock incrementing every minute, for LRU management\n`executable`: The path to the server's executable\n`config_file`: The path to the config file\n`io_threads_active`: Flag indicating if I/O threads are active\n`shutdown_in_milliseconds`: The maximum time remaining for replicas to catch up the replication before completing the shutdown sequence.\n    This field is only present during shutdown.\n\nHere is the meaning of all fields in the clients section:\n\n`connected_clients`: Number of client connections (excluding connections\n     from replicas)\n`cluster_connections`: An approximation of the number of sockets used by the\n     cluster's bus\n`maxclients`: The value of the `maxclients` configuration directive. This is\n    the upper limit for the sum of `connected_clients`, `connected_slaves` and\n    `cluster_connections`.\n`client_recent_max_input_buffer`: Biggest input buffer among current client connections\n`client_recent_max_output_buffer`: Biggest output buffer among current client connections\n`blocked_clients`: Number of clients pending on a blocking call (`BLPOP`,\n     `BRPOP`, `BRPOPLPUSH`, `BLMOVE`, `BZPOPMIN`, `BZPOPMAX`)\n`tracking_clients`: Number of clients being tracked (`CLIENT TRACKING`)\n`clients_in_timeout_table`: Number of clients in the clients timeout table\n\nHere is the meaning of all fields in the memory section:\n\n`used_memory`: Total number of bytes allocated by Redis using its\n     allocator (either standard libc, jemalloc, or an alternative\n     allocator such as tcmalloc)\n`used_memory_human`: Human readable representation of previous value\n`used_memory_rss`: Number of bytes that Redis allocated as seen by the\n     operating system (a.k.a resident set size). This is the number reported by\n     tools such as `top(1)` and `ps(1)`\n`used_memory_rss_human`: Human readable representation of previous value\n`used_memory_peak`: Peak memory consumed by Redis (in bytes)\n`used_memory_peak_human`: Human readable representation of previous value\n`used_memory_peak_perc`: The percentage of `used_memory_peak` out of\n     `used_memory`\n`used_memory_overhead`: The sum in bytes of all overheads that the server\n     allocated for managing its internal data structures\n`used_memory_startup`: Initial amount of memory consumed by Redis at startup\n     in bytes\n`used_memory_dataset`: The size in bytes of the dataset\n     (`used_memory_overhead` subtracted from `used_memory`)\n`used_memory_dataset_perc`: The percentage of `used_memory_dataset` out of\n     the net memory usage (`used_memory` minus `used_memory_startup`)\n`total_system_memory`: The total amount of memory that the Redis host has\n`total_system_memory_human`: Human readable representation of previous value\n`used_memory_lua`: Number of bytes used by the Lua engine\n`used_memory_lua_human`: Human readable representation of previous value\n`used_memory_scripts`: Number of bytes used by cached Lua scripts\n`used_memory_scripts_human`: Human readable representation of previous value\n`maxmemory`: The value of the `maxmemory` configuration directive\n`maxmemory_human`: Human readable representation of previous value\n`maxmemory_policy`: The value of the `maxmemory-policy` configuration\n     directive\n`mem_fragmentation_ratio`: Ratio between `used_memory_rss` and `used_memory`.\n    Note that this doesn't only includes fragmentation, but also other process overheads (see the `allocator_*` metrics), and also overheads like code, shared libraries, stack, etc.\n`mem_fragmentation_bytes`: Delta between `used_memory_rss` and `used_memory`.\n    Note that when the total fragmentation bytes is low (few megabytes), a high ratio (e.g. 1.5 and above) is not an indication of an issue.\n`allocator_frag_ratio:`: Ratio between `allocator_active` and `allocator_allocated`. This is the true (external) fragmentation metric (not `mem_fragmentation_ratio`).\n`allocator_frag_bytes` Delta between `allocator_active` and `allocator_allocated`. See note about `mem_fragmentation_bytes`.\n`allocator_rss_ratio`: Ratio between `allocator_resident` and `allocator_active`. This usually indicates pages that the allocator can and probably will soon release back to the OS.\n`allocator_rss_bytes`: Delta between `allocator_resident` and `allocator_active`\n`rss_overhead_ratio`: Ratio between `used_memory_rss` (the process RSS) and `allocator_resident`. This includes RSS overheads that are not allocator or heap related.\n`rss_overhead_bytes`: Delta between `used_memory_rss` (the process RSS) and `allocator_resident`\n`allocator_allocated`: Total bytes allocated form the allocator, including internal-fragmentation. Normally the same as `used_memory`.\n`allocator_active`: Total bytes in the allocator active pages, this includes external-fragmentation.\n`allocator_resident`: Total bytes resident (RSS) in the allocator, this includes pages that can be released to the OS (by `MEMORY PURGE`, or just waiting).\n`mem_not_counted_for_evict`: Used memory that's not counted for key eviction. This is basically transient replica and AOF buffers.\n`mem_clients_slaves`: Memory used by replica clients - Starting Redis 7.0, replica buffers share memory with the replication backlog, so this field can show 0 when replicas don't trigger an increase of memory usage.\n`mem_clients_normal`: Memory used by normal clients\n`mem_cluster_links`: Memory used by links to peers on the cluster bus when cluster mode is enabled.\n`mem_aof_buffer`: Transient memory used for AOF and AOF rewrite buffers\n`mem_replication_backlog`: Memory used by replication backlog\n`mem_total_replication_buffers`: Total memory consumed for replication buffers - Added in Redis 7.0.\n`mem_allocator`: Memory allocator, chosen at compile time.\n`active_defrag_running`: When `activedefrag` is enabled, this indicates whether defragmentation is currently active, and the CPU percentage it intends to utilize.\n`lazyfree_pending_objects`: The number of objects waiting to be freed (as a\n     result of calling `UNLINK`, or `FLUSHDB` and `FLUSHALL` with the ASYNC\n     option)\n`lazyfreed_objects`: The number of objects that have been lazy freed.\n\nIdeally, the `used_memory_rss` value should be only slightly higher than\n`used_memory`.\nWhen rss >> used, a large difference may mean there is (external) memory fragmentation, which can be evaluated by checking\n`allocator_frag_ratio`, `allocator_frag_bytes`.\nWhen used >> rss, it means part of Redis memory has been swapped off by the\noperating system: expect some significant latencies.\nBecause Redis does not have control over how its allocations are mapped to\nmemory pages, high `used_memory_rss` is often the result of a spike in memory\nusage.\nWhen Redis frees memory, the memory is given back to the allocator, and the\nallocator may or may not give the memory back to the system. There may be\na discrepancy between the `used_memory` value and memory consumption as\nreported by the operating system. It may be due to the fact memory has been\nused and released by Redis, but not given back to the system. The\n`used_memory_peak` value is generally useful to check this point.\nAdditional introspective information about the server's memory can be obtained\nby referring to the `MEMORY STATS` command and the `MEMORY DOCTOR`.\nHere is the meaning of all fields in the persistence section:\n\n`loading`: Flag indicating if the load of a dump file is on-going\n`async_loading`: Currently loading replication data-set asynchronously while serving old data. This means `repl-diskless-load` is enabled and set to `swapdb`. Added in Redis 7.0.\n`current_cow_peak`: The peak size in bytes of copy-on-write memory\n     while a child fork is running\n`current_cow_size`: The size in bytes of copy-on-write memory\n     while a child fork is running\n`current_cow_size_age`: The age, in seconds, of the `current_cow_size` value.\n`current_fork_perc`: The percentage of progress of the current fork process. For AOF and RDB forks it is the percentage of `current_save_keys_processed` out of `current_save_keys_total`.\n`current_save_keys_processed`: Number of keys processed by the current save operation\n`current_save_keys_total`: Number of keys at the beginning of the current save operation \n`rdb_changes_since_last_save`: Number of changes since the last dump\n`rdb_bgsave_in_progress`: Flag indicating a RDB save is on-going\n`rdb_last_save_time`: Epoch-based timestamp of last successful RDB save\n`rdb_last_bgsave_status`: Status of the last RDB save operation\n`rdb_last_bgsave_time_sec`: Duration of the last RDB save operation in\n     seconds\n`rdb_current_bgsave_time_sec`: Duration of the on-going RDB save operation\n     if any\n`rdb_last_cow_size`: The size in bytes of copy-on-write memory during\n     the last RDB save operation\n`rdb_last_load_keys_expired`: Number of volatile keys deleted during the last RDB loading. Added in Redis 7.0.\n`rdb_last_load_keys_loaded`: Number of keys loaded during the last RDB loading. Added in Redis 7.0.\n`aof_enabled`: Flag indicating AOF logging is activated\n`aof_rewrite_in_progress`: Flag indicating a AOF rewrite operation is\n     on-going\n`aof_rewrite_scheduled`: Flag indicating an AOF rewrite operation\n     will be scheduled once the on-going RDB save is complete.\n`aof_last_rewrite_time_sec`: Duration of the last AOF rewrite operation in\n     seconds\n`aof_current_rewrite_time_sec`: Duration of the on-going AOF rewrite\n     operation if any\n`aof_last_bgrewrite_status`: Status of the last AOF rewrite operation\n`aof_last_write_status`: Status of the last write operation to the AOF\n`aof_last_cow_size`: The size in bytes of copy-on-write memory during\n     the last AOF rewrite operation\n`module_fork_in_progress`: Flag indicating a module fork is on-going\n`module_fork_last_cow_size`: The size in bytes of copy-on-write memory\n     during the last module fork operation\n`aof_rewrites`: Number of AOF rewrites performed since startup\n`rdb_saves`: Number of RDB snapshots performed since startup\n\n`rdb_changes_since_last_save` refers to the number of operations that produced\nsome kind of changes in the dataset since the last time either `SAVE` or\n`BGSAVE` was called.\nIf AOF is activated, these additional fields will be added:\n\n`aof_current_size`: AOF current file size\n`aof_base_size`: AOF file size on latest startup or rewrite\n`aof_pending_rewrite`: Flag indicating an AOF rewrite operation\n     will be scheduled once the on-going RDB save is complete.\n`aof_buffer_length`: Size of the AOF buffer\n`aof_rewrite_buffer_length`: Size of the AOF rewrite buffer. Note this field was removed in Redis 7.0\n`aof_pending_bio_fsync`: Number of fsync pending jobs in background I/O\n     queue\n`aof_delayed_fsync`: Delayed fsync counter\n\nIf a load operation is on-going, these additional fields will be added:\n\n`loading_start_time`: Epoch-based timestamp of the start of the load\n     operation\n`loading_total_bytes`: Total file size\n`loading_rdb_used_mem`: The memory usage of the server that had generated\n    the RDB file at the time of the file's creation\n`loading_loaded_bytes`: Number of bytes already loaded\n`loading_loaded_perc`: Same value expressed as a percentage\n`loading_eta_seconds`: ETA in seconds for the load to be complete\n\nHere is the meaning of all fields in the stats section:\n\n`total_connections_received`: Total number of connections accepted by the\n     server\n`total_commands_processed`: Total number of commands processed by the server\n`instantaneous_ops_per_sec`: Number of commands processed per second\n`total_net_input_bytes`: The total number of bytes read from the network\n`total_net_output_bytes`: The total number of bytes written to the network\n`total_net_repl_input_bytes`: The total number of bytes read from the network for replication purposes\n`total_net_repl_output_bytes`: The total number of bytes written to the network for replication purposes\n`instantaneous_input_kbps`: The network's read rate per second in KB/sec\n`instantaneous_output_kbps`: The network's write rate per second in KB/sec\n`instantaneous_input_repl_kbps`: The network's read rate per second in KB/sec for replication purposes\n`instantaneous_output_repl_kbps`: The network's write rate per second in KB/sec for replication purposes\n`rejected_connections`: Number of connections rejected because of\n     `maxclients` limit\n`sync_full`: The number of full resyncs with replicas\n`sync_partial_ok`: The number of accepted partial resync requests\n`sync_partial_err`: The number of denied partial resync requests\n`expired_keys`: Total number of key expiration events\n`expired_stale_perc`: The percentage of keys probably expired\n`expired_time_cap_reached_count`: The count of times that active expiry cycles have stopped early\n`expire_cycle_cpu_milliseconds`: The cumulative amount of time spend on active expiry cycles\n`evicted_keys`: Number of evicted keys due to `maxmemory` limit\n`evicted_clients`: Number of evicted clients due to `maxmemory-clients` limit. Added in Redis 7.0.\n`total_eviction_exceeded_time`:  Total time `used_memory` was greater than `maxmemory` since server startup, in milliseconds\n`current_eviction_exceeded_time`: The time passed since `used_memory` last rose above `maxmemory`, in milliseconds\n`keyspace_hits`: Number of successful lookup of keys in the main dictionary\n`keyspace_misses`: Number of failed lookup of keys in the main dictionary\n`pubsub_channels`: Global number of pub/sub channels with client\n     subscriptions\n`pubsub_patterns`: Global number of pub/sub pattern with client\n     subscriptions\n`pubsubshard_channels`: Global number of pub/sub shard channels with client subscriptions. Added in Redis 7.0.3\n`latest_fork_usec`: Duration of the latest fork operation in microseconds\n`total_forks`: Total number of fork operations since the server start\n`migrate_cached_sockets`: The number of sockets open for `MIGRATE` purposes\n`slave_expires_tracked_keys`: The number of keys tracked for expiry purposes\n     (applicable only to writable replicas)\n`active_defrag_hits`: Number of value reallocations performed by active the\n     defragmentation process\n`active_defrag_misses`: Number of aborted value reallocations started by the\n     active defragmentation process\n`active_defrag_key_hits`: Number of keys that were actively defragmented\n`active_defrag_key_misses`: Number of keys that were skipped by the active\n     defragmentation process\n`total_active_defrag_time`: Total time memory fragmentation was over the limit, in milliseconds\n`current_active_defrag_time`: The time passed since memory fragmentation last was over the limit, in milliseconds\n`tracking_total_keys`: Number of keys being tracked by the server\n`tracking_total_items`: Number of items, that is the sum of clients number for\n     each key, that are being tracked\n`tracking_total_prefixes`: Number of tracked prefixes in server's prefix table\n    (only applicable for broadcast mode)\n`unexpected_error_replies`: Number of unexpected error replies, that are types\n    of errors from an AOF load or replication\n`total_error_replies`: Total number of issued error replies, that is the sum of\n    rejected commands (errors prior command execution) and\n    failed commands (errors within the command execution)\n`dump_payload_sanitizations`: Total number of dump payload deep integrity validations (see `sanitize-dump-payload` config).\n`total_reads_processed`: Total number of read events processed\n`total_writes_processed`: Total number of write events processed\n`io_threaded_reads_processed`: Number of read events processed by the main and I/O threads\n`io_threaded_writes_processed`: Number of write events processed by the main and I/O threads\n`acl_access_denied_auth`: Number of authentication failures\n`acl_access_denied_cmd`: Number of commands rejected because of access denied to the command\n`acl_access_denied_key`: Number of commands rejected because of access denied to a key\n`acl_access_denied_channel`: Number of commands rejected because of access denied to a channel \n\nHere is the meaning of all fields in the replication section:\n\n`role`: Value is \"master\" if the instance is replica of no one, or \"slave\" if the instance is a replica of some master instance.\n     Note that a replica can be master of another replica (chained replication).\n`master_failover_state`: The state of an ongoing failover, if any.\n`master_replid`: The replication ID of the Redis server.\n`master_replid2`: The secondary replication ID, used for PSYNC after a failover.\n`master_repl_offset`: The server's current replication offset\n`second_repl_offset`: The offset up to which replication IDs are accepted\n`repl_backlog_active`: Flag indicating replication backlog is active\n`repl_backlog_size`: Total size in bytes of the replication backlog buffer\n`repl_backlog_first_byte_offset`: The master offset of the replication\n     backlog buffer\n`repl_backlog_histlen`: Size in bytes of the data in the replication backlog\n     buffer\n\nIf the instance is a replica, these additional fields are provided:\n\n`master_host`: Host or IP address of the master\n`master_port`: Master listening TCP port\n`master_link_status`: Status of the link (up/down)\n`master_last_io_seconds_ago`: Number of seconds since the last interaction\n     with master\n`master_sync_in_progress`: Indicate the master is syncing to the replica\n`slave_read_repl_offset`: The read replication offset of the replica instance.\n`slave_repl_offset`: The replication offset of the replica instance\n`slave_priority`: The priority of the instance as a candidate for failover\n`slave_read_only`: Flag indicating if the replica is read-only\n`replica_announced`: Flag indicating if the replica is announced by Sentinel.\n\nIf a SYNC operation is on-going, these additional fields are provided:\n\n`master_sync_total_bytes`: Total number of bytes that need to be \n    transferred. this may be 0 when the size is unknown (for example, when\n    the `repl-diskless-sync` configuration directive is used)\n`master_sync_read_bytes`: Number of bytes already transferred\n`master_sync_left_bytes`: Number of bytes left before syncing is complete\n    (may be negative when `master_sync_total_bytes` is 0)\n`master_sync_perc`: The percentage `master_sync_read_bytes` from \n    `master_sync_total_bytes`, or an approximation that uses\n    `loading_rdb_used_mem` when `master_sync_total_bytes` is 0\n`master_sync_last_io_seconds_ago`: Number of seconds since last transfer I/O\n     during a SYNC operation\n\nIf the link between master and replica is down, an additional field is provided:\n\n`master_link_down_since_seconds`: Number of seconds since the link is down\n\nThe following field is always provided:\n\n`connected_slaves`: Number of connected replicas\n\nIf the server is configured with the `min-slaves-to-write` (or starting with Redis 5 with the `min-replicas-to-write`) directive, an additional field is provided:\n\n`min_slaves_good_slaves`: Number of replicas currently considered good\n\nFor each replica, the following line is added:\n\n`slaveXXX`: id, IP address, port, state, offset, lag\n\nHere is the meaning of all fields in the cpu section:\n\n`used_cpu_sys`: System CPU consumed by the Redis server, which is the sum of system CPU consumed by all threads of the server process (main thread and background threads)\n`used_cpu_user`: User CPU consumed by the Redis server, which is the sum of user CPU consumed by all threads of the server process (main thread and background threads)\n`used_cpu_sys_children`: System CPU consumed by the background processes\n`used_cpu_user_children`: User CPU consumed by the background processes\n`used_cpu_sys_main_thread`: System CPU consumed by the Redis server main thread\n`used_cpu_user_main_thread`: User CPU consumed by the Redis server main thread\n\nThe commandstats section provides statistics based on the command type,\n including the number of calls that reached command execution (not rejected),\n the total CPU time consumed by these commands, the average CPU consumed\n per command execution, the number of rejected calls\n (errors prior command execution), and the number of failed calls\n (errors within the command execution).\nFor each command type, the following line is added:\n\n`cmdstat_XXX`: `calls=XXX,usec=XXX,usec_per_call=XXX,rejected_calls=XXX,failed_calls=XXX`\n\nThe latencystats section provides latency percentile distribution statistics based on the command type.\nBy default, the exported latency percentiles are the p50, p99, and p999.\n If you need to change the exported percentiles, use `CONFIG SET latency-tracking-info-percentiles \"50.0 99.0 99.9\"`.\nThis section requires the extended latency monitoring feature to be enabled (by default it's enabled).\n If you need to enable it, use `CONFIG SET latency-tracking yes`.\nFor each command type, the following line is added:\n\n`latency_percentiles_usec_XXX: p<percentile 1>=<percentile 1 value>,p<percentile 2>=<percentile 2 value>,...`\n\nThe errorstats section enables keeping track of the different errors that occurred within Redis, \n based upon the reply error prefix ( The first word after the \"-\", up to the first space. Example: `ERR` ).\nFor each error type, the following line is added:\n\n`errorstat_XXX`: `count=XXX`\n\nThe sentinel section is only available in Redis Sentinel instances. It consists of the following fields:\n\n`sentinel_masters`: Number of Redis masters monitored by this Sentinel instance\n`sentinel_tilt`: A value of 1 means this sentinel is in TILT mode\n`sentinel_tilt_since_seconds`: Duration in seconds of current TILT, or -1 if not TILTed. Added in Redis 7.0.0\n`sentinel_running_scripts`: The number of scripts this Sentinel is currently executing\n`sentinel_scripts_queue_length`: The length of the queue of user scripts that are pending execution\n`sentinel_simulate_failure_flags`: Flags for the `SENTINEL SIMULATE-FAILURE` command\n\nThe cluster section currently only contains a unique field:\n\n`cluster_enabled`: Indicate Redis cluster is enabled\n\nThe modules section contains additional information about loaded modules if the modules provide it. The field part of properties lines in this section is always prefixed with the module's name.\nThe keyspace section provides statistics on the main dictionary of each\ndatabase.\nThe statistics are the number of keys, and the number of keys with an expiration.\nFor each database, the following line is added:\n\n`dbXXX`: `keys=XXX,expires=XXX`\n\nA note about the word slave used in this man page: Starting with Redis 5, if not for backward compatibility, the Redis project no longer uses the word slave. Unfortunately in this command the word slave is part of the protocol, so we'll be able to remove such occurrences only when this API will be naturally deprecated.",
    "tag": "redis"
  },
  {
    "title": "Exclusive intervals and infinity",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrangebyscore.md",
    "content": "Returns all the elements in the sorted set at `key` with a score between `min`\nand `max` (including elements with score equal to `min` or `max`).\nThe elements are considered to be ordered from low to high scores.\nThe elements having the same score are returned in lexicographical order (this\nfollows from a property of the sorted set implementation in Redis and does not\ninvolve further computation).\nThe optional `LIMIT` argument can be used to only get a range of the matching\nelements (similar to SELECT LIMIT offset, count in SQL). A negative `count`\nreturns all elements from the `offset`.\nKeep in mind that if `offset` is large, the sorted set needs to be traversed for\n`offset` elements before getting to the elements to return, which can add up to\nO(N) time complexity.\nThe optional `WITHSCORES` argument makes the command return both the element and\nits score, instead of the element alone.\nThis option is available since Redis 2.0.\nExclusive intervals and infinity\n`min` and `max` can be `-inf` and `+inf`, so that you are not required to know\nthe highest or lowest score in the sorted set to get all elements from or up to\na certain score.\nBy default, the interval specified by `min` and `max` is closed (inclusive).\nIt is possible to specify an open interval (exclusive) by prefixing the score\nwith the character `(`.\nFor example:\n`ZRANGEBYSCORE zset (1 5`\nWill return all elements with `1 < score <= 5` while:\n`ZRANGEBYSCORE zset (5 (10`\nWill return all the elements with `5 < score < 10` (5 and 10 excluded).\n@return\n@array-reply: list of elements in the specified score range (optionally\nwith their scores).\n@examples\n`cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZRANGEBYSCORE myzset -inf +inf\nZRANGEBYSCORE myzset 1 2\nZRANGEBYSCORE myzset (1 2\nZRANGEBYSCORE myzset (1 (2`\nPattern: weighted random selection of an element\nNormally `ZRANGEBYSCORE` is simply used in order to get range of items\nwhere the score is the indexed integer key, however it is possible to do less\nobvious things with the command.\nFor example a common problem when implementing Markov chains and other algorithms\nis to select an element at random from a set, but different elements may have\ndifferent weights that change how likely it is they are picked.\nThis is how we use this command in order to mount such an algorithm:\nImagine you have elements A, B and C with weights 1, 2 and 3.\nYou compute the sum of the weights, which is 1+2+3 = 6\nAt this point you add all the elements into a sorted set using this algorithm:\n`SUM = ELEMENTS.TOTAL_WEIGHT // 6 in this case.\nSCORE = 0\nFOREACH ELE in ELEMENTS\n    SCORE += ELE.weight / SUM\n    ZADD KEY SCORE ELE\nEND`\nThis means that you set:\n`A to score 0.16\nB to score .5\nC to score 1`\nSince this involves approximations, in order to avoid C is set to,\nlike, 0.998 instead of 1, we just modify the above algorithm to make sure\nthe last score is 1 (left as an exercise for the reader...).\nAt this point, each time you want to get a weighted random element,\njust compute a random number between 0 and 1 (which is like calling\n`rand()` in most languages), so you can just do:",
    "tag": "redis"
  },
  {
    "title": "Summary form of XPENDING",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xpending.md",
    "content": "Fetching data from a stream via a consumer group, and not acknowledging\nsuch data, has the effect of creating pending entries. This is\nwell explained in the `XREADGROUP` command, and even better in our\nintroduction to Redis Streams. The `XACK` command\nwill immediately remove the pending entry from the Pending Entries List (PEL)\nsince once a message is successfully processed, there is no longer need\nfor the consumer group to track it and to remember the current owner\nof the message.\nThe `XPENDING` command is the interface to inspect the list of pending\nmessages, and is as thus a very important command in order to observe\nand understand what is happening with a streams consumer groups: what\nclients are active, what messages are pending to be consumed, or to see\nif there are idle messages. Moreover this command, together with `XCLAIM`\nis used in order to implement recovering of consumers that are failing\nfor a long time, and as a result certain messages are not processed: a\ndifferent consumer can claim the message and continue. This is better\nexplained in the streams intro and in the\n`XCLAIM` command page, and is not covered here.\nSummary form of XPENDING\nWhen `XPENDING` is called with just a key name and a consumer group\nname, it just outputs a summary about the pending messages in a given\nconsumer group. In the following example, we create a consumer group and\nimmediately create a pending message by reading from the group with\n`XREADGROUP`.\n```\n\nXGROUP CREATE mystream group55 0-0\nOK\nXREADGROUP GROUP group55 consumer-123 COUNT 1 STREAMS mystream >\n1) 1) \"mystream\"\n   2) 1) 1) 1526984818136-0\n         2) 1) \"duration\"\n            2) \"1532\"\n            3) \"event-id\"\n            4) \"5\"\n            5) \"user-id\"\n            6) \"7782813\"\n```\n\nWe expect the pending entries list for the consumer group `group55` to\nhave a message right now: consumer named `consumer-123` fetched the\nmessage without acknowledging its processing. The simple `XPENDING`\nform will give us this information:\n```\n\nXPENDING mystream group55\n1) (integer) 1\n2) 1526984818136-0\n3) 1526984818136-0\n4) 1) 1) \"consumer-123\"\n      2) \"1\"\n```\n\nIn this form, the command outputs the total number of pending messages for this\nconsumer group, which is one, followed by the smallest and greatest ID among the\npending messages, and then list every consumer in the consumer group with\nat least one pending message, and the number of pending messages it has.\nExtended form of XPENDING\nThe summary provides a good overview, but sometimes we are interested in the\ndetails. In order to see all the pending messages with more associated\ninformation we need to also pass a range of IDs, in a similar way we do it with\n`XRANGE`, and a non optional count argument, to limit the number\nof messages returned per call:\n```\n\nXPENDING mystream group55 - + 10\n1) 1) 1526984818136-0\n   2) \"consumer-123\"\n   3) (integer) 196415\n   4) (integer) 1\n```\n\nIn the extended form we no longer see the summary information, instead there\nis detailed information for each message in the pending entries list. For\neach message four attributes are returned:\n\nThe ID of the message.\nThe name of the consumer that fetched the message and has still to acknowledge it. We call it the current owner of the message.\nThe number of milliseconds that elapsed since the last time this message was delivered to this consumer.\nThe number of times this message was delivered.\n\nThe deliveries counter, that is the fourth element in the array, is incremented\nwhen some other consumer claims the message with `XCLAIM`, or when the\nmessage is delivered again via `XREADGROUP`, when accessing the history\nof a consumer in a consumer group (see the `XREADGROUP` page for more info).\nIt is possible to pass an additional argument to the command, in order\nto see the messages having a specific owner:\n```\n\nXPENDING mystream group55 - + 10 consumer-123\n```\n\nBut in the above case the output would be the same, since we have pending\nmessages only for a single consumer. However what is important to keep in\nmind is that this operation, filtering by a specific consumer, is not\ninefficient even when there are many pending messages from many consumers:\nwe have a pending entries list data structure both globally, and for\nevery consumer, so we can very efficiently show just messages pending for\na single consumer.\nIdle time filter\nIt is also possible to filter pending stream entries by their idle-time,\ngiven in milliseconds (useful for `XCLAIM`ing entries that have not been\nprocessed for some time):\n```\n\nXPENDING mystream group55 IDLE 9000 - + 10\nXPENDING mystream group55 IDLE 9000 - + 10 consumer-123\n```\n\nThe first case will return the first 10 (or less) PEL entries of the entire group\nthat are idle for over 9 seconds, whereas in the second case only those of\n`consumer-123`.\nExclusive ranges and iterating the PEL\nThe `XPENDING` command allows iterating over the pending entries just like\n`XRANGE` and `XREVRANGE` allow for the stream's entries. You can do this by\nprefixing the ID of the last-read pending entry with the `(` character that\ndenotes an open (exclusive) range, and proving it to the subsequent call to the\ncommand.\n@return\n@array-reply, specifically:\nThe command returns data in different format depending on the way it is\ncalled, as previously explained in this page. However the reply is always",
    "tag": "redis"
  },
  {
    "title": "Options",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/set.md",
    "content": "Set `key` to hold the string `value`.\nIf `key` already holds a value, it is overwritten, regardless of its type.\nAny previous time to live associated with the key is discarded on successful `SET` operation.\nOptions\nThe `SET` command supports a set of options that modify its behavior:\n\n`EX` seconds -- Set the specified expire time, in seconds.\n`PX` milliseconds -- Set the specified expire time, in milliseconds.\n`EXAT` timestamp-seconds -- Set the specified Unix time at which the key will expire, in seconds.\n`PXAT` timestamp-milliseconds -- Set the specified Unix time at which the key will expire, in milliseconds.\n`NX` -- Only set the key if it does not already exist.\n`XX` -- Only set the key if it already exist.\n`KEEPTTL` -- Retain the time to live associated with the key.\n`!GET` -- Return the old string stored at key, or nil if key did not exist. An error is returned and `SET` aborted if the value stored at key is not a string.\n\nNote: Since the `SET` command options can replace `SETNX`, `SETEX`, `PSETEX`, `GETSET`, it is possible that in future versions of Redis these commands will be deprecated and finally removed.\n@return\n@simple-string-reply: `OK` if `SET` was executed correctly.\n@nil-reply: `(nil)` if the `SET` operation was not performed because the user specified the `NX` or `XX` option but the condition was not met.\nIf the command is issued with the `!GET` option, the above does not apply. It will instead reply as follows, regardless if the `SET` was actually performed:\n@bulk-string-reply: the old string value stored at key.\n@nil-reply: `(nil)` if the key did not exist.\n@examples\n```cli\nSET mykey \"Hello\"\nGET mykey\nSET anotherkey \"will expire in a minute\" EX 60\n```\nPatterns\nNote: The following pattern is discouraged in favor of the Redlock algorithm which is only a bit more complex to implement, but offers better guarantees and is fault tolerant.\nThe command `SET resource-name anystring NX EX max-lock-time` is a simple way to implement a locking system with Redis.\nA client can acquire the lock if the above command returns `OK` (or retry after some time if the command returns Nil), and remove the lock just using `DEL`.\nThe lock will be auto-released after the expire time is reached.\nIt is possible to make this system more robust modifying the unlock schema as follows:\n\nInstead of setting a fixed string, set a non-guessable large random string, called token.\nInstead of releasing the lock with `DEL`, send a script that only removes the key if the value matches.\n\nThis avoids that a client will try to release the lock after the expire time deleting the key created by another client that acquired the lock later.\nAn example of unlock script would be similar to the following:\n\n\n```if redis.call(\"get\",KEYS[1]) == ARGV[1]\nthen\n    return redis.call(\"del\",KEYS[1])\nelse\n    return 0\nend\n```\n\n",
    "tag": "redis"
  },
  {
    "title": "fcall.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/fcall.md",
    "content": "Invoke a function.\nFunctions are loaded to the server with the `FUNCTION LOAD` command.\nThe first argument is the name of a loaded function.\nThe second argument is the number of input key name arguments, followed by all the keys accessed by the function.\nIn Lua, these names of input keys are available to the function as a table that is the callback's first argument.\nImportant:\nTo ensure the correct execution of functions, both in standalone and clustered deployments, all names of keys that a function accesses must be explicitly provided as input key arguments.\nThe function should only access keys whose names are given as input arguments.\nFunctions should never access keys with programmatically-generated names or based on the contents of data structures stored in the database.\nAny additional input argument should not represent names of keys.\nThese are regular arguments and are passed in a Lua table as the callback's second argument.\nFor more information please refer to the Redis Programmability and Introduction to Redis Functions pages.\n@examples\nThe following example will create a library named `mylib` with a single function, `myfunc`, that returns the first argument it gets.\n```\nredis> FUNCTION LOAD \"#!lua name=mylib \\n redis.register_function('myfunc', function(keys, args) return args[1] end)\"\n\"mylib\"\nredis> FCALL myfunc 0 hello\n\"hello\"",
    "tag": "redis"
  },
  {
    "title": "Example",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-delslots.md",
    "content": "In Redis Cluster, each node keeps track of which master is serving\na particular hash slot.\nThe `CLUSTER DELSLOTS` command asks a particular Redis Cluster node to\nforget which master is serving the hash slots specified as arguments.\nIn the context of a node that has received a `CLUSTER DELSLOTS` command and\nhas consequently removed the associations for the passed hash slots,\nwe say those hash slots are unbound. Note that the existence of\nunbound hash slots occurs naturally when a node has not been\nconfigured to handle them (something that can be done with the\n`CLUSTER ADDSLOTS` command) and if it has not received any information about\nwho owns those hash slots (something that it can learn from heartbeat\nor update messages).\nIf a node with unbound hash slots receives a heartbeat packet from\nanother node that claims to be the owner of some of those hash\nslots, the association is established instantly. Moreover, if a\nheartbeat or update message is received with a configuration epoch\ngreater than the node's own, the association is re-established.\nHowever, note that:\n\nThe command only works if all the specified slots are already\nassociated with some node.\nThe command fails if the same slot is specified multiple times.\nAs a side effect of the command execution, the node may go into\ndown state because not all hash slots are covered.\n\nExample\nThe following command removes the association for slots 5000 and\n5001 from the node receiving the command:\n\n\n```> CLUSTER DELSLOTS 5000 5001\nOK\n```\n\n\nUsage in Redis Cluster\nThis command only works in cluster mode and may be useful for\ndebugging and in order to manually orchestrate a cluster configuration\nwhen a new cluster is created. It is currently not used by `redis-cli`,\nand mainly exists for API completeness.\n@return\n@simple-string-reply: `OK` if the command was successful. Otherwise",
    "tag": "redis"
  },
  {
    "title": "slowlog-len.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/slowlog-len.md",
    "content": "This command returns the current number of entries in the slow log.\nA new entry is added to the slow log whenever a command exceeds the execution time threshold defined by the `slowlog-log-slower-than` configuration directive.\nThe maximum number of entries in the slow log is governed by the `slowlog-max-len` configuration directive.\nOnce the slog log reaches its maximal size, the oldest entry is removed whenever a new entry is created.\nThe slow log can be cleared with the `SLOWLOG RESET` command.\n@reply\n@integer-reply",
    "tag": "redis"
  },
  {
    "title": "Pattern: Reliable queue",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/brpoplpush.md",
    "content": "`BRPOPLPUSH` is the blocking variant of `RPOPLPUSH`.\nWhen `source` contains elements, this command behaves exactly like `RPOPLPUSH`.\nWhen used inside a `MULTI`/`EXEC` block, this command behaves exactly like `RPOPLPUSH`.\nWhen `source` is empty, Redis will block the connection until another client\npushes to it or until `timeout` is reached.\nA `timeout` of zero can be used to block indefinitely.\nSee `RPOPLPUSH` for more information.\n@return\n@bulk-string-reply: the element being popped from `source` and pushed to `destination`.\nIf `timeout` is reached, a @nil-reply is returned.\nPattern: Reliable queue\nPlease see the pattern description in the `RPOPLPUSH` documentation.\nPattern: Circular list",
    "tag": "redis"
  },
  {
    "title": "geodist.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/geodist.md",
    "content": "Return the distance between two members in the geospatial index represented by the sorted set.\nGiven a sorted set representing a geospatial index, populated using the `GEOADD` command, the command returns the distance between the two specified members in the specified unit.\nIf one or both the members are missing, the command returns NULL.\nThe unit must be one of the following, and defaults to meters:\n\nm for meters.\nkm for kilometers.\nmi for miles.\nft for feet.\n\nThe distance is computed assuming that the Earth is a perfect sphere, so errors up to 0.5% are possible in edge cases.\n@return\n@bulk-string-reply, specifically:\nThe command returns the distance as a double (represented as a string)\nin the specified unit, or NULL if one or both the elements are missing.\n@examples\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEODIST Sicily Palermo Catania\nGEODIST Sicily Palermo Catania km\nGEODIST Sicily Palermo Catania mi\nGEODIST Sicily Foo Bar",
    "tag": "redis"
  },
  {
    "title": "Notes",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-list.md",
    "content": "The `CLIENT LIST` command returns information and statistics about the client\nconnections server in a mostly human readable format.\nYou can use one of the optional subcommands to filter the list. The `TYPE type` subcommand filters the list by clients' type, where type is one of `normal`, `master`, `replica`, and `pubsub`. Note that clients blocked by the `MONITOR` command belong to the `normal` class.\nThe `ID` filter only returns entries for clients with IDs matching the `client-id` arguments.\n@return\n@bulk-string-reply: a unique string, formatted as follows:\n\nOne client connection per line (separated by LF)\nEach line is composed of a succession of `property=value` fields separated\n  by a space character.\n\nHere is the meaning of the fields:\n\n`id`: a unique 64-bit client ID\n`addr`: address/port of the client\n`laddr`: address/port of local address client connected to (bind address)\n`fd`: file descriptor corresponding to the socket\n`name`: the name set by the client with `CLIENT SETNAME`\n`age`: total duration of the connection in seconds\n`idle`: idle time of the connection in seconds\n`flags`: client flags (see below)\n`db`: current database ID\n`sub`: number of channel subscriptions\n`psub`: number of pattern matching subscriptions\n`ssub`: number of shard channel subscriptions. Added in Redis 7.0.3\n`multi`: number of commands in a MULTI/EXEC context\n`qbuf`: query buffer length (0 means no query pending)\n`qbuf-free`: free space of the query buffer (0 means the buffer is full)\n`argv-mem`: incomplete arguments for the next command (already extracted from query buffer)\n`multi-mem`: memory is used up by buffered multi commands. Added in Redis 7.0\n`obl`: output buffer length\n`oll`: output list length (replies are queued in this list when the buffer is full)\n`omem`: output buffer memory usage\n`tot-mem`: total memory consumed by this client in its various buffers\n`events`: file descriptor events (see below)\n`cmd`: last command played\n`user`: the authenticated username of the client\n`redir`: client id of current client tracking redirection\n`resp`: client RESP protocol version. Added in Redis 7.0\n\nThe client flags can be a combination of:\n`A: connection to be closed ASAP\nb: the client is waiting in a blocking operation\nc: connection to be closed after writing entire reply\nd: a watched keys has been modified - EXEC will fail\ni: the client is waiting for a VM I/O (deprecated)\nM: the client is a master\nN: no specific flag set\nO: the client is a client in MONITOR mode\nP: the client is a Pub/Sub subscriber\nr: the client is in readonly mode against a cluster node\nS: the client is a replica node connection to this instance\nu: the client is unblocked\nU: the client is connected via a Unix domain socket\nx: the client is in a MULTI/EXEC context\nt: the client enabled keys tracking in order to perform client side caching\nR: the client tracking target client is invalid\nB: the client enabled broadcast tracking mode`\nThe file descriptor events can be:\n`r: the client socket is readable (event loop)\nw: the client socket is writable (event loop)`\nNotes\nNew fields are regularly added for debugging purpose. Some could be removed\nin the future. A version safe Redis client using this command should parse\nthe output accordingly (i.e. handling gracefully missing fields, skipping",
    "tag": "redis"
  },
  {
    "title": "pfadd.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pfadd.md",
    "content": "Adds all the element arguments to the HyperLogLog data structure stored at the variable name specified as first argument.\nAs a side effect of this command the HyperLogLog internals may be updated to reflect a different estimation of the number of unique items added so far (the cardinality of the set).\nIf the approximated cardinality estimated by the HyperLogLog changed after executing the command, `PFADD` returns 1, otherwise 0 is returned. The command automatically creates an empty HyperLogLog structure (that is, a Redis String of a specified length and with a given encoding) if the specified key does not exist.\nTo call the command without elements but just the variable name is valid, this will result into no operation performed if the variable already exists, or just the creation of the data structure if the key does not exist (in the latter case 1 is returned).\nFor an introduction to HyperLogLog data structure check the `PFCOUNT` command page.\n@return\n@integer-reply, specifically:\n\n1 if at least 1 HyperLogLog internal register was altered. 0 otherwise.\n\n@examples\n```cli\nPFADD hll a b c d e f g\nPFCOUNT hll",
    "tag": "redis"
  },
  {
    "title": "script-debug.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/script-debug.md",
    "content": "Set the debug mode for subsequent scripts executed with `EVAL`. Redis includes a\ncomplete Lua debugger, codename LDB, that can be used to make the task of\nwriting complex scripts much simpler. In debug mode Redis acts as a remote\ndebugging server and a client, such as `redis-cli`, can execute scripts step by\nstep, set breakpoints, inspect variables and more - for additional information\nabout LDB refer to the Redis Lua debugger page.\nImportant note: avoid debugging Lua scripts using your Redis production\nserver. Use a development server instead.\nLDB can be enabled in one of two modes: asynchronous or synchronous. In\nasynchronous mode the server creates a forked debugging session that does not\nblock and all changes to the data are rolled back after the session\nfinishes, so debugging can be restarted using the same initial state. The\nalternative synchronous debug mode blocks the server while the debugging session\nis active and retains all changes to the data set once it ends.\n\n`YES`. Enable non-blocking asynchronous debugging of Lua scripts (changes are discarded).\n`!SYNC`. Enable blocking synchronous debugging of Lua scripts (saves changes to data).\n`NO`. Disables scripts debug mode.\n\nFor more information about `EVAL` scripts please refer to Introduction to Eval Scripts.\n@return\n@simple-string-reply: `OK`.",
    "tag": "redis"
  },
  {
    "title": "CLUSTER SETSLOT `<slot>` MIGRATING `<destination-node-id>`",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-setslot.md",
    "content": "`CLUSTER SETSLOT` is responsible of changing the state of a hash slot in the receiving node in different ways. It can, depending on the subcommand used:\n\n`MIGRATING` subcommand: Set a hash slot in migrating state.\n`IMPORTING` subcommand: Set a hash slot in importing state.\n`STABLE` subcommand: Clear any importing / migrating state from hash slot.\n`NODE` subcommand: Bind the hash slot to a different node.\n\nThe command with its set of subcommands is useful in order to start and end cluster live resharding operations, which are accomplished by setting a hash slot in migrating state in the source node, and importing state in the destination node.\nEach subcommand is documented below. At the end you'll find a description of\nhow live resharding is performed using this command and other related commands.\nCLUSTER SETSLOT `<slot>` MIGRATING `<destination-node-id>`\nThis subcommand sets a slot to migrating state. In order to set a slot\nin this state, the node receiving the command must be the hash slot owner,\notherwise an error is returned.\nWhen a slot is set in migrating state, the node changes behavior in the\nfollowing way:\n\nIf a command is received about an existing key, the command is processed as usually.\nIf a command is received about a key that does not exists, an `ASK` redirection is emitted by the node, asking the client to retry only that specific query into `destination-node`. In this case the client should not update its hash slot to node mapping.\nIf the command contains multiple keys, in case none exist, the behavior is the same as point 2, if all exist, it is the same as point 1, however if only a partial number of keys exist, the command emits a `TRYAGAIN` error in order for the keys interested to finish being migrated to the target node, so that the multi keys command can be executed.\n\nCLUSTER SETSLOT `<slot>` IMPORTING `<source-node-id>`\nThis subcommand is the reverse of `MIGRATING`, and prepares the destination\nnode to import keys from the specified source node. The command only works if\nthe node is not already owner of the specified hash slot.\nWhen a slot is set in importing state, the node changes behavior in the following way:\n\nCommands about this hash slot are refused and a `MOVED` redirection is generated as usually, but in the case the command follows an `ASKING` command, in this case the command is executed.\n\nIn this way when a node in migrating state generates an `ASK` redirection, the client contacts the target node, sends `ASKING`, and immediately after sends the command. This way commands about non-existing keys in the old node or keys already migrated to the target node are executed in the target node, so that:\n\nNew keys are always created in the target node. During a hash slot migration we'll have to move only old keys, not new ones.\nCommands about keys already migrated are correctly processed in the context of the node which is the target of the migration, the new hash slot owner, in order to guarantee consistency.\nWithout `ASKING` the behavior is the same as usually. This guarantees that clients with a broken hash slots mapping will not write for error in the target node, creating a new version of a key that has yet to be migrated.\n\nCLUSTER SETSLOT `<slot>` STABLE\nThis subcommand just clears migrating / importing state from the slot. It is\nmainly used to fix a cluster stuck in a wrong state by `redis-cli --cluster fix`.\nNormally the two states are cleared automatically at the end of the migration\nusing the `SETSLOT ... NODE ...` subcommand as explained in the next section.\nCLUSTER SETSLOT `<slot>` NODE `<node-id>`\nThe `NODE` subcommand is the one with the most complex semantics. It\nassociates the hash slot with the specified node, however the command works\nonly in specific situations and has different side effects depending on the\nslot state. The following is the set of pre-conditions and side effects of the\ncommand:\n\nIf the current hash slot owner is the node receiving the command, but for effect of the command the slot would be assigned to a different node, the command will return an error if there are still keys for that hash slot in the node receiving the command.\nIf the slot is in migrating state, the state gets cleared when the slot is assigned to another node.\nIf the slot was in importing state in the node receiving the command, and the command assigns the slot to this node (which happens in the target node at the end of the resharding of a hash slot from one node to another), the command has the following side effects: A) the importing state is cleared. B) If the node config epoch is not already the greatest of the cluster, it generates a new one and assigns the new config epoch to itself. This way its new hash slot ownership will win over any past configuration created by previous failovers or slot migrations.\n\nIt is important to note that step 3 is the only time when a Redis Cluster node will create a new config epoch without agreement from other nodes. This only happens when a manual configuration is operated. However it is impossible that this creates a non-transient setup where two nodes have the same config epoch, since Redis Cluster uses a config epoch collision resolution algorithm.\n@return\n@simple-string-reply: All the subcommands return `OK` if the command was successful. Otherwise an error is returned.\nRedis Cluster live resharding explained\nThe `CLUSTER SETSLOT` command is an important piece used by Redis Cluster in order to migrate all the keys contained in one hash slot from one node to another. This is how the migration is orchestrated, with the help of other commands as well. We'll call the node that has the current ownership of the hash slot the `source` node, and the node where we want to migrate the `destination` node.\n\nSet the destination node slot to importing state using `CLUSTER SETSLOT <slot> IMPORTING <source-node-id>`.\nSet the source node slot to migrating state using `CLUSTER SETSLOT <slot> MIGRATING <destination-node-id>`.\nGet keys from the source node with `CLUSTER GETKEYSINSLOT` command and move them into the destination node using the `MIGRATE` command.\nSend `CLUSTER SETSLOT <slot> NODE <destination-node-id>` to the destination node.\nSend `CLUSTER SETSLOT <slot> NODE <destination-node-id>` to the source node.\nSend `CLUSTER SETSLOT <slot> NODE <destination-node-id>` to the other master nodes (optional).\n\nNotes:\n\nThe order of step 1 and 2 is important. We want the destination node to be ready to accept `ASK` redirections when the source node is configured to redirect.\nThe order of step 4 and 5 is important.\n  The destination node is responsible for propagating the change to the rest of the cluster.\n  If the source node is informed before the destination node and the destination node crashes before it is set as new slot owner, the slot is left with no owner, even after a successful failover.\nStep 6, sending `SETSLOT` to the nodes not involved in the resharding, is not technically necessary since the configuration will eventually propagate itself.\n",
    "tag": "redis"
  },
  {
    "title": "Pattern: Time series",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/append.md",
    "content": "If `key` already exists and is a string, this command appends the `value` at the\nend of the string.\nIf `key` does not exist it is created and set as an empty string, so `APPEND`\nwill be similar to `SET` in this special case.\n@return\n@integer-reply: the length of the string after the append operation.\n@examples\n`cli\nEXISTS mykey\nAPPEND mykey \"Hello\"\nAPPEND mykey \" World\"\nGET mykey`\nPattern: Time series\nThe `APPEND` command can be used to create a very compact representation of a\nlist of fixed-size samples, usually referred as time series.\nEvery time a new sample arrives we can store it using the command\n`APPEND timeseries \"fixed-size sample\"`\nAccessing individual elements in the time series is not hard:\n\n`STRLEN` can be used in order to obtain the number of samples.\n`GETRANGE` allows for random access of elements.\n  If our time series have associated time information we can easily implement\n  a binary search to get range combining `GETRANGE` with the Lua scripting\n  engine available in Redis 2.6.\n`SETRANGE` can be used to overwrite an existing time series.\n\nThe limitation of this pattern is that we are forced into an append-only mode\nof operation, there is no way to cut the time series to a given size easily\nbecause Redis currently lacks a command able to trim string objects.\nHowever the space efficiency of time series stored in this way is remarkable.\nHint: it is possible to switch to a different key based on the current Unix\ntime, in this way it is possible to have just a relatively small amount of\nsamples per key, to avoid dealing with very big keys, and to make this pattern\nmore friendly to be distributed across many Redis instances.\nAn example sampling the temperature of a sensor using fixed-size strings (using\na binary format is better in real implementations).\n```cli\nAPPEND ts \"0043\"\nAPPEND ts \"0035\"\nGETRANGE ts 0 3\nGETRANGE ts 4 7",
    "tag": "redis"
  },
  {
    "title": "bgrewriteaof.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bgrewriteaof.md",
    "content": "Instruct Redis to start an Append Only File rewrite process.\nThe rewrite will create a small optimized version of the current Append Only\nFile.\nIf `BGREWRITEAOF` fails, no data gets lost as the old AOF will be untouched.\nThe rewrite will be only triggered by Redis if there is not already a background\nprocess doing persistence.\nSpecifically:\n\nIf a Redis child is creating a snapshot on disk, the AOF rewrite is scheduled but not started until the saving child producing the RDB file terminates. In this case the `BGREWRITEAOF` will still return a positive status reply, but with an appropriate message.  You can check if an AOF rewrite is scheduled looking at the `INFO` command as of Redis 2.6 or successive versions.\nIf an AOF rewrite is already in progress the command returns an error and no\n  AOF rewrite will be scheduled for a later time.\nIf the AOF rewrite could start, but the attempt at starting it fails (for instance because of an error in creating the child process), an error is returned to the caller.\n\nSince Redis 2.4 the AOF rewrite is automatically triggered by Redis, however the\n`BGREWRITEAOF` command can be used to trigger a rewrite at any time.\nPlease refer to the persistence documentation for detailed information.\n@return\n@simple-string-reply: A simple string reply indicating that the rewriting started or is about to start ASAP, when the call is executed with success.",
    "tag": "redis"
  },
  {
    "title": "readonly.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/readonly.md",
    "content": "Enables read queries for a connection to a Redis Cluster replica node. \nNormally replica nodes will redirect clients to the authoritative master for\nthe hash slot involved in a given command, however clients can use replicas\nin order to scale reads using the `READONLY` command.\n`READONLY` tells a Redis Cluster replica node that the client is willing to\nread possibly stale data and is not interested in running write queries.\nWhen the connection is in readonly mode, the cluster will send a redirection\nto the client only if the operation involves keys not served by the replica's\nmaster node. This may happen because:\n\nThe client sent a command about hash slots never served by the master of this replica.\nThe cluster was reconfigured (for example resharded) and the replica is no longer able to serve commands for a given hash slot.\n\n@return",
    "tag": "redis"
  },
  {
    "title": "acl-deluser.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-deluser.md",
    "content": "Delete all the specified ACL users and terminate all the connections that are\nauthenticated with such users. Note: the special `default` user cannot be\nremoved from the system, this is the default user that every new connection\nis authenticated with. The list of users may include usernames that do not\nexist, in such case no operation is performed for the non existing users.\n@return\n@integer-reply: The number of users that were deleted. This number will not always match the number of arguments since certain users may not exist.\n@examples\n```\n\nACL DELUSER antirez\n1\n",
    "tag": "redis"
  },
  {
    "title": "smove.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/smove.md",
    "content": "Move `member` from the set at `source` to the set at `destination`.\nThis operation is atomic.\nIn every given moment the element will appear to be a member of `source` or\n`destination` for other clients.\nIf the source set does not exist or does not contain the specified element, no\noperation is performed and `0` is returned.\nOtherwise, the element is removed from the source set and added to the\ndestination set.\nWhen the specified element already exists in the destination set, it is only\nremoved from the source set.\nAn error is returned if `source` or `destination` does not hold a set value.\n@return\n@integer-reply, specifically:\n\n`1` if the element is moved.\n`0` if the element is not a member of `source` and no operation was performed.\n\n@examples\n```cli\nSADD myset \"one\"\nSADD myset \"two\"\nSADD myotherset \"three\"\nSMOVE myset myotherset \"two\"\nSMEMBERS myset\nSMEMBERS myotherset",
    "tag": "redis"
  },
  {
    "title": "xtrim.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xtrim.md",
    "content": "`XTRIM` trims the stream by evicting older entries (entries with lower IDs) if needed.\nTrimming the stream can be done using one of these strategies:\n\n`MAXLEN`: Evicts entries as long as the stream's length exceeds the specified `threshold`, where `threshold` is a positive integer.\n`MINID`: Evicts entries with IDs lower than `threshold`, where `threshold` is a stream ID.\n\nFor example, this will trim the stream to exactly the latest 1000 items:\n`XTRIM mystream MAXLEN 1000`\nWhereas in this example, all entries that have an ID lower than 649085820-0 will be evicted:\n`XTRIM mystream MINID 649085820`\nBy default, or when provided with the optional `=` argument, the command performs exact trimming.\nDepending on the strategy, exact trimming means:\n\n`MAXLEN`: the trimmed stream's length will be exactly the minimum between its original length and the specified `threshold`.\n`MINID`: the oldest ID in the stream will be exactly the maximum between its original oldest ID and the specified `threshold`.\n\nNearly exact trimming\nBecause exact trimming may require additional effort from the Redis server, the optional `~` argument can be provided to make it more efficient.\nFor example:\n`XTRIM mystream MAXLEN ~ 1000`\nThe `~` argument between the `MAXLEN` strategy and the `threshold` means that the user is requesting to trim the stream so its length is at least the `threshold`, but possibly slightly more.\nIn this case, Redis will stop trimming early when performance can be gained (for example, when a whole macro node in the data structure can't be removed).\nThis makes trimming much more efficient, and it is usually what you want, although after trimming, the stream may have few tens of additional entries over the `threshold`.\nAnother way to control the amount of work done by the command when using the `~`, is the `LIMIT` clause. \nWhen used, it specifies the maximal `count` of entries that will be evicted.\nWhen `LIMIT` and `count` aren't specified, the default value of 100 * the number of entries in a macro node will be implicitly used as the `count`.\nSpecifying the value 0 as `count` disables the limiting mechanism entirely.\n@return\n@integer-reply: The number of entries deleted from the stream.\n@examples\n```cli\nXADD mystream * field1 A field2 B field3 C field4 D\nXTRIM mystream MAXLEN 2\nXRANGE mystream - +",
    "tag": "redis"
  },
  {
    "title": "See also",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/setex.md",
    "content": "Set `key` to hold the string `value` and set `key` to timeout after a given\nnumber of seconds.\nThis command is equivalent to executing the following commands:\n`SET mykey value\nEXPIRE mykey seconds`\n`SETEX` is atomic, and can be reproduced by using the previous two commands\ninside an `MULTI` / `EXEC` block.\nIt is provided as a faster alternative to the given sequence of operations,\nbecause this operation is very common when Redis is used as a cache.\nAn error is returned when `seconds` is invalid.\n@return\n@simple-string-reply\n@examples\n`cli\nSETEX mykey 10 \"Hello\"\nTTL mykey\nGET mykey`\nSee also",
    "tag": "redis"
  },
  {
    "title": "Commands not logged by MONITOR",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/monitor.md",
    "content": "`MONITOR` is a debugging command that streams back every command processed by\nthe Redis server.\nIt can help in understanding what is happening to the database.\nThis command can both be used via `redis-cli` and via `telnet`.\nThe ability to see all the requests processed by the server is useful in order\nto spot bugs in an application both when using Redis as a database and as a\ndistributed caching system.\n`$ redis-cli monitor\n1339518083.107412 [0 127.0.0.1:60866] \"keys\" \"*\"\n1339518087.877697 [0 127.0.0.1:60866] \"dbsize\"\n1339518090.420270 [0 127.0.0.1:60866] \"set\" \"x\" \"6\"\n1339518096.506257 [0 127.0.0.1:60866] \"get\" \"x\"\n1339518099.363765 [0 127.0.0.1:60866] \"eval\" \"return redis.call('set','x','7')\" \"0\"\n1339518100.363799 [0 lua] \"set\" \"x\" \"7\"\n1339518100.544926 [0 127.0.0.1:60866] \"del\" \"x\"`\nUse `SIGINT` (Ctrl-C) to stop a `MONITOR` stream running via `redis-cli`.\n`$ telnet localhost 6379\nTrying 127.0.0.1...\nConnected to localhost.\nEscape character is '^]'.\nMONITOR\n+OK\n+1339518083.107412 [0 127.0.0.1:60866] \"keys\" \"*\"\n+1339518087.877697 [0 127.0.0.1:60866] \"dbsize\"\n+1339518090.420270 [0 127.0.0.1:60866] \"set\" \"x\" \"6\"\n+1339518096.506257 [0 127.0.0.1:60866] \"get\" \"x\"\n+1339518099.363765 [0 127.0.0.1:60866] \"del\" \"x\"\n+1339518100.544926 [0 127.0.0.1:60866] \"get\" \"x\"\nQUIT\n+OK\nConnection closed by foreign host.`\nManually issue the `QUIT` or `RESET` commands to stop a `MONITOR` stream running\nvia `telnet`.\nCommands not logged by MONITOR\nBecause of security concerns, no administrative commands are logged\nby `MONITOR`'s output and sensitive data is redacted in the command `AUTH`.\nFurthermore, the command `QUIT` is also not logged.\nCost of running MONITOR\nBecause `MONITOR` streams back all commands, its use comes at a cost.\nThe following (totally unscientific) benchmark numbers illustrate what the cost\nof running `MONITOR` can be.\nBenchmark result without `MONITOR` running:\n`$ src/redis-benchmark -c 10 -n 100000 -q\nPING_INLINE: 101936.80 requests per second\nPING_BULK: 102880.66 requests per second\nSET: 95419.85 requests per second\nGET: 104275.29 requests per second\nINCR: 93283.58 requests per second`\nBenchmark result with `MONITOR` running (`redis-cli monitor > /dev/null`):\n`$ src/redis-benchmark -c 10 -n 100000 -q\nPING_INLINE: 58479.53 requests per second\nPING_BULK: 59136.61 requests per second\nSET: 41823.50 requests per second\nGET: 45330.91 requests per second\nINCR: 41771.09 requests per second`\nIn this particular case, running a single `MONITOR` client can reduce the\nthroughput by more than 50%.\nRunning more `MONITOR` clients will reduce throughput even more.\n@return\nNon standard return value, just dumps the received commands in an infinite\nflow.\nBehavior change history\n\n`>= 6.0.0`: `AUTH` excluded from the command's output.\n`>= 6.2.0`: \"`RESET` can be called to exit monitor mode.\n",
    "tag": "redis"
  },
  {
    "title": "ltrim.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/ltrim.md",
    "content": "Trim an existing list so that it will contain only the specified range of\nelements specified.\nBoth `start` and `stop` are zero-based indexes, where `0` is the first element\nof the list (the head), `1` the next element and so on.\nFor example: `LTRIM foobar 0 2` will modify the list stored at `foobar` so that\nonly the first three elements of the list will remain.\n`start` and `end` can also be negative numbers indicating offsets from the end\nof the list, where `-1` is the last element of the list, `-2` the penultimate\nelement and so on.\nOut of range indexes will not produce an error: if `start` is larger than the\nend of the list, or `start > end`, the result will be an empty list (which\ncauses `key` to be removed).\nIf `end` is larger than the end of the list, Redis will treat it like the last\nelement of the list.\nA common use of `LTRIM` is together with `LPUSH` / `RPUSH`.\nFor example:\n`LPUSH mylist someelement\nLTRIM mylist 0 99`\nThis pair of commands will push a new element on the list, while making sure\nthat the list will not grow larger than 100 elements.\nThis is very useful when using Redis to store logs for example.\nIt is important to note that when used in this way `LTRIM` is an O(1) operation\nbecause in the average case just one element is removed from the tail of the\nlist.\n@return\n@simple-string-reply\n@examples\n```cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nLTRIM mylist 1 -1\nLRANGE mylist 0 -1",
    "tag": "redis"
  },
  {
    "title": "bgsave.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bgsave.md",
    "content": "Save the DB in background.\nNormally the OK code is immediately returned.\nRedis forks, the parent continues to serve the clients, the child saves the DB\non disk then exits.\nAn error is returned if there is already a background save running or if there\nis another non-background-save process running, specifically an in-progress AOF\nrewrite.\nIf `BGSAVE SCHEDULE` is used, the command will immediately return `OK` when an\nAOF rewrite is in progress and schedule the background save to run at the next\nopportunity.\nA client may be able to check if the operation succeeded using the `LASTSAVE`\ncommand.\nPlease refer to the persistence documentation for detailed information.\n@return",
    "tag": "redis"
  },
  {
    "title": "Name",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/command.md",
    "content": "Return an array with details about every Redis command.\nThe `COMMAND` command is introspective.\nIts reply describes all commands that the server can process.\nRedis clients can call it to obtain the server's runtime capabilities during the handshake.\n`COMMAND` also has several subcommands.\nPlease refer to its subcommands for further details.\nCluster note:\nthis command is especially beneficial for cluster-aware clients.\nSuch clients must identify the names of keys in commands to route requests to the correct shard.\nAlthough most commands accept a single key as their first argument, there are many exceptions to this rule. \nYou can call `COMMAND` and then keep the mapping between commands and their respective key specification rules cached in the client.\nThe reply it returns is an array with an element per command.\nEach element that describes a Redis command is represented as an array by itself.\nThe command's array consists of a fixed number of elements.\nThe exact number of elements in the array depends on the server's version.\n\nName\nArity\nFlags\nFirst key\nLast key\nStep\nACL categories (as of Redis 6.0)\nTips (as of Redis 7.0)\nKey specifications (as of Redis 7.0)\nSubcommands (as of Redis 7.0)\n\nName\nThis is the command's name in lowercase.\nNote:\nRedis command names are case-insensitive.\nArity\nArity is the number of arguments a command expects.\nIt follows a simple pattern:\n\nA positive integer means a fixed number of arguments.\nA negative integer means a minimal number of arguments.\n\nCommand arity always includes the command's name itself (and the subcommand when applicable).\nExamples:\n\n`GET`'s arity is 2 since the command only accepts one argument and always has the format `GET _key_`.\n`MGET`'s arity is -2 since the command accepts at least one argument, but possibly multiple ones: `MGET _key1_ [key2] [key3] ...`.\n\nFlags\nCommand flags are an array. It can contain the following simple strings (status reply):\n\nadmin: the command is an administrative command.\nasking: the command is allowed even during hash slot migration.\n  This flag is relevant in Redis Cluster deployments.\nblocking: the command may block the requesting client.\ndenyoom: the command is rejected if the server's memory usage is too high (see the maxmemory configuration directive).\nfast: the command operates in constant or log(N) time.\n  This flag is used for monitoring latency with the `LATENCY` command.\nloading: the command is allowed while the database is loading.\nmovablekeys: the first key, last key, and step values don't determine all key positions.\n  Clients need to use `COMMAND GETKEYS` or key specifications in this case.\n  See below for more details.\nno_auth: executing the command doesn't require authentication.\nno_async_loading: the command is denied during asynchronous loading (that is when a replica uses disk-less `SWAPDB SYNC`, and allows access to the old dataset).\nno_mandatory_keys: the command may accept key name arguments, but these aren't mandatory.\nno_multi: the command isn't allowed inside the context of a transaction.\nnoscript: the command can't be called from scripts or functions.\npubsub: the command is related to Redis Pub/Sub.\nrandom: the command returns random results, which is a concern with verbatim script replication.\n  As of Redis 7.0, this flag is a command tip.\nreadonly: the command doesn't modify data.\nsort_for_script: the command's output is sorted when called from a script.\nskip_monitor: the command is not shown in `MONITOR`'s output.\nskip_slowlog: the command is not shown in `SLOWLOG`'s output.\n  As of Redis 7.0, this flag is a command tip.\nstale: the command is allowed while a replica has stale data.\nwrite: the command may modify data.\n\nMovablekeys\nConsider `SORT`:\n`1) 1) \"sort\"\n   2) (integer) -2\n   3) 1) write\n      2) denyoom\n      3) movablekeys\n   4) (integer) 1\n   5) (integer) 1\n   6) (integer) 1\n   ...`\nSome Redis commands have no predetermined key locations or are not easy to find.\nFor those commands, the movablekeys flag indicates that the first key, last key, and step values are insufficient to find all the keys.\nHere are several examples of commands that have the movablekeys flag:\n\n`SORT`: the optional STORE, BY, and GET modifiers are followed by names of keys.\n`ZUNION`: the numkeys argument specifies the number key name arguments.\n`MIGRATE`: the keys appear KEYS keyword and only when the second argument is the empty string.\n\nRedis Cluster clients need to use other measures, as follows, to locate the keys for such commands.\nYou can use the `COMMAND GETKEYS` command and have your Redis server report all keys of a given command's invocation.\nAs of Redis 7.0, clients can use the key specifications to identify the positions of key names.\nThe only commands that require using `COMMAND GETKEYS` are `SORT` and `MIGRATE` for clients that parse keys' specifications.\nFor more information, please refer to the key specifications page.\nFirst key\nThe position of the command's first key name argument.\nFor most commands, the first key's position is 1.\nPosition 0 is always the command name itself.\nLast key\nThe position of the command's last key name argument.\nRedis commands usually accept one, two or multiple number of keys.\nCommands that accept a single key have both first key and last key set to 1.\nCommands that accept two key name arguments, e.g. `BRPOPLPUSH`, `SMOVE` and `RENAME`, have this value set to the position of their second key.\nMulti-key commands that accept an arbitrary number of keys, such as `MSET`, use the value -1.\nStep\nThe step, or increment, between the first key and the position of the next key.\nConsider the following two examples:\n`1) 1) \"mset\"\n   2) (integer) -3\n   3) 1) write\n      2) denyoom\n   4) (integer) 1\n   5) (integer) -1\n   6) (integer) 2\n   ...`\n`1) 1) \"mget\"\n   2) (integer) -2\n   3) 1) readonly\n      2) fast\n   4) (integer) 1\n   5) (integer) -1\n   6) (integer) 1\n   ...`\nThe step count allows us to find keys' positions. \nFor example `MSET`: Its syntax is `MSET _key1_ _val1_ [key2] [val2] [key3] [val3]...`, so the keys are at every other position (step value of 2).\nUnlike `MGET`, which uses a step value of 1.\nACL categories\nThis is an array of simple strings that are the ACL categories to which the command belongs.\nPlease refer to the Access Control List page for more information.\nCommand tips\nHelpful information about the command.\nTo be used by clients/proxies.\nPlease check the Command tips page for more information.\nKey specifications\nThis is an array consisting of the command's key specifications.\nEach element in the array is a map describing a method for locating keys in the command's arguments.\nFor more information please check the key specifications page.\nSubcommands\nThis is an array containing all of the command's subcommands, if any.\nSome Redis commands have subcommands (e.g., the `REWRITE` subcommand of `CONFIG`).\nEach element in the array represents one subcommand and follows the same specifications as those of `COMMAND`'s reply.\n@return\n@array-reply: a nested list of command details.\nThe order of commands in the array is random.\n@examples\nThe following is `COMMAND`'s output for the `GET` command:\n```\n1)  1) \"get\"\n    2) (integer) 2\n    3) 1) readonly\n       2) fast\n    4) (integer) 1\n    5) (integer) 1\n    6) (integer) 1\n    7) 1) @read\n       2) @string\n       3) @fast\n    8) (empty array)\n    9) 1) 1) \"flags\"\n          2) 1) read\n          3) \"begin_search\"\n          4) 1) \"type\"\n             2) \"index\"\n             3) \"spec\"\n             4) 1) \"index\"\n                2) (integer) 1\n          5) \"find_keys\"\n          6) 1) \"type\"\n             2) \"range\"\n             3) \"spec\"\n             4) 1) \"lastkey\"\n                2) (integer) 0\n                3) \"keystep\"\n                4) (integer) 1\n                5) \"limit\"\n                6) (integer) 0\n   10) (empty array)\n...",
    "tag": "redis"
  },
  {
    "title": "Options",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/getex.md",
    "content": "Get the value of `key` and optionally set its expiration.\n`GETEX` is similar to `GET`, but is a write command with additional options.\nOptions\nThe `GETEX` command supports a set of options that modify its behavior:\n\n`EX` seconds -- Set the specified expire time, in seconds.\n`PX` milliseconds -- Set the specified expire time, in milliseconds.\n`EXAT` timestamp-seconds -- Set the specified Unix time at which the key will expire, in seconds.\n`PXAT` timestamp-milliseconds -- Set the specified Unix time at which the key will expire, in milliseconds.\n`PERSIST` -- Remove the time to live associated with the key.\n\n@return\n@bulk-string-reply: the value of `key`, or `nil` when `key` does not exist.\n@examples\n```cli\nSET mykey \"Hello\"\nGETEX mykey\nTTL mykey\nGETEX mykey EX 60\nTTL mykey",
    "tag": "redis"
  },
  {
    "title": "Common behavior and options",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrange.md",
    "content": "Returns the specified range of elements in the sorted set stored at `<key>`.\n`ZRANGE` can perform different types of range queries: by index (rank), by the score, or by lexicographical order.\nStarting with Redis 6.2.0, this command can replace the following commands: `ZREVRANGE`, `ZRANGEBYSCORE`, `ZREVRANGEBYSCORE`, `ZRANGEBYLEX` and `ZREVRANGEBYLEX`.\nCommon behavior and options\nThe order of elements is from the lowest to the highest score. Elements with the same score are ordered lexicographically.\nThe optional `REV` argument reverses the ordering, so elements are ordered from highest to lowest score, and score ties are resolved by reverse lexicographical ordering.\nThe optional `LIMIT` argument can be used to obtain a sub-range from the matching elements (similar to SELECT LIMIT offset, count in SQL).\nA negative `<count>` returns all elements from the `<offset>`. Keep in mind that if `<offset>` is large, the sorted set needs to be traversed for `<offset>` elements before getting to the elements to return, which can add up to O(N) time complexity.\nThe optional `WITHSCORES` argument supplements the command's reply with the scores of elements returned. The returned list contains `value1,score1,...,valueN,scoreN` instead of `value1,...,valueN`. Client libraries are free to return a more appropriate data type (suggestion: an array with (value, score) arrays/tuples).\nIndex ranges\nBy default, the command performs an index range query. The `<start>` and `<stop>` arguments represent zero-based indexes, where `0` is the first element, `1` is the next element, and so on. These arguments specify an inclusive range, so for example, `ZRANGE myzset 0 1` will return both the first and the second element of the sorted set.\nThe indexes can also be negative numbers indicating offsets from the end of the sorted set, with `-1` being the last element of the sorted set, `-2` the penultimate element, and so on.\nOut of range indexes do not produce an error.\nIf `<start>` is greater than either the end index of the sorted set or `<stop>`, an empty list is returned.\nIf `<stop>` is greater than the end index of the sorted set, Redis will use the last element of the sorted set.\nScore ranges\nWhen the `BYSCORE` option is provided, the command behaves like `ZRANGEBYSCORE` and returns the range of elements from the sorted set having scores equal or between `<start>` and `<stop>`.\n`<start>` and `<stop>` can be `-inf` and `+inf`, denoting the negative and positive infinities, respectively. This means that you are not required to know the highest or lowest score in the sorted set to get all elements from or up to a certain score.\nBy default, the score intervals specified by `<start>` and `<stop>` are closed (inclusive).\nIt is possible to specify an open interval (exclusive) by prefixing the score\nwith the character `(`.\nFor example:\n`ZRANGE zset (1 5 BYSCORE`\nWill return all elements with `1 < score <= 5` while:\n`ZRANGE zset (5 (10 BYSCORE`\nWill return all the elements with `5 < score < 10` (5 and 10 excluded).\nReverse ranges\nUsing the `REV` option reverses the sorted set, with index 0 as the element with the highest score.\nBy default, `<start>` must be less than or equal to `<stop>` to return anything.\nHowever, if the `BYSCORE`, or `BYLEX` options are selected, the `<start>` is the highest score to consider, and `<stop>` is the lowest score to consider, therefore `<start>` must be greater than or equal to `<stop>` in order to return anything.\nFor example:\n`ZRANGE zset 5 10 REV`\nWill return the elements between index 5 and 10 in the reversed index.\n`ZRANGE zset 10 5 REV BYSCORE`\nWill return all elements with scores less than 10 and greater than 5.\nLexicographical ranges\nWhen the `BYLEX` option is used, the command behaves like `ZRANGEBYLEX` and returns the range of elements from the sorted set between the `<start>` and `<stop>` lexicographical closed range intervals.\nNote that lexicographical ordering relies on all elements having the same score. The reply is unspecified when the elements have different scores.\nValid `<start>` and `<stop>` must start with `(` or `[`, in order to specify\nwhether the range interval is exclusive or inclusive, respectively.\nThe special values of `+` or `-` for `<start>` and `<stop>` mean positive and negative infinite strings, respectively, so for instance the command `ZRANGE myzset - + BYLEX` is guaranteed to return all the elements in the sorted set, providing that all the elements have the same score.\nThe `REV` options reverses the order of the `<start>` and `<stop>` elements, where `<start>` must be lexicographically greater than `<stop>` to produce a non-empty result.\nLexicographical comparison of strings\nStrings are compared as a binary array of bytes. Because of how the ASCII character set is specified, this means that usually this also have the effect of comparing normal ASCII characters in an obvious dictionary way. However, this is not true if non-plain ASCII strings are used (for example, utf8 strings).\nHowever, the user can apply a transformation to the encoded string so that the first part of the element inserted in the sorted set will compare as the user requires for the specific application. For example, if I want to\nadd strings that will be compared in a case-insensitive way, but I still\nwant to retrieve the real case when querying, I can add strings in the\nfollowing way:\n\n\n```ZADD autocomplete 0 foo:Foo 0 bar:BAR 0 zap:zap\n```\n\n\nBecause of the first normalized part in every element (before the colon character), we are forcing a given comparison. However, after the range is queried using `ZRANGE ... BYLEX`, the application can display to the user the second part of the string, after the colon.\nThe binary nature of the comparison allows to use sorted sets as a general purpose index, for example, the first part of the element can be a 64-bit big-endian number. Since big-endian numbers have the most significant bytes in the initial positions, the binary comparison will match the numerical comparison of the numbers. This can be used in order to implement range queries on 64-bit values. As in the example below, after the first 8 bytes, we can store the value of the element we are indexing.\n@return\n@array-reply: list of elements in the specified range (optionally with\ntheir scores, in case the `WITHSCORES` option is given).\n@examples\n`cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZRANGE myzset 0 -1\nZRANGE myzset 2 3\nZRANGE myzset -2 -1`\nThe following example using `WITHSCORES` shows how the command returns always an array, but this time, populated with element_1, score_1, element_2, score_2, ..., element_N, score_N.\n`cli\nZRANGE myzset 0 1 WITHSCORES`\nThis example shows how to query the sorted set by score, excluding the value `1` and up to infinity, returning only the second element of the result:\n```cli\nZRANGE myzset (1 +inf BYSCORE LIMIT 1 1",
    "tag": "redis"
  },
  {
    "title": "getrange.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/getrange.md",
    "content": "Returns the substring of the string value stored at `key`, determined by the\noffsets `start` and `end` (both are inclusive).\nNegative offsets can be used in order to provide an offset starting from the end\nof the string.\nSo -1 means the last character, -2 the penultimate and so forth.\nThe function handles out of range requests by limiting the resulting range to\nthe actual length of the string.\n@return\n@bulk-string-reply\n@examples\n```cli\nSET mykey \"This is a string\"\nGETRANGE mykey 0 3\nGETRANGE mykey -3 -1\nGETRANGE mykey 0 -1\nGETRANGE mykey 10 100",
    "tag": "redis"
  },
  {
    "title": "sort_ro.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/sort_ro.md",
    "content": "Read-only variant of the `SORT` command. It is exactly like the original `SORT` but refuses the `STORE` option and can safely be used in read-only replicas.\nSince the original `SORT` has a `STORE` option it is technically flagged as a writing command in the Redis command table. For this reason read-only replicas in a Redis Cluster will redirect it to the master instance even if the connection is in read-only mode (see the `READONLY` command of Redis Cluster).\nThe `SORT_RO` variant was introduced in order to allow `SORT` behavior in read-only replicas without breaking compatibility on command flags.\nSee original `SORT` for more details.\n@examples\n`SORT_RO mylist BY weight_*->fieldname GET object_*->fieldname`\n@return",
    "tag": "redis"
  },
  {
    "title": "Behavior change history",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/rename.md",
    "content": "Renames `key` to `newkey`.\nIt returns an error when `key` does not exist.\nIf `newkey` already exists it is overwritten, when this happens `RENAME` executes an implicit `DEL` operation, so if the deleted key contains a very big value it may cause high latency even if `RENAME` itself is usually a constant-time operation.\nIn Cluster mode, both `key` and `newkey` must be in the same hash slot, meaning that in practice only keys that have the same hash tag can be reliably renamed in cluster.\n@return\n@simple-string-reply\n@examples\n`cli\nSET mykey \"Hello\"\nRENAME mykey myotherkey\nGET myotherkey`\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "Pattern: accessing the entire bitmap",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/setbit.md",
    "content": "Sets or clears the bit at offset in the string value stored at key.\nThe bit is either set or cleared depending on value, which can be either 0 or\n1.\nWhen key does not exist, a new string value is created.\nThe string is grown to make sure it can hold a bit at offset.\nThe offset argument is required to be greater than or equal to 0, and smaller\nthan 2^32 (this limits bitmaps to 512MB).\nWhen the string at key is grown, added bits are set to 0.\nWarning: When setting the last possible bit (offset equal to 2^32 -1) and\nthe string value stored at key does not yet hold a string value, or holds a\nsmall string value, Redis needs to allocate all intermediate memory which can\nblock the server for some time.\nOn a 2010 MacBook Pro, setting bit number 2^32 -1 (512MB allocation) takes\n~300ms, setting bit number 2^30 -1 (128MB allocation) takes ~80ms, setting bit\nnumber 2^28 -1 (32MB allocation) takes ~30ms and setting bit number 2^26 -1 (8MB\nallocation) takes ~8ms.\nNote that once this first allocation is done, subsequent calls to `SETBIT` for\nthe same key will not have the allocation overhead.\n@return\n@integer-reply: the original bit value stored at offset.\n@examples\n`cli\nSETBIT mykey 7 1\nSETBIT mykey 7 0\nGET mykey`\nPattern: accessing the entire bitmap\nThere are cases when you need to set all the bits of single bitmap at once, for\nexample when initializing it to a default non-zero value. It is possible to do\nthis with multiple calls to the `SETBIT` command, one for each bit that needs to\nbe set. However, so as an optimization you can use a single `SET` command to set\nthe entire bitmap.\nBitmaps are not an actual data type, but a set of bit-oriented operations\ndefined on the String type (for more information refer to the\nBitmaps section of the Data Types Introduction page). This means that\nbitmaps can be used with string commands, and most importantly with `SET` and\n`GET`.\nBecause Redis' strings are binary-safe, a bitmap is trivially encoded as a bytes\nstream. The first byte of the string corresponds to offsets 0..7 of\nthe bitmap, the second byte to the 8..15 range, and so forth.\nFor example, after setting a few bits, getting the string value of the bitmap\nwould look like this:\n```\n\nSETBIT bitmapsarestrings 2 1\nSETBIT bitmapsarestrings 3 1\nSETBIT bitmapsarestrings 5 1\nSETBIT bitmapsarestrings 10 1\nSETBIT bitmapsarestrings 11 1\nSETBIT bitmapsarestrings 14 1\nGET bitmapsarestrings\n\"42\"\n```\n\nBy getting the string representation of a bitmap, the client can then parse the\nresponse's bytes by extracting the bit values using native bit operations in its\nnative programming language. Symmetrically, it is also possible to set an entire\nbitmap by performing the bits-to-bytes encoding in the client and calling `SET`\nwith the resultant string.\nPattern: setting multiple bits\n`SETBIT` excels at setting single bits, and can be called several times when\nmultiple bits need to be set. To optimize this operation you can replace\nmultiple `SETBIT` calls with a single call to the variadic `BITFIELD` command\nand the use of fields of type `u1`.\nFor example, the example above could be replaced by:\n```\n\nBITFIELD bitsinabitmap SET u1 2 1 SET u1 3 1 SET u1 5 1 SET u1 10 1 SET u1 11 1 SET u1 14 1\n```\n\nAdvanced Pattern: accessing bitmap ranges\nIt is also possible to use the `GETRANGE` and `SETRANGE` string commands to\nefficiently access a range of bit offsets in a bitmap. Below is a sample\nimplementation in idiomatic Redis Lua scripting that can be run with the `EVAL`\ncommand:\n```\n--[[\nSets a bitmap range\nBitmaps are stored as Strings in Redis. A range spans one or more bytes,\nso we can call `SETRANGE` when entire bytes need to be set instead of flipping\nindividual bits. Also, to avoid multiple internal memory allocations in\nRedis, we traverse in reverse.\nExpected input:\n  KEYS[1] - bitfield key\n  ARGV[1] - start offset (0-based, inclusive)\n  ARGV[2] - end offset (same, should be bigger than start, no error checking)\n  ARGV[3] - value (should be 0 or 1, no error checking)\n]]--\n-- A helper function to stringify a binary string to semi-binary format\nlocal function tobits(str)\n  local r = ''\n  for i = 1, string.len(str) do\n    local c = string.byte(str, i)\n    local b = ' '\n    for j = 0, 7 do\n      b = tostring(bit.band(c, 1)) .. b\n      c = bit.rshift(c, 1)\n    end\n    r = r .. b\n  end\n  return r\nend\n-- Main\nlocal k = KEYS[1]\nlocal s, e, v = tonumber(ARGV[1]), tonumber(ARGV[2]), tonumber(ARGV[3])\n-- First treat the dangling bits in the last byte\nlocal ms, me = s % 8, (e + 1) % 8\nif me > 0 then\n  local t = math.max(e - me + 1, s)\n  for i = e, t, -1 do\n    redis.call('SETBIT', k, i, v)\n  end\n  e = t\nend\n-- Then the danglings in the first byte\nif ms > 0 then\n  local t = math.min(s - ms + 7, e)\n  for i = s, t, 1 do\n    redis.call('SETBIT', k, i, v)\n  end\n  s = t + 1\nend\n-- Set a range accordingly, if at all\nlocal rs, re = s / 8, (e + 1) / 8\nlocal rl = re - rs\nif rl > 0 then\n  local b = '\\255'\n  if 0 == v then\n    b = '\\0'\n  end\n  redis.call('SETRANGE', k, rs, string.rep(b, rl))\nend\n```\nNote: the implementation for getting a range of bit offsets from a bitmap is",
    "tag": "redis"
  },
  {
    "title": "xinfo-stream.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xinfo-stream.md",
    "content": "This command returns information about the stream stored at `<key>`.\nThe informative details provided by this command are:\n\nlength: the number of entries in the stream (see `XLEN`)\nradix-tree-keys: the number of keys in the underlying radix data structure\nradix-tree-nodes: the number of nodes in the underlying radix data structure\ngroups: the number of consumer groups defined for the stream\nlast-generated-id: the ID of the least-recently entry that was added to the stream\nmax-deleted-entry-id: the maximal entry ID that was deleted from the stream\nentries-added: the count of all entries added to the stream during its lifetime\nfirst-entry: the ID and field-value tuples of the first entry in the stream\nlast-entry: the ID and field-value tuples of the last entry in the stream\n\nThe optional `FULL` modifier provides a more verbose reply.\nWhen provided, the `FULL` reply includes an entries array that consists of the stream entries (ID and field-value tuples) in ascending order.\nFurthermore, groups is also an array, and for each of the consumer groups it consists of the information reported by `XINFO GROUPS` and `XINFO CONSUMERS`.\nThe `COUNT` option can be used to limit the number of stream and PEL entries that are returned (The first `<count>` entries are returned).\nThe default `COUNT` is 10 and a `COUNT` of 0 means that all entries will be returned (execution time may be long if the stream has a lot of entries).\n@return\n@array-reply: a list of informational bits\n@examples\nDefault reply:\n```\n\nXINFO STREAM mystream\n 1) \"length\"\n 2) (integer) 2\n 3) \"radix-tree-keys\"\n 4) (integer) 1\n 5) \"radix-tree-nodes\"\n 6) (integer) 2\n 7) \"last-generated-id\"\n 8) \"1638125141232-0\"\n 9) \"max-deleted-entry-id\"\n10) \"0-0\"\n11) \"entries-added\"\n12) (integer) 2\n13) \"groups\"\n14) (integer) 1\n15) \"first-entry\"\n16) 1) \"1638125133432-0\"\n    2) 1) \"message\"\n       2) \"apple\"\n17) \"last-entry\"\n18) 1) \"1638125141232-0\"\n    2) 1) \"message\"\n       2) \"banana\"\n```\n\nFull reply:\n```\n\nXADD mystream * foo bar\n\"1638125133432-0\"\nXADD mystream * foo bar2\n\"1638125141232-0\"\nXGROUP CREATE mystream mygroup 0-0\nOK\nXREADGROUP GROUP mygroup Alice COUNT 1 STREAMS mystream >\n1) 1) \"mystream\"\n   2) 1) 1) \"1638125133432-0\"\n         2) 1) \"foo\"\n            2) \"bar\"\nXINFO STREAM mystream FULL\n 1) \"length\"\n 2) (integer) 2\n 3) \"radix-tree-keys\"\n 4) (integer) 1\n 5) \"radix-tree-nodes\"\n 6) (integer) 2\n 7) \"last-generated-id\"\n 8) \"1638125141232-0\"\n 9) \"max-deleted-entry-id\"\n10) \"0-0\"\n11) \"entries-added\"\n12) (integer) 2\n13) \"entries\"\n14) 1) 1) \"1638125133432-0\"\n       2) 1) \"foo\"\n          2) \"bar\"\n    2) 1) \"1638125141232-0\"\n       2) 1) \"foo\"\n          2) \"bar2\"\n15) \"groups\"\n16) 1)  1) \"name\"\n        2) \"mygroup\"\n        3) \"last-delivered-id\"\n        4) \"1638125133432-0\"\n        5) \"entries-read\"\n        6) (integer) 1\n        7) \"lag\"\n        8) (integer) 1\n        9) \"pel-count\"\n       10) (integer) 1\n       11) \"pending\"\n       12) 1) 1) \"1638125133432-0\"\n              2) \"Alice\"\n              3) (integer) 1638125153423\n              4) (integer) 1\n       13) \"consumers\"\n       14) 1) 1) \"name\"\n              2) \"Alice\"\n              3) \"seen-time\"\n              4) (integer) 1638125153423\n              5) \"pel-count\"\n              6) (integer) 1\n              7) \"pending\"\n              8) 1) 1) \"1638125133432-0\"\n                    2) (integer) 1638125153423\n                    3) (integer) 1\n\n",
    "tag": "redis"
  },
  {
    "title": "xinfo-groups.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xinfo-groups.md",
    "content": "This command returns the list of all consumers groups of the stream stored at `<key>`.\nBy default, only the following information is provided for each of the groups:\n\nname: the consumer group's name\nconsumers: the number of consumers in the group\npending: the length of the group's pending entries list (PEL), which are messages that were delivered but are yet to be acknowledged\nlast-delivered-id: the ID of the last entry delivered the group's consumers\nentries-read: the logical \"read counter\" of the last entry delivered to group's consumers\nlag: the number of entries in the stream that are still waiting to be delivered to the group's consumers, or a NULL when that number can't be determined.\n\nConsumer group lag\nThe lag of a given consumer group is the number of entries in the range between the group's `entries_read` and the stream's `entries_added`.\nPut differently, it is the number of entries that are yet to be delivered to the group's consumers.\nThe values and trends of this metric are helpful in making scaling decisions about the consumer group.\nYou can address high lag values by adding more consumers to the group, whereas low values may indicate that you can remove consumers from the group to scale it down.\nRedis reports the lag of a consumer group by keeping two counters: the number of all entries added to the stream and the number of logical reads made by the consumer group.\nThe lag is the difference between these two.\nThe stream's counter (the `entries_added` field of the `XINFO STREAM` command) is incremented by one with every `XADD` and counts all of the entries added to the stream during its lifetime.\nThe consumer group's counter, `entries_read`, is the logical counter of entries that the group had read.\nIt is important to note that this counter is only a heuristic rather than an accurate counter, and therefore the use of the term \"logical\".\nThe counter attempts to reflect the number of entries that the group should have read to get to its current `last-delivered-id`.\nThe `entries_read` counter is accurate only in a perfect world, where a consumer group starts at the stream's first entry and processes all of its entries (i.e., no entries deleted before processing).\nThere are two special cases in which this mechanism is unable to report the lag:\n\nA consumer group is created or set with an arbitrary last delivered ID (the `XGROUP CREATE` and `XGROUP SETID` commands, respectively).\n    An arbitrary ID is any ID that isn't the ID of the stream's first entry, its last entry or the zero (\"0-0\") ID.\nOne or more entries between the group's `last-delivered-id` and the stream's `last-generated-id` were deleted (with `XDEL` or a trimming operation).\n\nIn both cases, the group's read counter is considered invalid, and the returned value is set to NULL to signal that the lag isn't currently available.\nHowever, the lag is only temporarily unavailable.\nIt is restored automatically during regular operation as consumers keep processing messages.\nOnce the consumer group delivers the last message in the stream to its members, it will be set with the correct logical read counter, and tracking its lag can be resumed.\n@reply\n@array-reply: a list of consumer groups.\n@examples\n```\n\nXINFO GROUPS mystream\n1)  1) \"name\"\n    2) \"mygroup\"\n    3) \"consumers\"\n    4) (integer) 2\n    5) \"pending\"\n    6) (integer) 2\n    7) \"last-delivered-id\"\n    8) \"1638126030001-0\"\n    9) \"entries-read\"\n   10) (integer) 2\n   11) \"lag\"\n   12) (integer) 0\n2)  1) \"name\"\n    2) \"some-other-group\"\n    3) \"consumers\"\n    4) (integer) 1\n    5) \"pending\"\n    6) (integer) 0\n    7) \"last-delivered-id\"\n    8) \"1638126028070-0\"\n    9) \"entries-read\"\n   10) (integer) 1\n   11) \"lag\"\n   12) (integer) 1\n",
    "tag": "redis"
  },
  {
    "title": "Example",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-delslotsrange.md",
    "content": "The `CLUSTER DELSLOTSRANGE` command is similar to the `CLUSTER DELSLOTS` command in that they both remove hash slots from the node.\nThe difference is that `CLUSTER DELSLOTS` takes a list of hash slots to remove from the node, while `CLUSTER DELSLOTSRANGE` takes a list of slot ranges (specified by start and end slots) to remove from the node.\nExample\nTo remove slots 1 2 3 4 5 from the node, the `CLUSTER DELSLOTS` command is:\n\n\n```> CLUSTER DELSLOTS 1 2 3 4 5\nOK\n```\n\n\nThe same operation can be completed with the following `CLUSTER DELSLOTSRANGE` command:\n\n\n```> CLUSTER DELSLOTSRANGE 1 5\nOK\n```\n\n\nHowever, note that:\n\nThe command only works if all the specified slots are already associated with the node.\nThe command fails if the same slot is specified multiple times.\nAs a side effect of the command execution, the node may go into down state because not all hash slots are covered.\n\nUsage in Redis Cluster\nThis command only works in cluster mode and may be useful for\ndebugging and in order to manually orchestrate a cluster configuration\nwhen a new cluster is created. It is currently not used by `redis-cli`,\nand mainly exists for API completeness.\n@return\n@simple-string-reply: `OK` if the command was successful. Otherwise",
    "tag": "redis"
  },
  {
    "title": "Details on why the ban-list is needed",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-forget.md",
    "content": "The command is used in order to remove a node, specified via its node ID,\nfrom the set of known nodes of the Redis Cluster node receiving the command.\nIn other words the specified node is removed from the nodes table of the\nnode receiving the command.\nBecause when a given node is part of the cluster, all the other nodes\nparticipating in the cluster knows about it, in order for a node to be\ncompletely removed from a cluster, the `CLUSTER FORGET` command must be\nsent to all the remaining nodes, regardless of the fact they are masters\nor replicas.\nHowever the command cannot simply drop the node from the internal node\ntable of the node receiving the command, it also implements a ban-list, not\nallowing the same node to be added again as a side effect of processing the\ngossip section of the heartbeat packets received from other nodes.\nDetails on why the ban-list is needed\nIn the following example we'll show why the command must not just remove\na given node from the nodes table, but also prevent it for being re-inserted\nagain for some time.\nLet's assume we have four nodes, A, B, C and D. In order to\nend with just a three nodes cluster A, B, C we may follow these steps:\n\nReshard all the hash slots from D to nodes A, B, C.\nD is now empty, but still listed in the nodes table of A, B and C.\nWe contact A, and send `CLUSTER FORGET D`.\nB sends node A a heartbeat packet, where node D is listed.\nA does no longer known node D (see step 3), so it starts a handshake with D.\nD ends re-added in the nodes table of A.\n\nAs you can see in this way removing a node is fragile, we need to send\n`CLUSTER FORGET` commands to all the nodes ASAP hoping there are no\ngossip sections processing in the meantime. Because of this problem the\ncommand implements a ban-list with an expire time for each entry.\nSo what the command really does is:\n\nThe specified node gets removed from the nodes table.\nThe node ID of the removed node gets added to the ban-list, for 1 minute.\nThe node will skip all the node IDs listed in the ban-list when processing gossip sections received in heartbeat packets from other nodes.\n\nThis way we have a 60 second window to inform all the nodes in the cluster that\nwe want to remove a node.\nSpecial conditions not allowing the command execution\nThe command does not succeed and returns an error in the following cases:\n\nThe specified node ID is not found in the nodes table.\nThe node receiving the command is a replica, and the specified node ID identifies its current master.\nThe node ID identifies the same node we are sending the command to.\n\n@return",
    "tag": "redis"
  },
  {
    "title": "Consumer groups in 30 seconds",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xreadgroup.md",
    "content": "The `XREADGROUP` command is a special version of the `XREAD` command\nwith support for consumer groups. Probably you will have to understand the\n`XREAD` command before reading this page will makes sense.\nMoreover, if you are new to streams, we recommend to read our\nintroduction to Redis Streams.\nMake sure to understand the concept of consumer group in the introduction\nso that following how this command works will be simpler.\nConsumer groups in 30 seconds\nThe difference between this command and the vanilla `XREAD` is that this\none supports consumer groups.\nWithout consumer groups, just using `XREAD`, all the clients are served with all the entries arriving in a stream. Instead using consumer groups with `XREADGROUP`, it is possible to create groups of clients that consume different parts of the messages arriving in a given stream. If, for instance, the stream gets the new entries A, B, and C and there are two consumers reading via a consumer group, one client will get, for instance, the messages A and C, and the other the message B, and so forth.\nWithin a consumer group, a given consumer (that is, just a client consuming messages from the stream), has to identify with a unique consumer name. Which is just a string.\nOne of the guarantees of consumer groups is that a given consumer can only see the history of messages that were delivered to it, so a message has just a single owner. However there is a special feature called message claiming that allows other consumers to claim messages in case there is a non recoverable failure of some consumer. In order to implement such semantics, consumer groups require explicit acknowledgment of the messages successfully processed by the consumer, via the `XACK` command. This is needed because the stream will track, for each consumer group, who is processing what message.\nThis is how to understand if you want to use a consumer group or not:\n\nIf you have a stream and multiple clients, and you want all the clients to get all the messages, you do not need a consumer group.\nIf you have a stream and multiple clients, and you want the stream to be partitioned or sharded across your clients, so that each client will get a sub set of the messages arriving in a stream, you need a consumer group.\n\nDifferences between XREAD and XREADGROUP\nFrom the point of view of the syntax, the commands are almost the same,\nhowever `XREADGROUP` requires a special and mandatory option:\n\n\n```GROUP <group-name> <consumer-name>\n```\n\n\nThe group name is just the name of a consumer group associated to the stream.\nThe group is created using the `XGROUP` command. The consumer name is the\nstring that is used by the client to identify itself inside the group.\nThe consumer is auto created inside the consumer group the first time it\nis saw. Different clients should select a different consumer name.\nWhen you read with `XREADGROUP`, the server will remember that a given\nmessage was delivered to you: the message will be stored inside the\nconsumer group in what is called a Pending Entries List (PEL), that is\na list of message IDs delivered but not yet acknowledged.\nThe client will have to acknowledge the message processing using `XACK`\nin order for the pending entry to be removed from the PEL. The PEL\ncan be inspected using the `XPENDING` command.\nThe `NOACK` subcommand can be used to avoid adding the message to the PEL in\ncases where reliability is not a requirement and the occasional message loss\nis acceptable. This is equivalent to acknowledging the message when it is read.\nThe ID to specify in the STREAMS option when using `XREADGROUP` can\nbe one of the following two:\n\nThe special `>` ID, which means that the consumer want to receive only messages that were never delivered to any other consumer. It just means, give me new messages.\nAny other ID, that is, 0 or any other valid ID or incomplete ID (just the millisecond time part), will have the effect of returning entries that are pending for the consumer sending the command with IDs greater than the one provided. So basically if the ID is not `>`, then the command will just let the client access its pending entries: messages delivered to it, but not yet acknowledged. Note that in this case, both `BLOCK` and `NOACK` are ignored.\n\nLike `XREAD` the `XREADGROUP` command can be used in a blocking way. There\nare no differences in this regard.\nWhat happens when a message is delivered to a consumer?\nTwo things:\n\nIf the message was never delivered to anyone, that is, if we are talking about a new message, then a PEL (Pending Entries List) is created.\nIf instead the message was already delivered to this consumer, and it is just re-fetching the same message again, then the last delivery counter is updated to the current time, and the number of deliveries is incremented by one. You can access those message properties using the `XPENDING` command.\n\nUsage example\nNormally you use the command like that in order to get new messages and\nprocess them. In pseudo-code:\n```\nWHILE true\n    entries = XREADGROUP GROUP $GroupName $ConsumerName BLOCK 2000 COUNT 10 STREAMS mystream >\n    if entries == nil\n        puts \"Timeout... try again\"\n        CONTINUE\n    end\n\n\n```FOREACH entries AS stream_entries\n    FOREACH stream_entries as message\n        process_message(message.id,message.fields)\n\n        # ACK the message as processed\n        XACK mystream $GroupName message.id\n    END\nEND\n```\n\n\nEND\n```\nIn this way the example consumer code will fetch only new messages, process\nthem, and acknowledge them via `XACK`. However the example code above is\nnot complete, because it does not handle recovering after a crash. What\nwill happen if we crash in the middle of processing messages, is that our\nmessages will remain in the pending entries list, so we can access our\nhistory by giving `XREADGROUP` initially an ID of 0, and performing the same\nloop. Once providing an ID of 0 the reply is an empty set of messages, we\nknow that we processed and acknowledged all the pending messages: we\ncan start to use `>` as ID, in order to get the new messages and rejoin the\nconsumers that are processing new things.\nTo see how the command actually replies, please check the `XREAD` command page.\nWhat happens when a pending message is deleted?\nEntries may be deleted from the stream due to trimming or explicit calls to `XDEL` at any time.\nBy design, Redis doesn't prevent the deletion of entries that are present in the stream's PELs.\nWhen this happens, the PELs retain the deleted entries' IDs, but the actual entry payload is no longer available.\nTherefore, when reading such PEL entries, Redis will return a null value in place of their respective data.\nExample:\n```\n\nXADD mystream 1 myfield mydata\n\"1-0\"\nXGROUP CREATE mystream mygroup 0\nOK\nXREADGROUP GROUP mygroup myconsumer STREAMS mystream >\n1) 1) \"mystream\"\n   2) 1) 1) \"1-0\"\n         2) 1) \"myfield\"\n            2) \"mydata\"\nXDEL mystream 1-0\n(integer) 1\nXREADGROUP GROUP mygroup myconsumer STREAMS mystream 0\n1) 1) \"mystream\"\n   2) 1) 1) \"1-0\"\n         2) (nil)\n```\n\n@return\n@array-reply, specifically:\nThe command returns an array of results: each element of the returned\narray is an array composed of a two element containing the key name and\nthe entries reported for that key. The entries reported are full stream\nentries, having IDs and the list of all the fields and values. Field and\nvalues are guaranteed to be reported in the same order they were added\nby `XADD`.\nWhen BLOCK is used, on timeout a null reply is returned.\nReading the Redis Streams introduction is highly\nsuggested in order to understand more about the streams overall behavior",
    "tag": "redis"
  },
  {
    "title": "zdiffstore.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zdiffstore.md",
    "content": "Computes the difference between the first and all successive input sorted sets\nand stores the result in `destination`. The total number of input keys is\nspecified by `numkeys`.\nKeys that do not exist are considered to be empty sets.\nIf `destination` already exists, it is overwritten.\n@return\n@integer-reply: the number of elements in the resulting sorted set at\n`destination`.\n@examples\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset1 3 \"three\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZDIFFSTORE out 2 zset1 zset2\nZRANGE out 0 -1 WITHSCORES",
    "tag": "redis"
  },
  {
    "title": "latency-graph.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/latency-graph.md",
    "content": "Produces an ASCII-art style graph for the specified event.\n`LATENCY GRAPH` lets you intuitively understand the latency trend of an `event` via state-of-the-art visualization. It can be used for quickly grasping the situation before resorting to means such parsing the raw data from `LATENCY HISTORY` or external tooling.\nValid values for `event` are:\n* `active-defrag-cycle`\n* `aof-fsync-always`\n* `aof-stat`\n* `aof-rewrite-diff-write`\n* `aof-rename`\n* `aof-write`\n* `aof-write-active-child`\n* `aof-write-alone`\n* `aof-write-pending-fsync`\n* `command`\n* `expire-cycle`\n* `eviction-cycle`\n* `eviction-del`\n* `fast-command`\n* `fork`\n* `rdb-unlink-temp-file`\n@examples\n```\n127.0.0.1:6379> latency reset command\n(integer) 0\n127.0.0.1:6379> debug sleep .1\nOK\n127.0.0.1:6379> debug sleep .2\nOK\n127.0.0.1:6379> debug sleep .3\nOK\n127.0.0.1:6379> debug sleep .5\nOK\n127.0.0.1:6379> debug sleep .4\nOK\n127.0.0.1:6379> latency graph command\ncommand - high 500 ms, low 101 ms (all time high 500 ms)\n\n#\n||\n |||\n||||\n11186\n542ss\nsss\n```\nThe vertical labels under each graph column represent the amount of seconds,\nminutes, hours or days ago the event happened. For example \"15s\" means that the\nfirst graphed event happened 15 seconds ago.\nThe graph is normalized in the min-max scale so that the zero (the underscore\nin the lower row) is the minimum, and a # in the higher row is the maximum.\nFor more information refer to the Latency Monitoring Framework page.\n@return",
    "tag": "redis"
  },
  {
    "title": "Security notice",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/auth.md",
    "content": "The AUTH command authenticates the current connection in two cases:\n\nIf the Redis server is password protected via the `requirepass` option.\nIf a Redis 6.0 instance, or greater, is using the Redis ACL system.\n\nRedis versions prior of Redis 6 were only able to understand the one argument\nversion of the command:\n\n\n```AUTH <password>\n```\n\n\nThis form just authenticates against the password set with `requirepass`.\nIn this configuration Redis will deny any command executed by the just\nconnected clients, unless the connection gets authenticated via `AUTH`.\nIf the password provided via AUTH matches the password in the configuration file, the server replies with the `OK` status code and starts accepting commands.\nOtherwise, an error is returned and the clients needs to try a new password.\nWhen Redis ACLs are used, the command should be given in an extended way:\n\n\n```AUTH <username> <password>\n```\n\n\nIn order to authenticate the current connection with one of the connections\ndefined in the ACL list (see `ACL SETUSER`) and the official ACL guide for more information.\nWhen ACLs are used, the single argument form of the command, where only the password is specified, assumes that the implicit username is \"default\".\nSecurity notice\nBecause of the high performance nature of Redis, it is possible to try\na lot of passwords in parallel in very short time, so make sure to generate a\nstrong and very long password so that this attack is infeasible.\nA good way to generate strong passwords is via the `ACL GENPASS` command.\n@return",
    "tag": "redis"
  },
  {
    "title": "pubsub-shardchannels.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pubsub-shardchannels.md",
    "content": "Lists the currently active shard channels.\nAn active shard channel is a Pub/Sub shard channel with one or more subscribers.\nIf no `pattern` is specified, all the channels are listed, otherwise if pattern is specified only channels matching the specified glob-style pattern are listed.\nThe information returned about the active shard channels are at the shard level and not at the cluster level.\n@return\n@array-reply: a list of active channels, optionally matching the specified pattern.\n@examples\n```\n\nPUBSUB SHARDCHANNELS\n1) \"orders\"\nPUBSUB SHARDCHANNELS o*\n1) \"orders\"\n",
    "tag": "redis"
  },
  {
    "title": "Pattern: real-time metrics using bitmaps",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bitcount.md",
    "content": "Count the number of set bits (population counting) in a string.\nBy default all the bytes contained in the string are examined.\nIt is possible to specify the counting operation only in an interval passing the\nadditional arguments start and end.\nLike for the `GETRANGE` command start and end can contain negative values in\norder to index bytes starting from the end of the string, where -1 is the last\nbyte, -2 is the penultimate, and so forth.\nNon-existent keys are treated as empty strings, so the command will return zero.\nBy default, the additional arguments start and end specify a byte index.\nWe can use an additional argument `BIT` to specify a bit index.\nSo 0 is the first bit, 1 is the second bit, and so forth.\nFor negative values, -1 is the last bit, -2 is the penultimate, and so forth.\n@return\n@integer-reply\nThe number of bits set to 1.\n@examples\n`cli\nSET mykey \"foobar\"\nBITCOUNT mykey\nBITCOUNT mykey 0 0\nBITCOUNT mykey 1 1\nBITCOUNT mykey 1 1 BYTE\nBITCOUNT mykey 5 30 BIT`\nPattern: real-time metrics using bitmaps\nBitmaps are a very space-efficient representation of certain kinds of\ninformation.\nOne example is a Web application that needs the history of user visits, so that\nfor instance it is possible to determine what users are good targets of beta\nfeatures.\nUsing the `SETBIT` command this is trivial to accomplish, identifying every day\nwith a small progressive integer.\nFor instance day 0 is the first day the application was put online, day 1 the\nnext day, and so forth.\nEvery time a user performs a page view, the application can register that in\nthe current day the user visited the web site using the `SETBIT` command setting\nthe bit corresponding to the current day.\nLater it will be trivial to know the number of single days the user visited the\nweb site simply calling the `BITCOUNT` command against the bitmap.\nA similar pattern where user IDs are used instead of days is described\nin the article called \"Fast easy realtime metrics using Redis\nbitmaps\".\nPerformance considerations\nIn the above example of counting days, even after 10 years the application is\nonline we still have just `365*10` bits of data per user, that is just 456 bytes\nper user.\nWith this amount of data `BITCOUNT` is still as fast as any other O(1) Redis\ncommand like `GET` or `INCR`.\nWhen the bitmap is big, there are two alternatives:\n\nTaking a separated key that is incremented every time the bitmap is modified.\n  This can be very efficient and atomic using a small Redis Lua script.\nRunning the bitmap incrementally using the `BITCOUNT` start and end\n  optional parameters, accumulating the results client-side, and optionally\n",
    "tag": "redis"
  },
  {
    "title": "lindex.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lindex.md",
    "content": "Returns the element at index `index` in the list stored at `key`.\nThe index is zero-based, so `0` means the first element, `1` the second element\nand so on.\nNegative indices can be used to designate elements starting at the tail of the\nlist.\nHere, `-1` means the last element, `-2` means the penultimate and so forth.\nWhen the value at `key` is not a list, an error is returned.\n@return\n@bulk-string-reply: the requested element, or `nil` when `index` is out of range.\n@examples\n```cli\nLPUSH mylist \"World\"\nLPUSH mylist \"Hello\"\nLINDEX mylist 0\nLINDEX mylist -1\nLINDEX mylist 3",
    "tag": "redis"
  },
  {
    "title": "cluster-set-config-epoch.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-set-config-epoch.md",
    "content": "This command sets a specific config epoch in a fresh node. It only works when:\n\nThe nodes table of the node is empty.\nThe node current config epoch is zero.\n\nThese prerequisites are needed since usually, manually altering the\nconfiguration epoch of a node is unsafe, we want to be sure that the node with\nthe higher configuration epoch value (that is the last that failed over) wins\nover other nodes in claiming the hash slots ownership.\nHowever there is an exception to this rule, and it is when a new\ncluster is created from scratch. Redis Cluster config epoch collision\nresolution algorithm can deal with new nodes all configured with the\nsame configuration at startup, but this process is slow and should be\nthe exception, only to make sure that whatever happens, two more\nnodes eventually always move away from the state of having the same\nconfiguration epoch.\nSo, using `CLUSTER SET-CONFIG-EPOCH`, when a new cluster is created, we can\nassign a different progressive configuration epoch to each node before\njoining the cluster together.\n@return",
    "tag": "redis"
  },
  {
    "title": "zrevrange.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrevrange.md",
    "content": "Returns the specified range of elements in the sorted set stored at `key`.\nThe elements are considered to be ordered from the highest to the lowest score.\nDescending lexicographical order is used for elements with equal score.\nApart from the reversed ordering, `ZREVRANGE` is similar to `ZRANGE`.\n@return\n@array-reply: list of elements in the specified range (optionally with\ntheir scores).\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREVRANGE myzset 0 -1\nZREVRANGE myzset 2 3\nZREVRANGE myzset -2 -1",
    "tag": "redis"
  },
  {
    "title": "command-docs.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/command-docs.md",
    "content": "Return documentary information about commands.\nBy default, the reply includes all of the server's commands.\nYou can use the optional command-name argument to specify the names of one or more commands.\nThe reply includes a map for each returned command.\nThe following keys may be included in the mapped reply:\n\nsummary: short command description.\nsince: the Redis version that added the command (or for module commands, the module version).\ngroup: the functional group to which the command belongs.\n  Possible values are:\nbitmap\ncluster\nconnection\ngeneric\ngeo\nhash\nhyperloglog\nlist\nmodule\npubsub\nscripting\nsentinel\nserver\nset\nsorted-set\nstream\nstring\ntransactions\ncomplexity: a short explanation about the command's time complexity.\ndoc_flags: an array of documentation flags.\n  Possible values are:\ndeprecated: the command is deprecated.\nsyscmd: a system command that isn't meant to be called by users.\ndeprecated_since: the Redis version that deprecated the command (or for module commands, the module version)..\nreplaced_by: the alternative for a deprecated command.\nhistory: an array of historical notes describing changes to the command's behavior or arguments.\n  Each entry is an array itself, made up of two elements:\nThe Redis version that the entry applies to.\nThe description of the change.\narguments: an array of maps that describe the command's arguments.\n  Please refer to the Redis command arguments page for more information.\n\n@return\n@array-reply: a map as a flattened array as described above.\n@examples\n```cli\nCOMMAND DOCS SET",
    "tag": "redis"
  },
  {
    "title": "client-caching.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-caching.md",
    "content": "This command controls the tracking of the keys in the next command executed\nby the connection, when tracking is enabled in `OPTIN` or `OPTOUT` mode.\nPlease check the\nclient side caching documentation for\nbackground information.\nWhen tracking is enabled Redis, using the `CLIENT TRACKING` command, it is\npossible to specify the `OPTIN` or `OPTOUT` options, so that keys\nin read only commands are not automatically remembered by the server to\nbe invalidated later. When we are in `OPTIN` mode, we can enable the\ntracking of the keys in the next command by calling `CLIENT CACHING yes`\nimmediately before it. Similarly when we are in `OPTOUT` mode, and keys\nare normally tracked, we can avoid the keys in the next command to be\ntracked using `CLIENT CACHING no`.\nBasically the command sets a state in the connection, that is valid only\nfor the next command execution, that will modify the behavior of client\ntracking.\n@return",
    "tag": "redis"
  },
  {
    "title": "How to specify intervals",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrangebylex.md",
    "content": "When all the elements in a sorted set are inserted with the same score, in order to force lexicographical ordering, this command returns all the elements in the sorted set at `key` with a value between `min` and `max`.\nIf the elements in the sorted set have different scores, the returned elements are unspecified.\nThe elements are considered to be ordered from lower to higher strings as compared byte-by-byte using the `memcmp()` C function. Longer strings are considered greater than shorter strings if the common part is identical.\nThe optional `LIMIT` argument can be used to only get a range of the matching\nelements (similar to SELECT LIMIT offset, count in SQL). A negative `count`\nreturns all elements from the `offset`.\nKeep in mind that if `offset` is large, the sorted set needs to be traversed for\n`offset` elements before getting to the elements to return, which can add up to\nO(N) time complexity.\nHow to specify intervals\nValid start and stop must start with `(` or `[`, in order to specify\nif the range item is respectively exclusive or inclusive.\nThe special values of `+` or `-` for start and stop have the special\nmeaning or positively infinite and negatively infinite strings, so for\ninstance the command ZRANGEBYLEX myzset - + is guaranteed to return\nall the elements in the sorted set, if all the elements have the same\nscore.\nDetails on strings comparison\nStrings are compared as binary array of bytes. Because of how the ASCII character\nset is specified, this means that usually this also have the effect of comparing\nnormal ASCII characters in an obvious dictionary way. However this is not true\nif non plain ASCII strings are used (for example utf8 strings).\nHowever the user can apply a transformation to the encoded string so that\nthe first part of the element inserted in the sorted set will compare as the\nuser requires for the specific application. For example if I want to\nadd strings that will be compared in a case-insensitive way, but I still\nwant to retrieve the real case when querying, I can add strings in the\nfollowing way:\n\n\n```ZADD autocomplete 0 foo:Foo 0 bar:BAR 0 zap:zap\n```\n\n\nBecause of the first normalized part in every element (before the colon character), we are forcing a given comparison, however after the range is queries using `ZRANGEBYLEX` the application can display to the user the second part of the string, after the colon.\nThe binary nature of the comparison allows to use sorted sets as a general\npurpose index, for example the first part of the element can be a 64 bit\nbig endian number: since big endian numbers have the most significant bytes\nin the initial positions, the binary comparison will match the numerical\ncomparison of the numbers. This can be used in order to implement range\nqueries on 64 bit values. As in the example below, after the first 8 bytes\nwe can store the value of the element we are actually indexing.\n@return\n@array-reply: list of elements in the specified score range.\n@examples\n```cli\nZADD myzset 0 a 0 b 0 c 0 d 0 e 0 f 0 g\nZRANGEBYLEX myzset - [c\nZRANGEBYLEX myzset - (c\nZRANGEBYLEX myzset [aaa (g",
    "tag": "redis"
  },
  {
    "title": "save.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/save.md",
    "content": "The `SAVE` commands performs a synchronous save of the dataset producing a\npoint in time snapshot of all the data inside the Redis instance, in the form\nof an RDB file.\nYou almost never want to call `SAVE` in production environments where it will\nblock all the other clients.\nInstead usually `BGSAVE` is used.\nHowever in case of issues preventing Redis to create the background saving child\n(for instance errors in the fork(2) system call), the `SAVE` command can be a\ngood last resort to perform the dump of the latest dataset.\nPlease refer to the persistence documentation for detailed information.\n@return",
    "tag": "redis"
  },
  {
    "title": "cluster-slaves.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-slaves.md",
    "content": "A note about the word slave used in this man page and command name: starting with Redis version 5, if not for backward compatibility, the Redis project no longer uses the word slave. Please use the new command `CLUSTER REPLICAS`. The command `CLUSTER SLAVES` will continue to work for backward compatibility.\nThe command provides a list of replica nodes replicating from the specified\nmaster node. The list is provided in the same format used by `CLUSTER NODES` (please refer to its documentation for the specification of the format).\nThe command will fail if the specified node is not known or if it is not\na master according to the node table of the node receiving the command.\nNote that if a replica is added, moved, or removed from a given master node,\nand we ask `CLUSTER SLAVES` to a node that has not yet received the\nconfiguration update, it may show stale information. However eventually\n(in a matter of seconds if there are no network partitions) all the nodes\nwill agree about the set of nodes associated with a given master.\n@return",
    "tag": "redis"
  },
  {
    "title": "latency-reset.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/latency-reset.md",
    "content": "The `LATENCY RESET` command resets the latency spikes time series of all, or only some, events.\nWhen the command is called without arguments, it resets all the\nevents, discarding the currently logged latency spike events, and resetting\nthe maximum event time register.\nIt is possible to reset only specific events by providing the `event` names\nas arguments.\nValid values for `event` are:\n* `active-defrag-cycle`\n* `aof-fsync-always`\n* `aof-stat`\n* `aof-rewrite-diff-write`\n* `aof-rename`\n* `aof-write`\n* `aof-write-active-child`\n* `aof-write-alone`\n* `aof-write-pending-fsync`\n* `command`\n* `expire-cycle`\n* `eviction-cycle`\n* `eviction-del`\n* `fast-command`\n* `fork`\n* `rdb-unlink-temp-file`\nFor more information refer to the Latency Monitoring Framework page.\n@return",
    "tag": "redis"
  },
  {
    "title": "hello.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/hello.md",
    "content": "Switch to a different protocol, optionally authenticating and setting the\nconnection's name, or provide a contextual client report.\nRedis version 6 and above supports two protocols: the old protocol, RESP2, and\na new one introduced with Redis 6, RESP3. RESP3 has certain advantages since\nwhen the connection is in this mode, Redis is able to reply with more semantical\nreplies: for instance, `HGETALL` will return a map type, so a client library\nimplementation no longer requires to know in advance to translate the array into\na hash before returning it to the caller. For a full coverage of RESP3, please\ncheck this repository.\nIn Redis 6 connections start in RESP2 mode, so clients implementing RESP2 do\nnot need to updated or changed. There are no short term plans to drop support for\nRESP2, although future version may default to RESP3.\n`HELLO` always replies with a list of current server and connection properties,\nsuch as: versions, modules loaded, client ID, replication role and so forth.\nWhen called without any arguments in Redis 6.2 and its default use of RESP2\nprotocol, the reply looks like this:\n\n\n```> HELLO\n 1) \"server\"\n 2) \"redis\"\n 3) \"version\"\n 4) \"255.255.255\"\n 5) \"proto\"\n 6) (integer) 2\n 7) \"id\"\n 8) (integer) 5\n 9) \"mode\"\n10) \"standalone\"\n11) \"role\"\n12) \"master\"\n13) \"modules\"\n14) (empty array)\n```\n\n\nClients that want to handshake using the RESP3 mode need to call the `HELLO`\ncommand and specify the value \"3\" as the `protover` argument, like so:\n\n\n```> HELLO 3\n1# \"server\" => \"redis\"\n2# \"version\" => \"6.0.0\"\n3# \"proto\" => (integer) 3\n4# \"id\" => (integer) 10\n5# \"mode\" => \"standalone\"\n6# \"role\" => \"master\"\n7# \"modules\" => (empty array)\n```\n\n\nBecause `HELLO` replies with useful information, and given that `protover` is\noptional or can be set to \"2\", client library authors may consider using this\ncommand instead of the canonical `PING` when setting up the connection.\nWhen called with the optional `protover` argument, this command switches the\nprotocol to the specified version and also accepts the following options:\n\n`AUTH <username> <password>`: directly authenticate the connection in addition to switching to the specified protocol version. This makes calling `AUTH` before `HELLO` unnecessary when setting up a new connection. Note that the `username` can be set to \"default\" to authenticate against a server that does not use ACLs, but rather the simpler `requirepass` mechanism of Redis prior to version 6.\n`SETNAME <clientname>`: this is the equivalent of calling `CLIENT SETNAME`.\n\n@return",
    "tag": "redis"
  },
  {
    "title": "latency-histogram.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/latency-histogram.md",
    "content": "The `LATENCY HISTOGRAM` command reports a cumulative distribution of latencies in the format of a histogram for each of the specified command names. \nIf no command names are specified then all commands that contain latency information will be replied.\nEach reported histogram has the following fields:\n\nCommand name.\nThe total calls for that command.\nA map of time buckets:\nEach bucket represents a latency range.\nEach bucket covers twice the previous bucket's range.\nEmpty buckets are not printed.\nThe tracked latencies are between 1 microsecond and roughly 1 second.\nEverything above 1 sec is considered +Inf.\nAt max there will be log2(1000000000)=30 buckets.\n\nThis command requires the extended latency monitoring feature to be enabled (by default it's enabled).\nIf you need to enable it, use `CONFIG SET latency-tracking yes`.\n@examples\n`127.0.0.1:6379> LATENCY HISTOGRAM set\n1# \"set\" =>\n   1# \"calls\" => (integer) 100000\n   2# \"histogram_usec\" =>\n      1# (integer) 1 => (integer) 99583\n      2# (integer) 2 => (integer) 99852\n      3# (integer) 4 => (integer) 99914\n      4# (integer) 8 => (integer) 99940\n      5# (integer) 16 => (integer) 99968\n      6# (integer) 33 => (integer) 100000`\n@return\n@array-reply: specifically:",
    "tag": "redis"
  },
  {
    "title": "xgroup-setid.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xgroup-setid.md",
    "content": "Set the last delivered ID for a consumer group.\nNormally, a consumer group's last delivered ID is set when the group is created with `XGROUP CREATE`.\nThe `XGROUP SETID` command allows modifying the group's last delivered ID, without having to delete and recreate the group.\nFor instance if you want the consumers in a consumer group to re-process all the messages in a stream, you may want to set its next ID to 0:\n\n\n```XGROUP SETID mystream mygroup 0\n```\n\n\nThe optional `entries_read` argument can be specified to enable consumer group lag tracking for an arbitrary ID.\nAn arbitrary ID is any ID that isn't the ID of the stream's first entry, its last entry or the zero (\"0-0\") ID.\nThis can be useful you know exactly how many entries are between the arbitrary ID (excluding it) and the stream's last entry.\nIn such cases, the `entries_read` can be set to the stream's `entries_added` subtracted with the number of entries.\n@return",
    "tag": "redis"
  },
  {
    "title": "memory-usage.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/memory-usage.md",
    "content": "The `MEMORY USAGE` command reports the number of bytes that a key and its value\nrequire to be stored in RAM.\nThe reported usage is the total of memory allocations for data and\nadministrative overheads that a key its value require.\nFor nested data types, the optional `SAMPLES` option can be provided, where\n`count` is the number of sampled nested values. The samples are averaged to estimate the total size.\nBy default, this option is set to `5`. To sample the all of the nested values, use `SAMPLES 0`.\n@examples\nWith Redis v4.0.1 64-bit and jemalloc, the empty string measures as follows:\n```\n\nSET \"\" \"\"\nOK\nMEMORY USAGE \"\"\n(integer) 51\n```\n\nThese bytes are pure overhead at the moment as no actual data is stored, and are\nused for maintaining the internal data structures of the server. Longer keys and\nvalues show asymptotically linear usage.\n```\n\nSET foo bar\nOK\nMEMORY USAGE foo\n(integer) 54\nSET cento 01234567890123456789012345678901234567890123\n45678901234567890123456789012345678901234567890123456789\nOK\n127.0.0.1:6379> MEMORY USAGE cento\n(integer) 153\n```\n\n@return",
    "tag": "redis"
  },
  {
    "title": "latency-doctor.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/latency-doctor.md",
    "content": "The `LATENCY DOCTOR` command reports about different latency-related issues and advises about possible remedies.\nThis command is the most powerful analysis tool in the latency monitoring\nframework, and is able to provide additional statistical data like the average\nperiod between latency spikes, the median deviation, and a human-readable\nanalysis of the event. For certain events, like `fork`, additional information\nis provided, like the rate at which the system forks processes.\nThis is the output you should post in the Redis mailing list if you are\nlooking for help about Latency related issues.\n@examples\n```\n127.0.0.1:6379> latency doctor\nDave, I have observed latency spikes in this Redis instance.\nYou don't mind talking about it, do you Dave?\n\ncommand: 5 latency spikes (average 300ms, mean deviation 120ms,\n    period 73.40 sec). Worst all time event 500ms.\n\nI have a few advices for you:\n\nYour current Slow Log configuration only logs events that are\n    slower than your configured latency monitor threshold. Please\n    use 'CONFIG SET slowlog-log-slower-than 1000'.\nCheck your Slow Log to understand what are the commands you are\n    running which are too slow to execute. Please check\n    http://redis.io/commands/slowlog for more information.\nDeleting, expiring or evicting (because of maxmemory policy)\n    large objects is a blocking operation. If you have very large\n    objects that are often deleted, expired, or evicted, try to\n    fragment those objects into multiple smaller objects.\n```\n\nNote: the doctor has erratic psychological behaviors, so we recommend interacting with it carefully.\nFor more information refer to the Latency Monitoring Framework page.\n@return",
    "tag": "redis"
  },
  {
    "title": "function-stats.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/function-stats.md",
    "content": "Return information about the function that's currently running and information about the available execution engines.\nThe reply is map with two keys:\n\n`running_script`: information about the running script.\n  If there's no in-flight function, the server replies with a nil.\n  Otherwise, this is a map with the following keys:\nname: the name of the function.\ncommand: the command and arguments used for invoking the function.\nduration_ms: the function's runtime duration in milliseconds.\n`engines`: this is a map of maps. Each entry in the map represent a single engine.\n   Engine map contains statistics about the engine like number of functions and number of libraries.\n\nYou can use this command to inspect the invocation of a long-running function and decide whether kill it with the `FUNCTION KILL` command.\nFor more information please refer to Introduction to Redis Functions.\n@return",
    "tag": "redis"
  },
  {
    "title": "lpos.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lpos.md",
    "content": "The command returns the index of matching elements inside a Redis list.\nBy default, when no options are given, it will scan the list from head to tail,\nlooking for the first match of \"element\". If the element is found, its index (the zero-based position in the list) is returned. Otherwise, if no match is found, `nil` is returned.\n```\n\nRPUSH mylist a b c 1 2 3 c c\nLPOS mylist c\n2\n```\n\nThe optional arguments and options can modify the command's behavior.\nThe `RANK` option specifies the \"rank\" of the first element to return, in case there are multiple matches. A rank of 1 means to return the first match, 2 to return the second match, and so forth.\nFor instance, in the above example the element \"c\" is present multiple times, if I want the index of the second match, I'll write:\n```\n\nLPOS mylist c RANK 2\n6\n```\n\nThat is, the second occurrence of \"c\" is at position 6.\nA negative \"rank\" as the `RANK` argument tells `LPOS` to invert the search direction, starting from the tail to the head.\nSo, we want to say, give me the first element starting from the tail of the list:\n```\n\nLPOS mylist c RANK -1\n7\n```\n\nNote that the indexes are still reported in the \"natural\" way, that is, considering the first element starting from the head of the list at index 0, the next element at index 1, and so forth. This basically means that the returned indexes are stable whatever the rank is positive or negative.\nSometimes we want to return not just the Nth matching element, but the position of all the first N matching elements. This can be achieved using the `COUNT` option.\n```\n\nLPOS mylist c COUNT 2\n[2,6]\n```\n\nWe can combine `COUNT` and `RANK`, so that `COUNT` will try to return up to the specified number of matches, but starting from the Nth match, as specified by the `RANK` option.\n```\n\nLPOS mylist c RANK -1 COUNT 2\n[7,6]\n```\n\nWhen `COUNT` is used, it is possible to specify 0 as the number of matches, as a way to tell the command we want all the matches found returned as an array of indexes. This is better than giving a very large `COUNT` option because it is more general.\n```\n\nLPOS mylist c COUNT 0\n[2,6,7]\n```\n\nWhen `COUNT` is used and no match is found, an empty array is returned. However when `COUNT` is not used and there are no matches, the command returns `nil`.\nFinally, the `MAXLEN` option tells the command to compare the provided element only with a given maximum number of list items. So for instance specifying `MAXLEN 1000` will make sure that the command performs only 1000 comparisons, effectively running the algorithm on a subset of the list (the first part or the last part depending on the fact we use a positive or negative rank). This is useful to limit the maximum complexity of the command. It is also useful when we expect the match to be found very early, but want to be sure that in case this is not true, the command does not take too much time to run.\nWhen `MAXLEN` is used, it is possible to specify 0 as the maximum number of comparisons, as a way to tell the command we want unlimited comparisons. This is better than giving a very large `MAXLEN` option because it is more general.\n@return\nThe command returns the integer representing the matching element, or `nil` if there is no match. However, if the `COUNT` option is given the command returns an array (empty if there are no matches).\n@examples\n```cli\nRPUSH mylist a b c d 1 2 3 4 3 3 3\nLPOS mylist 3\nLPOS mylist 3 COUNT 0 RANK 2",
    "tag": "redis"
  },
  {
    "title": "acl-log.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-log.md",
    "content": "The command shows a list of recent ACL security events:\n\nFailures to authenticate their connections with `AUTH` or `HELLO`.\nCommands denied because against the current ACL rules.\nCommands denied because accessing keys not allowed in the current ACL rules.\n\nThe optional argument specifies how many entries to show. By default\nup to ten failures are returned. The special `RESET` argument clears the log.\nEntries are displayed starting from the most recent.\n@return\nWhen called to show security events:\n@array-reply: a list of ACL security events.\nWhen called with `RESET`:\n@simple-string-reply: `OK` if the security log was cleared.\n@examples\n```\n\nAUTH someuser wrongpassword\n(error) WRONGPASS invalid username-password pair\nACL LOG 1\n1)  1) \"count\"\n    2) (integer) 1\n    3) \"reason\"\n    4) \"auth\"\n    5) \"context\"\n    6) \"toplevel\"\n    7) \"object\"\n    8) \"AUTH\"\n    9) \"username\"\n   10) \"someuser\"\n   11) \"age-seconds\"\n   12) \"8.038\"\n   13) \"client-info\"\n   14) \"id=3 addr=127.0.0.1:57275 laddr=127.0.0.1:6379 fd=8 name= age=16 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=48 qbuf-free=16842 argv-mem=25 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18737 events=r cmd=auth user=default redir=-1 resp=2\"\n   15) \"entry-id\"\n   16) (integer) 0\n   17) \"timestamp-created\"\n   18) (integer) 1675361492408\n   19) \"timestamp-last-updated\"\n   20) (integer) 1675361492408\n```\n\nEach log entry is composed of the following fields:\n\n`count`: The number of security events detected within a 60 second period that are represented by this entry.\n`reason`: The reason that the security events were logged. Either `command`, `key`, `channel`, or `auth`.\n`context`: The context that the security events were detected in. Either `toplevel`, `multi`, `lua`, or `module`.\n`object`: The resource that the user had insufficient permissions to access. `auth` when the reason is `auth`.\n`username`: The username that executed the command that caused the security events or the username that had a failed authentication attempt.\n`age-seconds`: Age of the log entry in seconds.\n`client-info`: Displays the client info of a client which caused one of the security events.\n`entry-id`: The sequence number of the entry (starting at 0) since the server process started. Can also be used to check if items were \u201clost\u201d, if they fell between periods.\n`timestamp-created`: A UNIX timestamp in `milliseconds` at the time the entry was first created.\n",
    "tag": "redis"
  },
  {
    "title": "function-list.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/function-list.md",
    "content": "Return information about the functions and libraries.\nYou can use the optional `LIBRARYNAME` argument to specify a pattern for matching library names.\nThe optional `WITHCODE` modifier will cause the server to include the libraries source implementation in the reply.\nThe following information is provided for each of the libraries in the response:\n\nlibrary_name: the name of the library.\nengine: the engine of the library.\nfunctions: the list of functions in the library.\n  Each function has the following fields:\nname: the name of the function.\ndescription: the function's description.\nflags: an array of function flags.\nlibrary_code: the library's source code (when given the `WITHCODE` modifier).\n\nFor more information please refer to Introduction to Redis Functions.\n@return",
    "tag": "redis"
  },
  {
    "title": "georadiusbymember.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/georadiusbymember.md",
    "content": "This command is exactly like `GEORADIUS` with the sole difference that instead\nof taking, as the center of the area to query, a longitude and latitude value, it takes the name of a member already existing inside the geospatial index represented by the sorted set.\nThe position of the specified member is used as the center of the query.\nPlease check the example below and the `GEORADIUS` documentation for more information about the command and its options.\nNote that `GEORADIUSBYMEMBER_RO` is also available since Redis 3.2.10 and Redis 4.0.0 in order to provide a read-only command that can be used in replicas. See the `GEORADIUS` page for more information.\n@examples\n```cli\nGEOADD Sicily 13.583333 37.316667 \"Agrigento\"\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEORADIUSBYMEMBER Sicily Agrigento 100 km",
    "tag": "redis"
  },
  {
    "title": "Read-only variants",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/georadius.md",
    "content": "Return the members of a sorted set populated with geospatial information using `GEOADD`, which are within the borders of the area specified with the center location and the maximum distance from the center (the radius).\nThis manual page also covers the `GEORADIUS_RO` and `GEORADIUSBYMEMBER_RO` variants (see the section below for more information).\nThe common use case for this command is to retrieve geospatial items near a specified point not farther than a given amount of meters (or other units). This allows, for example, to suggest mobile users of an application nearby places.\nThe radius is specified in one of the following units:\n\nm for meters.\nkm for kilometers.\nmi for miles.\nft for feet.\n\nThe command optionally returns additional information using the following options:\n\n`WITHDIST`: Also return the distance of the returned items from the specified center. The distance is returned in the same unit as the unit specified as the radius argument of the command.\n`WITHCOORD`: Also return the longitude,latitude coordinates of the matching items.\n`WITHHASH`: Also return the raw geohash-encoded sorted set score of the item, in the form of a 52 bit unsigned integer. This is only useful for low level hacks or debugging and is otherwise of little interest for the general user.\n\nThe command default is to return unsorted items. Two different sorting methods can be invoked using the following two options:\n\n`ASC`: Sort returned items from the nearest to the farthest, relative to the center.\n`DESC`: Sort returned items from the farthest to the nearest, relative to the center.\n\nBy default all the matching items are returned. It is possible to limit the results to the first N matching items by using the COUNT `<count>` option.\nWhen `ANY` is provided the command will return as soon as enough matches are found,\nso the results may not be the ones closest to the specified point, but on the other hand, the effort invested by the server is significantly lower.\nWhen `ANY` is not provided, the command will perform an effort that is proportional to the number of items matching the specified area and sort them,\nso to query very large areas with a very small `COUNT` option may be slow even if just a few results are returned.\nBy default the command returns the items to the client. It is possible to store the results with one of these options:\n\n`!STORE`: Store the items in a sorted set populated with their geospatial information.\n`!STOREDIST`: Store the items in a sorted set populated with their distance from the center as a floating point number, in the same unit specified in the radius.\n\n@return\n@array-reply, specifically:\n\nWithout any `WITH` option specified, the command just returns a linear array like [\"New York\",\"Milan\",\"Paris\"].\nIf `WITHCOORD`, `WITHDIST` or `WITHHASH` options are specified, the command returns an array of arrays, where each sub-array represents a single item.\n\nWhen additional information is returned as an array of arrays for each item, the first item in the sub-array is always the name of the returned item. The other information is returned in the following order as successive elements of the sub-array.\n\nThe distance from the center as a floating point number, in the same unit specified in the radius.\nThe geohash integer.\nThe coordinates as a two items x,y array (longitude,latitude).\n\nSo for example the command `GEORADIUS Sicily 15 37 200 km WITHCOORD WITHDIST` will return each item in the following way:\n\n\n```[\"Palermo\",\"190.4424\",[\"13.361389338970184\",\"38.115556395496299\"]]\n```\n\n\nRead-only variants\nSince `GEORADIUS` and `GEORADIUSBYMEMBER` have a `STORE` and `STOREDIST` option they are technically flagged as writing commands in the Redis command table. For this reason read-only replicas will flag them, and Redis Cluster replicas will redirect them to the master instance even if the connection is in read-only mode (see the `READONLY` command of Redis Cluster).\nBreaking the compatibility with the past was considered but rejected, at least for Redis 4.0, so instead two read-only variants of the commands were added. They are exactly like the original commands but refuse the `STORE` and `STOREDIST` options. The two variants are called `GEORADIUS_RO` and `GEORADIUSBYMEMBER_RO`, and can safely be used in replicas.\n@examples\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEORADIUS Sicily 15 37 200 km WITHDIST\nGEORADIUS Sicily 15 37 200 km WITHCOORD\nGEORADIUS Sicily 15 37 200 km WITHDIST WITHCOORD",
    "tag": "redis"
  },
  {
    "title": "Example",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-addslots.md",
    "content": "This command is useful in order to modify a node's view of the cluster\nconfiguration. Specifically it assigns a set of hash slots to the node\nreceiving the command. If the command is successful, the node will map\nthe specified hash slots to itself, and will start broadcasting the new\nconfiguration.\nHowever note that:\n\nThe command only works if all the specified slots are, from the point of view of the node receiving the command, currently not assigned. A node will refuse to take ownership for slots that already belong to some other node (including itself).\nThe command fails if the same slot is specified multiple times.\nAs a side effect of the command execution, if a slot among the ones specified as argument is set as `importing`, this state gets cleared once the node assigns the (previously unbound) slot to itself.\n\nExample\nFor example the following command assigns slots 1 2 3 to the node receiving\nthe command:\n\n\n```> CLUSTER ADDSLOTS 1 2 3\nOK\n```\n\n\nHowever trying to execute it again results into an error since the slots\nare already assigned:\n\n\n```> CLUSTER ADDSLOTS 1 2 3\nERR Slot 1 is already busy\n```\n\n\nUsage in Redis Cluster\nThis command only works in cluster mode and is useful in the following\nRedis Cluster operations:\n\nTo create a new cluster ADDSLOTS is used in order to initially setup master nodes splitting the available hash slots among them.\nIn order to fix a broken cluster where certain slots are unassigned.\n\nInformation about slots propagation and warnings\nNote that once a node assigns a set of slots to itself, it will start\npropagating this information in heartbeat packet headers. However the\nother nodes will accept the information only if they have the slot as\nnot already bound with another node, or if the configuration epoch of the\nnode advertising the new hash slot, is greater than the node currently listed\nin the table.\nThis means that this command should be used with care only by applications\norchestrating Redis Cluster, like `redis-cli`, and the command if used\nout of the right context can leave the cluster in a wrong state or cause\ndata loss.\n@return",
    "tag": "redis"
  },
  {
    "title": "Example",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-addslotsrange.md",
    "content": "The `CLUSTER ADDSLOTSRANGE` is similar to the `CLUSTER ADDSLOTS` command in that they both assign hash slots to nodes.\nThe difference between the two commands is that `ADDSLOTS` takes a list of slots to assign to the node, while `ADDSLOTSRANGE` takes a list of slot ranges (specified by start and end slots) to assign to the node.\nExample\nTo assign slots 1 2 3 4 5 to the node, the `ADDSLOTS` command is:\n\n\n```> CLUSTER ADDSLOTS 1 2 3 4 5\nOK\n```\n\n\nThe same operation can be completed with the following `ADDSLOTSRANGE` command:\n\n\n```> CLUSTER ADDSLOTSRANGE 1 5\nOK\n```\n\n\nUsage in Redis Cluster\nThis command only works in cluster mode and is useful in the following Redis Cluster operations:\n\nTo create a new cluster ADDSLOTSRANGE is used in order to initially setup master nodes splitting the available hash slots among them.\nIn order to fix a broken cluster where certain slots are unassigned.\n\n@return",
    "tag": "redis"
  },
  {
    "title": "zincrby.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zincrby.md",
    "content": "Increments the score of `member` in the sorted set stored at `key` by\n`increment`.\nIf `member` does not exist in the sorted set, it is added with `increment` as\nits score (as if its previous score was `0.0`).\nIf `key` does not exist, a new sorted set with the specified `member` as its\nsole member is created.\nAn error is returned when `key` exists but does not hold a sorted set.\nThe `score` value should be the string representation of a numeric value, and\naccepts double precision floating point numbers.\nIt is possible to provide a negative value to decrement the score.\n@return\n@bulk-string-reply: the new score of `member` (a double precision floating point\nnumber), represented as string.\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZINCRBY myzset 2 \"one\"\nZRANGE myzset 0 -1 WITHSCORES",
    "tag": "redis"
  },
  {
    "title": "zlexcount.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zlexcount.md",
    "content": "When all the elements in a sorted set are inserted with the same score, in order to force lexicographical ordering, this command returns the number of elements in the sorted set at `key` with a value between `min` and `max`.\nThe `min` and `max` arguments have the same meaning as described for\n`ZRANGEBYLEX`.\nNote: the command has a complexity of just O(log(N)) because it uses elements ranks (see `ZRANK`) to get an idea of the range. Because of this there is no need to do a work proportional to the size of the range.\n@return\n@integer-reply: the number of elements in the specified score range.\n@examples\n```cli\nZADD myzset 0 a 0 b 0 c 0 d 0 e\nZADD myzset 0 f 0 g\nZLEXCOUNT myzset - +\nZLEXCOUNT myzset [b [f",
    "tag": "redis"
  },
  {
    "title": "geosearch.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/geosearch.md",
    "content": "Return the members of a sorted set populated with geospatial information using `GEOADD`, which are within the borders of the area specified by a given shape. This command extends the `GEORADIUS` command, so in addition to searching within circular areas, it supports searching within rectangular areas.\nThis command should be used in place of the deprecated `GEORADIUS` and `GEORADIUSBYMEMBER` commands.\nThe query's center point is provided by one of these mandatory options:\n\n`FROMMEMBER`: Use the position of the given existing `<member>` in the sorted set.\n`FROMLONLAT`: Use the given `<longitude>` and `<latitude>` position.\n\nThe query's shape is provided by one of these mandatory options:\n\n`BYRADIUS`: Similar to `GEORADIUS`, search inside circular area according to given `<radius>`.\n`BYBOX`: Search inside an axis-aligned rectangle, determined by `<height>` and `<width>`.\n\nThe command optionally returns additional information using the following options:\n\n`WITHDIST`: Also return the distance of the returned items from the specified center point. The distance is returned in the same unit as specified for the radius or height and width arguments.\n`WITHCOORD`: Also return the longitude and latitude of the matching items.\n`WITHHASH`: Also return the raw geohash-encoded sorted set score of the item, in the form of a 52 bit unsigned integer. This is only useful for low level hacks or debugging and is otherwise of little interest for the general user.\n\nMatching items are returned unsorted by default. To sort them, use one of the following two options:\n\n`ASC`: Sort returned items from the nearest to the farthest, relative to the center point.\n`DESC`: Sort returned items from the farthest to the nearest, relative to the center point.\n\nAll matching items are returned by default. To limit the results to the first N matching items, use the COUNT `<count>` option.\nWhen the `ANY` option is used, the command returns as soon as enough matches are found.  This means that the results returned may not be the ones closest to the specified point, but the effort invested by the server to generate them is significantly less.\nWhen `ANY` is not provided, the command will perform an effort that is proportional to the number of items matching the specified area and sort them,\nso to query very large areas with a very small `COUNT` option may be slow even if just a few results are returned.\n@return\n@array-reply, specifically:\n\nWithout any `WITH` option specified, the command just returns a linear array like [\"New York\",\"Milan\",\"Paris\"].\nIf `WITHCOORD`, `WITHDIST` or `WITHHASH` options are specified, the command returns an array of arrays, where each sub-array represents a single item.\n\nWhen additional information is returned as an array of arrays for each item, the first item in the sub-array is always the name of the returned item. The other information is returned in the following order as successive elements of the sub-array.\n\nThe distance from the center as a floating point number, in the same unit specified in the shape.\nThe geohash integer.\nThe coordinates as a two items x,y array (longitude,latitude).\n\n@examples\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEOADD Sicily 12.758489 38.788135 \"edge1\"   17.241510 38.788135 \"edge2\" \nGEOSEARCH Sicily FROMLONLAT 15 37 BYRADIUS 200 km ASC\nGEOSEARCH Sicily FROMLONLAT 15 37 BYBOX 400 400 km ASC WITHCOORD WITHDIST",
    "tag": "redis"
  },
  {
    "title": "decr.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/decr.md",
    "content": "Decrements the number stored at `key` by one.\nIf the key does not exist, it is set to `0` before performing the operation.\nAn error is returned if the key contains a value of the wrong type or contains a\nstring that can not be represented as integer.\nThis operation is limited to 64 bit signed integers.\nSee `INCR` for extra information on increment/decrement operations.\n@return\n@integer-reply: the value of `key` after the decrement\n@examples\n```cli\nSET mykey \"10\"\nDECR mykey\nSET mykey \"234293482390480948029348230948\"\nDECR mykey",
    "tag": "redis"
  },
  {
    "title": "zinterstore.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zinterstore.md",
    "content": "Computes the intersection of `numkeys` sorted sets given by the specified keys,\nand stores the result in `destination`.\nIt is mandatory to provide the number of input keys (`numkeys`) before passing\nthe input keys and the other (optional) arguments.\nBy default, the resulting score of an element is the sum of its scores in the\nsorted sets where it exists.\nBecause intersection requires an element to be a member of every given sorted\nset, this results in the score of every element in the resulting sorted set to\nbe equal to the number of input sorted sets.\nFor a description of the `WEIGHTS` and `AGGREGATE` options, see `ZUNIONSTORE`.\nIf `destination` already exists, it is overwritten.\n@return\n@integer-reply: the number of elements in the resulting sorted set at\n`destination`.\n@examples\n```cli\nZADD zset1 1 \"one\"\nZADD zset1 2 \"two\"\nZADD zset2 1 \"one\"\nZADD zset2 2 \"two\"\nZADD zset2 3 \"three\"\nZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3\nZRANGE out 0 -1 WITHSCORES",
    "tag": "redis"
  },
  {
    "title": "Example",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-keyslot.md",
    "content": "Returns an integer identifying the hash slot the specified key hashes to.\nThis command is mainly useful for debugging and testing, since it exposes\nvia an API the underlying Redis implementation of the hashing algorithm.\nExample use cases for this command:\n\nClient libraries may use Redis in order to test their own hashing algorithm, generating random keys and hashing them with both their local implementation and using Redis `CLUSTER KEYSLOT` command, then checking if the result is the same.\nHumans may use this command in order to check what is the hash slot, and then the associated Redis Cluster node, responsible for a given key.\n\nExample\n```\n\nCLUSTER KEYSLOT somekey\n(integer) 11058\nCLUSTER KEYSLOT foo{hash_tag}\n(integer) 2515\nCLUSTER KEYSLOT bar{hash_tag}\n(integer) 2515\n```\n\nNote that the command implements the full hashing algorithm, including support for hash tags, that is the special property of Redis Cluster key hashing algorithm, of hashing just what is between `{` and `}` if such a pattern is found inside the key name, in order to force multiple keys to be handled by the same node.\n@return",
    "tag": "redis"
  },
  {
    "title": "Behavior change history",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/subscribe.md",
    "content": "Subscribes the client to the specified channels.\nOnce the client enters the subscribed state it is not supposed to issue any\nother commands, except for additional `SUBSCRIBE`, `SSUBSCRIBE`, `PSUBSCRIBE`, `UNSUBSCRIBE`, `SUNSUBSCRIBE`, \n`PUNSUBSCRIBE`, `PING`, `RESET` and `QUIT` commands.\nHowever, if RESP3 is used (see `HELLO`) it is possible for a client to issue any commands while in subscribed state.\nFor more information, see Pub/sub.\n@return\nWhen successful, this command doesn't return anything.\nInstead, for each channel, one message with the first element being the string \"subscribe\" is pushed as a confirmation that the command succeeded.\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "zremrangebylex.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zremrangebylex.md",
    "content": "When all the elements in a sorted set are inserted with the same score, in order to force lexicographical ordering, this command removes all elements in the sorted set stored at `key` between the lexicographical range specified by `min` and `max`.\nThe meaning of `min` and `max` are the same of the `ZRANGEBYLEX` command. Similarly, this command actually removes the same elements that `ZRANGEBYLEX` would return if called with the same `min` and `max` arguments.\n@return\n@integer-reply: the number of elements removed.\n@examples\n```cli\nZADD myzset 0 aaaa 0 b 0 c 0 d 0 e\nZADD myzset 0 foo 0 zap 0 zip 0 ALPHA 0 alpha\nZRANGE myzset 0 -1\nZREMRANGEBYLEX myzset [alpha [omega\nZRANGE myzset 0 -1",
    "tag": "redis"
  },
  {
    "title": "pfmerge.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pfmerge.md",
    "content": "Merge multiple HyperLogLog values into a unique value that will approximate\nthe cardinality of the union of the observed Sets of the source HyperLogLog\nstructures.\nThe computed merged HyperLogLog is set to the destination variable, which is\ncreated if does not exist (defaulting to an empty HyperLogLog).\nIf the destination variable exists, it is treated as one of the source sets \nand its cardinality will be included in the cardinality of the computed\nHyperLogLog.\n@return\n@simple-string-reply: The command just returns `OK`.\n@examples\n```cli\nPFADD hll1 foo bar zap a\nPFADD hll2 a b c foo\nPFMERGE hll3 hll1 hll2\nPFCOUNT hll3",
    "tag": "redis"
  },
  {
    "title": "pubsub-numsub.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pubsub-numsub.md",
    "content": "Returns the number of subscribers (exclusive of clients subscribed to patterns) for the specified channels.\nNote that it is valid to call this command without channels. In this case it will just return an empty list.\nCluster note: in a Redis Cluster clients can subscribe to every node, and can also publish to every other node. The cluster will make sure that published messages are forwarded as needed. That said, `PUBSUB`'s replies in a cluster only report information from the node's Pub/Sub context, rather than the entire cluster.\n@return\n@array-reply: a list of channels and number of subscribers for every channel.",
    "tag": "redis"
  },
  {
    "title": "pexpiretime.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pexpiretime.md",
    "content": "`PEXPIRETIME` has the same semantic as `EXPIRETIME`, but returns the absolute Unix expiration timestamp in milliseconds instead of seconds.\n@return\n@integer-reply: Expiration Unix timestamp in milliseconds, or a negative value in order to signal an error (see the description below).\n\nThe command returns `-1` if the key exists but has no associated expiration time.\nThe command returns `-2` if the key does not exist.\n\n@examples\n```cli\nSET mykey \"Hello\"\nPEXPIREAT mykey 33177117420000\nPEXPIRETIME mykey",
    "tag": "redis"
  },
  {
    "title": "Atomic rewrite process",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/config-rewrite.md",
    "content": "The `CONFIG REWRITE` command rewrites the `redis.conf` file the server was started with, applying the minimal changes needed to make it reflect the configuration currently used by the server, which may be different compared to the original one because of the use of the `CONFIG SET` command.\nThe rewrite is performed in a very conservative way:\n\nComments and the overall structure of the original redis.conf are preserved as much as possible.\nIf an option already exists in the old redis.conf file, it will be rewritten at the same position (line number).\nIf an option was not already present, but it is set to its default value, it is not added by the rewrite process.\nIf an option was not already present, but it is set to a non-default value, it is appended at the end of the file.\nNon used lines are blanked. For instance if you used to have multiple `save` directives, but the current configuration has fewer or none as you disabled RDB persistence, all the lines will be blanked.\n\nCONFIG REWRITE is also able to rewrite the configuration file from scratch if the original one no longer exists for some reason. However if the server was started without a configuration file at all, the CONFIG REWRITE will just return an error.\nAtomic rewrite process\nIn order to make sure the redis.conf file is always consistent, that is, on errors or crashes you always end with the old file, or the new one, the rewrite is performed with a single `write(2)` call that has enough content to be at least as big as the old file. Sometimes additional padding in the form of comments is added in order to make sure the resulting file is big enough, and later the file gets truncated to remove the padding at the end.\n@return\n@simple-string-reply: `OK` when the configuration was rewritten properly.",
    "tag": "redis"
  },
  {
    "title": "Design pattern",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/getset.md",
    "content": "Atomically sets `key` to `value` and returns the old value stored at `key`.\nReturns an error when `key` exists but does not hold a string value.  Any \nprevious time to live associated with the key is discarded on successful \n`SET` operation.\nDesign pattern\n`GETSET` can be used together with `INCR` for counting with atomic reset.\nFor example: a process may call `INCR` against the key `mycounter` every time\nsome event occurs, but from time to time we need to get the value of the counter\nand reset it to zero atomically.\nThis can be done using `GETSET mycounter \"0\"`:\n`cli\nINCR mycounter\nGETSET mycounter \"0\"\nGET mycounter`\n@return\n@bulk-string-reply: the old value stored at `key`, or `nil` when `key` did not exist.\n@examples\n```cli\nSET mykey \"Hello\"\nGETSET mykey \"World\"\nGET mykey",
    "tag": "redis"
  },
  {
    "title": "keys.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/keys.md",
    "content": "Returns all keys matching `pattern`.\nWhile the time complexity for this operation is O(N), the constant times are\nfairly low.\nFor example, Redis running on an entry level laptop can scan a 1 million key\ndatabase in 40 milliseconds.\nWarning: consider `KEYS` as a command that should only be used in production\nenvironments with extreme care.\nIt may ruin performance when it is executed against large databases.\nThis command is intended for debugging and special operations, such as changing\nyour keyspace layout.\nDon't use `KEYS` in your regular application code.\nIf you're looking for a way to find keys in a subset of your keyspace, consider\nusing `SCAN` or sets.\nSupported glob-style patterns:\n\n`h?llo` matches `hello`, `hallo` and `hxllo`\n`h*llo` matches `hllo` and `heeeello`\n`h[ae]llo` matches `hello` and `hallo,` but not `hillo`\n`h[^e]llo` matches `hallo`, `hbllo`, ... but not `hello`\n`h[a-b]llo` matches `hallo` and `hbllo`\n\nUse `\\` to escape special characters if you want to match them verbatim.\n@return\n@array-reply: list of keys matching `pattern`.\n@examples\n```cli\nMSET firstname Jack lastname Stuntman age 35\nKEYS name\nKEYS a??\nKEYS *",
    "tag": "redis"
  },
  {
    "title": "Consistency with range functions in various programming languages",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lrange.md",
    "content": "Returns the specified elements of the list stored at `key`.\nThe offsets `start` and `stop` are zero-based indexes, with `0` being the first\nelement of the list (the head of the list), `1` being the next element and so\non.\nThese offsets can also be negative numbers indicating offsets starting at the\nend of the list.\nFor example, `-1` is the last element of the list, `-2` the penultimate, and so\non.\nConsistency with range functions in various programming languages\nNote that if you have a list of numbers from 0 to 100, `LRANGE list 0 10` will\nreturn 11 elements, that is, the rightmost item is included.\nThis may or may not be consistent with behavior of range-related functions\nin your programming language of choice (think Ruby's `Range.new`, `Array#slice`\nor Python's `range()` function).\nOut-of-range indexes\nOut of range indexes will not produce an error.\nIf `start` is larger than the end of the list, an empty list is returned.\nIf `stop` is larger than the actual end of the list, Redis will treat it like\nthe last element of the list.\n@return\n@array-reply: list of elements in the specified range.\n@examples\n```cli\nRPUSH mylist \"one\"\nRPUSH mylist \"two\"\nRPUSH mylist \"three\"\nLRANGE mylist 0 0\nLRANGE mylist -3 2\nLRANGE mylist -100 100\nLRANGE mylist 5 10",
    "tag": "redis"
  },
  {
    "title": "cluster-count-failure-reports.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-count-failure-reports.md",
    "content": "The command returns the number of failure reports for the specified node.\nFailure reports are the way Redis Cluster uses in order to promote a\n`PFAIL` state, that means a node is not reachable, to a `FAIL` state,\nthat means that the majority of masters in the cluster agreed within\na window of time that the node is not reachable.\nA few more details:\n\nA node flags another node with `PFAIL` when the node is not reachable for a time greater than the configured node timeout, which is a fundamental configuration parameter of a Redis Cluster.\nNodes in `PFAIL` state are provided in gossip sections of heartbeat packets.\nEvery time a node processes gossip packets from other nodes, it creates (and refreshes the TTL if needed) failure reports, remembering that a given node said another given node is in `PFAIL` condition.\nEach failure report has a time to live of two times the node timeout time.\nIf at a given time a node has another node flagged with `PFAIL`, and at the same time collected the majority of other master nodes failure reports about this node (including itself if it is a master), then it elevates the failure state of the node from `PFAIL` to `FAIL`, and broadcasts a message forcing all the nodes that can be reached to flag the node as `FAIL`.\n\nThis command returns the number of failure reports for the current node which are currently not expired (so received within two times the node timeout time). The count does not include what the node we are asking this count believes about the node ID we pass as argument, the count only includes the failure reports the node received from other nodes.\nThis command is mainly useful for debugging, when the failure detector of\nRedis Cluster is not operating as we believe it should.\n@return",
    "tag": "redis"
  },
  {
    "title": "Handling of strings with different lengths",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bitop.md",
    "content": "Perform a bitwise operation between multiple keys (containing string values) and\nstore the result in the destination key.\nThe `BITOP` command supports four bitwise operations: AND, OR, XOR\nand NOT, thus the valid forms to call the command are:\n\n`BITOP AND destkey srckey1 srckey2 srckey3 ... srckeyN`\n`BITOP OR  destkey srckey1 srckey2 srckey3 ... srckeyN`\n`BITOP XOR destkey srckey1 srckey2 srckey3 ... srckeyN`\n`BITOP NOT destkey srckey`\n\nAs you can see NOT is special as it only takes an input key, because it\nperforms inversion of bits so it only makes sense as a unary operator.\nThe result of the operation is always stored at `destkey`.\nHandling of strings with different lengths\nWhen an operation is performed between strings having different lengths, all the\nstrings shorter than the longest string in the set are treated as if they were\nzero-padded up to the length of the longest string.\nThe same holds true for non-existent keys, that are considered as a stream of\nzero bytes up to the length of the longest string.\n@return\n@integer-reply\nThe size of the string stored in the destination key, that is equal to the\nsize of the longest input string.\n@examples\n`cli\nSET key1 \"foobar\"\nSET key2 \"abcdef\"\nBITOP AND dest key1 key2\nGET dest`\nPattern: real time metrics using bitmaps\n`BITOP` is a good complement to the pattern documented in the `BITCOUNT` command\ndocumentation.\nDifferent bitmaps can be combined in order to obtain a target bitmap where\nthe population counting operation is performed.\nSee the article called \"Fast easy realtime metrics using Redis\nbitmaps\" for an interesting use cases.\nPerformance considerations\n`BITOP` is a potentially slow command as it runs in O(N) time.\nCare should be taken when running it against long input strings.\nFor real-time metrics and statistics involving large inputs a good approach is\nto use a replica (with replica-read-only option enabled) where the bit-wise",
    "tag": "redis"
  },
  {
    "title": "copy.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/copy.md",
    "content": "This command copies the value stored at the `source` key to the `destination`\nkey.\nBy default, the `destination` key is created in the logical database used by the\nconnection. The `DB` option allows specifying an alternative logical database\nindex for the destination key.\nThe command returns an error when the `destination` key already exists. The\n`REPLACE` option removes the `destination` key before copying the value to it.\n@return\n@integer-reply, specifically:\n\n`1` if `source` was copied.\n`0` if `source` was not copied.\n\n@examples\n```\nSET dolly \"sheep\"\nCOPY dolly clone\nGET clone",
    "tag": "redis"
  },
  {
    "title": "acl-cat.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-cat.md",
    "content": "The command shows the available ACL categories if called without arguments.\nIf a category name is given, the command shows all the Redis commands in\nthe specified category.\nACL categories are very useful in order to create ACL rules that include or\nexclude a large set of commands at once, without specifying every single\ncommand. For instance, the following rule will let the user `karin` perform\neverything but the most dangerous operations that may affect the server\nstability:\n\n\n```ACL SETUSER karin on +@all -@dangerous\n```\n\n\nWe first add all the commands to the set of commands that `karin` is able\nto execute, but then we remove all the dangerous commands.\nChecking for all the available categories is as simple as:\n```\n\nACL CAT\n 1) \"keyspace\"\n 2) \"read\"\n 3) \"write\"\n 4) \"set\"\n 5) \"sortedset\"\n 6) \"list\"\n 7) \"hash\"\n 8) \"string\"\n 9) \"bitmap\"\n10) \"hyperloglog\"\n11) \"geo\"\n12) \"stream\"\n13) \"pubsub\"\n14) \"admin\"\n15) \"fast\"\n16) \"slow\"\n17) \"blocking\"\n18) \"dangerous\"\n19) \"connection\"\n20) \"transaction\"\n21) \"scripting\"\n```\n\nThen we may want to know what commands are part of a given category:\n```\n\nACL CAT dangerous\n 1) \"flushdb\"\n 2) \"acl\"\n 3) \"slowlog\"\n 4) \"debug\"\n 5) \"role\"\n 6) \"keys\"\n 7) \"pfselftest\"\n 8) \"client\"\n 9) \"bgrewriteaof\"\n10) \"replicaof\"\n11) \"monitor\"\n12) \"restore-asking\"\n13) \"latency\"\n14) \"replconf\"\n15) \"pfdebug\"\n16) \"bgsave\"\n17) \"sync\"\n18) \"config\"\n19) \"flushall\"\n20) \"cluster\"\n21) \"info\"\n22) \"lastsave\"\n23) \"slaveof\"\n24) \"swapdb\"\n25) \"module\"\n26) \"restore\"\n27) \"migrate\"\n28) \"save\"\n29) \"shutdown\"\n30) \"psync\"\n31) \"sort\"\n```\n\n@return",
    "tag": "redis"
  },
  {
    "title": "config-set.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/config-set.md",
    "content": "The `CONFIG SET` command is used in order to reconfigure the server at run time\nwithout the need to restart Redis.\nYou can change both trivial parameters or switch from one to another persistence\noption using this command.\nThe list of configuration parameters supported by `CONFIG SET` can be obtained\nissuing a `CONFIG GET *` command, that is the symmetrical command used to obtain\ninformation about the configuration of a running Redis instance.\nAll the configuration parameters set using `CONFIG SET` are immediately loaded\nby Redis and will take effect starting with the next command executed.\nAll the supported parameters have the same meaning of the equivalent\nconfiguration parameter used in the redis.conf file.\nNote that you should look at the redis.conf file relevant to the version you're\nworking with as configuration options might change between versions. The link\nabove is to the latest development version.\nIt is possible to switch persistence from RDB snapshotting to append-only file\n(and the other way around) using the `CONFIG SET` command.\nFor more information about how to do that please check the persistence\npage.\nIn general what you should know is that setting the `appendonly` parameter to\n`yes` will start a background process to save the initial append-only file\n(obtained from the in memory data set), and will append all the subsequent\ncommands on the append-only file, thus obtaining exactly the same effect of a\nRedis server that started with AOF turned on since the start.\nYou can have both the AOF enabled with RDB snapshotting if you want, the two\noptions are not mutually exclusive.\n@return\n@simple-string-reply: `OK` when the configuration was set properly.",
    "tag": "redis"
  },
  {
    "title": "spublish.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/spublish.md",
    "content": "Posts a message to the given shard channel.\nIn Redis Cluster, shard channels are assigned to slots by the same algorithm used to assign keys to slots.\nA shard message must be sent to a node that own the slot the shard channel is hashed to. \nThe cluster makes sure that published shard messages are forwarded to all the node in the shard, so clients can subscribe to a shard channel by connecting to any one of the nodes in the shard.\nFor more information about sharded pubsub, see Sharded Pubsub.\n@return\n@integer-reply: the number of clients that received the message.\nNote that in a Redis Cluster, only clients that are connected to the same node as the publishing client are included in the count.\n@examples\nFor example the following command publish to channel `orders` with a subscriber already waiting for message(s).\n```\n\nspublish orders hello\n(integer) 1\n",
    "tag": "redis"
  },
  {
    "title": "latency-history.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/latency-history.md",
    "content": "The `LATENCY HISTORY` command returns the raw data of the `event`'s latency spikes time series.\nThis is useful to an application that wants to fetch raw data in order to perform monitoring, display graphs, and so forth.\nThe command will return up to 160 timestamp-latency pairs for the `event`.\nValid values for `event` are:\n* `active-defrag-cycle`\n* `aof-fsync-always`\n* `aof-stat`\n* `aof-rewrite-diff-write`\n* `aof-rename`\n* `aof-write`\n* `aof-write-active-child`\n* `aof-write-alone`\n* `aof-write-pending-fsync`\n* `command`\n* `expire-cycle`\n* `eviction-cycle`\n* `eviction-del`\n* `fast-command`\n* `fork`\n* `rdb-unlink-temp-file`\n@examples\n`127.0.0.1:6379> latency history command\n1) 1) (integer) 1405067822\n   2) (integer) 251\n2) 1) (integer) 1405067941\n   2) (integer) 1001`\nFor more information refer to the Latency Monitoring Framework page.\n@return\n@array-reply: specifically:\nThe command returns an array where each element is a two elements array",
    "tag": "redis"
  },
  {
    "title": "Optional arguments",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/failover.md",
    "content": "This command will start a coordinated failover between the currently-connected-to master and one of its replicas.\nThe failover is not synchronous, instead a background task will handle coordinating the failover. \nIt is designed to limit data loss and unavailability of the cluster during the failover.\nThis command is analogous to the `CLUSTER FAILOVER` command for non-clustered Redis and is similar to the failover support provided by sentinel.\nThe specific details of the default failover flow are as follows:\n\nThe master will internally start a `CLIENT PAUSE WRITE`, which will pause incoming writes and prevent the accumulation of new data in the replication stream.\nThe master will monitor its replicas, waiting for a replica to indicate that it has fully consumed the replication stream. If the master has multiple replicas, it will only wait for the first replica to catch up.\nThe master will then demote itself to a replica. This is done to prevent any dual master scenarios. NOTE: The master will not discard its data, so it will be able to rollback if the replica rejects the failover request in the next step.\nThe previous master will send a special PSYNC request to the target replica, `PSYNC FAILOVER`, instructing the target replica to become a master.\nOnce the previous master receives acknowledgement the `PSYNC FAILOVER` was accepted it will unpause its clients. If the PSYNC request is rejected, the master will abort the failover and return to normal.\n\nThe field `master_failover_state` in `INFO replication` can be used to track the current state of the failover, which has the following values:\n\n`no-failover`: There is no ongoing coordinated failover.\n`waiting-for-sync`: The master is waiting for the replica to catch up to its replication offset.\n`failover-in-progress`: The master has demoted itself, and is attempting to hand off ownership to a target replica.\n\nIf the previous master had additional replicas attached to it, they will continue replicating from it as chained replicas. You will need to manually execute a `REPLICAOF` on these replicas to start replicating directly from the new master.\nOptional arguments\nThe following optional arguments exist to modify the behavior of the failover flow:\n\n\n`TIMEOUT` milliseconds -- This option allows specifying a maximum time a master will wait in the `waiting-for-sync` state before aborting the failover attempt and rolling back.\nThis is intended to set an upper bound on the write outage the Redis cluster can experience.\nFailovers typically happen in less than a second, but could take longer if there is a large amount of write traffic or the replica is already behind in consuming the replication stream. \nIf this value is not specified, the timeout can be considered to be \"infinite\".\n\n\n`TO` HOST PORT -- This option allows designating a specific replica, by its host and port, to failover to. The master will wait specifically for this replica to catch up to its replication offset, and then failover to it.\n\n\n`FORCE` -- If both the `TIMEOUT` and `TO` options are set, the force flag can also be used to designate that that once the timeout has elapsed, the master should failover to the target replica instead of rolling back.\nThis can be used for a best-effort attempt at a failover without data loss, but limiting write outage.\n\n\nNOTE: The master will always rollback if the `PSYNC FAILOVER` request is rejected by the target replica. \nFailover abort\nThe failover command is intended to be safe from data loss and corruption, but can encounter some scenarios it can not automatically remediate from and may get stuck. \nFor this purpose, the `FAILOVER ABORT` command exists, which will abort an ongoing failover and return the master to its normal state. \nThe command has no side effects if issued in the `waiting-for-sync` state but can introduce multi-master scenarios in the `failover-in-progress` state. \nIf a multi-master scenario is encountered, you will need to manually identify which master has the latest data and designate it as the master and have the other replicas.\nNOTE: `REPLICAOF` is disabled while a failover is in progress, this is to prevent unintended interactions with the failover that might cause data loss.\n@return",
    "tag": "redis"
  },
  {
    "title": "cluster-getkeysinslot.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-getkeysinslot.md",
    "content": "The command returns an array of keys names stored in the contacted node and\nhashing to the specified hash slot. The maximum number of keys to return\nis specified via the `count` argument, so that it is possible for the user\nof this API to batch-processing keys.\nThe main usage of this command is during rehashing of cluster slots from one\nnode to another. The way the rehashing is performed is exposed in the Redis\nCluster specification, or in a more simple to digest form, as an appendix\nof the `CLUSTER SETSLOT` command documentation.\n```\n\nCLUSTER GETKEYSINSLOT 7000 3\n1) \"key_39015\"\n2) \"key_89793\"\n3) \"key_92937\"\n```\n\n@return",
    "tag": "redis"
  },
  {
    "title": "Behavior change history",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/flushdb.md",
    "content": "Delete all the keys of the currently selected DB.\nThis command never fails.\nBy default, `FLUSHDB` will synchronously flush all keys from the database.\nStarting with Redis 6.2, setting the lazyfree-lazy-user-flush configuration directive to \"yes\" changes the default flush mode to asynchronous.\nIt is possible to use one of the following modifiers to dictate the flushing mode explicitly:\n\n`ASYNC`: flushes the database asynchronously\n`!SYNC`: flushes the database synchronously\n\nNote: an asynchronous `FLUSHDB` command only deletes keys that were present at the time the command was invoked. Keys created during an asynchronous flush will be unaffected.\n@return\n@simple-string-reply\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "Modifiers",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/shutdown.md",
    "content": "The command behavior is the following:\n\nIf there are any replicas lagging behind in replication:\nPause clients attempting to write by performing a `CLIENT PAUSE` with the `WRITE` option.\nWait up to the configured `shutdown-timeout` (default 10 seconds) for replicas to catch up the replication offset.\nStop all the clients.\nPerform a blocking SAVE if at least one save point is configured.\nFlush the Append Only File if AOF is enabled.\nQuit the server.\n\nIf persistence is enabled this commands makes sure that Redis is switched off\nwithout any data loss.\nNote: A Redis instance that is configured for not persisting on disk (no AOF\nconfigured, nor \"save\" directive) will not dump the RDB file on `SHUTDOWN`, as\nusually you don't want Redis instances used only for caching to block on when\nshutting down.\nAlso note: If Redis receives one of the signals `SIGTERM` and `SIGINT`, the same shutdown sequence is performed.\nSee also Signal Handling.\nModifiers\nIt is possible to specify optional modifiers to alter the behavior of the command.\nSpecifically:\n\nSAVE will force a DB saving operation even if no save points are configured.\nNOSAVE will prevent a DB saving operation even if one or more save points are configured.\nNOW skips waiting for lagging replicas, i.e. it bypasses the first step in the shutdown sequence.\nFORCE ignores any errors that would normally prevent the server from exiting.\n  For details, see the following section.\nABORT cancels an ongoing shutdown and cannot be combined with other flags.\n\nConditions where a SHUTDOWN fails\nWhen a save point is configured or the SAVE modifier is specified, the shutdown may fail if the RDB file can't be saved.\nThen, the server continues to run in order to ensure no data loss.\nThis may be bypassed using the FORCE modifier, causing the server to exit anyway.\nWhen the Append Only File is enabled the shutdown may fail because the\nsystem is in a state that does not allow to safely immediately persist\non disk.\nNormally if there is an AOF child process performing an AOF rewrite, Redis\nwill simply kill it and exit.\nHowever, there are situations where it is unsafe to do so and, unless the FORCE modifier is specified, the SHUTDOWN command will be refused with an error instead.\nThis happens in the following situations:\n\nThe user just turned on AOF, and the server triggered the first AOF rewrite in order to create the initial AOF file. In this context, stopping will result in losing the dataset at all: once restarted, the server will potentially have AOF enabled without having any AOF file at all.\nA replica with AOF enabled, reconnected with its master, performed a full resynchronization, and restarted the AOF file, triggering the initial AOF creation process. In this case not completing the AOF rewrite is dangerous because the latest dataset received from the master would be lost. The new master can actually be even a different instance (if the REPLICAOF or SLAVEOF command was used in order to reconfigure the replica), so it is important to finish the AOF rewrite and start with the correct data set representing the data set in memory when the server was terminated.\n\nThere are situations when we want just to terminate a Redis instance ASAP, regardless of what its content is.\nIn such a case, the command SHUTDOWN NOW NOSAVE FORCE can be used.\nIn versions before 7.0, where the NOW and FORCE flags are not available, the right combination of commands is to send a CONFIG appendonly no followed by a SHUTDOWN NOSAVE.\nThe first command will turn off the AOF if needed, and will terminate the AOF rewriting child if there is one active.\nThe second command will not have any problem to execute since the AOF is no longer enabled.\nMinimize the risk of data loss\nSince Redis 7.0, the server waits for lagging replicas up to a configurable `shutdown-timeout`, by default 10 seconds, before shutting down.\nThis provides a best effort minimizing the risk of data loss in a situation where no save points are configured and AOF is disabled.\nBefore version 7.0, shutting down a heavily loaded master node in a diskless setup was more likely to result in data loss.\nTo minimize the risk of data loss in such setups, it's advised to trigger a manual `FAILOVER` (or `CLUSTER FAILOVER`) to demote the master to a replica and promote one of the replicas to be the new master, before shutting down a master node.\n@return\n@simple-string-reply: `OK` if `ABORT` was specified and shutdown was aborted.\nOn successful shutdown, nothing is returned since the server quits and the connection is closed.\nOn failure, an error is returned.\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "function-restore.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/function-restore.md",
    "content": "Restore libraries from the serialized payload.\nYou can use the optional policy argument to provide a policy for handling existing libraries.\nThe following policies are allowed:\n\nAPPEND: appends the restored libraries to the existing libraries and aborts on collision. \n  This is the default policy.\nFLUSH: deletes all existing libraries before restoring the payload.\nREPLACE: appends the restored libraries to the existing libraries, replacing any existing ones in case of name collisions. Note that this policy doesn't prevent function name collisions, only libraries.\n\nFor more information please refer to Introduction to Redis Functions.\n@return",
    "tag": "redis"
  },
  {
    "title": "Background",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/expireat.md",
    "content": "`EXPIREAT` has the same effect and semantic as `EXPIRE`, but instead of\nspecifying the number of seconds representing the TTL (time to live), it takes\nan absolute Unix timestamp (seconds since January 1, 1970). A\ntimestamp in the past will delete the key immediately.\nPlease for the specific semantics of the command refer to the documentation of\n`EXPIRE`.\nBackground\n`EXPIREAT` was introduced in order to convert relative timeouts to absolute\ntimeouts for the AOF persistence mode.\nOf course, it can be used directly to specify that a given key should expire at\na given time in the future.\nOptions\nThe `EXPIREAT` command supports a set of options:\n\n`NX` -- Set expiry only when the key has no expiry\n`XX` -- Set expiry only when the key has an existing expiry\n`GT` -- Set expiry only when the new expiry is greater than current one\n`LT` -- Set expiry only when the new expiry is less than current one\n\nA non-volatile key is treated as an infinite TTL for the purpose of `GT` and `LT`.\nThe `GT`, `LT` and `NX` options are mutually exclusive.\n@return\n@integer-reply, specifically:\n\n`1` if the timeout was set.\n`0` if the timeout was not set. e.g. key doesn't exist, or operation skipped due to the provided arguments.\n\n@examples\n```cli\nSET mykey \"Hello\"\nEXISTS mykey\nEXPIREAT mykey 1293840000\nEXISTS mykey",
    "tag": "redis"
  },
  {
    "title": "CLIENT KILL and Redis Sentinel",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-kill.md",
    "content": "The `CLIENT KILL` command closes a given client connection. This command support two formats, the old format:\n\n\n```CLIENT KILL addr:port\n```\n\n\nThe `ip:port` should match a line returned by the `CLIENT LIST` command (`addr` field).\nThe new format:\n\n\n```CLIENT KILL <filter> <value> ... ... <filter> <value>\n```\n\n\nWith the new form it is possible to kill clients by different attributes\ninstead of killing just by address. The following filters are available:\n\n`CLIENT KILL ADDR ip:port`. This is exactly the same as the old three-arguments behavior.\n`CLIENT KILL LADDR ip:port`. Kill all clients connected to specified local (bind) address.\n`CLIENT KILL ID client-id`. Allows to kill a client by its unique `ID` field. Client `ID`'s are retrieved using the `CLIENT LIST` command.\n`CLIENT KILL TYPE type`, where type is one of `normal`, `master`, `replica` and `pubsub`. This closes the connections of all the clients in the specified class. Note that clients blocked into the `MONITOR` command are considered to belong to the `normal` class.\n`CLIENT KILL USER username`. Closes all the connections that are authenticated with the specified ACL username, however it returns an error if the username does not map to an existing ACL user.\n`CLIENT KILL SKIPME yes/no`. By default this option is set to `yes`, that is, the client calling the command will not get killed, however setting this option to `no` will have the effect of also killing the client calling the command.\n\nIt is possible to provide multiple filters at the same time. The command will handle multiple filters via logical AND. For example:\n\n\n```CLIENT KILL addr 127.0.0.1:12345 type pubsub\n```\n\n\nis valid and will kill only a pubsub client with the specified address. This format containing multiple filters is rarely useful currently.\nWhen the new form is used the command no longer returns `OK` or an error, but instead the number of killed clients, that may be zero.\nCLIENT KILL and Redis Sentinel\nRecent versions of Redis Sentinel (Redis 2.8.12 or greater) use CLIENT KILL\nin order to kill clients when an instance is reconfigured, in order to\nforce clients to perform the handshake with one Sentinel again and update\nits configuration.\nNotes\nDue to the single-threaded nature of Redis, it is not possible to\nkill a client connection while it is executing a command. From\nthe client point of view, the connection can never be closed\nin the middle of the execution of a command. However, the client\nwill notice the connection has been closed only when the\nnext command is sent (and results in network error).\n@return\nWhen called with the three arguments format:\n@simple-string-reply: `OK` if the connection exists and has been closed\nWhen called with the filter / value format:",
    "tag": "redis"
  },
  {
    "title": "bzpopmin.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bzpopmin.md",
    "content": "`BZPOPMIN` is the blocking variant of the sorted set `ZPOPMIN` primitive.\nIt is the blocking version because it blocks the connection when there are no\nmembers to pop from any of the given sorted sets.\nA member with the lowest score is popped from first sorted set that is\nnon-empty, with the given keys being checked in the order that they are given.\nThe `timeout` argument is interpreted as a double value specifying the maximum\nnumber of seconds to block. A timeout of zero can be used to block indefinitely.\nSee the BLPOP documentation for the exact semantics, since `BZPOPMIN` is\nidentical to `BLPOP` with the only difference being the data structure being\npopped from.\n@return\n@array-reply: specifically:\n\nA `nil` multi-bulk when no element could be popped and the timeout expired.\nA three-element multi-bulk with the first element being the name of the key\n  where a member was popped, the second element is the popped member itself,\n  and the third element is the score of the popped element.\n\n@examples\n```\nredis> DEL zset1 zset2\n(integer) 0\nredis> ZADD zset1 0 a 1 b 2 c\n(integer) 3\nredis> BZPOPMIN zset1 zset2 0\n1) \"zset1\"\n2) \"a\"\n3) \"0\"",
    "tag": "redis"
  },
  {
    "title": "Behavior change history",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/flushall.md",
    "content": "Delete all the keys of all the existing databases, not just the currently selected one.\nThis command never fails.\nBy default, `FLUSHALL` will synchronously flush all the databases.\nStarting with Redis 6.2, setting the lazyfree-lazy-user-flush configuration directive to \"yes\" changes the default flush mode to asynchronous.\nIt is possible to use one of the following modifiers to dictate the flushing mode explicitly:\n\n`ASYNC`: flushes the databases asynchronously\n`!SYNC`: flushes the databases synchronously\n\nNote: an asynchronous `FLUSHALL` command only deletes keys that were present at the time the command was invoked. Keys created during an asynchronous flush will be unaffected.\n@return\n@simple-string-reply\nBehavior change history",
    "tag": "redis"
  },
  {
    "title": "Specification of the behavior when count is passed",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrandmember.md",
    "content": "When called with just the `key` argument, return a random element from the sorted set value stored at `key`.\nIf the provided `count` argument is positive, return an array of distinct elements.\nThe array's length is either `count` or the sorted set's cardinality (`ZCARD`), whichever is lower.\nIf called with a negative `count`, the behavior changes and the command is allowed to return the same element multiple times.\nIn this case, the number of returned elements is the absolute value of the specified `count`.\nThe optional `WITHSCORES` modifier changes the reply so it includes the respective scores of the randomly selected elements from the sorted set.\n@return\n@bulk-string-reply: without the additional `count` argument, the command returns a Bulk Reply with the randomly selected element, or `nil` when `key` does not exist.\n@array-reply: when the additional `count` argument is passed, the command returns an array of elements, or an empty array when `key` does not exist.\nIf the `WITHSCORES` modifier is used, the reply is a list elements and their scores from the sorted set.\n@examples\n`cli\nZADD dadi 1 uno 2 due 3 tre 4 quattro 5 cinque 6 sei\nZRANDMEMBER dadi\nZRANDMEMBER dadi\nZRANDMEMBER dadi -5 WITHSCORES`\nSpecification of the behavior when count is passed\nWhen the `count` argument is a positive value this command behaves as follows:\n\nNo repeated elements are returned.\nIf `count` is bigger than the cardinality of the sorted set, the command will only return the whole sorted set without additional elements.\nThe order of elements in the reply is not truly random, so it is up to the client to shuffle them if needed.\n\nWhen the `count` is a negative value, the behavior changes as follows:\n\nRepeating elements are possible.\nExactly `count` elements, or an empty array if the sorted set is empty (non-existing key), are always returned.\n",
    "tag": "redis"
  },
  {
    "title": "acl-save.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-save.md",
    "content": "When Redis is configured to use an ACL file (with the `aclfile` configuration\noption), this command will save the currently defined ACLs from the server memory to the ACL file.\n@return\n@simple-string-reply: `OK` on success.\nThe command may fail with an error for several reasons: if the file cannot be written or if the server is not configured to use an external ACL file.\n@examples\n```\n\nACL SAVE\n+OK\nACL SAVE\n-ERR There was an error trying to save the ACLs. Please check the server logs for more information\n",
    "tag": "redis"
  },
  {
    "title": "latency-latest.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/latency-latest.md",
    "content": "The `LATENCY LATEST` command reports the latest latency events logged.\nEach reported event has the following fields:\n\nEvent name.\nUnix timestamp of the latest latency spike for the event.\nLatest event latency in millisecond.\nAll-time maximum latency for this event.\n\n\"All-time\" means the maximum latency since the Redis instance was\nstarted, or the time that events were reset `LATENCY RESET`.\n@examples\n`127.0.0.1:6379> debug sleep 1\nOK\n(1.00s)\n127.0.0.1:6379> debug sleep .25\nOK\n127.0.0.1:6379> latency latest\n1) 1) \"command\"\n   2) (integer) 1405067976\n   3) (integer) 251\n   4) (integer) 1001`\nFor more information refer to the Latency Monitoring Framework page.\n@return\n@array-reply: specifically:\nThe command returns an array where each element is a four elements array",
    "tag": "redis"
  },
  {
    "title": "bzmpop.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bzmpop.md",
    "content": "`BZMPOP` is the blocking variant of `ZMPOP`.\nWhen any of the sorted sets contains elements, this command behaves exactly like `ZMPOP`.\nWhen used inside a `MULTI`/`EXEC` block, this command behaves exactly like `ZMPOP`.\nWhen all sorted sets are empty, Redis will block the connection until another client adds members to one of the keys or until the `timeout` (a double value specifying the maximum number of seconds to block) elapses.\nA `timeout` of zero can be used to block indefinitely.\nSee `ZMPOP` for more information.\n@return\n@array-reply: specifically:\n\nA `nil` when no element could be popped.\nA two-element array with the first element being the name of the key from which elements were popped, and the second element is an array of the popped elements. Every entry in the elements array is also an array that contains the member and its score.\n",
    "tag": "redis"
  },
  {
    "title": "substr.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/substr.md",
    "content": "Returns the substring of the string value stored at `key`, determined by the\noffsets `start` and `end` (both are inclusive).\nNegative offsets can be used in order to provide an offset starting from the end\nof the string.\nSo -1 means the last character, -2 the penultimate and so forth.\nThe function handles out of range requests by limiting the resulting range to\nthe actual length of the string.\n@return\n@bulk-string-reply\n@examples\n```cli\nSET mykey \"This is a string\"\nGETRANGE mykey 0 3\nGETRANGE mykey -3 -1\nGETRANGE mykey 0 -1\nGETRANGE mykey 10 100",
    "tag": "redis"
  },
  {
    "title": "Output format",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/role.md",
    "content": "Provide information on the role of a Redis instance in the context of replication, by returning if the instance is currently a `master`, `slave`, or `sentinel`. The command also returns additional information about the state of the replication (if the role is master or slave) or the list of monitored master names (if the role is sentinel).\nOutput format\nThe command returns an array of elements. The first element is the role of\nthe instance, as one of the following three strings:\n\n\"master\"\n\"slave\"\n\"sentinel\"\n\nThe additional elements of the array depends on the role.\nMaster output\nAn example of output when `ROLE` is called in a master instance:\n`1) \"master\"\n2) (integer) 3129659\n3) 1) 1) \"127.0.0.1\"\n      2) \"9001\"\n      3) \"3129242\"\n   2) 1) \"127.0.0.1\"\n      2) \"9002\"\n      3) \"3129543\"`\nThe master output is composed of the following parts:\n\nThe string `master`.\nThe current master replication offset, which is an offset that masters and replicas share to understand, in partial resynchronizations, the part of the replication stream the replicas needs to fetch to continue.\nAn array composed of three elements array representing the connected replicas. Every sub-array contains the replica IP, port, and the last acknowledged replication offset.\n\nOutput of the command on replicas\nAn example of output when `ROLE` is called in a replica instance:\n`1) \"slave\"\n2) \"127.0.0.1\"\n3) (integer) 9000\n4) \"connected\"\n5) (integer) 3167038`\nThe replica output is composed of the following parts:\n\nThe string `slave`, because of backward compatibility (see note at the end of this page).\nThe IP of the master.\nThe port number of the master.\nThe state of the replication from the point of view of the master, that can be `connect` (the instance needs to connect to its master), `connecting` (the master-replica connection is in progress), `sync` (the master and replica are trying to perform the synchronization), `connected` (the replica is online).\nThe amount of data received from the replica so far in terms of master replication offset.\n\nSentinel output\nAn example of Sentinel output:\n`1) \"sentinel\"\n2) 1) \"resque-master\"\n   2) \"html-fragments-master\"\n   3) \"stats-master\"\n   4) \"metadata-master\"`\nThe sentinel output is composed of the following parts:\n\nThe string `sentinel`.\nAn array of master names monitored by this Sentinel instance.\n\n@return\n@array-reply: where the first element is one of `master`, `slave`, `sentinel` and the additional elements are role-specific as illustrated above.\n@examples\n`cli\nROLE`",
    "tag": "redis"
  },
  {
    "title": "slowlog-get.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/slowlog-get.md",
    "content": "The `SLOWLOG GET` command returns entries from the slow log in chronological order.\nThe Redis Slow Log is a system to log queries that exceeded a specified execution time.\nThe execution time does not include I/O operations like talking with the client, sending the reply and so forth, but just the time needed to actually execute the command (this is the only stage of command execution where the thread is blocked and can not serve other requests in the meantime).\nA new entry is added to the slow log whenever a command exceeds the execution time threshold defined by the `slowlog-log-slower-than` configuration directive.\nThe maximum number of entries in the slow log is governed by the `slowlog-max-len` configuration directive.\nBy default the command returns all of the entries in the log. The optional `count` argument limits the number of returned entries, so the command returns at most up to `count` entries.\nEach entry from the slow log is comprised of the following six values:\n\nA unique progressive identifier for every slow log entry.\nThe unix timestamp at which the logged command was processed.\nThe amount of time needed for its execution, in microseconds.\nThe array composing the arguments of the command.\nClient IP address and port.\nClient name if set via the `CLIENT SETNAME` command.\n\nThe entry's unique ID can be used in order to avoid processing slow log entries multiple times (for instance you may have a script sending you an email alert for every new slow log entry).\nThe ID is never reset in the course of the Redis server execution, only a server\nrestart will reset it.\n@reply",
    "tag": "redis"
  },
  {
    "title": "Patterns",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/setrange.md",
    "content": "Overwrites part of the string stored at key, starting at the specified offset,\nfor the entire length of value.\nIf the offset is larger than the current length of the string at key, the\nstring is padded with zero-bytes to make offset fit.\nNon-existing keys are considered as empty strings, so this command will make\nsure it holds a string large enough to be able to set value at offset.\nNote that the maximum offset that you can set is 2^29 -1 (536870911), as Redis\nStrings are limited to 512 megabytes.\nIf you need to grow beyond this size, you can use multiple keys.\nWarning: When setting the last possible byte and the string value stored at\nkey does not yet hold a string value, or holds a small string value, Redis\nneeds to allocate all intermediate memory which can block the server for some\ntime.\nOn a 2010 MacBook Pro, setting byte number 536870911 (512MB allocation) takes\n~300ms, setting byte number 134217728 (128MB allocation) takes ~80ms, setting\nbit number 33554432 (32MB allocation) takes ~30ms and setting bit number 8388608\n(8MB allocation) takes ~8ms.\nNote that once this first allocation is done, subsequent calls to `SETRANGE` for\nthe same key will not have the allocation overhead.\nPatterns\nThanks to `SETRANGE` and the analogous `GETRANGE` commands, you can use Redis\nstrings as a linear array with O(1) random access.\nThis is a very fast and efficient storage in many real world use cases.\n@return\n@integer-reply: the length of the string after it was modified by the command.\n@examples\nBasic usage:\n`cli\nSET key1 \"Hello World\"\nSETRANGE key1 6 \"Redis\"\nGET key1`\nExample of zero padding:\n```cli\nSETRANGE key2 6 \"Redis\"\nGET key2",
    "tag": "redis"
  },
  {
    "title": "Implementation details: MEET and PING packets",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-meet.md",
    "content": "`CLUSTER MEET` is used in order to connect different Redis nodes with cluster\nsupport enabled, into a working cluster.\nThe basic idea is that nodes by default don't trust each other, and are\nconsidered unknown, so that it is unlikely that different cluster nodes will\nmix into a single one because of system administration errors or network\naddresses modifications.\nSo in order for a given node to accept another one into the list of nodes\ncomposing a Redis Cluster, there are only two ways:\n\nThe system administrator sends a `CLUSTER MEET` command to force a node to meet another one.\nAn already known node sends a list of nodes in the gossip section that we are not aware of. If the receiving node trusts the sending node as a known node, it will process the gossip section and send a handshake to the nodes that are still not known.\n\nNote that Redis Cluster needs to form a full mesh (each node is connected with each other node), but in order to create a cluster, there is no need to send all the `CLUSTER MEET` commands needed to form the full mesh. What matter is to send enough `CLUSTER MEET` messages so that each node can reach each other node through a chain of known nodes. Thanks to the exchange of gossip information in heartbeat packets, the missing links will be created.\nSo, if we link node A with node B via `CLUSTER MEET`, and B with C, A and C will find their ways to handshake and create a link.\nAnother example: if we imagine a cluster formed of the following four nodes called A, B, C and D, we may send just the following set of commands to A:\n\n`CLUSTER MEET B-ip B-port`\n`CLUSTER MEET C-ip C-port`\n`CLUSTER MEET D-ip D-port`\n\nAs a side effect of `A` knowing and being known by all the other nodes, it will send gossip sections in the heartbeat packets that will allow each other node to create a link with each other one, forming a full mesh in a matter of seconds, even if the cluster is large.\nMoreover `CLUSTER MEET` does not need to be reciprocal. If I send the command to A in order to join B, I don't need to also send it to B in order to join A.\nIf the optional `cluster_bus_port` argument is not provided, the default of port + 10000 will be used.\nImplementation details: MEET and PING packets\nWhen a given node receives a `CLUSTER MEET` message, the node specified in the\ncommand still does not know the node we sent the command to. So in order for\nthe node to force the receiver to accept it as a trusted node, it sends a\n`MEET` packet instead of a `PING` packet. The two packets have exactly the\nsame format, but the former forces the receiver to acknowledge the node as\ntrusted.\n@return",
    "tag": "redis"
  },
  {
    "title": "xrevrange.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xrevrange.md",
    "content": "This command is exactly like `XRANGE`, but with the notable difference of\nreturning the entries in reverse order, and also taking the start-end\nrange in reverse order: in `XREVRANGE` you need to state the end ID\nand later the start ID, and the command will produce all the element\nbetween (or exactly like) the two IDs, starting from the end side.\nSo for instance, to get all the elements from the higher ID to the lower\nID one could use:\n\n\n```XREVRANGE somestream + -\n```\n\n\nSimilarly to get just the last element added into the stream it is\nenough to send:\n\n\n```XREVRANGE somestream + - COUNT 1\n```\n\n\n@return\n@array-reply, specifically:\nThe command returns the entries with IDs matching the specified range,\nfrom the higher ID to the lower ID matching.\nThe returned entries are complete, that means that the ID and all the fields\nthey are composed are returned. Moreover the entries are returned with\ntheir fields and values in the exact same order as `XADD` added them.\n@examples\n```cli\nXADD writers * name Virginia surname Woolf\nXADD writers * name Jane surname Austen\nXADD writers * name Toni surname Morrison\nXADD writers * name Agatha surname Christie\nXADD writers * name Ngozi surname Adichie\nXLEN writers\nXREVRANGE writers + - COUNT 1",
    "tag": "redis"
  },
  {
    "title": "zrevrank.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zrevrank.md",
    "content": "Returns the rank of `member` in the sorted set stored at `key`, with the scores\nordered from high to low.\nThe rank (or index) is 0-based, which means that the member with the highest\nscore has rank `0`.\nThe optional `WITHSCORE` argument supplements the command's reply with the score of the element returned.\nUse `ZRANK` to get the rank of an element with the scores ordered from low to\nhigh.\n@return\n\nIf `member` exists in the sorted set:\nusing `WITHSCORE`, @array-reply: an array containing the rank and score of `member`.\nwithout using `WITHSCORE`, @integer-reply: the rank of `member`.\nIf `member` does not exist in the sorted set or `key` does not exist:\nusing `WITHSCORE`, @array-reply: `nil`.\nwithout using `WITHSCORE`, @bulk-string-reply: `nil`.\n\nNote that in RESP3 null and nullarray are the same, but in RESP2 they are not.\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZREVRANK myzset \"one\"\nZREVRANK myzset \"four\"\nZREVRANK myzset \"three\" WITHSCORE\nZREVRANK myzset \"four\" WITHSCORE",
    "tag": "redis"
  },
  {
    "title": "expiretime.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/expiretime.md",
    "content": "Returns the absolute Unix timestamp (since January 1, 1970) in seconds at which the given key will expire.\nSee also the `PEXPIRETIME` command which returns the same information with milliseconds resolution.\n@return\n@integer-reply: Expiration Unix timestamp in seconds, or a negative value in order to signal an error (see the description below).\n\nThe command returns `-1` if the key exists but has no associated expiration time.\nThe command returns `-2` if the key does not exist.\n\n@examples\n```cli\nSET mykey \"Hello\"\nEXPIREAT mykey 33177117420\nEXPIRETIME mykey",
    "tag": "redis"
  },
  {
    "title": "swapdb.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/swapdb.md",
    "content": "This command swaps two Redis databases, so that immediately all the\nclients connected to a given database will see the data of the other database, and\nthe other way around. Example:\n\n\n```SWAPDB 0 1\n```\n\n\nThis will swap database 0 with database 1. All the clients connected with database 0 will immediately see the new data, exactly like all the clients connected with database 1 will see the data that was formerly of database 0.\n@return\n@simple-string-reply: `OK` if `SWAPDB` was executed correctly.\n@examples\n```\nSWAPDB 0 1",
    "tag": "redis"
  },
  {
    "title": "client-trackinginfo.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/client-trackinginfo.md",
    "content": "The command returns information about the current client connection's use of the server assisted client side caching feature.\n@return\n@array-reply: a list of tracking information sections and their respective values, specifically:\n\nflags: A list of tracking flags used by the connection. The flags and their meanings are as follows:\n`off`: The connection isn't using server assisted client side caching.\n`on`: Server assisted client side caching is enabled for the connection.\n`bcast`: The client uses broadcasting mode.\n`optin`: The client does not cache keys by default.\n`optout`: The client caches keys by default.\n`caching-yes`: The next command will cache keys (exists only together with `optin`).\n`caching-no`: The next command won't cache keys (exists only together with `optout`).\n`noloop`: The client isn't notified about keys modified by itself.\n`broken_redirect`: The client ID used for redirection isn't valid anymore.\nredirect: The client ID used for notifications redirection, or -1 when none.\n",
    "tag": "redis"
  },
  {
    "title": "Sorting by external keys",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/sort.md",
    "content": "Returns or stores the elements contained in the list, set or\nsorted set at `key`.\nThere is also the `SORT_RO` read-only variant of this command.\nBy default, sorting is numeric and elements are compared by their value\ninterpreted as double precision floating point number.\nThis is `SORT` in its simplest form:\n`SORT mylist`\nAssuming `mylist` is a list of numbers, this command will return the same list\nwith the elements sorted from small to large.\nIn order to sort the numbers from large to small, use the `!DESC` modifier:\n`SORT mylist DESC`\nWhen `mylist` contains string values and you want to sort them\nlexicographically, use the `!ALPHA` modifier:\n`SORT mylist ALPHA`\nRedis is UTF-8 aware, assuming you correctly set the `!LC_COLLATE` environment\nvariable.\nThe number of returned elements can be limited using the `!LIMIT` modifier.\nThis modifier takes the `offset` argument, specifying the number of elements to\nskip and the `count` argument, specifying the number of elements to return from\nstarting at `offset`.\nThe following example will return 10 elements of the sorted version of `mylist`,\nstarting at element 0 (`offset` is zero-based):\n`SORT mylist LIMIT 0 10`\nAlmost all modifiers can be used together.\nThe following example will return the first 5 elements, lexicographically sorted\nin descending order:\n`SORT mylist LIMIT 0 5 ALPHA DESC`\nSorting by external keys\nSometimes you want to sort elements using external keys as weights to compare\ninstead of comparing the actual elements in the list, set or sorted set.\nLet's say the list `mylist` contains the elements `1`, `2` and `3` representing\nunique IDs of objects stored in `object_1`, `object_2` and `object_3`.\nWhen these objects have associated weights stored in `weight_1`, `weight_2` and\n`weight_3`, `SORT` can be instructed to use these weights to sort `mylist` with\nthe following statement:\n`SORT mylist BY weight_*`\nThe `BY` option takes a pattern (equal to `weight_*` in this example) that is\nused to generate the keys that are used for sorting.\nThese key names are obtained substituting the first occurrence of `*` with the\nactual value of the element in the list (`1`, `2` and `3` in this example).\nSkip sorting the elements\nThe `!BY` option can also take a non-existent key, which causes `SORT` to skip\nthe sorting operation.\nThis is useful if you want to retrieve external keys (see the `!GET` option\nbelow) without the overhead of sorting.\n`SORT mylist BY nosort`\nRetrieving external keys\nOur previous example returns just the sorted IDs.\nIn some cases, it is more useful to get the actual objects instead of their IDs\n(`object_1`, `object_2` and `object_3`).\nRetrieving external keys based on the elements in a list, set or sorted set can\nbe done with the following command:\n`SORT mylist BY weight_* GET object_*`\nThe `!GET` option can be used multiple times in order to get more keys for every\nelement of the original list, set or sorted set.\nIt is also possible to `!GET` the element itself using the special pattern `#`:\n`SORT mylist BY weight_* GET object_* GET #`\nRestrictions for using external keys\nWhen enabling `Redis cluster-mode` there is no way to guarantee the existence of the external keys on the node which the command is processed on.\nIn this case, any use of `GET` or `BY` which reference external key pattern will cause the command to fail with an error.\nStarting from Redis 7.0, any use of `GET` or `BY` which reference external key pattern will only be allowed in case the current user running the command has full key read permissions.\nFull key read permissions can be set for the user by, for example, specifying `'%R~*'` or `'~*` with the relevant command access rules.\nYou can check the `ACL SETUSER` command manual for more information on setting ACL access rules.\nIf full key read permissions aren't set, the command will fail with an error.\nStoring the result of a SORT operation\nBy default, `SORT` returns the sorted elements to the client.\nWith the `!STORE` option, the result will be stored as a list at the specified\nkey instead of being returned to the client.\n`SORT mylist BY weight_* STORE resultkey`\nAn interesting pattern using `SORT ... STORE` consists in associating an\n`EXPIRE` timeout to the resulting key so that in applications where the result\nof a `SORT` operation can be cached for some time.\nOther clients will use the cached list instead of calling `SORT` for every\nrequest.\nWhen the key will timeout, an updated version of the cache can be created by\ncalling `SORT ... STORE` again.\nNote that for correctly implementing this pattern it is important to avoid\nmultiple clients rebuilding the cache at the same time.\nSome kind of locking is needed here (for instance using `SETNX`).\nUsing hashes in `!BY` and `!GET`\nIt is possible to use `!BY` and `!GET` options against hash fields with the\nfollowing syntax:\n`SORT mylist BY weight_*->fieldname GET object_*->fieldname`\nThe string `->` is used to separate the key name from the hash field name.\nThe key is substituted as documented above, and the hash stored at the resulting\nkey is accessed to retrieve the specified hash field.\n@return\n@array-reply: without passing the `store` option the command returns a list of sorted elements.",
    "tag": "redis"
  },
  {
    "title": "blmpop.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/blmpop.md",
    "content": "`BLMPOP` is the blocking variant of `LMPOP`.\nWhen any of the lists contains elements, this command behaves exactly like `LMPOP`.\nWhen used inside a `MULTI`/`EXEC` block, this command behaves exactly like `LMPOP`.\nWhen all lists are empty, Redis will block the connection until another client pushes to it or until the `timeout` (a double value specifying the maximum number of seconds to block) elapses.\nA `timeout` of zero can be used to block indefinitely.\nSee `LMPOP` for more information.\n@return\n@array-reply: specifically:\n\nA `nil` when no element could be popped, and timeout is reached.\n",
    "tag": "redis"
  },
  {
    "title": "pubsub-channels.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pubsub-channels.md",
    "content": "Lists the currently active channels.\nAn active channel is a Pub/Sub channel with one or more subscribers (excluding clients subscribed to patterns).\nIf no `pattern` is specified, all the channels are listed, otherwise if pattern is specified only channels matching the specified glob-style pattern are listed.\nCluster note: in a Redis Cluster clients can subscribe to every node, and can also publish to every other node. The cluster will make sure that published messages are forwarded as needed. That said, `PUBSUB`'s replies in a cluster only report information from the node's Pub/Sub context, rather than the entire cluster.\n@return",
    "tag": "redis"
  },
  {
    "title": "replicaof.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/replicaof.md",
    "content": "The `REPLICAOF` command can change the replication settings of a replica on the fly.\nIf a Redis server is already acting as replica, the command `REPLICAOF` NO ONE will turn off the replication, turning the Redis server into a MASTER.  In the proper form `REPLICAOF` hostname port will make the server a replica of another server listening at the specified hostname and port.\nIf a server is already a replica of some master, `REPLICAOF` hostname port will stop the replication against the old server and start the synchronization against the new one, discarding the old dataset.\nThe form `REPLICAOF` NO ONE will stop replication, turning the server into a MASTER, but will not discard the replication. So, if the old master stops working, it is possible to turn the replica into a master and set the application to use this new master in read/write. Later when the other Redis server is fixed, it can be reconfigured to work as a replica.\n@return\n@simple-string-reply\n@examples\n```\n\nREPLICAOF NO ONE\n\"OK\"\nREPLICAOF 127.0.0.1 6799\n\"OK\"\n",
    "tag": "redis"
  },
  {
    "title": "lcs.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/lcs.md",
    "content": "The LCS command implements the longest common subsequence algorithm. Note that this is different than the longest common string algorithm, since matching characters in the string does not need to be contiguous.\nFor instance the LCS between \"foo\" and \"fao\" is \"fo\", since scanning the two strings from left to right, the longest common set of characters is composed of the first \"f\" and then the \"o\".\nLCS is very useful in order to evaluate how similar two strings are. Strings can represent many things. For instance if two strings are DNA sequences, the LCS will provide a measure of similarity between the two DNA sequences. If the strings represent some text edited by some user, the LCS could represent how different the new text is compared to the old one, and so forth.\nNote that this algorithm runs in `O(N*M)` time, where N is the length of the first string and M is the length of the second string. So either spin a different Redis instance in order to run this algorithm, or make sure to run it against very small strings.\n```\n\nMSET key1 ohmytext key2 mynewtext\nOK\nLCS key1 key2\n\"mytext\"\n```\n\nSometimes we need just the length of the match:\n```\n\nLCS key1 key2 LEN\n(integer) 6\n```\n\nHowever what is often very useful, is to know the match position in each strings:\n```\n\nLCS key1 key2 IDX\n1) \"matches\"\n2) 1) 1) 1) (integer) 4\n         2) (integer) 7\n      2) 1) (integer) 5\n         2) (integer) 8\n   2) 1) 1) (integer) 2\n         2) (integer) 3\n      2) 1) (integer) 0\n         2) (integer) 1\n3) \"len\"\n4) (integer) 6\n```\n\nMatches are produced from the last one to the first one, since this is how\nthe algorithm works, and it more efficient to emit things in the same order.\nThe above array means that the first match (second element of the array)\nis between positions 2-3 of the first string and 0-1 of the second.\nThen there is another match between 4-7 and 5-8.\nTo restrict the list of matches to the ones of a given minimal length:\n```\n\nLCS key1 key2 IDX MINMATCHLEN 4\n1) \"matches\"\n2) 1) 1) 1) (integer) 4\n         2) (integer) 7\n      2) 1) (integer) 5\n         2) (integer) 8\n3) \"len\"\n4) (integer) 6\n```\n\nFinally to also have the match len:\n```\n\nLCS key1 key2 IDX MINMATCHLEN 4 WITHMATCHLEN\n1) \"matches\"\n2) 1) 1) 1) (integer) 4\n         2) (integer) 7\n      2) 1) (integer) 5\n         2) (integer) 8\n      3) (integer) 4\n3) \"len\"\n4) (integer) 6\n```\n\n@return\n\nWithout modifiers the string representing the longest common substring is returned.\nWhen `LEN` is given the command returns the length of the longest common substring.\nWhen `IDX` is given the command returns an array with the LCS length and all the ranges in both the strings, start and end offset for each string, where there are matches. When `WITHMATCHLEN` is given each array representing a match will also have the length of the match (see examples).\n",
    "tag": "redis"
  },
  {
    "title": "Serialization format",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/cluster-nodes.md",
    "content": "Each node in a Redis Cluster has its view of the current cluster configuration,\ngiven by the set of known nodes, the state of the connection we have with such\nnodes, their flags, properties and assigned slots, and so forth.\n`CLUSTER NODES` provides all this information, that is, the current cluster\nconfiguration of the node we are contacting, in a serialization format which\nhappens to be exactly the same as the one used by Redis Cluster itself in\norder to store on disk the cluster state (however the on disk cluster state\nhas a few additional info appended at the end).\nNote that normally clients willing to fetch the map between Cluster\nhash slots and node addresses should use `CLUSTER SLOTS` instead.\n`CLUSTER NODES`, that provides more information, should be used for\nadministrative tasks, debugging, and configuration inspections.\nIt is also used by `redis-cli` in order to manage a cluster.\nSerialization format\nThe output of the command is just a space-separated CSV string, where\neach line represents a node in the cluster. Starting from 7.2.0, the\noutput of the command always contains a new auxiliary field called\nshard-id. The following is an example of output on Redis 7.2.0.\n`07c37dfeb235213a872192d90877d0cd55635b91 127.0.0.1:30004@31004,,shard-id=69bc080733d1355567173199cff4a6a039a2f024 slave e7d1eecce10fd6bb5eb35b9f99a514335d9ba9ca 0 1426238317239 4 connected\n67ed2db8d677e59ec4a4cefb06858cf2a1a89fa1 127.0.0.1:30002@31002,,shard-id=114f6674a35b84949fe567f5dfd41415ee776261 master - 0 1426238316232 2 connected 5461-10922\n292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f 127.0.0.1:30003@31003,,shard-id=fdb36c73e72dd027bc19811b7c219ef6e55c550e master - 0 1426238318243 3 connected 10923-16383\n6ec23923021cf3ffec47632106199cb7f496ce01 127.0.0.1:30005@31005,,shard-id=114f6674a35b84949fe567f5dfd41415ee776261 slave 67ed2db8d677e59ec4a4cefb06858cf2a1a89fa1 0 1426238316232 5 connected\n824fe116063bc5fcf9f4ffd895bc17aee7731ac3 127.0.0.1:30006@31006,,shard-id=fdb36c73e72dd027bc19811b7c219ef6e55c550e slave 292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f 0 1426238317741 6 connected\ne7d1eecce10fd6bb5eb35b9f99a514335d9ba9ca 127.0.0.1:30001@31001,,shard-id=69bc080733d1355567173199cff4a6a039a2f024 myself,master - 0 0 1 connected 0-5460`\nEach line is composed of the following fields:\n`<id> <ip:port@cport[,hostname[,auxiliary_field=value]*]> <flags> <master> <ping-sent> <pong-recv> <config-epoch> <link-state> <slot> <slot> ... <slot>`\nThe meaning of each filed is the following:\n\n`id`: The node ID, a 40-character globally unique string generated when a node is created and never changed again (unless `CLUSTER RESET HARD` is used).\n`ip:port@cport`: The node address that clients should contact to run queries.\n`hostname`: A human readable string that can be configured via the `cluster-annouce-hostname` setting. The max length of the string is 256 characters, excluding the null terminator. The name can contain ASCII alphanumeric characters, '-', and '.' only.\n`[,auxiliary_field=value]*`: A list of comma-separated key-value pairs that represent various node properties, such as `shard-id`. There is no intrinsic order among auxiliary fields. The auxiliary fields can appear at different position in the list from release to release. Both the key name and value can contain ASCII alphanumeric characters and the characters in `!#$%&()*+-.:;<>?@[]^_{|}~` only. Auxiliary fields are explained in detail in the section below.\n`flags`: A list of comma separated flags: `myself`, `master`, `slave`, `fail?`, `fail`, `handshake`, `noaddr`, `nofailover`, `noflags`. Flags are explained below.\n`master`: If the node is a replica, and the primary is known, the primary node ID, otherwise the \"-\" character.\n`ping-sent`: Unix time at which the currently active ping was sent, or zero if there are no pending pings, in milliseconds.\n`pong-recv`: Unix time the last pong was received, in milliseconds.\n`config-epoch`: The configuration epoch (or version) of the current node (or of the current primary if the node is a replica). Each time there is a failover, a new, unique, monotonically increasing configuration epoch is created. If multiple nodes claim to serve the same hash slots, the one with the higher configuration epoch wins.\n`link-state`: The state of the link used for the node-to-node cluster bus. Use this link to communicate with the node. Can be `connected` or `disconnected`.\n`slot`: A hash slot number or range. Starting from argument number 9, but there may be up to 16384 entries in total (limit never reached). This is the list of hash slots served by this node. If the entry is just a number, it is parsed as such.  If it is a range, it is in the form `start-end`, and means that the node is responsible for all the hash slots from `start` to `end` including the start and end values.\n\nAuxiliary fields are:\n* `shard-id`: a 40-character globally unique string generated when a node is created. A node's shard id changes only when the node joins a different shard via `cluster replicate` and there the node's shard id is updated to its primary's.\nFlags are:\n\n`myself`: The node you are contacting.\n`master`: Node is a primary.\n`slave`: Node is a replica.\n`fail?`: Node is in `PFAIL` state. Not reachable for the node you are contacting, but still logically reachable (not in `FAIL` state).\n`fail`: Node is in `FAIL` state. It was not reachable for multiple nodes that promoted the `PFAIL` state to `FAIL`.\n`handshake`: Untrusted node, we are handshaking.\n`noaddr`: No address known for this node.\n`nofailover`: Replica will not try to failover.\n`noflags`: No flags at all.\n\nNotes on published config epochs\nReplicas broadcast their primary's config epochs (in order to get an `UPDATE`\nmessage if they are found to be stale), so the real config epoch of the\nreplica (which is meaningless more or less, since they don't serve hash slots)\ncan be only obtained checking the node flagged as `myself`, which is the entry\nof the node we are asking to generate `CLUSTER NODES` output. The other\nreplicas epochs reflect what they publish in heartbeat packets, which is, the\nconfiguration epoch of the primaries they are currently replicating.\nSpecial slot entries\nNormally hash slots associated to a given node are in one of the following formats,\nas already explained above:\n\nSingle number: 3894\nRange: 3900-4000\n\nHowever node hash slots can be in a special state, used in order to communicate errors after a node restart (mismatch between the keys in the AOF/RDB file, and the node hash slots configuration), or when there is a resharding operation in progress. This two states are importing and migrating.\nThe meaning of the two states is explained in the Redis Specification, however the gist of the two states is the following:\n\nImporting slots are yet not part of the nodes hash slot, there is a migration in progress. The node will accept queries about these slots only if the `ASK` command is used.\nMigrating slots are assigned to the node, but are being migrated to some other node. The node will accept queries if all the keys in the command exist already, otherwise it will emit what is called an ASK redirection, to force new keys creation directly in the importing node.\n\nImporting and migrating slots are emitted in the `CLUSTER NODES` output as follows:\n\nImporting slot: `[slot_number-<-importing_from_node_id]`\nMigrating slot: `[slot_number->-migrating_to_node_id]`\n\nThe following are a few examples of importing and migrating slots:\n\n`[93-<-292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f]`\n`[1002-<-67ed2db8d677e59ec4a4cefb06858cf2a1a89fa1]`\n`[77->-e7d1eecce10fd6bb5eb35b9f99a514335d9ba9ca]`\n`[16311->-292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f]`\n\nNote that the format does not have any space, so `CLUSTER NODES` output format is plain CSV with space as separator even when this special slots are emitted. However a complete parser for the format should be able to handle them.\nNote that:\n\nMigration and importing slots are only added to the node flagged as `myself`. This information is local to a node, for its own slots.\nImporting and migrating slots are provided as additional info. If the node has a given hash slot assigned, it will be also a plain number in the list of hash slots, so clients that don't have a clue about hash slots migrations can just skip this special fields.\n\n@return\n@bulk-string-reply: The serialized cluster configuration.",
    "tag": "redis"
  },
  {
    "title": "script-exists.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/script-exists.md",
    "content": "Returns information about the existence of the scripts in the script cache.\nThis command accepts one or more SHA1 digests and returns a list of ones or\nzeros to signal if the scripts are already defined or not inside the script\ncache.\nThis can be useful before a pipelining operation to ensure that scripts are\nloaded (and if not, to load them using `SCRIPT LOAD`) so that the pipelining\noperation can be performed solely using `EVALSHA` instead of `EVAL` to save\nbandwidth.\nFor more information about `EVAL` scripts please refer to Introduction to Eval Scripts.\n@return\n@array-reply The command returns an array of integers that correspond to\nthe specified SHA1 digest arguments.\nFor every corresponding SHA1 digest of a script that actually exists in the",
    "tag": "redis"
  },
  {
    "title": "bitpos.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/bitpos.md",
    "content": "Return the position of the first bit set to 1 or 0 in a string.\nThe position is returned, thinking of the string as an array of bits from left to\nright, where the first byte's most significant bit is at position 0, the second\nbyte's most significant bit is at position 8, and so forth.\nThe same bit position convention is followed by `GETBIT` and `SETBIT`.\nBy default, all the bytes contained in the string are examined.\nIt is possible to look for bits only in a specified interval passing the additional arguments start and end (it is possible to just pass start, the operation will assume that the end is the last byte of the string. However there are semantic differences as explained later).\nBy default, the range is interpreted as a range of bytes and not a range of bits, so `start=0` and `end=2` means to look at the first three bytes.\nYou can use the optional `BIT` modifier to specify that the range should be interpreted as a range of bits.\nSo `start=0` and `end=2` means to look at the first three bits.\nNote that bit positions are returned always as absolute values starting from bit zero even when start and end are used to specify a range.\nLike for the `GETRANGE` command start and end can contain negative values in\norder to index bytes starting from the end of the string, where -1 is the last\nbyte, -2 is the penultimate, and so forth. When `BIT` is specified, -1 is the last\nbit, -2 is the penultimate, and so forth.\nNon-existent keys are treated as empty strings.\n@return\n@integer-reply\nThe command returns the position of the first bit set to 1 or 0 according to the request.\nIf we look for set bits (the bit argument is 1) and the string is empty or composed of just zero bytes, -1 is returned.\nIf we look for clear bits (the bit argument is 0) and the string only contains bit set to 1, the function returns the first bit not part of the string on the right. So if the string is three bytes set to the value `0xff` the command `BITPOS key 0` will return 24, since up to bit 23 all the bits are 1.\nBasically, the function considers the right of the string as padded with zeros if you look for clear bits and specify no range or the start argument only.\nHowever, this behavior changes if you are looking for clear bits and specify a range with both start and end. If no clear bit is found in the specified range, the function returns -1 as the user specified a clear range and there are no 0 bits in that range.\n@examples\n```cli\nSET mykey \"\\xff\\xf0\\x00\"\nBITPOS mykey 0\nSET mykey \"\\x00\\xff\\xf0\"\nBITPOS mykey 1 0\nBITPOS mykey 1 2\nBITPOS mykey 1 2 -1 BYTE\nBITPOS mykey 1 7 15 BIT\nset mykey \"\\x00\\x00\\x00\"\nBITPOS mykey 1\nBITPOS mykey 1 7 -3 BIT",
    "tag": "redis"
  },
  {
    "title": "wait.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/wait.md",
    "content": "This command blocks the current client until all the previous write commands\nare successfully transferred and acknowledged by at least the specified number\nof replicas. If the timeout, specified in milliseconds, is reached, the command\nreturns even if the specified number of replicas were not yet reached.\nThe command will always return the number of replicas that acknowledged\nthe write commands sent before the `WAIT` command, both in the case where\nthe specified number of replicas are reached, or when the timeout is reached.\nA few remarks:\n\nWhen `WAIT` returns, all the previous write commands sent in the context of the current connection are guaranteed to be received by the number of replicas returned by `WAIT`.\nIf the command is sent as part of a `MULTI` transaction, the command does not block but instead just return ASAP the number of replicas that acknowledged the previous write commands.\nA timeout of 0 means to block forever.\nSince `WAIT` returns the number of replicas reached both in case of failure and success, the client should check that the returned value is equal or greater to the replication level it demanded.\n\nConsistency and WAIT\nNote that `WAIT` does not make Redis a strongly consistent store: while synchronous replication is part of a replicated state machine, it is not the only thing needed. However in the context of Sentinel or Redis Cluster failover, `WAIT` improves the real world data safety.\nSpecifically if a given write is transferred to one or more replicas, it is more likely (but not guaranteed) that if the master fails, we'll be able to promote, during a failover, a replica that received the write: both Sentinel and Redis Cluster will do a best-effort attempt to promote the best replica among the set of available replicas.\nHowever this is just a best-effort attempt so it is possible to still lose a write synchronously replicated to multiple replicas.\nImplementation details\nSince the introduction of partial resynchronization with replicas (PSYNC feature) Redis replicas asynchronously ping their master with the offset they already processed in the replication stream. This is used in multiple ways:\n\nDetect timed out replicas.\nPerform a partial resynchronization after a disconnection.\nImplement `WAIT`.\n\nIn the specific case of the implementation of `WAIT`, Redis remembers, for each client, the replication offset of the produced replication stream when a given\nwrite command was executed in the context of a given client. When `WAIT` is\ncalled Redis checks if the specified number of replicas already acknowledged\nthis offset or a greater one.\n@return\n@integer-reply: The command returns the number of replicas reached by all the writes performed in the context of the current connection.\n@examples\n```\n\nSET foo bar\nOK\nWAIT 1 0\n(integer) 1\nWAIT 2 1000\n(integer) 1\n```\n",
    "tag": "redis"
  },
  {
    "title": "geosearchstore.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/geosearchstore.md",
    "content": "This command is like `GEOSEARCH`, but stores the result in destination key.\nThis command replaces the now deprecated `GEORADIUS` and `GEORADIUSBYMEMBER`.\nBy default, it stores the results in the `destination` sorted set with their geospatial information.\nWhen using the `STOREDIST` option, the command stores the items in a sorted set populated with their distance from the center of the circle or box, as a floating-point number, in the same unit specified for that shape.\n@return\n@integer-reply: the number of elements in the resulting set.\n@examples\n```cli\nGEOADD Sicily 13.361389 38.115556 \"Palermo\" 15.087269 37.502669 \"Catania\"\nGEOADD Sicily 12.758489 38.788135 \"edge1\"   17.241510 38.788135 \"edge2\" \nGEOSEARCHSTORE key1 Sicily FROMLONLAT 15 37 BYBOX 400 400 km ASC COUNT 3\nGEOSEARCH key1 FROMLONLAT 15 37 BYBOX 400 400 km ASC WITHCOORD WITHDIST WITHHASH\nGEOSEARCHSTORE key2 Sicily FROMLONLAT 15 37 BYBOX 400 400 km ASC COUNT 3 STOREDIST\nZRANGE key2 0 -1 WITHSCORES",
    "tag": "redis"
  },
  {
    "title": "Options",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/pexpireat.md",
    "content": "`PEXPIREAT` has the same effect and semantic as `EXPIREAT`, but the Unix time at\nwhich the key will expire is specified in milliseconds instead of seconds.\nOptions\nThe `PEXPIREAT` command supports a set of options since Redis 7.0:\n\n`NX` -- Set expiry only when the key has no expiry\n`XX` -- Set expiry only when the key has an existing expiry\n`GT` -- Set expiry only when the new expiry is greater than current one\n`LT` -- Set expiry only when the new expiry is less than current one\n\nA non-volatile key is treated as an infinite TTL for the purpose of `GT` and `LT`.\nThe `GT`, `LT` and `NX` options are mutually exclusive.\n@return\n@integer-reply, specifically:\n\n`1` if the timeout was set.\n`0` if the timeout was not set. e.g. key doesn't exist, or operation skipped due to the provided arguments.\n\n@examples\n```cli\nSET mykey \"Hello\"\nPEXPIREAT mykey 1555555555005\nTTL mykey\nPTTL mykey",
    "tag": "redis"
  },
  {
    "title": "reset.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/reset.md",
    "content": "This command performs a full reset of the connection's server-side context, \nmimicking the effect of disconnecting and reconnecting again.\nWhen the command is called from a regular client connection, it does the\nfollowing:\n\nDiscards the current `MULTI` transaction block, if one exists.\nUnwatches all keys `WATCH`ed by the connection.\nDisables `CLIENT TRACKING`, if in use.\nSets the connection to `READWRITE` mode.\nCancels the connection's `ASKING` mode, if previously set.\nSets `CLIENT REPLY` to `ON`.\nSets the protocol version to RESP2.\n`SELECT`s database 0.\nExits `MONITOR` mode, when applicable.\nAborts Pub/Sub's subscription state (`SUBSCRIBE` and `PSUBSCRIBE`), when\n  appropriate.\nDeauthenticates the connection, requiring a call `AUTH` to reauthenticate when\n  authentication is enabled.\n\n@return",
    "tag": "redis"
  },
  {
    "title": "config-get.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/config-get.md",
    "content": "The `CONFIG GET` command is used to read the configuration parameters of a\nrunning Redis server.\nNot all the configuration parameters are supported in Redis 2.4, while Redis 2.6\ncan read the whole configuration of a server using this command.\nThe symmetric command used to alter the configuration at run time is `CONFIG\nSET`.\n`CONFIG GET` takes multiple arguments, which are glob-style patterns.\nAny configuration parameter matching any of the patterns are reported as a list\nof key-value pairs.\nExample:\n`redis> config get *max-*-entries* maxmemory\n 1) \"maxmemory\"\n 2) \"0\"\n 3) \"hash-max-listpack-entries\"\n 4) \"512\"\n 5) \"hash-max-ziplist-entries\"\n 6) \"512\"\n 7) \"set-max-intset-entries\"\n 8) \"512\"\n 9) \"zset-max-listpack-entries\"\n10) \"128\"\n11) \"zset-max-ziplist-entries\"\n12) \"128\"`\nYou can obtain a list of all the supported configuration parameters by typing\n`CONFIG GET *` in an open `redis-cli` prompt.\nAll the supported parameters have the same meaning of the equivalent\nconfiguration parameter used in the redis.conf file:\nNote that you should look at the redis.conf file relevant to the version you're\nworking with as configuration options might change between versions. The link\nabove is to the latest development version.\n@return",
    "tag": "redis"
  },
  {
    "title": "`-` and `+` special IDs",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/xrange.md",
    "content": "The command returns the stream entries matching a given range of IDs.\nThe range is specified by a minimum and maximum ID. All the entries having\nan ID between the two specified or exactly one of the two IDs specified\n(closed interval) are returned.\nThe `XRANGE` command has a number of applications:\n\nReturning items in a specific time range. This is possible because\n  Stream IDs are related to time.\nIterating a stream incrementally, returning just\n  a few items at every iteration. However it is semantically much more\n  robust than the `SCAN` family of functions.\nFetching a single entry from a stream, providing the ID of the entry\n  to fetch two times: as start and end of the query interval.\n\nThe command also has a reciprocal command returning items in the\nreverse order, called `XREVRANGE`, which is otherwise identical.\n`-` and `+` special IDs\nThe `-` and `+` special IDs mean respectively the minimum ID possible\nand the maximum ID possible inside a stream, so the following command\nwill just return every entry in the stream:\n```\n\nXRANGE somestream - +\n1) 1) 1526985054069-0\n   2) 1) \"duration\"\n      2) \"72\"\n      3) \"event-id\"\n      4) \"9\"\n      5) \"user-id\"\n      6) \"839248\"\n2) 1) 1526985069902-0\n   2) 1) \"duration\"\n      2) \"415\"\n      3) \"event-id\"\n      4) \"2\"\n      5) \"user-id\"\n      6) \"772213\"\n... other entries here ...\n```\n\nThe `-` and `+` special IDs mean, respectively, the minimal and maximal range IDs,\nhowever they are nicer to type.\nIncomplete IDs\nStream IDs are composed of two parts, a Unix millisecond time stamp and a\nsequence number for entries inserted in the same millisecond. It is possible\nto use `XRANGE` specifying just the first part of the ID, the millisecond time,\nlike in the following example:\n```\n\nXRANGE somestream 1526985054069 1526985055069\n```\n\nIn this case, `XRANGE` will auto-complete the start interval with `-0`\nand end interval with `-18446744073709551615`, in order to return all the\nentries that were generated between a given millisecond and the end of\nthe other specified millisecond. This also means that repeating the same\nmillisecond two times, we get all the entries within such millisecond,\nbecause the sequence number range will be from zero to the maximum.\nUsed in this way `XRANGE` works as a range query command to obtain entries\nin a specified time. This is very handy in order to access the history\nof past events in a stream.\nExclusive ranges\nThe range is close (inclusive) by default, meaning that the reply can include\nentries with IDs matching the query's start and end intervals. It is possible\nto specify an open interval (exclusive) by prefixing the ID with the\ncharacter `(`. This is useful for iterating the stream, as explained below.\nReturning a maximum number of entries\nUsing the COUNT option it is possible to reduce the number of entries\nreported. This is a very important feature even if it may look marginal,\nbecause it allows, for instance, to model operations such as give me\nthe entry greater or equal to the following:\n```\n\nXRANGE somestream 1526985054069-0 + COUNT 1\n1) 1) 1526985054069-0\n   2) 1) \"duration\"\n      2) \"72\"\n      3) \"event-id\"\n      4) \"9\"\n      5) \"user-id\"\n      6) \"839248\"\n```\n\nIn the above case the entry `1526985054069-0` exists, otherwise the server\nwould have sent us the next one. Using `COUNT` is also the base in order to\nuse `XRANGE` as an iterator.\nIterating a stream\nIn order to iterate a stream, we can proceed as follows. Let's assume that\nwe want two elements per iteration. We start fetching the first two\nelements, which is trivial:\n```\n\nXRANGE writers - + COUNT 2\n1) 1) 1526985676425-0\n   2) 1) \"name\"\n      2) \"Virginia\"\n      3) \"surname\"\n      4) \"Woolf\"\n2) 1) 1526985685298-0\n   2) 1) \"name\"\n      2) \"Jane\"\n      3) \"surname\"\n      4) \"Austen\"\n```\n\nThen instead of starting the iteration again from `-`, as the start\nof the range we use the entry ID of the last entry returned by the\nprevious `XRANGE` call as an exclusive interval.\nThe ID of the last entry is `1526985685298-0`, so we just prefix it\nwith a '(', and continue our iteration:\n```\n\nXRANGE writers (1526985685298-0 + COUNT 2\n1) 1) 1526985691746-0\n   2) 1) \"name\"\n      2) \"Toni\"\n      3) \"surname\"\n      4) \"Morrison\"\n2) 1) 1526985712947-0\n   2) 1) \"name\"\n      2) \"Agatha\"\n      3) \"surname\"\n      4) \"Christie\"\n```\n\nAnd so forth. Eventually this will allow to visit all the entries in the\nstream. Obviously, we can start the iteration from any ID, or even from\na specific time, by providing a given incomplete start ID. Moreover, we\ncan limit the iteration to a given ID or time, by providing an end\nID or incomplete ID instead of `+`.\nThe command `XREAD` is also able to iterate the stream.\nThe command `XREVRANGE` can iterate the stream reverse, from higher IDs\n(or times) to lower IDs (or times).\nIterating with earlier versions of Redis\nWhile exclusive range intervals are only available from Redis 6.2, it is still\npossible to use a similar stream iteration pattern with earlier versions. You\nstart fetching from the stream the same way as described above to obtain the\nfirst entries.\nFor the subsequent calls, you'll need to programmatically advance the last\nentry's ID returned. Most Redis client should abstract this detail, but the\nimplementation can also be in the application if needed. In the example above,\nthis means incrementing the sequence of `1526985685298-0` by one, from 0 to 1.\nThe second call would, therefore, be:\n```\n\nXRANGE writers 1526985685298-1 + COUNT 2\n1) 1) 1526985691746-0\n   2) 1) \"name\"\n      2) \"Toni\"\n...\n```\n\nAlso, note that once the sequence part of the last ID equals \n18446744073709551615, you'll need to increment the timestamp and reset the\nsequence part to 0. For example, incrementing the ID\n`1526985685298-18446744073709551615` should result in `1526985685299-0`.\nA symmetrical pattern applies to iterating the stream with `XREVRANGE`. The\nonly difference is that the client needs to decrement the ID for the subsequent\ncalls. When decrementing an ID with a sequence part of 0, the timestamp needs\nto be decremented by 1 and the sequence set to 18446744073709551615.\nFetching single items\nIf you look for an `XGET` command you'll be disappointed because `XRANGE`\nis effectively the way to go in order to fetch a single entry from a\nstream. All you have to do is to specify the ID two times in the arguments\nof XRANGE:\n```\n\nXRANGE mystream 1526984818136-0 1526984818136-0\n1) 1) 1526984818136-0\n   2) 1) \"duration\"\n      2) \"1532\"\n      3) \"event-id\"\n      4) \"5\"\n      5) \"user-id\"\n      6) \"7782813\"\n```\n\nAdditional information about streams\nFor further information about Redis streams please check our\nintroduction to Redis Streams document.\n@return\n@array-reply, specifically:\nThe command returns the entries with IDs matching the specified range.\nThe returned entries are complete, that means that the ID and all the fields\nthey are composed are returned. Moreover, the entries are returned with\ntheir fields and values in the exact same order as `XADD` added them.\n@examples\n```cli\nXADD writers * name Virginia surname Woolf\nXADD writers * name Jane surname Austen\nXADD writers * name Toni surname Morrison\nXADD writers * name Agatha surname Christie\nXADD writers * name Ngozi surname Adichie\nXLEN writers\nXRANGE writers - + COUNT 2",
    "tag": "redis"
  },
  {
    "title": "zpopmin.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/zpopmin.md",
    "content": "Removes and returns up to `count` members with the lowest scores in the sorted\nset stored at `key`.\nWhen left unspecified, the default value for `count` is 1. Specifying a `count`\nvalue that is higher than the sorted set's cardinality will not produce an\nerror. When returning multiple elements, the one with the lowest score will\nbe the first, followed by the elements with greater scores.\n@return\n@array-reply: list of popped elements and scores.\n@examples\n```cli\nZADD myzset 1 \"one\"\nZADD myzset 2 \"two\"\nZADD myzset 3 \"three\"\nZPOPMIN myzset",
    "tag": "redis"
  },
  {
    "title": "hincrby.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/hincrby.md",
    "content": "Increments the number stored at `field` in the hash stored at `key` by\n`increment`.\nIf `key` does not exist, a new key holding a hash is created.\nIf `field` does not exist the value is set to `0` before the operation is\nperformed.\nThe range of values supported by `HINCRBY` is limited to 64 bit signed integers.\n@return\n@integer-reply: the value at `field` after the increment operation.\n@examples\nSince the `increment` argument is signed, both increment and decrement\noperations can be performed:\n```cli\nHSET myhash field 5\nHINCRBY myhash field 1\nHINCRBY myhash field -1\nHINCRBY myhash field -10",
    "tag": "redis"
  },
  {
    "title": "acl-list.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/acl-list.md",
    "content": "The command shows the currently active ACL rules in the Redis server. Each\nline in the returned array defines a different user, and the format is the\nsame used in the redis.conf file or the external ACL file, so you can\ncut and paste what is returned by the ACL LIST command directly inside a\nconfiguration file if you wish (but make sure to check `ACL SAVE`).\n@return\nAn array of strings.\n@examples\n```\n\nACL LIST\n1) \"user antirez on #9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08 ~objects: & +@all -@admin -@dangerous\"\n2) \"user default on nopass ~ & +@all\"\n",
    "tag": "redis"
  },
  {
    "title": "linsert.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/linsert.md",
    "content": "Inserts `element` in the list stored at `key` either before or after the reference\nvalue `pivot`.\nWhen `key` does not exist, it is considered an empty list and no operation is\nperformed.\nAn error is returned when `key` exists but does not hold a list value.\n@return\n@integer-reply: the list length after a successful insert operation, `0` if the `key` doesn't exist, and `-1` when the `pivot` wasn't found.\n@examples\n```cli\nRPUSH mylist \"Hello\"\nRPUSH mylist \"World\"\nLINSERT mylist BEFORE \"World\" \"There\"\nLRANGE mylist 0 -1",
    "tag": "redis"
  },
  {
    "title": "Pattern: Reliable queue",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/blmove.md",
    "content": "`BLMOVE` is the blocking variant of `LMOVE`.\nWhen `source` contains elements, this command behaves exactly like `LMOVE`.\nWhen used inside a `MULTI`/`EXEC` block, this command behaves exactly like `LMOVE`.\nWhen `source` is empty, Redis will block the connection until another client\npushes to it or until `timeout` (a double value specifying the maximum number of seconds to block) is reached.\nA `timeout` of zero can be used to block indefinitely.\nThis command comes in place of the now deprecated `BRPOPLPUSH`. Doing\n`BLMOVE RIGHT LEFT` is equivalent.\nSee `LMOVE` for more information.\n@return\n@bulk-string-reply: the element being popped from `source` and pushed to `destination`.\nIf `timeout` is reached, a @nil-reply is returned.\nPattern: Reliable queue\nPlease see the pattern description in the `LMOVE` documentation.\nPattern: Circular list",
    "tag": "redis"
  },
  {
    "title": "memory-stats.md",
    "source": "https://github.com/redis/redis-doc/tree/master/commands/memory-stats.md",
    "content": "The `MEMORY STATS` command returns an @array-reply about the memory usage of the\nserver.\nThe information about memory usage is provided as metrics and their respective\nvalues. The following metrics are reported:\n\n`peak.allocated`: Peak memory consumed by Redis in bytes (see `INFO`'s\n     `used_memory_peak`)\n`total.allocated`: Total number of bytes allocated by Redis using its\n     allocator (see `INFO`'s `used_memory`)\n`startup.allocated`: Initial amount of memory consumed by Redis at startup\n     in bytes (see `INFO`'s `used_memory_startup`)\n`replication.backlog`: Size in bytes of the replication backlog (see\n     `INFO`'s `repl_backlog_active`)\n`clients.slaves`: The total size in bytes of all replicas overheads (output\n     and query buffers, connection contexts)\n`clients.normal`: The total size in bytes of all clients overheads (output\n     and query buffers, connection contexts)\n`cluster.links`: Memory usage by cluster links (Added in Redis 7.0, see `INFO`'s `mem_cluster_links`).\n`aof.buffer`: The summed size in bytes of AOF related buffers.\n`lua.caches`: the summed size in bytes of the overheads of the Lua scripts'\n     caches\n`dbXXX`: For each of the server's databases, the overheads of the main and\n     expiry dictionaries (`overhead.hashtable.main` and\n    `overhead.hashtable.expires`, respectively) are reported in bytes\n`overhead.total`: The sum of all overheads, i.e. `startup.allocated`,\n     `replication.backlog`, `clients.slaves`, `clients.normal`, `aof.buffer` and\n     those of the internal data structures that are used in managing the\n     Redis keyspace (see `INFO`'s `used_memory_overhead`)\n`keys.count`: The total number of keys stored across all databases in the\n     server\n`keys.bytes-per-key`: The ratio between net memory usage (`total.allocated`\n     minus `startup.allocated`) and `keys.count` \n`dataset.bytes`: The size in bytes of the dataset, i.e. `overhead.total`\n     subtracted from `total.allocated` (see `INFO`'s `used_memory_dataset`)\n`dataset.percentage`: The percentage of `dataset.bytes` out of the net\n     memory usage\n`peak.percentage`: The percentage of `peak.allocated` out of\n     `total.allocated`\n`fragmentation`: See `INFO`'s `mem_fragmentation_ratio`\n\n@return\n@array-reply: nested list of memory usage metrics and their values",
    "tag": "redis"
  },
  {
    "title": "Code of Conduct",
    "source": "https://github.com/redis/redis-doc/tree/master/community/_index.md",
    "content": "\ntitle: Community\nlinkTitle: Community\n\nSince 2009, the Redis open source project has inspired an enthusiastic and active community of users and contributors. We continue to be committed to fostering an open, welcoming, diverse, inclusive, and healthy community.\nCode of Conduct\nRedis has adopted the Contributor Covenant Code of Conduct.\nGetting help\nDiscord server\nOn the Redis Discord server, you can chat with members of the Redis community in real time. You'll meet Redis users, contributors, and developer advocates. This is a great place to stop in for quick questions or to share your latest Redis discoveries.\nMailing list\nJoin the Redis mailing list to discuss the ongoing development of Redis and to find out about new Redis releases.\nStack Overflow\nHave a question about Redis? Search the Stack Overflow Redis tag for answers, or post a question of your own.\nRedis news\nFor occasional updates on the new Redis releases, you can either subscribe to the Redis mailing list or follow the Redis News Feed Twitter account.\nTo keep up with the latest from Redis Inc., including news on Redis Cloud and Redis Stack, consider following the Redis Twitter feed.\nProject governance\nRedis has adopted a light governance model led by individuals who have made significant contributions to Redis and demonstrated a long-term commitment to the project.\nLearn more about the project's governance and the Redis Core Team on the Redis governance page.\nConferences and meetups\nRedis regularly sponsors conferences and meetups. Recent conferences include:\n\n\nRedis Days 2022\n\n\nRedisConf 2021\n\n\nRedisConf 2020\n\n\nContributing to Redis\nThere are many ways to contribute to Redis, starting with documentation all the way to changes to the open source Redis server. Here are a few ways you can get involved.\nContributing to docs\nThe Redis docs are open source, and we'd love to incorporate your contributions. For small changes and typos, we recommend creating a pull request against redis-doc repo.\nReporting bugs\nTo report a bug in Redis, create a Redis Github issue.\nFor larger doc changes, we ask that you first create an issue describing your proposed changes. This is a good way to get feedback in advance to increase the likelihood that your changes will be accepted.\nClient libraries\nThe Redis client libraries are nearly always open source and accepting of contributions. Consult the contribution guidelines for the library you're interested in.\nHacktoberfest",
    "tag": "redis"
  }
]