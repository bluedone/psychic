[
  {
    "title": "Step 1: Setup",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/get-started.mdx",
    "content": "\ntitle: Get started with Apollo Client\nHello! \ud83d\udc4b This short tutorial gets you up and running with Apollo Client.\n\nFor an introduction to the entire Apollo platform, check out Odyssey, Apollo's interactive learning platform.\n\nStep 1: Setup\nTo start this tutorial, do one of the following:\n\nCreate a new React project locally with Create React App, or\nCreate a new React sandbox on CodeSandbox.\n\nStep 2: Install dependencies\nApplications that use Apollo Client require two top-level dependencies:\n\n`@apollo/client`: This single package contains virtually everything you need to set up Apollo Client. It includes the in-memory cache, local state management, error handling, and a React-based view layer.\n`graphql`: This package provides logic for parsing GraphQL queries.\n\nRun the following command to install both of these packages:\n`bash\nnpm install @apollo/client graphql`\n\nIf you're using a React sandbox from CodeSandbox and you encounter a `TypeError`, try downgrading the version of the `graphql` package to `15.8.0` in the Dependencies panel. If you encounter a different error after downgrading, refresh the page.\n\nOur example application will use the FlyBy GraphQL API from Apollo Odyssey's Voyage tutorial series. This API provides a list of intergalactic travel locations and details about those locations \ud83d\udc7d\nStep 3: Initialize `ApolloClient`\nWith our dependencies set up, we can now initialize an `ApolloClient` instance.\nIn `index.js`, let's first import the symbols we need from `@apollo/client`:\n`js title=\"index.js\"\nimport { ApolloClient, InMemoryCache, ApolloProvider, gql } from '@apollo/client';`\nNext we'll initialize `ApolloClient`, passing its constructor a configuration object with the `uri` and `cache` fields:\n`js title=\"index.js\"\nconst client = new ApolloClient({\n  uri: 'https://flyby-router-demo.herokuapp.com/',\n  cache: new InMemoryCache(),\n});`\n\n`uri` specifies the URL of our GraphQL server.\n`cache` is an instance of `InMemoryCache`, which Apollo Client uses to cache query results after fetching them.\n\nThat's it! Our `client` is ready to start fetching data. Now before we start using Apollo Client with React, let's first try sending a query with plain JavaScript.\nIn the same `index.js` file, call `client.query()` with the query string (wrapped in the `gql` template literal) shown below:\n```js title=\"index.js\"\n// const client = ...\nclient\n  .query({\n    query: gql`query GetLocations {\n        locations {\n          id\n          name\n          description\n          photo\n        }\n      }`,\n  })\n  .then((result) => console.log(result));\n```\nRun this code, open your console, and inspect the result object. You should see a `data` property with `locations` attached, along with some other properties like `loading` and `networkStatus`. Nice!\nAlthough executing GraphQL operations directly like this can be useful, Apollo Client really shines when it's integrated with a view layer like React. You can bind queries to your UI and update it automatically as new data is fetched.\nLet's look at how that works!\nStep 4: Connect your client to React\nYou connect Apollo Client to React with the `ApolloProvider` component. Similar to React's Context.Provider, `ApolloProvider` wraps your React app and places Apollo Client on the context, enabling you to access it from anywhere in your component tree.\nIn `index.js`, let's wrap our React app with an `ApolloProvider`. We suggest putting the `ApolloProvider` somewhere high in your app, above any component that might need to access GraphQL data.\n```jsx title=\"index.js\" {15-17}\nimport React from 'react';\nimport * as ReactDOM from 'react-dom/client';\nimport { ApolloClient, InMemoryCache, ApolloProvider } from '@apollo/client';\nimport App from './App';\nconst client = new ApolloClient({\n  uri: 'https://flyby-router-demo.herokuapp.com/',\n  cache: new InMemoryCache(),\n});\n// Supported in React 18+\nconst root = ReactDOM.createRoot(document.getElementById('root'));\nroot.render(\n  \n\n,\n);\n```\nStep 5: Fetch data with `useQuery`\nAfter your `ApolloProvider` is hooked up, you can start requesting data with `useQuery`. The `useQuery` hook is a React hook that shares GraphQL data with your UI.\nSwitching over to our `App.js` file, we'll start by replacing our existing file contents with the code snippet below:\n```js title=\"App.js\"\n// Import everything needed to use the`useQuery` hook\nimport { useQuery, gql } from '@apollo/client';\nexport default function App() {\n  return (\n    \nMy first Apollo app \ud83d\ude80\n\n  );\n}\n```\nWe can define the query we want to execute by wrapping it in the `gql` template literal:\n`js title=\"App.js\"\nconst GET_LOCATIONS = gql`\n  query GetLocations {\n    locations {\n      id\n      name\n      description\n      photo\n    }\n  }\n`;`\nNext, let's define a component named `DisplayLocations` that executes our `GET_LOCATIONS` query with the `useQuery` hook:\n```js title=\"App.js\" {2}\nfunction DisplayLocations() {\n  const { loading, error, data } = useQuery(GET_LOCATIONS);\nif (loading) return Loading...;\n  if (error) return Error : {error.message};\nreturn data.locations.map(({ id, name, description, photo }) => (\n    \n{name}\n${photo}} />\n      \nAbout this location:\n{description}\n\n\n  ));\n}\n```\nWhenever this component renders, the `useQuery` hook automatically executes our query and returns a result object containing `loading`, `error`, and `data` properties:\n\nApollo Client automatically tracks a query's loading and error states, which are reflected in the `loading` and `error` properties.\nWhen the result of your query comes back, it's attached to the `data` property.\n\nFinally, we'll add `DisplayLocations` to our existing component tree:\n`jsx title=\"App.js\" {6}\nexport default function App() {\n  return (\n    <div>\n      <h2>My first Apollo app \ud83d\ude80</h2>\n      <br/>\n      <DisplayLocations />\n    </div>\n  );\n}`\nWhen your app reloads, you should briefly see a loading indicator, followed by a list of locations and details about those locations! If you don't, you can compare your code against the completed app on CodeSandbox.\nCongrats, you just made your first component that renders with GraphQL data from Apollo Client! \ud83c\udf89 Now you can try building more components that use `useQuery` and experiment with the concepts you just learned.\nNext steps\nNow that you've learned how to fetch data with Apollo Client, you're ready to dive deeper into creating more complex queries and mutations. After this section, we recommend moving on to:\n\nQueries: Learn how to fetch queries with arguments and dive deeper into configuration options. For a full list of options, check out the API reference for `useQuery`.\nMutations: Learn how to update data with mutations and when you'll need to update the Apollo cache. For a full list of options, check out the API reference for `useMutation`.\n",
    "tag": "apollo-client"
  },
  {
    "title": "Features",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/index.mdx",
    "content": "\ntitle: Introduction to Apollo Client\nimport { Link } from 'gatsby';\nApollo Client is a comprehensive state management library for JavaScript that enables you to manage both local and remote data with GraphQL. Use it to fetch, cache, and modify application data, all while automatically updating your UI.\nApollo Client helps you structure code in an economical, predictable, and declarative way that's consistent with modern development practices. The core `@apollo/client` library provides built-in integration with React, and the larger Apollo community maintains integrations for other popular view layers.\n\n\n    Get started!\n  \n\nFeatures\n\nDeclarative data fetching: Write a query and receive data without manually tracking loading states.\nExcellent developer experience: Enjoy helpful tooling for TypeScript, Chrome / Firefox devtools, and VS Code.\nDesigned for modern React: Take advantage of the latest React features, such as hooks.\nIncrementally adoptable: Drop Apollo into any JavaScript app and incorporate it feature by feature.\nUniversally compatible: Use any build setup and any GraphQL API.\nCommunity driven: Share knowledge with thousands of developers in the GraphQL community.\n\nRecommended docs\nAfter you get started, check out the full Apollo Client documentation in the navigation on the left.\nWe recommend the following articles in particular:\n\nQueries and Mutations. These are the read and write operations of GraphQL.\nCaching overview. Apollo Client's normalized cache enables you to skip network requests entirely when data is already available locally.\nManaging local state. Apollo Client provides APIs for managing both remote and local data, enabling you to consolidate all of your application's state.\nBasic HTTP networking. Learn how to send custom headers and other authentication metadata in your queries.\nTesting React components. Test your GraphQL operations without requiring a connection to a server.\n\nCommunity integrations\nThis documentation set focuses on React, but Apollo Client supports many other libraries and languages:\n\nJavaScript\nAngular\nVue\nSvelte\nSolid.js\nEmber\nMeteor (thanks to DDP-Apollo)\nWeb Components\nApollo Elements\nNative mobile\nNative iOS with Swift\n",
    "tag": "apollo-client"
  },
  {
    "title": "Declarative data fetching",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/why-apollo.mdx",
    "content": "\ntitle: Why Apollo Client?\ndescription: Why choose Apollo Client to manage your data?\n\nApollo Client is a state management library that simplifies managing remote and local data with GraphQL. Apollo Client's intelligent caching and declarative approach to data fetching can help you iterate faster while writing less code. Additionally, if you need custom functionality, you can create your dream client by building extensions on top of Apollo Client.\nLet's jump right into what Apollo Client can offer you! \ud83d\ude80\nDeclarative data fetching\nApollo Client handles the request cycle from start to finish, including tracking loading and error states. There's no middleware or boilerplate code to set up before making your first request, and you don't need to worry about transforming or caching responses. All you have to do is describe the data your component needs and let Apollo Client do the heavy lifting. \ud83d\udcaa\nApollo Client's `useQuery` hook leverages React's Hooks API to bind a query to a component, enabling that component to render a query's results immediately. The `useQuery` hook encapsulates the logic for retrieving your data, tracking loading and error states, and updating your UI. This encapsulation makes integrating query results into your presentational components a breeze!\nLet's see what this looks like in practice with Apollo Client for React:\n```jsx\nfunction ShowDogs() {\n  const { loading, error, data } = useQuery(GET_DOGS);\n  if (error) return ;\n  if (loading) return ;\nreturn ;\n}\n```\nIn the example above, we're using the `useQuery` hook to fetch dogs from our GraphQL server and display them in a list. Once our data comes back, our `<DogList />` component reactively updates to display the new data.\nWhen switching to Apollo Client, you'll find you can remove much of your previous code related to data management. Some teams have reported deleting thousands of lines of code!\nThough you'll find yourself writing less code with Apollo Client, that doesn't mean you have to compromise on features. The useQuery hook supports advanced features like an optimistic UI, refetching, and pagination.\nCombining local & remote data\nThousands of developers have told us that Apollo Client excels at managing remote data, equating to roughly 80% of their data needs. But what about local data (e.g., global flags or device API results), which makes up the other 20% of the pie?\nApollo Client includes local state management features straight out of the box, enabling you to use your Apollo cache as the single source of truth for your application's data.\nBy using Apollo Client's local state functionality, you can include local fields and remotely fetched fields in the same query:\n`js\nconst GET_DOG = gql`\n  query GetDogByBreed($breed: String!) {\n    dog(breed: $breed) {\n      images {\n        url\n        id\n        isLiked @client\n      }\n    }\n  }\n`;`\nIn the above example, we're querying the local-only field `isLiked` while fetching data from our GraphQL server. Your components contain local and remote data; now, your queries can too!\nManaging your data with Apollo Client lets you take advantage of GraphQL as a unified interface for all of your data. Using the Apollo Client Devtools, you can inspect both your local and remote schemas using GraphiQL.\nZero-config caching\nCaching a graph is no easy task, but we've spent years solving this problem. We've found that normalization is the key to maintaining consistent data across multiple components in an application.\nOne of the key features that sets Apollo Client apart from other data management solutions is its local, in-memory, normalized cache.\nThe Apollo Client cache is easy to get started with and configure as you go:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n});\n```\nOnce you've passed your cache to `ApolloClient`, whenever Apollo Client receives query response data, it automatically attempts to identify and store the distinct objects (i.e., those with a `__typename` and an id property) from a query's data into separate entries within its cache.\nLet's look at some practical examples of how this caching mechanism can make your application more efficient.\nThe below query, `GET_ALL_DOGS`, fetches a list of dogs and information about each dog:\n`js\nconst GET_ALL_DOGS = gql`\n  query GetAllDogs {\n    dogs {\n      id\n      breed\n      displayImage\n    }\n  }\n`;`\nThe below mutation, `UPDATE_DISPLAY_IMAGE`, updates a specified dog's `displayImage` and returns the updated dog:\n`js\nconst UPDATE_DISPLAY_IMAGE = gql`\n  mutation UpdateDisplayImage($id: String!, $displayImage: String!) {\n    updateDisplayImage(id: $id, displayImage: $displayImage) {\n      id\n      displayImage\n    }\n  }\n`;`\nWhen we run the `UPDATE_DISPLAY_IMAGE` mutation, we want to ensure that our dog's image is updated everywhere in our application. We also need to ensure we update any previously cached data about that dog.\nOur `UPDATE_DISPLAY_IMAGE` mutation returns the object the mutation modified (i.e., the `id` and `displayImage` of the dog), enabling Apollo Client to automatically overwrite the existing fields of any previously cached object with the same `id`. Tying it all together, if we've already run the `GET_ALL_DOGS` query before Apollo Client runs the `UPDATE_DISPLAY_IMAGE` mutation, it automatically updates the changed dog's `displayImage` in our local cache. \u2728\n\nFor more examples of updating a cache with mutations, see Updating the cache directly.\n\nThe ability to update our cache under the hood can also help in scenarios where we want to avoid refetching information already contained in our cache.\nFor example, let's say we want to navigate to the details page for a particular dog. Here's what the query would look like:\n`js\nconst GET_DOG = gql`\n  query GetDog {\n    dog(id: \"abc\") {\n      id\n      breed\n      displayImage\n    }\n  }\n`;`\nIf we've run the above `GET_ALL_DOGS` query at any point, the data for our `GET_DOG` query might already be in our local cache. We can tell Apollo Client where to check first for any cached `Dog` objects, avoiding refetching information if it already exists in our cache.\nBelow we define a custom FieldPolicy that returns a reference to our previously cached `Dog` object data:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        dog(_, { args, toReference }) {\n          return toReference({\n            __typename: 'Dog',\n            id: args.id,\n          });\n        },\n      },\n    },\n  },\n});\nconst client = new ApolloClient({ cache });\n```\nThe above field policy enables our `GET_DOG` query to read previously stored data straight from our cache instead of sending off an unnecessary query.\n\nLearn more about Caching in Apollo Client.\n\nVibrant ecosystem\nApollo Client is easy to get started with but extensible enough for when you want to build out more advanced features. If you need custom functionality that `@apollo/client` doesn't cover, you can use Apollo Link's architecture to create your dream client by building an extension on top of Apollo Client.\nWe're always impressed by what our contributors have built on top of Apollo Client. Check out some of our community's extensions below:\n\napollo3-cache-persist: Simple persistence for your Apollo cache (@jamesreggio).\napollo-storybook-decorator: Wrap your React Storybook stories with Apollo Client (@abhiaiyer91).\nAppSync by AWS: Amazon's real-time GraphQL client uses Apollo Client under the hood.\napollo-augmented-hooks: Adding additional functionality for Apollo Client's hooks (appmotion).\napollo-cache-policies: Extending Apollo Client's cache with support for advanced cache policies (NerdWalletOSS).\n\nWhen you choose to use Apollo Client to manage your data, you also gain the support of our fantastic community. There are thousands of developers in our community forums for you to share ideas with.\nYou can also read articles on best practices and announcements on the frequently updated Apollo blog.\nCase studies\nCompanies ranging from enterprises to startups trust Apollo Client to power their most critical web and native applications. If you'd like to learn more about how transitioning to GraphQL and Apollo simplified engineers' workflows and improved companies' products, check out these case studies:\n\nThe New York Times: Learn how The New York Times switched from Relay to Apollo & implemented features in their app such as SSR and persisted queries.\nExpress: Easy-to-use pagination with Apollo helped improve the Express eCommerce team's key product pages.\nMajor League Soccer: MLS' switch from Redux to Apollo for state management enabled them to delete nearly all of their Redux code.\nExpo: Developing their React Native app with Apollo enabled the Expo engineers to focus on improving their product instead of writing data fetching logic.\nKLM: Learn how the KLM team scaled their Angular app with GraphQL and Apollo.\n",
    "tag": "apollo-client"
  },
  {
    "title": "What\u2019s new in 3.0",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/migrating/apollo-client-3-migration.mdx",
    "content": "\ntitle: Migrating to Apollo Client 3.0\nThis article walks you through migrating your application to Apollo Client 3.0 from previous versions of Apollo Client.\nTo illustrate the migration process, we've also made this video that uses the example app from our full-stack quickstart as a starting point, updating it from Apollo client 2.6 to 3.0:\n\nWhat\u2019s new in 3.0\n\nApollo Client is now distributed as the `@apollo/client` package (previous versions are distributed as `apollo-client`).\nThe `@apollo/client` package includes both React hooks and GraphQL request handling, which previously required installing separate packages.\nApollo Client\u2019s cache (`InMemoryCache`) is more flexible and performant. It now supports garbage collection, storage of both normalized and non-normalized data, and the customization of cached data with new `TypePolicy` and `FieldPolicy` APIs.\nThe update also includes numerous bug fixes and optimizations, as described in the changelog.\n\nInstallation\n\nWARNING: Apollo Client 3.0 is a major-version release that includes breaking changes. If you are updating an existing application to use Apollo Client 3.0, please see the changelog for details about these changes.\n\nInstall Apollo Client 3.0 with the following command:\n`npm install @apollo/client`\nIf you\u2019re installing Apollo Client 3.0 in a project that already uses an earlier version, follow the instructions in each section of Updating imports that applies to a library you are currently using.\nUpdating imports\nThe `@apollo/client` library includes functionality that previously required installing additional packages. As part of migrating to Apollo Client 3.0, follow the instructions below for each library your application currently uses.\n\nTo simplify the process of converting your `import` declarations from older packages to `@apollo/client`, we provide an automated transform based on jscodeshift. Note that this transform merely moves `import` specifiers between `import` declarations, without checking for proper usage of the imported values. Since the transform cannot take care of everything, pay close attention to any errors produced by TypeScript or your bundling tools, and be sure to verify all changes made by the transform. A more detailed list of caveats can be found in the README.md.\n\n@apollo/react-hoc and @apollo/react-components\nReact Apollo HOC and component functionality is now included in the `@apollo/client` package:\n`js\nimport { Query, Mutation, Subscription } from '@apollo/client/react/components';\nimport { graphql } from '@apollo/client/react/hoc';`\nAs part of migrating, we recommend removing all `@apollo/react-hoc` and `@apollo/react-components` dependencies.\n@apollo/react-hooks\nAll `@apollo/react-hooks` functionality is included in the `@apollo/client` package. For example:\n`js\nimport { ApolloProvider, useQuery, useApolloClient } from '@apollo/client'`\nAs part of migrating, we recommend removing all `@apollo/react-hooks` dependencies.\nBreaking Changes:\n\n`useQuery` no longer maintains the previously fetched results in its `data` result when loading new data. Instead, when new data is being loaded (i.e. `loading` === `true`) the `data` result of `useQuery` is set to `undefined`. Use the `previousData` result as a bridge to the old v2 behavior.\n`refetch` functionality of `useQuery` was broken in v3.5.x until it was fixed in v3.5.8. Previous to this version, if the `skip: true` option was used, `refetch` would always be `undefined`.\n\n@apollo/react-ssr\nReact Apollo\u2019s SSR utilities (like `getDataFromTree`, `getMarkupFromTree`, and `renderToStringWithData`) are included in the `@apollo/client` package. Access them via `@apollo/client/react/ssr`:\n`js\nimport { renderToStringWithData } from '@apollo/client/react/ssr';`\nAs part of migrating, we recommend removing all `@apollo/react-ssr` dependencies.\n@apollo/react-testing\nReact Apollo\u2019s testing utilities (like `MockedProvider`) are included in the `@apollo/client` package. Access them via `@apollo/client/testing`:\n`js\nimport { MockedProvider } from '@apollo/client/testing';`\nAs part of migrating, we recommend removing all `@apollo/react-testing` dependencies.\napollo-boost\nThe Apollo Boost project is now retired, because Apollo Client 3.0 provides a similarly straightforward setup. We recommend removing all `apollo-boost` dependencies and modifying your `ApolloClient` constructor as needed.\napollo-client\nWith Apollo Client 3.0, the `apollo-client` package is retired in favor of `@apollo/client`. As part of migrating, remove all `apollo-client` dependencies.\napollo-link and apollo-link-http\nAll `apollo-link`, `apollo-link-http`, and `apollo-link-http-common` functionality is included in the `@apollo/client` package. For example:\n`js\nimport { ApolloLink, HttpLink, from, split, execute } from '@apollo/client';`\nAs part of migrating, we recommend removing all `apollo-link`, `apollo-link-http`, and `apollo-link-http-common` dependencies.\nIf you want to configure your own link chain, the `ApolloClient` constructor still accepts a link option. Otherwise, the `ApolloClient` constructor now also supports `uri`, `headers`, and `credentials` options. For example:\n`js\nconst client = new ApolloClient({\n  cache,\n  uri: 'http://localhost:4000/graphql',\n  headers: {\n    authorization: localStorage.getItem('token') || '',\n    'client-name': 'Space Explorer [web]',\n    'client-version': '1.0.0',\n  },\n  ...\n});`\nThese options are passed into a new `HttpLink` instance behind the scenes, which `ApolloClient` is then configured to use.\napollo-link-*\nThe separate `apollo-link-*` packages, that were previously maintained in the https://github.com/apollographql/apollo-link repo, have been merged into the Apollo Client project. These links now have their own nested `@apollo/client` entry points. Imports should be updated as follows:\n\n`apollo-link-batch` is now `@apollo/client/link/batch`\n`apollo-link-batch-http` is now `@apollo/client/link/batch-http`\n`apollo-link-context` is now `@apollo/client/link/context`\n`apollo-link-error` is now `@apollo/client/link/error`\n`apollo-link-retry` is now `@apollo/client/link/retry`\n`apollo-link-schema` is now `@apollo/client/link/schema`\n`apollo-link-ws` is now `@apollo/client/link/ws`\n\nIt is important to note that Apollo Client 3 no longer allows `@client` fields to be passed through a Link chain. While Apollo Client 2 made it possible to intercept `@client` fields in Link's like `apollo-link-state` and `apollo-link-schema`, Apollo Client 3 enforces that `@client` fields are local only. This helps ensure Apollo Client's local state story is easier to understand, and prevents unwanted fields from accidentally ending up in network requests (PR #5982).\ngraphql-anywhere\nThe `graphql-anywhere` package\u2019s functionality is no longer included with Apollo Client. You can continue to use the `graphql-anywhere` package, but Apollo no longer uses it and will not actively support it moving forward.\ngraphql-tag\nThe `@apollo/client` package includes `graphql-tag` as a dependency and re-exports `gql`. To simplify your dependencies, we recommend importing gql from `@apollo/client` and removing all `graphql-tag` dependencies.\nreact-apollo\n`react-apollo` v3 is an umbrella package that re-exports the following packages:\n\n`@apollo/react-common`\n`@apollo/react-hooks`\n`@apollo/react-components`\n`@apollo/react-hoc`\n`@apollo/react-ssr`\n`@apollo/react-testing`\n\nThe `react-apollo` package has been deprecated, and the functionality offered by each of the above packages can now be accessed from `@apollo/client` directly:\n\n`@apollo/react-hooks` -> now available directly from `@apollo/client`\n`@apollo/react-components` -> now available from `@apollo/client/react/components`\n`@apollo/react-hoc` -> now available from `@apollo/client/react/hoc`\n`@apollo/react-ssr` -> now available from `@apollo/client/react/ssr`\n`@apollo/react-testing` -> now available from `@apollo/client/testing`\n\nUsing individual components of Apollo Client 3\nApollo Client 3.0 provides multiple entry points for you to import from. If you only use a particular part of Apollo Client\u2019s functionality, you can import that functionality from its corresponding entry point. By doing so, modern bundlers can omit the remainder of the `@apollo/client` package from your bundle and reduce its size considerably.\nUsing Apollo Client without React\nApollo Client 3.0 includes built-in support for React hooks, but it absolutely still supports non-React view layers. To use Apollo Client 3.0 with Vue, Angular, or another view layer of your choosing, import `ApolloClient` from the `@apollo/client/core` entry point:\n`js\nimport { ApolloClient } from '@apollo/client/core';`\nUsing apollo-utilities without the rest of Apollo Client\nThe `apollo-utilities` package has been removed, but you can access the utilities themselves from the `@apollo/client/utilities` entry point:\n`js\nimport { isReference, isInlineFragment } from '@apollo/client/utilities';`\nUsing apollo-cache and/or apollo-cache-inmemory without the rest of Apollo Client\nThe `apollo-cache` and `apollo-cache-inmemory` packages have been removed, but if you're interested in using Apollo Client's cache by itself, you can access their contents with the `@apollo/client/cache` entry point:\n`js\nimport { ApolloCache, InMemoryCache } from '@apollo/client/cache';`\nCache improvements\nApollo Client 3.0 introduces powerful improvements to its caching system. Most of these improvements are backward compatible, so most applications will continue to work without any changes to caching logic. However, we highly recommend learning more about the capabilities of the Apollo Client 3.0 cache.\n\nConfiguring the cache\nInteracting with cached data\n\nBreaking cache changes\nThe following cache changes are not backward compatible. Take them into consideration before you upgrade to Apollo Client 3.0.\n\nBy default, the `InMemoryCache` no longer merges the fields of two objects unless those objects have the same unique identifier and that identifier is present in both objects. Additionally, the values of fields with the same name are no longer merged recursively by default. You can define a custom `merge`  function for a field to handle both of these changes for a particular field. You can read more about these changes in Merging non-normalized objects. (PR #5603).\nAll cache results are now frozen/immutable, as promised in the Apollo Client 2.6 blog post (PR #5153).\n`FragmentMatcher`, `HeuristicFragmentMatcher`, and `IntrospectionFragmentMatcher` have all been removed. We recommend using the `InMemoryCache`\u2019s `possibleTypes` option instead. For more information, see Defining possibleTypes manually (PR #5073).\nThe internal representation of normalized data in the cache has changed. If you\u2019re using `apollo-cache-inmemory`\u2019s public API, then these changes shouldn\u2019t impact you. If you are manipulating cached data directly instead, review PR #5146 for details.\n`client|cache.writeData` have been fully removed. `client|cache.writeQuery`, `client|cache.writeFragment`, and/or `cache.modify` can be used to update the cache. For example:\n\n`js\n    client.writeData({\n      data: {\n        cartItems: []\n      }\n    });`\ncan be converted to:\n`js\n    client.writeQuery({\n      query: gql`\n        query GetCartItems {\n          cartItems\n        }\n      `,\n      data: {\n        cartItems: []\n      }\n    });`",
    "tag": "apollo-client"
  },
  {
    "title": "Core packages",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/migrating/hooks-migration.md",
    "content": "\ntitle: Hooks migration guide\ndescription: How to integrate the new hooks API into your existing Apollo app\n\nThe new hooks API for Apollo Client is a simpler way to fetch data in your React app without the boilerplate of render prop components and higher-order components (HOC). We recommend using hooks for all new Apollo code going forward.\nCore packages\nReact hooks functionality is included in the Apollo Client bundle, whereas the older HOC / render prop component approaches are not. The React team has made it clear that hooks are the future, so we've decided to keep the older approaches available through separate packages.\n\n@apollo/client - Apollo Client core with React hooks integration\n@apollo/react-components - React Apollo render prop components\n@apollo/react-hoc - React Apollo HOC (`grapqhl`) API\n\nInstallation/upgrade scenarios\nI just want to use Apollo hooks:\n`npm install @apollo/client`\n(remove the `react-apollo` and `@apollo/react-hooks` packages if they were previously installed)\nI just want to use Apollo render prop components:\n`npm install @apollo/client @apollo/react-components`\n(remove the `react-apollo` package if it was previously installed)\nI just want to use Apollo HOCs:\n`npm install @apollo/client @apollo/react-hoc`\n(remove the `react-apollo` package if it was previously installed)\nI want to use all 3 React paradigms in my application:\n`npm install @apollo/client @apollo/react-components @apollo/react-hoc`\n(remove the `react-apollo` and `@apollo/react-hooks` packages if they were previously installed)\nServer-side rendering\nThe `getDataFromTree`, `getMarkupFromTree`, and `renderToStringWithData` React SSR functions are bundled with Apollo Client 3. If you want to use these functions, you'll need to import them from `@apollo/client/react/ssr`:\n`import { getDataFromTree } from \"@apollo/client/react/ssr\";`\nTesting\nReact testing utilities are now available through the Apollo Client project, but they aren't included in the default bundle. To access the React testing utilities, you can use the `@apollo/client/testing` bundle like:\n```\nimport { MockedProvider } from '@apollo/client/testing';",
    "tag": "apollo-client"
  },
  {
    "title": "The Apollo Client approach",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/pagination/overview.mdx",
    "content": "\ntitle: Pagination in Apollo Client\ndescription: Overview\n\nGraphQL enables you to fetch exactly the fields you need from your graph, with no unnecessary overhead. This helps keep network responses small and fast.\nHowever, GraphQL doesn't automatically guarantee small responses. This is especially apparent when you query a field that contains a list. A list can contain infinitely many elements, which can result in an enormous response from a seemingly small query like this one:\n`graphql\nquery GetBookTitles {\n  books {\n    title\n  }\n}`\nIf your graph includes thousands or millions of books, this query probably returns much more data than you need. To resolve this issue, GraphQL servers can paginate their list fields.\nWhen a client queries a paginated list field, the server returns only a portion (or \"page\") of the list's elements. The client's query includes arguments that indicate which page the server should return:\n`mermaid\nsequenceDiagram;\n  Client app->>GraphQL server: query GetBookTitles(offset=0 limit=20)\n  GraphQL server->>Client app: Returns the first 20 list elements\n  Client app->>GraphQL server: query GetBookTitles(offset=20 limit=10)\n  GraphQL server->>Client app: Returns the next 10 list elements`\nThis diagram shows offset-based pagination, in which a client requests a page based on an absolute index in the list (`offset`) and the maximum number of elements to return (`limit`).\nThere are many different pagination strategies a server can use for a particular list field: offset-based, cursor-based, page-number-based, forwards, backwards, and so on. Each strategy requires a slightly different set of arguments. Because these strategies can each be useful in different situations, neither Apollo nor the GraphQL specification prescribes a canonical pagination strategy.\nThe Apollo Client approach\nInstead of recommending a particular pagination strategy, Apollo Client provides flexible cache APIs that help you merge results from a paginated list field, regardless of which pagination strategy your GraphQL server uses. And because you can represent these custom pagination strategies with stateless functions, you can reuse a single function for every list field that uses the same strategy.",
    "tag": "apollo-client"
  },
  {
    "title": "The `offsetLimitPagination` helper",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/pagination/offset-based.mdx",
    "content": "\ntitle: Offset-based pagination\n\nWe recommend reading Core pagination API before learning about considerations specific to offset-based pagination.\n\nWith offset-based pagination, a list field accepts an `offset` argument that indicates where in the list the server should start when returning items for a particular query. The field usually also accepts a `limit` argument that indicates the maximum number of items to return:\n```graphql {2}\ntype Query {\n  feed(offset: Int, limit: Int): [FeedItem!]\n}\ntype FeedItem {\n  id: ID!\n  message: String!\n}\n```\nThis pagination strategy works well for immutable lists, or for lists where each item's index never changes. In other cases, you should avoid it in favor of cursor-based pagination, because moving or removing items can shift offsets. This causes items to be skipped or duplicated if changes occur between paginated queries.\nAlthough it has limitations, offset-based pagination is a common pattern in many applications, in part because it's relatively straightforward to implement.\nThe `offsetLimitPagination` helper\nApollo Client provides an `offsetLimitPagination` helper function that you can use to generate a field policy for every relevant list field.\nThis example uses `offsetLimitPagination` to generate a field policy for `Query.feed`:\n```js {2,8} title=\"index.js\"\nimport { InMemoryCache } from \"@apollo/client\";\nimport { offsetLimitPagination } from \"@apollo/client/utilities\";\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: offsetLimitPagination()\n      },\n    },\n  },\n});\n```\nThis defines a merge function for the field that handles merging paginated results in the cache for you (see the source).\nUsing with `fetchMore`\nIf you use `offsetLimitPagination` to set your feed policy as shown above, then you can use `fetchMore` with `useQuery` like so:\n```jsx {17-21} title=\"FeedData.jsx\"\nconst FeedData() {\n  const { loading, data, fetchMore } = useQuery(FEED_QUERY, {\n    variables: {\n      offset: 0,\n      limit: 10\n    },\n  });\n// If you want your component to rerender with loading:true whenever\n  // fetchMore is called, add notifyOnNetworkStatusChange:true to the\n  // options you pass to useQuery above.\n  if (loading) return ;\nreturn (\n     fetchMore({\n        variables: {\n          offset: data.feed.length\n        },\n      })}\n    />\n  );\n}\n```\nBy default, `fetchMore` uses the original query and `variables`, so we only need to pass the variable that's changing: `offset`. When new data is returned from the server, it's automatically merged with any existing `Query.feed` data in the cache. This causes `useQuery` to rerender with the expanded list of data.\nIn this example, the `Feed` component receives the entire cached list (`data.feed`) every time it renders, which includes data from all pages received so far. This is a non-paginated read function.\nUsing with a paginated `read` function\nIn the example above, the GraphQL server returns individual pages of results, but each query then returns all cached results received so far. To limit each query's result to only the items you requested, you can include a paginated read function in your field policy.\nBecause the `offsetLimitPagination` helper is currently defining your field policy, you combine your `read` function with the helper's result, like so:\n```js {8-13} title=\"index.js\"\nimport { InMemoryCache } from \"@apollo/client\";\nimport { offsetLimitPagination } from \"@apollo/client/utilities\";\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          ...offsetLimitPagination(),\n          read(existing, { args }) {\n            // Implement here\n          }\n        }\n      },\n    },\n  },\n});\n```\n\nFor example implementations, see Paginated read functions.\n\nIf you use a paginated `read` function, you probably need to  update your `offset` and `limit` variables as required by your use case after you call `fetchMore`. Otherwise, you'll continue rendering only the first page of results.\nFor example, to display all the data received so far, you could modify the previous example as follows:\n```jsx\nconst FeedData = () => {\n  const [limit, setLimit] = useState(10);\n  const { loading, data, fetchMore } = useQuery(FEED_QUERY, {\n    variables: {\n      offset: 0,\n      limit,\n    },\n  });\nif (loading) return ;\nreturn (\n     {\n        const currentLength = data.feed.length;\n        fetchMore({\n          variables: {\n            offset: currentLength,\n            limit: 10,\n          },\n        }).then(fetchMoreResult => {\n          // Update variables.limit for the original query to include\n          // the newly added feed items.\n          setLimit(currentLength + fetchMoreResult.data.feed.length);\n        });\n      }}\n    />\n  );\n}\n```\nThis code uses a React `useState` Hook to store the current `limit` value, which it updates by calling `setLimit` in a callback attached to the `Promise` returned by `fetchMore`.\nYou could store `offset` in a React `useState` Hook as well, if you need the `offset` to change. Exactly when and how these `variables` change is up to your component, and may not always be the result of calling `fetchMore`, so it makes sense to use React component state to store these variable values.\n\nIf you are not using React and `useQuery`, the `ObservableQuery` object returned by `client.watchQuery` has a method called `setVariables` that you can call to update the original variables.\n\nBecause `fetchMore` requires some extra work to update the original variables if you're using a `read` function that is sensitive to those variables (the second kind of `read` function), it's fair to say `fetchMore` encourages the first kind of `read` function, which simply returns all available data.\nHowever, now that you understand your options, there's nothing wrong with moving read-time pagination logic out of your application code and into your field `read` functions. Both kinds of `read` functions have their uses, and both can be made to work with `fetchMore`.\nSetting `keyArgs` with `offsetLimitPagination`\nIf a paginated field accepts arguments besides `offset` and `limit`, you might need to specify the key arguments that indicate whether two result sets belong to the same list or different lists.\nTo set `keyArgs` for the field policy generated by `offsetLimitPagination`, provide an array of argument names to the function as a parameter:\n`js\nfields {\n  // Results belong to the same list only if both the type\n  // and userId arguments match exactly\n  feed: offsetLimitPagination([\"type\", \"userId\"])\n}`",
    "tag": "apollo-client"
  },
  {
    "title": "Using list element IDs as cursors",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/pagination/cursor-based.mdx",
    "content": "\ntitle: Cursor-based pagination\n\nWe recommend reading Core pagination API before learning about considerations specific to cursor-based pagination.\n\nUsing list element IDs as cursors\nSince numeric offsets within paginated lists can be unreliable, a common improvement is to identify the beginning of a page using some unique identifier that belongs to each element of the list.\nIf the list represents a set of elements without duplicates, this identifier could simply be the unique ID of each object, allowing additional pages to be requested using the ID of the last object in the list, together with some `limit` argument. With this approach, the requested `cursor` ID should not appear in the new page, since it identifies the item just before the beginning of the page.\nSince the elements of the list could be normalized `Reference` objects, you will probably want to use the `options.readField` helper function to read the `id` field in your `merge` and/or `read` functions:\n```js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          keyArgs: [\"type\"],\n\n\n```      merge(existing, incoming, {\n        args: { cursor },\n        readField,\n      }) {\n        const merged = existing ? existing.slice(0) : [];\n        let offset = offsetFromCursor(merged, cursor, readField);\n        // If we couldn't find the cursor, default to appending to\n        // the end of the list, so we don't lose any data.\n        if (offset < 0) offset = merged.length;\n        // Now that we have a reliable offset, the rest of this logic\n        // is the same as in offsetLimitPagination.\n        for (let i = 0; i < incoming.length; ++i) {\n          merged[offset + i] = incoming[i];\n        }\n        return merged;\n      },\n\n      // If you always want to return the whole list, you can omit\n      // this read function.\n      read(existing, {\n        args: { cursor, limit = existing.length },\n        readField,\n      }) {\n        if (existing) {\n          let offset = offsetFromCursor(existing, cursor, readField);\n          // If we couldn't find the cursor, default to reading the\n          // entire list.\n          if (offset < 0) offset = 0;\n          return existing.slice(offset, offset + limit);\n        }\n      },\n    },\n  },\n},\n```\n\n\n},\n});\nfunction offsetFromCursor(items, cursor, readField) {\n  // Search from the back of the list because the cursor we're\n  // looking for is typically the ID of the last item.\n  for (let i = items.length - 1; i >= 0; --i) {\n    const item = items[i];\n    // Using readField works for both non-normalized objects\n    // (returning item.id) and normalized references (returning\n    // the id field from the referenced entity object), so it's\n    // a good idea to use readField when you're not sure what\n    // kind of elements you're dealing with.\n    if (readField(\"id\", item) === cursor) {\n      // Add one because the cursor identifies the item just\n      // before the first item in the page we care about.\n      return i + 1;\n    }\n  }\n  // Report that the cursor could not be found.\n  return -1;\n}\n```\nSince items can be removed from, added to, or moved around within the list without altering their `id` fields, this pagination strategy tends to be more resilient to list mutations than the `offset`-based strategy we saw above.\nHowever, this strategy works best when your `merge` function always appends new pages to the existing data, since it doesn't take any precautions to avoid overwriting elements if the `cursor` falls somewhere in the middle of the existing data.\nUsing a map to store unique items\nIf your paginated field logically represents a set of unique items, you can store it internally using a more convenient data structure than an array.\nIn fact, your `merge` function can return internal data in any format you like, as long as your `read` function cooperates by turning that internal representation back into a list:\n```js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          keyArgs: [\"type\"],\n\n\n```      // While args.cursor may still be important for requesting\n      // a given page, it no longer has any role to play in the\n      // merge function.\n      merge(existing, incoming, { readField }) {\n        const merged = { ...existing };\n        incoming.forEach(item => {\n          merged[readField(\"id\", item)] = item;\n        });\n        return merged;\n      },\n\n      // Return all items stored so far, to avoid ambiguities\n      // about the order of the items.\n      read(existing) {\n        return existing && Object.values(existing);\n      },\n    },\n  },\n},\n```\n\n\n},\n});\n```\nWith this internal representation, you no longer have to worry about incoming items overwriting unrelated existing items, because an assignment to the map can only replace an item with the same `id` field.\nHowever, this approach leaves an important question unanswered: what `cursor` should we use when requesting the next page? Thanks to the predictable ordering of JavaScript object keys by insertion order, you should be able to use the `id` field of the last element returned by the `read` function as the `cursor` for the next request\u2014though you're not alone if relying on this behavior makes you nervous. In the next section we'll see a slightly different approach that makes the next `cursor` more explicit.\nKeeping cursors separate from items\nPagination cursors are often derived from ID fields of list items, but not always. In cases where the list could have duplicates, or is sorted or filtered according to some criteria, the cursor may need to encode not just a position within the list but also the sorting/filtering logic that produced the list. In such situations, since the cursor does not logically belong to the elements of the list, the cursor may be returned separately from the list:\n```jsx\nconst MORE_COMMENTS_QUERY = gql`\n  query MoreComments($cursor: String, $limit: Int!) {\n    moreComments(cursor: $cursor, limit: $limit) {\n      cursor\n      comments {\n        id\n        author\n        text\n      }\n    }\n  }\n`;\nfunction CommentsWithData() {\n  const {\n    data,\n    loading,\n    fetchMore,\n  } = useQuery(MORE_COMMENTS_QUERY, {\n    variables: { limit: 10 },\n  });\nif (loading) return ;\nreturn (\n     fetchMore({\n        variables: {\n          cursor: data.moreComments.cursor,\n        },\n      })}\n    />\n  );\n}\n```\nTo demonstrate the flexibility of the field policy system, here's an implementation of the `Query.moreComments` field that uses a map internally, but returns an array of unique `comments`:\n```js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        moreComments: {\n          keyArgs: false,\n          merge(existing, incoming, { readField }) {\n            const comments = existing ? { ...existing.comments } : {};\n            incoming.comments.forEach(comment => {\n              comments[readField(\"id\", comment)] = comment;\n            });\n            return {\n              cursor: incoming.cursor,\n              comments,\n            };\n          },\n\n\n```      read(existing) {\n        if (existing) {\n          return {\n            cursor: existing.cursor,\n            comments: Object.values(existing.comments),\n          };\n        }\n      },\n    },\n  },\n},\n```\n\n\n},\n});\n```\nNow there's less ambiguity about where the next `cursor` comes from, because it is explicitly stored and returned as part of the query.\nRelay-style cursor pagination\nThe `InMemoryCache` field policy API allows for any conceivable style of pagination, even though some of the simpler approaches have known drawbacks.\nIf you were designing a GraphQL client without the flexibility that `read` and `merge` functions provide, you would most likely attempt to standardize around a one-size-fits-all style of pagination that you felt was sophisticated enough to support most use cases. That's the path Relay, another popular GraphQL client, has chosen with their Cursor Connections Specification. As a consequence, a number of public GraphQL APIs have adopted the Relay connection specification to be maximally compatible with Relay clients.\nUsing Relay-style connections is similar to cursor-based pagination, but differs in the format of the query response, which affects the way cursors are managed. In addition to `connection.edges`, which is a list of `{ cursor, node }` objects, where each `edge.node` is a list item, Relay provides a `connection.pageInfo` object which gives the cursors of the first and last items in `connection.edges` as `connection.pageInfo.startCursor` and `connection.pageInfo.endCursor`, respectively. The `pageInfo` object also contains the boolean properties `hasPreviousPage` and `hasNextPage`, which can be used to determine if there are more results available (both forwards and backwards):\n```jsx\nconst COMMENTS_QUERY = gql`\n  query Comments($cursor: String) {\n    comments(first: 10, after: $cursor) {\n      edges {\n        node {\n          author\n          text\n        }\n      }\n      pageInfo {\n        endCursor\n        hasNextPage\n      }\n    }\n  }\n`;\nfunction CommentsWithData() {\n  const { data, loading, fetchMore } = useQuery(COMMENTS_QUERY);\nif (loading) return ;\nconst nodes = data.comments.edges.map((edge) => edge.node);\n  const pageInfo = data.comments.pageInfo;\nreturn (\n     {\n        if (pageInfo.hasNextPage) {\n          fetchMore({\n            variables: {\n              cursor: pageInfo.endCursor,\n            },\n          });\n        }\n      }}\n    />\n  );\n}\n```\nFortunately, Relay-style pagination can be implemented in Apollo Client using `merge` and `read` functions, which means all the thorny details of connections and `edges` and `pageInfo` can be abstracted away, into a single, reusable helper function:\n```js\nimport { relayStylePagination } from \"@apollo/client/utilities\";\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        comments: relayStylePagination(),\n      },\n    },\n  },\n});\n```\nWhenever you need to consume a Relay pagination API using Apollo Client, `relayStylePagination` is a great tool to try first, even if you end up copy/pasting its code and making changes to suit your specific needs.",
    "tag": "apollo-client"
  },
  {
    "title": "The `fetchMore` function",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/pagination/core-api.mdx",
    "content": "\ntitle: Core pagination API\ndescription: Fetching and caching paginated results\n\nRegardless of which pagination strategy your GraphQL server uses for a particular list field, your Apollo Client app needs to do the following to query that field effectively:\n\nCall the fetchMore function to fetch the next page of results when needed\nMerge individual pages of results into a single list in the Apollo Client cache\n\nThis article describes these core requirements for paginated fields.\nThe `fetchMore` function\nPagination always involves sending followup queries to your GraphQL server to obtain additional pages of results. In Apollo Client, the recommended way to send these followup queries is with the fetchMore function. This function is a member of the `ObservableQuery` object returned by `client.watchQuery`, and it's also provided by the `useQuery` hook:\n```jsx {11} title=\"FeedWithData.jsx\"\nconst FEED_QUERY = gql`\n  query Feed($offset: Int, $limit: Int) {\n    feed(offset: $offset, limit: $limit) {\n      id\n      # ...\n    }\n  }\n`;\nconst FeedWithData() {\n  const { loading, data, fetchMore } = useQuery(FEED_QUERY, {\n    variables: {\n      offset: 0,\n      limit: 10\n    },\n  });\n  // ...continues below...\n}\n```\nYou usually call `fetchMore` in response to a user action, such as clicking a button or scrolling to the current \"bottom\" of an infinite-scroll feed.\nBy default, `fetchMore` executes a query with the exact same shape and variables as your original query. You can pass new values for the query's `variables` (such as providing a new `offset`) like so:\n```jsx {12-16} title=\"FeedWithData.jsx\"\nconst FeedWithData() {\n// ...continuing from above...\n// If you want your component to rerender with loading:true whenever\n// fetchMore is called, add `notifyOnNetworkStatusChange:true` to the\n// options you pass to useQuery.\nif (loading) return 'Loading...';\nreturn (\n     fetchMore({\n        variables: {\n          offset: data.feed.length\n        },\n      })}\n    />\n  );\n}\n```\nHere, we set the `offset` variable to `feed.length` to fetch items after the last item in our cached list. The `variables` we provide here are merged with the `variables` provided for the original query, which means that variables omitted here (such as `limit`) retain their original value (`10`) in the followup query.\nIn addition to `variables`, you can optionally provide an entirely different shape of `query` to execute. This can be useful when `fetchMore` needs to fetch only a single paginated field, but the original query contained unrelated fields.\n\nAdditional examples of using `fetchMore` are provided in the detailed documentation for offset-based pagination and cursor-based pagination.\n\nOur `fetchMore` function is ready, but we're not finished! The cache doesn't know yet that it should merge our followup query's result with the original query's result. Instead, it will store the two results as two completely separate lists. To resolve this, let's move on to Merging paginated results.\nMerging paginated results\n\nThe examples in this section use offset-based pagination, but this article applies to all pagination strategies.\n\nAs mentioned above, a fetchMore followup query doesn't automatically merge its result with the original query's cached result. To achieve this behavior, we need to define a field policy for our paginated field.\nWhy do I need a field policy?\nLet's say we have a field in our GraphQL schema that takes an argument:\n`graphql {2}\ntype Query {\n  user(id: ID!): User\n}`\nNow, let's say we execute the following query two times and provide different values for the `$id` variable each time:\n`graphql\nquery GetUser($id: ID!) {\n  user(id: $id) {\n    id\n    name\n  }\n}`\nOur two queries return two entirely different `User` objects. Helpfully, the Apollo Client cache automatically stores these two objects separately, because it sees that different values were provided for at least one field argument (`id`). Otherwise, the cache might overwrite the first `User` object with the second `User` object, and we want to cache both!\nNow, let's say we execute this query two times, with different values for the `$offset` variable:\n`graphql\nquery Feed($offset: Int, $limit: Int) {\n  feed(offset: $offset, limit: $limit) {\n    id\n    # ...\n  }\n}`\nIn this case, we're querying a paginated list field twice to obtain two different pages of results, and we want those two pages to be merged. But the cache doesn't know that! It sees no difference between this scenario and the `User` scenario above, so it stores the results as two completely separate lists.\nWith field policies, we can modify the cache's behavior for individual fields that require it. For example, we can tell the cache not to store separate results for the `feed` field based on the values of `offset` and `limit`. Let's look at how.\nDefining a field policy\nA field policy specifies how a particular field in your `InMemoryCache` is read and written. You can define a field policy to merge the results of paginated queries into a single list.\nExample\nHere's the server-side schema for our message feed application that uses offset-based pagination:\n```graphql {2}\ntype Query {\n  feed(offset: Int, limit: Int): [FeedItem!]\n}\ntype FeedItem {\n  id: String!\n  message: String!\n}\n```\nIn our client, we want to define a field policy for `Query.feed` so that all returned pages of the list are merged into a single list in our cache.\nWe define our field policy within the `typePolicies` option we provide the `InMemoryCache` constructor:\n```js {5-15}\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          // Don't cache separate results based on\n          // any of this field's arguments.\n          keyArgs: false,\n\n\n```      // Concatenate the incoming list items with\n      // the existing list items.\n      merge(existing = [], incoming) {\n        return [...existing, ...incoming];\n      },\n    }\n  }\n}\n```\n\n\n}\n})\n```\nThis field policy specifies the field's `keyArgs`, along with a `merge` function. Both of these configurations are necessary for handling pagination:\n\n`keyArgs` specifies which of the field's arguments cause the cache to store a separate value for each unique combination of those arguments.\nIn our case, the cache shouldn't store a separate result based on any argument value (`offset` or `limit`). So, we disable this behavior entirely by passing `false`. An empty array (`keyArgs: []`) also works, but `keyArgs: false` is more expressive, and it results in a cleaner field key within the cache (`feed` in this case).\nIf a particular argument's value could cause items from an entirely different list to be returned in the field, that argument should be included in `keyArgs`.\nFor more information, see Specifying key arguments and The keyArgs API.\nA `merge` function tells the Apollo Client cache how to combine `incoming` data with `existing` cached data for a particular field. Without this function, incoming field values overwrite existing field values by default.\nFor more information, see The merge function.\n\nWith this field policy in place, the cache automatically merges the results of all queries that use the following structure, regardless of argument values:\n`ts\n// Client-side query definition\nconst FEED_QUERY = gql`\n  query Feed($offset: Int, $limit: Int) {\n    feed(offset: $offset, limit: $limit) {\n      id\n      message\n    }\n  }\n`;`\nImproving the `merge` function\nIn the example above, our `merge` function is a single line:\n`js\nmerge(existing = [], incoming) {\n  return [...existing, ...incoming];\n}`\nThis function makes risky assumptions about the order in which the client requests pages, because it ignores the values of `offset` and `limit`. A more robust `merge` function can use `options.args` to decide where to put `incoming` data relative to `existing` data, like so:\n`js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          keyArgs: [],\n          merge(existing, incoming, { args: { offset = 0 }}) {\n            // Slicing is necessary because the existing data is\n            // immutable, and frozen in development.\n            const merged = existing ? existing.slice(0) : [];\n            for (let i = 0; i < incoming.length; ++i) {\n              merged[offset + i] = incoming[i];\n            }\n            return merged;\n          },\n        },\n      },\n    },\n  },\n});`\nThis logic handles sequential page writes the same way the single-line strategy does, but it can also tolerate repeated, overlapping, or out-of-order writes, without duplicating any list items.\n`read` functions for paginated fields\nAs shown above, a `merge` function helps you combine paginated query results from your GraphQL server into a single list in your client cache. But what if you also want to configure how that locally cached list is read? For that, you can define a `read` function.\nYou define a `read` function for a field within its field policy, alongside the `merge` function and `keyArgs`. If you define a `read` function for a field, the cache calls that function whenever you query the field, passing the field's existing cached value (if any) as the first argument. In the query response, the field is populated with the `read` function's return value, instead of the existing cached value.\n\nIf a field policy includes both a `merge` function and a `read` function, the default value of `keyArgs` becomes `false` (i.e., no arguments are key arguments). If either function isn't defined, all of the field's arguments are considered key arguments by default. In either case, you can define `keyArgs` yourself to override the default behavior.\n\nA `read` function for a paginated field typically uses one of the following approaches:\n\nRe-pagination, in which the cached list is split back into pages, based on field arguments\nNo pagination, in which the cached list is always returned in full\n\nAlthough the \"right\" approach varies from field to field, a non-paginated read function often works best for infinitely scrolling feeds, because it gives your code full control over which elements to display at a given time, without requiring any additional cache reads.\nPaginated `read` functions\nThe `read` function for a list field can perform client-side re-pagination for that list. It can even transform a page before returning it, such as by sorting or filtering its elements.\nThis capability goes beyond returning the same pages that you fetched from your server, because a `read` function for `offset`/`limit` pagination could read from any available `offset`, with any desired `limit`:\n```js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          read(existing, { args: { offset, limit }}) {\n            // A read function should always return undefined if existing is\n            // undefined. Returning undefined signals that the field is\n            // missing from the cache, which instructs Apollo Client to\n            // fetch its value from your GraphQL server.\n            return existing && existing.slice(offset, offset + limit);\n          },\n\n\n```      // The keyArgs list and merge function are the same as above.\n      keyArgs: [],\n      merge(existing, incoming, { args: { offset = 0 }}) {\n        const merged = existing ? existing.slice(0) : [];\n        for (let i = 0; i < incoming.length; ++i) {\n          merged[offset + i] = incoming[i];\n        }\n        return merged;\n      },\n    },\n  },\n},\n```\n\n\n},\n});\n```\nDepending on the assumptions you feel comfortable making, you might want to make this code more defensive. For example, you can provide default values for `offset` and `limit`, in case someone fetches `Query.feed` without providing arguments:\n`js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          read(existing, {\n            args: {\n              // Default to returning the entire cached list,\n              // if offset and limit are not provided.\n              offset = 0,\n              limit = existing?.length,\n            } = {},\n          }) {\n            return existing && existing.slice(offset, offset + limit);\n          },\n          // ... keyArgs, merge ...\n        },\n      },\n    },\n  },\n});`\nThis style of `read` function takes responsibility for re-paginating your data based on field arguments, essentially inverting the behavior of your `merge` function. This way, your application can query different pages using different arguments.\nNon-paginated `read` functions\nThe `read` function for a paginated field can choose to ignore arguments like `offset` and `limit`, and always return the entire list as it exists in the cache. In this case, your application code takes responsibility for slicing the list into pages depending on your needs.\nIf you adopt this approach, you might not need to define a `read` function at all, because the cached list can be returned without any processing. That's why the offsetLimitPagination helper function is implemented without a `read` function.",
    "tag": "apollo-client"
  },
  {
    "title": "First query",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/pagination/key-args.mdx",
    "content": "\ntitle: Key arguments in Apollo Client\ndescription: Using the keyArgs API\n\n\nWe recommend reading Core pagination API before learning about considerations specific to `keyArgs` configuration.\n\nThe Apollo Client cache can store multiple entries for a single schema field. By default, each entry corresponds to a different set of values for the field's arguments.\nFor example, consider this `Query.user` field:\n`graphql {3}\ntype Query {\n  # Returns whichever User object corresponds to `id`\n  user(id: ID!): User\n}`\nIf we query for `User`s with `id`s `1` and `2`, the Apollo Client cache stores entries for both like so:\n`js {3,6} title=\"Cache\"\n{\n  'ROOT_QUERY': {\n    'user({\"id\":\"1\"})': {\n      '__ref': 'User:1'\n    },\n    'user({\"id\":\"2\"})': {\n      '__ref': 'User:2'\n    }\n  }\n}`\nAs shown above, each entry's storage key includes the corresponding argument values. This means that if any of a field's arguments differ between queries, the storage keys also differ, and those queries result in distinct cache entries.\n\nIf a field has no arguments, its storage key is just its name.\n\nThis default behavior is for safety: the cache doesn't know whether it can merge the values returned for different argument combinations without invalidating data. In the example above, the cache definitely shouldn't merge the results of querying for `User`s with `id`s `1` and `2`.\nPagination issues\nCertain arguments shouldn't cause the Apollo Client cache to store a separate entry. This is almost always the case for arguments related to paginated lists.\nConsider this `Query.feed` field:\n`graphql {2}\ntype Query {\n  feed(offset: Int, limit: Int, category: Category): [FeedItem!]\n}`\nThe `offset` and `limit` arguments enable a client to specify which \"page\" of the feed it wants to fetch. In an app with an infinitely scrolling feed, the client might initially fetch the first ten items, then fetch the next ten:\n```graphql\nFirst query\nquery GetFeedItems {\n  feed(offset: 0, limit: 10, category: \"SPORTS\")\n}\nSecond query\nquery GetFeedItems {\n  feed(offset: 10, limit: 10, category: \"SPORTS\")\n}\n```\nBut because their argument values differ, these two lists of ten items are cached separately by default. This means that when the second query completes, the returned items aren't appended to the original list in the feed!\n`js {3-4,10-11} title=\"Cache\"\n{\n  'ROOT_QUERY': {\n    // First query\n    'feed({\"offset\":\"0\",\"limit\":\"10\",\"category\":\"SPORTS\"})': [\n      {\n        '__ref': 'FeedItem:1'\n      },\n      // ...additional items...\n    ],\n    // Second query\n    'feed({\"offset\":\"10\",\"limit\":\"10\",\"category\":\"SPORTS\"})': [\n      {\n        '__ref': 'FeedItem:11'\n      },\n      // ...additional items...\n    ]\n  }\n}`\nIn this case, we don't want `offset` or `limit` to be included in a cache entry's storage key. Instead, we want the cache to merge the results of the two above queries into a single cache entry that includes the items from both lists.\nTo help handle this case, we can set key arguments for the field.\nSetting `keyArgs`\nA key argument is an argument for a GraphQL field that's included in cache storage keys for that field. By default, all GraphQL arguments are key arguments, as shown in our feed example:\n`js {3-4,10-11} title=\"Cache\"\n{\n  'ROOT_QUERY': {\n    // First query\n    'feed({\"offset\":\"0\",\"limit\":\"10\",\"category\":\"SPORTS\"})': [\n      {\n        '__ref': 'FeedItem:1'\n      },\n      // ...additional items...\n    ],\n    // Second query\n    'feed({\"offset\":\"10\",\"limit\":\"10\",\"category\":\"SPORTS\"})': [\n      {\n        '__ref': 'FeedItem:11'\n      },\n      // ...additional items...\n    ]\n  }\n}`\nYou can override this default behavior by defining a cache field policy for a particular field:\n`js {5-7}\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          keyArgs: [\"category\"],\n        },\n      },\n    },\n  },\n});`\nThis field policy for `Query.feed` includes a `keyArgs` array, which contains the names of all arguments that the cache should include in its storage keys.\nIn this case, we don't want the cache to treat `offset` or `limit` as key arguments, because those arguments don't change which list we're fetching from. However, we do want to treat `category` as a key argument, because we want to store our `SPORTS` feed separately from other feeds (such as `FASHION` or `MUSIC`).\nAfter setting `keyArgs` as shown, we end up with a single cache entry for our `SPORTS` feed (note the absence of `offset` and `limit` in the storage key):\n`js:title=Cache\n{\n  'ROOT_QUERY': {\n    'feed({\"category\":\"SPORTS\"})': [\n      {\n        '__ref': 'FeedItem:1'\n      },\n      // ...additional items from first query...\n      {\n        '__ref': 'FeedItem:11'\n      },\n      // ...additional items from second query...\n    ]\n  }\n}`\n\nImportant: After you define `keyArgs` for a paginated list field like `Query.feed`, you also need to define a merge function for the field. Otherwise, the list returned by the second query will overwrite the first list instead of merging with it.\n\nSupported values for `keyArgs`\nYou can provide the following values for a field's `keyArgs`:\n\n`false` (indicates that the field has no key arguments)\nAn array of argument, directive, and variable names\nA function (advanced)\n\n`keyArgs` array\nA `keyArgs` array can include the types of values shown below. The storage key for a cached field uses the values of all arguments, directives, and variables included in the array.\n\n\nArgument names:\n`js\n// Here, category and id are two arguments of the field\n[\"category\", \"id\"]`\n\n\nNested argument names for input types with subfields:\n`js\n// Here, details is an input type argument\n// with subfields name and date\n[\"details\", [\"name\", \"date\"] ]`\n\n\nDirective names (indicated with `@`), optionally with one or more of their arguments:\n`js\n// Here, @units is a directive that can be applied\n// to the field, and it has a type argument\n[\"@units\", [\"type\"] ]`\n\n\nVariable names (indicated with `$`):\n`js\n// Here, $userId is a variable that's provided to some\n// operations that include the field\n[\"$userId\"]`\n\n\n`keyArgs` function (advanced)\nYou can define a completely different format for a field's storage key by providing a custom function to `keyArgs`. This function takes the field's arguments and other context as parameters, and it can return any string to use as the storage key (or a dynamically-generated `keyArgs` array).\nThis is for advanced use cases. For details, see FieldPolicy API reference.\nWhich arguments belong in `keyArgs`?\nWhen deciding which of a field's arguments to include in `keyArgs`, it's helpful to start by considering the two extremes: all arguments and no arguments. These initial options help to demonstrate the effects of adding or removing a single argument.\nUsing all arguments\nIf all arguments are key arguments (this is the default behavior), every distinct combination of argument values for a field results in a distinct cache entry. In other words, changing any argument value results in a different storage key, so the returned value is stored separately. We see this in our pagination example:\n`js {3-4,10-11} title=\"Cache\"\n{\n  'ROOT_QUERY': {\n    // First query\n    'feed({\"offset\":\"0\",\"limit\":\"10\",\"category\":\"SPORTS\"})': [\n      {\n        '__ref': 'FeedItem:1'\n      },\n      // ...additional items...\n    ],\n    // Second query\n    'feed({\"offset\":\"10\",\"limit\":\"10\",\"category\":\"SPORTS\"})': [\n      {\n        '__ref': 'FeedItem:11'\n      },\n      // ...additional items...\n    ]\n  }\n}`\nWith this approach, Apollo Client can't return a cached value for a field unless all of the field's arguments match a previously cached result. This significantly reduces the cache's hit rate, but it also prevents the cache from returning an incorrect value when differences in arguments are relevant (as with our `User` example):\n`js {3,6} title=\"Cache\"\n{\n  'ROOT_QUERY': {\n    'user({\"id\":\"1\"})': {\n      '__ref': 'User:1'\n    },\n    'user({\"id\":\"2\"})': {\n      '__ref': 'User:2'\n    }\n  }\n}`\nUsing no arguments\nIf no arguments are key arguments (you configure this by setting `keyArgs: false`), the field's storage key is just the field's name, without any argument values appended to it. This means that by default, whenever a query returns a value for that field, that value replaces whatever value was already in the cache.\nThis default behavior is often undesirable (especially for a paginated list), so you can define `read` and `merge` functions that use argument values to determine how a newly returned value is combined with an existing cached value.\nExample\nRecall this `Query.feed` field from Pagination issues:\n`graphql {2}\ntype Query {\n  feed(offset: Int, limit: Int, category: Category): [FeedItem!]\n}`\nWe originally set `keyArgs: [\"category\"]` for this field to keep feed items from different categories separate. We can achieve the same behavior by setting `keyArgs: false` and defining the following `read` and `merge` functions:\n```js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          keyArgs: false,\n\n\n```      read(existing = {}, { args: { offset, limit, category }}) {\n        return existing[category]?.slice(offset, offset + limit);\n      },\n\n      merge(existing = {}, incoming, { args: { category, offset = 0 }}) {\n        const merged = existing[category] ? existing[category].slice(0) : [];\n        for (let i = 0; i < incoming.length; ++i) {\n          merged[offset + i] = incoming[i];\n        }\n        existing[category] = merged;\n        return existing;\n      },\n    },\n  },\n},\n```\n\n\n},\n});\n```\nWith the code above, the value of the `existing` cached value passed to our `read` and `merge` functions is a map of `category` names to `FeedItem` lists. This map enables our single cached field value to store multiple distinct lists. This manual separation is logically equivalent to using `keyArgs: [\"category\"]`, so the extra effort is often unnecessary.\nIf we know that feeds with different `category` values have different data, and we know that our `read` function never needs simultaneous access to multiple category feeds, we can safely shift the responsibility for the `category` argument to `keyArgs`. This enables us to simplify our `read` and `merge` functions to handle only one feed at a time.\nSummary\nIf the logic for storing and retrieving a field's data is identical for different values of a given argument (like `category` above), and the distinct field values are logically independent from one another, then you should probably add that argument to `keyArgs` to avoid handling it in your `read` and `merge` functions.\nBy contrast, arguments that limit, filter, sort, or otherwise reprocess existing field data usually do not belong in `keyArgs`. This is because putting them in `keyArgs` makes storage keys more diverse, reducing cache hit rate and limiting your ability to use different arguments to retrieve different views of the same data.\nAs a general rule, `read` and `merge` functions can do almost anything with your cached field data, but `keyArgs` often provide similar functionality with less code complexity. Whenever possible you should prefer the limited, declarative API of `keyArgs` over the unlimited power of functions like `merge` and `read`.\nThe `@connection` directive\nThe `@connection` directive is a Relay-inspired convention that Apollo Client supports. However, we recommend using `keyArgs` instead, because you can achieve the same effect with a single `keyArgs` configuration, whereas you need to include the `@connection` directive in every query you send to your server.\nIn other words, whereas Relay encourages the following `@connection(...)` directive for `Query.feed` queries:\n`js\nconst FEED_QUERY = gql`\n  query Feed($category: FeedCategory!, $offset: Int, $limit: Int) {\n    feed(category: $category, offset: $offset, limit: $limit) @connection(\n      key: \"feed\",\n      filter: [\"category\"]\n    ) {\n      edges {\n        node { ... }\n      }\n      pageInfo {\n        endCursor\n        hasNextPage\n      }\n    }\n  }\n`;`\nin Apollo Client, you can use the following query (the same query without the `@connection(...)` directive):\n`js\nconst FEED_QUERY = gql`\n  query Feed($category: FeedCategory!, $offset: Int, $limit: Int) {\n    feed(category: $category, offset: $offset, limit: $limit) {\n      edges {\n        node { ... }\n      }\n      pageInfo {\n        endCursor\n        hasNextPage\n      }\n    }\n  }\n`;`\nand instead configure `keyArgs` in your `Query.feed` field policy:\n`js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          keyArgs: [\"category\"],\n        },\n      },\n    },\n  },\n})`\nIf the `Query.feed` field does not have an argument like `category` that you can use in `keyArgs: [...]`, then it might make sense to use the `@connection` directive after all:\n`js\nconst FEED_QUERY = gql`\n  query Feed($offset: Int, $limit: Int, $feedKey: String) {\n    feed(offset: $offset, limit: $limit) @connection(key: $feedKey) {\n      edges {\n        node { ... }\n      }\n      pageInfo {\n        endCursor\n        hasNextPage\n      }\n    }\n  }\n`;`\nIf you execute this query with different values for the `$feedKey` variable, those feed results are stored separately in the cache, whereas normally they would all be stored in the same list.\nWhen choosing a `keyArgs` configuration for this `Query.feed` field, you should include the `@connection` directive as if it were an argument (the `@` tells `InMemoryCache` you mean a directive):\n`js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          keyArgs: [\"@connection\", [\"key\"]],\n        },\n      },\n    },\n  },\n})`\nWith this configuration, your cache uses a `feed:{\"@connection\":{\"key\":...}}` key instead of just `feed` to store separate `{ edges, pageInfo }` objects within the `ROOT_QUERY` object:\n`js\nexpect(cache.extract()).toEqual({\n  ROOT_QUERY: {\n    __typename: \"Query\",\n    'feed:{\"@connection\":{\"key\":\"some feed key\"}}': { edges, pageInfo },\n    'feed:{\"@connection\":{\"key\":\"another feed key\"}}': { edges, pageInfo },\n    'feed:{\"@connection\":{\"key\":\"yet another key\"}}': { edges, pageInfo },\n    // ...\n  },\n})`\nThe `[\"key\"]` in `keyArgs: [\"@connection\", [\"key\"]]` means only the `key` argument to the `@connection` directive is considered, and any other arguments (like `filter`) are ignored. Passing just `key` to `@connection` is usually adequate, but if you want to pass a `filter: [\"someArg\", \"anotherArg\"]` argument as well, you should instead include those argument names directly in `keyArgs`:\n`js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: {\n          keyArgs: [\"someArg\", \"anotherArg\", \"@connection\", [\"key\"]],\n        },\n      },\n    },\n  },\n})`\nIf any of these arguments or directives are not provided for the current query, they're omitted from the field key automatically, without error. This means it's generally safe to include more arguments or directives in `keyArgs` than you expect to receive in all cases.\n\nAs mentioned above, if a `keyArgs` array is insufficient to specify your desired field keys, you can alternatively pass a function for `keyArgs`, which takes the `args` object and a `{ typename, field, fieldName, variables }` context parameter. This function can return either a string or a dynamically-generated `keyArgs` array.\n\nAlthough `keyArgs` (and `@connection`) are useful for more than just paginated fields, it's worth noting that `relayStylePagination` configures `keyArgs: false` by default. You can reconfigure this `keyArgs` behavior by passing an alternate value to `relayStylePagination`:\n`js\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        feed: relayStylePagination([\"type\", \"@connection\", [\"key\"]]),\n      },\n    },\n  },\n})`",
    "tag": "apollo-client"
  },
  {
    "title": "Including credentials in requests",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/networking/basic-http-networking.md",
    "content": "\ntitle: Basic HTTP networking\ndescription: Communicate with a GraphQL server over HTTP\n\nApollo Client has built-in support for communicating with a GraphQL server over HTTP. To set up this communication, provide the server's URL as the `uri` parameter to the `ApolloClient` constructor:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  uri: 'https://api.example.com',\n  cache: new InMemoryCache()\n});\n```\nIf you provide this parameter, Apollo Client sends all GraphQL operations (queries and mutations) to the specified URL over HTTP.\nIncluding credentials in requests\nApollo Client can include user credentials (basic auth, cookies, etc.) in the HTTP requests it makes to a GraphQL server. By default, credentials are included only if the server is hosted at the same origin as the application using Apollo Client. You can adjust this behavior by providing a value for the `credentials` parameter to the `ApolloClient` constructor:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  uri: 'https://api.example.com',\n  cache: new InMemoryCache(),\n  // Enable sending cookies over cross-origin requests\n  credentials: 'include'\n});\n```\nThe following values for `credentials` are supported:\n| Option | Description |\n| - | - |\n| `same-origin` | Send user credentials (cookies, basic http auth, etc.) if the server's URL is on the same origin as the requesting client. This is the default value. |\n| `omit` | Never send or receive credentials. |\n| `include` | Always send user credentials (cookies, basic http auth, etc.), even for cross-origin requests. |\nFor more information, see Request.credentials.\nCustomizing request headers\nYou can specify the names and values of custom headers to include in every HTTP request to a GraphQL server. To do so, provide the `headers` parameter to the  `ApolloClient` constructor, like so:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  uri: 'https://api.example.com',\n  cache: new InMemoryCache(),\n  headers: {\n    authorization: localStorage.getItem('token'),\n    'client-name': 'WidgetX Ecom [web]',\n    'client-version': '1.0.0'\n  }\n});",
    "tag": "apollo-client"
  },
  {
    "title": "Customizing request logic",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/networking/advanced-http-networking.md",
    "content": "\ntitle: Advanced HTTP networking\ndescription: Take full network control with Apollo Link\n\nThe Apollo Link library gives you fine-grained control of HTTP requests that are sent by Apollo Client. You can also use it to replace Apollo Client's networking layer with something completely custom, such as a WebSocket transport or mocked server data.\nWhen using Apollo Link, you define network behavior as a collection of link objects that execute in sequence to control the flow of data. By default, Apollo Client uses Apollo Link's `HttpLink` to send GraphQL queries over HTTP.\nApollo Link includes installable, premade links that support a variety of use cases. You can also create your own custom links.\nCustomizing request logic\nThe following example demonstrates adding a custom link to Apollo Client. This link adds an `Authorization` header to every HTTP request before the `HttpLink` sends it:\n```js\nimport { ApolloClient, HttpLink, ApolloLink, InMemoryCache, concat } from '@apollo/client';\nconst httpLink = new HttpLink({ uri: '/graphql' });\nconst authMiddleware = new ApolloLink((operation, forward) => {\n  // add the authorization to the headers\n  operation.setContext(({ headers = {} }) => ({\n    headers: {\n      ...headers,\n      authorization: localStorage.getItem('token') || null,\n    }\n  }));\nreturn forward(operation);\n})\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: concat(authMiddleware, httpLink),\n});\n```\nThis next example demonstrates providing multiple custom links in an array:\n```js\nimport { ApolloClient, HttpLink, ApolloLink, InMemoryCache, from } from '@apollo/client';\nconst httpLink = new HttpLink({ uri: '/graphql' });\nconst authMiddleware = new ApolloLink((operation, forward) => {\n  // add the authorization to the headers\n  operation.setContext(({ headers = {} }) => ({\n    headers: {\n      ...headers,\n      authorization: localStorage.getItem('token') || null,\n    }\n  }));\nreturn forward(operation);\n})\nconst activityMiddleware = new ApolloLink((operation, forward) => {\n  // add the recent-activity custom header to the headers\n  operation.setContext(({ headers = {} }) => ({\n    headers: {\n      ...headers,\n      'recent-activity': localStorage.getItem('lastOnlineTime') || null,\n    }\n  }));\nreturn forward(operation);\n})\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: from([\n    authMiddleware,\n    activityMiddleware,\n    httpLink\n  ]),\n});\n```\nIn the example above, the `authMiddleware` link sets each request's `Authorization` header, and the `activityMiddleware` then sets each request's `Recent-Activity` header. Finally, the `HttpLink` sends the modified request.\nCustomizing response logic\nYou can use Apollo Link to customize Apollo Client's behavior whenever it receives a response from a request.\nThe following example demonstrates using @apollo/client/link/error to handle network errors that are included in a response:\n```js\nimport { ApolloClient, InMemoryCache, HttpLink } from '@apollo/client';\nimport { onError } from '@apollo/client/link/error';\nimport { logout } from './logout';\nconst httpLink = new HttpLink({ uri: '/graphql' });\nconst logoutLink = onError(({ networkError }) => {\n  if (networkError.statusCode === 401) logout();\n})\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: logoutLink.concat(httpLink),\n});\n```\nIn this example, the user is logged out of the application if the server returns a `401` code (unauthorized).\nModifying response data\nYou can create a custom link that edits or removes fields from `response.data`. To do so, you call `map` on the result of the link's `forward(operation)` call. In the `map` function, make the desired changes to `response.data` and then return it:\n```js\nimport { ApolloClient, InMemoryCache, HttpLink, ApolloLink } from '@apollo/client';\nconst httpLink = new HttpLink({ uri: '/graphql' });\nconst formatDateLink = new ApolloLink((operation, forward) => {\n  return forward(operation).map(response => {\n    if (response.data.date) {\n      response.data.date = new Date(response.data.date);\n    }\n    return response;\n  });\n});\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: formatDateLink.concat(httpLink),\n});\n```\nIn the above example, `formatDateLink` changes a `date` field to a Javascript Date object at the top level of each response.\nNote that `forward(operation).map(func)` doesn't support asynchronous execution of the `func` mapping function. If you need to make asynchronous modifications, use the `asyncMap` function from `@apollo/client/utilities`, like so:\n```js\nimport {\n  ApolloClient,\n  InMemoryCache,\n  HttpLink,\n  ApolloLink\n} from \"@apollo/client\";\nimport { asyncMap } from \"@apollo/client/utilities\";\nimport { usdToEur } from './currency';\nconst httpLink = new HttpLink({ uri: '/graphql' });\nconst usdToEurLink = new ApolloLink((operation, forward) => {\n  return asyncMap(forward(operation), async (response) => {\n    let data = response.data;\n    if (data.price && data.currency === \"USD\") {\n      data.price = await usdToEur(data.price);\n      data.currency = \"EUR\";\n    }\n    return response;\n  });\n});\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: usdToEurLink.concat(httpLink)\n});\n```\nIn the example above, `usdToEurLink` uses `asyncMap` to convert the response object's `price` field from USD to EUR using an external API.\nWhile this technique can be useful for modifying existing fields (or adding additional objects to lists within `data`), adding new fields to `data` won't work in most cases, because the operation document cannot be safely modified within the `ApolloLink` request pipeline.\nThe `HttpLink` object\nApollo Client uses `HttpLink` to send GraphQL operations to a server over HTTP. The link supports both POST and GET requests, and it can modify HTTP options on a per-query basis. This comes in handy when implementing authentication, persisted queries, dynamic URIs, and other granular updates.\n\nIf your client doesn't have complex HTTP requirements, you probably don't need to create a custom instance of `HttpLink`. For details, see Basic HTTP networking.\n\nUsage\n```js\nimport { HttpLink } from \"@apollo/client\";\nconst link = new HttpLink({ uri: \"/graphql\" });\n```\nConstructor options\nThe `HttpLink` constructor accepts the following options:\n| Options | Description |\n| - | - |\n| `uri` | A string endpoint or function that resolves to the GraphQL server you want to execute operations against. (default: `/graphql`)|\n| `includeExtensions` | If `true`, you can pass an `extensions` field to your GraphQL server. (default: `false`) |\n| `fetch` | A `fetch`-compatible API for making a request. See Providing a fetch replacement for certain environments. |\n| `headers` | An object containing header names and values to include in each request. |\n| `preserveHeaderCase` | If `true`, header values retain their capitalization for non-http-spec-compliant servers. (default: `false`) |\n| `credentials` | A string representing the credentials policy to use for the `fetch` call. (valid values: `omit`, `include`, `same-origin`) |\n| `fetchOptions` | Include this to override the values of certain options that are provided to the `fetch` call. |\n| `useGETForQueries` | If `true`, `HttpLink` uses `GET` requests instead of `POST` requests to execute query operations (but not mutation operations). (default: `false`) |\n| `print` | A function to customize AST formatting in requests. See Overriding the default print function.  |\nProviding a `fetch` replacement for certain environments\n`HttpLink` requires that `fetch` is present in your runtime environment. This is the case for React Native and most modern browsers. If you're targeting an environment that doesn't include `fetch` (such as older browsers or the server), you need to pass your own `fetch` to `HttpLink` via its constructor options. We recommend using cross-fetch for older browsers and Node.\nOverriding the default `print` function\nThe `print` option is useful for customizing the way `DocumentNode` objects are transformed back into strings before they are sent over the network. If no custom `print` function is provided, the GraphQL print function will be used. A custom `print` function should accept an `ASTNode` (typically a `DocumentNode`) and the original `print` function as arguments, and return a string. This option can be used with `stripIgnoredCharacters` to remove whitespace from queries:\n```ts\nimport { ASTNode, stripIgnoredCharacters } from 'graphql';\nconst httpLink = new HttpLink({\n  uri: '/graphql',\n  print(\n    ast: ASTNode,\n    originalPrint: (ast: ASTNode) => string,\n  ) {\n    return stripIgnoredCharacters(originalPrint(ast));\n  },\n});\n```\nOverriding options\nYou can override most `HttpLink` constructor options on an operation-by-operation basis by modifying the `context` object for the operation. For example, you can set the `headers` field on the `context` to pass custom headers for a particular operation. The `context` also supports the `credentials` field for defining credentials policy, `uri` for changing the endpoint dynamically, and `fetchOptions` to allow generic fetch overrides (i.e., `method: \"GET\"`).\nNote that if you set `fetchOptions.method` to `GET`, `HttpLink` follows the standard GraphQL HTTP GET encoding. The query, variables, operation name, and extensions are passed as query parameters instead of in the HTTP request body (because there isn't one). If you to continue to send mutations as non-idempotent `POST` requests, set the top-level `useGETForQueries` option to `true` instead of setting `fetchOptions.method` to `GET`.\n`HttpLink` also attaches the response from the `fetch` operation to the context as `response`, so you can access it in another link.\nContext options:\n| Option | Description |\n| - | - |\n| `headers` | An object containing header names and values to include in each request. |\n| `credentials` | A string representing the credentials policy to use for the `fetch` call. (valid values: `omit`, `include`, `same-origin`) |\n| `uri` | A string endpoint or function that resolves to the GraphQL server you want to execute operations against. |\n| `fetchOptions` | Any overrides of the fetch options argument to pass to the `fetch` call. |\n| `response` | The raw response from the `fetch` request after it is made. |\n| `http` | An object that lets you control fine-grained aspects of `HttpLink` itself, such as persisted queries (see below). |\nThe following example shows how to use the `context` to pass a special header for a single query:\n```js\nimport { ApolloClient, InMemoryCache } from \"@apollo/client\";\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  uri: \"/graphql\"\n});\nclient.query({\n  query: MY_QUERY,\n  context: {\n    // example of setting the headers with context per operation\n    headers: {\n      special: \"Special header value\"\n    }\n  }\n});\n```\nCustom fetching\n`HttpLink`'s `fetch` option can be used to wire in custom networking. This is useful if you want to modify the request based on calculated headers, or calculate the URI based on an operation. For example:\nCustom auth:\n```js\nconst customFetch = (uri, options) => {\n  const { header } = Hawk.client.header(\n    \"http://example.com:8000/resource/1?b=1&a=2\",\n    \"POST\",\n    { credentials: credentials, ext: \"some-app-data\" }\n  );\n  options.headers.Authorization = header;\n  return fetch(uri, options);\n};\nconst link = new HttpLink({ fetch: customFetch });\n```\nDynamic URI:\n```js\nconst customFetch = (uri, options) => {\n  const { operationName } = JSON.parse(options.body);\n  return fetch(`${uri}/graph/graphql?opname=${operationName}`, options);\n};\nconst link = new HttpLink({ fetch: customFetch });\n```\nUsing other links\nApollo Link includes many links for specialized use cases, such as the `WebSocketLink` for communicating over WebSocket and the `BatchHttpLink` for combining multiple GraphQL operations in a single HTTP request.",
    "tag": "apollo-client"
  },
  {
    "title": "Cookie",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/networking/authentication.mdx",
    "content": "\ntitle: Authentication\nUnless all of the data you are loading is completely public, your app has some sort of users, accounts and permissions systems. If different users have different permissions in your application, then you need a way to tell the server which user is associated with each request.\nApollo Client uses the ultra flexible Apollo Link that includes several options for authentication.\nCookie\nIf your app is browser based and you are using cookies for login and session management with a backend, tell your network interface to send the cookie along with every request. Pass the credentials option e.g.  `credentials: 'same-origin'` if your backend server is the same domain, as shown below, or else `credentials: 'include'` if your backend is a different domain.\n```js\nconst link = createHttpLink({\n  uri: '/graphql',\n  credentials: 'same-origin'\n});\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link,\n});\n```\nThis option is passed through to the fetch implementation used by the HttpLink when sending the query.\nNote: the backend must also allow credentials from the requested origin. e.g. if using the popular 'cors' package from npm in node.js, the following settings would work in tandem with the above apollo client settings:\n`js\n// enable cors\nvar corsOptions = {\n  origin: '<insert uri of front-end domain>',\n  credentials: true // <-- REQUIRED backend setting\n};\napp.use(cors(corsOptions));`\nHeader\nAnother common way to identify yourself when using HTTP is to send along an authorization header. Add an `authorization` header to every HTTP request by chaining together Apollo Links. In this example, we'll pull the login token from `localStorage` every time a request is sent:\nReactJS example:\n```js\nimport { ApolloClient, createHttpLink, InMemoryCache } from '@apollo/client';\nimport { setContext } from '@apollo/client/link/context';\nconst httpLink = createHttpLink({\n  uri: '/graphql',\n});\nconst authLink = setContext((_, { headers }) => {\n  // get the authentication token from local storage if it exists\n  const token = localStorage.getItem('token');\n  // return the headers to the context so httpLink can read them\n  return {\n    headers: {\n      ...headers,\n      authorization: token ? `Bearer ${token}` : \"\",\n    }\n  }\n});\nconst client = new ApolloClient({\n  link: authLink.concat(httpLink),\n  cache: new InMemoryCache()\n});\n`VueJS example:`js\nimport ApolloClient from \"apollo-client\";\nimport { HttpLink } from \"apollo-link-http\";\nimport { ApolloLink, concat, split } from \"apollo-link\";\nimport { InMemoryCache } from \"apollo-cache-inmemory\";\nimport { getMainDefinition } from \"apollo-utilities\";\nconst httpLink = new HttpLink({ uri: process.env.VUE_APP_API_TARGET });\nconst authMiddleware = new ApolloLink((operation, forward) => {\n  // add the authorization to the headers\nconst token = localStorage.getItem('token');\n  operation.setContext({\n    headers: {\n      authorization: token ? `Bearer ${token}` : \"\",\n    },\n  });\n  return forward(operation);\n});\nexport const apolloClient = new ApolloClient({\n  link: concat(authMiddleware, httpLink),\n  cache: new InMemoryCache(),\n});\n```\nThe server can use that header to authenticate the user and attach it to the GraphQL execution context, so resolvers can modify their behavior based on a user's role and permissions.\nReset store on logout\nSince Apollo caches all of your query results, it's important to get rid of them when the login state changes.\nThe most straightforward way to ensure that the UI and store state reflects the current user's permissions is to call `client.resetStore()` after your login or logout process has completed. This will cause the store to be cleared and all active queries to be refetched. If you just want the store to be cleared and don't want to refetch active queries, use `client.clearStore()` instead. Another option is to reload the page, which will have a similar effect.\n```jsx\nconst PROFILE_QUERY = gql`\n  query CurrentUserForLayout {\n    currentUser {\n      login\n      avatar_url\n    }\n  }\n`;\nfunction Profile() {\n  const { client, loading, data: { currentUser } } = useQuery(\n    PROFILE_QUERY,\n    { fetchPolicy: \"network-only\" }\n  );\nif (loading) {\n    return Loading...;\n  }\nif (currentUser) {\n    return (\n      \n\n          {currentUser.login}\n          \u00a0\n           {\n              // call your auth logout code then reset store\n              App.logout().then(() => client.resetStore());\n            }}\n          >\n            Log out\n          \n\n\n    );\n  }\nreturn (\n    \nLog in with GitHub\n\n  );\n}",
    "tag": "apollo-client"
  },
  {
    "title": "1. Define a client-side schema (recommended)",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/development-testing/client-schema-mocking.mdx",
    "content": "\ntitle: Mocking schema capabilities\ndescription: Start on client-side features before your server supports them\n\nIf your GraphQL server doesn't yet support a field that your client will use, you can still start building against that field by mocking its behavior within the client.\nFor example, let's say we want to add a feature to the Space Explorer app from the full-stack quickstart course. Specifically, we want to display a description of the rocket used for each launch. To support this functionality on the server side, we'll add a `description` field to our schema's `Rocket` type:\n`graphql {5}\ntype Rocket {\n  id: ID!\n  name: String\n  type: String\n  description: String # field not yet supported\n}`\nBut what if our back-end team isn't finished adding support for the `description` field? By mocking the field's behavior, we can still start developing the feature in our client. To do so, we'll follow the steps below.\n1. Define a client-side schema (recommended)\nOur client application can define a client-side schema that extends types from our server,  or even defines entirely new types. The syntax is identical to server-side schema definitions.\n\nAlthough a client-side schema isn't required for mocking, it helps team members understand your app's local capabilities. It also unlocks powerful local state support in tools like the Apollo Client Devtools and the Apollo extension for VS Code.\n\nThis client-side schema extends the `Rocket` type to add a `description` field (make sure to name the variable `typeDefs` as shown):\n`js title=\"index.js\"\nconst typeDefs = gql`\n  extend type Rocket {\n    description: String\n  }\n`;`\nWe can then provide this schema to the `ApolloClient` constructor, like so:\n`js {4} title=\"index.js\"\nconst client = new ApolloClient({\n  uri: 'http://localhost:4000/graphql',\n  cache: new InMemoryCache(),\n  typeDefs\n});`\n2. Define a `read` function\nOur client app doesn't yet know how to populate the `Rocket.description` field. To fix this, we can define a read function for the field. The Apollo Client cache calls this function whenever the field is queried, and the function's return value is used as the field's value.\nLet's define our `read` function in the configuration object we provide to the `InMemoryCache` constructor:\n`js {5-9} title=\"index.js\"\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Rocket: {\n      fields: {\n        description: {\n          read() { // Read function for Rocket.description\n            return 'Placeholder rocket description';\n          }\n        },\n      },\n    },\n  },\n});`\nThis enables us to query the field, but we might not want to show the same boilerplate description for every rocket. To add variety to our mocked output, we can use a library like faker.js:\n```js title=\"index.js\"\nimport { faker } from \"@faker-js/faker\";\n// Returns 1 or 2 sentences of Lorem Ipsum\nconst oneOrTwoSentences = () =>\n  faker.lorem.sentences(Math.random() < 0.5 ? 1 : 2);\n```\nWe can then update our `read` function like so:\n`js\n// (within InMemoryCache constructor)\nread() {\n  return oneOrTwoSentences();\n}`\n\nMake sure to include libraries like faker.js only in your development build, because they can needlessly increase your production bundle size.\n\n3. Query with the `@client` directive\nWe're ready to execute a query that includes our new field. Here's an abridged `GET_LAUNCH_DETAILS` query from the full-stack quickstart with our `description` field added:\n`jsx {7}\nexport const GET_LAUNCH_DETAILS = gql`\n  query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      site\n      rocket {\n        type\n        description @client\n      }\n    }\n  }\n`;`\nNotice that this field includes the `@client` directive. This directive tells Apollo Client not to include `description` in the query it sends to our server. This is important for two related reasons:\n\nThe `description` field is populated entirely locally, so including it in network requests isn't helpful.\nThe `description` field isn't in our server-side schema yet, so including it will produce a GraphQL error.\n\nWe can now execute this query in a component with the `useQuery` hook as usual:\n`jsx\nexport default function LaunchDetails({ launchId }) {\n  const { data } = useQuery(GET_LAUNCH_DETAILS, { variables: { rocketId } });\n  return (\n    <div>\n      <p>Rocket Type: {data.launch.rocket.type}</p>\n      <p>Description: {data.launch.rocket.description}</p>\n    </div>\n  );\n}`\n4. Use live data when ready\nWhen your server's support for the `Rocket.description` field is ready, you can begin using it by doing the following:\n\nRemove the `@client` directive from `description` in every query that includes it.\nRemove the field's `read` function (or modify the function so that it uses the current cached value instead of a random string).\n\n\nFor more information on the Apollo Client features used here, see the following:\n\nClient-side schema\nLocal-only fields\n",
    "tag": "apollo-client"
  },
  {
    "title": "The `MockedProvider` component",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/development-testing/testing.mdx",
    "content": "\ntitle: Testing React components\ndescription: Using MockedProvider and associated APIs\n\nThis article describes best practices for testing React components that use Apollo Client.\nThe examples below use Jest and React Testing Library, but the concepts apply to any testing framework.\nThe `MockedProvider` component\nEvery test for a React component that uses Apollo Client must make Apollo Client available on React's context. In application code, you achieve this by wrapping your component tree with the `ApolloProvider` component. In your tests, you use the `MockedProvider` component instead.\nThe `MockedProvider` component enables you to define mock responses for individual queries that are executed in your test. This means your test doesn't need to communicate with a GraphQL server, which removes an external dependency and therefore improves the test's reliability.\nExample\nLet's say we want to test the following `Dog` component, which executes a basic query and displays its result:\n\n```jsx title=\"dog.jsx\"\nimport React from \"react\";\nimport { gql, useQuery } from \"@apollo/client\";\n// Make sure that both the query and the component are exported\nexport const GET_DOG_QUERY = gql`query GetDog($name: String) {\n    dog(name: $name) {\n      id\n      name\n      breed\n    }\n  }`;\nexport function Dog({ name }) {\n  const { loading, error, data } = useQuery(GET_DOG_QUERY, {\n    variables: { name }\n  });\n  if (loading) return Loading...;\n  if (error) return {error.message};\n  return (\n    \n      {data.dog.name} is a {data.dog.breed}\n    \n  );\n}\n```\n\nA basic rendering test for the component looks like this (minus mocked responses):\n```jsx title=\"dog.test.js\"\nimport \"@testing-library/jest-dom\";\nimport { render, screen } from \"@testing-library/react\";\nimport { MockedProvider } from \"@apollo/client/testing\";\nimport { GET_DOG_QUERY, Dog } from \"./dog\";\nconst mocks = []; // We'll fill this in next\nit(\"renders without error\", async () => {\n  render(\n    \n\n\n  );\n  expect(await screen.findByText(\"Loading...\")).toBeInTheDocument();\n});\n```\n\nNote: Usually, you import `@testing-library/jest-dom` in your test setup file, which provides certain custom jest matchers (such as `toBeInTheDocument`). The import is included in these examples for completeness.\n\nDefining mocked responses\nThe `mocks` prop of `MockedProvider` is an array of objects, each of which defines the mock response for a single operation. Let's define a mocked response for `GET_DOG_QUERY` when it's passed the `name` `Buck`:\n`jsx title=\"dog.test.js\"\nconst mocks = [\n  {\n    request: {\n      query: GET_DOG_QUERY,\n      variables: {\n        name: \"Buck\"\n      }\n    },\n    result: {\n      data: {\n        dog: { id: \"1\", name: \"Buck\", breed: \"bulldog\" }\n      }\n    }\n  }\n];`\nEach mock object defines a `request` field (indicating the shape and variables of the operation to match against) and a `result` field (indicating the shape of the response to return for that operation).\n\nYour test must execute an operation that exactly matches a mock's shape and variables to receive the associated mocked response.\n\nAlternatively, the `result` field can be a function that returns a mocked response after performing arbitrary logic:\n```jsx\nresult: () => {\n  // ...arbitrary logic...\nreturn {\n    data: {\n      dog: { id: '1', name: 'Buck', breed: 'bulldog' },\n    },\n  }\n},\n```\nCombining our code above, we get the following complete test:\n\n```jsx title=\"dog.test.js\"\nimport \"@testing-library/jest-dom\";\nimport { render, screen } from \"@testing-library/react\";\nimport { MockedProvider } from \"@apollo/client/testing\";\nimport { GET_DOG_QUERY, Dog } from \"./dog\";\nconst mocks = [\n  {\n    request: {\n      query: GET_DOG_QUERY,\n      variables: {\n        name: \"Buck\"\n      }\n    },\n    result: {\n      data: {\n        dog: { id: \"1\", name: \"Buck\", breed: \"bulldog\" }\n      }\n    }\n  }\n];\nit(\"renders without error\", async () => {\n  render(\n    \n\n\n  );\n  expect(await screen.findByText(\"Loading...\")).toBeInTheDocument();\n});\n```\n\nSetting `addTypename`\nIn the example above, we set the `addTypename` prop of `MockedProvider` to `false`. This prevents Apollo Client from automatically adding the special `__typename` field to every object it queries for (it does this by default to support data normalization in the cache).\nWe don't want to automatically add `__typename` to `GET_DOG_QUERY` in our test, because then it won't match the shape of the query that our mock is expecting.\nUnless you explicitly configure your mocks to expect a `__typename` field, always set `addTypename` to `false` in your tests.\nTesting the \"loading\" and \"success\" states\nTo test how your component is rendered after its query completes, Testing Library provides several `findBy` methods. From the Testing Library docs:\n\n`findBy` queries work when you expect an element to appear but the change to the DOM might not happen immediately.\n\nWe can use the asynchronous `screen.findByText` method to query the DOM elements containing the loading message first, followed by the success message `\"Buck is a poodle\"` (which appears after our query completes):\n`jsx\nit(\"should render dog\", async () => {\n  const dogMock = {\n    request: {\n      query: GET_DOG_QUERY,\n      variables: { name: \"Buck\" }\n    },\n    result: {\n      data: { dog: { id: 1, name: \"Buck\", breed: \"poodle\" } }\n    }\n  };\n  render(\n    <MockedProvider mocks={[dogMock]} addTypename={false}>\n      <Dog name=\"Buck\" />\n    </MockedProvider>\n  );\n  expect(await screen.findByText(\"Loading...\")).toBeInTheDocument();\n  expect(await screen.findByText(\"Buck is a poodle\")).toBeInTheDocument();\n});`\nTesting error states\nYour component's error states are just as important to test as its success state, if not more so. You can use the `MockedProvider` component to simulate both network errors and GraphQL errors.\n\nNetwork errors are errors that occur while your client attempts to communicate with your GraphQL server.\nGraphQL errors are errors that occur while your GraphQL server attempts to resolve your client's operation.\n\nNetwork errors\nTo simulate a network error, you can include an `error` field in your test's mock object, instead of the `result` field:\n`jsx\nit(\"should show error UI\", async () => {\n  const dogMock = {\n    request: {\n      query: GET_DOG_QUERY,\n      variables: { name: \"Buck\" }\n    },\n    error: new Error(\"An error occurred\")\n  };\n  render(\n    <MockedProvider mocks={[dogMock]} addTypename={false}>\n      <Dog name=\"Buck\" />\n    </MockedProvider>\n  );\n  expect(await screen.findByText(\"An error occurred\")).toBeInTheDocument();\n});`\nIn this case, when the `Dog` component executes its query, the `MockedProvider` returns the corresponding error. This applies the error state to our `Dog` component, enabling us to verify that the error is handled gracefully.\nGraphQL errors\nTo simulate GraphQL errors, you define an `errors` field inside a mock's `result` field. The value of this field is an array of instantiated `GraphQLError` objects:\n`js\nconst dogMock = {\n  // ...\n  result: {\n    errors: [new GraphQLError(\"Error!\")],\n  },\n};`\nBecause GraphQL supports returning partial results when an error occurs, a mock object's `result` can include both `errors` and `data`.\nTesting mutations\nYou test components that use `useMutation` similarly to how you test components that use `useQuery`. Just like in your application code, the primary difference is that you need to call the mutation's mutate function to actually execute the operation.\nExample\nThe following `DeleteButton` component executes the `DELETE_DOG_MUTATION` to delete a dog named `Buck` from our graph (don't worry, Buck will be fine \ud83d\udc36):\n```jsx title=\"delete-dog.jsx\"\nimport React from \"react\";\nimport { gql, useMutation } from \"@apollo/client\";\nexport const DELETE_DOG_MUTATION = gql`mutation deleteDog($name: String!) {\n    deleteDog(name: $name) {\n      id\n      name\n      breed\n    }\n  }`;\nexport function DeleteButton() {\n  const [mutate, { loading, error, data }] = useMutation(DELETE_DOG_MUTATION);\nif (loading) return Loading...;\n  if (error) return Error!;\n  if (data) return Deleted!;\nreturn (\n     mutate({ variables: { name: \"Buck\" } })}>\n      Click to Delete Buck\n    \n  );\n}\n```\nWe can test the initial rendering of this component just like we tested our Dog component:\n```jsx title=\"delete-dog.test.js\"\nimport '@testing-library/jest-dom';\nimport userEvent from '@testing-library/user-event';\nimport { render, screen } from '@testing-library/react';\nimport { MockedProvider } from \"@apollo/client/testing\";\nimport { DeleteButton, DELETE_DOG_MUTATION } from \"./delete-dog\";\nit(\"should render without error\", () => {\n  render(\n    \n\n\n  );\n});\n```\nIn the test above, `DELETE_DOG_MUTATION` is not executed, because the mutate function is not called.\nThe following test does execute the mutation by clicking the button:\n```jsx title=\"delete-dog.test.js\"\nit(\"should render loading and success states on delete\", async () => {\n  const deleteDog = { name: \"Buck\", breed: \"Poodle\", id: 1 };\n  const mocks = [\n    {\n      request: {\n        query: DELETE_DOG_MUTATION,\n        variables: { name: \"Buck\" }\n      },\n      result: { data: deleteDog }\n    }\n  ];\nrender(\n    \n\n\n  );\n// Find the button element...\n  const button = await screen.findByText(\"Click to Delete Buck\");\n  userEvent.click(button); // Simulate a click and fire the mutation\nexpect(await screen.findByText(\"Loading...\")).toBeInTheDocument();\n  expect(await screen.findByText(\"Deleted!\")).toBeInTheDocument();\n});\n```\nAgain, this example is similar to the useQuery-based component above, but it differs after the rendering is completed. Because this component relies on a button click to fire a mutation, we use Testing Library's user-event library to simulate a click with its `click` method. This fires off the mutation, and the rest of the test runs as expected.\nRemember that the mock's value for `result` can also be a function, so you can perform arbitrary logic (like setting a boolean to indicate that the mutation completed) before returning its result.\nTesting error states for mutations is identical to testing them for queries.\nTesting with the cache\nIf your application sets any cache configuration options (such as `possibleTypes` or `typePolicies`), you should provide `MockedProvider` with an instance of `InMemoryCache` that sets the exact same options:\n```jsx\nconst cache = new InMemoryCache({\n  // ...configuration options...\n})\n\n\n,\n```\nThe following sample specifies `possibleTypes` and `typePolicies` in its cache configuration, both of which must also be specified in relevant tests to prevent unexpected behavior.\n\n```jsx\n// \"Dog\" supertype can be of type \"ShibaInu\"\nconst ShibaFragment = gql`\n  fragment ShibaInuFields on Dog {\n    ... on ShibaInu {\n      tail {\n        isCurly\n      }\n    }\n  }\n`;\nexport const GET_DOG_QUERY = gql`\n  query GetDog($name: String) {\n    dog(name: $name) {\n      id\n      name\n      breed\n\n\n```  ...ShibaInuFields\n}\n```\n\n\n}\n${ShibaFragment}\n`;\nexport const cache = new ApolloClient({\n  cache: new InMemoryCache({\n    possibleTypes: {\n      Dog: [\"ShibaInu\"],\n    },\n    // suppose you want you key fields for \"Dog\" to not be simply \"id\"\n    typePolicies: {\n      keyFields: {\n        Dog: [\"name\", \"breed\"],\n      },\n    },\n  }),\n});\n```\n\nTesting local state\nIn order to properly test local state using `MockedProvider`, you'll need to pass a configured cache into `MockedProvider` itself.\n`MockedProvider` creates its own ApolloClient instance behind the scenes like this:\n`jsx\nconst { \n  mocks,\n  addTypename,\n  defaultOptions,\n  cache,\n  resolvers,\n  link,\n  showWarnings,\n} = this.props;\nconst client = new ApolloClient({\n  cache: cache || new Cache({ addTypename }),\n  defaultOptions,\n  link: link || new MockLink(mocks || [], addTypename, { showWarnings }),\n  resolvers,\n});`\nTherefore if you're using Apollo Client 2.x local resolvers, or Apollo Client 3.x type/field policies, you have to tell the `MockedProvider` component what you're going to do with `@client` fields. Otherwise the `ApolloClient` instance created behind the scenes doesn't know how handle your tests.\nIf using Apollo Client 2.x local resolvers, make sure your resolvers object is passed into `MockedProvider`:\n`jsx\n<MockedProvider mocks={mocks} resolvers={resolvers} ...`\nIf using Apollo Client 3.x type/field policies, make sure your configured cache instance (with your typePolicies) is passed into `MockedProvider`:\n`jsx\n<MockedProvider mocks={mocks} cache={cache} ...`\nIf you're using Apollo Client 2.x local resolvers, you also need to pass your resolver map:\n`jsx\n<MockedProvider mocks={mocks} cache={cache} resolvers={resolvers} ...`\nThis is necessary because otherwise, the `MockedProvider` component doesn't know how resolve local-only fields in your queries.\nSandbox example\nFor a working example that demonstrates how to test components, check out this project on CodeSandbox:",
    "tag": "apollo-client"
  },
  {
    "title": "Setting up your project",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/development-testing/static-typing.md",
    "content": "\ntitle: TypeScript with Apollo Client\ndescriptions: How to generate and use TypeScript types in your application\n\nAs your application grows, a type system can become an essential tool for catching bugs early and improving your overall developer experience.\nGraphQL uses a type system to clearly define the available data for each type and field in a GraphQL schema. Given that a GraphQL server's schema is strongly typed, we can generate TypeScript definitions automatically using a tool like GraphQL Code Generator. We'll use our generated types to ensure type safety for the inputs and results of our GraphQL operations.\nBelow, we'll guide you through installing and configuring GraphQL Code Generator to generate types for your hooks and components.\nSetting up your project\n\nThis article assumes your project already uses TypeScript. If not, configure your project to use TypeScript or start a new project.\n\nTo get started using GraphQL Code Generator, begin by installing the following packages (using Yarn or NPM):\n`bash\nyarn add -D typescript @graphql-codegen/cli @graphql-codegen/client-preset`\nNext, we'll create a configuration file for GraphQL Code Generator, named codegen.ts, at the root of our project:\n```ts title=\"codegen.ts\"\nimport { CodegenConfig } from '@graphql-codegen/cli';\nconst config: CodegenConfig = {\n  schema: '',\n  documents: ['src/*/.tsx'],\n  generates: {\n    './src/generated/': {\n      preset: 'client',\n      plugins: [],\n      presetConfig: {\n        gqlTagName: 'gql',\n      }\n    }\n  },\n  ignoreNoDocuments: true,\n};\nexport default config;\n```\n\nThere are multiple ways to specify a schema in your `codegen.ts`, so pick whichever way works best for your project setup.\n\nFinally, we'll add the following scripts to our `package.json` file:\n`json title=\"package.json\"\n{\n  \"scripts\": {\n    \"compile\": \"graphql-codegen\",\n    \"watch\": \"graphql-codegen -w\",\n  }\n}`\nRunning either of the scripts above generates types based on the schema file or GraphQL API you provided in `codegen.ts`:\n`bash\n$ yarn run compile\n\u2714 Parse Configuration\n\u2714 Generate outputs`\nTyping hooks\nGraphQL Code Generator automatically creates a `gql` function (from the `src/__generated__/gql.ts` file). This function enables us to type the variables that go into our React hooks, along with the results from those hooks.\n`useQuery`\nBelow we use the `gql` function to define our query, which automatically generates types for our `useQuery` hook:\n```tsx\nimport React from 'react';\nimport { useQuery } from '@apollo/client';\nimport { gql } from '../src/generated/gql';\nconst GET_ROCKET_INVENTORY = gql(/ GraphQL / `query GetRocketInventory($year: Int!) {\n    rocketInventory(year: $year) {\n      id\n      model\n      year\n      stock\n    }\n  }`);\nexport function RocketInventoryList() {\n  // our query's result, data, is typed!\n  const { loading, data } = useQuery(\n    GET_ROCKET_INVENTORY,\n    // variables are also typed!\n    { variables: { year: 2019 } }\n  );\n  return (\n    \nAvailable Inventory\n      {loading ? (\n        Loading ...\n      ) : (\n        \n\n\nModel\nStock\n\n\n\n            {data && data.rocketInventory.map(inventory => (\n              \n{inventory.model}\n{inventory.stock}\n\n            ))}\n          \n\n      )}\n    \n  );\n}\n```\n`fetchMore` and `subscribeToMore`\nThe `useQuery` hook returns an instance of `QueryResult`, which includes the `fetchMore` and `subscribeToMore` functions. See Queries for detailed type information. Because these functions execute GraphQL operations, they accept type parameters.\nBy default, the type parameters for `fetchMore` are the same as those for `useQuery`. Because both `fetchMore` and `useQuery` encapsulate a query operation, it's unlikely that you'll need to pass any type arguments to `fetchMore`.\nExpanding our previous example, notice that we don't explicitly type `fetchMore`, because it defaults to using the same type parameters as `useQuery`:\n```tsx\n// ...\nexport function RocketInventoryList() {\n  const { fetchMore, loading, data } = useQuery(\n    GET_ROCKET_INVENTORY,\n    // variables are typed!\n    { variables: { year: 2019 } }\n  );\nreturn (\n    //...\n     {\n        // variables are typed!\n        fetchMore({ variables: { year: 2020 } });\n      }}\n    >\n      Add 2020 Inventory\n    \n    //...\n  );\n}\n```\nThe type parameters and defaults for `subscribeToMore` are identical to those for `fetchMore`. Keep in mind that `subscribeToMore` executes a subscription, whereas `fetchMore` executes follow-up queries.\nUsing `subscribeToMore`, you usually pass at least one typed argument, like so:\n```tsx\n// ...\nconst ROCKET_STOCK_SUBSCRIPTION = gql(/* GraphQL */`\n  subscription OnRocketStockUpdated {\n    rocketStockAdded {\n      id\n      stock\n    }\n  }\n`);\nexport function RocketInventoryList() {\n  const { subscribeToMore, loading, data } = useQuery(\n    GET_ROCKET_INVENTORY,\n    { variables: { year: 2019 } }\n  );\nReact.useEffect(() => {\n    subscribeToMore(\n      // variables are typed!\n      { document: ROCKET_STOCK_SUBSCRIPTION, variables: { year: 2019 } }\n    );\n  }, [subscribeToMore])\n// ...\n}\n```\n`useMutation`\nWe can type `useMutation` hooks the same way we type `useQuery` hooks. Using the generated `gql` function to define our GraphQL mutations, we ensure that we type our mutation's variables and return data:\n```tsx\nimport React, { useState } from 'react';\nimport { useMutation } from '@apollo/client';\nimport { gql } from '../src/generated/gql';\nconst SAVE_ROCKET = gql(/ GraphQL / `mutation saveRocket($rocket: RocketInput!) {\n    saveRocket(rocket: $rocket) {\n      model\n    }\n  }`);\nexport function NewRocketForm() {\n  const [model, setModel] = useState('');\n  const [year, setYear] = useState(0);\n  const [stock, setStock] = useState(0);\n// our mutation's result, data, is typed!\n  const [saveRocket, { error, data }] = useMutation(SAVE_ROCKET, {\n    // variables are also typed!\n    variables: { rocket: { model, year: +year, stock: +stock } }\n  });\nreturn (\n    \nAdd a Rocket\n      {error ? Oh no! {error.message} : null}\n      {data && data.saveRocket ? Saved! : null}\n      \n\nModel\n setModel(e.target.value)}\n          />\n        \n\nYear\n setYear(+e.target.value)}\n          />\n        \n\nStock\n setStock(e.target.value)}\n          />\n        \n model && year && stock && saveRocket()}>\n          Add\n        \n\n\n  );\n}\n```\n`useSubscription`\nWe can type our `useSubscription` hooks the same way we typed our `useQuery` and `useMutation` hooks. Using the generated `gql` function to define our GraphQL subscriptions, we ensure that we type our subscription variables and return data:\n```tsx\nimport React from 'react';\nimport { useSubscription } from '@apollo/client';\nimport { gql } from '../src/gql';\nconst LATEST_NEWS = gql(/ GraphQL / `subscription getLatestNews {\n    latestNews {\n      content\n    }\n  }`);\nexport function LatestNews() {\n  // our returned data is typed!\n  const { loading, data } = useSubscription(LATEST_NEWS);\n  return (\n    \nLatest News\n\n        {loading ? 'Loading...' : data!.latestNews.content}\n      \n\n  );\n}\n```\nTyping Render Prop components\nTo type render prop components, you'll first define a GraphQL query using the generated `gql` function (from `src/__generated__/gql`).\nThis creates a type for that query and its variables, which you can then pass to your `Query` component:\n```tsx\nimport { gql, AllPeopleQuery, AllPeopleQueryVariables } from '../src/generated/gql';\nconst ALL_PEOPLE_QUERY = gql(/ GraphQL / `query All_People {\n    allPeople {\n      people {\n        id\n        name\n      }\n    }\n  }`;\nconst AllPeopleComponent =  query={ALL_PEOPLE_QUERY}>\n  {({ loading, error, data }) => { ... }}\n\n```\nOur `<Query />` component's function arguments are now typed. Since we aren't mapping any props coming into our component, nor are we rewriting the props passed down, we only need to provide the shape of our data and the variables for our typing to work!\nThis approach works also works for `<Mutation />` and `<Subscription />` components.\nExtending components\nIn previous versions of Apollo Client, render prop components (`Query`, `Mutation` and `Subscription`) could be extended to add additional type information:\n`ts\nclass SomeQuery extends Query<SomeData, SomeVariables> {}`\nNow that class-based render prop components have been converted into functional components, you can no longer extend components in this manner.\nWhile we recommend switching over to using the new `useQuery`, `useMutation`, and `useSubscription` hooks as soon as possible, you can replace your class with a wrapped and typed component in the meantime:\n`tsx\nexport const SomeQuery = () => (\n  <Query<SomeData, SomeVariables> query={SOME_QUERY} /* ... */>\n    {({ loading, error, data }) => { ... }}\n  </Query>\n);`\nTyping Higher-order components\nTo type higher-order components, begin by defining your GraphQL queries with the `gql` function (from `./src/__generated__/gql`). In the below example, this generates the query and variable types (`GetCharacterQuery` and `GetCharacterQueryVariables`).\nOur wrapped component receives our query's result as props, and we'll need to tell our type system the shape these props take.\nBelow is an example of setting types for an operation using the `graphql` higher-order component:\n```tsx\nimport React from \"react\";\nimport { ChildDataProps, graphql } from \"@apollo/react-hoc\";\nimport { gql, GetCharacterQuery, GetCharacterQueryVariables } from '../src/gql';\nconst HERO_QUERY = gql(/ GraphQL / `query GetCharacter($episode: Episode!) {\n    hero(episode: $episode) {\n      name\n      id\n      friends {\n        name\n        id\n        appearsIn\n      }\n    }\n  }`);\ntype ChildProps = ChildDataProps<{}, GetCharacterQuery, GetCharacterQueryVariables>;\n// Note that the first parameter here is an empty Object, which means we're\n// not checking incoming props for type safety in this example. The next\n// example (in the \"Options\" section) shows how the type safety of incoming\n// props can be ensured.\nconst withCharacter = graphql<{}, GetCharacterQuery, GetCharacterQueryVariables, ChildProps>(HERO_QUERY, {\n  options: () => ({\n    variables: { episode: \"JEDI\" }\n  })\n});\nexport default withCharacter(({ data: { loading, hero, error } }) => {\n  if (loading) return Loading;\n  if (error) return ERROR;\n  return ...// actual component with data;\n});\n```\n\nThe following logic also works for query, mutation, and subscription higher-order components!\n\nOptions\nTypically, our wrapper component's props pass in a query's variables. Wherever our application uses our wrapper component, we want to ensure that we correctly type those passed-in arguments.\nBelow is an example of setting a type for a component's props:\n```tsx\nimport React from \"react\";\nimport { ChildDataProps, graphql } from \"@apollo/react-hoc\";\nimport { gql, GetCharacterQuery, GetCharacterQueryVariables } from '../src/gql';\nconst HERO_QUERY = gql(/ GraphQL / `query GetCharacter($episode: Episode!) {\n    hero(episode: $episode) {\n      name\n      id\n      friends {\n        name\n        id\n        appearsIn\n      }\n    }\n  }`);\ntype ChildProps = ChildDataProps;\nconst withCharacter = graphql<\n  GetCharacterQueryVariables,\n  GetCharacterQuery,\n  GetCharacterQueryVariables,\n  ChildProps\n\n(HERO_QUERY, {\n  // highlight-start\n  options: ({ episode }) => ({\n    variables: { episode }\n  }),\n  // highlight-end\n});\n\nexport default withCharacter(({ data: { loading, hero, error } }) => {\n  if (loading) return Loading;\n  if (error) return ERROR;\n  return ...// actual component with data;\n});\n```\nThis is especially helpful when accessing deeply nested objects passed to our component via props. For example, when adding prop types, a project using TypeScript begins to surface errors with invalid props:\n```tsx\nimport React from \"react\";\nimport {\n  ApolloClient,\n  createHttpLink,\n  InMemoryCache,\n  ApolloProvider\n} from \"@apollo/client\";\nimport Character from \"./Character\";\nexport const link = createHttpLink({\n  uri: \"https://mpjk0plp9.lp.gql.zone/graphql\"\n});\nexport const client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link,\n});\nexport default () =>\n  \n    // $ExpectError property `episode`. Property not found in. See: src/Character.js:43\n    \n;\n```\nProps\nThe `props` function enables you to manually reshape an operation result's data into the shape your wrapped component requires:\n```tsx\nimport React from \"react\";\nimport { graphql, ChildDataProps } from \"@apollo/react-hoc\";\nimport { gql, GetCharacterQuery, GetCharacterQueryVariables } from '../src/gql';\nconst HERO_QUERY = gql(/ GraphQL / `query GetCharacter($episode: Episode!) {\n    hero(episode: $episode) {\n      name\n      id\n      friends {\n        name\n        id\n        appearsIn\n      }\n    }\n  }`);\ntype ChildProps = ChildDataProps;\nconst withCharacter = graphql<\n  GetCharacterQueryVariables,\n  GetCharacterQuery,\n  GetCharacterQueryVariables,\n  ChildProps\n\n(HERO_QUERY, {\n  options: ({ episode }) => ({\n    variables: { episode }\n  }),\n  props: ({ data }) => ({ ...data }) // highlight-line\n});\n\nexport default withCharacter(({ loading, hero, error }) => {\n  if (loading) return Loading;\n  if (error) return ERROR;\n  return ...// actual component with data;\n});\n```\nAbove, we type the shape of our response, props, and our client's variables. Our options and props function (within the `graphql` wrapper) are now type-safe, our rendered component is protected, and our tree of components has their required props enforced:\n```ts\nexport const withCharacter = graphql<\n  GetCharacterQueryVariables,\n  GetCharacterQuery,\n  GetCharacterQueryVariables,\n  Props\n\n(HERO_QUERY, {\n  options: ({ episode }) => ({\n    variables: { episode }\n  }),\n  props: ({ data, ownProps }) => ({\n    ...data,\n    // $ExpectError [string] This type cannot be compared to number\n    episode: ownProps.episode > 1,\n    // $ExpectError property `isHero`. Property not found on object type\n    isHero: data && data.hero && data.hero.isHero\n  })\n});\n```\n\nClasses vs functions\nIf you are using React classes (instead of using the `graphql` wrapper), you can still type the incoming props for your class like so:\n```tsx\nimport { ChildProps } from \"@apollo/react-hoc\";\nconst withCharacter = graphql(HERO_QUERY, {\n  options: ({ episode }) => ({\n    variables: { episode }\n  })\n});\nclass Character extends React.Component, {}> {\n  render(){\n    const { loading, hero, error } = this.props.data;\n    if (loading) return Loading;\n    if (error) return ERROR;\n    return ...// actual component with data;\n  }\n}\nexport default withCharacter(Character);\n```\nUsing the `name` property\nIf you are using the `name` property in the configuration of the `graphql` wrapper, you need to manually attach the type of the response to the `props` function, like so:\n```ts\nimport { NamedProps, QueryProps } from '@apollo/react-hoc';\nexport const withCharacter = graphql(HERO_QUERY, {\n  name: 'character', // highlight-line\n  props: ({ character, ownProps }: NamedProps<{ character: QueryProps & GetCharacterQuery }, Props) => ({\n    ...character,\n    // $ExpectError [string] This type cannot be compared to number\n    episode: ownProps.episode > 1,\n    // $ExpectError property `isHero`. Property not found on object type\n    isHero: character && character.hero && character.hero.isHero\n  })\n});\n```\nUsing `TypedDocumentNode`\nIn TypeScript, all APIs that intake `DocumentNode` can alternatively take `TypedDocumentNode<Data, Variables>`. This type has the same JavaScript representation but enables APIs to infer the data and variable types (instead of making you specify types upon invocation).\nThis technique enables us to modify the useQuery example above to use a type inference:\n```tsx\nimport React from 'react';\nimport { useQuery, gql, TypedDocumentNode } from '@apollo/client';\ninterface RocketInventoryData {\n  rocketInventory: RocketInventory[];\n}\ninterface RocketInventoryVars {\n  year: number;\n}\nconst GET_ROCKET_INVENTORY: TypedDocumentNode = gql`query GetRocketInventory($year: Int!) {\n    rocketInventory(year: $year) {\n      id\n      model\n      year\n      stock\n    }\n  }`;\nexport function RocketInventoryList() {\n  const { loading, data } = useQuery(\n    GET_ROCKET_INVENTORY,\n    { variables: { year: 2019 } }\n  );\n  return (\n    \nAvailable Inventory\n      {loading ? (\n        Loading ...\n      ) : (\n        \n\n\nModel\nStock\n\n\n\n            {data && data.rocketInventory.map(inventory => (\n              \n{inventory.model}\n{inventory.stock}\n\n            ))}\n          \n\n      )}\n    \n  );\n}",
    "tag": "apollo-client"
  },
  {
    "title": "GraphOS and Apollo Studio",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/development-testing/developer-tooling.md",
    "content": "\ntitle: Developer tools\ndescription: Improve your developer experience with these services and extensions\n\nGraphOS and Apollo Studio\nGraphOS is Apollo's all-purpose platform for growing and collaborating on your graph. Apollo Studio is the web interface for GraphOS, which provides helpful views into your graph's usage and performance.\nAmong others, these GraphOS features are available to all Apollo users for free:\n\nThe Explorer, a powerful GraphQL IDE that connects to all your environments and provides ergonomic ways to author and manage queries.\nA GraphQL schema registry that tracks the evolution of your graph across your environments.\nKey insights into which parts of your schema are being actively used, and by whom.\nTeam collaboration via organizations\n\nTo learn more about GraphOS, check out the overview.\nApollo Client Devtools\nThe Apollo Client Devtools are available as an extension for Chrome and Firefox.\nFeatures\nThe Apollo Client Devtools appear as an \"Apollo\" tab in your web browser's Inspector panel, alongside default tabs like \"Console\" and \"Network\". The devtools currently have four main features:\n\nGraphiQL: Send queries to your server through your web application's configured Apollo Client instance, or query the Apollo Client cache to see what data is loaded.\nWatched query inspector: View active queries, variables, and cached results, and re-run individual queries.\nMutation inspector: View active mutations and their variables, and re-run individual mutations.\nCache inspector: Visualize the Apollo Client cache and search it by field name and/or value.\n\n\nInstallation\nYou can install the extension via the webstores for Chrome and Firefox.\nConfiguration\nWhile your app is in dev mode, the Apollo Client Devtools will appear as an \"Apollo\" tab in your web browser inspector. To enable the devtools in your app in production, pass `connectToDevTools: true` to the `ApolloClient` constructor in your app. Pass `connectToDevTools: false` if want to manually disable this functionality.",
    "tag": "apollo-client"
  },
  {
    "title": "Example application",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/integrations/react-native.md",
    "content": "\ntitle: Integrating with React Native\nYou can use Apollo Client with React Native exactly as you do with React.js. Install it with `npm` like so:\n`bash\nnpm install @apollo/client graphql`\nThen wrap your application in the `ApolloProvider` component, like so:\n```jsx\nimport React from 'react';\nimport { AppRegistry } from 'react-native';\nimport { ApolloClient, InMemoryCache, ApolloProvider } from '@apollo/client';\n// Initialize Apollo Client\nconst client = new ApolloClient({\n  uri: 'localhost:4000/graphql',\n  cache: new InMemoryCache()\n});\nconst App = () => (\n  \n\n\n);\nAppRegistry.registerComponent('MyApplication', () => App);\n```\nFor more information on setting up Apollo Client, see Getting started.\nExample application\nThis sample application maintained by The GraphQL Guide uses Apollo Client with React Native.\nApollo Client Devtools\nReact Native Debugger supports the Apollo Client Devtools:\n\nInstall React Native Debugger and open it.\nEnable \"Debug JS Remotely\" in your app.\n",
    "tag": "apollo-client"
  },
  {
    "title": "React",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/integrations/integrations.md",
    "content": "\ntitle: View integrations\ndescription: How to use Apollo Client with the view layer your application is developed in!\n\nReact\nApollo Client's built-in React support allows you to fetch data from your GraphQL server and use it in building complex and reactive UIs using the React framework. Apollo Client may be used in any context that React may be used. In the browser, in React Native, or in Node.js when you want to server side render.\nApollo Client, unlike some other tools in the React ecosystem, requires no complex build setup to get up and running. As long as you have a GraphQL server you can get started building out your application with React immediately. Apollo Client's React functionality works out of the box with both create-react-app and React Native with a single install and with no extra hassle configuring Babel or other JavaScript tools.\nVue\nA Vue.js integration is maintained by Guillaume Chau (@Akryum). See the Github repository for more details.\nSvelte\nA Svelte integration is maintained by Tim Hall (@timhall). See the Github repository for more details.\nAngular\nAn Angular integration is maintained by Kamil Kisiela (@kamilkisiela). See the website for more details.\nSolidjs\nA Solid.js integration is maintained by (@Torsten85). See the Github repository for more details.\nEmber\nAn Ember integration is maintained by Josemar Luedke (@josemarluedke). See the Github repository for more details. The creator of the project is Blake Gentry (@bgentry).\nWeb Components\nWeb components are the browser-built-in component APIs. They are defined in a framework-agnostic way, using either vanilla JS or libraries like lit-element or hybrids.\n\napollo-elements includes support for `lit-element`, `gluon`, `hybrids`, and `polymer`, as well as providing class mixin functions so you can integrate Apollo into vanilla elements or any other web component library. Apollo Elements is maintained by Benny Powers (@bennypowers).\n",
    "tag": "apollo-client"
  },
  {
    "title": "Jest",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/integrations/webpack.md",
    "content": "\ntitle: Loading queries with Webpack\nYou can load GraphQL queries over `.graphql` files using Webpack. The package `graphql-tag` comes with a loader easy to setup and with some benefits:\n\nDo not process GraphQL ASTs on client-side\nEnable queries to be separated from logic\n\nIn the example below, we create a new file called `currentUser.graphql`:\n`graphql\nquery CurrentUserForLayout {\n  currentUser {\n    login\n    avatar_url\n  }\n}`\nYou can load this file adding a rule in your webpack config file:\n`js\nmodule: {\n  rules: [\n    {\n      test: /\\.(graphql|gql)$/,\n      exclude: /node_modules/,\n      loader: 'graphql-tag/loader',\n    },\n  ],\n},`\nAs you can see, `.graphql` or `.gql` files will be parsed whenever imported:\n```js\nimport React, { Component } from 'react';\nimport { graphql } from '@apollo/react-hoc';\nimport currentUserQuery from './currentUser.graphql';\nclass Profile extends Component { ... }\nProfile.propTypes = { ... };\nexport default graphql(currentUserQuery)(Profile)\n```\nJest\nJest can't use the Webpack loaders. To make the same transformation work in Jest, use jest-transform-graphql.\nFuseBox\nFuseBox can't use the Webpack loaders. To make the same transformation work in FuseBox, use fuse-box-graphql-plugin.\nReact native\nReact native can't use the Webpack loaders. To make the same transformation work in React native, use babel-plugin-import-graphql.\nCreate-React-App\ncreate-react-app can't use the Webpack loaders unless ejected. To make the same transformation work in `create-react-app` without ejecting, use graphql.macro.\n`javascript\nimport { loader } from 'graphql.macro';\nconst currentUserQuery = loader('./currentUser.graphql');`\nFragments\nYou can use and include fragments in .graphql files and have webpack include those dependencies for you, similar to how you would use fragments and queries with the gql tag in plain JS.\n```graphql\nimport \"./UserInfoFragment.graphql\"\nquery CurrentUserForLayout {\n  currentUser {\n    ...UserInfo\n  }\n}\n```\nSee how we import the UserInfo fragment from another .graphql file (same way you'd import modules in JS).\nAnd here's an example of defining the fragment in another .graphql file.\n```graphql\nfragment UserInfo on User {\n  login\n  avatar_url\n}",
    "tag": "apollo-client"
  },
  {
    "title": "Defining",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/local-state/managing-state-with-field-policies.mdx",
    "content": "\ntitle: Local-only fields in Apollo Client\ndescription: Fetch local and remote data with one GraphQL query\n\nYour Apollo Client queries can include local-only fields that aren't defined in your GraphQL server's schema:\n`graphql {5}\nquery ProductDetails($productId: ID!) {\n  product(id: $productId) {\n    name\n    price\n    isInCart @client # This is a local-only field\n  }\n}`\nThe values for these fields are calculated locally using any logic you want, such as reading data from `localStorage`.\nAs shown, a query can include both local-only fields and fields that are fetched from your GraphQL server.\nDefining\nLet's say we're building an e-commerce application. Most of a product's details are stored on our back-end server, but we want to define a `Product.isInCart` boolean field that's local to the client. First, we create a field policy for `isInCart`.\nA field policy specifies custom logic for how a single GraphQL field is fetched from and written to your Apollo Client cache. You can define field policies for both local-only fields and remotely fetched fields.\n\nField policies are primarily documented in Customizing the behavior of cached fields. This article specifically describes how to use them with local-only fields.\n\nYou define your application's field policies in a map that you provide to the constructor of Apollo Client's `InMemoryCache`. Each field policy is a child of a particular type policy (much like the corresponding field is a child of a particular type).\nHere's a sample `InMemoryCache` constructor that defines a field policy for `Product.isInCart`:\n`js\nconst cache = new InMemoryCache({\n  typePolicies: { // Type policy map\n    Product: {\n      fields: { // Field policy map for the Product type\n        isInCart: { // Field policy for the isInCart field\n          read(_, { variables }) { // The read function for the isInCart field\n            return localStorage.getItem('CART').includes(\n              variables.productId\n            );\n          }\n        }\n      }\n    }\n  }\n});`\nThe field policy above defines a read function for the `isInCart` field. Whenever you query a field that has a `read` function, the cache calls that function to calculate the field's value. In this case, the `read` function returns whether the queried product's ID is in the `CART` array in `localStorage`.\nYou can use `read` functions to perform any sort of logic you want, including:\n\nManually executing other cache operations\nCalling helper utilities or libraries to prepare, validate, or sanitize data\nFetching data from a separate store\nLogging usage metrics\n\n\nIf you query a local-only field that doesn't define a `read` function, Apollo Client performs a default cache lookup for the field. See Storing local state in the cache for details.\n\nReads are synchronous by design\nMany UI frameworks like React (when not using `Suspense`) have synchronous rendering pipelines, therefore it's important for UI components to have immediate access to any existing data.  This is why all `read` functions are synchronous, as are the cache's `readQuery` and `readFragment` methods.  It is possible, however, to leverage reactive variables and `options.storage` to compose a `read` function that behaves in a manner that resembles an asynchronous action:\n\n`js\nnew InMemoryCache({\n  typePolicies: {\n    Person: {\n      fields: {\n        isInCart: {\n          read(_, { variables, storage }) {\n            if (!storage.var) {\n              storage.var = makeVar(false);\n              setTimeout(() => {\n                storage.var(\n                  localStorage.getItem('CART').includes(\n                    variables.productId\n                  )\n                );\n              }, 100);\n            }\n            return storage.var();\n          }\n        }\n      }\n    }\n  }\n})`\n\nQuerying\nNow that we've defined a field policy for `isInCart`, we can include the field in a query that also queries our back-end server, like so:\n`js {6}\nconst GET_PRODUCT_DETAILS = gql`\n  query ProductDetails($productId: ID!) {\n    product(id: $productId) {\n      name\n      price\n      isInCart @client\n    }\n  }\n`;`\nThat's it! The `@client` directive tells Apollo Client that `isInCart` is a local-only field. Because `isInCart` is local-only, Apollo Client omits it from the query it sends to our server to fetch `name` and `price`. The final query result is returned only after all local and remote fields are populated.\n\nNote: If you apply the `@client` directive to a field with subfields, the directive is automatically applied to all subfields.\n\n`js {6-9}\nconst GET_PRODUCT_DETAILS = gql`\n  query ProductDetails($productId: ID!) {\n    product(id: $productId) {\n      name\n      price\n      purchaseStatus @client {\n        isInCart\n        isOnWishlist\n      }\n    }\n  }\n`;`\n\n\nStoring and mutations\nYou can use Apollo Client to query and modify local state, regardless of how you store that state. Apollo Client provides a couple of optional but helpful mechanisms for representing local state:\n\nReactive variables\nThe Apollo Client cache itself\n\nIt's tempting to think of local-only mutations as being expressed similarly to other local-only fields. When using previous versions of Apollo Client, developers would define local-only mutations using `@client`. They would then use local resolvers to handle `client.mutate` / `useMutation` calls. This is no longer the case, however. For Apollo Client version >= 3 users we recommend using writeQuery, writeFragment, or reactive variables to manage local state.\nStoring and updating local state with reactive variables\nApollo Client reactive variables are great for representing local state:\n\nYou can read and modify reactive variables from anywhere in your application, without needing to use a GraphQL operation to do so.\nUnlike the Apollo Client cache, reactive variables don't enforce data normalization, which means you can store data in any format you want.\nIf a field's value depends on the value of a reactive variable, and that variable's value changes, every active query that includes the field automatically refreshes.\n\nExample\nReturning to our e-commerce application, let's say we want to fetch a list of the item IDs in a user's cart, and this list is stored locally. The query to do that looks like this:\n`js title=\"Cart.js\"\nexport const GET_CART_ITEMS = gql`\n  query GetCartItems {\n    cartItems @client\n  }\n`;`\nLet's use the `makeVar` function to initialize a reactive variable that stores our local list of cart items:\n```js {3} title=\"cache.js\"\nimport { makeVar } from '@apollo/client';\nexport const cartItemsVar = makeVar([]);\n```\nThis initializes a reactive variable with an empty array (you can pass any initial value to `makeVar`). Note that the return value of `makeVar` isn't the variable itself, but rather a function. We get the variable's current value by calling `cartItemsVar()`, and we set a new value by calling `cartItemsVar(newValue)`.\nNext, let's define the field policy for `cartItems`. As always, we pass this to the constructor of `InMemoryCache`:\n`js {5-9} title=\"cache.js\"\nexport const cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        cartItems: {\n          read() {\n            return cartItemsVar();\n          }\n        }\n      }\n    }\n  }\n});`\nThis `read` function returns the value of our reactive variable whenever `cartItems` is queried.\nNow, let's create a button component that enables the user to add a product to their cart:\n```jsx {7} title=\"AddToCartButton.js\"\nimport { cartItemsVar } from './cache';\n// ... other imports\nexport function AddToCartButton({ productId }) {\n  return (\n    \n cartItemsVar([...cartItemsVar(), productId])}>\n        Add to Cart\n      \n\n  );\n}\n```\nOn click, this button updates the value of `cartItemsVar` to append the button's associated `productId`. When this happens, Apollo Client notifies every active query that includes the `cartItems` field.\nHere's a `Cart` component that uses the `GET_CART_ITEMS` query and therefore refreshes automatically whenever the value of `cartItemsVar` changes:\n```jsx title=\"Cart.js\"\nexport const GET_CART_ITEMS = gql`\n  query GetCartItems {\n    cartItems @client\n  }\n`;\nexport function Cart() {\n  const { data, loading, error } = useQuery(GET_CART_ITEMS);\nif (loading) return ;\n  if (error) return ERROR: {error.message};\nreturn (\n    \nMy Cart\n      {data && data.cartItems.length === 0 ? (\n        No items in your cart\n      ) : (\n        \n          {data && data.cartItems.map(productId => (\n            \n          ))}\n        \n      )}\n    \n  );\n}\n```\nInstead of querying for `cartItems`, the `Cart` component can read and react to a reactive variable directly with the `useReactiveVar` hook:\n```jsx {1,4} title=\"Cart.js\"\nimport { useReactiveVar } from '@apollo/client';\nexport function Cart() {\n  const cartItems = useReactiveVar(cartItemsVar);\nreturn (\n    \nMy Cart\n      {cartItems.length === 0 ? (\n        No items in your cart\n      ) : (\n        \n          {cartItems.map(productId => (\n            \n          ))}\n        \n      )}\n    \n  );\n}\n```\nAs with the preceding `useQuery` example, whenever the `cartItemsVar` variable is updated, the `Cart` component rerenders.\n\nImportant: If you call `cartItemsVar()` instead of `useReactiveVar(cartItemsVar)` in the example above, future variable updates do not cause the `Cart` component to rerender.\n\nStoring and modifying local state in the cache\nStoring local state directly in the Apollo Client cache provides some advantages, but usually requires more code than using reactive variables:\n\nYou don't have to define a field policy for local-only fields that are present in the cache. If you query a field that doesn't define a `read` function, by default Apollo Client attempts to fetch that field's value directly from the cache.\nWhen you modify a cached field with writeQuery or writeFragment, every active query that includes the field automatically refreshes.\n\nExample\nLet's say our application defines the following query:\n`js\nconst IS_LOGGED_IN = gql`\n  query IsUserLoggedIn {\n    isLoggedIn @client\n  }\n`;`\nThe `isLoggedIn` field of this query is a local-only field. We can use the writeQuery method to write a value for this field directly to the Apollo Client cache, like so:\n`js\ncache.writeQuery({\n  query: IS_LOGGED_IN,\n  data: {\n    isLoggedIn: !!localStorage.getItem(\"token\"),\n  },\n});`\nThis writes a boolean value according to whether `localStorage` includes a `token` item, indicating an active session.\nNow our application's components can render according to the value of the `isLoggedIn` field, without our needing to define a `read` function for it:\n`js\nfunction App() {\n  const { data } = useQuery(IS_LOGGED_IN);\n  return data.isLoggedIn ? <Pages /> : <Login />;\n}`\nHere's a full example that incorporates the code blocks above:\n\n```jsx\nimport React from 'react';\nimport ReactDOM from 'react-dom';\nimport {\n  ApolloClient,\n  InMemoryCache,\n  ApolloProvider,\n  useQuery,\n  gql\n} from '@apollo/client';\nimport Pages from './pages';\nimport Login from './pages/login';\nconst cache = new InMemoryCache();\nconst client = new ApolloClient({\n  uri: 'http://localhost:4000/graphql',\n  cache\n});\nconst IS_LOGGED_IN = gql`query IsUserLoggedIn {\n    isLoggedIn @client\n  }`;\ncache.writeQuery({\n  query: IS_LOGGED_IN,\n  data: {\n    isLoggedIn: !!localStorage.getItem(\"token\"),\n  },\n});\nfunction App() {\n  const { data } = useQuery(IS_LOGGED_IN);\n  return data.isLoggedIn ?  : ;\n}\nReactDOM.render(\n  \n\n,\n  document.getElementById(\"root\"),\n);\n```\n\nNote that even if you do store local data as fields in the Apollo Client cache, you can (and probably should!) still define `read` functions for those fields. A `read` function can execute helpful custom logic, such as returning a default value if a field isn't present in the cache.\nPersisting local state across sessions\nBy default, neither a reactive variable nor the `InMemoryCache` persists its state across sessions (for example, if a user refreshes their browser). To persist this state, you need to add logic to do so.\nThe `apollo-3-cache-persist` library helps you persist and rehydrate the Apollo Client cache between sessions. For details, see Persisting the cache.\nThere is currently no built-in API for persisting reactive variables, but you can write variable values to `localStorage` (or another store) whenever they're modified, and initialize those variables with their stored value (if any) on app load.\nModifying\nThe way you modify the value of a local-only field depends on how you store that field:\n\n\nIf you're using a reactive variable, all you do is set the reactive variable's new value. Apollo Client automatically detects this change and triggers a refresh of every active operation that includes an affected field.\n\n\nIf you're using the cache directly, call one of `writeQuery`, `writeFragment`, or `cache.modify` (all documented here) to modify cached fields. Like reactive variables, all of these methods trigger a refresh of every affected active operation.\n\n\nIf you're using another storage method, such as `localStorage`, set the field's new value in whatever method you're using. Then, you can force a refresh of every affected operation by calling cache.evict. In your call, provide both the `id` of your field's containing object and the name of the local-only field.\n\n\nUsing local-only fields as GraphQL variables\nIf your GraphQL query uses variables, the local-only fields of that query can provide the values of those variables.\nTo do so, you apply the `@export(as: \"variableName\")` directive, like so:\n`js {3}\nconst GET_CURRENT_AUTHOR_POST_COUNT = gql`\n  query CurrentAuthorPostCount($authorId: Int!) {\n    currentAuthorId @client @export(as: \"authorId\")\n    postCount(authorId: $authorId)\n  }\n`;`\nIn the query above, the result of the local-only field `currentAuthorId` is used as the value of the `$authorId` variable that's passed to `postCount`.\nYou can do this even if `postCount` is also a local-only field (i.e., if it's also marked as `@client`).\nConsiderations for using `@export`\n\n\nTo use the `@export` directive, a field must also use the `@client` directive. In other words, only local-only fields can be used as variable values.\n\n\nA field that `@export`s a variable value must appear before any fields that use that variable.\n\n\nIf multiple fields in an operation use the `@export` directive to assign their value to the same variable, the field listed last takes precedence. When this happens in development mode, Apollo Client logs a warning message.\n\n\nAt first glance, the `@export` directive appears to violate the GraphQL specification's requirement that the execution order of an operation must not affect its result:\n\n\u2026the resolution of fields other than top\u2010level mutation fields must always be side effect\u2010free and idempotent, the execution order must not affect the result, and hence the server has the freedom to execute the field entries in whatever order it deems optimal.\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "Setup",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/local-state/client-side-schema.mdx",
    "content": "\ntitle: Client-side schema\ndescription: Extend your schema with client-specific fields\n\nYou can optionally provide a client-side schema to Apollo Client that defines local-only types and fields. You can define completely new types, or extend types from your server's schema with new fields.\nAs with any GraphQL schema, your client-side schema must be written in Schema Definition Language.\nThe client-side schema is not used to validate operations like it is on the server (the `graphql-js` modules for schema validation would dramatically increase your bundle size). Instead, your client-side schema is used for introspection in the Apollo Client Devtools, where you can explore your schema in GraphiQL.\nSetup\nThe following demonstrates how to define a client-side schema and provide it to the `ApolloClient` constructor:\n```js\nimport { ApolloClient, InMemoryCache, gql } from '@apollo/client';\nconst typeDefs = gql`\n  extend type Query {\n    isLoggedIn: Boolean!\n    cartItems: [Launch]!\n  }\nextend type Launch {\n    isInCart: Boolean!\n  }\nextend type Mutation {\n    addOrRemoveFromCart(id: ID!): [Launch]\n  }\n`;\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  uri: 'http://localhost:4000/graphql',\n  typeDefs,\n});\n```\nIf you open up the Apollo Client Devtools and click on the `GraphiQL` tab, you'll be able to explore your client schema in the \"Docs\" section. This example doesn't include a remote schema, but if it did, you would be able to see your local queries and mutations alongside your remote ones.",
    "tag": "apollo-client"
  },
  {
    "title": "Creating",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/local-state/reactive-variables.mdx",
    "content": "\ntitle: Reactive variables\ndescription: State containers integrated into Apollo Client's reactivity model\n\nNew in Apollo Client 3, reactive variables are a useful mechanism for representing local state outside of the Apollo Client cache. Because they're separate from the cache, reactive variables can store data of any type and structure, and you can interact with them anywhere in your application without using GraphQL syntax.\nMost importantly, modifying a reactive variable triggers an update of every active query that depends on that variable. Additionally, this updates the React state for components that use the `useReactiveVar` React hook.\n\nA query \"depends on\" a reactive variable if any of the query's requested fields defines a read function that reads the variable's value.\n\nCreating\nCreate a reactive variable with the `makeVar` method, like so:\n```js\nimport { makeVar } from '@apollo/client';\nconst cartItemsVar = makeVar([]);\n```\nThis code creates a reactive variable with an empty array as its initial value.\n\nImportant: The return value of `makeVar` is a function that you call to read or modify your reactive variable's value.\n\nReading\nTo read the value of your reactive variable, call the function returned by `makeVar` with zero arguments:\n```js\nconst cartItemsVar = makeVar([]);\n// Output: []\nconsole.log(cartItemsVar());\n```\nModifying\nTo modify the value of your reactive variable, call the function returned by `makeVar` with one argument (the variable's new value):\n```js\nconst cartItemsVar = makeVar([]);\nconst cartItemIds = [100, 101, 102];\ncartItemsVar(cartItemIds);\n// Output: [100, 101, 102]\nconsole.log(cartItemsVar());\n// Don't mutate an existing object or array.\n// cartItemIds.push(456) will not trigger an update.\n// Instead, pass a new copy:\ncartItemsVar([...cartItemIds, 456]);\n// Output: [100, 101, 102, 456]\nconsole.log(cartItemsVar());\n```\nReacting\nAs their name suggests, reactive variables can trigger reactive changes in your application. Whenever you modify the value of a reactive variable, queries that depend on that variable refresh, and your application's UI updates accordingly.\nWith the `useReactiveVar` hook, React components can also include reactive variable values in their state directly, without wrapping them in a query.\nFor more information, see Storing local state in reactive variables.\nuseReactiveVar hook\nThe `useReactiveVar` hook can be used to read from a reactive variable in a way that allows the React component to re-render if/when the variable is next updated.\nPreviously, the only way for a reactive variable to trigger a React component re-render was through the use of `useQuery`. Now you don't have to be using `useQuery` to benefit from the reactivity that `ReactiveVar<T>` provides.\n```tsx\nimport { makeVar, useReactiveVar } from \"@apollo/client\";\nexport const cartItemsVar = makeVar([]);\nexport function Cart() {\n  const cartItems = useReactiveVar(cartItemsVar);\n  // ...\n```\nExample application",
    "tag": "apollo-client"
  },
  {
    "title": "Updating local state",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/local-state/local-resolvers.mdx",
    "content": "\ntitle: Local resolvers\ndescription: Manage local data with GraphQL like resolvers\n\n\n\ud83d\udcc4 NOTE: We recommend using field policies instead of local resolvers as described in Local-only fields.\nLocal resolver support will be moved out of the core of Apollo Client in a future major release. The same or similar functionality will be available via `ApolloLink`, as described in this issue.\n\nWe've learned how to manage remote data from our GraphQL server with Apollo Client, but what should we do with our local data? We want to be able to access boolean flags and device API results from multiple components in our app, but don't want to maintain a separate Redux or MobX store. Ideally, we would like the Apollo cache to be the single source of truth for all data in our client application.\nApollo Client (>= 2.5) has built-in local state handling capabilities that allow you to store your local data inside the Apollo cache alongside your remote data. To access your local data, just query it with GraphQL. You can even request local and server data within the same query!\nIn this section, you'll learn how Apollo Client can help simplify local state management in your app. We'll cover how client-side resolvers can help us execute local queries and mutations. You'll also learn how to query and update the cache with the `@client` directive.\nPlease note that this documentation is intended to be used to familiarize yourself with Apollo Client's local state management capabilities, and serve as a reference guide. If you're looking for a step by step tutorial outlining how to handle local state with Apollo Client (and leverage other Apollo components to build a fullstack application), please refer to the full-stack quickstart course.\nUpdating local state\nThere are two main ways to perform local state mutations. The first way is to directly write to the cache by calling `cache.writeQuery`. Direct writes are great for one-off mutations that don't depend on the data that's currently in the cache, such as writing a single value. The second way is by leveraging the `useMutation` hook with a GraphQL mutation that calls a local client-side resolver. We recommend using resolvers if your mutation depends on existing values in the cache, such as adding an item to a list or toggling a boolean.\nDirect writes\nDirect writes to the cache do not require a GraphQL mutation or a resolver function. They leverage your Apollo Client instance directly by accessing the `client` property returned from the `useApolloClient` hook, made available in the `useQuery` hook result, or within the render prop function of the `ApolloConsumer` component. We recommend using this strategy for simple writes, such as writing a string, or one-off writes. It's important to note that direct writes are not implemented as GraphQL mutations under the hood, so you shouldn't include them in your schema. They also do not validate that the data you're writing to the cache is in the shape of valid GraphQL data. If either of these features are important to you, you should opt to use a local resolver instead.\n```jsx\nimport React from \"react\";\nimport { useApolloClient } from \"@apollo/client\";\nimport Link from \"./Link\";\nfunction FilterLink({ filter, children }) {\n  const client = useApolloClient();\n  return (\n     client.writeQuery({\n        query: gql`query GetVisibilityFilter { visibilityFilter }`,\n        data: { visibilityFilter: filter },\n      })}\n    >\n      {children}\n    \n  );\n}\n```\nThe `ApolloConsumer` render prop function is called with a single value, the Apollo Client instance. You can think of the `ApolloConsumer` component as being similar to the `Consumer` component from the React context API. From the client instance, you can directly call `client.writeQuery` and pass in the data you'd like to write to the cache.\nWhat if we want to immediately subscribe to the data we just wrote to the cache? Let's create an `active` property on the link that marks the link's filter as active if it's the same as the current `visibilityFilter` in the cache. To immediately subscribe to a client-side mutation, we can use `useQuery`. The `useQuery` hook also makes the client instance available in its result object.\n```jsx\nimport React from \"react\";\nimport { gql, useQuery } from \"@apollo/client\";\nimport Link from \"./Link\";\nconst GET_VISIBILITY_FILTER = gql`query GetVisibilityFilter {\n    visibilityFilter @client\n  }`;\nfunction FilterLink({ filter, children }) {\n  const { data, client } = useQuery(GET_VISIBILITY_FILTER);\n  return (\n     client.writeQuery({\n        query: GET_VISIBILITY_FILTER,\n        data: { visibilityFilter: filter },\n      })}\n      active={data.visibilityFilter === filter}\n    >\n      {children}\n    \n  )\n}\n```\nYou'll notice in our query that we have a `@client` directive next to our `visibilityFilter` field. This tells Apollo Client to fetch the field data locally (either from the cache or using a local resolver), instead of sending it to our GraphQL server. Once you call `client.writeQuery`, the query result on the render prop function will automatically update. All cache writes and reads are synchronous, so you don't have to worry about loading state.\nLocal resolvers\nIf you'd like to implement your local state update as a GraphQL mutation, then you'll need to specify a function in your local resolver map. The resolver map is an object with resolver functions for each GraphQL object type. To visualize how this all lines up, it's useful to think of a GraphQL query or mutation as a tree of function calls for each field. These function calls resolve to data or another function call. So when a GraphQL query is run through Apollo Client, it looks for a way to essentially run functions for each field in the query. When it finds an `@client` directive on a field, it turns to its internal resolver map looking for a function it can run for that field.\nTo help make local resolvers more flexible, the signature of a resolver function is the exact same as resolver functions on the server built with Apollo Server. Let's recap the four parameters of a resolver function:\n`js\nfieldName: (obj, args, context, info) => result;`\n\n`obj`: The object containing the result returned from the resolver on the parent field or the `ROOT_QUERY` object in the case of a top-level query or mutation.\n`args`: An object containing all of the arguments passed into the field. For example, if you called a mutation with `updateNetworkStatus(isConnected: true)`, the `args` object would be `{ isConnected: true }`.\n`context`: An object of contextual information shared between your React components and your Apollo Client network stack. In addition to any custom context properties that may be present, local resolvers always receive the following:\n`context.client`: The Apollo Client instance.\n`context.cache`: The Apollo Cache instance, which can be used to manipulate the cache with `context.cache.readQuery`, `.writeQuery`, `.readFragment`, `.writeFragment`, `.modify`, and `.evict`. You can learn more about these methods in Managing the cache.\n`context.getCacheKey`: Get a key from the cache using a `__typename` and `id`.\n\n\n`info`: Information about the execution state of the query. You will probably never have to use this one.\n\nLet's take a look at an example of a resolver where we toggle a todo's completed status:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  resolvers: {\n    Mutation: {\n      toggleTodo: (_root, variables, { cache }) => {\n        cache.modify({\n          id: cache.identify({\n            __typename: 'TodoItem',\n            id: variables.id,\n          }),\n          fields: {\n            completed: value => !value,\n          },\n        });\n        return null;\n      },\n    },\n  },\n});\n```\nIn previous versions of Apollo Client, toggling the `completed` status of the `TodoItem` required reading a fragment from the cache, modifying the result by negating the `completed` boolean, and then writing the fragment back into the cache. Apollo Client 3.0 introduced the `cache.modify` method as an easier and faster way to update specific fields within a given entity object. To determine the ID of the entity, we pass the `__typename` and primary key fields of the object to `cache.identify` method.\nOnce we toggle the `completed` field, since we don't plan on using the mutation's return result in our UI, we return `null` since all GraphQL types are nullable by default.\nLet's learn how to trigger our `toggleTodo` mutation from our component:\n```jsx\nimport React from \"react\"\nimport { gql, useMutation } from \"@apollo/client\";\nconst TOGGLE_TODO = gql`mutation ToggleTodo($id: Int!) {\n    toggleTodo(id: $id) @client\n  }`;\nfunction Todo({ id, completed, text }) {\n  const [toggleTodo] = useMutation(TOGGLE_TODO, { variables: { id } });\n  return (\n    \n      {text}\n    \n  );\n}\n```\nFirst, we create a GraphQL mutation that takes the todo's id we want to toggle as its only argument. We indicate that this is a local mutation by marking the field with a `@client` directive. This will tell Apollo Client to call our local `toggleTodo` mutation resolver in order to resolve the field. Then, we create a component with `useMutation` just as we would for a remote mutation. Finally, pass in your GraphQL mutation to your component and trigger it from within the UI in your render prop function.\nQuerying local state\nQuerying for local data is very similar to querying your GraphQL server. The only difference is that you add a `@client` directive on your local fields to indicate they should be resolved from the Apollo Client cache or a local resolver function. Let's look at an example:\n```jsx\nimport React from \"react\";\nimport { gql, useQuery } from \"@apollo/client\";\nimport Todo from \"./Todo\";\nconst GET_TODOS = gql`query GetTodos {\n    todos @client {\n      id\n      completed\n      text\n    }\n    visibilityFilter @client\n  }`;\nfunction TodoList() {\n  const { data: { todos, visibilityFilter } } = useQuery(GET_TODOS);\n  return (\n    \n      {getVisibleTodos(todos, visibilityFilter).map(todo => (\n        \n      ))}\n    \n  );\n}\n```\nHere we create our GraphQL query and add `@client` directives to `todos` and `visibilityFilter`. We then pass the query to the `useQuery` hook. The `@client` directives here let `useQuery` component know that `todos` and `visibilityFilter` should be pulled from the Apollo Client cache or resolved using pre-defined local resolvers. The following sections help explain how both options work in more detail.\n\n\u26a0\ufe0f Since the above query runs as soon as the component is mounted, what do we do if there are no todos in the cache or there aren't any local resolvers defined to help calculate `todos`? We need to write an initial state to the cache before the query is run to prevent it from erroring out. Refer to the Initializing the cache section below for more information.\n\nInitializing the cache\nOften, you'll need to write an initial state to the cache so any components querying data before a mutation is triggered don't error out. To accomplish this, you can use `cache.writeQuery` to prep the cache with initial values.\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst cache = new InMemoryCache();\nconst client = new ApolloClient({\n  cache,\n  resolvers: { / ... / },\n});\ncache.writeQuery({\n  query: gql`query GetTodosNetworkStatusAndFilter {\n      todos\n      visibilityFilter\n      networkStatus {\n        isConnected\n      }\n    }`,\n  data: {\n    todos: [],\n    visibilityFilter: 'SHOW_ALL',\n    networkStatus: {\n      __typename: 'NetworkStatus',\n      isConnected: false,\n    },\n  },\n});\n```\nSometimes you may need to reset the store in your application, when a user logs out for example. If you call `client.resetStore` anywhere in your application, you will likely want to initialize your cache again. You can do this using the `client.onResetStore` method to register a callback that will call `cache.writeQuery` again.\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst cache = new InMemoryCache();\nconst client = new ApolloClient({\n  cache,\n  resolvers: { / ... / },\n});\nfunction writeInitialData() {\n  cache.writeQuery({\n    query: gql`query GetTodosNetworkStatusAndFilter {\n        todos\n        visibilityFilter\n        networkStatus {\n          isConnected\n        }\n      }`,\n    data: {\n      todos: [],\n      visibilityFilter: 'SHOW_ALL',\n      networkStatus: {\n        __typename: 'NetworkStatus',\n        isConnected: false,\n      },\n    },\n  });\n}\nwriteInitialData();\nclient.onResetStore(writeInitialData);\n```\nLocal data query flow\nWhen a query containing `@client` directives is executed, Apollo Client runs through a few sequential steps to try to find a result for the `@client` field. Let's use the following query to walk through the local data look up flow:\n`js\nconst GET_LAUNCH_DETAILS = gql`\n  query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      isInCart @client\n      site\n      rocket {\n        type\n      }\n    }\n  }\n`;`\nThis query includes a mixture of both remote and local fields. `isInCart` is the only field marked with an `@client` directive, so it's the field we'll focus on. When Apollo Client executes this query and tries to find a result for the `isInCart` field, it runs through the following steps:\n\nHas a resolver function been set (either through the `ApolloClient` constructor `resolvers` parameter or Apollo Client's `setResolvers` / `addResolvers` methods) that is associated with the field name `isInCart`? If yes, run and return the result from the resolver function.\nIf a matching resolver function can't be found, check the Apollo Client cache to see if a `isInCart` value can be found directly. If so, return that value.\n\nLet's look at both of these steps more closely.\n\nResolving `@client` data with the help of local resolvers (step 1 above) is explained in [Handling `@client` fields with resolvers][].\nLoading `@client` data from the cache (step 2 above) is explained in Handling @client fields with the cache.\n\nHandling `@client` fields with resolvers\nLocal resolvers are very similar to remote resolvers. Instead of sending your GraphQL query to a remote GraphQL endpoint, which then runs resolver functions against your query to populate and return a result set, Apollo Client runs locally defined resolver functions against any fields marked with the `@client` directive. Let's look at an example:\n```js\nimport { ApolloClient, InMemoryCache, HttpLink, gql } from '@apollo/client';\nconst GET_CART_ITEMS = gql`query GetCartItems {\n    cartItems @client\n  }`;\nconst cache = new InMemoryCache();\ncache.writeQuery({\n  query: GET_CART_ITEMS,\n  data: {\n    cartItems: [],\n  },\n});\nconst client = new ApolloClient({\n  cache,\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql',\n  }),\n  resolvers: {\n    Launch: {\n      isInCart: (launch, _args, { cache }) => {\n        const { cartItems } = cache.readQuery({ query: GET_CART_ITEMS });\n        return cartItems.includes(launch.id);\n      },\n    },\n  },\n});\nconst GET_LAUNCH_DETAILS = gql`query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      isInCart @client\n      site\n      rocket {\n        type\n      }\n    }\n  }`;\n// ... run the query using client.query, a  component, etc.\n```\nHere when the `GET_LAUNCH_DETAILS` query is executed, Apollo Client looks for a local resolver associated with the `isInCart` field. Since we've defined a local resolver for the `isInCart` field in the `ApolloClient` constructor, it finds a resolver it can use. This resolver function is run, then the result is calculated and merged in with the rest of the query result (if a local resolver can't be found, Apollo Client will check the cache for a matching field - see Local data query flow for more details).\nSetting resolvers through `ApolloClient`'s constructor `resolvers` parameter, or through its `setResolvers` / `addResolvers` methods, adds resolvers to Apollo Client's internal resolver map (refer to the Local resolvers section for more details concerning the resolver map). In the above example we added a  `isInCart` resolver, for the `Launch` GraphQL object type, to the resolver map. Let's look at the `isInCart` resolver function more closely:\n`js\n  resolvers: {\n    Launch: {\n      isInCart: (launch, _args, { cache }) => {\n        const { cartItems } = cache.readQuery({ query: GET_CART_ITEMS });\n        return cartItems.includes(launch.id);\n      },\n    },\n  },`\n`launch` holds the data returned from the server for the rest of the query, which means in this case we can use `launch` to get the current launch `id`. We aren't using any arguments in this resolver, so we can skip the second resolver parameter. From the `context` however (the third parameter), we're using the `cache` reference, to work directly with the cache ourselves. So in this resolver, we're making a call directly to the cache to get all cart items, checking to see if any of those loaded cart items matches the parent  `launch.id`, and returning `true` / `false` accordingly. The returned boolean is then incorporated back into the result of running the original query.\nJust like resolvers on the server, local resolvers are extremely flexible. They can be used to perform any kind of local computation you want, before returning a result for the specified field. You can manually query (or write to) the cache in different ways, call other helper utilities or libraries to prep/validate/clean data, track statistics, call into other data stores to prep a result, etc.\nIntegrating `@client` into remote queries\nWhile Apollo Client\u2019s local state handling features can be used to work with local state exclusively, most Apollo based applications are built to work with remote data sources. To address this, Apollo Client supports mixing `@client` based local resolvers with remote queries, as well as using `@client` based fields as arguments to remote queries, in the same request.\nThe `@client` directive can be used on any GraphQL selection set or field, to identify that the result of that field should be loaded locally with the help of a local resolver:\n```js\nimport { ApolloClient, InMemoryCache, HttpLink, gql } from '@apollo/client';\nconst MEMBER_DETAILS = gql`query Member {\n    member {\n      name\n      role\n      isLoggedIn @client\n    }\n  }`;\nconst client = new ApolloClient({\n  link: new HttpLink({ uri: 'http://localhost:4000/graphql' }),\n  cache: new InMemoryCache(),\n  resolvers: {\n    Member: {\n      isLoggedIn() {\n        return someInternalLoginVerificationFunction();\n      }\n    }\n  },\n});\n// ... run the query using client.query, the  component, etc.\n```\nWhen the above `MEMBER_DETAILS` query is fired by Apollo Client (assuming we're talking to a network based GraphQL API), the `@client` `isLoggedIn` field is first stripped from the document, and the remaining query is sent over the network to the GraphQL API. After the query has been handled by the remote resolvers and the result is passed back to Apollo Client from the API, the `@client` parts of the original query are then run against any defined local resolvers, their results are merged with the network results, and the final resulting data is returned as the response to the original operation. So in the above example, `isLoggedIn` is stripped before the rest of the query is sent and handled by the network API, then when the results come back `isLoggedIn` is calculated by running the `isLoggedIn()` function from the resolver map. Local and network results are merged together, and the final response is made available to the application.\nThe `@client` directive can be used with entire selection sets as well:\n```js\nimport { ApolloClient, InMemoryCache, HttpLink, gql } from '@apollo/client';\nconst MEMBER_DETAILS = gql`query Member {\n    member {\n      name\n      role\n      session @client {\n        isLoggedIn\n        connectionCount\n        errors\n      }\n    }\n  }`;\nconst client = new ApolloClient({\n  link: new HttpLink({ uri: 'http://localhost:4000/graphql' }),\n  cache: new InMemoryCache(),\n  resolvers: {\n    Member: {\n      session() {\n        return {\n          __typename: 'Session',\n          isLoggedIn: someInternalLoginVerificationFunction(),\n          connectionCount: calculateOpenConnections(),\n          errors: sessionError(),\n        };\n      }\n    }\n  },\n});\n```\nApollo Client supports the merging of local `@client` results and remote results for Queries, Mutations and Subscriptions.\nAsync local resolvers\nApollo Client supports asynchronous local resolver functions. These functions can either be `async` functions or ordinary functions that return a `Promise`. Asynchronous resolvers are useful when they need to return data from an asynchronous API.\n\n\u26a0\ufe0f If you would like to hit a REST endpoint from your resolver, we recommend checking out apollo-link-rest instead, which is a more complete solution for using REST endpoints with Apollo Client.\n\nFor React Native and most browser APIs, you should set up a listener in a component lifecycle method and pass in your mutation trigger function as the callback instead of using an async resolver. However, an `async` resolver function is often the most convenient way to consume asynchronous device APIs:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nimport { CameraRoll } from 'react-native';\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  resolvers: {\n    Query: {\n      async cameraRoll(_, { assetType }) {\n        try {\n          const media = await CameraRoll.getPhotos({\n            first: 20,\n            assetType,\n          });\n\n\n```      return {\n        ...media,\n        id: assetType,\n        __typename: 'CameraRoll',\n      };\n    } catch (e) {\n      console.error(e);\n      return null;\n    }\n  },\n},\n```\n\n\n},\n});\n```\nCameraRoll.getPhotos() returns a `Promise` resolving to an object with an `edges` property, which is an array of camera node objects, and a `page_info` property, which is an object with pagination information. This is a great use case for GraphQL, since we can filter down the return value to only the data that our components consume.\n```js\nimport { gql } from \"@apollo/client\";\nconst GET_PHOTOS = gql`query GetPhotos($assetType: String!) {\n    cameraRoll(assetType: $assetType) @client {\n      id\n      edges {\n        node {\n          image {\n            uri\n          }\n          location {\n            latitude\n            longitude\n          }\n        }\n      }\n    }\n  }`;\n```\nHandling `@client` fields with the cache\nAs outlined in [Handling `@client` fields with resolvers][], `@client` fields can be resolved with the help of local resolver functions. However, it's important to note that local resolvers are not always required when using an `@client` directive. Fields marked with `@client` can still be resolved locally, by pulling matching values out of the cache directly. For example:\n```jsx\nimport React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport {\n  ApolloClient,\n  InMemoryCache,\n  HttpLink,\n  ApolloProvider,\n  useQuery,\n  gql\n} from \"@apollo/client\";\nimport Pages from \"./pages\";\nimport Login from \"./pages/login\";\nconst cache = new InMemoryCache();\nconst client = new ApolloClient({\n  cache,\n  link: new HttpLink({ uri: \"http://localhost:4000/graphql\" }),\n  resolvers: {},\n});\nconst IS_LOGGED_IN = gql`query IsUserLoggedIn {\n    isLoggedIn @client\n  }`;\ncache.writeQuery({\n  query: IS_LOGGED_IN,\n  data: {\n    isLoggedIn: !!localStorage.getItem(\"token\"),\n  },\n});\nfunction App() {\n  const { data } = useQuery(IS_LOGGED_IN);\n  return data.isLoggedIn ?  : ;\n}\nReactDOM.render(\n  \n\n,\n  document.getElementById(\"root\"),\n);\n```\nIn the above example, we first prep the cache using `cache.writeQuery` to store a value for the `isLoggedIn` field. We then run the `IS_LOGGED_IN` query via an Apollo Client `useQuery` hook, which includes an `@client` directive. When Apollo Client executes the `IS_LOGGED_IN` query, it first looks for a local resolver that can be used to handle the `@client` field. When it can't find one, it falls back on trying to pull the specified field out of the cache. So in this case, the `data` value returned by the `useQuery` hook has a `isLoggedIn` property available, which includes the `isLoggedIn` result (`!!localStorage.getItem('token')`) pulled directly from the cache.\n\n\u26a0\ufe0f If you want to use Apollo Client's `@client` support to query the cache without using local resolvers, you must pass an empty object into the `ApolloClient` constructor `resolvers` option. Without this Apollo Client will not enable its integrated `@client` support, which means your `@client` based queries will be passed to the Apollo Client link chain. You can find more details about why this is necessary here.\n\nPulling `@client` field values directly out of the cache isn't quite as flexible as local resolver functions, since local resolvers can perform extra computations before returning a result. Depending on your application's needs however, loading `@client` fields directly from the cache might be a simpler option. Apollo Client doesn't restrict combining both approaches, so feel free to mix and match. If the need arises, you can pull some `@client` values from the cache, and resolve others with local resolvers, all in the same query.\nWorking with fetch policies\nBefore Apollo Client executes a query, one of the first things it does is check to see which fetchPolicy it has been configured to use. It does this so it knows where it should attempt to resolve the query from first, either the cache or the network. When running a query, Apollo Client treats `@client` based local resolvers just like it does remote resolvers, in that it will adhere to its defined `fetchPolicy` to know where to attempt to pull data from first. When working with local resolvers, it's important to understand how fetch policies impact the running of resolver functions, since by default local resolver functions are not run on every request. This is because the result of running a local resolver is cached with the rest of the query result, and pulled from the cache on the next request. Let's look at an example:\n```jsx\nimport React, { Fragment } from \"react\";\nimport { useQuery, gql } from \"@apollo/client\";\nimport { Loading, Header, LaunchDetail } from \"../components\";\nimport { ActionButton } from \"../containers\";\nexport const GET_LAUNCH_DETAILS = gql`query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      isInCart @client\n      site\n      rocket {\n        type\n      }\n    }\n  }`;\nexport default function Launch({ launchId }) {\n  const { loading, error, data } = useQuery(\n    GET_LAUNCH_DETAILS,\n    { variables: { launchId } }\n  );\nif (loading) return ;\n  if (error) return ERROR: {error.message};\nreturn (\n    \n\n        {data.launch.mission.name}\n      \n\n\n\n  );\n}\n```\nIn the above example we're using an Apollo Client `useQuery` hook to run the `GET_LAUNCH_DETAILS` query. The `@client` based `isInCart` field is configured to pull its data from the following resolver:\n```js\nimport { GET_CART_ITEMS } from './pages/cart';\nexport const resolvers = {\n  Launch: {\n    isInCart: (launch, _, { cache }) => {\n      const { cartItems } = cache.readQuery({ query: GET_CART_ITEMS });\n      return cartItems.includes(launch.id);\n    },\n  },\n};\n```\nLet's assume we're starting with an empty cache. Since we haven't specified a `fetchPolicy` prop in our `useQuery` call, we're using Apollo Client's default `cache-first` `fetchPolicy`. This means when the `GET_LAUNCH_DETAILS` query is run, it checks the cache first to see if it can find a result. It's important to note that when the cache is checked the entire query is run against the cache, but any `@client` associated local resolvers are skipped (not run). So the cache is queried with the following (it's as if the `@client` directive was never specified):\n`graphql\nlaunch(id: $launchId) {\n  isInCart\n  site\n  rocket {\n    type\n  }\n}`\nIn this case a result can't be extracted from the cache (since our cache is empty), so behind the scenes Apollo Client moves further down the query execution path. At its next step, it essentially splits the original query into two parts - the part that has `@client` fields and the part that will be fired over the network. Both parts are then executed - results are fetched from the network, and results are calculated by running local resolvers. The results from the local resolvers and from the network are then merged together, and the final result is written to the cache and returned. So after our first run, we now have a result in the cache for the original query, that includes data for both the `@client` parts and network parts of the query.\nWhen the `GET_LAUNCH_DETAILS` query is run a second time, again since we're using Apollo Client's default `fetchPolicy` of `cache-first`, the cache is checked first for a result. This time a full result can be found for the query, so that result is returned through our `useQuery` call. Our `@client` field local resolvers aren't fired since the result we're looking for can already be extracted from the cache.\nIn a lot of situations treating local resolvers just like remote resolvers, by having them adhere to the same `fetchPolicy`, makes a lot of sense. Once you have the data you're looking for, which might have been fetched remotely or calculated using a local resolver, you can cache it and avoid recalculating/re-fetching it again on a subsequent request. But what if you're using local resolvers to run calculations that you need fired on every request? There are a few different ways this can be handled. You can switch your query to use a `fetchPolicy` that forces your entire query to run on each request, like `no-cache` or `network-only`. This will make sure your local resolvers fire on every request, but it will also make sure your network based query components fire on every request. Depending on your use case this might be okay, but what if you want the network parts of your query to leverage the cache, and just want your `@client` parts to run on every request? We'll cover a more flexible option for this in the Forcing resolvers with @client(always: true) section.\nForcing resolvers with `@client(always: true)`\nApollo Client leverages its cache to help reduce the network overhead required when constantly making requests for the same data. By default, `@client` based fields leverage the cache in the exact same manner as remote fields. After a local resolver is run, its result is cached alongside any remote results. This way the next time a query is fired that can find its results in the cache, those results are used, and any associated local resolvers are not fired again (until the data is either removed from the cache or the query is updated to use a `no-cache` or `network-only` `fetchPolicy`).\nWhile leveraging the cache for both local and remote results can be super helpful in a lot of cases, it's not always the best fit. We might want to use a local resolver to calculate a dynamic value that needs to be refreshed on every request, while at the same time continue to use the cache for the network based parts of our query. To support this use case, Apollo Client's `@client` directive accepts an `always` argument, that when set to `true` will ensure that the associated local resolver is run on every request. Looking at an example:\n```jsx\nimport { ApolloClient, InMemoryCache, gql } from '@apollo/client';\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  resolvers: {\n    Query: {\n      isLoggedIn() {\n        return !!localStorage.getItem('token');\n      },\n    },\n  },\n});\nconst IS_LOGGED_IN = gql`query IsUserLoggedIn {\n    isLoggedIn @client(always: true)\n  }`;\n// ... run the query using client.query, a  component, etc.\n```\nThe `isLoggedIn` resolver above is checking to see if an authentication token exists in `localStorage`. In this example, we want to make sure that every time the `IS_LOGGED_IN` query is executed, the `isLoggedIn` local resolver is also fired, so that we have the most up to date login information. To do this, we're using a `@client(always: true)` directive in the query, for the `isLoggedIn` field. If we didn't include `always: true`, then the local resolver would fire based on the queries `fetchPolicy`, which means we could be getting back a cached value for `isLoggedIn`. Using `@client(always: true)` ensures that we're always getting the direct result of running the associated local resolver.\n\n\u26a0\ufe0f Please consider the impact of using `@client(always: true)` carefully. While forcing a local resolver to run on every request can be useful, if that resolver is computationally expensive or has side effects, you could be negatively impacting your application. We recommend leveraging the cache as much as possible when using local resolvers, to help with application performance. `@client(always: true)` is helpful to have in your tool-belt, but letting local resolvers adhere to a query `fetchPolicy` should be the preferred choice.\n\nWhile `@client(always: true)` ensures that a local resolver is always fired, it's important to note that if a query is using a `fetchPolicy` that leverages the cache first (`cache-first`, `cache-and-network`, `cache-only`), the query is still attempted to be resolved from the cache first, before the local resolver is fired.    This happens because `@client(always: true)` use could be mixed with normal `@client` use in the same query, which means we want part of the query to adhere to the defined `fetchPolicy`. The benefit of this is that anything that can be loaded from the cache first is made available to your `@client(always: true)` resolver function, as its first parameter. So even though you've used `@client(always: true)` to identify that you want to always run a specific resolver, within that resolver you can look at the loaded cache values for the query, and decide if you want to proceed with running the resolver.\nUsing `@client` fields as variables\nApollo Client provides a way to use an `@client` field result as a variable for a selection set or field, in the same operation. So instead of running an `@client` based query first, getting the local result, then running a second query using the loaded local result as a variable, everything can be handled in one request. This is achieved by combining the `@client` directive with the `@export(as: \"variableName\")` directive:\n```js\nimport { ApolloClient, InMemoryCache, HttpLink, gql } from '@apollo/client';\nconst query = gql`query CurrentAuthorPostCount($authorId: Int!) {\n    currentAuthorId @client @export(as: \"authorId\")\n    postCount(authorId: $authorId)\n  }`;\nconst cache = new InMemoryCache();\nconst client = new ApolloClient({\n  link: new HttpLink({ uri: 'http://localhost:4000/graphql' }),\n  cache,\n  resolvers: {},\n});\ncache.writeQuery({\n  query: gql`query GetCurrentAuthorId { currentAuthorId }`,\n  data: {\n    currentAuthorId: 12345,\n  },\n});\n// ... run the query using client.query, the  component, etc.\n```\nIn the example above, `currentAuthorId` is first loaded from the cache, then passed into the subsequent  `postCount` field as the `authorId` variable (specified by the `@export(as: \"authorId\")` directive). The `@export` directive can also be used on specific fields within a selection set, like:\n```js\nimport { ApolloClient, InMemoryCache, HttpLink, gql } from '@apollo/client';\nconst query = gql`query CurrentAuthorPostCount($authorId: Int!) {\n    currentAuthor @client {\n      name\n      authorId @export(as: \"authorId\")\n    }\n    postCount(authorId: $authorId)\n  }`;\nconst cache = new InMemoryCache();\nconst client = new ApolloClient({\n  link: new HttpLink({ uri: 'http://localhost:4000/graphql' }),\n  cache,\n  resolvers: {},\n});\ncache.writeQuery({\n  query: gql`query GetCurrentAuthor {\n      currentAuthor {\n        name\n        authorId\n      }\n    }`,\n  data: {\n    currentAuthor: {\n      __typename: 'Author',\n      name: 'John Smith',\n      authorId: 12345,\n    },\n  },\n});\n// ... run the query using client.query, the  component, etc.\n```\nHere the `authorId` variable is set from the `authorId` field loaded from the cache stored `currentAuthor`. `@export` variable use isn't limited to remote queries; it can also be used to define variables for other `@client` fields or selection sets:\n```js\nimport { ApolloClient, InMemoryCache, HttpLink, gql } from '@apollo/client';\nconst query = gql`query CurrentAuthorPostCount($authorId: Int!) {\n    currentAuthorId @client @export(as: \"authorId\")\n    postCount(authorId: $authorId) @client\n  }`;\nconst cache = new InMemoryCache();\nconst client = new ApolloClient({\n  cache,\n  resolvers: {\n    Query: {\n      postCount(_, { authorId }) {\n        return authorId === 12345 ? 100 : 0;\n      },\n    },\n  },\n});\ncache.writeQuery({\n  query: gql`{ currentAuthorId }`,\n  data: {\n    currentAuthorId: 12345,\n  },\n});\n// ... run the query using client.query, the  component, etc.\n```\nSo here the `currentAuthorId` is loaded from the cache, then passed into the `postCount` local resolver as `authorId`.\nA few important notes about `@export` use:\n\n\nApollo Client currently only supports using the `@export` directive to store variables for local data. `@export` must be used with `@client`.\n\n\n`@client @export` use might appear to go against the GraphQL specification, given that the execution order of an operation looks like it could affect the result. From the Normal and Serial Execution section of the GraphQL spec:\n\n\n\n... the resolution of fields other than top\u2010level mutation fields must always be side effect\u2010free and idempotent, the execution order must not affect the result, and hence the server has the freedom to execute the field entries in whatever order it deems optimal.\n\nApollo Client currently only supports the use of the `@export` directive when mixed with the `@client` directive. It prepares `@export` variables by first running through an operation that has `@client @export` directives, extracting the specified `@export` variables, then attempting to resolve the value of those variables from the local cache or local resolvers. Once a map of variable names to local values is built up, that map is then used to populate the variables passed in when running the server based GraphQL query. The execution order of the server based GraphQL query is not impacted by `@export` use; the variables are prepped and organized before the server query runs, so the specification is being followed.\n\nIf you define multiple `@export` variables that use the same name, in a single operation, the value of the last `@export` variable will be used as the variable value moving forward. When this happens Apollo Client will log a warning message (dev only).\n\nManaging the cache\nWhen you're using Apollo Client to work with local state, your Apollo cache becomes the single source of truth for all of your local and remote data. The Apollo cache API has several methods that can assist you with updating and retrieving data. Let's walk through the most relevant methods, and explore some common use cases for each one.\ncache.writeQuery\nThe easiest way to update the cache is with `cache.writeQuery`. Here's how you use it in your resolver map for a simple update:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  resolvers: {\n    Mutation: {\n      updateVisibilityFilter: (_, { visibilityFilter }, { cache }) => {\n        cache.writeQuery({\n          query: gql`query GetVisibilityFilter { visibilityFilter }`,\n          data: {\n            __typename: 'Filter',\n            visibilityFilter,\n          },\n        });\n      },\n    },\n  },\n};\n```\nThe `cache.writeFragment` method allows you to pass in an optional `id` property to write a fragment to an existing object in the cache. This is useful if you want to add some client-side fields to an existing object in the cache.\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  resolvers: {\n    Mutation: {\n      updateUserEmail: (_, { id, email }, { cache }) => {\n        cache.writeFragment({\n          id: cache.identify({ __typename: \"User\", id }),\n          fragment: gql`fragment UserEmail on User { email }`,\n          data: { email },\n        });\n      },\n    },\n  },\n};\n```\nThe `cache.writeQuery` and `cache.writeFragment` methods should cover most of your needs; however, there are some cases where the data you're writing to the cache depends on the data that's already there. In that scenario, you can either use a combination of `cache.read{Query,Fragment}` followed by `cache.write{Query,Fragment}`, or use `cache.modify({ id, fields })` to update specific fields within the entity object identified by `id`.\nwriteQuery and readQuery\nSometimes, the data you're writing to the cache depends on data that's already in the cache; for example, you're adding an item to a list or setting a property based on an existing property value. In that case, you should use `cache.modify` to update specific existing fields. Let's look at an example where we add a todo to a list:\n```js\nimport { ApolloClient, InMemoryCache, gql } from '@apollo/client';\nlet nextTodoId = 0;\nconst cache = new InMemoryCache();\ncache.writeQuery({\n  query: gql`query GetTodos { todos { ... } }`,\n  data: { todos: [] },\n});\nconst client = new ApolloClient({\n  resolvers: {\n    Mutation: {\n      addTodo: (_, { text }, { cache }) => {\n        const query = gql`query GetTodos {\n            todos @client {\n              id\n              text\n              completed\n            }\n          }`;\n\n\n```    const previous = cache.readQuery({ query });\n    const newTodo = { id: nextTodoId++, text, completed: false, __typename: 'TodoItem' };\n    const data = {\n      todos: [...previous.todos, newTodo],\n    };\n\n    cache.writeQuery({ query, data });\n    return newTodo;\n  },\n},\n```\n\n\n},\n});\n```\nIn order to add our todo to the list, we need the todos that are currently in the cache, which is why we call `cache.readQuery` to retrieve them. `cache.readQuery` will throw an error if the data isn't in the cache, so we need to provide an initial state. This is why we're calling `cache.writeQuery` with the empty array of todos after creating the `InMemoryCache`.\nwriteFragment and readFragment\n`cache.readFragment` is similar to `cache.readQuery` except you pass in a fragment. This allows for greater flexibility because you can read from any entry in the cache as long as you have its cache key. In contrast, `cache.readQuery` only lets you read from the root of your cache.\nLet's go back to our previous todo list example and see how `cache.readFragment` can help us toggle one of our todos as completed.\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  resolvers: {\n    Mutation: {\n      toggleTodo: (_, variables, { cache }) => {\n        const id = `TodoItem:${variables.id}`;\n        const fragment = gql`fragment CompleteTodo on TodoItem {\n            completed\n          }`;\n        const todo = cache.readFragment({ fragment, id });\n        const data = { ...todo, completed: !todo.completed };\n\n\n```    cache.writeFragment({ fragment, id, data });\n    return null;\n  },\n},\n```\n\n\n},\n});\n```\nIn order to toggle our todo, we need the todo and its status from the cache, which is why we call `cache.readFragment` and pass in a fragment to retrieve it. The `id` we're passing into `cache.readFragment` refers to its cache key. If you're using the `InMemoryCache` and not overriding the `dataIdFromObject` config property, your cache key should be `__typename:id`.\nAdvanced\nCode splitting\nDepending on the complexity and size of your local resolvers, you might not always want to define them up front, when you create your initial `ApolloClient` instance. If you have local resolvers that are only needed in a specific part of your application, you can leverage Apollo Client's addResolvers and setResolvers functions to adjust your resolver map at any point. This can be really useful when leveraging techniques like route based code-splitting, using something like react-loadable.\nLet's say we're building a messaging app and have a `/stats` route that is used to return the total number of messages stored locally. If we use `react-loadable` to load our `Stats` component like:\n```js\nimport Loadable from 'react-loadable';\nimport Loading from './components/Loading';\nexport const Stats = Loadable({\n  loader: () => import('./components/stats/Stats'),\n  loading: Loading,\n});\n```\nand wait until our `Stats` component is called to define our local resolvers (using `addResolvers`):\n```js\nimport React from \"react\";\nimport { ApolloConsumer, useApolloClient, useQuery, gql } from \"@apollo/client\";\nconst GET_MESSAGE_COUNT = gql`query GetMessageCount {\n    messageCount @client {\n      total\n    }\n  }`;\nconst resolvers = {\n  Query: {\n    messageCount: (_, args, { cache }) => {\n      // ... calculate and return the number of messages in\n      // the cache ...\n      return {\n        total: 123,\n        __typename: \"MessageCount\",\n      };\n    },\n  },\n};\nexport function MessageCount() {\n  const client = useApolloClient();\n  client.addResolvers(resolvers);\nconst { loading, data: { messageCount } } = useQuery(GET_MESSAGE_COUNT);\nif (loading) return \"Loading ...\";\nreturn (\n    \n      Total number of messages: {messageCount.total}\n    \n  );\n};\n```\nour local resolver code will only be included in the bundle a user downloads when (if) they access `/stats`. It won't be included in the initial application bundle, which helps keep the size of our initial bundle down, and ultimately helps with download and application startup times.\nAPI\nApollo Client local state handling is baked in, so you don't have to install anything extra. Local state management can be configured during `ApolloClient` instantiation (via the `ApolloClient` constructor) or by using the `ApolloClient` local state API. Data in the cache can be managed through the `ApolloCache` API.\nApolloClient\nConstructor\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  resolvers: { ... },\n  typeDefs: { ... },\n});\n```\n| Option | Type | Description |\n| - | - | - |\n| `resolvers?` | Resolvers \\| Resolvers[] | A map of resolver functions that your GraphQL queries and mutations call in order to read and write to the cache. |\n| `typeDefs?` | string \\| string[] \\| DocumentNode \\| DocumentNode[];<string> | A string representing your client-side schema written in the Schema Definition Language. This schema is not used for validation, but is used for introspection by the Apollo Client Devtools. |\nNone of these options are required. If you don't specify anything, you will still be able to use the `@client` directive to query the Apollo Client cache.\nMethods\n```js\nimport { ApolloClient, InMemoryCache, HttpLink } from '@apollo/client';\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: new HttpLink({ uri: 'http://localhost:4000/graphql' }),\n});\nclient.setResolvers({ ... });\n```\n| Method | Description |\n| - | - |\n| addResolvers(resolvers: Resolvers \\| Resolvers[]) | A map of resolver functions that your GraphQL queries and mutations call in order to read and write to the cache. Resolver functions added through`addResolvers`are added to the internal resolver function map, meaning any existing resolvers (that aren't overwritten) are preserved. |\n| setResolvers(resolvers: Resolvers \\| Resolvers[]) | A map of resolver functions that your GraphQL queries and mutations call in order to read and write to the cache. Resolver functions added through`setResolvers`overwrite all existing resolvers (a pre-existing resolver map is wiped out, before the new resolvers are added). |\n|`getResolvers`| Get the currently defined resolver map. |\n|`setLocalStateFragmentMatcher(fragmentMatcher: FragmentMatcher)`| Set a custom`FragmentMatcher` to be used when resolving local state queries. |\nTypescript interfaces/types:\n```ts\ninterface Resolvers {\n\n\n```[field: string]: (\n  rootValue?: any,\n  args?: any,\n  context?: any,\n  info?: any,\n) => any;\n```\n\n\n};\n}\ntype FragmentMatcher = (\n  rootValue: any,\n  typeCondition: string,\n  context: any,\n) => boolean;\n```\nApolloCache\nMethods\n```js\nimport { InMemoryCache } from '@apollo/client';\nconst cache = new InMemoryCache();\ncache.writeQuery({\n  query: gql`query MyQuery {\n    isLoggedIn,\n    cartItems\n  }`,\n  data: {\n    isLoggedIn: !!localStorage.getItem('token'),\n    cartItems: [],\n  },\n});\n```\n| Method | Description |\n| - | - |\n| `writeQuery({ query, variables, data })` | Writes data to the root of the cache using the specified query to validate that the shape of the data you\u2019re writing to the cache is the same as the shape of the data required by the query. Great for prepping the cache with initial data. |\n| `readQuery({ query, variables })` | Read data from the cache for the specified query. |\n| `writeFragment({ id, fragment, fragmentName, variables, data })` | Similar to `writeQuery` (writes data to the cache) but uses the specified fragment to validate that the shape of the data you\u2019re writing to the cache is the same as the shape of the data required by the fragment. |\n| `readFragment({ id, fragment, fragmentName, variables })` | Read data from the cache for the specified fragment. |\nDeprecation notice\nThe idea of using client side resolvers to manage local state was first introduced into the Apollo Client ecosystem through the apollo-link-state project. The Apollo Client team is always looking for ways to improve local state handling, so we decided to bring local resolver and `@client` support into the Apollo Client core directly, in version 2.5. While managing state with local resolvers works well, the functionality offered by `apollo-link-state`, and then from Apollo Client directly, was originally designed with certain imposed limitations due to its distance from the Apollo Client cache. Apollo Link's don't have direct access to the cache, which means `apollo-link-state` had to implement an approach that couldn't feed or hook into the cache as seamlessly as we would have liked. The local resolver support merged into the Apollo Client core in version 2.5 was essentially a mirror of the Link approach, with a few adjustments to tie into the cache a little more closely. This means Apollo Client's local resolver approach is still a bit limited when it comes to being able to work with the cache more closely, and ultimately providing a better developer experience.\nTo help address limitations in the local resolver API, we have designed and implemented a new approach for managing local state in Apollo Client 3.0, that works as a direct extension of the cache. Field policies and reactive variables not only help provide a better developer experience from an API use and functionality point of view, but they also improve performance and provide a more reliable foundation for local state management. Re-thinking local state handling with the Apollo Client cache in mind has helped reduce a large number of local state bugs caused by local resolvers being a few too many layers removed from the cache internals.",
    "tag": "apollo-client"
  },
  {
    "title": "How it works",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/local-state/local-state-management.mdx",
    "content": "\ntitle: Managing local state\ndescription: Interacting with local data in Apollo Client\n\nAt its core, Apollo Client is a state management library that happens to use GraphQL to interact with a remote server. Naturally, some application state doesn't require a remote server because it's entirely local.\nApollo Client enables you to manage local state alongside remotely fetched state, meaning you can interact with all of your application's state with a single API.\nHow it works\nYou can store your application's local state any way you want (such as in `localStorage` or the Apollo Client cache). You then define the logic that Apollo Client uses to fetch and populate that local data when you query a particular field. You can even include both local and remotely fetched fields in the same query:\n```mermaid\nsequenceDiagram\n    participant Apollo Client;\n    participant Cache;\n    participant GraphQL Server;\n\n\n```Apollo Client->>Cache: Queries local and remote fields;\nNote over Cache: Calculates local fields;\nCache->>GraphQL Server: Queries remote fields;\nNote over GraphQL Server: Resolves remote fields;\nGraphQL Server->>Cache: Returns remote fields;\nNote over Cache: Caches remote fields*;\nCache->>Apollo Client: Returns ALL fields;\nNote over Apollo Client: Time passes\u2026;\nApollo Client->>Cache: Executes same query;\nNote over Cache: Calculates local fields;\nNote over Cache: Fetches remote fields (now cached);\nCache->>Apollo Client: Returns ALL fields;\n```\n\n\n```\nTo support this flow, Apollo Client 3 introduces two complementary mechanisms for managing local state: field policies and reactive variables.\n\n* The local resolver API from previous versions of Apollo Client is also available but is deprecated. Some additional steps may occur when using this, e.g. the `@client(always:true)` directive would recalculate local field resolvers after remote fields are cached.\n\nField policies and local-only fields\n\nAvailable in Apollo Client >= 3.0\n\nField policies enable you to define what happens when you query a particular field, including fields that aren't defined in your GraphQL server's schema. By defining field policies for these local-only fields, you can populate them with data that's stored anywhere, such as in `localStorage` or reactive variables.\nA single GraphQL query can include both local-only fields and remotely fetched fields. In the field policy for each local-only field, you specify a function that defines how that field's value is populated.\nGet started with local-only fields\nReactive variables\n\nAvailable in Apollo Client >= 3.0\n\nReactive variables enable you to read and write local data anywhere in your application, without needing to use a GraphQL operation to do so. The field policy of a local-only field can use a reactive variable to populate the field's current value.\nReactive variables aren't stored in the Apollo Client cache, so they don't need to conform to the strict structure of a cached type. You can store anything you want in them.\nWhenever the value of a reactive variable changes, Apollo Client automatically detects that change. Every active query with a field that depends on the changed variable automatically updates.\nGet started with reactive variables\nLocal resolvers\n\nAvailable in Apollo Client >= 2.5\n\nIn earlier versions of Apollo Client, you define local resolvers to populate and modify local-only fields. These resolvers are similar in structure and purpose to the resolvers that your GraphQL server defines.\nThis functionality is still available in Apollo Client 3, but will be moved out of the core module in a future major release.",
    "tag": "apollo-client"
  },
  {
    "title": "The `ApolloClient` constructor",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/core/ApolloClient.mdx",
    "content": "\ntitle: class ApolloClient\ndescription: API reference\norder: 11\napi_reference: true\n\nThe `ApolloClient` class encapsulates Apollo's core client-side API. It backs all available view-layer integrations (React, iOS, and so on).\nThe `ApolloClient` constructor\n\nTakes an `ApolloClientOptions` parameter that supports the fields listed below.\nReturns an initialized `ApolloClient` object.\nExample\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst cache = new InMemoryCache();\nconst client = new ApolloClient({\n  // Provide required constructor fields\n  cache: cache,\n  uri: 'http://localhost:4000/',\n// Provide some optional constructor fields\n  name: 'react-web-client',\n  version: '1.3',\n  queryDeduplication: false,\n  defaultOptions: {\n    watchQuery: {\n      fetchPolicy: 'cache-and-network',\n    },\n  },\n});\n```\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `uri`\n\n`String`\n\n\n\nThe URI of the GraphQL endpoint that Apollo Client will communicate with.\n\nOne of `uri` or `link` is **required**. If you provide both, `link` takes precedence.\n\n\n\n\n\n###### `link`\n\n`ApolloLink`\n\n\n\nYou can provide an Apollo Link instance to serve as Apollo Client's network layer. For more information, see [Advanced HTTP networking](../../networking/advanced-http-networking/).\n\nOne of `uri` or `link` is **required**. If you provide both, `link` takes precedence.\n\n\n\n\n\n###### `cache`\n\n`ApolloCache` (usually `InMemoryCache`)\n\n\n\n**Required.** The cache that Apollo Client should use to store query results locally. The recommended cache is `InMemoryCache`, which is provided by the `@apollo/client` package.\n\nFor more information, see [Configuring the cache](../../caching/cache-configuration/).\n\n\n\n\n\n###### `name`\n\n`String`\n\n\n\nA custom name (e.g., `iOS`) that identifies this particular client among your set of clients. Apollo Server and Apollo Studio use this property as part of the [client awareness](/apollo-server/monitoring/metrics/#identifying-distinct-clients) feature.\n\n\n\n\n\n###### `version`\n\n`String`\n\n\n\nA custom version that identifies the current version of this particular client (e.g., `1.2`). Apollo Server and Apollo Studio use this property as part of the [client awareness](/apollo-server/monitoring/metrics/#identifying-distinct-clients) feature.\n\nThis is **not** the version of Apollo Client that you are using, but rather any version string that helps you differentiate between versions of your client.\n\n\n\n\n\n###### `ssrMode`\n\n`Boolean`\n\n\n\nWhen using Apollo Client for [server-side rendering](../../performance/server-side-rendering/), set this to `true` so that the [`getDataFromTree` function](../react/ssr/#getdatafromtree) can work effectively.\n\nThe default value is `false`.\n\n\n\n\n\n###### `ssrForceFetchDelay`\n\n`Number`\n\n\n\nThe time interval (in milliseconds) before Apollo Client force-fetches queries after a server-side render.\n\nThe default value is `0` (no delay).\n\n\n\n\n\n###### `connectToDevTools`\n\n`Boolean`\n\n\n\nIf `true`, the [Apollo Client Devtools](../../development-testing/developer-tooling/#apollo-client-devtools) browser extension can connect to Apollo Client in your production environment. The extension can _always_ connect in a non-production environment.\n\nThe default value is `false`.\n\n\n\n\n\n###### `queryDeduplication`\n\n`Boolean`\n\n\n\nIf `false`, Apollo Client sends every created query to the server, even if a _completely_ identical query (identical in terms of query string, variable values, and operationName) is already in flight.\n\nThe default value is `true`.\n\n\n\n\n\n###### `defaultOptions`\n\n`Object`\n\n\n\nProvide this object to set application-wide default values for options you can provide to the `watchQuery`, `query`, and `mutate` functions. See below for an example object.\n\nSee the [example object below](#example-defaultoptions-object).\n\n\n\n\n\n###### `assumeImmutableResults`\n\n`Boolean`\n\n\n\nIf `true`, Apollo Client will assume results read from the cache are never mutated by application code, which enables substantial performance optimizations.\n\nThe default value is `false`.\n\n\n\n\nExample `defaultOptions` object\n`js\nconst defaultOptions = {\n  watchQuery: {\n    fetchPolicy: 'cache-and-network',\n    errorPolicy: 'ignore',\n  },\n  query: {\n    fetchPolicy: 'network-only',\n    errorPolicy: 'all',\n  },\n  mutate: {\n    errorPolicy: 'all',\n  },\n};`\nYou can override any default option you specify in this object by providing a\ndifferent value for the same option in individual function calls.\n\nNote: The `useQuery` hook uses Apollo Client's `watchQuery` function. To set `defaultOptions` when using the `useQuery` hook, make sure to set them under the `defaultOptions.watchQuery` property.\n\nFunctions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTypes\n",
    "tag": "apollo-client"
  },
  {
    "title": "`readQuery`",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/cache/InMemoryCache.mdx",
    "content": "\ntitle: class InMemoryCache\ndescription: API reference\napi_reference: true\n\nMethods of the `InMemoryCache` class (the cache used by almost every instance of ApolloClient) are documented here.\n\nBefore reading about individual methods, see Caching in Apollo Client.\n\n`readQuery`\nExecutes a GraphQL query directly against the cache and returns its result (or `null` if the query cannot be fulfilled):\n`js\n// Query a cached Todo object with id 5\nconst { todo } = cache.readQuery({\n  query: gql`\n    query ReadTodo {\n      todo(id: 5) {\n        id\n        text\n        completed\n      }\n    }\n  `,\n});`\nFor usage instructions, see Interacting with cached data: readQuery.\nAccepts the following parameters:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `options`\n\n`Object`\n\n\n\n**Required.** Provides configuration options for the query, including the actual query to execute.\n\nSupported fields are listed below.\n\n\n\n\n\n###### `optimistic`\n\n`Boolean`\n\n\n\nIf `true`, `readQuery` returns optimistic results.\n\nThe default value is `false`.\n\n\n\n\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `query`\n\n`DocumentNode`\n\n\n\n**Required.** The GraphQL query to execute, created by wrapping a query string in the `gql` template literal.\n\n\n\n\n\n###### `variables`\n\n`Object`\n\n\n\nA map of any GraphQL variable names and values required by `query`.\n\n\n\n\n\n###### `id`\n\n`String`\n\n\n\nThe root `id` to use for the query.\n\nThe default value is `ROOT_QUERY`, which is the ID of the root query object.\n\nBy specifying the ID of another cached object, you can query arbitrary cached data without conforming to the structure of your schema's supported queries. This enables `readQuery` to behave similarly to [`readFragment`](#readfragment).\n\n\n\n\n\n###### `canonizeResults`\n\n`Boolean`\n\n\n\nIf `true`, result objects read from the cache will be _canonized_, which means deeply-equal objects will also be `===` (literally the same object), allowing much more efficient comparison of past/present results.\n\nThe default value is `false`.\n\n\n\n\nSignature\n`ts title=\"src/cache/core/cache.ts\"\nreadQuery<QueryType, TVariables = any>(\n  options: DataProxy.Query<TVariables>,\n  optimistic: boolean = false,\n): QueryType | null`\n`writeQuery`\nWrites data to the cache in the shape of a provided GraphQL query. Returns a `Reference` to the written object or `undefined` if the write failed.\n`js\n// Create or modify a cached Todo object with id 5\ncache.writeQuery({\n  query: gql`\n    query ReadTodo($id: ID!) {\n      todo(id: $id) {\n        id\n        text\n        completed\n      }\n    }\n  `,\n  data: {\n    todo: {\n      __typename: 'Todo',\n      id: 5,\n      text: 'Buy grapes \ud83c\udf47',\n      completed: false\n    },\n  },\n  variables: {\n    id: 5\n  }\n});`\nFor usage instructions, see Interacting with cached data: writeQuery.\nTakes an `options` object as a parameter. Supported fields of this object are described below.\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `query`\n\n`DocumentNode`\n\n\n\n**Required.** The GraphQL query that defines the shape of the data to write. Created by wrapping a query string in the `gql` template literal.\n\n\n\n\n\n###### `data`\n\n`Object`\n\n\n\n**Required.** The data to write to the cache. This object's fields must conform to the shape defined by `query`.\n\n\n\n\n\n###### `variables`\n\n`Object`\n\n\n\nA map of any GraphQL variable names and values required by `query`.\n\n\n\n\n\n###### `id`\n\n`String`\n\n\n\nThe `id` of the root object to use with `query`.\n\nThe default value is `ROOT_QUERY`, which is the ID of the root query object.\n\nBy specifying the ID of another cached object, you can modify arbitrary cached data without conforming to the structure of your schema's supported queries. This enables `writeQuery` to behave similarly to [`writeFragment`](#writefragment).\n\n\n\n\n\n###### `broadcast`\n\n`Boolean`\n\n\n\nIf `true`, automatically refresh all active queries that depend on at least one field that's modified by this call. If `false`, silences the broadcast of cache updates and prevents automatic query refresh.\n\nThe default value is `true`.\n\n\n\n\n\n###### `overwrite`\n\n`Boolean`\n\n\n\nIf `true`, ignore existing cache data when calling `merge` functions, allowing incoming data to replace existing data, without warnings about data loss.\n\nThe default value is `false`.\n\n\n\n\nSignature\n`ts title=\"src/cache/core/cache.ts\"\nwriteQuery<TData = any, TVariables = any>(\n  options: Cache.WriteQueryOptions<TData, TVariables>,\n): Reference | undefined`\n`updateQuery`\n\nThis method is available in Apollo Client 3.5 and later.\n\nFetches data from the cache in the shape of a provided GraphQL query, then updates that cached data according to a provided update function.\nReturns the updated result or `null` if the update failed.\n`js\n// Fetches a Todo object with id 5 and flips its `completed` boolean\ncache.updateQuery({ // options object\n  query: gql`\n    query ReadTodo($id: ID!) {\n      todo(id: $id) {\n        id\n        text\n        completed\n      }\n    }\n  `,\n  variables: {\n    id: 5\n  }\n}, (data) => ({ // update function\n  todo: {\n    ...data.todo,\n    completed: !data.todo.completed\n  }\n}));`\nTakes an `options` object and an update function as parameters (both described below).\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `query`\n\n`DocumentNode`\n\n\n\n**Required.** The GraphQL query that defines the shape of the data to fetch. Created by wrapping a query string in the `gql` template literal.\n\n\n\n\n\n###### `variables`\n\n`Object`\n\n\n\nA map of any GraphQL variable names and values required by `query`.\n\n\n\n\n\n###### `id`\n\n`String`\n\n\n\nThe `id` of the root object to use with `query`.\n\nThe default value is `ROOT_QUERY`, which is the ID of the root query object.\n\nBy specifying the ID of another cached object, you can modify arbitrary cached data without conforming to the structure of your schema's supported queries. This enables `updateQuery` to behave similarly to [`updateFragment`](#updatefragment).\n\n\n\n\n\n###### `broadcast`\n\n`Boolean`\n\n\n\nIf `true`, automatically refresh all active queries that depend on at least one field that's modified by this call.  If `false`, silences the broadcast of cache updates and prevents automatic query refresh.\n\nThe default value is `true`.\n\n\n\n\n\n###### `overwrite`\n\n`Boolean`\n\n\n\nIf `true`, ignore existing cache data when calling `merge` functions, allowing incoming data to replace existing data, without warnings about data loss.\n\nThe default value is `false`.\n\n\n\n\n`updateQuery` update function\nThe update function of `updateQuery` takes a query's current cached value and returns the value that should replace it (or `undefined` if no change should be made).\nThe returned value is automatically passed to writeQuery, which modifies the cached data.\nPlease note the `update` function has to calculate the new value in an immutable way. You can read more about immutable updates in the React documentation.\nSignature\n`ts title=\"src/cache/core/cache.ts\"\npublic updateQuery<TData = any, TVariables = any>(\n  options: Cache.UpdateQueryOptions<TData, TVariables>,\n  update: (data: TData | null) => TData | null | void,\n): TData | null`\n`readFragment`\nReads data from the cache in the shape of a provided GraphQL fragment:\n`js\nconst todo = cache.readFragment({\n  id: '5', // The value of the to-do item's unique identifier\n  fragment: gql`\n    fragment MyTodo on Todo {\n      id\n      text\n      completed\n    }\n  `,\n});`\nReturns the requested data or `null` if data is not available in the cache.\nFor usage instructions, see Interacting with cached data: readFragment.\nAccepts the following parameters:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `options`\n\n`Object`\n\n\n\n**Required.** Provides configuration options, including the actual fragment to use.\n\nSupported fields are listed below.\n\n\n\n\n\n###### `optimistic`\n\n`Boolean`\n\n\n\nIf `true`, `readFragment` returns optimistic results.\n\nThe default value is `false`.\n\n\n\n\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `id`\n\n`String`\n\n\n\n**Required.** The ID of the cached object that this call is reading a fragment of.\n\nIf the cache does not contain an object with the specified ID, `readFragment` returns `null`.\n\n\n\n\n\n###### `fragment`\n\n`DocumentNode`\n\n\n\n**Required.** A GraphQL document created with the `gql` template literal tag that includes the fragment to read.\n\nIf the document includes more than one fragment, you must also provide [`fragmentName`](#fragmentname) to indicate which to use.\n\n\n\n\n\n###### `fragmentName`\n`String`\n\n\n\nThe name of the fragment defined in the `fragment` document to use in the call.\n\nYou don't need to provide this value if the `fragment` document includes only one fragment.\n\n\n\n\n\n###### `variables`\n\n`Object`\n\n\n\nA map of any GraphQL variable names and values required by `fragment`.\n\n\n\n\n\n###### `canonizeResults`\n\n`Boolean`\n\n\n\nIf `true`, result objects read from the cache will be _canonized_, which means deeply-equal objects will also be `===` (literally the same object), allowing much more efficient comparison of past/present results.\n\nThe default value is `false`.\n\n\n\n\nSignature\n`ts title=\"src/cache/core/cache.ts\"\nreadFragment<FragmentType, TVariables = any>(\n  options: DataProxy.Fragment<TVariables>,\n  optimistic: boolean = false,\n): FragmentType | null`\n`writeFragment`\nWrites data to the cache in the shape of the provided GraphQL fragment. Returns a `Reference` to the written object or `undefined` if the write failed.\n`js\nclient.writeFragment({\n  id: 'Todo:5',\n  fragment: gql`\n    fragment MyTodo on Todo {\n      completed\n    }\n  `,\n  data: {\n    completed: true,\n  },\n});`\nFor usage instructions, see Interacting with cached data: writeFragment.\nTakes an `options` object as a parameter. Supported fields of this object are described below.\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `id`\n\n`String`\n\n\n\n**Required.** The ID of the cached object that this call is writing a fragment to.\n\nIf the cache does not contain an object with the specified ID, `writeFragment` returns `null`.\n\n\n\n\n\n###### `fragment`\n\n`DocumentNode`\n\n\n\n**Required.** A GraphQL document created with the `gql` template literal tag that includes the fragment to write.\n\nIf the document includes more than one fragment, you must also provide [`fragmentName`](#fragmentname) to indicate which to use.\n\n\n\n\n\n###### `data`\n\n`Object`\n\n\n\n**Required.** The data to write to the cache. This object's fields must conform to the shape defined by `fragment`.\n\n\n\n\n\n###### `fragmentName`\n\n`String`\n\n\n\nThe name of the fragment defined in the `fragment` document to use in the call.\n\nYou don't need to provide this value if the `fragment` document includes only one fragment.\n\n\n\n\n\n###### `variables`\n\n`Object`\n\n\n\nA map of any GraphQL variable names and values required by `fragment`.\n\n\n\n\n\n###### `broadcast`\n\n`Boolean`\n\n\n\nIf `true`, automatically refresh all active queries that depend on at least one field that's modified by this call.  If `false`, silences the broadcast of cache updates and prevents automatic query refresh.\n\nThe default value is `true`.\n\n\n\n\n\n###### `overwrite`\n\n`Boolean`\n\n\n\nIf `true`, ignore existing cache data when calling `merge` functions, allowing incoming data to replace existing data, without warnings about data loss.\n\nThe default value is `false`.\n\n\n\n\nSignature\n`ts title=\"src/cache/core/cache.ts\"\nwriteFragment<TData = any, TVariables = any>(\n  options: Cache.WriteFragmentOptions<TData, TVariables>,\n): Reference | undefined`\n`updateFragment`\n\nThis method is available in Apollo Client 3.5 and later.\n\nFetches data from the cache in the shape of a provided GraphQL fragment, then updates that cached data according to a provided update function.\nReturns the updated result or `null` if the update failed.\n`js\n// Fetches a Todo object with id 5 and sets its `completed` boolean to true\nconst todo = cache.updateFragment({ // options object\n  id: '5', // The value of the to-do item's unique identifier\n  fragment: gql`\n    fragment MyTodo on Todo {\n      completed\n    }\n  `,\n}, (data) => ({ ...data, completed: true }) // update function\n);`\nTakes an `options` object and an update function as parameters (both described below).\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `id`\n\n`String`\n\n\n\n**Required.** The ID of the cached object that this call is reading a fragment of.\n\nIf the cache does not contain an object with the specified ID, `updateFragment` returns `null`.\n\n\n\n\n\n###### `fragment`\n\n`DocumentNode`\n\n\n\n**Required.** A GraphQL document created with the `gql` template literal tag that includes the fragment to read.\n\nIf the document includes more than one fragment, you must also provide [`fragmentName`](#fragmentname) to indicate which to use.\n\n\n\n\n\n###### `fragmentName`\n\n`String`\n\n\n\nThe name of the fragment defined in the `fragment` document to use in the call.\n\nYou don't need to provide this value if the `fragment` document includes only one fragment.\n\n\n\n\n\n###### `variables`\n\n`Object`\n\n\n\nA map of any GraphQL variable names and values required by `fragment`.\n\n\n\n\n\n###### `broadcast`\n\n`Boolean`\n\n\n\nIf `true`, automatically refresh all active queries that depend on at least one field that's modified by this call.  If `false`, silences the broadcast of cache updates and prevents automatic query refresh.\n\nThe default value is `true`.\n\n\n\n\n\n###### `overwrite`\n\n`Boolean`\n\n\n\nIf `true`, ignore existing cache data when calling `merge` functions, allowing incoming data to replace existing data, without warnings about data loss.\n\nThe default value is `false`.\n\n\n\n\n`updateFragment` update function\nThe update function of `updateFragment` takes a fragment's current cached value and returns the value that should replace it (or `undefined` if no change should be made).\nThe returned value is automatically passed to writeFragment, which modifies the cached data.\nPlease note the `update` function has to calculate the new value in an immutable way. You can read more about immutable updates in the React documentation.\nSignature\n`ts title=\"src/cache/core/cache.ts\"\npublic updateFragment<TData = any, TVariables = any>(\n  options: Cache.UpdateFragmentOptions<TData, TVariables>,\n  update: (data: TData | null) => TData | null | void,\n): TData | null`\n`identify`\nReturns the canonical ID for a specified cached object.\nYou can provide either an object or an object reference to this function:\n\nIf you provide an object, `identify` returns the object's string-based ID (e.g., `Car:1`).\nIf you provide a reference, `identify` return the reference's `__ref` ID string.\n\nFor usage instructions, see Interacting with cached data: Identify cached entities.\nAccepts the following parameters:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `object`\n\n`StoreObject` or `Reference`\n\n\n\n**Required.** The cached object (or object reference) to obtain the canonical ID for.\n\n\n\n\nSignature\n`ts title=\"src/cache/inmemory/inMemoryCache.ts\"\nidentify(object: StoreObject | Reference): string | undefined`\n`modify`\nModifies one or more field values of a cached object. Must provide a modifier function for each field to modify. A modifier function takes a cached field's current value and returns the value that should replace it.\nReturns `true` if the cache was modified successfully and `false` otherwise.\nFor usage instructions, see Using cache.modify.\nTakes an `options` object as a parameter. Supported fields of this object are described below.\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `fields`\n\n`Object`\n\n\n\n**Required.** A map that specifies the modifier function to call for each modified field of the cached object.\n\nSee [Modifier function API](#modifier-function-api) below.\n\n\n\n\n\n###### `id`\n\n`string`\n\n\n\nThe ID of the cached object to modify.\n\nThe default value is `ROOT_QUERY` (the ID of the root query singleton object).\n\n\n\n\n\n###### `optimistic`\n\n`Boolean`\n\n\n\nIf `true`, also modifies the optimistically cached values for included fields.\n\nThe default value is `false`.\n\n\n\n\n\n###### `broadcast`\n\n`Boolean`\n\n\n\nIf `true`, automatically refresh all active queries that depend on at least one field that's modified by this call.  If `false`, silences the broadcast of cache updates and prevents automatic query refresh.\n\nThe default value is `true`.\n\n\n\n\nModifier function API\nA modifier function takes a cached field's current value and returns the value that should replace it, or the DELETE sentinel object to delete the field entirely.\nThe first parameter passed to a modifier function is the current cached value of the field being modified.\nThe second parameter is a helper object that contains the following utilities:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `fieldName`\n\n`String`\n\n\n\nThe name of the field being modified.\n\n\n\n\n\n###### `storeFieldName`\n\n`String`\n\n\n\nThe full key for the field used internally, including serialized key arguments.\n\n\n\n\n\n###### `readField`\n\n`Function`\n\n\n\nA helper function for reading other fields within the current object.\n\n\n\n\n\n###### `canRead`\n\n`Function`\n\n\n\nA helper function that returns `true` for non-normalized `StoreObject`s and non-dangling `Reference`s. This indicates that `readField(name, objOrRef)` has a chance of working.\n\nUseful for filtering dangling references out of lists.\n\n\n\n\n\n###### `isReference`\n\n`Function`\n\n\n\nA helper function that returns `true` if a particular object is a reference to a cached entity.\n\n\n\n\n\n###### `DELETE`\n\n`Object`\n\n\n\nA sentinel object that you can return from a modifier function to indicate that the field should be deleted entirely.\n\n\n\n\nSignature\n`ts title=\"src/cache/inmemory/inMemoryCache.ts\"\nmodify(options: Cache.ModifyOptions): boolean`\n`gc`\nPerforms garbage collection of unreachable normalized objects in the cache:\n`js\ncache.gc();`\nReturns an array containing the IDs of all objects removed from the cache.\nFor usage instructions, see cache.gc.\nSignature\n`ts title=\"src/cache/inmemory/inMemoryCache.ts\"\ngc()`\n`evict`\nEither removes a normalized object from the cache or removes a specific field from a normalized object in the cache:\n`js\ncache.evict({ id: 'my-object-id', fieldName: 'myFieldName' });`\nReturns `true` if data was removed from the cache, `false` otherwise.\nFor usage instructions, see cache.evict.\nTakes an `options` object as a parameter. Supported fields of this object are described below.\nOptions\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `id`\n\n`String`\n\n\n\nThe ID of the cached object to remove (or remove a field from).\n\nThe default value is `ROOT_QUERY`, which is the ID of the root query object.\n\n\n\n\n\n###### `fieldName`\n\n`String`\n\n\n\nThe name of the field to remove from the cached object.\n\nOmit this option if you are removing the entire object.\n\n\n\n\n\n###### `args`\n\n`Record`\n\n\n\nIf provided with `fieldName`, only instances of the field with the specified arguments are removed from the cache.\n\nOtherwise, all instances of the field are removed for the cached object.\n\n\n\n\n\n###### `broadcast`\n\n`Boolean`\n\n\n\nIf `true`, automatically refresh all active queries that depend on at least one field that's removed by this call.  If `false`, silences the broadcast of cache updates and prevents automatic query refresh.\n\nThe default value is `true`.\n\n\n\n\nSignature\n`ts title=\"src/cache/inmemory/inMemoryCache.ts\"\nevict(options: Cache.EvictOptions): boolean`\n`extract`\nReturns a serialized representation of the cache's current contents as a `NormalizedCacheObject`.\nAccepts the following parameters:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `optimistic`\n\n`Boolean`\n\n\n\nIf `true`, optimistic data is included in the serialization.\n\nThe default value is `false`.\n\n\n\n\nSignature\n`ts title=\"src/cache/inmemory/inMemoryCache.ts\"\nextract(optimistic: boolean = false): NormalizedCacheObject`\n`restore`\nRestores the cache's state from a serialized `NormalizedCacheObject` (such as one returned by extract). This removes all existing data from the cache.\nReturns the `InMemoryCache` instance it's called on.\nAccepts the following parameters:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `data`\n\n`NormalizedCacheObject`\n\n\n\n**Required.** The serialization to restore the cache from.\n\n\n\n\nSignature\n`ts title=\"src/cache/inmemory/inMemoryCache.ts\"\nrestore(data: NormalizedCacheObject): this`\n`makeVar`\nCreates a reactive variable with an optional initial value:\n`js\nconst cartItems = makeVar([]);`\nReturns the reactive variable function you use to read or modify the variable's value.\nFor usage instructions, see Reactive variables.\nAccepts the following parameters:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `value`\n\nAny\n\n\n\nThe reactive variable's initial value.\n\n\n\n\nSignature\n```ts title=\"src/cache/inmemory/inMemoryCache.ts\"\nmakeVar(value: T): ReactiveVar",
    "tag": "apollo-client"
  },
  {
    "title": "Overview",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-batch-http.mdx",
    "content": "\ntitle: Batch HTTP Link\ndescription: Batch multiple operations into a single HTTP request\n\nOverview\nThe `BatchHttpLink` is a terminating link that batches an array of individual GraphQL operations into a single HTTP request that's sent to a single GraphQL endpoint.\n```js\nimport { BatchHttpLink } from \"@apollo/client/link/batch-http\";\nconst link = new BatchHttpLink({\n  uri: \"http://localhost:4000/graphql\",\n  batchMax: 5, // No more than 5 operations per batch\n  batchInterval: 20 // Wait no more than 20ms after first batched operation\n});\n```\nIf you use `BatchHttpLink` instead of HttpLink as your terminating link, Apollo Client automatically batches executed GraphQL operations and transmits them to your server according to the batching options you provide.\nOptions\nThe `BatchHttpLink` constructor accepts a configuration object that supports the following options:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n**Batching options**\n\n\n\n\n\n###### `batchMax`\n\n`number`\n\n\n\nThe maximum number of operations to include in a single batch.\n\nThe default value is `10`.\n\n\n\n\n\n###### `batchInterval`\n\n`number`\n\n\n\nThe maximum number of milliseconds to wait before sending each batched request. If `batchMax` operations are batched before `batchInterval` is reached, the request is sent immediately.\n\nThe default value is `10`.\n\n\n\n\n\n###### `batchDebounce`\n\n`boolean`\n\n\n\nIf `true`, the `batchInterval` timer is reset whenever an operation is added to the batch. In other words, the next batched request is not sent until either:\n\n* No operation is added for `batchInterval` milliseconds, or\n* `batchMax` is reached.\n\nThe default value is `false`.\n\n\n\n\n\n###### `batchKey`\n\n`string`\n\n\n\nA function that accepts an operation and returns a string key, which uniquely names the batch the operation belongs to.\n\n[See the default function](https://github.com/apollographql/apollo-client/blob/main/src/link/batch-http/batchHttpLink.ts#L192-L206)\n\n\n\n\n\n**HTTP options**\n\n\n\n\n\n###### `uri`\n\n`String` or `Function`\n\n\n\nThe URL of the GraphQL endpoint to send requests to. Can also be a function that accepts an `Operation` object and returns the string URL to use for that operation.\n\nThe default value is `/graphql`.\n\n\n\n\n\n###### `includeExtensions`\n\n`Boolean`\n\n\n\nIf true, includes the `extensions` field in operations sent to your GraphQL endpoint.\n\nThe default value is `false`.\n\n\n\n\n\n###### `fetch`\n\n`Function`\n\n\n\nA function to use instead of calling the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch) directly when sending HTTP requests to your GraphQL endpoint. The function must conform to the signature of `fetch`.\n\nBy default, the Fetch API is used unless it isn't available in your runtime environment.\n\nSee [Customizing `fetch`](./apollo-link-http/#customizing-fetch).\n\n\n\n\n\n###### `headers`\n\n`Object`\n\n\n\nAn object representing headers to include in every HTTP request, such as `{Authentication: 'Bearer abc123'}`.\n\n\n\n\n\n###### `preserveHeaderCase`\n\n`Boolean`\n\n\n\nIf set to true, header names won't be automatically normalized to lowercase. This allows for non-http-spec-compliant servers that might expect capitalized header names.\n\nThe default value is `false`.\n\n\n\n\n\n###### `credentials`\n\n`String`\n\n\n\nThe credentials policy to use for each `fetch` call. Can be `omit`, `include`, or `same-origin`.\n\n\n\n\n\n###### `fetchOptions`\n\n`Object`\n\n\n\nAn object containing options to use for each call to `fetch`. If a particular option is not included in this object, the default value of that option is used.\n\nNote that if you set `fetchOptions.method` to `GET`, `BatchHttpLink` follows [standard GraphQL HTTP GET encoding](http://graphql.org/learn/serving-over-http/#get-request).\n\n[See available options](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/fetch#Parameters)\n\n\n\n\nContext\nThe batch HTTP link currently uses the context in two different ways, per batch and per query. The context fields below are used per batch and taken from the first operation in the batch.\n| Option | Description |\n| - | - |\n| `headers` | An object representing values to be sent as headers on the request |\n| `credentials` | A string representing the credentials policy you want for the fetch call |\n| `uri` | A string of the endpoint you want to fetch from |\n| `fetchOptions` | Any overrides of the fetch options argument to pass to the fetch call |\n| `response` | This is the raw response from the fetch request after it is made |\nFor each query, the `http` field is used to modify each individual query in the batch, such as persisted queries (see below).\nPersisted queries\nThe batch HTTP link supports an advanced GraphQL feature called persisted queries. This allows you to not send the stringified query over the wire, but instead send some kind of identifier for the query. To support this you need to attach the id somewhere in the extensions field, and pass the following options to the context:\n`js\noperation.setContext({\n  http: {\n    includeExtensions: true,\n    includeQuery: false,\n  }\n})`\nFrom the context `http` object:\n\n`includeExtensions`: Send the extensions object for this request.\n`includeQuery`: Don't send the `query` field for this request.\n\nSee the http option fields for more information.\nOne way to use persisted queries is with apollo-link-persisted-queries and Apollo Server.\nCustom fetching",
    "tag": "apollo-client"
  },
  {
    "title": "Constructor",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-ws.md",
    "content": "\ntitle: WebSocket Link\ndescription: Execute subscriptions (or other operations) over WebSocket with the subscriptions-transport-ws library\napi_reference: true\n\n\n\u26a0\ufe0f We no longer recommend using `WebSocketLink` or the `subscriptions-transport-ws` library, because the library is not actively maintained. To execute subscriptions, We instead recommend using the newer `graphql-ws` library with the accompanying GraphQLWsLink.\nWhichever library you use, make sure you use the same library in your server and any clients you support. For more information, see Choosing a subscription library.\nWe recommend reading Apollo Link overview before learning about individual links.\n\nThe `WebSocketLink` is a terminating link that's used most commonly with GraphQL subscriptions (which usually communicate over WebSocket), although you can send queries and mutations over WebSocket as well.\n`WebSocketLink` requires the subscriptions-transport-ws library. Install it in your project like so:\n`shell\nnpm install subscriptions-transport-ws`\nConstructor\n```js\nimport { WebSocketLink } from \"@apollo/client/link/ws\";\nimport { SubscriptionClient } from \"subscriptions-transport-ws\";\nconst link = new WebSocketLink(\n  new SubscriptionClient(\"ws://localhost:4000/graphql\", {\n    reconnect: true\n  })\n);\n```\nOptions\nThe `WebSocketLink` constructor takes either a `SubscriptionClient` object or an options object with the following fields. (These options are passed directly to the `SubscriptionClient` constructor.)\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `uri`\n\n`String`\n\n\n\n**Required.** The URL of the WebSocket endpoint to connect to (e.g., `ws://localhost:4000/subscriptions`).\n\n\n\n\n\n\n###### `options`\n\n`Object`\n\n\n\nOptions for configuring the WebSocket connection.\n\n[See supported options](https://github.com/apollographql/subscriptions-transport-ws/blob/master/src/client.ts#L61-L71)\n\n\n\n\n\n\n###### `webSocketImpl`\n\n`Object`\n\n\n\nA W3C-compliant WebSocket implementation to use. Provide this if your environment does not provide native WebSocket support (for example, in Node.js).\n\n\n\n\n\nUsage",
    "tag": "apollo-client"
  },
  {
    "title": "community-links.md",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/community-links.md",
    "content": "\ntitle: Community links\nThank you to all the Apollo community members who have contributed custom Apollo links! If you've built a link and would like it to be featured, please submit a pull request.\n\nLinks that do not appear to be actively maintained might be removed from this list at Apollo's discretion.\n\n| Link | Author | Description |\n|------|--------|-------------|\n| apollo-link-webworker | @PCreations | Lets you use GraphQL client-side only, with a webworker as a \"server\" supporting normal query and subscriptions. |\n| apollo-upload-client | @jaydenseric | Enhances Apollo for intuitive file uploads via GraphQL mutations. |\n| apollo-angular-link-http | @kamilkisiela | An HTTP link for use with Apollo Angular. |\n| apollo-angular-link-headers | @kamilkisiela | Transform a key-value object into an instance of `HttpHeaders` (`@angular/common/http`). |\n| react-apollo-network-status | @amannn | Brings information about the global network status from Apollo into React. |\n| apollo-link-watched-mutation | @haytko | Organizes cache invalidations per query on a mutation. |\n| apollo-link-token-refresh | @newsiberian | Performs expired JWT renewal. |\n| link-http-dataloader | @graphcool | Batching and caching provided by dataloader. |\n| @absinthe/socket-apollo-link | @absinthe-graphql | Communicate over an Absinthe socket. |\n| apollo-absinthe-upload-link | @bytewitchcraft | Enables file uploading to Absinthe backends. |\n| apollo-link-logger | @blackxored | Logger that uses similar format to redux-logger and includes performance information. |\n| apollo-link-queue | @helfer | Buffers requests on a toggle, such as an on/offline event. |\n| apollo-link-optimistic | @helfer | Returns an immediate optimistic response before returning server results. |\n| apollo-link-serialize | @helfer | Serializes requests by key to ensure execution order. |\n| apollo-link-debounce | @helfer | Debounce requests made within an interval. |\n| apollo-link-segment | @hobochild | Automatically track apollo operations with segment. |\n| apollo-link-observable | @dragozin | Link that allows you to make side effects of graphql queries using RxJS. |\n| apollo-multi-endpoint-link | @habx | Add directive to redirect requests to right endpoint |",
    "tag": "apollo-client"
  },
  {
    "title": "Options",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-error.md",
    "content": "\ntitle: Error Link\ndescription: Handle and inspect errors in your GraphQL network stack.\n\n\nWe recommend reading Apollo Link overview before learning about individual links.\n\nUse the `onError` link to perform custom logic when a GraphQL or network error occurs. You pass this link a function that's executed if an operation returns one or more errors:\n```js\nimport { onError } from \"@apollo/client/link/error\";\n// Log any GraphQL errors or network error that occurred\nconst errorLink = onError(({ graphQLErrors, networkError }) => {\n  if (graphQLErrors)\n    graphQLErrors.forEach(({ message, locations, path }) =>\n      console.log(\n        `[GraphQL error]: Message: ${message}, Location: ${locations}, Path: ${path}`\n      )\n    );\n  if (networkError) console.log(`[Network error]: ${networkError}`);\n});\n```\nThis function is called after the GraphQL operation completes and execution is moving back up your link chain. The function should not return a value unless you want to retry the operation.\nOptions\nThe function you provide the `onError` link is passed an object with the following fields:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `operation`\n\n`Operation`\n\n\n\nThe details of the GraphQL operation that produced an error.\n\n[See type definition](https://github.com/apollographql/apollo-client/blob/main/src/link/core/types.ts#L14-L21)\n\n\n\n\n\n###### `response`\n\n`ExecutionResult`\n\n\n\nThe (possibly modified) GraphQL result from the server, passed by the next link down the chain (i.e., the link closer to the terminating link).\n\n[See type definition](https://github.com/graphql/graphql-js/blob/main/src/execution/execute.ts#L104-L111)\n\n\n\n\n\n###### `graphQLErrors`\n\n`ReadonlyArray`\n\n\n\nAn array of [GraphQL errors](../../data/error-handling/#graphql-errors) that occurred while executing the operation, if any.\n\n[See type definition](https://github.com/graphql/graphql-js/blob/main/src/error/GraphQLError.ts)\n\n\n\n\n\n\n###### `networkError`\n\n`Error | ServerError | ServerParseError`\n\n\n\nA network error that occurred while attempting to execute the operation, if any.\n\n\n\n\n\n\n###### `forward`\n\n`function`\n\n\n\nA function that calls the next link down the chain. Calling `return forward(operation)` in your `onError` callback [retries the operation](../../data/error-handling#retrying-operations), returning a new observable for the upstream link to subscribe to.\n\n\n\n\n\nError categorization\nAn error is passed as a `networkError` if a link further down the chain called the `error` callback on the observable. In most cases, `graphQLErrors` is the `errors` field of the result from the last `next` call.",
    "tag": "apollo-client"
  },
  {
    "title": "Overview",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-rest.md",
    "content": "\ntitle: REST Link\ndescription: Call REST APIs inside your GraphQL queries.\n\nOverview\n\nThe Apollo Link Rest library is maintained by Apollo community members and not an Apollo GraphQL maintained library.\n\nCalling REST APIs from a GraphQL client opens the benefits of GraphQL for more people, whether:\n\nYou are in a front-end developer team that wants to try GraphQL without asking for the backend team to implement a GraphQL server.\nYou have no access to change the backend because it's an existing set of APIs, potentially managed by a 3rd party.\nYou have an existing codebase, but you're looking to evaluate whether GraphQL can work for your needs.\nYou have a large codebase, and the GraphQL migration is happening on the backend, but you want to use GraphQL now without waiting!\n\nWith `apollo-link-rest`, you can call your endpoints inside your GraphQL queries and have all your data managed by Apollo Client. `apollo-link-rest` is suitable for just dipping your toes in the water, or doing a full-steam ahead integration, and then later on migrating to a backend-driven GraphQL experience.\n\nFor more advanced or complex back-ends, you may want to consider using @apollo/server.\n\nQuick start\nTo get started, first install Apollo Client and any `peerDependencies` we need:\n`bash\nnpm install --save @apollo/client apollo-link-rest graphql qs`\nAfter this, you're ready to setup the Apollo Client instance:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nimport { RestLink } from 'apollo-link-rest';\n// Set `RestLink` with your endpoint\nconst restLink = new RestLink({ uri: \"https://swapi.dev/api/\" });\n// Setup your client\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: restLink\n});\n```\nNow it's time to write our first query:\n```js\nimport { gql } from '@apollo/client';\nconst query = gql`query Luke {\n    person @rest(type: \"Person\", path: \"people/1/\") {\n      name\n    }\n  }`;\n```\nYou can then fetch your data using Apollo Client:\n`js\n// Invoke the query and log the person's name\nclient.query({ query }).then(response => {\n  console.log(response.data.person.name);\n});`\nOptions\nThe `RestLink` constructor accepts an options object that can be used to customize the behavior of the link. Supported options are outlined below:\n| Option | Type | Description |\n| - | - | - |\n| `uri` | `string` | The URI key is a string endpoint/domain for your requests to hit (optional when `endpoints` provides a default) |\n| `endpoints: /map-of-endpoints/` | `any` | optional A map of endpoints. If you use this, you need to provide `endpoint` to the `@rest(...)` directives. |\n| `customFetch?` | `any` | optional A custom `fetch` to handle `REST` calls |\n| `headers?` | `Headers` | optional An object representing values to be sent as headers with all requests. Documented here |\n| `credentials?` | `string` | optional A string representing the credentials policy the fetch call should operate with. Document here |\n| `fieldNameNormalizer?: /function/` | `any` | optional A function that takes the response field name and converts it into a GraphQL compliant name. This is useful if your `REST` API returns fields that aren't representable as GraphQL, or if you want to convert between `snake_case` field names in JSON to `camelCase` keyed fields. |\n| `fieldNameDenormalizer?: /function/` | `any` | optional A function that takes a GraphQL-compliant field name and converts it back into an endpoint-specific name. |\n| `typePatcher: /map-of-functions/` | `any` | optional A structure to allow you to specify the `__typename` when you have nested objects in your REST response. |\n| `defaultSerializer /function/` | `any` | optional A function that will be used by the `RestLink` as the default serializer when no `bodySerializer` is defined for a `@rest` call. The function will also be passed the current `Header` set, which can be updated before the request is sent to `fetch`. Default method uses `JSON.stringify` and sets the `Content-Type` to `application/json`. |\n| `bodySerializers: /map-of-functions/` | `any` | optional Structure to allow the definition of alternative serializers, which can then be specified by their key. |\n| `responseTransformer?: /function/` | `any` | optional Apollo expects a record response to return a root object, and a collection of records response to return an array of objects. Use this function to structure the response into the format Apollo expects if your response data is structured differently. |\nMultiple endpoints\nIf you want to be able to use multiple endpoints, you can create your link like:\n`js\nconst link = new RestLink({ endpoints: { v1: 'api.com/v1', v2: 'api.com/v2' } });`\nYou then need to specify the endpoint you want to use, in the rest directive:\n`js\nconst postTitleQuery1 = gql`\n  query PostTitle {\n    post @rest(type: \"Post\", path: \"/post\", endpoint: \"v1\") {\n      id\n      title\n    }\n  }\n`;\nconst postTitleQuery2 = gql`\n  query PostTitle {\n    post @rest(type: \"[Tag]\", path: \"/tags\", endpoint: \"v2\") {\n      id\n      tags\n    }\n  }\n`;`\nIf you have a default endpoint, you can create your link like:\n`js\nconst link = new RestLink({\n  endpoints: { github: 'github.com' },\n  uri: 'api.com',\n});`\nIf you don't specify an endpoint in your query, the default endpoint (the one you specify in the `uri` option) will be used.\nTypename patching\nWhen sending a query like:\n`graphql\nquery MyQuery {\n  planets @rest(type: \"PlanetPayload\", path: \"planets/\") {\n    count\n    next\n    results {\n      name\n    }\n  }\n}`\nthe outer response object (`data.planets`) gets its `__typename: \"PlanetPayload\"` from the @rest(...) directive's type parameter. You, however, need to have a way to set the typename of `PlanetPayload.results`.\nOne way you can do this is by providing a `typePatcher`:\n`typescript\nconst restLink = new RestLink({\n  uri: '/api',\n  typePatcher: {\n    PlanetPayload: (\n      data: any,\n      outerType: string,\n      patchDeeper: RestLink.FunctionalTypePatcher,\n    ): any => {\n      if (data.results != null) {\n        data.results =\n          data.results.map(planet => ({ __typename: \"Planet\", ...planet }));\n      }\n      return data;\n    },\n    // ... other nested type patchers\n  },\n})`\nIf you have a very lightweight REST integration, you can use the `@type(name: ...)` directive.\n`graphql\nquery MyQuery {\n  planets @rest(type: \"PlanetPayload\", path: \"planets/\") {\n    count\n    next\n    results @type(name: \"Planet\") {\n      name\n    }\n  }\n}`\nThis is appropriate if you have a small list of nested objects. The cost of this strategy is that every query that deals with these objects needs to also include `@type(name: ...)`, which means this approach can be quite verbose and error prone.\nYou can also use both of these approaches in tandem:\n`graphql\nquery MyQuery {\n  planets @rest(type: \"PlanetPayload\", path: \"planets/\") {\n    count\n    next\n    results @type(name: \"Results\") {\n      name\n    }\n    typePatchedResults {\n      name\n    }\n  }\n}`\n`typescript\nconst restLink = new RestLink({\n  uri: '/api',\n  typePatcher: {\n    PlanetPayload: (\n      data: any,\n      outerType: string,\n      patchDeeper: RestLink.FunctionalTypePatcher,\n    ): any => {\n      if (data.typePatchedResults != null) {\n        data.typePatchedResults =\n          data.typePatchedResults.map(planet => { __typename: \"Planet\", ...planet });\n      }\n      return data;\n    },\n    // ... other nested type patchers\n  },\n})`\nWarning\nIt's important to note that at the moment the `typePatcher` is not able to act on nested objects within annotated `@type` objects. For instance, `failingResults` will not be patched if you define it on the `typePatcher`:\n`graphql\nquery MyQuery {\n  planets @rest(type: \"PlanetPayload\", path: \"planets/\") {\n    count\n    next\n    results @type(name: \"Planet\") {\n      name\n      failingResults {\n        name\n      }\n    }\n    typePatchedResults {\n      name\n    }\n  }\n}`\nTo make this work you should try to pick one strategy, and stick with it -- either all `typePatcher` or all `@type` directives.\nResponse transforming\nBy default, Apollo expects an object at the root for record requests, and an array of objects at the root for collection requests. For example, if fetching a user by ID (`/users/1`), the following response is expected.\n`json\n{\n  \"id\": 1,\n  \"name\": \"Apollo\"\n}`\nAnd when fetching for a list of users (`/users`), the following response is expected.\n`json\n[\n  {\n    \"id\": 1,\n    \"name\": \"Apollo\"\n  },\n  {\n    \"id\": 2,\n    \"name\": \"Starman\"\n  }\n]`\nIf the structure of your API responses differs than what Apollo expects, you can define a `responseTransformer` in the client. This function receives the response object as the 1st argument, and the current `typeName` as the 2nd argument. It should return a `Promise` as it will be responsible for reading the response stream by calling one of `json()`, `text()` etc.\nFor example, if the record is not at the root level:\n`json\n{\n  \"meta\": {},\n  \"data\": [\n    {\n      \"id\": 1,\n      \"name\": \"Apollo\"\n    },\n    {\n      \"id\": 2,\n      \"name\": \"Starman\"\n    }\n  ]\n}`\nThe following transformer could be used to support it:\n`js\nconst link = new RestLink({\n  uri: '/api',\n  responseTransformer: async response => response.json().then(({data}) => data),\n});`\nPlaintext, XML, or otherwise-encoded responses can be handled by manually parsing and converting them to JSON (using the previously described format that Apollo expects):\n`js\nconst link = new RestLink({\n  uri: '/xmlApi',\n  responseTransformer: async response => response.text().then(text => parseXmlResponseToJson(text)),\n});`\nCustom endpoint responses\nThe client level `responseTransformer` applies for all responses, across all URIs and endpoints. If you need a custom `responseTransformer` per endpoint, you can define an object of options for that specific endpoint.\n`js\nconst link = new RestLink({\n  endpoints: {\n    v1: {\n      uri: '/v1',\n      responseTransformer: async response => response.data,\n    },\n    v2: {\n      uri: '/v2',\n      responseTransformer: async (response, typeName) => response[typeName],\n    },\n  },\n});`\n\nWhen using the object form, the `uri` field is required.\n\nCustom Fetch\nBy default, Apollo uses the browsers `fetch` method to handle `REST` requests to your domain/endpoint. The `customFetch` option allows you to specify your own request handler by defining a function that returns a `Promise` with a fetch-response-like object:\n`js\nconst link = new RestLink({\n  endpoints: \"/api\",\n  customFetch: (uri, options) => new Promise((resolve, reject) => {\n    // Your own (asynchronous) request handler\n    resolve(responseObject)\n  }),\n});`\nTo resolve your GraphQL queries quickly, Apollo will issue requests to relevant endpoints as soon as possible. This is generally ok, but can lead to large numbers of `REST` requests to be fired at once; especially for deeply nested queries (see @export directive).\n\nSome endpoints (like public APIs) might enforce rate limits, leading to failed responses and unresolved queries in such cases.\n\nBy example, `customFetch` is a good place to manage your apps fetch operations. The following implementation makes sure to only issue 2 requests at a time (concurrency) while waiting at least 500ms until the next batch of requests is fired.\n```js\nimport pThrottle from \"p-throttle\";\nconst link = new RestLink({\n  endpoints: \"/api\",\n  customFetch: pThrottle((uri, config) => {\n      return fetch(uri, config);\n    },\n    2, // Max. concurrent Requests\n    500 // Min. delay between calls\n  ),\n});\n```\n\nSince Apollo issues `Promise` based requests, we can resolve them as we see fit. This example uses pThrottle; part of the popular promise-fun collection.\n\nComplete options\nHere is one way you might customize `RestLink`:\n```js\nimport fetch from 'cross-fetch';\nimport * as camelCase from 'camelcase';\nimport * as snake_case from 'snake-case';\nconst link = new RestLink({\n  endpoints: { github: 'github.com' },\n  uri: 'api.com',\n  customFetch: fetch,\n  headers: {\n    \"Content-Type\": \"application/json\"\n  },\n  credentials: \"same-origin\",\n  fieldNameNormalizer: (key: string) => camelCase(key),\n  fieldNameDenormalizer: (key: string) => snake_case(key),\n  typePatcher: {\n    Post: ()=> {\n      bodySnippet...\n    }\n  },\n  defaultSerializer: (data: any, headers: Headers) => {\n    const formData = new FormData();\n    for (let key in data) {\n      formData.append(key, data[key]);\n    }\n    headers.set(\"Content-Type\", \"x-www-form-encoded\")\n    return {data: formData, headers};\n  }\n});\n```\nLink Context\n`RestLink` has an interface LinkChainContext which it uses as the structure of things that it will look for in the `context`, as it decides how to fulfill a specific `RestLink` request. (Please see the @apollo/client/link/context page for a discussion of why you might want this).\n| Option | Type | Description |\n| - | - | - |\n| `credentials?` | `RequestCredentials` | Overrides the `RestLink`-level setting for `credentials`. Values documented here |\n| `headers?` | `Headers` | Additional headers provided in this `context-link` Values documented here |\n| `headersToOverride?` | `string[]` | If you provide this array, we will merge the headers you provide in this link, by replacing any matching headers that exist in the root `RestLink` configuration. Alternatively you can use `headersMergePolicy` for more fine-grained customization of the merging behavior. |\n| `headersMergePolicy?` | `RestLink.HeadersMergePolicy` | This is a function that decide how the headers returned in this `contextLink` are merged with headers defined at the `RestLink`-level. If you don't provide this, the headers will be simply appended. To use this option, you can provide your own function that decides how to process the headers. Code references |\n| `restResponses?` | `Response[]` | This will be populated after the operation has completed with the Responses of every REST url fetched during the operation. This can be useful if you need to access the response headers to grab an authorization token for example. |\nExample\n`RestLink` uses the `headers` field on the @apollo/client/link/context so you can compose other links that provide additional & dynamic headers to a given query.\nHere is one way to add request `headers` to the context and retrieve the response headers of the operation:\n```js\nconst authRestLink = new ApolloLink((operation, forward) => {\n  operation.setContext(({headers}) => {\n    const token = localStorage.getItem(\"token\");\n    return {\n      headers: {\n        ...headers,\n        Accept: \"application/json\",\n        Authorization: token\n      }\n    };\n  });\n  return forward(operation).map(result => {\n    const { restResponses } = operation.getContext();\n    const authTokenResponse = restResponses.find(res => res.headers.has(\"Authorization\"));\n    // You might also filter on res.url to find the response of a specific API call\n    if (authTokenResponse) {\n      localStorage.setItem(\"token\", authTokenResponse.headers.get(\"Authorization\"));\n    }\n    return result;\n  });\n});\nconst restLink = new RestLink({ uri: \"uri\" });\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: ApolloLink.from([authRestLink, restLink])\n});\n```\nLink order\nIf you are using multiple link types, `restLink` should go before `httpLink`, as `httpLink` will swallow any calls that should be routed through `apollo-link-rest`.\nFor example:\n```js\nconst httpLink = createHttpLink({ uri: \"server.com/graphql\" });\nconst restLink = new RestLink({ uri: \"api.server.com\" });\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: ApolloLink.from([authLink, restLink, errorLink, retryLink, httpLink])\n  // Note: httpLink is terminating so must be last, while retry & error wrap\n  // the links to their right. State & context links should happen before (to\n  // the left of) restLink.\n});\n```\nNote: you should also consider this if you're using @apollo/client/link/context to set `Headers`, you need that link to be before `restLink` as well.\n@rest directive\nThis is where you setup the endpoint you want to fetch. The rest directive can be used at any depth in a query.\nArguments\nAn `@rest(\u2026)` directive takes two required and several optional arguments:\n| Option | Type | Description |\n| - | - | - |\n| `type` | `string` | The GraphQL type this will return |\n| `path` | `string` | uri-path to the REST API. This could be a path or a full url. If a path, the endpoint given on link creation or from the context is concatenated with it to produce a full `URI`. See also: `pathBuilder` |\n| `method?` | `GET` `PUT` `POST` `DELETE` | The HTTP method to send the request via (i.e GET, PUT, POST) |\n| `endpoint?` | `string` | Key to use when looking up the endpoint in the (optional) `endpoints` table if provided to RestLink at creation time. |\n| `pathBuilder?: /function/` | `string` | If provided, this function gets to control what path is produced for this request. |\n| `bodyKey?: \"input\"` | `string` | This is the name of the `variable` to use when looking to build a REST request-body for a `PUT` or `POST` request. It defaults to `input` if not supplied. |\n| `bodyBuilder?: /function/` | `string` | If provided, this is the name a `function` that you provided to `variables`, that is called when a request-body needs to be built. This lets you combine arguments or encode the body in some format other than JSON. |\n| `bodySerializer?: /string \\| function/` | `string` | String key to look up a function in `bodySerializers` or a custom serialization function for the body/headers of this request before it is passed to the fetch call. Defaults to `JSON.stringify` and setting `Content-Type: application-json`. |\nVariables\nYou can use query `variables` inside nested queries, or in the the path argument of your directive:\n`graphql\nquery PostTitle {\n  post(id: \"1\") @rest(type: \"Post\", path: \"/post/{args.id}\") {\n    id\n    title\n  }\n}`\n\nWarning: Variables in the main path will not automatically have `encodeURIComponent` called on them.\n\nAdditionally, you can also control the query-string:\n`graphql\nquery PostTitle {\n  postSearch(query: \"some key words\", page_size: 5)\n    @rest(type: \"Post\", path: \"/search?{args}&{context.language}\") {\n    id\n    title\n  }\n}`\nThings to note:\n\nThis will be converted into `/search?query=some%20key%20words&page_size=5&lang=en`\nThe `context.language / lang=en` is extracting an object from the Apollo Context, that was added via an `@apollo/client/link/context` Link.\nThe query string arguments are assembled by npm:qs and have `encodeURIComponent` called on them.\n\nThe available variable sources are:\n| Option | Description |\n| - | - |\n| `args` | These are the things passed directly to this field parameters. In the above example `postSearch` had `query` and `page_size` in args. |\n| `exportVariables` | These are the things in the parent context that were tagged as `@export(as: ...)` |\n| `context` | These are the apollo-context, so you can have globals set up via `@apollo/client/link/context` |\n| `@rest` | These include any other parameters you pass to the `@rest()` directive. This is probably more useful when working with `pathBuilder`, documented below. |\n`pathBuilder`\nIf the variable-replacement options described above aren't enough, you can provide a `pathBuilder` to your query. This will be called to dynamically construct the path. This is considered an advanced feature, and is documented in the source -- it also should be considered syntactically unstable, and we're looking for feedback!\n`bodyKey` / `bodyBuilder`\nWhen making a `POST` or `PUT` HTTP request, you often need to provide a request body. By convention, GraphQL recommends you name your input-types as `input`, so by default that's where we'll look to find a JSON object for your body.\n`bodyKey`\nIf you need/want to name it something different, you can pass `bodyKey`, and we'll look at that variable instead.\nIn this example the publish API accepts a body in the variable `body` instead of input:\n`graphql\nmutation PublishPost(\n  $someApiWithACustomBodyKey: PublishablePostInput!\n) {\n  publishedPost: publish(input: \"Foo\", body: $someApiWithACustomBodyKey)\n    @rest(\n      type: \"Post\"\n      path: \"/posts/{args.input}/new\"\n      method: \"POST\"\n      bodyKey: \"body\"\n    ) {\n    id\n    title\n  }\n}`\nUnit Test\n`bodyBuilder`\nIf you need to structure your data differently, or you need to custom encode your body (say as form-encoded), you can provide `bodyBuilder` instead:\n`graphql\nmutation EncryptedPost(\n  $input: PublishablePostInput!\n  $encryptor: any\n) {\n  publishedPost: publish(input: $input)\n    @rest(\n      type: \"Post\"\n      path: \"/posts/new\"\n      method: \"POST\"\n      bodyBuilder: $encryptor\n    ) {\n    id\n    title\n  }\n}`\nUnit Test\n`bodySerializer`\nIf you need to serialize your data differently (say as form-encoded), you can provide a `bodySerializer` instead of relying on the default JSON serialization.\n`bodySerializer` can be either a function of the form `(data: any, headers: Headers) => {body: any, header: Headers}` or a string key. When using the string key\n`RestLink` will instead use the corresponding serializer from the `bodySerializers` object, that can optionally be passed in during initialization.\n```graphql\nmutation EncryptedForm(\n  $input: PublishablePostInput!,\n  $formSerializer: any\n) {\n  publishedPost: publish(input: $input)\n    @rest(\n      type: \"Post\",\n      path: \"/posts/new\",\n      method: \"POST\",\n      bodySerializer: $formSerializer\n    ) {\n      id\n      title\n    }\npublishRSS(input: $input)\n    @rest(\n      type: \"Post\",\n      path: \"/feed\",\n      method: \"POST\",\n      bodySerializer: \"xml\"\n    )\n}\n```\nWhere `formSerializer` could be defined as\n```typescript\nconst formSerializer = (data: any, headers: Headers) => {\n  const formData = new FormData();\n  for (let key in data) {\n    if (data.hasOwnProperty(key)) {\n      formData.append(key, data[key]);\n    }\n  }\nheaders.set('Content-Type', 'application/x-www-form-urlencoded');\nreturn {body: formData, headers};\n}\n```\nAnd `\"xml\"` would have been defined on the `RestLink` directly\n`typescript\nconst restLink = new RestLink({\n  ...otherOptions,\n  bodySerializers: {\n    xml: xmlSerializer\n  }\n})`\n@export directive\nThe export directive re-exposes a field for use in a later (nested) query. These are the same semantics that will be supported on the server, but when used in a `RestLink` you can use the exported variables for further calls (i.e. waterfall requests from nested fields).\nNote: If you're constantly using @export you may prefer to take a look at @apollo/server.\nArguments\n\n`as: string`: name to create this as a variable to be used down the selection set\n\nExample\nAn example use-case would be getting a list of users, and hitting a different endpoint to fetch more data using the exported field in the REST query args.\n`graphql\nconst QUERY = gql`\n  query RestData($email: String!) {\n    users @rest(path: '/users/email?{args.email}', method: 'GET', type: 'User') {\n      id @export(as: \"id\")\n      firstName\n      lastName\n      friends @rest(path: '/friends/{exportVariables.id}', type: '[User]') {\n        firstName\n        lastName\n      }\n    }\n  }\n`;`\nMutations\nYou can write also mutations with the apollo-link-rest, for example:\n`graphql\nmutation DeletePost($id: ID!) {\n  deletePostResponse(id: $id)\n    @rest(type: \"Post\", path: \"/posts/{args.id}\", method: \"DELETE\") {\n    NoResponse\n  }\n}`\nTroubleshooting\nHere are a few common `apollo-link-rest` problems and solutions.\n\n`Missing field __typename in ...` -- If you see this, it's possible you haven't provided `type:` to the @rest(...)-directive. Alternately you need to set up a typePatcher.\n`Headers is undefined` -- If you see something like this, you're running in a browser or other Javascript environment that does not yet support the full specification for the `Headers` API.\n\nExample apps\nTo get you started, here are some example apps:\n\nSimple:\n  A very simple app with a single query that reflects the setup section.\nAdvanced:\n  A more complex app that demonstrates how to use an export directive.\n\nContributing",
    "tag": "apollo-client"
  },
  {
    "title": "Your first link chain",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/introduction.mdx",
    "content": "\ntitle: Apollo Link overview\ndescription: Customize Apollo Client's data flow\n\nimport LinkChain from '../../../shared/link-chain.mdx';\n\nIf your application only needs to send conventional HTTP-based requests to a GraphQL server, you probably don't need to use the Apollo Link API. See Basic HTTP networking.\n\nThe Apollo Link library helps you customize the flow of data between Apollo Client and your GraphQL server. You can define your client's network behavior as a chain of link objects that execute in a sequence:\n`mermaid\nflowchart LR\n  subgraph Apollo Client\n  operation(GraphQL operation)\n  link1(Link)\n  link2(Link)\n  link3(Terminating Link)\n  operation--\"Initiated\"-->link1\n  link1--down-->link2\n  link2--down-->link3\n  link3--up-->link2\n  link2--up-->link1\n  link1--\"Completed\"-->operation\n  end\n  server(GraphQL server)\n  link3--Request-->server\n  server--Response-->link3\n  class server secondary;`\nEach link should represent either a self-contained modification to a GraphQL operation or a side effect (such as logging).\nIn the above diagram:\n\nThe first link might log the details of the operation for debugging purposes.\nThe second link might add an HTTP header to the outgoing operation request for authentication purposes.\nThe final (terminating) link sends the operation to its destination (usually a GraphQL server over HTTP).\nThe server's response is passed back up each link in reverse order, enabling links to modify the response or take other actions before the data is cached.\n\nBy default, Apollo Client uses Apollo Link's `HttpLink` to send GraphQL operations to a remote server over HTTP. Apollo Client takes care of creating this default link, and it covers many use cases without requiring additional customization.\nTo extend or replace this default networking behavior, you can define custom links and specify their order of execution in the `ApolloClient` constructor.\nYour first link chain\nThe example below demonstrates a basic link chain with two Apollo-provided links:\n\nAn `onError` link that checks for errors in the server's response. It logs the details of whichever error(s) it finds.\nAn `HttpLink` that sends each GraphQL operation to your server.\nThis is the chain's terminating link.\n\n\n\nNote that if you provide a link chain to the `ApolloClient` constructor, you don't provide the `uri` option. Instead, you provide your server's URL to your `HttpLink`.\n\n\n\nCreating a custom link\nA link object is an instance of the ApolloLink class (or a subclass of it). Each link must define a method named `request`, which is known as the link's request handler. You can provide this method's definition to the `ApolloLink` constructor.\nExample\nThe following custom link defines a request handler that adds a GraphQL operation's approximate start time to the operation's context:\n```js\nimport { ApolloLink } from '@apollo/client';\nconst timeStartLink = new ApolloLink((operation, forward) => {\n  operation.setContext({ start: new Date() });\n  return forward(operation);\n});\n```\nThis request handler then calls `return forward(operation)`, which is the syntax for calling the next link down the chain.\nThe request handler\nEvery link must define a `request` method, also known as its request handler. This method is passed the following arguments:\n\n`operation`: The GraphQL operation that's being passed through the link.\nFor details, see The Operation object.\n\n\n`forward`: A function for executing the next link in the chain (unless this is a terminating link).\n\nWhenever Apollo Client prepares to execute a GraphQL operation, it calls the request handler of the first link in the chain. Each link is responsible for executing its logic and then passing execution to the next link by calling the forward function and returning its result.\nThe `Operation` object\nThe `Operation` object includes the following fields:\n| Name  | Description  |\n|---|---|\n| `query`  | A `DocumentNode` (parsed GraphQL operation) that describes the operation taking place.  |\n| `variables`  | A map of GraphQL variables being sent with the operation.  |\n| `operationName`  | A string name of the query if it is named, otherwise `null`.  |\n| `extensions`  |  A map to store extensions data to be sent to the server. |\n| `getContext`  | A function to return the context of the request. This context can be used by links to determine which actions to perform. See Managing context. |\n| `setContext`  |  A function that takes either a new context object, or a function which takes in the previous context and returns a new one. See Managing context. |\nThe `forward` function\nWhen your custom link's request handler is done executing its logic, it should return a call to the `forward` function that's passed to it (unless it's the chain's terminating link). Calling `return forward(operation)` passes execution along to the next link in the chain.\n\nIf a non-terminating custom link's request handler doesn't `return forward(operation)`, the link chain ends and the associated GraphQL operation is not executed.\n\nThe `forward` function's return type is an `Observable` provided by the zen-observable library. See the `zen-observable` documentation for details.\nHandling a response\nWhen your GraphQL server responds with an operation result, that result is passed back up through each link in your link chain before it's cached:\n`mermaid\nflowchart LR\n  subgraph Apollo Client\n  operation(GraphQL operation)\n  link1(Link)\n  link2(Link)\n  link3(Terminating Link)\n  operation--\"Initiated\"-->link1\n  link1--down-->link2\n  link2--down-->link3\n  link3--up-->link2\n  link2--up-->link1\n  link1--\"Completed\"-->operation\n  end\n  server(GraphQL server)\n  link3--Request-->server\n  server--Response-->link3\n  class server secondary;`\nEach link can execute logic while the result is being passed back by modifying their request handler's `return` statement, like so:\n```js {4-8}\n// BEFORE (NO INTERACTION)\nreturn forward(operation);\n// AFTER\nreturn forward(operation).map((data) => {\n  // ...modify result as desired here...\n  return data;\n});\n```\nWhatever the function provided to `map` returns is passed to the next link up the chain.\nYou can also perform logic here that has nothing to do with the result. This request handler uses the request context to estimate the round-trip time for each operation:\n```js\nimport { ApolloLink } from '@apollo/client';\nconst roundTripLink = new ApolloLink((operation, forward) => {\n  // Called before operation is sent to server\n  operation.setContext({ start: new Date() });\nreturn forward(operation).map((data) => {\n    // Called after server responds\n    const time = new Date() - operation.getContext().start;\n    console.log(`Operation ${operation.operationName} took ${time} to complete`);\n    return data;\n  });\n});\n```\nComposing a link chain\nEach link represents either a self-contained modification to a GraphQL operation or a side effect (such as logging). By composing these links into a chain, you can create an arbitrarily complex model for your client's data flow.\nThere are two forms of link composition: additive and directional.\n\n\nAdditive composition involves combining a set of links into a serially executed chain:\n`mermaid\nflowchart LR\n  link1(Link)\n  link2(Link)\n  link3(Terminating Link)\n  link1-->link2\n  link2-->link3`\n\n\nDirectional composition involves branching to one of two links, depending on the details of an operation:\n`mermaid\nflowchart LR\n  link1(Link)\n  link2(Link)\n  link3(Terminating Link)\n  link4(Terminating Link)\n  link1-->link2\n  link1-->link3\n  link2-->link4`\n\n\nNote that no matter how your chain branches, each branch always ends in a terminating link.\nThe terminating link\nThe terminating link is the last link in a link chain. Instead of calling the `forward` function, the terminating link is responsible for sending your composed GraphQL operation to the destination that executes it (usually a GraphQL server) and returning an `ExecutionResult`.\nHttpLink and BatchHttpLink are both examples of terminating links.\nAdditive composition\nIf you have a collection of two or more links that should always be executed in serial order, use the `ApolloLink.from` helper method to combine those links into a single link, like so:\n```js\nimport { from, HttpLink } from '@apollo/client';\nimport { RetryLink } from '@apollo/client/link/retry';\nimport MyAuthLink from '../auth';\nconst additiveLink = from([\n  new RetryLink(),\n  new MyAuthLink(),\n  new HttpLink({ uri: 'http://localhost:4000/graphql' })\n]);\n```\nDirectional composition\nYou might want your link chain's execution to branch, depending on the details of the operation being performed.\nTo support this, the `@apollo/client` library provides a `split` function that lets you use one of two different `Link`s, according to the result of a boolean check. You can also use the `split` method of an `ApolloLink` instance.\n| Name  | Description  |\n|---|---|\n| `test`  | A function that takes in the current `Operation` and returns either `true` or `false` depending on its details.  |\n| `left`  | The link to execute next if the `test` function returns `true`.  |\n| `right`  | An optional link to execute next if the `test` function returns `false`. If this is not provided, the request handler's `forward` parameter is used. |\nIn the following example, a `RetryLink` passes execution along to one of two different `HttpLink`s depending on the associated context's `version`:\n```js\nimport { ApolloLink, HttpLink } from '@apollo/client';\nimport { RetryLink } from '@apollo/client/link/retry';\nconst directionalLink = new RetryLink().split(\n  (operation) => operation.getContext().version === 1,\n  new HttpLink({ uri: 'http://localhost:4000/v1/graphql' }),\n  new HttpLink({ uri: 'http://localhost:4000/v2/graphql' })\n);\n```\nOther uses for the `split` method include:\n\nCustomizing the number of allowed retry attempts depending on the operation type\nUsing different transport methods depending on the operation type (such as HTTP for queries and WebSocket for subscriptions)\nCustomizing logic depending on whether a user is logged in\n\nIn the following example, all subscription operations are sent to `GraphQLWsLink`, with all other operations sent to `HttpLink`:\n```js\nimport { split, HttpLink } from '@apollo/client';\nimport { getMainDefinition } from '@apollo/client/utilities';\nimport { GraphQLWsLink } from '@apollo/client/link/subscriptions';\nimport { createClient } from 'graphql-ws';\nexport const link = split(\n  ({ query }) => {\n    const definition = getMainDefinition(query);\n    return (\n      definition.kind === 'OperationDefinition' &&\n      definition.operation === 'subscription'\n    );\n  },\n  new GraphQLWsLink(createClient({ url: 'ws://localhost:3000/subscriptions' })),\n  new HttpLink({ uri: 'http://localhost:4000/graphql' })\n);\n```\nProviding to Apollo Client\nAfter you finish composing your entire link chain, you provide the resulting link to the constructor of `ApolloClient`, like so:\n```js {12}\nimport { ApolloClient, HttpLink, InMemoryCache } from '@apollo/client';\nimport { RetryLink } from '@apollo/client/link/retry';\nconst directionalLink = new RetryLink().split(\n  (operation) => operation.getContext().version === 1,\n  new HttpLink({ uri: \"http://localhost:4000/v1/graphql\" }),\n  new HttpLink({ uri: \"http://localhost:4000/v2/graphql\" })\n);\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: directionalLink\n});\n```\nLink types\nStateless links\nMost links perform the same logic for every operation they process, and they don't need to know anything about operations that have been executed previously. These links are stateless.\nYou can define the request handler for a stateless link in the constructor of an `ApolloLink` object, like so:\n```js\nimport { ApolloLink } from '@apollo/client';\nconst consoleLink = new ApolloLink((operation, forward) => {\n  console.log(`starting request for ${operation.operationName}`);\n  return forward(operation).map((data) => {\n    console.log(`ending request for ${operation.operationName}`);\n    return data;\n  })\n})\n```\nStateless links are great for implementing middleware and even network requests. The following link adds an `Authorization` header to every outgoing request:\n```js\nimport { ApolloLink } from '@apollo/client';\nconst authLink = new ApolloLink((operation, forward) => {\n  operation.setContext(({ headers }) => ({ headers: {\n    authorization: Auth.userId(), // however you get your token\n    ...headers\n  }}));\n  return forward(operation);\n});\n```\nThis style of link also composes well for customization using a function:\n```js\nimport { ApolloLink } from '@apollo/client';\nconst reportErrors = (errorCallback) => new ApolloLink((operation, forward) => {\n  const observable = forward(operation);\n  // errors will be sent to the errorCallback\n  observable.subscribe({ error: errorCallback })\n  return observable;\n});\nconst link = reportErrors(console.error);\n```\nExtending `ApolloLink`\nYou can also create a stateless link by extending the `ApolloLink` class and overwriting its constructor and request handler. For example, here's the same `reportErrors` link written as an extension of `ApolloLink`:\n```js\nimport { ApolloLink } from '@apollo/client';\nclass ReportErrorLink extends ApolloLink {\n  constructor(errorCallback) {\n    super();\n    this.errorCallback = errorCallback;\n  }\n  request(operation, forward) {\n    const observable = forward(operation);\n    // errors will be sent to the errorCallback\n    observable.subscribe({ error: this.errorCallback })\n    return observable;\n  }\n}\nconst link = new ReportErrorLink(console.error);\n```\nStateful links\nWhen it's useful, links can maintain state between operations. These links are stateful.\nStateful links are usually defined as subclasses of `ApolloLink`. They override the constructor of `ApolloLink` and implement a `request` function with the same signature as a stateless link. For example:\n```js\nimport { ApolloLink } from '@apollo/client';\nclass OperationCountLink extends ApolloLink {\n  constructor() {\n    super();\n    this.operationCount = 0;\n  }\n  request(operation, forward) {\n    this.operationCount += 1;\n    return forward(operation);\n  }\n}\nconst link = new OperationCountLink();\n```\nThis stateful link maintains a counter called `operationCount` as an instance variable. Every time a request is passed through the link, `operationCount` is incremented.\nManaging context\nAs an operation moves along your link chain, it maintains a `context` that each link can read and modify. This allows links to pass metadata along the chain that other links use in their execution logic.\n\nObtain the current context object by calling `operation.getContext()`.\nModify the context object and then write it back with `operation.setContext(newContext)` or `operation.setContext((prevContext) => newContext)`.\n\nNote that this context is not included in the terminating link's request to the GraphQL server or other destination.\nHere's an example:\n```js\nimport { ApolloLink, from } from '@apollo/client';\nconst timeStartLink = new ApolloLink((operation, forward) => {\n  operation.setContext({ start: new Date() });\n  return forward(operation);\n});\nconst logTimeLink = new ApolloLink((operation, forward) => {\n  return forward(operation).map((data) => {\n    // data from a previous link\n    const time = new Date() - operation.getContext().start;\n    console.log(`operation ${operation.operationName} took ${time} to complete`);\n    return data;\n  })\n});\nconst additiveLink = from([\n  timeStartLink,\n  logTimeLink\n]);\n```\nThis example defines two links, `timeStartLink` and `logTimeLink`. The `timeStartLink` assigns the current time to the context's `start` field. When the operation completes, the `logTimeLink` then subtracts the value of `start` from the current time to determine the total duration of the operation.",
    "tag": "apollo-client"
  },
  {
    "title": "Overview",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-context.md",
    "content": "\ntitle: Context Link\ndescription: Easily set a context on your operation, which is used by other links further down the chain.\n\nOverview\nThe `setContext` function accepts a function that returns either an object or a promise, which then returns an object to set the new context of a request. It receives two arguments: the GraphQL request being executed, and the previous context. This link makes it easy to perform the asynchronous lookup of things like authentication tokens and more.\n```js\nimport { setContext } from \"@apollo/client/link/context\";\nconst setAuthorizationLink = setContext((request, previousContext) => ({\n  headers: {authorization: \"1234\"}\n}));\nconst asyncAuthLink = setContext(\n  request =>\n    new Promise((success, fail) => {\n      // do some async lookup here\n      setTimeout(() => {\n        success({ token: \"async found token\" });\n      }, 10);\n    })\n);\n```\nCaching lookups\nTypically async actions can be expensive and may not need to be called for every request, especially when a lot of request are happening at once. You can setup your own caching and invalidation outside of the link, to make it faster but still flexible.\nTake for example a user auth token being found, cached, then removed on a 401 response:\n```js\nimport { setContext } from \"@apollo/client/link/context\";\nimport { onError } from \"@apollo/client/link/error\";\n// cached storage for the user token\nlet token;\nconst withToken = setContext(() => {\n  // if you have a cached value, return it immediately\n  if (token) return { token };\nreturn AsyncTokenLookup().then(userToken => {\n    token = userToken;\n    return { token };\n  });\n});\nconst resetToken = onError(({ networkError }) => {\n  if (\n    networkError &&\n    networkError.name ==='ServerError' &&\n    networkError.statusCode === 401\n  ) {\n    // remove cached token on 401 from the server\n    token = null;\n  }\n});\nconst authFlowLink = withToken.concat(resetToken);",
    "tag": "apollo-client"
  },
  {
    "title": "Problem to solve",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/persisted-queries.md",
    "content": "\ntitle: Persisted Queries Link\ndescription: Replace full queries with generated ID's to reduce bandwidth.\n\nProblem to solve\nUnlike REST APIs that use a fixed URL to load data, GraphQL provides a rich query language that can be used to express the shape of application data requirements. This is a marvelous advancement in technology, but it comes at a cost: GraphQL query strings are often much longer than REST URLS \u2014 in some cases by many kilobytes.\nIn practice we've seen GraphQL query sizes ranging well above 10 KB just for the query text. This is significant overhead when compared with a simple URL of 50-100 characters. When paired with the fact that the uplink speed from the client is typically the most bandwidth-constrained part of the chain, large queries can become bottlenecks for client performance.\nAutomatic Persisted Queries solves this problem by sending a generated ID instead of the query text as the request.\nFor more information about this solution, read this article announcing Automatic Persisted Queries.\nHow it works\n\nWhen the client makes a query, it will optimistically send a short (64-byte) cryptographic hash instead of the full query text.\nIf the backend recognizes the hash, it will retrieve the full text of the query and execute it.\nIf the backend doesn't recognize the hash, it will ask the client to send the hash and the query text so it can store them mapped together for future lookups. During this request, the backend will also fulfill the data request.\n\nThis library is a client implementation for use with Apollo Client by using custom Apollo Link.\nInstallation\nThis link is included in the `@apollo/client` package:\n`npm install @apollo/client`\nIf you do not already have a SHA-256 based hashing function available in your application, you will need to install one separately. For example:\n`npm install crypto-hash`\nThis link doesn't include a SHA-256 hash function by default, to avoid forcing one as a dependency. Developers should pick the most appropriate SHA-256 function (sync or async) for their needs/environment.\nUsage\nThe persisted query link requires using the `HttpLink`. The easiest way to use them together is to `concat` them into a single link.\n```js\nimport { HttpLink, InMemoryCache, ApolloClient } from \"@apollo/client\";\nimport { createPersistedQueryLink } from \"@apollo/client/link/persisted-queries\";\nimport { sha256 } from 'crypto-hash';\nconst httpLink = new HttpLink({ uri: \"/graphql\" });\nconst persistedQueriesLink = createPersistedQueryLink({ sha256 });\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: persistedQueriesLink.concat(httpLink),\n});\n```\nThats it! Now your client will start sending query signatures instead of the full text resulting in improved network performance!\nOptions\nThe `createPersistedQueryLink` function takes a configuration object:\n\n`sha256`: a SHA-256 hashing function. Can be sync or async. Providing a SHA-256 hashing function is required, unless you're defining a fully custom hashing approach via `generateHash`.\n`generateHash`: an optional function that takes the query document and returns the hash. If provided this custom function will override the default hashing approach that uses the supplied `sha256` function. If not provided, the persisted queries link will use a fallback hashing approach leveraging the `sha256` function.\n`useGETForHashedQueries`: set to `true` to use the HTTP `GET` method when sending the hashed version of queries (but not for mutations). `GET` requests are not compatible with `@apollo/client/link/batch-http`.\nIf you want to use `GET` for non-mutation queries whether or not they are hashed, pass `useGETForQueries: true` option to `HttpLink` instead. If you want to use `GET` for all requests, pass `fetchOptions: {method: 'GET'}` to `HttpLink`.\n\n\n`disable`: a function which takes an `ErrorResponse` (see below) and returns a boolean to disable any future persisted queries for that session. This defaults to disabling on `PersistedQueryNotSupported` or a 400 or 500 http error.\n\nErrorResponse\nThe argument that the optional `disable` function is given is an object with the following keys:\n\n`operation`: The Operation that encountered an error (contains `query`, `variables`, `operationName`, and `context`).\n`response`: The Execution of the response (contains `data` and `errors` as well `extensions` if sent from the server).\n`graphQLErrors`: An array of errors from the GraphQL endpoint.\n`networkError`: Any error during the link execution or server response.\n\nNote: `networkError` is the value from the downlink's `error` callback. In most cases, `graphQLErrors` is the `errors` field of the result from the last `next` call. A `networkError` can contain additional fields, such as a GraphQL object in the case of a failing HTTP status code from `@apollo/link/http`. In this situation, `graphQLErrors` is an alias for `networkError.result.errors` if the property exists.\nApollo Studio\nApollo Studio supports receiving and fulfilling Automatic Persisted Queries. Simply adding this link into your client app will improve your network response times when using Apollo Studio.\nProtocol\nAutomatic Persisted Queries are made up of three parts: the query signature, error responses, and the negotiation protocol.\nQuery Signature\nThe query signature for Automatic Persisted Queries is sent through the `extensions` field of a request from the client. This is a transport independent way to send extra information along with the operation.\n`js\n{\n  operationName: 'MyQuery',\n  variables: null,\n  extensions: {\n    persistedQuery: {\n      version: 1,\n      sha256Hash: hashOfQuery\n    }\n  }\n}`\nWhen sending an Automatic Persisted Query, the client omits the `query` field normally present, and instead sends an extension field with a `persistedQuery` object as shown above. The hash algorithm defaults to a `sha256` hash of the query string.\nIf the client needs to register the hash, the query signature will be the same but include the full query text like so:\n`js\n{\n  operationName: 'MyQuery',\n  variables: null,\n  query: `query MyQuery { id }`,\n  extensions: {\n    persistedQuery: {\n      version: 1,\n      sha256Hash: hashOfQuery\n    }\n  }\n}`\nThis should only happen once across all clients when a new query is introduced into your application.\nError Responses\nWhen the initial query signature is received by a backend, if it is unable to find the hash previously stored, it will send back the following response signature:\n`js\n{\n  errors: [\n    { message: 'PersistedQueryNotFound' }\n  ]\n}`\nIf the backend doesn't support Automatic Persisted Queries, or does not want to support it for that particular client, it can send back the following which will tell the client to stop trying to send hashes:\n`{\n  errors: [\n    { message: 'PersistedQueryNotSupported' }\n  ]\n}`\nNegotiation Protocol\nIn order to support Automatic Persisted Queries, the client and server must follow the negotiation steps as outlined here:\nHappy Path\n1. Client sends query signature with no `query` field\n2. Server looks up query based on hash, if found, it resolves the data\n3. Client receives data and completes request\nMissing hash path\n1. Client sends query signature with no `query` field\n2. Server looks up query based on hash, none is found\n3. Server responds with NotFound error response\n4. Client sends both hash and query string to Server\n5. Server fulfills response and saves query string + hash for future lookup\n6. Client receives data and completes request\nBuild time generation\nIf you want to avoid hashing in the browser, you can use a build script to include the hash as part of the request, then pass a function to retrieve that hash when the operation is run. This works well with projects like GraphQL Persisted Document Loader which uses webpack to generate hashes at build time.",
    "tag": "apollo-client"
  },
  {
    "title": "Usage",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-http.md",
    "content": "\ntitle: HTTP Link\ndescription: Get GraphQL results over a network using HTTP fetch.\n\n\nWe recommend reading Apollo Link overview before learning about individual links.\n\n`HttpLink` is a terminating link that sends a GraphQL operation to a remote endpoint over HTTP. Apollo Client uses `HttpLink` by default when you provide the `uri` option to the `ApolloClient` constructor.\n`HttpLink` supports both POST and GET requests, and you can configure HTTP options on a per-operation basis. You can use these options for authentication, persisted queries, dynamic URIs, and other granular updates.\nUsage\nImport the `HttpLink` class and initialize a link like so:\n```js\nimport { HttpLink } from '@apollo/client';\nconst link = new HttpLink({\n  uri: \"http://localhost:4000/graphql\"\n  // Additional options\n});\n```\n`HttpLink` constructor options\nThe `HttpLink` constructor takes an options object that can include the fields below. Note that you can also override some of these options on a per-operation basis using the operation context.\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `uri`\n\n`String` or `Function`\n\n\n\nThe URL of the GraphQL endpoint to send requests to. Can also be a function that accepts an `Operation` object and returns the string URL to use for that operation.\n\nThe default value is `/graphql`.\n\n\n\n\n\n###### `includeExtensions`\n\n`Boolean`\n\n\n\nIf true, includes the `extensions` field in operations sent to your GraphQL endpoint.\n\nThe default value is `false`.\n\n\n\n\n\n###### `fetch`\n\n`Function`\n\n\n\nA function to use instead of calling the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch) directly when sending HTTP requests to your GraphQL endpoint. The function must conform to the signature of `fetch`.\n\nBy default, the Fetch API is used unless it isn't available in your runtime environment.\n\nSee [Customizing `fetch`](#customizing-fetch).\n\n\n\n\n\n###### `headers`\n\n`Object`\n\n\n\nAn object representing headers to include in every HTTP request, such as `{Authorization: 'Bearer abc123'}`.\n\n\n\n\n\n###### `preserveHeaderCase`\n\n`Boolean`\n\n\n\nIf set to true, header names won't be automatically normalized to lowercase. This allows for non-http-spec-compliant servers that might expect capitalized header names.\n\nThe default value is `false`.\n\n\n\n\n\n###### `credentials`\n\n`String`\n\n\n\nThe credentials policy to use for each `fetch` call. Can be `omit`, `include`, or `same-origin`.\n\n\n\n\n\n###### `fetchOptions`\n\n`Object`\n\n\n\nAn object containing options to use for each call to `fetch`. If a particular option is not included in this object, the default value of that option is used.\n\nNote that if you set `fetchOptions.method` to `GET`, `HttpLink` follows [standard GraphQL HTTP GET encoding](http://graphql.org/learn/serving-over-http/#get-request).\n\n[See available options](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/fetch#Parameters)\n\n\n\n\n\n###### `useGETForQueries`\n\n`Boolean`\n\n\n\nIf `true`, the link uses an HTTP GET request when sending query operations to your GraphQL endpoint. Mutation operations continue to use `POST` requests. If you want _all_ operations to use `GET` requests, set [`fetchOptions.method`](#fetchoptions) instead.\n\nThe default value is `false`.\n\n\n\n\n\n###### `print`\n\n`Function`\n\n\n\nAn optional function to use when transforming a query or mutation `DocumentNode` into a string. It accepts an `ASTNode` (typically a `DocumentNode`) and the original `print` function as arguments, and is expected to return a string. This option can be used with `stripIgnoredCharacters` to remove whitespace from queries.\n\n```js\nimport { stripIgnoredCharacters } from 'graphql';\n\nconst httpLink = new HttpLink({\n  uri: '/graphql',\n  print: (ast, originalPrint) => stripIgnoredCharacters(originalPrint(ast)),\n});\n```\n\nBy default the bare [GraphQL `print` function](https://graphql.org/graphql-js/language/#print) is used.\n\n\n\n\nContext options\n`HttpLink` checks the current operation's context for certain values before sending its request to your GraphQL endpoint. Previous links in the link chain can set these values to customize the behavior of `HttpLink` for each operation.\n\nSome of these values can also be provided as options to the HttpLink constructor. If a value is provided to both, the value in the `context` takes precedence.\n\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `uri`\n\n`String` or `Function`\n\n\n\nThe URL of the GraphQL endpoint to send requests to. Can also be a function that accepts an `Operation` object and returns the string URL to use for that operation.\n\nThe default value is `/graphql`.\n\n\n\n\n\n###### `headers`\n\n`Object`\n\n\n\nAn object representing headers to include in the HTTP request, such as `{Authorization: 'Bearer abc123'}`.\n\n\n\n\n\n###### `credentials`\n\n`String`\n\n\n\nThe credentials policy to use for this `fetch` call. Can be `omit`, `include`, or `same-origin`.\n\n\n\n\n\n###### `fetchOptions`\n\n`Object`\n\n\n\nAn object containing options to use for this call to `fetch`. If a particular option is not included in this object, the default value of that option is used.\n\nNote that if you set `fetchOptions.method` to `GET`, `HttpLink` follows [standard GraphQL HTTP GET encoding](http://graphql.org/learn/serving-over-http/#get-request).\n\n[See available options](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/fetch#Parameters)\n\n\n\n\n\n###### `http`\n\n`Object`\n\n\n\nAn object that configures advanced `HttpLink` functionality, such as support for persisted queries. Options are listed in [`http` option fields](#http-option-fields).\n\n\n\n\n\n`http` option fields\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `includeExtensions`\n\n`Boolean`\n\n\n\nIf true, includes the `extensions` field in operations sent to your GraphQL endpoint.\n\nThe default value is `false`.\n\n\n\n\n\n###### `includeQuery`\n\n`Boolean`\n\n\n\nIf `false`, the GraphQL query string is _not_ included in the request. Set this option if you're sending a request that uses a [persisted query](./persisted-queries/).\n\nThe default value is `true`.\n\n\n\n\n\n###### `preserveHeaderCase`\n\n`Boolean`\n\n\n\nIf set to true, header names won't be automatically normalized to lowercase. This allows for non-http-spec-compliant servers that might expect capitalized header names.\n\nThe default value is `false`.\n\n\n\n\nOperation results\nAfter your GraphQL endpoint (successfully) responds with the result of the sent operation, `HttpLink` sets it as the `response` field of the operation `context`. This enables each previous link in your link chain to interact with the response before it's returned.\nHandling errors\n`HttpLink` distinguishes between client errors, server errors, and GraphQL errors. You can add the onError link to your link chain to handle these errors via a callback.\nThe following types of errors can occur:\n| Error          | Description | Callback | Error Type         |\n| -------------- | ------------| :------: | ------------------ |\n| Client Parse   | The request body is not serializable, for example due to a circular reference. |`error`  | `ClientParseError` |\n| Server Parse   | The server's response cannot be parsed (response.json()) | `error`  | `ServerParseError` |\n| Server Network | The server responded with a non-2xx HTTP code. | `error`  | `ServerError`      |\n| Server Data    | The server's response didn't contain `data` or `errors`. | `error`  | `ServerError`      |\n| GraphQL Error  | Resolving the GraphQL operation resulted in at least one error, which is present in the `errors` field. |  `next`  | `Object`           |\nBecause many server implementations can return a valid GraphQL result on a server network error, the thrown `Error` object contains the parsed server result. A server data error also receives the parsed result.\nAll error types inherit the `name`, `message`, and nullable `stack` properties from the generic javascript Error:\n```js\n//type ClientParseError\n{\n  parseError: Error;                // Error returned from response.json()\n};\n//type ServerParseError\n{\n  response: Response;               // Object returned from fetch()\n  statusCode: number;               // HTTP status code\n  bodyText: string                  // text that was returned from server\n};\n//type ServerError\n{\n  result: Record;      // Parsed object from server response\n  response: Response;               // Object returned from fetch()\n  statusCode: number;               // HTTP status code\n};\n```\nCustomizing `fetch`\nYou can provide the fetch option to the `HttpLink` constructor to enable many custom networking needs. For example, you can modify the request based on calculated headers or calculate the endpoint URI based on the operation's details.\nIf you're targeting an environment that doesn't provide the Fetch API (such as older browsers or the server) you can provide a different implementation of `fetch`. We recommend unfetch for older browsers and node-fetch for running in Node.\nCustom auth\nThis example adds a custom `Authorization` header to every request before calling `fetch`:\n```js\nconst customFetch = (uri, options) => {\n  const { header } = Hawk.client.header(\n    \"http://example.com:8000/resource/1?b=1&a=2\",\n    \"POST\",\n    { credentials: credentials, ext: \"some-app-data\" }\n  );\n  options.headers.Authorization = header;\n  return fetch(uri, options);\n};\nconst link = new HttpLink({ fetch: customFetch });\n```\nDynamic URI\nThis example customizes the endpoint URL's query parameters before calling `fetch`:\n```js\nconst customFetch = (uri, options) => {\n  const { operationName } = JSON.parse(options.body);\n  return fetch(`${uri}/graph/graphql?opname=${operationName}`, options);\n};\nconst link = new HttpLink({ fetch: customFetch });",
    "tag": "apollo-client"
  },
  {
    "title": "Constructor",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-subscriptions.md",
    "content": "\ntitle: Subscriptions Link\ndescription: Execute subscriptions (or other operations) over WebSocket with the graphql-ws library\napi_reference: true\n\n\nWe recommend reading Apollo Link overview before learning about individual links.\n\nThe `GraphQLWsLink` is a terminating link that's used most commonly with GraphQL subscriptions (which usually communicate over WebSocket), although you can send queries and mutations over WebSocket as well.\n`GraphQLWsLink` requires the graphql-ws library. Install it in your project like so:\n`shell\nnpm install graphql-ws`\n\nNote: This link works with the newer `graphql-ws` library. If your server uses the older `subscriptions-transport-ws`, you should use the WebSocketLink link from @apollo/client/link/ws instead.\n\nConstructor\n```js\nimport { GraphQLWsLink } from \"@apollo/client/link/subscriptions\";\nimport { createClient } from \"graphql-ws\";\nconst link = new GraphQLWsLink(\n  createClient({\n    url: \"ws://localhost:3000/subscriptions\",\n  }),\n);\n```\nOptions\nThe `GraphQLWsLink` constructor takes a single argument, which is a `Client` returned from the `graphql-ws` `createClient` function.\nThe `createClient` function can take many options, described in the graphql-ws docs for ClientOptions. The one required option is `url`, which is the URL (typically starting with `ws://` or `wss://`, which are the equivalents of `http://` and `https://` respectively) to your WebSocket server. (Note that this differs from the older link's URL option, which is named `uri` instead of `url`.)\nUsage",
    "tag": "apollo-client"
  },
  {
    "title": "Overview",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-retry.md",
    "content": "\ntitle: Retry Link\ndescription: Attempt an operation multiple times if it fails due to network or server errors.\n\nOverview\n`@apollo/client/link/retry` can be used to retry an operation a certain amount of times. This comes in handy when dealing with unreliable communication situations, where you would rather wait longer than explicitly fail an operation. `@apollo/client/link/retry` provides exponential backoff, and jitters delays between attempts by default. It does not (currently) handle retries for GraphQL errors in the response, only for network errors.\nAn example use case is to hold on to a request while a network connection is offline, and retry until it comes back online.\n```js\nimport { RetryLink } from \"@apollo/client/link/retry\";\nconst link = new RetryLink();\n```\nOptions\nThe standard retry strategy provides exponential backoff with jittering, and takes the following options, grouped into `delay` and `attempt` strategies:\noptions.delay\n| Option | Description |\n| - | - |\n| `delay.initial` | The number of milliseconds to wait before attempting the first retry. |\n| `delay.max` | The maximum number of milliseconds that the link should wait for any retry. |\n| `delay.jitter` | Whether delays between attempts should be randomized. |\noptions.attempts\n| Option | Description |\n| - | - |\n| `attempts.max` | The max number of times to try a single operation before giving up. |\n| `attempts.retryIf` | A predicate function that can determine whether a particular response should be retried. |\nDefault configuration\nThe default configuration is equivalent to:\n`ts\nnew RetryLink({\n  delay: {\n    initial: 300,\n    max: Infinity,\n    jitter: true\n  },\n  attempts: {\n    max: 5,\n    retryIf: (error, _operation) => !!error\n  }\n});`\nAvoiding thundering herd\nStarting with `initialDelay`, the delay of each subsequent retry is increased exponentially, meaning it's multiplied by 2 each time. For example, if `initialDelay` is 100, additional retries will occur after delays of 200, 400, 800, etc.\nWith the `jitter` option enabled, delays are randomized anywhere between 0ms (instant), and 2x the configured delay. This way you get the same result on average, but with random delays.\nThese two features are combined to help alleviate the thundering herd problem, by distributing load during major outages. Without these strategies, when your server comes back up it will be hit by all of your clients at once, possibly causing it to go down again.\nCustom strategies\nInstead of the options object, you may pass a function for `delay` and/or `attempts`, which implement custom strategies for each. In both cases the function is given the same arguments (`count`, `operation`, `error`).\nThe `attempts` function should return a `boolean` (or a `Promise` which resolves to a `boolean`) indicating whether the response should be retried. If yes, the `delay` function is then called, and should return the number of milliseconds to delay by.\n```js\nimport { RetryLink } from \"@apollo/client/link/retry\";\nconst link = new RetryLink({\n  attempts: (count, operation, error) => {\n    return !!error && operation.operationName != 'specialCase';\n  },\n  delay: (count, operation, error) => {\n    return count * 1000 * Math.random();\n  },\n});",
    "tag": "apollo-client"
  },
  {
    "title": "Overview",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/link/apollo-link-schema.md",
    "content": "\ntitle: Schema Link\ndescription: Assists with mocking and server-side rendering\n\nOverview\nThe schema link provides a graphql execution environment, which allows you to perform GraphQL operations on a provided schema. This type of behavior is commonly used for server-side rendering (SSR) to avoid network calls and mocking data. While the schema link could provide graphql results on the client, currently the graphql execution layer is too heavy weight for practical application.\n\nTo unify your state management with client-side GraphQL operations, refer to Apollo Client's local state management functionality. It integrates with the Apollo Client cache and is much more lightweight.\n\nInstallation\n`npm install @apollo/client --save`\nUsage\nServer Side Rendering\nWhen performing SSR on the same server, you can use this library to avoid making network calls.\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nimport { SchemaLink } from '@apollo/client/link/schema';\nimport schema from './path/to/your/schema';\nconst graphqlClient = new ApolloClient({\n  cache: new InMemoryCache(),\n  ssrMode: true,\n  link: new SchemaLink({ schema })\n});\n```\nMocking\nFor more detailed information about mocking, refer to the graphql-tools documentation.\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nimport { SchemaLink } from '@apollo/client/link/schema';\nimport { makeExecutableSchema, addMockFunctionsToSchema } from 'graphql-tools';\nconst typeDefs = `Query {\n  ...\n  }`;\nconst mocks = {\n  Query: () => ...,\n  Mutation: () => ...\n};\nconst schema = makeExecutableSchema({ typeDefs });\nconst schemaWithMocks = addMockFunctionsToSchema({\n  schema,\n  mocks\n});\nconst apolloCache = new InMemoryCache(window.APOLLO_STATE);\nconst graphqlClient = new ApolloClient({\n  cache: apolloCache,\n  link: new SchemaLink({ schema: schemaWithMocks })\n});\n```\nOptions\nThe `SchemaLink` constructor can be called with an object with the following properties:\n| Option | Description |\n| - | - |\n| `schema` | An executable graphql schema |\n| `rootValue` | The root value that is passed to the resolvers (i.e. the first parameter for the rootQuery) |\n| `context` | An object passed to the resolvers, following the graphql specification or a function that accepts the operation and returns the resolver context. The resolver context may contain all the data-fetching connectors for an operation. |",
    "tag": "apollo-client"
  },
  {
    "title": "Installation",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/react/hooks.mdx",
    "content": "\ntitle: Hooks\ndescription: Apollo Client react hooks API reference\n\nimport QueryOptions3 from '../../../shared/query-options.mdx';\nimport QueryResult3 from '../../../shared/query-result.mdx';\nimport MutationOptions3 from '../../../shared/mutation-options.mdx';\nimport MutationResult3 from '../../../shared/mutation-result.mdx';\nimport SubscriptionOptions3 from '../../../shared/subscription-options.mdx';\nimport SubscriptionResult3 from '../../../shared/subscription-result.mdx';\nInstallation\nApollo Client >= 3 includes React hooks functionality out of the box. You don't need to install any additional packages.\nThe `ApolloProvider` component\nThe `ApolloProvider` component leverages React's Context API to make a configured Apollo Client instance available throughout a React component tree. This component can be imported directly from the `@apollo/client` package.\n`js\nimport { ApolloProvider } from '@apollo/client';`\nProps\n| Option   | Type                       | Description                 |\n| -------- | -------------------------- | --------------------------- |\n| `client` | ApolloClient<TCache> | An `ApolloClient` instance. |\nExample\n```jsx {7-9}\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  uri: \"http://localhost:4000/graphql\"\n});\nReactDOM.render(\n  \n\n,\n  document.getElementById('root'),\n);\n```\nThe `ApolloConsumer` component\nOne way to access the configured Apollo Client instance directly is to create an `ApolloConsumer` component and provide a render prop function as its child. The render prop function will be called with your `ApolloClient` instance as its only argument. You can think of the `ApolloConsumer` component as similar to the `Consumer` component from the React Context API.\nExample\n```jsx\nimport { ApolloConsumer } from '@apollo/client';\nfunction WithApolloClient() {\n  return (\n    \n      {client => 'We have access to the client!' / do stuff here /}\n    \n  );\n}\n```\n`useQuery`\nExample\n```jsx\nimport { gql, useQuery } from '@apollo/client';\nconst GET_GREETING = gql`query GetGreeting($language: String!) {\n    greeting(language: $language) {\n      message\n    }\n  }`;\nfunction Hello() {\n  const { loading, error, data } = useQuery(GET_GREETING, {\n    variables: { language: 'english' },\n  });\n  if (loading) return Loading ...;\n  return Hello {data.greeting.message}!;\n}\n```\n\nRefer to the Queries section for a more in-depth overview of `useQuery`.\n\nFunction Signature\n`ts\nfunction useQuery<TData = any, TVariables = OperationVariables>(\n  query: DocumentNode,\n  options?: QueryHookOptions<TData, TVariables>,\n): QueryResult<TData, TVariables> {}`\nParams\n`query`\n| Param   | Type         | Description                                                   |\n| ------- | ------------ | ------------------------------------------------------------- |\n| `query` | DocumentNode | A GraphQL query document parsed into an AST by `gql`. |\n`options`\n\nResult\n\n`useLazyQuery`\nExample\n```jsx\nimport { gql, useLazyQuery } from \"@apollo/client\";\nconst GET_GREETING = gql`query GetGreeting($language: String!) {\n    greeting(language: $language) {\n      message\n    }\n  }`;\nfunction Hello() {\n  const [loadGreeting, { called, loading, data }] = useLazyQuery(\n    GET_GREETING,\n    { variables: { language: \"english\" } }\n  );\n  if (called && loading) return Loading ...\n  if (!called) {\n    return  loadGreeting()}>Load greeting\n  }\n  return Hello {data.greeting.message}!;\n}\n```\n\nRefer to the Queries section for a more in-depth overview of `useLazyQuery`.\n\nFunction Signature\n`ts\nfunction useLazyQuery<TData = any, TVariables = OperationVariables>(\n  query: DocumentNode,\n  options?: LazyQueryHookOptions<TData, TVariables>,\n): [\n  (options?: LazyQueryHookOptions<TData, TVariables>) => Promise<LazyQueryResult<TData, TVariables>>,\n  LazyQueryResult<TData, TVariables>\n] {}`\nParams\n`query`\n| Param   | Type         | Description                                                   |\n| ------- | ------------ | ------------------------------------------------------------- |\n| `query` | DocumentNode | A GraphQL query document parsed into an AST by `gql`. |\n`options`\n\nResult tuple\nExecute function (first tuple item)\n| Param            | Type                                                  | Description                                                                                                                     |\n| ---------------- | ----------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |\n| Execute function | `(options?: LazyQueryHookOptions<TVariables>) => Promise<LazyQueryResult<TData, TVariables>>` | Function that can be triggered to execute the suspended query. After being called, `useLazyQuery` behaves just like `useQuery`. The `useLazyQuery` function returns a promise that fulfills with a query result when the query succeeds or fails. |\n`LazyQueryResult<TData, TVariables>` object (second tuple item)\n\n`useMutation`\nExample\n```jsx\nimport { gql, useMutation } from '@apollo/client';\nconst ADD_TODO = gql`mutation AddTodo($type: String!) {\n    addTodo(type: $type) {\n      id\n      type\n    }\n  }`;\nfunction AddTodo() {\n  let input;\n  const [addTodo, { data }] = useMutation(ADD_TODO);\nreturn (\n    \n {\n          e.preventDefault();\n          addTodo({ variables: { type: input.value } });\n          input.value = '';\n        }}\n      >\n         {\n            input = node;\n          }}\n        />\n        Add Todo\n\n\n  );\n}\n```\n\nRefer to the Mutations section for a more in-depth overview of `useMutation`.\n\nFunction Signature\n`ts\nfunction useMutation<TData = any, TVariables = OperationVariables>(\n  mutation: DocumentNode,\n  options?: MutationHookOptions<TData, TVariables>,\n): MutationTuple<TData, TVariables> {}`\nParams\n`mutation`\n| Param      | Type         | Description                                                      |\n| ---------- | ------------ | ---------------------------------------------------------------- |\n| `mutation` | DocumentNode | A GraphQL mutation document parsed into an AST by `gql`. |\n`options`\n\n`MutationTuple<TData, TVariables>` result tuple\n\n`useSubscription`\nExample\n```jsx\nconst COMMENTS_SUBSCRIPTION = gql`\n  subscription OnCommentAdded($repoFullName: String!) {\n    commentAdded(repoFullName: $repoFullName) {\n      id\n      content\n    }\n  }\n`;\nfunction DontReadTheComments({ repoFullName }) {\n  const {\n    data: { commentAdded },\n    loading,\n  } = useSubscription(COMMENTS_SUBSCRIPTION, { variables: { repoFullName } });\n  return New comment: {!loading && commentAdded.content};\n}\n```\n\nRefer to the Subscriptions section for a more in-depth overview of `useSubscription`.\n\nFunction Signature\n`ts\nfunction useSubscription<TData = any, TVariables = OperationVariables>(\n  subscription: DocumentNode,\n  options?: SubscriptionHookOptions<TData, TVariables>,\n): {\n  variables: TVariables;\n  loading: boolean;\n  data?: TData;\n  error?: ApolloError;\n} {}`\nParams\n`subscription`\n| Param          | Type         | Description                                                          |\n| -------------- | ------------ | -------------------------------------------------------------------- |\n| `subscription` | DocumentNode | A GraphQL subscription document parsed into an AST by `gql`. |\n`options`\n\nResult\n\n`useApolloClient`\nExample\n```jsx\nimport { useApolloClient } from '@apollo/client';\nfunction SomeComponent() {\n  const client = useApolloClient();\n  // `client` is now set to the `ApolloClient` instance being used by the\n  // application (that was configured using something like `ApolloProvider`)\n}\n```\nFunction Signature\n`ts\nfunction useApolloClient(): ApolloClient<object> {}`\nResult\n| Param                  | Type                       | Description                                                |\n| ---------------------- | -------------------------- | ---------------------------------------------------------- |\n| Apollo Client instance | ApolloClient<object> | The `ApolloClient` instance being used by the application. |\n`useReactiveVar`\nReads the value of a reactive variable and re-renders the containing component whenever that variable's value changes. This enables a reactive variable to trigger changes without relying on the `useQuery` hook.\nExample\n```tsx\nimport { makeVar, useReactiveVar } from \"@apollo/client\";\nexport const cartItemsVar = makeVar([]);\nexport function Cart() {\n  const cartItems = useReactiveVar(cartItemsVar);\n  // ...\n```\nFunction Signature\n```tsx\nfunction useReactiveVar(rv: ReactiveVar): T {}",
    "tag": "apollo-client"
  },
  {
    "title": "`MockedProvider`",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/react/testing.md",
    "content": "\ntitle: Testing\ndescription: Apollo Client React testing API\napi_reference: true\n\n\nFor more guidance on running tests with `MockedProvider`, see Testing React components.\n\n`MockedProvider`\n`js\nimport { MockedProvider } from \"@apollo/client/testing\";`\nThe `MockedProvider` component is a mocked version of ApolloProvider that doesn't send network requests to your API. Instead, you to specify the exact response payload for a given GraphQL operation. This enables you to test your application's operations without communicating with a server.\nProps\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `mocks`\n\n`ReadonlyArray`\n\n\n\nAn array containing GraphQL operation definitions and their corresponding mocked responses. See [Defining mocked responses](../../development-testing/testing/#defining-mocked-responses).\n\n\n\n\n\n###### `addTypename`\n\n`Boolean`\n\n\n\nIf `true`, the `MockedProvider` automatically adds the `__typename` field to every object type included in every executed query. Set this to `false` if the responses in your `mocks` array do _not_ include `__typename` fields. See [Setting `addTypename`](../../development-testing/testing/#setting-addtypename).\n\nThe default value is `true`.\n\n\n\n\n\n\n###### `defaultOptions`\n\n`DefaultOptions`\n\n\n\nAn object containing options to pass directly to the `MockedProvider`'s `ApolloClient` instance. See [Example `defaultOptions` object](../core/ApolloClient/#example-defaultoptions-object).\n\n\n\n\n\n\n###### `cache`\n\n`ApolloCache`\n\n\n\nA custom cache for the `MockedProvider`'s `ApolloClient` instance to use. Useful when you need to define a custom `dataIdFromObject` function for automatic cache updates.\n\nBy default, `MockedProvider` creates an `InMemoryCache` with default configuration.\n\n\n\n\n\n\n###### `resolvers`\n\n`Resolvers`\n\n\n\n**Deprecated.** A collection of [local resolvers](../../local-state/local-resolvers/) for the `MockedProvider`'s `ApolloClient` instance to use.\n\n\n\n\n\n\n###### `childProps`\n\n`object`\n\n\n\nProps to pass down to the `MockedProvider`'s child.\n\n\n\n\n\n\n###### `showWarnings`\n\n`boolean`\n\n\n\nWhen a request fails to match a mock, a warning is logged to the console to indicate the mismatch. Set this to `false` to silence these warnings.\n\nThe default value is `true`.\n\n\n\n\n\nExample `mocks` array\n`js\nconst mocks = [\n  {\n    request: {\n      query: GET_DOG,\n      variables: { index: 4 }\n    },\n    result: {\n      data: {\n        dog: {\n          name: \"Douglas\"\n        }\n      }\n    }\n  },\n  {\n    request: {\n      query: GET_DOG,\n      variables: { index: 8 }\n    },\n    error: new Error(\"Something went wrong\")\n  }\n]`\nWith the `mocks` array above:\n\nIf the `GET_DOG` operation is executed with variables `{ index: 4 }`, it returns a dog named `Douglas`.\nIf `GET_DOG` is executed with variables `{ index: 8 }`, it returns an `error`.\n\nUsage",
    "tag": "apollo-client"
  },
  {
    "title": "`useFragment_experimental`",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/react/hooks-experimental.mdx",
    "content": "\ntitle: Hooks (experimental)\ndescription: Apollo Client experimental react hooks API reference\n\nimport UseFragmentOptions from '../../../shared/useFragment-options.mdx';\nimport UseFragmentResult from '../../../shared/useFragment-result.mdx';\nimport UseSuspenseQueryOptions from '../../../shared/useSuspenseQuery-options.mdx';\nimport UseSuspenseQueryResult from '../../../shared/useSuspenseQuery-result.mdx';\n`useFragment_experimental`\nInstallation\n\n\u26a0\ufe0f The `useFragment_experimental` hook is currently at the preview stage in Apollo Client. If you have feedback on it, please let us know via GitHub issues.\n\nBeginning with version `3.7.0`, Apollo Client Web has preview support for the `useFragment_experimental` hook, which represents a lightweight live binding into the Apollo Client Cache. This hook returns an always-up-to-date view of whatever data the cache currently contains for a given fragment. `useFragment_experimental` never triggers network requests of its own.\n`useFragment_experimental` enables Apollo Client to broadcast very specific fragment results to individual components. Note that the `useQuery` hook remains the primary hook responsible for querying and populating data in the cache (see the API reference). As a result, the component reading the fragment data via `useFragment_experimental` is still subscribed to all changes in the query data, but receives updates only when that fragment's specific data change.\nUsing `useFragment_experimental`\n\nA GraphQL fragment is a piece of logic that can be shared between multiple queries and mutations. See the API reference.\n\nGiven the following fragment definition:\n`js\nconst ItemFragment = gql`\n  fragment ItemFragment on Item {\n    text\n  }\n`;`\nWe can first use the `useQuery` hook to retrieve a list of items with `id`s.\n`jsx\nconst listQuery = gql`\n  query {\n    list {\n      id\n    }\n  }\n`;\nfunction List() {\n  const { loading, data } = useQuery(listQuery);\n  return (\n    <ol>\n      {data?.list.map(item => <Item key={item.id} id={item.id}/>)}\n    </ol>\n  );\n}`\nWe can then use `useFragment_experimental` from within the `<Item>` component to create a live binding for each item by providing the `fragment` document, `fragmentName` and object reference via `from`.\n`jsx\nfunction Item(props: { id: number }) {\n  const { complete, data } = useFragment_experimental({\n    fragment: ItemFragment,\n    fragmentName: \"ItemFragment\",\n    from: {\n      __typename: \"Item\",\n      id: props.id,\n    },\n  });\n  return <li>{complete ? data!.text : \"incomplete\"}</li>;\n}`\n`useFragment_experimental` API\nSupported options and result fields for the `useFragment_experimental` hook are listed below.\nMost calls to `useFragment_experimental` can omit the majority of these options, but it's useful to know they exist.\nOptions\nThe `useFragment_experimental` hook accepts the following options:\n\nResult\n\n`useSuspenseQuery_experimental`\nInstallation\n\n\u26a0\ufe0f The `useSuspenseQuery_experimental` hook is currently at the alpha stage in Apollo Client. If you have feedback on it, please let us know via GitHub issues.\n\nBeginning with version `3.8.0-alpha.0`, Apollo Client Web has alpha support for the `useSuspenseQuery_experimental` hook, which works with React's Suspense feature. You can install it via `npm install @apollo/client@alpha`.\nUsing `useSuspenseQuery_experimental`\nCreate and provide a `SuspenseCache` instance to your `ApolloProvider`.\n```js\nimport { SuspenseCache } from '@apollo/client';\nconst suspenseCache = new SuspenseCache();\n\n```\nWrite queries using `useSuspenseQuery_experimental`. Ensure the component is wrapped with React's Suspense component. Note that the hook returns only `data` and `error`: since Suspense provides the tools to manage our application's loading states, `useSuspenseQuery_experimental` does not return a `loading` boolean.\nSee the API reference for supported options.\n```jsx\nimport { Suspense } from 'react';\nimport { useSuspenseQuery_experimental } from '@apollo/client';\nconst listQuery = gql`query {\n    list {\n      id\n    }\n  }`;\nfunction App() {\n  return (\n    }>\n      \n\n  );\n}\nfunction List() {\n  const { data } = useSuspenseQuery_experimental(listQuery);\nreturn (\n    \n      {data.list.map(item => )}\n    \n  );\n}\n```\n`useSuspenseQuery_experimental` API\nFunction Signature\n```ts\nfunction useSuspenseQuery_experimental<\n  TData = any,\n  TVariables extends OperationVariables = OperationVariables\n\n(\n  query: DocumentNode,\n  options?: SuspenseQueryHookOptions,\n): UseSuspenseQueryResult {}\n```\n\nParams\n`query`\n| Param   | Type         | Description                                                   |\n| ------- | ------------ | ------------------------------------------------------------- |\n| `query` | DocumentNode | A GraphQL query document parsed into an AST by `gql`. |\n`options`\n\nResult",
    "tag": "apollo-client"
  },
  {
    "title": "Installation",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/react/ssr.md",
    "content": "\ntitle: SSR\ndescription: Apollo Client React server side rendering API\n\nInstallation\nApollo Client >= 3 includes React hooks functionality out of the box. You don't need to install any additional packages.\n`getDataFromTree`\nThe `getDataFromTree` function takes your React tree, determines which queries are needed to render them, and then fetches them all.\n`js\nimport { getDataFromTree } from \"@apollo/client/react/ssr\";`\nParams\n| Param | Type | description |\n| - | - | - |\n| `tree` | React.ReactNode | The React tree you would like to render and fetch data for. |\n| `context` | { [key: string]: any } | Optional values you would like to make available in the React Context during rendering / data retrieval. |\nResult\n`getDataFromTree` returns a promise (`Promise<string>`) which resolves when the data is ready in your Apollo Client store. The result is generated using ReactDOMServer.renderToStaticMarkup under the hood.\nExample\nSee Executing queries with getDataFromTree.\n`renderToStringWithData`\nThe `renderToStringWithData` function is similar to `getDataFromTree`, but uses ReactDOMServer.renderToString to render its result instead of ReactDOMServer.renderToStaticMarkup (the React docs help explain the difference).\n`js\nimport { renderToStringWithData } from \"@apollo/client/react/ssr\";`\nParams\n| Param | Type | description |\n| - | - | - |\n| `component` | ReactElement | The React component tree you would like to render and fetch data for. |\nResult",
    "tag": "apollo-client"
  },
  {
    "title": "Installation",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/react/hoc.mdx",
    "content": "\ntitle: HOC\ndescription: Deprecated React Apollo HOC API\n\n\nNote: Official support for React Apollo higher order components ended in March 2020. This library is still included in the `@apollo/client` package, but it no longer receives feature updates or bug fixes.\n\nInstallation\nThe HOC library is included in the core `@apollo/client` package:\n`npm install @apollo/client`\nYou then import the library's symbols from `@apollo/client/react/hoc`.\n`graphql(query, [config])(component)`\n`js\nimport { graphql } from '@apollo/client/react/hoc';`\nThe `graphql()` function is the core of Apollo's HOC API. Use this function to  create higher-order components that can execute queries and update reactively based on the data in your Apollo store.\nThe `graphql()` function returns a function that \"enhances\" any component with reactive GraphQL capabilities. This follows the React higher-order component pattern that's also used by react-redux\u2019s connect function.\nThe `graphql()` function can only provide access to your GraphQL data if there is an <ApolloProvider/> component higher up in your tree to provide an ApolloClient instance that's used to fetch your data.\nThe behavior of your component enhanced with the `graphql()` function will be different depending on if your GraphQL operation is a query, a mutation, or a subscription. See the appropriate API documentation for more information about the functionality and available options for each type.\nExamples\nYou can use the `graphql()` function like this:\n```js\nfunction TodoApp({ data: { todos } }) {\n  return (\n    \n      {todos.map(({ id, text }) => (\n        {text}\n      ))}\n    \n  );\n}\nexport default graphql(gql`query TodoAppQuery {\n    todos {\n      id\n      text\n    }\n  }`)(TodoApp);\n```\nYou can also define an intermediate function and hook up your component with the `graphql()` function like this:\n```js\n// Create our enhancer function.\nconst withTodoAppQuery = graphql(gql`query TodoAppQuery { ... }`);\n// Enhance our component.\nconst TodoAppWithData = withTodoAppQuery(TodoApp);\n// Export the enhanced component.\nexport default TodoAppWithData;\n```\nThe `config` object\nBefore we look into the specific behaviors of each operation, let's look at the `config` object. The `config` object is the second argument you pass into the `graphql()` function, after your GraphQL document. The config is optional and allows you to add some custom behavior to your higher order component.\n`js\nexport default graphql(\n  gql`query MyQuery { ... }`,\n  config, // <- The `config` object.\n)(MyComponent);`\nLets go through all of the properties that may live on your `config` object.\n`config.options`\n`config.options` is an object or a function that allows you to define the specific behavior your component should use in handling your GraphQL data.\nThe specific options available for configuration depend on the operation you pass as the first argument to `graphql()`. There are options specific to queries and mutations.\nYou can define `config.options` as a plain object, or you can compute your options from a function that takes the component\u2019s props as an argument.\nExample\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: {\n    // Options go here.\n  },\n})(MyComponent);`\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: props => ({\n    // Options are computed from `props` here.\n  }),\n})(MyComponent);`\n`config.props`\nThe `config.props` property allows you to define a map function that takes the `props` (and optionally `lastProps`) added by the `graphql()` function (props.data for queries and props.mutate for mutations) and allows you to compute a new `props` (and optionally `lastProps`) object that will be provided to the component that `graphql()` is wrapping.\nThe function you define behaves almost exactly like mapProps from Recompose providing the same benefits without the need for another library.\n`config.props` is most useful when you want to abstract away complex function calls into a simple prop that you can pass down to your component.\nAnother benefit of `config.props` is that it also allows you to decouple your pure UI components from your GraphQL and Apollo concerns. You can write your pure UI components in one file and then keep the logic required for them to interact with the store in a completely different place in your project. You can accomplish this by your pure UI components only asking for the props needed to render and `config.props` can contain the logic to provide exactly the props your pure component needs from the data provided by your GraphQL API.\nExample\nThis example uses props.data.fetchMore.\n```js\nexport default graphql(gql`query MyQuery { ... }`, {\n  props: ({ data: { fetchMore } }) => ({\n    onLoadMore: () => {\n      fetchMore({ ... });\n    },\n  }),\n})(MyComponent);\nfunction MyComponent({ onLoadMore }) {\n  return (\n    \n      Load More!\n    \n  );\n}\n```\nTo access props that are not added by the `graphql()` function, use the `ownProps` keyword. For example:\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  props: ({ data: { liveImage }, ownProps: { loadingImage } }) => ({\n    image: liveImage || loadingImage,\n  }),\n})(MyComponent);`\nTo access `lastProps`, use the second argument of `config.props`. For example:\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  props: ({ data: { liveImage } }, lastProps) => ({\n    image: liveImage,\n    lastImage: lastProps.data.liveImage,\n  }),\n})(MyComponent);`\n`config.skip`\nIf `config.skip` is `true`, then all of the React Apollo code is skipped entirely. Your component behaves as if the `graphql()` function isn't there at all.\nYou can also pass a function to `config.skip`. If you do, the function takes your component's props and should return a boolean. If the function returns `true`, then the skip behavior goes into effect.\n`config.skip` is especially useful if you want to use a different query based on some prop. You can see this in an example below.\nExample\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  skip: props => !!props.skip,\n})(MyComponent);`\nThe following example uses the compose function to use multiple `graphql()` enhancers at once.\n```js\nexport default compose(\n  graphql(gql`query MyQuery1 { ... }`, { skip: props => !props.useQuery1 }),\n  graphql(gql`query MyQuery2 { ... }`, { skip: props => props.useQuery1 }),\n)(MyComponent);\nfunction MyComponent({ data }) {\n  // The data may be from `MyQuery1` or `MyQuery2` depending on the value\n  // of the prop `useQuery1`.\n  console.log(data);\n}\n```\n`config.name`\nThis property allows you to configure the name of the prop that gets passed down to your component. By default, if the GraphQL document you pass into `graphql()` is a query, then your prop is named data. If you pass a mutation, then your prop will be named mutate. These default names collide when you use multiple queries or mutations with the same component. To avoid collisions, use `config.name` to specify a different name.\nExample\nThis example uses the compose function to use multiple `graphql()` HOCs together.\n```js\nexport default compose(\n  graphql(gql`mutation CreateTodoMutation (...) { ... }`, { name: 'createTodo' }),\n  graphql(gql`mutation UpdateTodoMutation (...) { ... }`, { name: 'updateTodo' }),\n  graphql(gql`mutation DeleteTodoMutation (...) { ... }`, { name: 'deleteTodo' }),\n)(MyComponent);\nfunction MyComponent(props) {\n  // Instead of the default prop name, `mutate`,\n  // we have three different prop names.\n  console.log(props.createTodo);\n  console.log(props.updateTodo);\n  console.log(props.deleteTodo);\nreturn null;\n}\n```\n`config.withRef`\nBy setting `config.withRef` to `true`, you can get the instance of your wrapped component from your higher-order GraphQL component using a `getWrappedInstance` method available on the instance of your higher-order GraphQL component.\nYou might want to set this to `true` when you want to call functions or access properties that are defined on your wrapped component\u2019s class instance.\nExample\nThis example uses the React ref feature.\n```js\nclass MyComponent extends Component {\n  saySomething() {\n    console.log('Hello, world!');\n  }\nrender() {\n    // ...\n  }\n}\nconst MyGraphQLComponent = graphql(gql`query MyQuery { ... }`, { withRef: true })(\n  MyComponent,\n);\nclass MyContainerComponent extends Component {\n  render() {\n    return (\n       {\n          const wrappedInstance = component.getWrappedInstance();\n          assert(wrappedInstance instanceof MyComponent);\n          // We can call methods on the component class instance.\n          wrappedInstance.saySomething();\n        }}\n      />\n    );\n  }\n}\n```\n`config.alias`\nUse this property to configure the name of your higher order component wrapper. For example, if you set `config.alias` to `'withCurrentUser'`, your wrapper component display name becomes `withCurrentUser(${WrappedComponent.displayName})` instead of `Apollo(${WrappedComponent.displayName})`.\nThe default display name for React Apollo components is `Apollo(${WrappedComponent.displayName})`. This pattern is used by most React libraries that make use of higher order components. However, this might get confusing when you are using more than one higher order component and you look at the React Devtools.\nExample\nThis example uses the compose function to use multiple `graphql()` HOCs together.\n`js\nexport default compose(\n  graphql(gql`query MyQuery { ... }`, { alias: 'withCurrentUser' }),\n  graphql(gql`query MyQuery { ... }`, { alias: 'withList' }),\n)(MyComponent);`\n`graphql() options for queries`\n`props.data`\nThe higher-order component created with `graphql()` feeds a `data` prop into your component. Like so:\n`js\nrender() {\n  const { data } = this.props; // <- The `data` prop.\n}`\nThe `data` prop contains the data fetched from your query in addition to some other useful information and functions to control the lifecycle of your GraphQL-connected component. So for example, if we had a query that looked like:\n`graphql\nquery ViewerAndTodos {\n  viewer {\n    name\n  }\n  todos {\n    text\n  }\n}`\nYour `data` prop would contain that data:\n```js\nrender() {\n  const { data } = this.props;\nconsole.log(data.viewer); // <- The data returned by your query for `viewer`.\n  console.log(data.todos); // <- The data returned by your query for `todos`.\n}\n```\nThe `data` prop has some other useful properties which can be accessed directly from `data`. For example, `data.loading` or `data.error`. These properties are documented below.\nMake sure to always check `data.loading` and `data.error` in your components before rendering. Properties like `data.todos` which contain your app\u2019s data may be undefined while your component is performing its initial fetch. Checking `data.loading` and `data.error` helps you avoid any issues with undefined data. Such checks may look like:\n`js\nrender() {\n  const { data: { loading, error, todos } } = this.props;\n  if (loading) {\n    return <p>Loading...</p>;\n  }\n  if (error) {\n    return <p>Error!</p>;\n  }\n  return (\n    <ul>\n      {todos.map(({ id, text }) => (\n        <li key={id}>{text}</li>\n      ))}\n    </ul>\n  );\n}`\n`data.loading`\nA boolean representing whether or not a query request is currently in flight for this component. This means that a query request has been sent using your network interface, and we have not yet gotten a response back. Use this property to render a loading component.\nHowever, just because `data.loading` is true it does not mean that you won\u2019t have data. For instance, if you already have `data.todos`, but you want to get the latest todos from your API `data.loading` might be true, but you will still have the todos from your previous request.\nThere are multiple different network states that your query may be in. If you want to see what the network state of your component is in more detail then refer to data.networkStatus.\nExample:\n```js\nfunction MyComponent({ data: { loading } }) {\n  if (loading) {\n    return Loading...;\n  } else {\n    // ...\n  }\n}\nexport default graphql(gql`query MyQuery { ... }`)(MyComponent);\n```\n`data.error`\nIf an error occurred then this property will be an instance of `ApolloError`. If you do not handle this error you will get a warning in your console that says something like: `\"Unhandled (in react-apollo) Error: ...\"`.\nExample:\n```js\nfunction MyComponent({ data: { error } }) {\n  if (error) {\n    return Error!;\n  } else {\n    // ...\n  }\n}\nexport default graphql(gql`query MyComponentQuery  { ... }`)(MyComponent);\n```\n`data.networkStatus`\n`data.networkStatus` is useful if you want to display a different loading indicator (or no indicator at all) depending on your network status as it provides a more detailed view into the state of a network request on your component than data.loading does. `data.networkStatus` is an enum with different number values between 1 and 8. These number values each represent a different network state.\n\n`loading`: The query has never been run before and the request is now pending. A query will still have this network status even if a result was returned from the cache, but a query was dispatched anyway.\n`setVariables`: If a query\u2019s variables change and a network request was fired then the network status will be `setVariables` until the result of that query comes back. React users will see this when options.variables changes on their queries.\n`fetchMore`: Indicates that `fetchMore` was called on this query and that the network request created is currently in flight.\n`refetch`: It means that `refetch` was called on a query and the refetch request is currently in flight.\nUnused.\n`poll`: Indicates that a polling query is currently in flight. So for example if you are polling a query every 10 seconds then the network status will switch to `poll` every 10 seconds whenever a poll request has been sent but not resolved.\n`ready`: No request is in flight for this query, and no errors happened. Everything is OK.\n`error`: No request is in flight for this query, but one or more errors were detected.\n\nIf the network status is less then 7 then it is equivalent to data.loading being true. In fact you could replace all of your `data.loading` checks with `data.networkStatus < 7` and you would not see a difference. It is recommended that you use `data.loading`, however.\nExample:\n```js\nfunction MyComponent({ data: { networkStatus } }) {\n  if (networkStatus === 6) {\n    return Polling!;\n  } else if (networkStatus < 7) {\n    return Loading...;\n  } else {\n    // ...\n  }\n}\nexport default graphql(gql`query MyComponentQuery  { ... }`)(MyComponent);\n```\n`data.variables`\nThe variables that Apollo used to fetch data from your GraphQL endpoint. This property is helpful if you want to render some information based on the variables that were used to make a request against your server.\nExample:\n```js\nfunction MyComponent({ data: { variables } }) {\n  return (\n    \n      Query executed with the following variables:\n      `{JSON.stringify(variables)}`\n\n  );\n}\nexport default graphql(gql`query MyComponentQuery  { ... }`)(MyComponent);\n```\n`data.refetch(variables)`\nForces your component to refetch the query you defined in the `graphql()` function. This method is helpful when you want to reload the data in your component, or retry a fetch after an error.\n`data.refetch` returns a promise that resolves with the new data fetched from your API once the query has finished executing. The promise will reject if the query failed.\nThe `data.refetch` function takes a single `variables` object argument. The `variables` argument will replace `variables` used with either the `query` option or the query from your `graphql()` HOC (depending on whether or not you specified a `query`) option to refetch the query you defined in the `graphql()` function.\nExample:\n```js\nfunction MyComponent({ data: { refetch } }) {\n  return  refetch()}>Reload;\n}\nexport default graphql(gql`query MyComponentQuery  { ... }`)(MyComponent);\n```\n`data.fetchMore(options)`\nThe `data.fetchMore` function allows you to do pagination with your query component. To learn more about pagination with `data.fetchMore`, be sure to read the pagination documentation.\n`data.fetchMore` returns a promise that resolves once the query executed to fetch more data has resolved.\nThe `data.fetchMore` function takes a single `options` object argument. The `options` argument may take the following properties:\n\n`[query]`: This is an optional GraphQL document created with the `gql` GraphQL tag. If you specify a `query` then that query will be fetched when you call `data.fetchMore`. If you do not specify a `query`, then the query from your `graphql()` HOC will be used.\n`[variables]`: The optional variables you may provide that will be used with either the `query` option or the query from your `graphql()` HOC (depending on whether or not you specified a `query`).\n`updateQuery(previousResult, { fetchMoreResult, variables })`: This is the required function you define that will actually update your paginated list. The first argument, `previousResult`, will be the previous data returned by the query you defined in your `graphql()` function. The second argument is an object with two properties, `fetchMoreResult` and `variables`. `fetchMoreResult` is the data returned by the new fetch that used the `query` and `variables` options from `data.fetchMore`. `variables` are the variables that were used when fetching more data. Using these arguments you should return a new data object with the same shape as the GraphQL query you defined in your `graphql()` function. See an example of this below, and also make sure to read the pagination documentation.\n\nExample:\n`js\ndata.fetchMore({\n  updateQuery: (previousResult, { fetchMoreResult, variables }) => {\n    return {\n      ...previousResult,\n      // Add the new feed data to the end of the old feed data.\n      feed: [...previousResult.feed, ...fetchMoreResult.feed],\n    };\n  },\n});`\n`data.subscribeToMore(options)`\nThis function will set up a subscription, triggering updates whenever the server sends a subscription publication. This requires subscriptions to be set up on the server to properly work. Check out the subscriptions guide for more information on getting this set up.\nThis function returns an `unsubscribe` function handler which can be used to unsubscribe later.\nA common practice is to wrap the `subscribeToMore` call within `getDerivedStateFromProps` and perform the subscription after the original query has completed. To ensure the subscription isn't created multiple times, you can add it to component state. See the example for more details.\n\n`[document]`: Document is a required property that accepts a GraphQL subscription created with the `gql` template string tag. It should contain a single GraphQL subscription operation with the data that will be returned.\n`[variables]`: The optional variables you may provide that will be used with the `document` option.\n`[updateQuery]`: An optional function that runs every time the server sends an update. This modifies the results of the HOC query. The first argument, `previousResult`, will be the previous data returned by the query you defined in your `graphql()` function. The second argument is an object with two properties. `subscriptionData` is result of the subscription. `variables` is the variables object used with the subscription query. Using these arguments you should return a new data object with the same shape as the GraphQL query you defined in your `graphql()` function. This is similar to the fetchMore callback.\n`[onError]`: An optional error callback.\n\nIn order to update the query's store with the result of the subscription, you must specify either the `updateQuery` option in `subscribeToMore` or the `reducer` option in your `graphql()` function.\nExample:\n```js\nclass SubscriptionComponent extends Component {\n  state = {\n    subscriptionParam: null,\n    unsubscribe: null,\n  };\nstatic getDerivedStateFromProps(nextProps, prevState) {\n    if (!nextProps.data.loading) {\n      // Check for existing subscription\n      if (prevState.unsubscribe) {\n        // Only unsubscribe/update state if subscription variable has changed\n        if (prevState.subscriptionParam === nextProps.subscriptionParam) {\n          return null;\n        }\n        prevState.unsubscribe();\n      }\n\n\n```  return {\n    // Subscribe\n    unsubscribe: nextProps.data.subscribeToMore({\n      document: gql`subscription MySubscription {...}`,\n      variables: {\n        param: nextProps.subscriptionParam,\n      },\n      updateQuery: (previousResult, { subscriptionData, variables }) => {\n        // Perform updates on previousResult with subscriptionData\n        return updatedResult;\n      },\n    }),\n    // Store subscriptionParam in state for next update\n    subscriptionParam: nextProps.subscriptionParam,\n  };\n}\n\nreturn null;\n```\n\n\n}\nrender() {\n    ...\n  }\n}\n```\n`data.startPolling(interval)`\nThis function will set up an interval and send a fetch request every time that interval ellapses. The function takes only one integer argument which allows you to configure how often you want your query to be executed in milliseconds. In other words, the `interval` argument represents the milliseconds between polls.\nPolling is a good way to keep the data in your UI fresh. By refetching your data every 5,000 milliseconds (or 5 seconds, for example) you may effectively emulate realtime data without needing to build up a realtime backend.\nIf you call `data.startPolling` when your query is already polling then the current polling process will be cancelled and a new process will be started with the interval you specified.\nYou may also use options.pollInterval to start polling immediately after your component mounts. It is recommend that you use `options.pollInterval` if you don\u2019t need to arbitrarily start and stop polling.\nIf you set your `interval` to 0 then that means no polling instead of executing a request every JavaScript event loop tick.\nExample:\n```js\nclass MyComponent extends Component {\n  componentDidMount() {\n    // In this specific case you may want to use`options.pollInterval` instead.\n    this.props.data.startPolling(1000);\n  }\nrender() {\n    // ...\n  }\n}\nexport default graphql(gql`query MyComponentQuery { ... }`)(MyComponent);\n```\n`data.stopPolling()`\nBy calling this function you will stop any current polling process. Your query will not start polling again until you call `data.startPolling`.\nExample:\n```js\nclass MyComponent extends Component {\n  render() {\n    return (\n      \n {\n            this.props.data.startPolling(1000);\n          }}\n        >\n          Start Polling\n        \n {\n            this.props.data.stopPolling();\n          }}\n        >\n          Stop Polling\n        \n\n    );\n  }\n}\nexport default graphql(gql`query MyComponentQuery  { ... }`)(MyComponent);\n```\n`data.updateQuery(updaterFn)`\nThis function allows you to update the data for your query outside of the context of any mutation, subscription, or fetch. This function only takes a single argument which will be another function. The argument function has the following signature:\n`(previousResult, { variables }) => nextResult`\nThe first argument will be the data for your query that currently exists in the store, and you are expected to return a new data object with the same shape. That new data object will be written to the store and any components tracking that data will be updated reactively.\nThe second argument is an object with a single property, `variables`. The `variables` property allows you to see what variables were used when reading the `previousResult` from the store.\nThis method will not update anything on the server. It will only update data in your client cache and if you reload your JavaScript environment then your update will disappear.\nExample:\n`js\ndata.updateQuery(previousResult => ({\n  ...previousResult,\n  count: previousResult.count + 1,\n}));`\n`config.options`\nAn object or function that returns an object of options that are used to configure how the query is fetched and updated.\nIf `config.options` is a function then it will take the component\u2019s props as its first argument.\nThe options available for use in this object depend on the operation type you pass in as the first argument to `graphql()`. The references below will document which options are available when your operation is a query. To see what other options are available for different operations, see the generic documentation for config.options.\nExample:\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: {\n    // Options go here.\n  },\n})(MyComponent);`\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: props => ({\n    // Options are computed from `props` here.\n  }),\n})(MyComponent);`\n`options.variables`\nThe variables that will be used when executing the query operation. These variables should correspond with the variables that your query definition accepts. If you define `config.options` as a function then you may compute your variables from your props.\nExample:\n`js\nexport default graphql(\n  gql`\n  query MyQuery ($width: Int!, $height: Int!) {\n    ...\n  }\n`,\n  {\n    options: props => ({\n      variables: {\n        width: props.size,\n        height: props.size,\n      },\n    }),\n  },\n)(MyComponent);`\n`options.fetchPolicy`\nThe fetch policy is an option that allows you to specify how you want your component to interact with the Apollo Client cache. By default, your component will try to read from the cache first, and if the full data for your query is in the cache then Apollo simply returns the data from the cache. If the full data for your query is not in the cache then Apollo will execute your request using your network interface. By changing this option you can change this behavior.\nFor a list of supported fetch policies, see Setting a fetch policy.\nExample:\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: { fetchPolicy: 'cache-and-network' },\n})(MyComponent);`\n`options.errorPolicy`\nThe error policy is an option which allows you to specify how you want your component to handle errors that can happen when fetching data from GraphQL. There are two types of errors that can happen during your request; a runtime error on the client or server which results in no data, or some GraphQL errors which may be delivered alongside actual data. In order to control how your UI interacts with these errors, you can use the error policy to tell Apollo when you want to know about GraphQL Errors or not!\nValid `errorPolicy` values are:\n\n`none`: This is the default value where we treat GraphQL errors as runtime errors. Apollo will discard any data that came back with the request and render your component with an `error` prop.\n`ignore`: Much like `none`, this causes Apollo to ignore any data from your server, but it also won't update your UI aside from setting the loading state back to false.\n`all`: Selecting all means you want to be notified any time there are any GraphQL errors. It will render your component with any data from the request and any errors with their information. It is particularly helpful for server side rendering so your UI always shows something\n\nExample:\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: { errorPolicy: 'all' },\n})(MyComponent);`\n`options.pollInterval`\nThe interval in milliseconds at which you want to start polling. Whenever that number of milliseconds elapses your query will be executed using the network interface and another execution will be scheduled using the configured number of milliseconds.\nThis option will start polling your query immediately when the component mounts. If you want to start and stop polling dynamically then you may use data.startPolling and data.stopPolling.\nIf you set `options.pollInterval` to 0 then that means no polling instead of executing a request every JavaScript event loop tick.\nExample:\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: { pollInterval: 5000 },\n})(MyComponent);`\n`options.notifyOnNetworkStatusChange`\nWhether or not updates to the network status or network error should trigger re-rendering of your component.\nThe default value is `false`.\nExample:\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: { notifyOnNetworkStatusChange: true },\n})(MyComponent);`\n`options.context`\nWith the flexibility and power of Apollo Link being part of Apollo Client, you may want to send information from your operation straight to a link in your network chain! This can be used to do things like set `headers` on HTTP requests from props, control which endpoint you send a query to, and so much more depending on what links your app is using. Everything under the `context` object gets passed directly to your network chain. For more information about using context, check out the HttpLink context docs\n`partialRefetch`\nIf `true`, perform a query `refetch` if the query result is marked as being partial, and the returned data is reset to an empty Object by the Apollo Client `QueryManager` (due to a cache miss).\nThe default value is `false` for backwards-compatibility's sake, but should be changed to true for most use-cases.\nExample:\n`js\nexport default graphql(gql`query MyQuery { ... }`, {\n  options: { partialRefetch: true },\n})(MyComponent);`\n`graphql() options for mutations`\n`props.mutate`\nThe higher order component created when you pass a mutation to `graphql()` will provide your component with a single prop named `mutate`. Unlike the `data` prop which you get when you pass a query to `graphql()`, `mutate` is a function.\nThe `mutate` function will actually execute your mutation using the network interface therefore mutating your data. The `mutate` function will also then update your cache in ways you define.\nTo learn more about how mutations work, be sure to check out the mutations usage documentation.\nThe `mutate` function accepts the same options that config.options for mutations accepts, so make sure to read through the documentation for that to know what you can pass into the `mutate` function.\nThe reason the `mutate` function accepts the same options is that it will use the options from config.options by default. When you pass an object into the `mutate` function you are just overriding what is already in config.options.\nExample:\n```js\nfunction MyComponent({ mutate }) {\n  return (\n     {\n        mutate({\n          variables: { foo: 42 },\n        });\n      }}\n    >\n      Mutate\n    \n  );\n}\nexport default graphql(gql`mutation MyMutation { ... }`)(MyComponent);\n```\n`config.options`\nAn object or function that returns an object of options that are used to configure how the query is fetched and updated.\nIf `config.options` is a function then it will take the component\u2019s props as its first argument.\nThe options available for use in this object depend on the operation type you pass in as the first argument to `graphql()`. The references below will document which options are available when your operation is a mutation. To see what other options are available for different operations, see the generic documentation for config.options.\nThe properties accepted in this options object may also be accepted by the props.mutate function. Any options passed into the `mutate` function will take precedence over the options defined in the `config` object.\nExample:\n`js\nexport default graphql(gql`mutation MyMutation { ... }`, {\n  options: {\n    // Options go here.\n  },\n})(MyComponent);`\n`js\nexport default graphql(gql`mutation MyMutation { ... }`, {\n  options: props => ({\n    // Options are computed from `props` here.\n  }),\n})(MyComponent);`\n```js\nfunction MyComponent({ mutate }) {\n  return (\n    <button\n      onClick={() => {\n        mutate({\n          // Options are component from`props` and component state here.\n        });\n      }}\n    >\n      Mutate\n    \n  );\n}\nexport default graphql(gql`mutation MyMutation { ... }`)(MyComponent);\n```\n`options.variables`\nThe variables which will be used to execute the mutation operation. These variables should correspond to the variables that your mutation definition accepts. If you define `config.options` as a function, or you pass variables into the props.mutate function then you may compute your variables from props and component state.\nExample:\n`js\nexport default graphql(\n  gql`\n  mutation MyMutation ($foo: String!, $bar: String!) {\n    ...\n  }\n`,\n  {\n    options: props => ({\n      variables: {\n        foo: props.foo,\n        bar: props.bar,\n      },\n    }),\n  },\n)(MyComponent);`\n`options.optimisticResponse`\nOften when you mutate data it is fairly easy to predict what the response of the mutation will be before asking your server. The optimistic response option allows you to make your mutations feel faster by simulating the result of your mutation in your UI before the mutation actually finishes.\nTo learn more about the benefits of optimistic data and how to use it be sure to read the recipe on Optimistic UI.\nThis optimistic response will be used with options.update and options.updateQueries to apply an update to your cache which will be rolled back before applying the update from the actual response.\nExample:\n```js\nfunction MyComponent({ newText, mutate }) {\n  return (\n     {\n        mutate({\n          variables: {\n            text: newText,\n          },\n          // The optimistic response has all of the fields that are included in\n          // the GraphQL mutation document below.\n          optimisticResponse: {\n            createTodo: {\n              id: -1, // A temporary id. The server decides the real id.\n              text: newText,\n              completed: false,\n            },\n          },\n        });\n      }}\n    >\n      Add Todo\n    \n  );\n}\nexport default graphql(gql`mutation CreateTodo ($text: String!) {\n    createTodo(text: $text) {\n      id\n      text\n      completed\n    }\n  }`)(MyComponent);\n```\n`options.update`\nThis option allows you to update your store based on your mutation\u2019s result. By default Apollo Client will update all of the overlapping nodes in your store. Anything that shares the same id as returned by the `dataIdFromObject` you defined will be updated with the new fields from your mutation results. However, sometimes this alone is not sufficient. Sometimes you may want to update your cache in a way that is dependent on the data currently in your cache. For these updates you may use an `options.update` function.\n`options.update` takes two arguments. The first is an instance of a `DataProxy` object which has some methods which will allow you to interact with the data in your store. The second is the response from your mutation - either the optimistic response, or the actual response returned by your server (see the mutation result described in the mutation render prop section for more details).\nIn order to change the data in your store call methods on your `DataProxy` instance like writeQuery and writeFragment. This will update your cache and reactively re-render any of your GraphQL components which are querying affected data.\nTo read the data from the store that you are changing, make sure to use methods on your `DataProxy` like readQuery and readFragment.\nFor more information on updating your cache after a mutation with the `options.update` function make sure to read the Apollo Client technical documentation on the subject.\nExample:\n```js\nconst query = gql`query GetAllTodos { todos { ... } }`;\nexport default graphql(\n  gql`mutation CreateTodo ($text: String!) {\n    createTodo(text: $text) { ... }\n  }`,\n  {\n    options: {\n      update: (proxy, { data: { createTodo } }) => {\n        const data = proxy.readQuery({ query });\n        data.todos.push(createTodo);\n        proxy.writeQuery({ query, data });\n      },\n    },\n  },\n)(MyComponent);\n```\n`options.refetchQueries`\nSometimes when you make a mutation you also want to update the data in your queries so that your users may see an up-to-date user interface. There are more fine-grained ways to update the data in your cache which include options.updateQueries, and options.update. However, you can update the data in your cache more reliably at the cost of efficiency by using `options.refetchQueries`.\n`options.refetchQueries` will execute one or more queries using your network interface and will then normalize the results of those queries into your cache. Allowing you to potentially refetch queries you had fetched before, or fetch brand new queries.\n`options.refetchQueries` is either an array of strings or objects, or a function which takes the result of the mutation and returns an array of strings or objects.\nIf `options.refetchQueries` is an array of strings then Apollo Client will look for any queries with the same names as the provided strings and will refetch those queries with their current variables. So for example if you have a GraphQL query component with a query named `Comments` (the query may look like: `query Comments { ... }`), and you pass an array of strings containing `Comments` to `options.refetchQueries` then the `Comments` query will be re-executed and when it resolves the latest data will be reflected in your UI.\nIf `options.refetchQueries` is an array of objects then the objects must have two properties:\n\n`query`: Query is a required property that accepts a GraphQL query created with the `gql` template string tag. It should contain a single GraphQL query operation that will be executed once the mutation has completed.\n`[variables]`: Is an optional object of variables that is required when `query` accepts some variables.\n\nIf an array of objects with this shape is specified then Apollo Client will refetch these queries with their variables.\nExample:\n`js\nexport default graphql(gql`mutation MyMutation { ... }`, {\n  options: {\n    refetchQueries: ['CommentList', 'PostList'],\n  },\n})(MyComponent);`\n```js\nimport { COMMENT_LIST_QUERY } from '../components/CommentList';\nexport default graphql(gql`mutation MyMutation { ... }`, {\n  options: props => ({\n    refetchQueries: [\n      {\n        query: COMMENT_LIST_QUERY,\n      },\n      {\n        query: gql`query GetPostById ($id: ID!) {\n            post(id: $id) {\n              commentCount\n            }\n          }`,\n        variables: {\n          id: props.postID,\n        },\n      },\n    ],\n  }),\n})(MyComponent);\n```\n`js\nexport default graphql(gql`mutation MyMutation { ... }`, {\n  options: {\n    refetchQueries: mutationResult => ['CommentList', 'PostList'],\n  },\n})(MyComponent);`\nPlease note that refetched queries are handled asynchronously, and by default are not necessarily completed before the mutation has completed. If you want to make sure refetched queries are completed before the mutation is considered done (or resolved), set options.awaitRefetchQueries to `true`.\n`options.awaitRefetchQueries`\nQueries refetched using options.refetchQueries are handled asynchronously, which means by default they are not necessarily completed before the mutation has completed. Setting `options.awaitRefetchQueries` to `true` will make sure refetched queries are completed before the mutation is considered done (or resolved). `options.awaitRefetchQueries` is `false` by default.\n`options.updateQueries`\nNote: We recommend using options.update instead of `updateQueries`. `updateQueries` will be removed in the next version of Apollo Client\nThis option allows you to update your store based on your mutation\u2019s result. By default Apollo Client will update all of the overlapping nodes in your store. Anything that shares the same id as returned by the `dataIdFromObject` you defined will be updated with the new fields from your mutation results. However, sometimes this alone is not sufficient. Sometimes you may want to update your cache in a way that is dependent on the data currently in your cache. For these updates you may use an `options.updateQueries` function.\n`options.updateQueries` takes an object where query names are the keys and reducer functions are the values. If you are familiar with Redux, defining your `options.updateQueries` reducers is very similar to defining your Redux reducers. The object looks something like this:\n`js\n{\n  Comments: (previousData, { mutationResult, queryVariables }) => nextData,\n}`\nMake sure that the key of your `options.updateQueries` object corresponds to an actual query that you have made somewhere else in your app. The query name will be the name you put after specifying the `query` operation type. So for example in the following query:\n`graphql\nquery Comments {\n  entry(id: 5) {\n    comments {\n      ...\n    }\n  }\n}`\nThe query name would be `Comments`. If you have not executed a GraphQL query with the name of `Comments` before somewhere in your application, then the reducer function will never be run by Apollo and the key/value pair in `options.updateQueries` will be ignored.\nThe first argument to the function you provide as the value for your object will be the previous data for your query. So if your key is `Comments` then the first argument will be the last data object that was returned for your `Comments` query, or the current object that is being rendered by any component using the `Comments` query.\nThe second argument to your function value will be an object with three properties:\n\n`mutationResult`: The `mutationResult` property will represent the result of your mutation after hitting the server. If you provided an options.optimisticResponse then `mutationResult` may be that object.\n`queryVariables`: The last set of variables that the query was executed with. This is helpful because when you specify the query name it will only update the data in the store for your current variable set.\n`queryName`: This is the name of the query you are updating. It is the same name as the key you provided to `options.updateQueries`.\n\nThe return value of your `options.updateQueries` functions must have the same shape as your first `previousData` argument. However, you must not mutate the `previousData` object. Instead you must create a new object with your changes. Just like in a Redux reducer.\nExample:\n`js\nexport default graphql(\n  gql`\n  mutation SubmitComment ($text: String!) {\n    submitComment(text: $text) { ... }\n  }\n`,\n  {\n    options: {\n      updateQueries: {\n        Comments: (previousData, { mutationResult }) => {\n          const newComment = mutationResult.data.submitComment;\n          // Note how we return a new copy of `previousData` instead of mutating\n          // it. This is just like a Redux reducer!\n          return {\n            ...previousData,\n            entry: {\n              ...previousData.entry,\n              comments: [newComment, ...previousData.entry.comments],\n            },\n          };\n        },\n      },\n    },\n  },\n)(MyComponent);`\n`withApollo(component)`\n`js\nimport { withApollo } from '@apollo/client/react/hoc';`\nAn enhancer that provides direct access to your ApolloClient instance. This is useful if you want to do custom logic with Apollo, such as executing one-off queries. By calling this function with the component you want to enhance, `withApollo()` creates a new component that passes an instance of `ApolloClient` as a `client` prop.\nMost of the time you want to use `graphql()` instead of `withApollo()`. `graphql()` provides helpful features for working with your GraphQL data. You should only use `withApollo()` if you want the GraphQL client without any of these features.\nThis will only be able to provide access to your client if there is an <ApolloProvider/> component higher up in your tree to actually provide the client.\nExample:\n```js\nfunction MyComponent({ client }) {\n  console.log(client);\n}\nexport default withApollo(MyComponent);",
    "tag": "apollo-client"
  },
  {
    "title": "Installation",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/api/react/components.mdx",
    "content": "\ntitle: Components\ndescription: Deprecated React Apollo render prop component API\n\nimport QueryOptions3 from '../../../shared/query-options.mdx';\nimport QueryResult3 from '../../../shared/query-result.mdx';\nimport MutationOptions3 from '../../../shared/mutation-options.mdx';\nimport MutationResult3 from '../../../shared/mutation-result.mdx';\nimport SubscriptionOptions3 from '../../../shared/subscription-options.mdx';\nimport SubscriptionResult3 from '../../../shared/subscription-result.mdx';\n\nNote: Official support for React Apollo render prop components ended in March 2020. This library is still included in the `@apollo/client` package, but it no longer receives feature updates or bug fixes.\n\nInstallation\nThe render prop library is included in the core `@apollo/client` package:\n`npm install @apollo/client`\nYou then import the library's symbols from `@apollo/client/react/components`.\n`Query`\nProps\nThe `Query` component accepts the following props. `query` is required.\n\nRender prop function\nThe render prop function that you pass to the `children` prop of `Query` is called with an object (`QueryResult`) that has the following properties. This object contains your query result, plus some helpful functions for refetching, dynamic polling, and pagination.\n\n`Mutation`\nThe Mutation component accepts the following props. Only `mutation` is required.\n\nRender prop function\nThe render prop function that you pass to the `children` prop of `Mutation` is called with the `mutate` function and an object with the mutation result. The `mutate` function is how you trigger the mutation from your UI. The object contains your mutation result, plus loading and error state.\n\n`Subscription`\nProps\nThe Subscription component accepts the following props. Only `subscription` is required.\n\nRender prop function\nThe render prop function that you pass to the `children` prop of `Subscription` is called with an object that has the following properties.",
    "tag": "apollo-client"
  },
  {
    "title": "with npm",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/performance/babel.md",
    "content": "\ntitle: Compiling queries with Babel\nIf you prefer co-locating your GraphQL queries in your Javascript files, you typically use the graphql-tag library to write them. That requires to process the query strings into a GraphQL AST, which will add to the startup time of your application, especially if you have many queries.\nTo avoid this runtime overhead, you can precompile your queries created with `graphql-tag` using Babel. Here are two ways you can do this:\n\nUsing babel-plugin-graphql-tag\nUsing graphql-tag.macro\nUsing ts-transform-graphql-tag for Typescript\n\nIf you prefer to keep your GraphQL code in separate files (`.graphql` or `.gql`) you can use babel-plugin-import-graphql. This plugin still uses `graphql-tag` under the hood, but transparently. You simply `import` your operations/fragments as if each were an export from your GraphQL file. This carries the same precompilation benefits as the above approaches.\nUsing babel-plugin-graphql-tag\nThis approach will allow you to use the `graphql-tag` library as usual, and when processing the files with this babel plugin, the calls to that library will be replaced by the precompiled result.\nInstall the plugin in your dev dependencies:\n```\nwith npm\nnpm install --save-dev babel-plugin-graphql-tag\nor with yarn\nyarn add --dev babel-plugin-graphql-tag\n```\nThen add the plugin in your `.babelrc` configuration file:\n`{\n  \"plugins\": [\n    \"graphql-tag\"\n  ]\n}`\nAnd that's it! All the usages of `import gql from 'graphql-tag'` will be removed, and the calls to `gql` will be replaced by the compiled version.\nUsing graphql-tag.macro\nThis approach is a bit more explicit, since you change all your usages of `graphql-tag` for `graphql-tag.macro`, which exports a `gql` function that you can use the same way as the original one. This macro requires the babel-macros plugin, which will do the same as the previous approach but only on the calls that come from the macro import, leaving regular calls to the `graphql-tag` library untouched.\nWhy would you prefer this approach? Mainly because it requires less configuration (`babel-macros` works with all kinds of macros, so if you already had it installed you don't have to do anything else), and also because of the explicitness. You can read more about the rationale of using `babel-macros` in this blog post.\nTo use it, provided that you already have babel-macros installed and configured, you just need to change this:\n```js\nimport gql from 'graphql-tag';\nconst query = gql`query HelloWorld {\n    hello {\n      world\n    }\n  }`;\n```\nto this:\n```js\nimport gql from 'graphql-tag.macro'; // <-- Use the macro\nconst query = gql`query HelloWorld {\n    hello {\n      world\n    }\n  }`;\n```\nUsing babel-plugin-import-graphql\nInstall the plugin in your dev dependencies:\n```\nwith npm\nnpm install --save-dev babel-plugin-import-graphql\nor with yarn\nyarn add --dev babel-plugin-import-graphql\n```\nThen add the plugin in your `.babelrc` configuration file:\n`{\n  \"plugins\": [\n    \"import-graphql\"\n  ]\n}`\nNow any `import` statements importing from a GraphQL file type will return a ready-to-use GraphQL DocumentNode object.\n```jsx\nimport React, { Component } from 'react';\nimport { graphql } from '@apollo/react-hoc';\nimport myImportedQuery from './productsQuery.graphql';\n// or for files with multiple operations:\n// import { query1, query2 } from './queries.graphql';\nclass QueryingComponent extends Component {\n  render() {\n    if (this.props.data.loading) return Loading...;\n    return {`This is my data: ${this.props.data.queryName}`};\n  }\n}\nexport default graphql(myImportedQuery)(QueryingComponent);\n```\nUsing ts-transform-graphql-tag\nInstall the plugin in your dev dependencies:\n```\nwith npm\nnpm install --save-dev ts-transform-graphql-tag\nor with yarn\nyarn add --dev ts-transform-graphql-tag\n```\nRead the ts-transform-graphql-tag documentation for Webpack or FuseBox usage instructions.\nFragments\nAll of these approaches support the use of fragments.\nFor the first two approaches, you can have fragments defined in a different call to `gql` (either in the same file or in a different one). You can then include them into the main query using interpolation, like this:\n```js\nimport gql from 'graphql-tag';\n// or import gql from 'graphql-tag.macro';\nconst fragments = {\n  hello: gql`fragment HelloStuff on Hello {\n      universe\n      galaxy\n    }`\n};\nconst query = gql`\n  query HelloWorld {\n    hello {\n      world\n      ...HelloStuff\n    }\n  }\n${fragments.hello}\n`;\n```",
    "tag": "apollo-client"
  },
  {
    "title": "The `optimisticResponse` option",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/performance/optimistic-ui.mdx",
    "content": "\ntitle: Optimistic mutation results\ndescription: Update your UI before your server responds\n\nIt's often possible to predict the most likely result of a mutation before your GraphQL server returns it. Apollo Client can use this \"most likely result\" to update your UI optimistically, making your app feel more responsive to the user.\nFor example, let's say we have a blog application that supports the following mutation:\n```graphql\ntype Mutation {\n  updateComment(commentId: ID!, content: String!): Comment!\n# ...other mutations...\n}\n```\nIf a user edits an existing comment on a post, the app executes the `updateComment` mutation, which returns a `Comment` object with updated `content`.\nOur app knows what the updated `Comment` object will probably look like, which means it can optimistically update its UI to display the update before the GraphQL server responds with it. If our app is wrong (e.g., the GraphQL server returns an unchanged `Comment` due to an error), the UI will automatically update to reflect the actual response.\nThe `optimisticResponse` option\nTo enable this optimistic UI behavior, we provide an `optimisticResponse` option to the mutate function that we use to execute our mutation.\nLet's look at some code:\n```jsx {20-26} title=\"CommentPageWithData.jsx\"\n// Mutation definition\nconst UPDATE_COMMENT = gql`\n  mutation UpdateComment($commentId: ID!, $commentContent: String!) {\n    updateComment(commentId: $commentId, content: $commentContent) {\n      id\n      __typename\n      content\n    }\n  }\n`;\n// Component definition\nfunction CommentPageWithData() {\n  const [mutate] = useMutation(UPDATE_COMMENT);\n  return (\n    \n        mutate({\n          variables: { commentId, commentContent },\n          optimisticResponse: {\n            updateComment: {\n              id: commentId,\n              __typename: \"Comment\",\n              content: commentContent\n            }\n          }\n        })\n      }\n    />\n  );\n}\n```\nAs this example shows, the value of `optimisticResponse` is an object that matches the shape of the mutation response we expect from the server. Importantly, this includes the `Comment`'s `id` and `__typename` fields. The Apollo Client cache uses these values to generate the comment's unique cache identifier (e.g., `Comment:5`).\nOptimistic mutation lifecycle\n\n\nWhen the code above calls `mutate`, the Apollo Client cache stores a `Comment` object with the field values specified in `optimisticResponse`. However, it does not overwrite the existing cached `Comment` with the same cache identifier. Instead, it stores a separate, optimistic version of the object. This ensures that our cached data remains accurate if our `optimisticResponse` is wrong.\n\n\nApollo Client notifies all active queries that include the modified comment. Those queries automatically update, and their associated components re-render to reflect the optimistic data. Because this doesn't require any network requests, it's nearly instantaneous to the user.\n\n\nEventually, our server responds with the mutation's actual resulting  `Comment` object.\n\n\nThe Apollo Client cache removes the optimistic version of the `Comment` object. It also overwrites the canonical cached version with values returned from the server.\n\n\nApollo Client notifies all affected queries again. The associated components re-render, but if the server's response matches our `optimisticResponse`, this is invisible to the user.\n\n\nExample: Adding a new object to a list\nThe previous example shows how to provide an optimistic result for an object that's already in the Apollo Client cache. But what about a mutation that creates a new object? This works similarly.\nThe biggest difference here is that the client doesn't yet have the new object's `id` (or other identifying field). This means you have to provide a temporary value for the `id` so the Apollo Client cache can store the optimistic result as an object of the correct type.\nFor example, here's an `optimisticResponse` for an `addTodo` mutation that creates a new item in a user's to-do list:\n`js\noptimisticResponse: {\n  addTodo: {\n    id: 'temp-id',\n    __typename: \"Todo\",\n    description: input.value // Obtained from user input\n  }\n}`\nWhen you execute the mutate function in this case, the Apollo Client cache stores a new `Todo` object with cache identifier `Todo:temp-id`. When the server responds with the new `Todo`'s actual `id`, the optimistic object is removed as usual, and the canonical object is cached.\nView on CodeSandbox\nYou can view a full to-do list example on CodeSandbox:\n\n\n\n\nYou can also run the example client and server locally by cloning the docs-examples repo.\n\nWhen viewing the example, try adding an item to the to-do list. Notice that the item appears in the list instantly, even though the server doesn't respond instantly.",
    "tag": "apollo-client"
  },
  {
    "title": "Redirecting to cached data",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/performance/performance.mdx",
    "content": "\ntitle: Improving performance in Apollo Client\nRedirecting to cached data\nIn some cases, a query might request data that's already present in the Apollo Client cache thanks to a different query that already ran. For example, your UI might have both a list view and a detail view with queries that fetch the same fields from a particular object.\nIn cases like these, you can avoid sending your server a followup query that fetches identical data. To learn how, see Cache redirects.\nPrefetching data\nPrefetching involves executing queries for data before that data needs to be rendered. It helps your application's UI feel more responsive to the user.\nMost of the time, prefetching involves querying for data as soon as you can guess that a user will probably need it.\nFor example, this code snippet calls `client.query` to execute a query when the user hovers over a particular link (to a page that uses the data returned by the query):\n\n```jsx {19-24}\nfunction Feed() {\n  const { loading, error, data, client } = useQuery(GET_DOGS);\nlet content;\n  if (loading) {\n    content = ;\n  } else if (error) {\n    content = ;\n  } else {\n    content = (\n       (\n          /${data.breed}/${data.id},\n              state: { id: data.id }\n            }}\n            onMouseOver={() =>\n              client.query({\n                query: GET_DOG,\n                variables: { breed: data.breed }\n              })\n            }\n            style={{ textDecoration: \"none\" }}\n          >\n            \n          \n        )}\n      />\n    );\n  }\nreturn (\n    \n\n      {content}\n    \n  );\n}\n```\n\nWhen the `GET_DOG` query completes, its result is stored in the Apollo Client cache. This means that if the user then clicks the link, the dog's detail page can immediately populate that data from the cache, which feels instantaneous to the user.\nIn addition to a mouse hover, here are some other suggestions for situations when prefetching can be helpful:\n\nDuring a multi-step flow (such as a wizard), you can preload each next step's data during each current step.\nIf your app's analytics indicate a frequent transition between two particular views, you can use prefetching to optimize for that path.\nIf a region of a page has multiple tabs or slides (such as a carousel), you can preload data for some or all of them to make transitions feel snappier.\n\nA special form of prefetching is store hydration from the server, so you might also consider hydrating more data than is actually needed for the first page load to make other interactions faster.",
    "tag": "apollo-client"
  },
  {
    "title": "Differences from client-side rendering",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/performance/server-side-rendering.mdx",
    "content": "\ntitle: Server-side rendering\nServer-side rendering (SSR) is a performance optimization for modern web apps. It enables you to render your app's initial state to raw HTML and CSS on the server before serving it to a browser. This means users don't have to wait for their browser to download and initialize React (or Angular, Vue, etc.) before content is available:\n```mermaid\nsequenceDiagram\n    participant Browser;\n    participant Server;\n\n\n```Browser->>Server: Requests example.com;\nNote over Server: Renders initial state of example.com on server;\nServer->>Browser: Returns raw HTML and CSS;\nNote over Browser: Displays raw HTML and CSS;\nNote over Browser: Initializes view layer and \"rehydrates\" it with returned data\n```\n\n\n```\nApollo Client provides a handy API for using it with server-side rendering, including a function that executes all of the GraphQL queries that are required to render your component tree. You don't need to make any changes to your queries to support this API.\nDifferences from client-side rendering\nWhen you render your React app on the server side, most of the code is identical to its client-side counterpart, with a few important exceptions:\n\n\nYou need to use a server-compatible router for React, such as React Router.\n(In the case of React Router, you wrap your application in a `StaticRouter` component instead of the `BrowserRouter` you use on the client side.)\n\n\nYou need to replace relative URLs with absolute URLs wherever applicable.\n\n\nThe initialization of Apollo Client changes slightly, as described below.\n\n\nInitializing Apollo Client\nHere's an example server-side initialization of Apollo Client:\n```js {7-17}\nimport {\n  ApolloClient,\n  createHttpLink,\n  InMemoryCache\n} from '@apollo/client';\nconst client = new ApolloClient({\n  ssrMode: true,\n  link: createHttpLink({\n    uri: 'http://localhost:3010',\n    credentials: 'same-origin',\n    headers: {\n      cookie: req.header('Cookie'),\n    },\n  }),\n  cache: new InMemoryCache(),\n});\n```\nYou'll notice a couple differences from a typical client-side initialization:\n\n\nYou provide `ssrMode: true`. This prevents Apollo Client from refetching queries unnecessarily, and it also enables you to use the `getDataFromTree` function (covered below).\n\n\nInstead of providing a `uri` option, you provide an `HttpLink` instance to the `link` option. This enables you to specify any required authentication details when sending requests to your GraphQL endpoint from the server side.\nNote that you also might need to make sure your GraphQL endpoint is configured to accept GraphQL operations from your SSR server (for example, by safelisting its domain or IP).\n\n\n\nIt's possible and valid for your GraphQL endpoint to be hosted by the same server that's performing SSR. In this case, Apollo Client doesn't need to make network requests to execute queries. For details, see Avoiding the network for local queries.\n\nExample\nLet's look at an example of SSR in a Node.js app. This example uses Express and React Router v4, although it can work with any server middleware and any router that supports SSR.\nFirst, here's an example `app.js` file, without the code for rendering React to HTML and CSS:\n\n```jsx title=\"app.js\"\nimport {\n  ApolloProvider,\n  ApolloClient,\n  createHttpLink,\n  InMemoryCache\n} from '@apollo/client';\nimport Express from 'express';\nimport React from 'react';\nimport { StaticRouter } from 'react-router';\n// File shown below\nimport Layout from './routes/Layout';\nconst app = new Express();\napp.use((req, res) => {\nconst client = new ApolloClient({\n    ssrMode: true,\n    link: createHttpLink({\n      uri: 'http://localhost:3010',\n      credentials: 'same-origin',\n      headers: {\n        cookie: req.header('Cookie'),\n      },\n    }),\n    cache: new InMemoryCache(),\n  });\nconst context = {};\n// The client-side App will instead use \n  const App = (\n    \n\n\n\n\n  );\n// TODO: rendering code (see below)\n});\napp.listen(basePort, () => console.log(\n  `app Server is now running on http://localhost:${basePort}`\n));\n```\n\nSo far, whenever this example server receives a request, it first initializes Apollo Client and then creates a React tree that's wrapped with the `ApolloProvider` and `StaticRouter` components. The contents of that tree depend on the request's path and the `StaticRouter`'s defined routes.\n\nIt's important to create an entirely new instance of Apollo Client for each request. Otherwise, your response to a request might include sensitive cached query results from a previous request.\n\nExecuting queries with `getDataFromTree`\nBecause our app uses Apollo Client, some of the components in the React tree probably execute a GraphQL query with the `useQuery` hook. We can instruct Apollo Client to execute all of the queries required by the tree's components with the `getDataFromTree` function.\nThis function walks down the entire tree and executes every required query it encounters (including nested queries). It returns a `Promise` that resolves when all result data is ready in the Apollo Client cache.\nWhen the `Promise` resolves, you're ready to render your React tree and return it, along with the current state of the Apollo Client cache.\n\nNote that if you are rendering your React tree directly to a string (instead of the component-based example below), you will need to use renderToStringWithData instead of `getDataFromTree`. This will ensure the client-side React hydration works correctly by using ReactDOMServer.renderToString to generate the string.\n\nThe following code replaces the `TODO` comment within the `app.use` call in the example above:\n```js title=\"app.js\"\n// Add this import to the top of the file\nimport { getDataFromTree } from \"@apollo/client/react/ssr\";\n// Replace the TODO with this\ngetDataFromTree(App).then((content) => {\n  // Extract the entirety of the Apollo Client cache's current state\n  const initialState = client.extract();\n// Add both the page content and the cache state to a top-level component\n  const html = ;\n// Render the component to static markup and return it\n  res.status(200);\n  res.send(`<!doctype html>\\n${ReactDOM.renderToStaticMarkup(html)}`);\n  res.end();\n});\n```\nThe definition of the top-level `Html` component that's rendered to static markup might look like this:\n`jsx title=\"components/html.js\"\nexport function Html({ content, state }) {\n  return (\n    <html>\n      <body>\n        <div id=\"root\" dangerouslySetInnerHTML={{ __html: content }} />\n        <script dangerouslySetInnerHTML={{\n          __html: `window.__APOLLO_STATE__=${JSON.stringify(state).replace(/</g, '\\\\u003c')};`,\n        }} />\n      </body>\n    </html>\n  );\n}`\nThis results in the rendered React tree being added as a child of the `root` `div`, and the initial cache state is assigned to the `__APOLLO_STATE__` global object.\n\nThe `replace` call in this example escapes the `<` character to prevent cross-site scripting attacks that are possible via the presence of `</script>` in a string literal.\n\nRehydrating the client-side cache\nAlthough the server-side cache's state is available in `__APOLLO_STATE__`, it isn't yet available in the client-side cache. `InMemoryCache` provides a helpful `restore` function for rehydrating its state with data `extract`ed from another cache instance.\nIn your client-side initialization of Apollo Client, you can rehydrate the cache like so:\n`js\nconst client = new ApolloClient({\n  cache: new InMemoryCache().restore(window.__APOLLO_STATE__),\n  uri: 'https://example.com/graphql'\n});`\nNow when the client-side version of the app runs its initial queries, the data is returned instantly because it's already in the cache!\nOverriding fetch policies during initialization\nIf some of your initial queries use the `network-only` or `cache-and-network` fetch policy, you can provide the `ssrForceFetchDelay` option to Apollo Client to skip force-fetching those queries during initialization. This way, even those queries initially run using only the cache:\n`js\nconst client = new ApolloClient({\n  cache: new InMemoryCache().restore(window.__APOLLO_STATE__),\n  link,\n  ssrForceFetchDelay: 100, // in milliseconds\n});`\nAvoiding the network for local queries\nIf your GraphQL endpoint is hosted by the same server that you're rendering from, you can optionally avoid using the network when executing your SSR queries. This is particularly helpful if `localhost` is firewalled in the server's environment (e.g., on Heroku).\nOne option is to use Apollo Link to fetch data using a local GraphQL schema instead of making a network request. To achieve this, when creating an Apollo Client on the server, you could use a SchemaLink instead of using `createHttpLink`. `SchemaLink` uses your schema and context to run the query immediately, without any additional network requests:\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client'\nimport { SchemaLink } from '@apollo/client/link/schema';\n// ...\nconst client = new ApolloClient({\n  ssrMode: true,\n  // Instead of \"createHttpLink\" use SchemaLink here\n  link: new SchemaLink({ schema }),\n  cache: new InMemoryCache(),\n});\n```\nSkipping a query\nIf you want to intentionally skip a particular query during SSR, you can include `ssr: false` in that query's options. Typically, this means the component is rendered in its \"loading\" state on the server. For example:\n```jsx\nfunction withClientOnlyUser() {\n  useQuery(GET_USER_WITH_ID, { ssr: false });\n  return My query won't be run on the server;\n}",
    "tag": "apollo-client"
  },
  {
    "title": "How is data stored?",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/caching/overview.mdx",
    "content": "\ntitle: Caching in Apollo Client\ndescription: Overview\n\nApollo Client stores the results of your GraphQL queries in a local, normalized, in-memory cache. This enables Apollo Client to respond almost immediately to queries for already-cached data, without even sending a network request.\nFor example, the first time your app executes a `GetBook` query for a `Book` object with id `5`, the flow looks like this:\n`mermaid\nsequenceDiagram\n  Apollo Client->>InMemoryCache: GetBook(bookId: \"5\")\n  Note over InMemoryCache: Book:5 not found<br/>in cache\n  InMemoryCache->>GraphQL Server: Query sent to server\n  GraphQL Server->>InMemoryCache: Server responds<br/>with Book\n  Note over InMemoryCache: Book:5 is cached\n  InMemoryCache->>Apollo Client: Returns Book`\nAnd each later time your app executes `GetBook` for that same object, the flow looks like this instead:\n`mermaid\nsequenceDiagram\n  Apollo Client->>InMemoryCache: GetBook(bookId: \"5\")\n  Note over InMemoryCache: Book:5 found<br/>in cache!\n  InMemoryCache->>Apollo Client: Returns Book\n  Note over GraphQL Server: (Server is never queried)`\nThe Apollo Client cache is highly configurable. You can customize its behavior for individual types and fields in your schema, and you can even use it to store and interact with local data that isn't fetched from your GraphQL server.\nHow is data stored?\nApollo Client's `InMemoryCache` stores data as a flat lookup table of objects that can reference each other. These objects correspond to the objects that are returned by your GraphQL queries. A single cached object might include fields returned by multiple queries, if those queries fetch different fields of the same object.\nThe cache is flat, but objects returned by a GraphQL query often aren't! In fact, their nesting can be arbitrarily deep. Take a look at this example query response:\n`json\n{\n  \"data\": {\n    \"person\": {\n      \"__typename\": \"Person\",\n      \"id\": \"cGVvcGxlOjE=\",\n      \"name\": \"Luke Skywalker\",\n      \"homeworld\": {\n        \"__typename\": \"Planet\",\n        \"id\": \"cGxhbmV0czox\",\n        \"name\": \"Tatooine\"\n      }\n    }\n  }\n}`\nThis response contains a `Person` object, which in turn contains a `Planet` object in its `homeworld` field.\nSo how does the `InMemoryCache` store nested data in a flat lookup table? Before storing this data, the cache needs to normalize it.\nData normalization\nWhenever the Apollo Client cache receives query response data, it does the following:\n1. Identify objects\nFirst, the cache identifies all of the distinct objects included in a query response. In the example above, there are two objects:\n\nA `Person` with `id` `cGVvcGxlOjE=`\nA `Planet` with `id` `cGxhbmV0czox`\n\n2. Generate cache IDs\nAfter identifying all objects, the cache generates a cache ID for each one. A cache ID uniquely identifies a particular object while it's in the `InMemoryCache`.\nBy default, an object's cache ID is the concatenation of the object's `__typename` and `id` (or `_id`) fields, separated by a colon (`:`).\nSo, the default cache IDs for the objects in the example above are:\n\n`Person:cGVvcGxlOjE=`\n`Planet:cGxhbmV0czox`\n\n\nYou can customize the cache ID format for a particular object type. See Customizing cache IDs.\n\nIf the cache can't generate a cache ID for a particular object (for example, if no `id` or `_id` field is present), that object is cached directly inside its parent object, and it must be referenced via the parent (this means the cache isn't always completely flat).\n3. Replace object fields with references\nNext, the cache takes each field that contains an object and replaces its value with a reference to the appropriate object.\nFor example, here's the `Person` object from the example above before reference replacement:\n`json {5-9}\n{\n  \"__typename\": \"Person\",\n  \"id\": \"cGVvcGxlOjE=\",\n  \"name\": \"Luke Skywalker\",\n  \"homeworld\": {\n    \"__typename\": \"Planet\",\n    \"id\": \"cGxhbmV0czox\",\n    \"name\": \"Tatooine\"\n  }\n}`\nAnd here's that same object after replacement:\n`json {5-7}\n{\n  \"__typename\": \"Person\",\n  \"id\": \"cGVvcGxlOjE=\",\n  \"name\": \"Luke Skywalker\",\n  \"homeworld\": {\n    \"__ref\": \"Planet:cGxhbmV0czox\"\n  }\n}`\nThe `homeworld` field now contains a reference to the appropriate normalized `Planet` object.\n\nThis replacement does not occur for a particular object if the previous step failed to generate a cache ID for that object. Instead, the original object remains.\n\nLater, if you query for another `Person` who has the same `homeworld`, that normalized `Person` object will contain a reference to the same cached object! Normalization can dramatically reduce data duplication, and it also helps your local data stay up to date with your server.\n4. Store normalized objects\nFinally, the resulting objects are all stored in the cache's flat lookup table.\nWhenever an incoming object has the same cache ID as an existing cached object, the fields of those objects are merged:\n\nIf the incoming object and the existing object share any fields, the incoming object overwrites the cached values for those fields.\nFields that appear in only the existing object or only the incoming object are preserved.\n\nNormalization constructs a partial copy of your graph on your client, in a format that's optimized for reading and updating as your app's state changes.\nVisualizing the cache\nTo help understand the structure of your cached data, we strongly recommend installing the Apollo Client Devtools.\nThis browser extension includes an inspector that enables you to view all of the normalized objects contained in your cache:\n\nExample\nLet's say we use Apollo Client to run the following query on the SWAPI demo API:\n`graphql\nquery {\n  allPeople(first:3) { # Return the first 3 items\n    people {\n      id\n      name\n      homeworld {\n        id\n        name\n      }\n    }\n  }\n}`\nThis query returns the following result of three `Person` objects, each with a corresponding `homeworld` (a `Planet` object):\n\n`json\n{\n  \"data\": {\n    \"allPeople\": {\n      \"people\": [\n        {\n          \"__typename\": \"Person\",\n          \"id\": \"cGVvcGxlOjE=\",\n          \"name\": \"Luke Skywalker\",\n          \"homeworld\": {\n            \"__typename\": \"Planet\",\n            \"id\": \"cGxhbmV0czox\",\n            \"name\": \"Tatooine\"\n          }\n        },\n        {\n          \"__typename\": \"Person\",\n          \"id\": \"cGVvcGxlOjI=\",\n          \"name\": \"C-3PO\",\n          \"homeworld\": {\n            \"__typename\": \"Planet\",\n            \"id\": \"cGxhbmV0czox\",\n            \"name\": \"Tatooine\"\n          }\n        },\n        {\n          \"__typename\": \"Person\",\n          \"id\": \"cGVvcGxlOjM=\",\n          \"name\": \"R2-D2\",\n          \"homeworld\": {\n            \"__typename\": \"Planet\",\n            \"id\": \"cGxhbmV0czo4\",\n            \"name\": \"Naboo\"\n          }\n        }\n      ]\n    }\n  }\n}`\n\n\nNotice that each object in the result includes a `__typename` field, even though our query string didn't include this field. That's because Apollo Client automatically queries for every object's `__typename`.\n\nAfter the result is cached, we can view the state of our cache in the Apollo Client Devtools:\n\nOur cache now contains five normalized objects (in addition to the `ROOT_QUERY` object): three `Person` objects and two `Planet` objects.\nWhy do we only have two `Planet` objects? Because two of the three returned `Person` objects have the same `homeworld`. By normalizing data like this, Apollo Client can cache a single copy of an object, and multiple other objects can include references to it (see the `__ref` field of the object in the screenshot above).\nNext steps\nNow that you have a basic understanding of how Apollo Client's cache works, learn more about how to configure it.",
    "tag": "apollo-client"
  },
  {
    "title": "Using GraphQL queries",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/caching/cache-interaction.mdx",
    "content": "\ntitle: Reading and writing data to the cache\nYou can read and write data directly to the Apollo Client cache, without communicating with your GraphQL server. You can interact with data that you previously fetched from your server, and with data that's only available locally.\nApollo Client supports multiple strategies for interacting with cached data:\n| Strategy | API | Description |\n|----------|-----|-------------|\n| Using GraphQL queries | `readQuery` / `writeQuery` / `updateQuery` | Use standard GraphQL queries for managing both remote and local data. |\n| Using GraphQL fragments | `readFragment` / `writeFragment` / `updateFragment` / `useFragment_experimental` | Access the fields of any cached object without composing an entire query to reach that object.  |\n| Directly modifying cached fields | `cache.modify` | Manipulate cached data without using GraphQL at all. |\nYou can use whichever combination of strategies and methods are most helpful for your use case.\n\nAll code samples below assume that you have initialized an instance of `ApolloClient` and that you have imported the `gql` function from `@apollo/client`. If you haven't, get started.\nIn a React component, you can access your instance of `ApolloClient` using ApolloProvider and the useApolloClient hook.\n\nUsing GraphQL queries\nYou can read and write cache data using GraphQL queries that are similar (or even identical) to queries that you execute on your server:\n`readQuery`\nThe `readQuery` method enables you to execute a GraphQL query directly on your cache, like so:\n```js {12-19}\nconst READ_TODO = gql`\n  query ReadTodo($id: ID!) {\n    todo(id: $id) {\n      id\n      text\n      completed\n    }\n  }\n`;\n// Fetch the cached to-do item with ID 5\nconst { todo } = client.readQuery({\n  query: READ_TODO,\n  // Provide any required variables in this object.\n  // Variables of mismatched types will return `null`.\n  variables: {\n    id: 5,\n  },\n});\n```\nIf your cache contains data for all of the query's fields, `readQuery` returns an object that matches the shape of the query:\n`js\n{\n  todo: {\n    __typename: 'Todo', // __typename is automatically included\n    id: 5,\n    text: 'Buy oranges \ud83c\udf4a',\n    completed: true\n  }\n}`\n\nApollo Client automatically queries for every object's `__typename` by default, even if you don't include this field in your query string.\n\nDo not modify the returned object directly. The same object might be returned to multiple components. To update cached data safely, see Combining reads and writes.\nIf the cache is missing data for any of the query's fields, `readQuery` returns `null`. It does not attempt to fetch data from your GraphQL server.\nThe query you provide `readQuery` can include fields that are not defined in your GraphQL server's schema (i.e., local-only fields).\n\nPrior to Apollo Client 3.3, `readQuery` threw a `MissingFieldError` exception to report missing fields. Beginning with Apollo Client 3.3, `readQuery` always returns `null` to indicate that fields are missing.\n\n`writeQuery`\nThe `writeQuery` method enables you to write data to your cache in a shape that matches a GraphQL query. It resembles `readQuery`, except that it requires a `data` option:\n`js\nclient.writeQuery({\n  query: gql`\n    query WriteTodo($id: Int!) {\n      todo(id: $id) {\n        id\n        text\n        completed\n      }\n    }`,\n  data: { // Contains the data to write\n    todo: {\n      __typename: 'Todo',\n      id: 5,\n      text: 'Buy grapes \ud83c\udf47',\n      completed: false\n    },\n  },\n  variables: {\n    id: 5\n  }\n});`\nThis example creates (or edits) a cached `Todo` object with ID `5`.\nNote the following about `writeQuery`:\n\nAny changes you make to cached data with `writeQuery` are not pushed to your GraphQL server. If you reload your environment, these changes disappear.\nThe shape of your query is not enforced by your GraphQL server's schema:\nThe query can include fields that are not present in your schema.\nYou can (but usually shouldn't) provide values for schema fields that are invalid according to your schema.\n\n\n\nEditing existing data\nIn the example above, if your cache already contains a `Todo` object with ID `5`, `writeQuery` overwrites the fields that are included in `data` (other fields are preserved):\n```js {6-7,17-18}\n// BEFORE\n{\n  'Todo:5': {\n    __typename: 'Todo',\n    id: 5,\n    text: 'Buy oranges \ud83c\udf4a',\n    completed: true,\n    dueDate: '2022-07-02'\n  }\n}\n// AFTER\n{\n  'Todo:5': {\n    __typename: 'Todo',\n    id: 5,\n    text: 'Buy grapes \ud83c\udf47',\n    completed: false,\n    dueDate: '2022-07-02'\n  }\n}\n```\n\nIf you include a field in `query` but don't include a value for it in `data`, the field's current cached value is preserved.\n\nUsing GraphQL fragments\nYou can read and write cache data using GraphQL fragments on any normalized cache object. This provides more \"random access\" to your cached data than `readQuery`/`writeQuery`, which require a complete valid query.\n`readFragment`\nThis example fetches the same data as the example for readQuery using `readFragment` instead:\n`js\nconst todo = client.readFragment({\n  id: 'Todo:5', // The value of the to-do item's cache ID\n  fragment: gql`\n    fragment MyTodo on Todo {\n      id\n      text\n      completed\n    }\n  `,\n});`\nUnlike `readQuery`, `readFragment` requires an `id` option. This option specifies the cache ID for the object in your cache. By default, cache IDs have the format `<__typename>:<id>` (which is why we provide `Todo:5` above). You can customize this ID.\nIn the example above, `readFragment` returns `null` in either of the following cases:\n\nThere is no cached `Todo` object with ID `5`.\nThere is a cached `Todo` object with ID `5`, but it's missing a value for either `text` or `completed`.\n\n\nPrior to Apollo Client 3.3, `readFragment` threw `MissingFieldError` exceptions to report missing fields, and returned `null` only when reading a fragment from a nonexistent ID. Beginning with Apollo Client 3.3, `readFragment` always returns `null` to indicate insufficient data (missing ID or missing fields), instead of throwing a `MissingFieldError`.\n\n`writeFragment`\nIn addition to reading \"random-access\" data from the Apollo Client cache with `readFragment`, you can write data to the cache with the `writeFragment` method.\n\nAny changes you make to cached data with `writeFragment` are not pushed to your GraphQL server. If you reload your environment, these changes will disappear.\n\nThe `writeFragment` method resembles `readFragment`, except it requires an additional `data` variable. For example, the following call to `writeFragment` updates the `completed` flag for a `Todo` object with an `id` of `5`:\n`js\nclient.writeFragment({\n  id: 'Todo:5',\n  fragment: gql`\n    fragment MyTodo on Todo {\n      completed\n    }\n  `,\n  data: {\n    completed: true,\n  },\n});`\nAll subscribers to the Apollo Client cache (including all active queries) see this change and update your application's UI accordingly.\n`useFragment_experimental`\n\n\u26a0\ufe0f The `useFragment_experimental` hook is currently at the preview stage in Apollo Client. If you have feedback on it, please let us know via GitHub issues.\n\nYou can read data for a given fragment directly from the cache using the `useFragment_experimental` hook. This hook returns an always-up-to-date view of whatever data the cache currently contains for a given fragment. See the API reference.\nCombining reads and writes\nYou can combine `readQuery` and `writeQuery` (or `readFragment` and `writeFragment`) to fetch currently cached data and make selective modifications to it. The following example creates a new `Todo` item and adds it to your cached to-do list. Remember, this addition is not sent to your remote server.\n\n```js\n// Query that fetches all existing to-do items\nconst query = gql`\n  query MyTodoAppQuery {\n    todos {\n      id\n      text\n      completed\n    }\n  }\n`;\n// Get the current to-do list\nconst data = client.readQuery({ query });\n// Create a new to-do item\nconst myNewTodo = {\n  id: '6',\n  text: 'Start using Apollo Client.',\n  completed: false,\n  __typename: 'Todo',\n};\n// Write back to the to-do list, appending the new item\nclient.writeQuery({\n  query,\n  data: {\n    todos: [...data.todos, myNewTodo],\n  },\n});\n```\n\nUsing `updateQuery` and `updateFragment`\n\nThese methods are available in Apollo Client 3.5 and later.\n\nAs a convenience, you can use `cache.updateQuery` or `cache.updateFragment` to combine reading and writing cached data with a single method call:\n```js {12-17}\n// Query to fetch all todo items\nconst query = gql`\n  query MyTodoAppQuery {\n    todos {\n      id\n      text\n      completed\n    }\n  }\n`;\n// Set all todos in the cache as completed\ncache.updateQuery({ query }, (data) => ({\n  todos: data.todos.map((todo) => ({ ...todo, completed: true }))\n}));\n```\nEach of these methods takes two parameters:\n\nThe same `options` parameter as its `read` method counterpart (which always includes a `query` or `fragment`)\nAn update function\n\nAfter either method fetches data from the cache, it calls its update function and passes it the cached `data`. The update function can then return a value to replace that `data` in the cache. In the example above, every cached `Todo` object has its `completed` field set to `true` (and other fields remain unchanged).\nPlease note that the replacement value has to be calculated in an immutable way. You can read more about immutable updates in the React documentation.\nIf the update function shouldn't make any changes to the cached data, it can return `undefined`.\nThe update function's return value is passed to either `writeQuery` or `writeFragment`, which modifies the cached data.\n\nSee the full API reference for cache.updateQuery and cache.updateFragment.\n\nUsing `cache.modify`\nThe `modify` method of `InMemoryCache` enables you to directly modify the values of individual cached fields, or even delete fields entirely.\n\nLike `writeQuery` and `writeFragment`, `modify` triggers a refresh of all active queries that depend on modified fields (unless you override this behavior by passing `broadcast: false`).\nUnlike `writeQuery` and `writeFragment`:\n`modify` circumvents any merge functions you've defined, which means that fields are always overwritten with exactly the values you specify.\n`modify` cannot write fields that do not already exist in the cache.\n\n\nWatched queries can control what happens when they're invalidated by updates to the cache, by passing options like `fetchPolicy` and `nextFetchPolicy` to client.watchQuery or the useQuery hook.\n\nParameters\nCanonically documented in the API reference, the `modify` method takes the following parameters:\n\nThe ID of a cached object to modify (which we recommend obtaining with cache.identify)\nA map of modifier functions to execute (one for each field to modify)\nOptional `broadcast` and `optimistic` boolean values to customize behavior\n\nA modifier function applies to a single field. It takes its associated field's current cached value as a parameter and returns whatever value should replace it.\nHere's an example call to `modify` that modifies a `name` field to convert its value to upper case:\n`js\ncache.modify({\n  id: cache.identify(myObject),\n  fields: {\n    name(cachedName) {\n      return cachedName.toUpperCase();\n    },\n  },\n  /* broadcast: false // Include this to prevent automatic query refresh */\n});`\n\nIf you don't provide a modifier function for a particular field, that field's cached value remains unchanged.\n\nValues vs. references\nWhen you define a modifier function for a field that contains a scalar, an enum, or a list of these base types, the modifier function is passed the exact existing value for the field. For example, if you define a modifier function for an object's `quantity` field that has current value `5`, your modifier function is passed the value `5`.\nHowever, when you define a modifier function for a field that contains an object type or a list of objects, those objects are represented as references. Each reference points to its corresponding object in the cache by its cache ID. If you return a different reference in your modifier function, you change which other cached object is contained in this field. You don't modify the original cached object's data.\nModifier function utilities\nA modifier function can optionally take a second parameter, which is an object that contains several helpful utilities.\nSome of these utilities (namely, the `readField` function and the `DELETE` sentinel object) are used in the examples below. For descriptions of all available utilities, see the API reference.\nExamples\nExample: Removing an item from a list\nLet's say we have a blog application where each `Post` has an array of `Comment`s. Here's how we might remove a specific `Comment` from a paginated `Post.comments` array:\n```js\nconst idToRemove = 'abc123';\ncache.modify({\n  id: cache.identify(myPost),\n  fields: {\n    comments(existingCommentRefs, { readField }) {\n      return existingCommentRefs.filter(\n        commentRef => idToRemove !== readField('id', commentRef)\n      );\n    },\n  },\n});\n```\nLet's break this down:\n\n\nIn the `id` field, we use cache.identify to obtain the cache ID of the cached `Post` object we want to remove a comment from.\n\n\nIn the `fields` field, we provide an object that lists our modifier functions. In this case, we define a single modifier function (for the `comments` field).\n\n\nThe `comments` modifier function takes our existing cached array of comments as a parameter (`existingCommentRefs`). It also uses the `readField` utility function, which helps you read the value of any cached field.\n\n\nThe modifier function returns an array that filters out all comments with an ID that matches `idToRemove`. The returned array replaces the existing array in the cache.\n\n\nExample: Adding an item to a list\nNow let's look at adding a `Comment` to a `Post`:\n```js\nconst newComment = {\n  __typename: 'Comment',\n  id: 'abc123',\n  text: 'Great blog post!',\n};\ncache.modify({\n  id: cache.identify(myPost),\n  fields: {\n    comments(existingCommentRefs = [], { readField }) {\n      const newCommentRef = cache.writeFragment({\n        data: newComment,\n        fragment: gql`fragment NewComment on Comment {\n            id\n            text\n          }`\n      });\n\n\n```  // Quick safety check - if the new comment is already\n  // present in the cache, we don't need to add it again.\n  if (existingCommentRefs.some(\n    ref => readField('id', ref) === newComment.id\n  )) {\n    return existingCommentRefs;\n  }\n\n  return [...existingCommentRefs, newCommentRef];\n}\n```\n\n\n}\n});\n```\nWhen the `comments` field modifier function is called, it first calls `writeFragment` to store our `newComment` data in the cache. The `writeFragment` function returns a reference (`newCommentRef`) that points to the newly cached comment.\nAs a safety check, we then scan the array of existing comment references (`existingCommentRefs`) to make sure that our new isn't already in the list. If it isn't, we add the new comment reference to the list of references, returning the full list to be stored in the cache.\nExample: Updating the cache after a mutation\nIf you call `writeFragment` with an `options.data` object that the cache is able to identify ( based on its `__typename` and cache ID fields), you can avoid passing `options.id` to `writeFragment`.\nWhether you provide `options.id` explicitly or let `writeFragment` figure it out using `options.data`, `writeFragment` returns a `Reference` to the identified object.\nThis behavior makes `writeFragment` a good tool for obtaining a `Reference` to an existing object in the cache, which can come in handy when writing an `update` function for useMutation:\nFor example:\n`js\nconst [addComment] = useMutation(ADD_COMMENT, {\n  update(cache, { data: { addComment } }) {\n    cache.modify({\n      id: cache.identify(myPost),\n      fields: {\n        comments(existingCommentRefs = [], { readField }) {\n          const newCommentRef = cache.writeFragment({\n            data: addComment,\n            fragment: gql`\n              fragment NewComment on Comment {\n                id\n                text\n              }\n            `\n          });\n          return [...existingCommentRefs, newCommentRef];\n        }\n      }\n    });\n  }\n});`\nIn this example, `useMutation` automatically creates a `Comment` and adds it to the cache, but it doesn't automatically know how to add that `Comment` to the corresponding `Post`'s list of `comments`. This means that any queries watching the `Post`'s list of `comments` won't update.\nTo address this, we use the update callback of `useMutation` to call `cache.modify`. Like the previous example, we add the new comment to the list. Unlike the previous example, the comment was already added to the cache by `useMutation`. Consequently, `cache.writeFragment` returns a reference to the existing object.\nExample: Deleting a field from a cached object\nA modifier function's optional second parameter is an object that includes several helpful utilities, such as the `canRead` and `isReference` functions. It also includes a sentinel object called `DELETE`.\nTo delete a field from a particular cached object, return the `DELETE` sentinel object from the field's modifier function, like so:\n`js\ncache.modify({\n  id: cache.identify(myPost),\n  fields: {\n    comments(existingCommentRefs, { DELETE }) {\n      return DELETE;\n    },\n  },\n});`\nExample: Invalidating fields within a cached object\nNormally, changing or deleting a field's value also invalidates the field, causing watched queries to be reread if they previously consumed the field.\nUsing `cache.modify`, it's also possible to invalidate the field without changing or deleting its value, by returning the `INVALIDATE` sentinel:\n`js\ncache.modify({\n  id: cache.identify(myPost),\n  fields: {\n    comments(existingCommentRefs, { INVALIDATE }) {\n      return INVALIDATE;\n    },\n  },\n});`\nIf you need to invalidate all fields within a given object, you can pass a modifier function as the value of the `fields` option:\n`js\ncache.modify({\n  id: cache.identify(myPost),\n  fields(fieldValue, details) {\n    return details.INVALIDATE;\n  },\n});`\nWhen using this form of `cache.modify`, you can determine individual field names using `details.fieldName`. This technique works for any modifier function, not just those that return `INVALIDATE`.\nObtaining an object's cache ID\nIf a type in your cache uses a custom cache ID (or even if it doesn't), you can use the `cache.identify` method to obtain the cache ID for an object of that type. This method takes an object and computes its ID based on both its `__typename` and its identifier field(s). This means you don't have to keep track of which fields make up each type's cache ID.\nExample\nLet's say we have a JavaScript representation of a cached GraphQL object, like this:\n`js {3}\nconst invisibleManBook = {\n  __typename: 'Book',\n  isbn: '9780679601395', // The key field for this type's cache ID\n  title: 'Invisible Man',\n  author: {\n    __typename: 'Author',\n    name: 'Ralph Ellison',\n  },\n};`\nIf we want to interact with this object in our cache with methods like writeFragment or cache.modify, we need the object's cache ID. Our `Book` type's cache ID appears to be custom, because the `id` field isn't present.\nInstead of needing to look up that our `Book` type uses the `isbn` field for its cache ID, we can use the `cache.identify` method, like so:\n```js {8}\nconst bookYearFragment = gql`\n  fragment BookYear on Book {\n    publicationYear\n  }\n`;\nconst fragmentResult = cache.writeFragment({\n  id: cache.identify(invisibleManBook),\n  fragment: bookYearFragment,\n  data: {\n    publicationYear: '1952'\n  }\n});\n```\nThe cache knows that the `Book` type uses the `isbn` field for its cache ID, so `cache.identify` can correctly populate the `id` field above.",
    "tag": "apollo-client"
  },
  {
    "title": "`cache.gc()`",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/caching/garbage-collection.mdx",
    "content": "\ntitle: Garbage collection and cache eviction\nApollo Client 3 enables you to selectively remove cached data that is no longer useful. The default garbage collection strategy of the `gc` method is suitable for most applications, but the `evict` method provides more fine-grained control for applications that require it.\n\nYou call these methods directly on the `InMemoryCache` object, not on the `ApolloClient` object.\n\n`cache.gc()`\nThe `gc` method removes all objects from the normalized cache that are not reachable:\n`js\ncache.gc();`\nTo determine whether an object is reachable, the cache starts from all known root objects (usually `Query` and/or `Mutation`) and uses a tracing strategy to recursively visit all available child references. Any normalized objects that are not visited during this process are removed. The `cache.gc()` method returns a list of the IDs of the removed objects.\nIn addition to pruning your GraphQL data, `cache.gc` can also release memory that the cache uses to preserve unchanged parts of previous cache results:\n`js\ncache.gc({ resetResultCache: true })`\nFreeing this memory temporarily slows down cache reads, because those reads don't benefit from any previous reading work.\nIf you're using the canonizeResults: true option, `cache.gc` can also reset the memory used for looking up canonical result objects:\n`js\ncache.gc({\n  resetResultCache: true,\n  resetResultIdentities: true,\n})`\nThese additional `cache.gc` options can be useful for investigating memory usage patterns or leaks. Before taking heap snapshots or recording allocation timelines, it's a good idea to force JavaScript garbage collection using your browser's devtools, to ensure memory released by the cache has been fully collected and returned to the heap.\nConfiguring garbage collection\nYou can use the `retain` method to prevent an object (and its children) from being garbage collected, even if the object isn't reachable:\n`js\ncache.retain('my-object-id');`\nIf you later want a `retain`ed object to be garbage collected, use the `release` method:\n`js\ncache.release('my-object-id');`\nIf the object is unreachable, it will be garbage collected during next call to `gc`.\n`cache.evict()`\nYou can remove any normalized object from the cache using the `evict` method:\n`js\ncache.evict({ id: 'my-object-id' })`\nYou can also remove a single field from a cached object by providing the name of the field to remove:\n`js\ncache.evict({ id: 'my-object-id', fieldName: 'yearOfFounding' });`\nEvicting an object often makes other cached objects unreachable. Because of this, you should call cache.gc after `evict`ing one or more objects from the cache.\nDangling references\nWhen an object is `evict`ed from the cache, references to that object might remain in other cached objects. Apollo Client preserves these dangling references by default, because the referenced object might be written back to the cache at a later time. This means the reference might still be useful.\nYou can customize behavior for dangling references by defining a custom read function for any field that might contain one. This function can perform whatever cleanup is necessary when the field's referenced object is missing. For example, the `read` function might:\n\nFilter the referenced object out of a list of available objects\nSet the field's value to `null`\nReturn a particular default value\n\nEvery `read` function is passed a `canRead` function that helps it detect when its field currently contains a dangling reference.\nThe following code defines two `read` functions (one for `Query.ruler` and one for `Deity.offspring`) that both use `canRead`:\n```js\nnew InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        ruler(existingRuler, { canRead, toReference }) {\n          // If there is no existing ruler, Apollo becomes the ruling deity\n          return canRead(existingRuler) ? existingRuler : toReference({\n            __typename: \"Deity\",\n            name: \"Apollo\",\n          });\n        },\n      },\n    },\n\n\n```Deity: {\n  keyFields: [\"name\"],\n  fields: {\n    offspring(existingOffspring: Reference[], { canRead }) {\n      // Filter out any dangling references left over from removing\n      // offspring, supplying a default empty array if there are no\n      // offspring left.\n      return existingOffspring\n        ? existingOffspring.filter(canRead)\n        : [];\n    },\n  },\n},\n```\n\n\n},\n})\n```\n\nThe `read` function for `Query.ruler` returns a default ruler (`Apollo`) if the `existingRuler` has been deposed.\nThe `read` function for `Deity.offspring` filters its array to return only offspring that are alive and well in the cache.\n\nFiltering dangling references out of a cached list field (like the `Deity.offspring` example above) is so common that the default `read` function for a list field performs this filtering automatically. You can define a custom `read` function to override this behavior.",
    "tag": "apollo-client"
  },
  {
    "title": "The `read` function",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/caching/cache-field-behavior.mdx",
    "content": "\ntitle: Customizing the behavior of cached fields\nYou can customize how a particular field in your Apollo Client cache is read and written. To do so, you define a field policy for the field. A field policy can include:\n\nA read function that specifies what happens when the field's cached value is read\nA merge function that specifies what happens when field's cached value is written\nAn array of key arguments that help the cache avoid storing unnecessary duplicate data.\n\nYou provide field policies to the constructor of `InMemoryCache`. Each field policy is defined inside whichever TypePolicy object  corresponds to the field's parent type.\nThe following example defines a field policy for the `name` field of a `Person` type:\n`ts {5-10}\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Person: {\n      fields: {\n        name: {\n          read(name) {\n            // Return the cached name, transformed to upper case\n            return name.toUpperCase();\n          }\n        }\n      },\n    },\n  },\n});`\nThis field policy defines a read function that specifies what the cache returns whenever `Person.name` is queried.\nThe `read` function\nIf you define a `read` function for a field, the cache calls that function whenever your client queries for the field. In the query response, the field is populated with the `read` function's return value, instead of the field's cached value.\nEvery `read` function is passed two parameters:\n\n\nThe first parameter is the field's currently cached value (if one exists). You can use this to help calculate the value to return.\n\n\nThe second parameter is an object that provides access to several properties and helper functions, including any arguments passed to the field.\n\nSee the fields of the `FieldFunctionOptions` type in FieldPolicy API reference.\n\n\n\nThe following `read` function returns a default value of `UNKNOWN NAME` for the `name` field of a `Person` type whenever a value isn't available in the cache. If a cached value is available, it's returned unmodified.\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Person: {\n      fields: {\n        name: {\n          // highlight-start\n          read(name = \"UNKNOWN NAME\") {\n            return name;\n          }\n          // highlight-end\n        },\n      },\n    },\n  },\n});`\nHandling field arguments\nIf a field accepts arguments, the `read` function's second parameter includes an `args` object that contains the values provided for those arguments.\nFor example, the following `read` function checks whether the `maxLength` argument was provided for the `name` field. If it was provided, the function returns only the first `maxLength` characters of the person's name. Otherwise, the person's full name is returned.\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Person: {\n      fields: {\n        // If a field's TypePolicy would only include a read function,\n        // you can optionally define the function like so, instead of\n        // nesting it inside an object as shown in the previous example.\n        name(name: string, { args }) {\n          if (args && typeof args.maxLength === \"number\") {\n            return name.substring(0, args.maxLength);\n          }\n          return name;\n        },\n      },\n    },\n  },\n});`\nIf a field requires numerous parameters then each parameter must be wrapped in a variable that is then destructured and returned.\nEach parameter will be available as individual subfields.\nThe following `read` function assigns a default value of `UNKNOWN FIRST NAME` to the `firstName` subfield of a `fullName` field and a `UNKNOWN LAST NAME` to the `lastName` of a `fullName` field.\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Person: {\n      fields: {\n        fullName: {\n          read(fullName = {\n            firstName: \"UNKNOWN FIRST NAME\",\n            lastName: \"UNKNOWN LAST NAME\",\n          }) {\n            return { ...fullName };\n          },\n        },\n      },\n    },\n  },\n});`\nThe following `query` returns the `firstName` and `lastName` subfields from the `fullName` field:\n`graphql\nquery personWithFullName {\n  fullName {\n    firstName\n    lastName\n  }\n}`\nYou can define a `read` function for a field that isn't even defined in your schema. For example, the following `read` function enables you to query a `userId` field that is always populated with locally stored data:\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Person: {\n      fields: {\n        userId() {\n          return localStorage.getItem(\"loggedInUserId\");\n        },\n      },\n    },\n  },\n});`\n\nNote that to query for a field that is only defined locally, your query should include the @client directive on that field so that Apollo Client doesn't include it in requests to your GraphQL server.\n\nOther use cases for a `read` function include:\n\nTransforming cached data to suit your client's needs, such as rounding floating-point values to the nearest integer\nDeriving local-only fields from one or more schema fields on the same object (such as deriving an `age` field from a `birthDate` field)\nDeriving local-only fields from one or more schema fields across multiple objects\n\nFor a full list of the options provided to the `read` function, see the API reference. You will almost never need to use all of these options, but each one has an important role when reading fields from the cache.\nThe `merge` function\nIf you define a `merge` function for a field, the cache calls that function whenever the field is about to be written with an incoming value (such as from your GraphQL server). When the write occurs, the field's new value is set to the `merge` function's return value, instead of the original incoming value.\nMerging arrays\nA common use case for a `merge` function is to define how to write to a field that holds an array. By default, the field's existing array is completely replaced by the incoming array. In many cases, it's preferable to concatenate the two arrays instead, like so:\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Agenda: {\n      fields: {\n        tasks: {\n          merge(existing = [], incoming: any[]) {\n            return [...existing, ...incoming];\n          },\n        },\n      },\n    },\n  },\n});`\n\nThis pattern is especially common when working with paginated lists.\n\nNote that `existing` is undefined the very first time this function is called for a given instance of the field, because the cache does not yet contain any data for the field. Providing the `existing = []` default parameter is a convenient way to handle this case.\n\nYour `merge` function cannot push the `incoming` array directly onto the `existing` array. It must instead return a new array to prevent potential errors. In development mode, Apollo Client prevents unintended modification of the `existing` data with `Object.freeze`.\n\nMerging non-normalized objects\nYou can use a `merge` function to intelligently combine nested objects that are not normalized in your cache, assuming those objects are nested within the same normalized parent.\n\n`ts {6-8}\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Book: {\n      fields: {\n        author: { // Non-normalized Author object within Book\n          merge(existing, incoming, { mergeObjects }) {\n            return mergeObjects(existing, incoming);\n          },\n        },\n      },\n    },\n  },\n});`\n\nExample\nLet's say our graph's schema includes the following types:\n```graphql\ntype Book {\n  id: ID!\n  title: String!\n  author: Author!\n}\ntype Author { # Has no key fields\n  name: String!\n  dateOfBirth: String!\n}\ntype Query {\n  favoriteBook: Book!\n}\n```\nWith this schema, our cache can normalize `Book` objects because they have an `id` field. However, `Author` objects have no `id` field, and they also have no other fields that can uniquely identify a particular instance. Therefore, the cache can't normalize `Author` objects, and it can't tell when two different `Author` objects actually represent the same author.\nNow, let's say our client executes the following two queries, in order:\n```graphql {5,14}\nquery BookWithAuthorName {\n  favoriteBook {\n    id\n    author {\n      name\n    }\n  }\n}\nquery BookWithAuthorBirthdate {\n  favoriteBook {\n    id\n    author {\n      dateOfBirth\n    }\n  }\n}\n```\nWhen the first query returns, Apollo Client writes a `Book` object like the following to the cache:\n`json\n{\n  \"__typename\": \"Book\",\n  \"id\": \"abc123\",\n  \"author\": {\n    \"__typename\": \"Author\",\n    \"name\": \"George Eliot\"\n  }\n}`\n\nRemember that because `Author` objects can't be normalized, they're nested directly within their parent object.\n\nNow, when the second query returns, the cached `Book` object is updated to the following:\n`json {6}\n{\n  \"__typename\": \"Book\",\n  \"id\": \"abc123\",\n  \"author\": {\n    \"__typename\": \"Author\",\n    \"dateOfBirth\": \"1819-11-22\"\n  }\n}`\nThe `Author`'s `name` field has been removed! This is because Apollo Client can't be sure that the `Author` objects returned by the two queries actually refer to the same author. So instead of merging fields of the two objects, Apollo Client completely overwrites the object (and logs a warning).\nHowever, we are confident that these two objects represent the same author, because a book's author virtually never changes. Therefore, we can tell the cache to treat `Book.author` objects as the same object as long as they belong to the same `Book`. This enables the cache to merge the `name` and `dateOfBirth` fields returned by different queries above.\nTo achieve this, we can define a custom `merge` function for the `author` field within the type policy for `Book`:\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Book: {\n      fields: {\n        author: {\n          merge(existing, incoming, { mergeObjects }) {\n            return mergeObjects(existing, incoming);\n          },\n        },\n      },\n    },\n  },\n});`\nHere, we use the `mergeObjects` helper function to merge values from the `existing` and `incoming` `Author` objects. It's important to use `mergeObjects` here instead of merging the objects with object spread syntax, because `mergeObjects` makes sure to call any defined `merge` functions for subfields of `Book.author`.\nNotice that this `merge` function has zero `Book`- or `Author`-specific logic in it! This means you can reuse it for any number of non-normalized object fields. And because this exact `merge` function definition is so common, you can also define it with the following shorthand:\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Book: {\n      fields: {\n        author: {\n          // Equivalent to options.mergeObjects(existing, incoming).\n          merge: true,\n        },\n      },\n    },\n  },\n});`\nIn summary, the `Book.author` policy above enables the cache to intelligently merge all of the `author` objects associated with any particular normalized `Book` object.\n\nRemember that for `merge: true` to merge two non-normalized objects, all of the following must be true:\n\nThe two objects must occupy the exact same field of the exact same normalized object in the cache.\nThe two objects must have the same `__typename`.\nThis is important for fields with an interface or union return type, which might return one of multiple object types.\n\n\n\nIf you require behavior that violates any of these rules, you need to write a custom `merge` function instead of using `merge: true`.\n\nMerging arrays of non-normalized objects\n\nMake sure you've read Merging arrays and Merging non-normalized objects first.\n\nConsider what happens if a `Book` can have multiple `authors`:\n```graphql\nquery BookWithAuthorNames {\n  favoriteBook {\n    isbn\n    title\n    authors {\n      name\n    }\n  }\n}\nquery BookWithAuthorLanguages {\n  favoriteBook {\n    isbn\n    title\n    authors {\n      language\n    }\n  }\n}\n```\nThe `favoriteBook.authors` field contains a list of non-normalized `Author` objects. In this case, we need to define a more sophisticated `merge` function to make sure the `name` and `language` fields returned by the two queries above are correctly associated with each other.\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Book: {\n      fields: {\n        authors: {\n          merge(existing: any[], incoming: any[], { readField, mergeObjects }) {\n            const merged: any[] = existing ? existing.slice(0) : [];\n            const authorNameToIndex: Record<string, number> = Object.create(null);\n            if (existing) {\n              existing.forEach((author, index) => {\n                authorNameToIndex[readField<string>(\"name\", author)] = index;\n              });\n            }\n            incoming.forEach(author => {\n              const name = readField<string>(\"name\", author);\n              const index = authorNameToIndex[name];\n              if (typeof index === \"number\") {\n                // Merge the new author data with the existing author data.\n                merged[index] = mergeObjects(merged[index], author);\n              } else {\n                // First time we've seen this author in this array.\n                authorNameToIndex[name] = merged.length;\n                merged.push(author);\n              }\n            });\n            return merged;\n          },\n        },\n      },\n    },\n  },\n});`\nInstead of replacing the existing `authors` array with the incoming array, this code concatenates the arrays together, while also checking for duplicate author names. Whenever a duplicate name is found, the fields of the repeated `Author` objects are merged.\nThe `readField` helper function is more robust than using `author.name` directly, because it tolerates the possibility that the `author` is a `Reference` object referring to data elsewhere in the cache. This is important if the `Author` type eventually defines `keyFields` and therefore becomes normalized.\nAs this example suggests, `merge` functions can become quite sophisticated. When this happens, you can often extract the generic logic into a reusable helper function:\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Book: {\n      fields: {\n        authors: {\n          merge: mergeArrayByField<AuthorType>(\"name\"),\n        },\n      },\n    },\n  },\n});`\nNow that you've hidden the details behind a reusable abstraction, it no longer matters how complicated the implementation gets. This is liberating, because it allows you to improve your client-side business logic over time, while keeping related logic consistent across your entire application.\nDefining a `merge` function at the type level\nIn Apollo Client 3.3 and later, you can define a default `merge` function for a non-normalized object type. If you do, every field that returns that type uses your default `merge` function unless it's overridden on a field-by-field basis.\nYou define this default `merge` function in the type policy for the non-normalized type. Here's what that looks like for the non-normalized `Author` type from Merging non-normalized objects:\n```ts {13}\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Book: {\n      fields: {\n        // No longer required!\n        // author: {\n        //   merge: true,\n        // },\n      },\n    },\n\n\n```Author: {\n  merge: true,\n},\n```\n\n\n},\n});\n```\nAs shown above, the field-level `merge` function for `Book.author` is no longer required. The net result in this basic example is identical, but this strategy automatically applies the default `merge` function to any other `Author`-returning fields you might add in the future (such as `Essay.author`).\nHandling pagination\nWhen a field holds an array, it's often useful to paginate that array's results, because the total result set can be arbitrarily large.\nTypically, a query includes pagination arguments that specify:\n\nWhere to start in the array, using either a numeric offset or a starting ID\nThe maximum number of elements to return in a single \"page\"\n\nIf you implement pagination for a field, it's important to keep pagination arguments in mind if you then implement `read` and `merge` functions for the field:\n```ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Agenda: {\n      fields: {\n        tasks: {\n          merge(existing: any[], incoming: any[], { args }) {\n            const merged = existing ? existing.slice(0) : [];\n            // Insert the incoming elements in the right places, according to args.\n            const end = args.offset + Math.min(args.limit, incoming.length);\n            for (let i = args.offset; i < end; ++i) {\n              merged[i] = incoming[i - args.offset];\n            }\n            return merged;\n          },\n\n\n```      read(existing: any[], { args }) {\n        // If we read the field before any data has been written to the\n        // cache, this function will return undefined, which correctly\n        // indicates that the field is missing.\n        const page = existing && existing.slice(\n          args.offset,\n          args.offset + args.limit,\n        );\n        // If we ask for a page outside the bounds of the existing array,\n        // page.length will be 0, and we should return undefined instead of\n        // the empty array.\n        if (page && page.length > 0) {\n          return page;\n        }\n      },\n    },\n  },\n},\n```\n\n\n},\n});\n```\nAs this example shows, your `read` function often needs to cooperate with your `merge` function, by handling the same arguments in the inverse direction.\nIf you want a given \"page\" to start after a specific entity ID instead of starting from `args.offset`, you can implement your `merge` and `read` functions as follows, using the `readField` helper function to examine existing task IDs:\n```ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Agenda: {\n      fields: {\n        tasks: {\n          merge(existing: any[], incoming: any[], { args, readField }) {\n            const merged = existing ? existing.slice(0) : [];\n            // Obtain a Set of all existing task IDs.\n            const existingIdSet = new Set(\n              merged.map(task => readField(\"id\", task)));\n            // Remove incoming tasks already present in the existing data.\n            incoming = incoming.filter(\n              task => !existingIdSet.has(readField(\"id\", task)));\n            // Find the index of the task just before the incoming page of tasks.\n            const afterIndex = merged.findIndex(\n              task => args.afterId === readField(\"id\", task));\n            if (afterIndex >= 0) {\n              // If we found afterIndex, insert incoming after that index.\n              merged.splice(afterIndex + 1, 0, ...incoming);\n            } else {\n              // Otherwise insert incoming at the end of the existing data.\n              merged.push(...incoming);\n            }\n            return merged;\n          },\n\n\n```      read(existing: any[], { args, readField }) {\n        if (existing) {\n          const afterIndex = existing.findIndex(\n            task => args.afterId === readField(\"id\", task));\n          if (afterIndex >= 0) {\n            const page = existing.slice(\n              afterIndex + 1,\n              afterIndex + 1 + args.limit,\n            );\n            if (page && page.length > 0) {\n              return page;\n            }\n          }\n        }\n      },\n    },\n  },\n},\n```\n\n\n},\n});\n```\nNote that if you call `readField(fieldName)`, it returns the value of the specified field from the current object. If you pass an object as a second argument to `readField`, (e.g., `readField(\"id\", task)`), `readField` instead reads the specified field from the specified object. In the above example, reading the `id` field from existing `Task` objects allows us to deduplicate the `incoming` task data.\nThe pagination code above is complicated, but after you implement your preferred pagination strategy, you can reuse it for every field that uses that strategy, regardless of the field's type. For example:\n```ts\nfunction afterIdLimitPaginatedFieldPolicy() {\n  return {\n    merge(existing: T[], incoming: T[], { args, readField }): T[] {\n      ...\n    },\n    read(existing: T[], { args, readField }): T[] {\n      ...\n    },\n  };\n}\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Agenda: {\n      fields: {\n        tasks: afterIdLimitPaginatedFieldPolicy(),\n      },\n    },\n  },\n});\n```\nDisabling `merge` functions\nIn some cases, you might want to completely disable merge functions for certain fields. To do so, pass `merge: false` like so:\n```ts {13}\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Book: {\n      fields: {\n        // No longer necessary!\n        // author: {\n        //   merge: true,\n        // },\n      },\n    },\n\n\n```Author: {\n  merge: false,\n},\n```\n\n\n},\n});\n```\nSpecifying key arguments\nIf a field accepts arguments, you can specify an array of `keyArgs` in the field's `FieldPolicy`. This array indicates which arguments are key arguments that affect the field's return value. Specifying this array can help reduce the amount of duplicate data in your cache.\nExample\nLet's say your schema's `Query` type includes a `monthForNumber` field. This field returns the details of particular month, given a provided `number` argument (January for `1` and so on). The `number` argument is a key argument for this field, because its value affects the field's return value:\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Query: {\n      fields: {\n        monthForNumber: {\n          keyArgs: [\"number\"],\n        },\n      },\n    },\n  },\n});`\nAn example of a non-key argument is an access token, which is used to authorize a query but not to calculate its result. If `monthForNumber` also accepts an `accessToken` argument, the value of that argument does not affect which month's details are returned.\nBy default, all of a field's arguments are key arguments. This means that the cache stores a separate value for every unique combination of argument values you provide when querying a particular field.\nIf you specify a field's key arguments, the cache understands that the rest of that field's arguments aren't key arguments. This means that the cache doesn't need to store a completely separate value when a non-key argument changes.\nFor example, let's say you execute two different queries with the `monthForNumber` field, passing the same `number` argument but different `accessToken` arguments. In this case, the second query response will overwrite the first, because both invocations use an identical value for the only key argument.\nProviding a `keyArgs` function\nIf you need more control over a particular field's `keyArgs`, you can pass a function instead of an array of argument names. This `keyArgs` function takes two parameters:\n\nAn `args` object containing all argument values provided for the field\nA `context` object providing other relevant details\n\nFor details, see `KeyArgsFunction` in the API reference below.\n`FieldPolicy` API reference\nHere are the definitions for the `FieldPolicy` type and its related types:\n```ts\n// These generic type parameters will be inferred from the provided policy in\n// most cases, though you can use this type to constrain them more precisely.\ntype FieldPolicy<\n  TExisting,\n  TIncoming = TExisting,\n  TReadResult = TExisting,\n\n= {\n  keyArgs?: KeySpecifier | KeyArgsFunction | false;\n  read?: FieldReadFunction;\n  merge?: FieldMergeFunction | boolean;\n};\n\ntype KeySpecifier = (string | KeySpecifier)[];\ntype KeyArgsFunction = (\n  args: Record | null,\n  context: {\n    typename: string;\n    fieldName: string;\n    field: FieldNode | null;\n    variables?: Record;\n  },\n) => string | KeySpecifier | null | void;\ntype FieldReadFunction = (\n  existing: Readonly | undefined,\n  options: FieldFunctionOptions,\n) => TReadResult;\ntype FieldMergeFunction = (\n  existing: Readonly | undefined,\n  incoming: Readonly,\n  options: FieldFunctionOptions,\n) => TExisting;\n// These options are common to both read and merge functions:\ninterface FieldFunctionOptions {\n  cache: InMemoryCache;\n// The final argument values passed to the field, after applying variables.\n  // If no arguments were provided, this property will be null.\n  args: Record | null;\n// The name of the field, equal to options.field.name.value when\n  // options.field is available. Useful if you reuse the same function for\n  // multiple fields, and you need to know which field you're currently\n  // processing. Always a string, even when options.field is null.\n  fieldName: string;\n// The FieldNode object used to read this field. Useful if you need to\n  // know about other attributes of the field, such as its directives. This\n  // option will be null when a string was passed to options.readField.\n  field: FieldNode | null;\n// The variables that were provided when reading the query that contained\n  // this field. Possibly undefined, if no variables were provided.\n  variables?: Record;\n// Easily detect { __ref: string } reference objects.\n  isReference(obj: any): obj is Reference;\n// Returns a Reference object if obj can be identified, which requires,\n  // at minimum, a __typename and any necessary key fields. If true is\n  // passed for the optional mergeIntoStore argument, the object's fields\n  // will also be persisted into the cache, which can be useful to ensure\n  // the Reference actually refers to data stored in the cache. If you\n  // pass an ID string, toReference will make a Reference out of it. If\n  // you pass a Reference, toReference will return it as-is.\n  toReference(\n    objOrIdOrRef: StoreObject | string | Reference,\n    mergeIntoStore?: boolean,\n  ): Reference | undefined;\n// Helper function for reading other fields within the current object.\n  // If a foreign object or reference is provided, the field will be read\n  // from that object instead of the current object, so this function can\n  // be used (together with isReference) to examine the cache outside the\n  // current object. If a FieldNode is passed instead of a string, and\n  // that FieldNode has arguments, the same options.variables will be used\n  // to compute the argument values. Note that this function will invoke\n  // custom read functions for other fields, if defined. Always returns\n  // immutable data (enforced with Object.freeze in development).\n  readField(\n    nameOrField: string | FieldNode,\n    foreignObjOrRef?: StoreObject | Reference,\n  ): T;\n// Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  canRead(value: StoreValue): boolean;\n// A handy place to put field-specific data that you want to survive\n  // across multiple read function calls. Useful for field-level caching,\n  // if your read function does any expensive work.\n  storage: Record;\n// Instead of just merging objects with { ...existing, ...incoming }, this\n  // helper function can be used to merge objects in a way that respects any\n  // custom merge functions defined for their fields.\n  mergeObjects(\n    existing: T,\n    incoming: T,\n  ): T | undefined;\n}",
    "tag": "apollo-client"
  },
  {
    "title": "Bypassing the cache",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/caching/advanced-topics.mdx",
    "content": "\ntitle: Advanced topics on caching in Apollo Client\nThis article describes special cases and considerations when using the Apollo Client cache.\nBypassing the cache\nSometimes you shouldn't use the cache for a particular GraphQL operation. For example, a query's response might be a token that's only used once. In cases like this, use the no-cache fetch policy:\n`js\nconst { loading, error, data } = useQuery(GET_DOGS, {\n  fetchPolicy: \"no-cache\" // highlight-line\n});`\nOperations that use this fetch policy don't write their result to the cache, and they also don't check the cache for data before sending a request to your server. See all available fetch policies.\nPersisting the cache\nYou can persist and rehydrate the `InMemoryCache` from a storage provider like `AsyncStorage` or `localStorage`. To do so, use the apollo3-cache-persist library. This library works with a variety of storage providers.\nTo get started, pass your cache and a storage provider to `persistCache`. By default, the contents of your cache are immediately restored asynchronously, and they're persisted on every write to the cache with a short configurable debounce interval.\n\nNote: The `persistCache` method is async and returns a `Promise`.\n\n```js\nimport { AsyncStorage } from 'react-native';\nimport { InMemoryCache } from '@apollo/client';\nimport { persistCache } from 'apollo3-cache-persist';\nconst cache = new InMemoryCache();\npersistCache({\n  cache,\n  storage: AsyncStorage,\n}).then(() => {\n  // Continue setting up Apollo Client as usual.\n})\n```\nFor advanced usage and additional configuration options, see the README of apollo3-cache-persist.\nResetting the cache\nSometimes, you might want to reset the cache entirely, such as when a user logs out. To accomplish this, call `client.resetStore`. This method is asynchronous, because it also refetches any of your active queries.\n`js\nimport { useQuery } from '@apollo/client';\nfunction Profile() {\n    const { data, client } = useQuery(PROFILE_QUERY);\n    return (\n      <Fragment>\n        <p>Current user: {data?.currentUser}</p>\n        <button onClick={async ()=>client.resetStore()}>\n            Log out\n        </button>\n      </Fragment>\n    );\n}`\n\nTo reset the cache without refetching active queries, use `client.clearStore()` instead of `client.resetStore()`.\n\nResponding to cache resets\nYou can register callback functions that execute whenever `client.resetStore` is called. To do so, call `client.onResetStore` and pass in your callback. To register multiple callbacks, call `client.onResetStore` multiple times. All of your callbacks are added to an array and are executed concurrently whenever the cache is reset.\nIn this example, we use `client.onResetStore` to write default values to the cache. This is useful when using Apollo Client's local state management features and calling `client.resetStore` anywhere in your application.\n```js\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nimport { withClientState } from 'apollo-link-state';\nimport { resolvers, defaults } from './resolvers';\nconst cache = new InMemoryCache();\nconst stateLink = withClientState({ cache, resolvers, defaults });\nconst client = new ApolloClient({\n  cache,\n  link: stateLink,\n});\nclient.onResetStore(stateLink.writeDefaults);\n```\nYou can also call `client.onResetStore` from your React components. This can be useful if you want to force your UI to rerender after the cache is reset.\nThe `client.onResetStore` method's return value is a function you can call to unregister your callback:\n```js {8-10,13}\nimport { useApolloClient } from '@apollo/client';\nfunction Foo (){\n  const [reset, setReset] = useState(0);\n  const client = useApolloClient();\nuseEffect(() => {\n    const unsubscribe = client.onResetStore(() => \n      new Promise(()=>setReset(reset + 1))\n    );\n\n\n```return () => {\n  unsubscribe();\n};\n```\n\n\n});\nreturn reset ?  : \n}\nexport default Foo;\n```\nTypePolicy inheritence\nJavaScript developers will be familiar with the idea of inheritance from the `extends` clause of `class` declarations, or possibly from dealing with prototype chains created by `Object.create`.\nInheritance is a powerful code-sharing tool, and it works well with Apollo Client for several reasons:\n\n\n`InMemoryCache` already knows about the supertype-subtype relationships (interfaces and unions) in your schema, thanks to `possibleTypes`, so no additional configuration is necessary to provide that information.\n\n\nInheritance allows a supertype to provide default configuration values to all its subtypes, including `keyFields` and individual field policies, which can be selectively overridden by subtypes that want something different.\n\n\nA single subtype can have multiple supertypes in a GraphQL schema, which is difficult to model using the single inheritance model of classes or prototypes. In other words, supporting multiple inheritance in JavaScript requires building a system something like this one, rather than just reusing built-in language features.\n\n\nDevelopers can add their own client-only supertypes to the `possibleTypes` map, as a way of reusing behavior across types, even if their schema knows nothing about those supertypes.\n\n\nThe `possibleTypes` map is currently used only for fragment matching purposes, which is an important but fairly small part of what the client does. Inheritance adds another compelling use for `possibleTypes`, and should drastically reduce repetition of `typePolicies` when used effectively.\n\n\nHere's how type policy inheritance works for `InMemoryCache`, considering the example below:\n```ts\nconst cache = new InMemoryCache({\n  possibleTypes: {\n    Reptile: [\"Snake\", \"Turtle\"],\n    Snake: [\"Python\", \"Viper\", \"Cobra\"],\n    Viper: [\"Cottonmouth\", \"DeathAdder\"],\n  },\ntypePolicies: {\n    Reptile: {\n      // Suppose all our reptiles are captive, and have a tag with an ID.\n      keyFields: [\"tagId\"],\n      fields: {\n        // Scientific name-related logic can be shared among Reptile subtypes.\n        scientificName: {\n          merge(_, incoming) {\n            // Normalize all scientific names to lower case.\n            return incoming.toLowerCase();\n          },\n        },\n      },\n    },\n\n\n```Snake: {\n  fields: {\n    // Default to a truthy non-boolean value if we don't know\n    // whether this snake is venomous.\n    venomous(status = \"unknown\") {\n      return status;\n    },\n  },\n},\n```\n\n\n},\n});\n```\nRefetching queries after a mutation\nIn certain cases, writing an `update` function to update the cache after a mutation can be complex, or even impossible if the mutation doesn't return modified fields.\nIn these cases, you can provide a `refetchQueries` option to the `useMutation` hook to automatically rerun certain queries after the mutation completes.\nFor details, see Refetching queries.\n\nNote that although `refetchQueries` can be faster to implement than an `update` function, it also requires additional network requests that are usually undesirable. For more information, see this blog post.\n\nCache redirects\nIn some cases, a query requests data that already exists in the cache under a different reference. For example, your UI might have a list view and a detail view that both use the same data.\nThe list view might run the following query:\n`graphql\nquery Books {\n  books {\n    id\n    title\n    abstract\n  }\n}`\nWhen a specific book is selected, the detail view might display an individual item using this query:\n`graphql\nquery Book($id: ID!) {\n  book(id: $id) {\n    id\n    title\n    abstract\n  }\n}`\nIn a case like this, we know that the second query's data might already be in the cache, but because that data was fetched by a different query, Apollo Client doesn't know that. To tell Apollo Client where to look for the cached `Book` object, we can define a field policy `read` function for the `book` field:\n```js {9-14}\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\nconst client = new ApolloClient({\n  cache: new InMemoryCache({\n    typePolicies: {\n      Query: {\n        fields: {\n          book: {\n            read(_, { args, toReference }) {\n              return toReference({\n                __typename: 'Book',\n                id: args.id,\n              });\n            }\n          }\n        }\n      }\n    }\n  })\n});\n```\nThis `read` function uses the `toReference` helper utility to generate and return a cache reference for a `Book` object, based on its `__typename` and `id`.\nNow whenever a query includes the `book` field, the `read` function above executes and returns a reference to a `Book` object. Apollo Client uses this reference to look up the object in its cache and return it if it's present. If it isn't present, Apollo Client knows it needs to execute the query over the network.\n\n\u26a0\ufe0f Note: To avoid a network request, all of a query's requested fields must already be present in the cache. If the detail view's query fetches any `Book` field that the list view's query didn't, Apollo Client considers the cache hit to be incomplete, and it executes the full query over the network.\n\nPagination utilities\nIncremental loading: `fetchMore`\nYou can use the `fetchMore` function to update a query's cached result with data returned by a followup query. Most often, `fetchMore` is used to handle infinite-scroll pagination and other situations where you're loading more data when you already have some.\nFor details, see The fetchMore function.\nThe `@connection` directive\nFundamentally, paginated queries are the same as any other query with the exception that calls to `fetchMore` update the same cache key. Because these queries are cached by both the initial query and their parameters, a problem arises when later retrieving or updating paginated queries in the cache. We don't care about pagination arguments such as limits, offsets, or cursors outside of the need to `fetchMore`, nor do we want to provide them simply for accessing cached data.\nTo solve this, you can use the `@connection` directive to specify a custom cache key for results. A connection allows us to set the cache key for a field and to filter which arguments actually alter the query.\nTo use the `@connection` directive, add it to the segment of the query you want a custom store key for and provide the `key` parameter to specify the store key. In addition to the `key` parameter, you can also include the optional `filter` parameter, which takes an array of query argument names to include in the generated custom store key.\n`js\nconst query = gql`\n  query Feed($type: FeedType!, $offset: Int, $limit: Int) {\n    feed(type: $type, offset: $offset, limit: $limit) @connection(key: \"feed\", filter: [\"type\"]) {\n      ...FeedEntry\n    }\n  }\n``\nWith the above query, even with multiple `fetchMore`s, the results of each feed update will always result in the `feed` key in the store being updated with the latest accumulated values. In this example, we also use the `@connection` directive's optional `filter` argument to include the `type` query argument in the store key, which results in multiple store values that accumulate queries from each type of feed.\nNow that we have a stable store key, we can easily use `writeQuery` to perform a store update, in this case clearing out the feed.\n`js\nclient.writeQuery({\n  query: gql`\n    query Feed($type: FeedType!) {\n      feed(type: $type) @connection(key: \"feed\", filter: [\"type\"]) {\n        id\n      }\n    }\n  `,\n  variables: {\n    type: \"top\",\n  },\n  data: {\n    feed: [],\n  },\n});`",
    "tag": "apollo-client"
  },
  {
    "title": "Initialization",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/caching/cache-configuration.mdx",
    "content": "\ntitle: Configuring the Apollo Client cache\nThis article describes cache setup and configuration. To learn how to interact with cached data, see Reading and writing data to the cache.\nInitialization\nCreate an `InMemoryCache` object and provide it to the `ApolloClient` constructor, like so:\n```ts\nimport { InMemoryCache, ApolloClient } from '@apollo/client';\nconst client = new ApolloClient({\n  // ...other arguments...\n  cache: new InMemoryCache(options)\n});\n```\nThe `InMemoryCache` constructor accepts a variety of configuration options.\nConfiguration options\nYou can configure the cache's behavior to better suit your application. For example, you can:\n\nCustomize the format of a particular type's cache ID\nCustomize the storage and retrieval of individual fields\nDefine polymorphic type relationships for fragment matching\nDefine patterns for pagination\nManage client-side local state\n\nTo customize cache behavior, you provide a configuration object to the `InMemoryCache` constructor. This object supports the following fields:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `addTypename`\n\n`Boolean`\n\n\n\n\nIf `true`, the cache automatically requests the `__typename` field for every object in your outgoing operations, which means you can omit `__typename` from your operation definitions.\n\nBy default, the cache uses the `__typename` field as part of the cache ID for every cached object, so it's helpful to guarantee that the field is always fetched.\n\nThe default value is `true`.\n\n\n\n\n\n\n###### `resultCaching`\n\n`Boolean`\n\n\n\n\nIf `true`, the cache returns an identical (`===`) response object for every execution of the same query, as long as the underlying data remains unchanged. This helps you detect changes to a query's result.\n\nThe default value is `true`.\n\n\n\n\n\n\n###### `possibleTypes`\n\n`Object`\n\n\n\n\nInclude this object to define polymorphic relationships between your schema's types. Doing so enables you to look up cached data by interface or by union.\n\nEach key in the object is the `__typename` of an interface or union, and the corresponding value is an array of the `__typename`s of the types that belong to that union or implement that interface.\n\nFor an example, see [Defining `possibleTypes` manually](../data/fragments/#defining-possibletypes-manually).\n\n\n\n\n\n\n###### `typePolicies`\n\n`Object`\n\n\n\n\nInclude this object to customize the cache's behavior on a type-by-type basis.\n\nEach key in the object is the `__typename` of a type to customize, and the corresponding value is a [`TypePolicy` object](#typepolicy-fields).\n\n\n\n\n\n\n###### `dataIdFromObject`\n\n`Function`\n\n\n\n\nA function that takes a response object and returns a unique identifier to be used when normalizing the data in the store.\n\nFor details, see [Customizing identifier generation globally](#customizing-identifier-generation-globally).\n\n\n\n\n\nCustomizing cache IDs\nYou can customize how the `InMemoryCache` generates cache IDs for individual types in your schema (see the default behavior). This is helpful especially if a type uses a field (or fields!) besides `id` or `_id` as its unique identifier.\nTo accomplish this, you define a `TypePolicy` for each type you want to customize. You specify all of your cache's `typePolicies` in the options object you provide to the InMemoryCache constructor.\nInclude a `keyFields` field in relevant `TypePolicy` objects, like so:\n`ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    Product: {\n      // In an inventory management system, products might be identified\n      // by their UPC.\n      keyFields: [\"upc\"],\n    },\n    Person: {\n      // In a user account system, the combination of a person's name AND email\n      // address might uniquely identify them.\n      keyFields: [\"name\", \"email\"],\n    },\n    Book: {\n      // If one of the keyFields is an object with fields of its own, you can\n      // include those nested keyFields by using a nested array of strings:\n      keyFields: [\"title\", \"author\", [\"name\"]],\n    },\n    AllProducts: {\n      // Singleton types that have no identifying field can use an empty\n      // array for their keyFields.\n      keyFields: [],\n    },\n  },\n});`\nThis example shows a variety of `typePolicies` with different `keyFields`:\n\nThe `Product` type uses its `upc` field as its identifying field.\nThe `Person` type uses the combination of both its `name` and `email` fields.\nThe `Book` type includes a subfield as part of its cache ID.\nThe `[\"name\"]` item indicates that the `name` field of the previous field in the array (`author`) is part of the cache ID. The `Book`'s `author` field must be an object that includes a `name` field for this to be valid.\nA valid cache ID for the `Book` type has the following structure:\n    `Book:{\"title\":\"Fahrenheit 451\",\"author\":{\"name\":\"Ray Bradbury\"}}`\n\n\nThe `AllProducts` type illustrates a special strategy for a singleton type. If the cache will only ever contain one `AllProducts` object and that object has no identifying fields, you can provide an empty array for its `keyFields`.\n\nIf an object has multiple `keyFields`, the cache ID always lists those fields in the same order to ensure uniqueness.\nNote that these `keyFields` strings always refer to the canonical field names defined in the schema. This means that ID computation is not sensitive to field aliases.\nCalculating an object's cache ID\nIf you define a custom cache ID that uses multiple fields, it can be challenging to calculate and provide that ID to methods that require it (such as `cache.readFragment`).\nTo help with this, you can use the `cache.identify` method to calculate the cache ID for any normalized object you fetch from your cache. See Obtaining an object's custom ID.\nCustomizing identifier generation globally\nIf you need to define a single fallback `keyFields` function that isn't specific to any particular `__typename`, you can use the `dataIdFromObject` function that was introduced in Apollo Client 2.x:\n```ts\nimport { defaultDataIdFromObject } from '@apollo/client';\nconst cache = new InMemoryCache({\n  dataIdFromObject(responseObject) {\n    switch (responseObject.__typename) {\n      case 'Product': return `Product:${responseObject.upc}`;\n      case 'Person': return `Person:${responseObject.name}:${responseObject.email}`;\n      default: return defaultDataIdFromObject(responseObject);\n    }\n  }\n});\n```\n\nThe `dataIdFromObject` API is included in Apollo Client 3 to ease the transition from Apollo Client 2.x.\n\nNotice that the above function still uses different logic to generate keys based on an object's `__typename`. In a case like this, you should almost always define `keyFields` arrays for the `Product` and `Person` types via `typePolicies`.\nThis code also has the following drawbacks:\n\nIt's sensitive to aliasing mistakes.\nIt does nothing to protect against undefined object properties.\nAccidentally using different key fields at different times can cause inconsistencies in the cache.\n\nDisabling normalization\nYou can instruct the `InMemoryCache` not to normalize objects of a particular type. This can be useful for metrics and other transient data that's identified by a timestamp and never receives updates.\nTo disable normalization for a type, define a `TypePolicy` for the type (as shown in Customizing cache IDs) and set the policy's `keyFields` field to `false`.\nObjects that are not normalized are instead embedded within their parent object in the cache. You can't access these objects directly, but you can access them via their parent.\n`TypePolicy` fields\nTo customize how the cache interacts with specific types in your schema, you can pass the `InMemoryCache` constructor an object that maps `__typename` strings to `TypePolicy` objects.\nA `TypePolicy` object can include the following fields:\n```ts\ntype TypePolicy = {\n  // Allows defining the primary key fields for this type, either using an\n  // array of field names, a function that returns an arbitrary string, or\n  // false to disable normalization for objects of this type.\n  keyFields?: KeySpecifier | KeyFieldsFunction | false;\n// If your schema uses a custom __typename for any of the root Query,\n  // Mutation, and/or Subscription types (rare), set the corresponding\n  // field below to true to indicate that this type serves as that type.\n  queryType?: true,\n  mutationType?: true,\n  subscriptionType?: true,\nfields?: {\n    [fieldName: string]:\n      | FieldPolicy\n      | FieldReadFunction;\n  }\n};\n// Recursive type aliases are coming in TypeScript 3.7, so this isn't the\n// actual type we use, but it's what it should be:\ntype KeySpecifier = (string | KeySpecifier)[];\ntype KeyFieldsFunction = (\n  object: Readonly,\n  context: {\n    typename: string;\n    selectionSet?: SelectionSetNode;\n    fragmentMap?: FragmentMap;\n  },\n) => string | null | void;\n```\nOverriding root operation types (uncommon)\nIn addition to `keyFields`, a `TypePolicy` can indicate that its type represents the root query, mutation, or subscription type by setting `queryType`, `mutationType`, or `subscriptionType` to `true`:\n```ts\nconst cache = new InMemoryCache({\n  typePolicies: {\n    UnconventionalRootQuery: {\n      // The RootQueryFragment can only match if the cache knows the __typename\n      // of the root query object.\n      queryType: true,\n    },\n  },\n});\nconst result = cache.readQuery({\n  query: gql`query MyQuery {\n      ...RootQueryFragment\n    }\n    fragment RootQueryFragment on UnconventionalRootQuery {\n      field1\n      field2 {\n        subfield\n      }\n    }`,\n});\nconst equivalentResult = cache.readQuery({\n  query: gql`query MyQuery {\n      field1\n      field2 {\n        subfield\n      }\n    }`,\n});\n```\nThe cache usually obtains `__typename` information by adding the `__typename` field to every query selection set it sends to the server. It could technically use this same method for the outermost selection set of every operation, but the `__typename`s of the root query and mutation are almost always `\"Query\"` and `\"Mutation\"`, so the cache assumes those common defaults unless instructed otherwise in a `TypePolicy`.\nFor most objects in a graph, the `__typename` field is vital for proper identification and normalization. For the root query and mutation types, the `__typename` is not nearly as useful or important, because those types are singletons with only one instance per client.\nThe `fields` property",
    "tag": "apollo-client"
  },
  {
    "title": "Prerequisites",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/queries.mdx",
    "content": "\ntitle: Queries\ndescription: Fetch data with the useQuery hook\n\nimport QueryOptions from '../../shared/query-options.mdx';\nimport QueryResult from '../../shared/query-result.mdx';\nThis article shows how to fetch GraphQL data in React with the `useQuery` hook and attach the result to your UI. You'll also learn how Apollo Client simplifies data management code by tracking error and loading states for you.\nPrerequisites\nThis article assumes you're familiar with building basic GraphQL queries. If you need a refresher, we recommend this guide. You can also build example queries against Apollo's full-stack tutorial server.\nThis article also assumes that you've already set up Apollo Client and have wrapped your React app in an `ApolloProvider` component. For more information, see the getting started guide.\n\nTo follow along with the examples below, open up our starter project and sample GraphQL server on CodeSandbox. You can view the completed version of the app here.\n\nExecuting a query\nThe `useQuery` React hook is the primary API for executing queries in an Apollo application. To run a query within a React component, call `useQuery` and pass it a GraphQL query string. When your component renders, `useQuery` returns an object from Apollo Client that contains `loading`, `error`, and `data` properties you can use to render your UI.\nLet's look at an example. First, we'll create a GraphQL query named `GET_DOGS`. Remember to wrap query strings in the `gql` function to parse them into query documents:\n```tsx title=\"index.js\"\nimport { gql, useQuery } from '@apollo/client';\nconst GET_DOGS = gql`query GetDogs {\n    dogs {\n      id\n      breed\n    }\n  }`;\n```\nNext, we'll create a component named `Dogs`. Inside it, we'll pass our `GET_DOGS` query to the `useQuery` hook:\n```tsx title=\"index.js\"\nfunction Dogs({ onDogSelected }) {\n  const { loading, error, data } = useQuery(GET_DOGS);\nif (loading) return 'Loading...';\n  if (error) return `Error! ${error.message}`;\nreturn (\n    \n      {data.dogs.map((dog) => (\n        \n          {dog.breed}\n        \n      ))}\n    \n  );\n}\n```\nAs our query executes and the values of `loading`, `error`, and `data` change, the `Dogs` component can intelligently render different UI elements according to the query's state:\n\nAs long as `loading` is `true` (indicating the query is still in flight), the component presents a `Loading...` notice.\nWhen loading is `false` and there is no `error`, the query has completed. The component renders a dropdown menu that's populated with the list of dog breeds returned by the server.\n\nWhen the user selects a dog breed from the populated dropdown, the selection is sent to the parent component via the provided `onDogSelected` function.\nIn the next step, we'll associate the dropdown with a more sophisticated query that uses GraphQL variables.\nCaching query results\nWhenever Apollo Client fetches query results from your server, it automatically caches those results locally. This makes later executions of that same query extremely fast.\nTo see this caching in action, let's build a new component called `DogPhoto`. `DogPhoto` accepts a prop called `breed` that reflects the current value of the dropdown menu in our `Dogs` component:\n```jsx title=\"index.js\"\nconst GET_DOG_PHOTO = gql`\n  query Dog($breed: String!) {\n    dog(breed: $breed) {\n      id\n      displayImage\n    }\n  }\n`;\nfunction DogPhoto({ breed }) {\n  const { loading, error, data } = useQuery(GET_DOG_PHOTO, {\n    variables: { breed },\n  });\nif (loading) return null;\n  if (error) return `Error! ${error}`;\nreturn (\n    \n  );\n}\n```\nNotice that we're providing a configuration option (`variables`) to the `useQuery` hook this time. The `variables` option is an object that contains all of the variables we want to pass to our GraphQL query. In this case, we want to pass the currently selected `breed` from the dropdown.\nSelect `bulldog` from the dropdown to see its photo appear. Then switch to another breed, and then switch back to `bulldog`. You'll notice that the bulldog photo loads instantly the second time around. This is the cache at work!\nNext, let's learn some techniques for ensuring that our cached data is fresh.\nUpdating cached query results\nSometimes, you want to make sure that your query's cached data is up to date with your server's data. Apollo Client supports two strategies for this: polling and refetching.\nPolling\nPolling provides near-real-time synchronization with your server by executing your query periodically at a specified interval. To enable polling for a query, pass a `pollInterval` configuration option to the `useQuery` hook with an interval in milliseconds:\n```jsx title=\"index.js\" {4}\nfunction DogPhoto({ breed }) {\n  const { loading, error, data } = useQuery(GET_DOG_PHOTO, {\n    variables: { breed },\n    pollInterval: 500,\n  });\nif (loading) return null;\n  if (error) return `Error! ${error}`;\nreturn (\n    \n  );\n}\n```\nBy setting `pollInterval` to 500, we fetch the current breed's image from the server every 0.5 seconds. Note that if you set `pollInterval` to `0`, the query does not poll.\n\nYou can also start and stop polling dynamically with the startPolling and stopPolling functions that are returned by the `useQuery` hook. When using these functions, set the `pollInterval` configuration option as a parameter of the `startPolling` function.\n\nRefetching\nRefetching enables you to refresh query results in response to a particular user\naction, as opposed to using a fixed interval.\nLet's add a button to our `DogPhoto` component that calls our query's\n`refetch` function whenever it's clicked.\nYou can optionally provide a new `variables` object to the `refetch` function.\nIf you avoid passing a `variables` object and use only `refetch()`, the query\nuses the same `variables` that it used in its previous execution.\n```jsx {2,12} title=\"index.js\"\nfunction DogPhoto({ breed }) {\n  const { loading, error, data, refetch } = useQuery(GET_DOG_PHOTO, {\n    variables: { breed },\n  });\nif (loading) return null;\n  if (error) return `Error! ${error}`;\nreturn (\n    \n\n refetch({ breed: 'new_dog_breed' })}>\n        Refetch new breed!\n      \n\n  );\n}\n```\nClick the button and notice that the UI updates with a new dog photo. Refetching is an excellent way to guarantee fresh data, but it introduces some complexity with loading state. In the next section, we'll cover strategies for handling complex loading and error state.\nProviding new variables to `refetch`\nYou call `refetch` with a new set of variables like so:\n```jsx\n\n    refetch({\n      breed: 'dalmatian', // Always refetches a dalmatian instead of original breed\n    })\n  }\n\nRefetch!\n\n```\n\nIf you provide new values for some of your original query's variables but not all of them, `refetch` uses each omitted variable's original value.\nInspecting loading states\nWe've already seen that the `useQuery` hook exposes our query's current loading state. This is helpful when a query first loads, but what happens to our loading state when we're refetching or polling?\nLet's return to our refetching example from the previous section. If you click the refetch button, you'll see that the component doesn't re-render until the new data arrives. What if we want to indicate to the user that we're refetching the photo?\nThe `useQuery` hook's result object provides fine-grained information about the status of the query via the `networkStatus` property. To take advantage\nof this information, we set the `notifyOnNetworkStatusChange` option to `true` so our query component re-renders while a refetch is in flight:\n```jsx title=\"index.js\" {4,8,12}\nimport { NetworkStatus } from '@apollo/client';\nfunction DogPhoto({ breed }) {\n  const { loading, error, data, refetch, networkStatus } = useQuery(\n    GET_DOG_PHOTO,\n    {\n      variables: { breed },\n      notifyOnNetworkStatusChange: true,\n    }\n  );\nif (networkStatus === NetworkStatus.refetch) return 'Refetching!';\n  if (loading) return null;\n  if (error) return `Error! ${error}`;\nreturn (\n    \n\n refetch({ breed: 'new_dog_breed' })}>\n        Refetch!\n      \n\n  );\n}\n```\nEnabling this option also ensures that the value of `loading` updates accordingly, even if you don't want to use the more fine-grained information provided by the `networkStatus` property.\nThe `networkStatus` property is a `NetworkStatus` enum that represents different loading states. Refetch is represented by `NetworkStatus.refetch`, and there are also values for polling and pagination. For a full list of all the possible loading states, check out the source.\n\nTo view a complete version of the app we just built, check out the CodeSandbox here.\n\nInspecting error states\nYou can customize your query error handling by providing the `errorPolicy`\nconfiguration option to the `useQuery` hook. The default value is `none`, which tells Apollo Client to treat all GraphQL errors as runtime errors. In this case, Apollo Client discards any query response data returned by the server and sets the `error` property in the `useQuery` result object.\nIf you set `errorPolicy` to `all`, `useQuery` does not discard query response data, allowing you to render partial results.\nFor more information, see Handling operation errors.\nManual execution with `useLazyQuery`\nWhen React renders a component that calls `useQuery`, Apollo Client automatically executes the corresponding query. But what if you want to execute a query in response to a different event, such as a user clicking a button?\nThe `useLazyQuery` hook is perfect for executing queries in response to events besides component rendering. Unlike with `useQuery`, when you call `useLazyQuery`, it does not immediately execute its associated query. Instead, it returns a query function in its result tuple that you call whenever you're ready to execute the query.\nHere's an example:\n```jsx {2,5,13} title=\"index.js\"\nimport React from 'react';\nimport { useLazyQuery } from '@apollo/client';\nfunction DelayedQuery() {\n  const [getDog, { loading, error, data }] = useLazyQuery(GET_DOG_PHOTO);\nif (loading) return Loading ...;\n  if (error) return `Error! ${error}`;\nreturn (\n    \n      {data?.dog && }\n       getDog({ variables: { breed: 'bulldog' } })}>\n        Click me!\n      \n\n  );\n}\n```\nThe first item in `useLazyQuery`'s return tuple is the query function, and the second item is the same result object returned by `useQuery`.\nAs shown above, you can pass options to the query function just like you pass them to `useLazyQuery` itself. If you pass a particular option to both, the value you pass to the query function takes precedence. This is a handy way to pass default options to `useLazyQuery` and then customize those options in the query function.\nFor a full list of supported options, see the API reference.\nSetting a fetch policy\nBy default, the `useQuery` hook checks the Apollo Client cache to see if all the data you requested is already available locally. If all data is available locally, `useQuery` returns that data and doesn't query your GraphQL server. This `cache-first` policy is Apollo Client's default fetch policy.\nYou can specify a different fetch policy for a given query. To do so, include the `fetchPolicy` option in your call to `useQuery`:\n`js {2}\nconst { loading, error, data } = useQuery(GET_DOGS, {\n  fetchPolicy: 'network-only', // Doesn't check cache before making a network request\n});`\n`nextFetchPolicy`\nYou can also specify a query's `nextFetchPolicy`. If you do, `fetchPolicy` is used for the query's first execution, and `nextFetchPolicy` is used to determine how the query responds to future cache updates:\n`js {3}\nconst { loading, error, data } = useQuery(GET_DOGS, {\n  fetchPolicy: 'network-only', // Used for first execution\n  nextFetchPolicy: 'cache-first', // Used for subsequent executions\n});`\nFor example, this is helpful if you want a query to always make an initial network request, but you're comfortable reading from the cache after that.\n`nextFetchPolicy` functions\nIf you want to apply a single `nextFetchPolicy` by default, because you find yourself manually providing `nextFetchPolicy` for most of your queries, you can configure `defaultOptions.watchQuery.nextFetchPolicy` when creating your `ApolloClient` instance:\n`js\nnew ApolloClient({\n  link,\n  client,\n  defaultOptions: {\n    watchQuery: {\n      nextFetchPolicy: 'cache-only',\n    },\n  },\n});`\nThis configuration applies to all `client.watchQuery` calls and `useQuery` calls that do not otherwise configure `nextFetchPolicy`.\nIf you want more control over how `nextFetchPolicy` behaves, you can provide a function instead of a `WatchQueryFetchPolicy` string:\n`js\nnew ApolloClient({\n  link,\n  client,\n  defaultOptions: {\n    watchQuery: {\n      nextFetchPolicy(currentFetchPolicy) {\n        if (\n          currentFetchPolicy === 'network-only' ||\n          currentFetchPolicy === 'cache-and-network'\n        ) {\n          // Demote the network policies (except \"no-cache\") to \"cache-first\"\n          // after the first request.\n          return 'cache-first';\n        }\n        // Leave all other fetch policies unchanged.\n        return currentFetchPolicy;\n      },\n    },\n  },\n});`\nThis `nextFetchPolicy` function will be called after each request, and uses the `currentFetchPolicy` parameter to decide how to modify the fetch policy.\nIn addition to being called after each request, your `nextFetchPolicy` function will also be called when variables change, which by default resets the `fetchPolicy` to its initial value, which is often important to trigger a fresh network request for queries that started out with `cache-and-network` or `network-only` fetch policies.\nTo intercept and handle the `variables-changed` case yourself, you can use the `NextFetchPolicyContext` object passed as the second argument to your `nextFetchPolicy` function:\n```js\nnew ApolloClient({\n  link,\n  client,\n  defaultOptions: {\n    watchQuery: {\n      nextFetchPolicy(\n        currentFetchPolicy,\n        {\n          // Either \"after-fetch\" or \"variables-changed\", indicating why the\n          // nextFetchPolicy function was invoked.\n          reason,\n          // The rest of the options (currentFetchPolicy === options.fetchPolicy).\n          options,\n          // The original value of options.fetchPolicy, before nextFetchPolicy was\n          // applied for the first time.\n          initialPolicy,\n          // The ObservableQuery associated with this client.watchQuery call.\n          observable,\n        }\n      ) {\n        // When variables change, the default behavior is to reset\n        // options.fetchPolicy to context.initialPolicy. If you omit this logic,\n        // your nextFetchPolicy function can override this default behavior to\n        // prevent options.fetchPolicy from changing in this case.\n        if (reason === 'variables-changed') {\n          return initialPolicy;\n        }\n\n\n```    if (\n      currentFetchPolicy === 'network-only' ||\n      currentFetchPolicy === 'cache-and-network'\n    ) {\n      // Demote the network policies (except \"no-cache\") to \"cache-first\"\n      // after the first request.\n      return 'cache-first';\n    }\n\n    // Leave all other fetch policies unchanged.\n    return currentFetchPolicy;\n  },\n},\n```\n\n\n},\n});\n```\nIn order to debug these `nextFetchPolicy` transitions, it can be useful to add `console.log` or `debugger` statements to the function body, to see when and why the function is called.\nSupported fetch policies\n\n\n\nName\nDescription\n\n\n\n\n\n\n###### `cache-first`\n\n\n\n\nApollo Client first executes the query against the cache. If _all_ requested data is present in the cache, that data is returned. Otherwise, Apollo Client executes the query against your GraphQL server and returns that data after caching it.\n\nPrioritizes minimizing the number of network requests sent by your application.\n\nThis is the default fetch policy.\n\n\n\n\n\n\n###### `cache-only`\n\n\n\n\nApollo Client executes the query _only_ against the cache. It never queries your server in this case.\n\nA `cache-only` query throws an error if the cache does not contain data for all requested fields.\n\n\n\n\n\n\n###### `cache-and-network`\n\n\n\n\nApollo Client executes the full query against both the cache _and_ your GraphQL server. The query automatically updates if the result of the server-side query modifies cached fields.\n\nProvides a fast response while also helping to keep cached data consistent with server data.\n\n\n\n\n\n\n###### `network-only`\n\n\n\n\nApollo Client executes the full query against your GraphQL server, _without_ first checking the cache. The query's result _is_ stored in the cache.\n\nPrioritizes consistency with server data, but can't provide a near-instantaneous response when cached data is available.\n\n\n\n\n\n\n###### `no-cache`\n\n\n\n\nSimilar to `network-only`, except the query's result _is not_ stored in the cache.\n\n\n\n\n\n\n###### `standby`\n\n\n\n\nUses the same logic as `cache-first`, except this query does _not_ automatically update when underlying field values change. You can still _manually_ update this query with `refetch` and `updateQueries`.\n\n\n\n\n\n`useQuery` API\nSupported options and result fields for the `useQuery` hook are listed below.\nMost calls to `useQuery` can omit the majority of these options, but it's useful to know they exist. To learn about the `useQuery` hook API in more detail with usage examples, see the API reference.\nOptions\nThe `useQuery` hook accepts the following options:\n\nResult\nAfter being called, the `useQuery` hook returns a result object with the following properties. This object contains your query result, plus some helpful functions for refetching, dynamic polling, and pagination.\n\nNext steps\nNow that you understand how to fetch data with the `useQuery` hook, learn how to update your data with the useMutation hook!\nAfter that, learn about some other handy Apollo Client features:\n\nLocal state management: Learn how to query local data.\n",
    "tag": "apollo-client"
  },
  {
    "title": "Example usage",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/fragments.md",
    "content": "\ntitle: Fragments\ndescription: Share fields between operations\n\nA GraphQL fragment is a piece of logic that can be shared between multiple queries and mutations.\nHere's the declaration of a `NameParts` fragment that can be used with any `Person` object:\n`graphql\nfragment NameParts on Person {\n  firstName\n  lastName\n}`\nEvery fragment includes a subset of the fields that belong to its associated type. In the above example, the `Person` type must declare `firstName` and `lastName` fields for the `NameParts` fragment to be valid.\nWe can now include the `NameParts` fragment in any number of queries and mutations that refer to `Person` objects, like so:\n`graphql\nquery GetPerson {\n  people(id: \"7\") {\n    ...NameParts\n    avatar(size: LARGE)\n  }\n}`\n\nYou precede an included fragment with three periods (`...`), much like JavaScript spread syntax.\n\nBased on our `NameParts` definition, the above query is equivalent to:\n`graphql\nquery GetPerson {\n  people(id: \"7\") {\n    firstName\n    lastName\n    avatar(size: LARGE)\n  }\n}`\nIf we later change which fields are included in the `NameParts` fragment, we automatically change which fields are included in operations that use the fragment. This reduces the effort required to keep fields consistent across a set of operations.\nExample usage\nLet's say we have a blog application that executes several GraphQL operations related to comments (submitting a comment, fetching a post's comments, etc.). These operations probably all include certain fields of a `Comment` type.\nTo specify this core set of fields, we can define a fragment on the `Comment` type, like so:\n```js title=\"fragments.js\"\nimport { gql } from '@apollo/client';\nexport const CORE_COMMENT_FIELDS = gql`fragment CoreCommentFields on Comment {\n    id\n    postedBy {\n      username\n      displayName\n    }\n    createdAt\n    content\n  }`;\n```\n\nYou can declare fragments in any file of your application. The example above `export`s the fragment from a `fragments.js` file.\n\nWe can then include the `CoreCommentFields` fragment in a GraphQL operation like so:\n```jsx {2,5,12} title=\"PostDetails.jsx\"\nimport { gql } from '@apollo/client';\nimport { CORE_COMMENT_FIELDS } from './fragments';\nexport const GET_POST_DETAILS = gql`${CORE_COMMENT_FIELDS}\n  query CommentsForPost($postId: ID!) {\n    post(postId: $postId) {\n      title\n      body\n      author\n      comments {\n        ...CoreCommentFields\n      }\n    }\n  }`;\n// ...PostDetails component definition...\n```\n\nWe first `import` `CORE_COMMENT_FIELDS` because it's declared in another file.\nWe add our fragment definition to the `GET_POST_DETAILS` `gql` template literal via a placeholder (`${CORE_COMMENT_FIELDS}`)\nWe include the `CoreCommentFields` fragment in our query with standard `...` notation.\n\nColocating fragments\nThe tree-like structure of a GraphQL response resembles the hierarchy of a frontend's rendered components. Because of this similarity, you can use fragments to split query logic up between components, so that each component requests exactly the fields that it uses. This helps you make your component logic more succinct.\nConsider the following view hierarchy for an app:\n`FeedPage\n\u2514\u2500\u2500 Feed\n    \u2514\u2500\u2500 FeedEntry\n        \u251c\u2500\u2500 EntryInfo\n        \u2514\u2500\u2500 VoteButtons`\nIn this app, the `FeedPage` component executes a query to fetch a list of `FeedEntry` objects. The `EntryInfo` and `VoteButtons` subcomponents need specific fields from the enclosing `FeedEntry` object.\nCreating colocated fragments\nA colocated fragment is just like any other fragment, except it's attached to a particular component that uses the fragment's fields. For example, the `VoteButtons` child component of `FeedPage` might use the fields `score` and `vote { choice }` from the `FeedEntry` object:\n`js title=\"VoteButtons.jsx\"\nVoteButtons.fragments = {\n  entry: gql`\n    fragment VoteButtonsFragment on FeedEntry {\n      score\n      vote {\n        choice\n      }\n    }\n  `,\n};`\nAfter you define a fragment in a child component, the parent component can refer to it in its own colocated fragments, like so:\n`js title=\"FeedEntry.jsx\"\nFeedEntry.fragments = {\n  entry: gql`\n    fragment FeedEntryFragment on FeedEntry {\n      commentCount\n      repository {\n        full_name\n        html_url\n        owner {\n          avatar_url\n        }\n      }\n      ...VoteButtonsFragment\n      ...EntryInfoFragment\n    }\n    ${VoteButtons.fragments.entry}\n    ${EntryInfo.fragments.entry}\n  `,\n};`\nThere's nothing special about the naming of `VoteButtons.fragments.entry` or `EntryInfo.fragments.entry`. Any naming convention works as long as you can retrieve a component's fragments given the component.\nImporting fragments when using Webpack\nWhen loading `.graphql` files with graphql-tag/loader, we can include fragments using `import` statements. For example:\n```graphql\nimport \"./someFragment.graphql\"\n```\nThis makes the contents of `someFragment.graphql` available to the current file. See the Webpack Fragments section for additional details.\nUsing fragments with unions and interfaces\nYou can define fragments on unions and interfaces.\nHere's an example of a query that includes three in-line fragments:\n```graphql\nquery AllCharacters {\n  all_characters {\n\n\n```... on Character {\n  name\n}\n\n... on Jedi {\n  side\n}\n\n... on Droid {\n  model\n}\n```\n\n\n}\n}\n```\nThe `all_characters` query above returns a list of `Character` objects. The `Character` type is an interface that both the `Jedi` and `Droid` types implement. Each item in the list includes a `side` field if it's an object of type `Jedi`, and it includes a `model` field if it's of type `Droid`.\nHowever, for this query to work, your client needs to understand the polymorphic relationship between the `Character` interface and the types that implement it. To inform the client about these relationships, you can pass a `possibleTypes` option when you initialize your `InMemoryCache`.\nDefining `possibleTypes` manually\n\nThe `possibleTypes` option is available in Apollo Client 3.0 and later.\n\nYou can pass a `possibleTypes` option to the `InMemoryCache` constructor to specify supertype-subtype relationships in your schema. This object maps the name of an interface or union type (the supertype) to the types that implement or belong to it (the subtypes).\nHere's an example `possibleTypes` declaration:\n`ts\nconst cache = new InMemoryCache({\n  possibleTypes: {\n    Character: [\"Jedi\", \"Droid\"],\n    Test: [\"PassingTest\", \"FailingTest\", \"SkippedTest\"],\n    Snake: [\"Viper\", \"Python\"],\n  },\n});`\nThis example lists three interfaces (`Character`, `Test`, and `Snake`) and the object types that implement them.\nIf your schema includes only a few unions and interfaces, you can probably specify your `possibleTypes` manually without issue. However, as your schema grows in size and complexity, you should consider generating possibleTypes automatically from your schema.\nGenerating `possibleTypes` automatically\nThe following example script translates a GraphQL introspection query into a `possibleTypes` configuration object:\n```js\nconst fetch = require('cross-fetch');\nconst fs = require('fs');\nfetch(`${YOUR_API_HOST}/graphql`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    variables: {},\n    query: `{\n        __schema {\n          types {\n            kind\n            name\n            possibleTypes {\n              name\n            }\n          }\n        }\n      }`,\n  }),\n}).then(result => result.json())\n  .then(result => {\n    const possibleTypes = {};\n\n\n```result.data.__schema.types.forEach(supertype => {\n  if (supertype.possibleTypes) {\n    possibleTypes[supertype.name] =\n      supertype.possibleTypes.map(subtype => subtype.name);\n  }\n});\n\nfs.writeFile('./possibleTypes.json', JSON.stringify(possibleTypes), err => {\n  if (err) {\n    console.error('Error writing possibleTypes.json', err);\n  } else {\n    console.log('Fragment types successfully extracted!');\n  }\n});\n```\n\n\n});\n```\nYou can then `import` the generated `possibleTypes` JSON module into the file where you create your `InMemoryCache`:\n```ts\nimport possibleTypes from './path/to/possibleTypes.json';\nconst cache = new InMemoryCache({\n  possibleTypes,\n});\n```\n`useFragment_experimental`",
    "tag": "apollo-client"
  },
  {
    "title": "file-uploads.md",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/file-uploads.md",
    "content": "\ntitle: File uploads\ndescription: Enabling file uploads in Apollo Client\n\nApollo Client doesn't support a file upload feature out of the box. If you'd like to enable file upload capabilities, you will have to set Apollo Client up manually with a 3rd party package.\nDetailed instructions on how to setup Apollo Client for file upload can be found here: https://github.com/jaydenseric/apollo-upload-client.\nAn example configuration is show below using the apollo-upload-client package.\n`bash\nnpm install apollo-upload-client`\nBasic setup for the Apollo Client:\n```js\nconst { ApolloClient } = require('apollo-client')\nconst { InMemoryCache } = require('apollo-cache-inmemory')\nconst { createUploadLink } = require('apollo-upload-client')\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: createUploadLink()\n})",
    "tag": "apollo-client"
  },
  {
    "title": "When to use subscriptions",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/subscriptions.mdx",
    "content": "\ntitle: Subscriptions\ndescription: Get real-time updates from your GraphQL server\n\nimport SubscriptionOptions from '../../shared/subscription-options.mdx';\nimport SubscriptionResult from '../../shared/subscription-result.mdx';\nIn addition to queries and mutations, GraphQL supports a third operation type: subscriptions.\nLike queries, subscriptions enable you to fetch data. Unlike queries, subscriptions are long-lasting operations that can change their result over time. They can maintain an active connection to your GraphQL server (most commonly via WebSocket), enabling the server to push updates to the subscription's result.\nSubscriptions are useful for notifying your client in real time about changes to back-end data, such as the creation of a new object or updates to an important field.\nWhen to use subscriptions\nIn the majority of cases, your client should not use subscriptions to stay up to date with your backend. Instead, you should poll intermittently with queries, or re-execute queries on demand when a user performs a relevant action (such as clicking a button).\nYou should use subscriptions for the following:\n\n\nSmall, incremental changes to large objects. Repeatedly polling for a large object is expensive, especially when most of the object's fields rarely change. Instead, you can fetch the object's initial state with a query, and your server can proactively push updates to individual fields as they occur.\n\n\nLow-latency, real-time updates. For example, a chat application's client wants to receive new messages as soon as they're available.\n\n\n\nNote: Subscriptions cannot be used to listen to local client events, like subscribing to changes in the cache. Subscriptions are intended to be used to subscribe to external data changes, and have those received changes be stored in the cache. You can then leverage Apollo Client's observability model to watch for changes in the cache, using client.watchQuery or useQuery.\n\nChoosing a subscription library\nThe GraphQL spec does not define a specific protocol for sending subscription requests. The first popular JavaScript library to implement subscriptions over WebSocket is called `subscriptions-transport-ws`. This library is no longer actively maintained. Its successor is a library called `graphql-ws`. The two libraries do not use the same WebSocket subprotocol, so you need to make sure that your server and clients all use the same library.\nApollo Client supports both `graphql-ws` and `subscriptions-transport-ws`. We recommend you use the newer library `graphql-ws`, and this page shows how to use it. If you need to use `subscriptions-transport-ws` because your server still uses that protocol, the differences are described at the bottom of this page.\n\nNote: Confusingly, the `subscriptions-transport-ws` library calls its WebSocket subprotocol `graphql-ws`, and the `graphql-ws` library calls its subprotocol `graphql-transport-ws`! In this article, we refer to the two libraries (`subscriptions-transport-ws` and `graphql-ws`), not the two subprotocols.\n\nDefining a subscription\nYou define a subscription on both the server side and the client side, just like you do for queries and mutations.\nServer side\nYou define available subscriptions in your GraphQL schema as fields of the `Subscription` type. The following `commentAdded` subscription notifies a subscribing client whenever a new comment is added to a particular blog post (specified by `postID`):\n`graphql\ntype Subscription {\n  commentAdded(postID: ID!): Comment\n}`\nFor more information on implementing support for subscriptions on the server side, see the Apollo Server documentation for subscriptions.\nClient side\nIn your application's client, you define the shape of each subscription you want Apollo Client to execute, like so:\n`js\nconst COMMENTS_SUBSCRIPTION = gql`\n  subscription OnCommentAdded($postID: ID!) {\n    commentAdded(postID: $postID) {\n      id\n      content\n    }\n  }\n`;`\nWhen Apollo Client executes the `OnCommentAdded` subscription, it establishes a connection to your GraphQL server and listens for response data. Unlike with a query, there is no expectation that the server will immediately process and return a response. Instead, your server only pushes data to your client when a particular event occurs on your backend.\nWhenever your GraphQL server does push data to a subscribing client, that data conforms to the structure of the executed subscription, just like it does for a query:\n`json\n{\n  \"data\": {\n    \"commentAdded\": {\n      \"id\": \"123\",\n      \"content\": \"What a thoughtful and well written post!\"\n    }\n  }\n}`\nSetting up the transport\nBecause subscriptions usually maintain a persistent connection, they shouldn't use the default HTTP transport that Apollo Client uses for queries and mutations. Instead, Apollo Client subscriptions most commonly communicate over WebSocket, via the graphql-ws library.\n\nAs mentioned in Choosing a subscription library, some servers use an older library called `subscriptions-transport-ws`. For necessary changes to use that library, see below.\n\n1. Install required libraries\nApollo Link is a library that helps you customize Apollo Client's network communication. You can use it to define a link chain that modifies your operations and routes them to the appropriate destination.\nTo execute subscriptions over WebSocket, you can add a `GraphQLWsLink` to your link chain. This link requires the `graphql-ws` library. Install it like so:\n`bash\nnpm install graphql-ws`\n2. Initialize a `GraphQLWsLink`\nImport and initialize a `GraphQLWsLink` object in the same project file where you initialize `ApolloClient`:\n```js title=\"index.js\"\nimport { GraphQLWsLink } from '@apollo/client/link/subscriptions';\nimport { createClient } from 'graphql-ws';\nconst wsLink = new GraphQLWsLink(createClient({\n  url: 'ws://localhost:4000/subscriptions',\n}));\n```\nReplace the value of the `url` option with your GraphQL server's subscription-specific WebSocket endpoint. If you're using Apollo Server, see Setting a subscription endpoint.\n3. Split communication by operation (recommended)\nAlthough Apollo Client can use your `GraphQLWsLink` to execute all operation types, in most cases it should continue using HTTP for queries and mutations. This is because queries and mutations don't require a stateful or long-lasting connection, making HTTP more efficient and scalable if a WebSocket connection isn't already present.\nTo support this, the `@apollo/client` library provides a `split` function that lets you use one of two different `Link`s, according to the result of a boolean check.\nThe following example expands on the previous one by initializing both a `GraphQLWsLink` and an `HttpLink`. It then uses the `split` function to combine those two `Link`s into a single `Link` that uses one or the other according to the type of operation being executed.\n```js title=\"index.js\"\nimport { split, HttpLink } from '@apollo/client';\nimport { getMainDefinition } from '@apollo/client/utilities';\nimport { GraphQLWsLink } from '@apollo/client/link/subscriptions';\nimport { createClient } from 'graphql-ws';\nconst httpLink = new HttpLink({\n  uri: 'http://localhost:4000/graphql'\n});\nconst wsLink = new GraphQLWsLink(createClient({\n  url: 'ws://localhost:4000/subscriptions',\n}));\n// The split function takes three parameters:\n//\n// * A function that's called for each operation to execute\n// * The Link to use for an operation if the function returns a \"truthy\" value\n// * The Link to use for an operation if the function returns a \"falsy\" value\nconst splitLink = split(\n  ({ query }) => {\n    const definition = getMainDefinition(query);\n    return (\n      definition.kind === 'OperationDefinition' &&\n      definition.operation === 'subscription'\n    );\n  },\n  wsLink,\n  httpLink,\n);\n```\nUsing this logic, queries and mutations will use HTTP as normal, and subscriptions will use WebSocket.\n4. Provide the link chain to Apollo Client\nAfter you define your link chain, you provide it to Apollo Client via the `link` constructor option:\n```js {6} title=\"index.js\"\nimport { ApolloClient, InMemoryCache } from '@apollo/client';\n// ...code from the above example goes here...\nconst client = new ApolloClient({\n  link: splitLink,\n  cache: new InMemoryCache()\n});\n```\n\nIf you provide the `link` option, it takes precedence over the `uri` option (`uri` sets up a default HTTP link chain using the provided URL).\n\n5. Authenticate over WebSocket (optional)\nIt is often necessary to authenticate a client before allowing it to receive subscription results. To do this, you can provide a `connectionParams` option to the `GraphQLWsLink` constructor, like so:\n```js {6-8}\nimport { GraphQLWsLink } from '@apollo/client/link/subscriptions';\nimport { createClient } from 'graphql-ws';\nconst wsLink = new GraphQLWsLink(createClient({\n  url: 'ws://localhost:4000/subscriptions',\n  connectionParams: {\n    authToken: user.authToken,\n  },\n}));\n```\nYour `GraphQLWsLink` passes the `connectionParams` object to your server whenever it connects. Your server receives the `connectionParams` object and can use it to perform authentication, along with any other connection-related tasks.\nExecuting a subscription\nYou use Apollo Client's `useSubscription` Hook to execute a subscription from React. Like useQuery, `useSubscription` returns an object from Apollo Client that contains `loading`, `error`, and `data` properties you can use to render your UI.\nThe following example component uses the subscription we defined earlier to render the most recent comment that's been added to a specified blog post. Whenever the GraphQL server pushes a new comment to the client, the component re-renders with the new comment.\n```jsx\nconst COMMENTS_SUBSCRIPTION = gql`\n  subscription OnCommentAdded($postID: ID!) {\n    commentAdded(postID: $postID) {\n      id\n      content\n    }\n  }\n`;\nfunction LatestComment({ postID }) {\n  const { data, loading } = useSubscription(\n    COMMENTS_SUBSCRIPTION,\n    { variables: { postID } }\n  );\n  return New comment: {!loading && data.commentAdded.content};\n}\n```\nSubscribing to updates for a query\nWhenever a query returns a result in Apollo Client, that result includes a `subscribeToMore` function. You can use this function to execute a followup subscription that pushes updates to the query's original result.\n\nThe `subscribeToMore` function is similar in structure to the fetchMore function that's commonly used for handling pagination. The primary difference is that `fetchMore` executes a followup query, whereas `subscribeToMore` executes a subscription.\n\nAs an example, let's start with a standard query that fetches all of the existing comments for a given blog post:\n```jsx\nconst COMMENTS_QUERY = gql`\n  query CommentsForPost($postID: ID!) {\n    post(postID: $postID) {\n      comments {\n        id\n        content\n      }\n    }\n  }\n`;\nfunction CommentsPageWithData({ params }) {\n  const result = useQuery(\n    COMMENTS_QUERY,\n    { variables: { postID: params.postID } }\n  );\n  return ;\n}\n```\nLet's say we want our GraphQL server to push an update to our client as soon as a new comment is added to the post. First we need to define the subscription that Apollo Client will execute when the `COMMENTS_QUERY` returns:\n`jsx\nconst COMMENTS_SUBSCRIPTION = gql`\n  subscription OnCommentAdded($postID: ID!) {\n    commentAdded(postID: $postID) {\n      id\n      content\n    }\n  }\n`;`\nNext, we modify our `CommentsPageWithData` function to add a `subscribeToNewComments` property to the `CommentsPage` component it returns. This property is a function that will be responsible for calling `subscribeToMore` after the component mounts.\n```jsx {10-25}\nfunction CommentsPageWithData({ params }) {\n  const { subscribeToMore, ...result } = useQuery(\n    COMMENTS_QUERY,\n    { variables: { postID: params.postID } }\n  );\nreturn (\n    \n        subscribeToMore({\n          document: COMMENTS_SUBSCRIPTION,\n          variables: { postID: params.postID },\n          updateQuery: (prev, { subscriptionData }) => {\n            if (!subscriptionData.data) return prev;\n            const newFeedItem = subscriptionData.data.commentAdded;\n\n\n```        return Object.assign({}, prev, {\n          post: {\n            comments: [newFeedItem, ...prev.post.comments]\n          }\n        });\n      }\n    })\n  }\n/>\n```\n\n\n);\n}\n```\nIn the example above, we pass three options to `subscribeToMore`:\n\n`document` indicates the subscription to execute.\n`variables` indicates the variables to include when executing the subscription.\n`updateQuery` is a function that tells Apollo Client how to combine the query's currently cached result (`prev`) with the `subscriptionData` that's pushed by our GraphQL server. The return value of this function completely replaces the current cached result for the query.\n\nFinally, in our definition of `CommentsPage`, we tell the component to `subscribeToNewComments` when it mounts:\n`jsx\nexport function CommentsPage({subscribeToNewComments}) {\n  useEffect(() => subscribeToNewComments(), []);\n  return <>...\n}`\n`useSubscription` API reference\n\nNote: If you're using React Apollo's `Subscription` render prop component, the option/result details listed below are still valid (options are component props and results are passed into the render prop function). The only difference is that a `subscription` prop (which holds a GraphQL subscription document parsed into an AST by `gql`) is also required.\n\nOptions\nThe `useSubscription` Hook accepts the following options:\n\nResult\nAfter being called, the `useSubscription` Hook returns a result object with the following properties:\n\nThe older `subscriptions-transport-ws` library\nIf your server uses `subscriptions-transport-ws` instead of the newer `graphql-ws` library, you need to make a few changes to how you set up your link:\n\n\nInstead of `npm install graphql-ws`:\n`bash\nnpm install subscriptions-transport-ws`\n\n\nInstead of `import { createClient } from 'graphql-ws'`:\n`js\nimport { SubscriptionClient } from 'subscriptions-transport-ws'`\n\n\nInstead of `import { GraphQLWsLink } from '@apollo/client/link/subscriptions'`:\n`js\nimport { WebSocketLink } from '@apollo/client/link/ws'`\n\n\nThe options you pass to `new SubscriptionClient` differ slightly from those passed to `createClient`:\n\nThe first argument passed to the `SubscriptionClient` constructor is the URL for your subscription server.\nThe `connectionParams` option is nested under an options object called `options` instead of being at the top level. (You can also pass the `new SubscriptionClient` constructor arguments directly to `new WebSocketLink`.)\nSee the subscriptions-transport-ws README for complete `SubscriptionClient` API docs.\n\n\n\nAfter you create your `wsLink`, everything else in this article still applies: `useSubscription`, `subscribeToMore`, and split links work exactly the same way for both implementations.\nThe following is an example of a typical `WebSocketLink` initialization:\n```js\nimport { WebSocketLink } from \"@apollo/client/link/ws\";\nimport { SubscriptionClient } from \"subscriptions-transport-ws\";\nconst wsLink = new WebSocketLink(\n  new SubscriptionClient(\"ws://localhost:4000/subscriptions\", {\n    connectionParams: {\n      authToken: user.authToken\n    }\n  })\n);\n```",
    "tag": "apollo-client"
  },
  {
    "title": "Example",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/defer.mdx",
    "content": "\ntitle: \"Using the @defer directive in Apollo Client\"\ndescription: Receive query response data incrementally\n\n\nThe `@defer` directive is currently at the General Availability stage in Apollo Client, and is available by installing `@apollo/client@latest`. If you have feedback on it, please let us know via GitHub issues.\n\nBeginning with version `3.7.0`, Apollo Client Web provides preview support for the @defer directive. This directive enables your queries to receive data for specific fields incrementally, instead of receiving all field data at the same time. This is helpful whenever some fields in a query take much longer to resolve than others.\n\nFor a query to defer fields successfully, the queried endpoint must also support the `@defer` directive. Entity-based `@defer` support is also at the General Availability stage in Apollo Router and is compatible with all federation-compatible subgraph libraries.\n\nExample\nLet's say we're building a social media application that can quickly fetch a user's basic profile information, but retrieving that user's friends takes longer.\nGraphQL allows us to declare all the fields our UI requires in a single query, but this also means that our query will be as slow as the field that takes the longest to resolve. The `@defer` directive allows us to mark parts of the query that are not necessary for our app's initial render which will be resolved once it becomes available.\nTo achieve this, we apply the `@defer` directive to an in-line fragment that contains all slow-resolving fields related to friend data:\n```graphql\nquery PersonQuery($personId: ID!) {\n  person(id: $personId) {\n    # Basic fields (fast)\n    id\n    firstName\n    lastName\n\n\n```# highlight-start\n# Friend fields (slower)\n... @defer {\n  friends {\n    id\n  }\n}\n# highlight-end\n```\n\n\n}\n}\n```\nUsing this syntax, if the queried server supports `@defer`, our client can receive the \"Basic fields\" in an initial response payload, followed by a supplementary payload containing the \"Friend fields\".\nLet's look at an example in React. Here's we can assume `GET_PERSON` is the above query, `PersonQuery`, with a deferred list of friends' `id`s:\n```tsx title=\"index.js\"\nimport { gql, useQuery } from \"@apollo/client\";\nfunction App() {\n  const { loading, error, data } = useQuery(GET_PERSON, {\n    variables: {\n      id: 1,\n    },\n  });\nif (loading) return \"Loading...\";\n  if (error) return `Error! ${error.message}`;\nreturn (\n    <>\n      Welcome, {data.firstName} {data.lastName}!\n      \nFriends list\n        {data.friends ? (\n          \n            {data.friends.map((id) => (\n              {id}\n            ))}\n          \n        ) : null}\n      \n\n  );\n}\n```\nWhen our call to the `useQuery` hook first resolves with an initial payload of data, `loading` will go from `true` to `false` and `firstName` and `lastName` will be populated with the values from the server. Our deferred fields will not exist as keys on `data` yet, so we must add conditional logic that checks for their presence. When subsequent chunks of deferred data arrive, `useQuery` will re-render (`loading` remains `false` between re-renders from deferred multipart responses) and `data` will include the deferred data as they arrive.\nFor this reason, `@defer` can be thought of as a tool to improve initial rendering speeds when some slower data will be displayed below the fold or offscreen. In this case, we're rendering the friends list inside a `<details>` element which is closed by default, avoiding any layout shift as the `friends` data arrives.\nUsing with code generation\nIf you currently use GraphQL Code Generator for your codegen needs, note that it doesn't yet support the use of the `@defer` directive in the code output.",
    "tag": "apollo-client"
  },
  {
    "title": "Prerequisites",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/mutations.mdx",
    "content": "\ntitle: Mutations in Apollo Client\ndescription: Modify data with the useMutation hook\n\nimport MutationOptions3 from '../../shared/mutation-options.mdx';\nimport MutationResult3 from '../../shared/mutation-result.mdx';\nNow that we've learned how to query data from our backend with Apollo Client, the natural next step is to learn how to modify back-end data with mutations.\nThis article demonstrates how to send updates to your GraphQL server with the `useMutation` hook. You'll also learn how to update the Apollo Client cache after executing a mutation, and how to track loading and error states.\n\nTo follow along with the examples below, open up our starter project and sample GraphQL server on CodeSandbox. You can view the completed version of the app here.\n\nPrerequisites\nThis article assumes you're familiar with building basic GraphQL mutations. If you need a refresher, we recommend that you\nread this guide.\nThis article also assumes that you've already set up Apollo Client and have wrapped your React app in an `ApolloProvider` component. For help with those steps, get started.\nExecuting a mutation\nThe `useMutation` React hook is the primary API for executing mutations in an Apollo application.\nTo execute a mutation, you first call `useMutation` within a React component and pass it the mutation you want to execute, like so:\n```jsx {13} title=\"my-component.jsx\"\nimport { gql, useMutation } from '@apollo/client';\n// Define mutation\nconst INCREMENT_COUNTER = gql`# Increments a back-end counter and gets its resulting value\n  mutation IncrementCounter {\n    currentValue\n  }`;\nfunction MyComponent() {\n  // Pass mutation to useMutation\n  const [mutateFunction, { data, loading, error }] = useMutation(INCREMENT_COUNTER);\n}\n```\nAs shown above, you use the `gql` function to parse the mutation string into a GraphQL document that you then pass to `useMutation`.\nWhen your component renders, `useMutation` returns a tuple that includes:\n\nA mutate function that you can call at any time to execute the mutation\nUnlike `useQuery`, `useMutation` doesn't execute its operation automatically on render. Instead, you call this mutate function.\n\n\nAn object with fields that represent the current status of the mutation's execution (`data`, `loading`, etc.)\nThis object is similar to the object returned by the `useQuery` hook. For details, see Result.\n\n\n\nExample\nLet's say we're creating a to-do list application and we want the user to be able to add items to their list. First, we'll create a corresponding GraphQL mutation named `ADD_TODO`. Remember to wrap GraphQL strings in the `gql` function to parse them into query documents:\n```jsx title=\"add-todo.jsx\"\nimport { gql, useMutation } from '@apollo/client';\nconst ADD_TODO = gql`mutation AddTodo($type: String!) {\n    addTodo(type: $type) {\n      id\n      type\n    }\n  }`;\n```\nNext, we'll create a component named `AddTodo` that represents the submission form for the to-do list. Inside it, we'll pass our\n`ADD_TODO` mutation to the `useMutation` hook:\n```jsx {3,13} title=\"add-todo.jsx\"\nfunction AddTodo() {\n  let input;\n  const [addTodo, { data, loading, error }] = useMutation(ADD_TODO);\nif (loading) return 'Submitting...';\n  if (error) return `Submission error! ${error.message}`;\nreturn (\n    \n {\n          e.preventDefault();\n          addTodo({ variables: { type: input.value } });\n          input.value = '';\n        }}\n      >\n         {\n            input = node;\n          }}\n        />\n        Add Todo\n\n\n  );\n}\n```\nIn this example, our form's `onSubmit` handler calls the mutate function (named `addTodo`) that's returned by the `useMutation` hook. This tells Apollo Client to execute the mutation by sending it to our GraphQL server.\n\nNote that this behavior differs from useQuery, which executes its operation as soon as its component renders. This is because mutations are more commonly executed in response to a user action (such as submitting a form in this case).\n\nProviding options\nThe `useMutation` hook accepts an `options` object as its second parameter. Here's an example that provides some default values for GraphQL `variables`:\n`js\nconst [addTodo, { data, loading, error }] = useMutation(ADD_TODO, {\n  variables: {\n    type: \"placeholder\",\n    someOtherVariable: 1234,\n  },\n});`\n\nAll supported options are listed in Options.\n\nYou can also provide options directly to your mutate function, as demonstrated in this snippet from the example above:\n`js\naddTodo({\n  variables: {\n    type: input.value,\n  },\n});`\nHere, we use the `variables` option to provide the values of any GraphQL variables that our mutation requires (specifically, the `type` of the created to-do item).\nOption precedence\nIf you provide the same option to both `useMutation` and your mutate function, the mutate function's value takes precedence. In the specific case of the `variables` option, the two objects are merged shallowly, which means any variables provided only to `useMutation` are preserved in the resulting object. This helps you set default values for variables.\nIn the example snippets above, `input.value` would override `\"placeholder\"` as the value of the `type` variable. The value of `someOtherVariable` (`1234`) would be preserved.\nTracking mutation status\nIn addition to a mutate function, the `useMutation` hook returns an object that represents the current state of the mutation's execution. The fields of this object (listed in Result) include booleans that indicate whether the mutate function has been `called` yet, and whether the mutation's result is currently `loading`.\nThe example above destructures the `loading` and `error` fields from this object to render the `AddTodo` component differently depending on the mutation's current status:\n`jsx\nif (loading) return 'Submitting...';\nif (error) return `Submission error! ${error.message}`;`\n\nThe `useMutation` hook also supports `onCompleted` and `onError` options if you prefer to use callbacks. See the API reference.\n\nResetting mutation status\nThe mutation result object returned by `useMutation` includes a reset function:\n`js\nconst [login, { data, loading, error, reset }] = useMutation(LOGIN_MUTATION);`\nCall `reset` to reset the mutation's result to its initial state (i.e., before the mutate function was called). You can use this to enable users to dismiss mutation result data or errors in the UI.\n\nCalling `reset` does not remove any cached data returned by the mutation's execution. It only affects the state associated with the `useMutation` hook, causing the corresponding component to rerender.\n\n```js {2,15}\nfunction LoginPage () {\n  const [login, { error, reset }] = useMutation(LOGIN_MUTATION);\nreturn (\n    <>\n      \n\n\nLogin\n\n      {\n        error &&\n         reset()}\n        />\n      }\n  \n  );\n}\n```\nUpdating local data\nWhen you execute a mutation, you modify back-end data. Usually, you then want to update your locally cached data to reflect the back-end modification. For example, if you execute a mutation to add an item to your to-do list, you also want that item to appear in your cached copy of the list.\nSupported methods\nThe most straightforward way to update your local data is to refetch any queries that might be affected by the mutation. However, this method requires additional network requests.\nIf your mutation returns all of the objects and fields that it modified, you can update your cache directly without making any followup network requests. However, this method increases in complexity as your mutations become more complex.\nIf you're just getting started with Apollo Client, we recommend refetching queries to update your cached data. After you get that working, you can improve your app's responsiveness by updating the cache directly.\nRefetching queries\nIf you know that your app usually needs to refetch certain queries after a particular mutation, you can include a `refetchQueries` array in that mutation's options:\n`js {3-6}\n// Refetches two queries after mutation completes\nconst [addTodo, { data, loading, error }] = useMutation(ADD_TODO, {\n  refetchQueries: [\n    {query: GET_POST}, // DocumentNode object parsed with gql\n    'GetComments' // Query name\n  ],\n});`\nEach element in the `refetchQueries` array is one of the following:\n\nAn object referencing `query` (a `DocumentNode` object parsed with the `gql` function) and `variables`\nThe name of a query you've previously executed, as a string (e.g., `GetComments`)\nTo refer to queries by name, make sure each of your app's queries have a unique name.\n\nEach included query is executed with its most recently provided set of variables.\nYou can provide the `refetchQueries` option either to `useMutation` or to the mutate function. For details, see Option precedence.\nNote that in an app with tens or hundreds of different queries, it can be challenging to determine exactly which queries to refetch after a particular mutation.\nUpdating the cache directly\nInclude modified objects in mutation responses\nIn most cases, a mutation response should include any object(s) the mutation modified. This enables Apollo Client to normalize those objects and cache them according to their `__typename` and `id` fields (by default).\nIn the example above, our `ADD_TODO` mutation might return a `Todo` object with the following structure:\n`json\n{\n  \"__typename\": \"Todo\",\n  \"id\": \"5\",\n  \"type\": \"groceries\"\n}`\n\nApollo Client automatically adds the `__typename` field to every object in your queries and mutations by default.\n\nUpon receiving this response object, Apollo Client caches it with key `Todo:5`. If a cached object already exists with this key, Apollo Client overwrites any existing fields that are also included in the mutation response (other existing fields are preserved).\nReturning modified objects like this is a helpful first step to keeping your cache in sync with your backend. However, it isn't always sufficient. For example, a newly cached object isn't automatically added to any list fields that should now include that object. To accomplish this, you can define an update function.\nThe `update` function\nWhen a mutation's response is insufficient to update all modified fields in your cache (such as certain list fields), you can define an `update` function to apply manual changes to your cached data after a mutation.\nYou provide an `update` function to `useMutation`, like so:\n```jsx {12-29}\nconst GET_TODOS = gql`\n  query GetTodos {\n    todos {\n      id\n    }\n  }\n`;\nfunction AddTodo() {\n  let input;\n  const [addTodo] = useMutation(ADD_TODO, {\n    update(cache, { data: { addTodo } }) {\n      cache.modify({\n        fields: {\n          todos(existingTodos = []) {\n            const newTodoRef = cache.writeFragment({\n              data: addTodo,\n              fragment: gql`fragment NewTodo on Todo {\n                  id\n                  type\n                }`\n            });\n            return [...existingTodos, newTodoRef];\n          }\n        }\n      });\n    }\n  });\nreturn (\n    \n {\n          e.preventDefault();\n          addTodo({ variables: { type: input.value } });\n          input.value = \"\";\n        }}\n      >\n         {\n            input = node;\n          }}\n        />\n        Add Todo\n\n\n  );\n}\n```\nAs shown, the `update` function is passed a `cache` object that represents the Apollo Client cache. This object provides access to cache API methods like `readQuery`/`writeQuery`, `readFragment`/`writeFragment`, `modify`, and `evict`. These methods enable you to execute GraphQL operations on the cache as though you're interacting with a GraphQL server.\n\nLearn more about supported cache functions in Interacting with cached data.\n\nThe `update` function is also passed an object with a `data` property that contains the result of the mutation. You can use this value to update the cache with `cache.writeQuery`, `cache.writeFragment`, or `cache.modify`.\n\nIf your mutation specifies an optimistic response, your `update` function is called twice: once with the optimistic result, and again with the actual result of the mutation when it returns.\n\nWhen the `ADD_TODO` mutation executes in the above example, the newly added and returned `addTodo` object is automatically saved into the cache before the `update` function runs. However, the cached list of `ROOT_QUERY.todos` (which is watched by the `GET_TODOS` query) is not automatically updated. This means that the `GET_TODOS` query isn't notified of the new `Todo` object, which in turn means that the query doesn't update to show the new item.\nTo address this, we use `cache.modify` to surgically insert or delete items from the cache, by running \"modifier\" functions. In the example above, we know the results of the `GET_TODOS` query are stored in the `ROOT_QUERY.todos` array in the cache, so we use a `todos` modifier function to update the cached array to include a reference to the newly added `Todo`. With the help of `cache.writeFragment`, we get an internal reference to the added `Todo`, then append that reference to the `ROOT_QUERY.todos` array.\nAny changes you make to cached data inside of an `update` function are automatically broadcast to queries that are listening for changes to that data. Consequently, your application's UI will update to reflect these updated cached values.\nRefetching after `update`\nAn `update` function attempts to replicate a mutation's back-end modifications in your client's local cache. These cache modifications are broadcast to all affected active queries, which updates your UI automatically. If the `update` function does this correctly, your users see the latest data immediately, without needing to await another network round trip.\nHowever, an `update` function might get this replication wrong by setting a cached value incorrectly. You can \"double check\" your `update` function's modifications by refetching affected active queries. To do so, you first provide an `onQueryUpdated` callback function to your mutate function:\n`js {6-11}\naddTodo({\n  variables: { type: input.value },\n  update(cache, result) {\n    // Update the cache as an approximation of server-side mutation effects\n  },\n  onQueryUpdated(observableQuery) {\n    // Define any custom logic for determining whether to refetch\n    if (shouldRefetchQuery(observableQuery)) {\n      return observableQuery.refetch();\n    }\n  },\n})`\nAfter your `update` function completes, Apollo Client calls `onQueryUpdated` once for each active query with cached fields that were updated. Within `onQueryUpdated`, you can use any custom logic to determine whether you want to refetch the associated query.\nTo refetch a query from `onQueryUpdated`, call `return observableQuery.refetch()`, as shown above. Otherwise, no return value is required. If a refetched query's response differs from your `update` function's modifications, your cache and UI are both automatically updated again. Otherwise, your users see no change.\nOccasionally, it might be difficult to make your `update` function update all relevant queries. Not every mutation returns enough information for the `update` function to do its job effectively. To make absolutely sure a certain query is included, you can combine `onQueryUpdated` with `refetchQueries: [...]`:\n`js\naddTodo({\n  variables: { type: input.value },\n  update(cache, result) {\n    // Update the cache as an approximation of server-side mutation effects.\n  },\n  // Force ReallyImportantQuery to be passed to onQueryUpdated.\n  refetchQueries: [\"ReallyImportantQuery\"],\n  onQueryUpdated(observableQuery) {\n    // If ReallyImportantQuery is active, it will be passed to onQueryUpdated.\n    // If no query with that name is active, a warning will be logged.\n  },\n})`\nIf `ReallyImportantQuery` was already going to be passed to `onQueryUpdated` thanks to your `update` function, then it will only be passed once. Using `refetchQueries: [\"ReallyImportantQuery\"]` just guarantees the query will be included.\nIf you find you've included more queries than you expected, you can skip or ignore a query by returning `false` from `onQueryUpdated`, after examining the `ObservableQuery` to determine that it doesn't need refetching. Returning a `Promise` from `onQueryUpdated` causes the final `Promise<FetchResult<TData>>` for the mutation to await any promises returned from `onQueryUpdated`, eliminating the need for the legacy `awaitRefetchQueries: true` option.\nTo use the `onQueryUpdated` API without performing a mutation, try the client.refetchQueries method. In the standalone `client.refetchQueries` API, the `refetchQueries: [...]` mutation option is called `include: [...]`, and the `update` function is called `updateCache` for clarity. Otherwise, the same internal system powers both `client.refetchQueries` and refetching queries after a mutation.\n`useMutation` API\nSupported options and result fields for the `useMutation` hook are listed below.\nMost calls to `useMutation` can omit the majority of these options, but it's\nuseful to know they exist. To learn about the `useMutation` hook API in more\ndetail with usage examples, see the API reference.\nOptions\nThe `useMutation` hook accepts the following options:\n\nResult\nThe `useMutation` result is a tuple with a mutate function in the first position and an object representing the mutation result in the second position.\nYou call the mutate function to trigger the mutation from your UI.\n\nNext steps\nThe `useQuery` and `useMutation` hooks together represent Apollo Client's core\nAPI for performing GraphQL operations. Now that you're familiar with both,\nyou can begin to take advantage of Apollo Client's full feature set, including:\n\nOptimistic UI: Learn how to improve perceived performance by returning an optimistic response before your mutation result comes back from the server.\nLocal state: Use Apollo Client to manage the entirety of your application's local state by executing client-side mutations.\n",
    "tag": "apollo-client"
  },
  {
    "title": "Error types",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/error-handling.mdx",
    "content": "\ntitle: Handling operation errors\nApollo Client can encounter a variety of errors when executing operations on your GraphQL server. Apollo Client helps you handle these errors according to their type, enabling you to show appropriate information to the user when an error occurs.\nError types\nExecuting GraphQL operations on a remote server can result in GraphQL errors or network errors.\nGraphQL errors\nThese are errors related to the server-side execution of a GraphQL operation. They include:\n\nSyntax errors (e.g., a query was malformed)\nValidation errors (e.g., a query included a schema field that doesn't exist)\nResolver errors (e.g., an error occurred while attempting to populate a query field)\n\nIf a syntax error or validation error occurs, your server doesn't execute the operation at all because it's invalid. If resolver errors occur, your server can still return partial data.\n\nLearn more about GraphQL errors in the Apollo Server documentation.\n\nIf a GraphQL error occurs, your server includes it in the `errors` array of its response to Apollo Client:\n\n`json\n{\n  \"errors\": [\n    {\n      \"message\": \"Cannot query field \\\"nonexistentField\\\" on type \\\"Query\\\".\",\n      \"locations\": [\n        {\n          \"line\": 2,\n          \"column\": 3\n        }\n      ],\n      \"extensions\": {\n        \"code\": \"GRAPHQL_VALIDATION_FAILED\",\n        \"exception\": {\n          \"stacktrace\": [\n            \"GraphQLError: Cannot query field \\\"nonexistentField\\\" on type \\\"Query\\\".\",\n            \"...additional lines...\"\n          ]\n        }\n      }\n    }\n  ],\n  \"data\": null\n}`\n\nApollo Client then adds those errors to the error.graphQLErrors array returned by your useQuery call (or whichever operation hook you used).\nIf a GraphQL error prevents Apollo Server from executing your operation at all, it responds with a `4xx` status code. Apollo Server responds with a `200` status code if resolver errors occurred but the response still includes partial data.\nPartial data with resolver errors\nAn operation that produces resolver errors might also return partial data. This means that some (but not all) of the data your operation requested is included in your server's response. Apollo Client ignores partial data by default, but you can override this behavior by setting a GraphQL error policy.\nNetwork errors\nThese are errors encountered while attempting to communicate with your GraphQL server, usually resulting in a `4xx` or `5xx` response status code (and no data).\nWhen a network error occurs, Apollo Client adds it to the error.networkError field returned by your useQuery call (or whichever operation hook you used).\nYou can add retry logic and other advanced network error handling to your application with Apollo Link.\nGraphQL error policies\nIf a GraphQL operation produces one or more resolver errors, your server's response might still include partial data in the `data` field:\n`json\n{\n  \"data\": {\n    \"getInt\": 12,\n    \"getString\": null\n  },\n  \"errors\": [\n    {\n      \"message\": \"Failed to get string!\"\n      // ...additional fields...\n    }\n  ]\n}`\nBy default, Apollo Client throws away partial data and populates the error.graphQLErrors array of your useQuery call (or whichever hook you're using). You can instead use these partial results by defining an error policy for your operation.\nApollo Client supports the following error policies for an operation:\n| Policy   | Description                                                                                                                                                                                                                                                                                             |\n| -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `none`   | If the response includes GraphQL errors, they are returned on `error.graphQLErrors` and the response `data` is set to `undefined` even if the server returns `data` in its response. This means network errors and GraphQL errors result in a similar response shape. This is the default error policy. |\n| `ignore` | `graphQLErrors` are ignored (`error.graphQLErrors` is not populated), and any returned `data` is cached and rendered as if no errors occurred.                                                                                                                                                        |\n| `all`    | Both `data` and `error.graphQLErrors` are populated, enabling you to render both partial results and error information.                                                                                                                                                                                 |\nSetting an error policy\nSpecify an error policy in the options object you provide your operation hook (such as `useQuery`), like so:\n```tsx {9}\nconst MY_QUERY = gql`\n  query WillFail {\n    badField # This field's resolver produces an error\n    goodField # This field is populated successfully\n  }\n`;\nfunction ShowingSomeErrors() {\n  const { loading, error, data } = useQuery(MY_QUERY, { errorPolicy: \"all\" });\nif (loading) return loading...;\n  return (\n    \nGood: {data.goodField}\n\n        Bad:{\" \"}\n        {error.graphQLErrors.map(({ message }, i) => (\n          {message}\n        ))}\n      \n\n  );\n}\n```\nThis example uses the `all` error policy to render both partial data and error information whenever applicable.\nAdvanced error handling with Apollo Link\nThe Apollo Link library enables you to configure advanced handling of errors that occur while executing GraphQL operations.\nAs a recommended first step, you can add an onError link to your link chain that receives error details and acts on them accordingly.\nThe example below passes the `ApolloClient` constructor a link chain with two links:\n\nAn `onError` link that checks for `graphQLErrors` or a `networkError` in the server's response. It logs the details of whichever error(s) it finds.\nAn `HttpLink` that sends each GraphQL operation to your server.\nThis is the chain's terminating link.\n\n\n```tsx\nimport { ApolloClient, HttpLink, InMemoryCache, from } from \"@apollo/client\";\nimport { onError } from \"@apollo/client/link/error\";\nconst errorLink = onError(({ graphQLErrors, networkError }) => {\n  if (graphQLErrors)\n    graphQLErrors.forEach(({ message, locations, path }) =>\n      console.log(\n        `[GraphQL error]: Message: ${message}, Location: ${locations}, Path: ${path}`\n      )\n    );\n  if (networkError) console.log(`[Network error]: ${networkError}`);\n});\nconst httpLink = new HttpLink({ uri: 'http://localhost:4000/graphql' })\nconst client = new ApolloClient({\n  cache: new InMemoryCache(),\n  link: from([errorLink, httpLink]),\n});\n```\n\nRetrying operations\nApollo Link helps you retry failed operations that might be resolved by a followup attempt. We recommend different links depending on the type of error that occurred:\n\nThe `onError` link for GraphQL errors\nThe `RetryLink` for network errors\n\nOn GraphQL errors\nThe `onError` link can retry a failed operation based on the type of GraphQL error that's returned. For example, when using token-based authentication, you might want to automatically handle re-authentication when the token expires.\nTo retry an operation, you `return forward(operation)` in your `onError` function. Here's an example:\n```js {18}\nonError(({ graphQLErrors, networkError, operation, forward }) => {\n  if (graphQLErrors) {\n    for (let err of graphQLErrors) {\n      switch (err.extensions.code) {\n        // Apollo Server sets code to UNAUTHENTICATED\n        // when an AuthenticationError is thrown in a resolver\n        case \"UNAUTHENTICATED\":\n          // Modify the operation context with a new token\n          const oldHeaders = operation.getContext().headers;\n          operation.setContext({\n            headers: {\n              ...oldHeaders,\n              authorization: getNewToken(),\n            },\n          });\n          // Retry the request, returning the new observable\n          return forward(operation);\n      }\n    }\n  }\n// To retry on network errors, we recommend the RetryLink\n  // instead of the onError link. This just logs the error.\n  if (networkError) {\n    console.log(`[Network error]: ${networkError}`);\n  }\n});\n```\n\nIf your retried operation also results in errors, those errors are not passed to your `onError` link to prevent an infinite loop of operations. This means that an `onError` link can retry a particular operation only once.\n\nIf you don't want to retry an operation, your `onError` link's function should return nothing.\nOn network errors\nTo retry operations that encounter a network error, we recommend adding a `RetryLink` to your link chain. This link enables you to configure retry logic like exponential backoff and total number of attempts.\nSee the documentation for RetryLink.\n`onError` link options",
    "tag": "apollo-client"
  },
  {
    "title": "Recommended \u2705",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/operation-best-practices.mdx",
    "content": "\ntitle: GraphQL query best practices\ndescription: Operation naming, GraphQL variables, and more\n\nWhen creating queries and mutations, follow these best practices to get the most out of both GraphQL and Apollo tooling.\nName all operations\nThese two queries fetch the same data:\n```graphql\nRecommended \u2705\nquery GetBooks {\n  books {\n    title\n  }\n}\nNot recommended \u274c\nquery {\n  books {\n    title\n  }\n}\n```\nThe first query is named `GetBooks`. The second query is anonymous.\nYou should define a name for every GraphQL operation in your application. Doing so provides the following benefits:\n\nYou clarify the purpose of each operation for both yourself and your teammates.\nYou avoid unexpected errors when combining multiple operations in a single query document (an anonymous operation can only appear alone).\nYou improve debugging output in both client and server code, helping you identify exactly which operation is causing issues.\nApollo Studio provides helpful operation-level metrics, which require named operations.\n\nUse GraphQL variables to provide arguments\nThese two queries can both fetch a `Dog` object with ID `\"5\"`:\n```graphql {2-3,10-11}\nRecommended \u2705\nquery GetDog($dogId: ID!) {\n  dog(id: $dogId) {\n    name\n    breed\n  }\n}\nNot recommended \u274c\nquery GetDog {\n  dog(id: \"5\") {\n    name\n    breed\n  }\n}\n```\nThe first query uses a variable (`$dogId`) for the value of the `dog` field's required argument. This means you can use the query to fetch a `Dog` object with any ID, making it much more reusable.\nYou pass variable values to `useQuery` (or `useMutation`) like so:\n```js {11-15} title=\"dog.tsx\"\nconst GET_DOG = gql`\n  query GetDog($dogId: ID!) {\n    dog(id: $dogId) {\n      name\n      breed\n    }\n  }\n`;\nfunction Dog({ id }) {\n  const { loading, error, data } = useQuery(GET_DOG, {\n    variables: {\n      dogId: id\n    },\n  });\n  // ...render component...\n}\n```\nDisadvantages of hardcoded GraphQL arguments\nBeyond reusability, hardcoded arguments have other disadvantages relative to variables:\nReduced cache effectiveness\nIf two otherwise identical queries have different hardcoded argument values, they're considered entirely different operations by your GraphQL server's cache. The cache enables your server to skip parsing and validating operations that it's encountered before, improving performance.\nThe server-side cache also powers features like automatic persisted queries and query plans in a federated gateway. Hardcoded arguments reduce the performance gains of these features and take up useful space in the cache.\nReduced information privacy\nThe value of a GraphQL argument might include sensitive information, such as an access token or a user's personal info. If this information is included in a query string, it's cached with the rest of that query string.\nVariable values are not included in query strings. You can also specify which variable values (if any) are included in metrics reporting to Apollo Studio.\nQuery only the data you need, where you need it\nOne of GraphQL's biggest advantages over a traditional REST API is its support for declarative data fetching. Each component can (and should) query exactly the fields it requires to render, with no superfluous data sent over the network.\nIf instead your root component executes a single, enormous query to obtain data for all of its children, it might query on behalf of components that aren't even rendered given the current state. This can result in a delayed response, and it drastically reduces the likelihood that the query's result can be reused by a server-side response cache.\nIn the large majority of cases, a query such as the following should be divided into multiple queries that are distributed among the appropriate components:\n\n```graphql\nNot recommended \u274c\nquery GetGlobalStatus {\n  stores {\n    id\n    name\n    address {\n      street\n      city\n    }\n    employees {\n      id\n    }\n    manager {\n      id\n    }\n  }\n  products {\n    id\n    name\n    price {\n      amount\n      currency\n    }\n  }\n  employees {\n    id\n    role\n    name {\n      firstName\n      lastName\n    }\n    store {\n      id\n    }\n  }\n  offers {\n    id\n    products {\n      id\n    }\n    discount {\n      discountType\n      amount\n    }\n  }\n}\n```\n\n\nIf you have collections of components that are always rendered together, you can use fragments to distribute the structure of a single query between them. See Colocating fragments.\nIf you're querying a list field that returns more items than your component needs to render, you should paginate that field.\n\nUse fragments to encapsulate related sets of fields\nGraphQL fragments are sets of fields you can share across multiple operations. Here's an example declaration:\n```graphql\nRecommended \u2705\nfragment NameParts on Person {\n  title\n  firstName\n  middleName\n  lastName\n}\n```\nIt's likely that multiple queries in an app require a person's full name. This `NameParts` fragment helps keep those queries consistent, readable, and short:\n```graphql\nRecommended \u2705\nquery GetAttendees($eventId: ID!) {\n  attendees(id: $eventId) {\n    id\n    rsvp\n    ...NameParts # Include all fields from the NameParts fragment\n  }\n}\n```\nAvoid excessive or illogical fragments\nIf you use too many fragments, your queries might become less readable:\n\n```graphql\nUse caution \u26a0\ufe0f\nquery GetAttendees($eventId: ID!) {\n  attendees(id: $eventId) {\n    id\n    rsvp\n    ...NameParts\n    profile {\n      ...VisibilitySettings\n      events {\n        ...EventSummary\n      }\n      avatar {\n        ...ImageDetails\n      }\n    }\n  }\n}\n```\n\nAdditionally, only define fragments for sets of fields that share a logical semantic relationship. Don't create a fragment just because multiple queries happen to share certain fields:\n```graphql\nRecommended \u2705\nfragment NameParts on Person {\n  title\n  firstName\n  middleName\n  lastName\n}\nNot recommended \u274c\nfragment SharedFields on Country {\n  population\n  neighboringCountries {\n    capital\n    rivers {\n      name\n    }\n  }\n}\n```\nQuery global data and user-specific data separately\nSome fields return the exact same data regardless of which user queries them:\n```graphql\nReturns all elements of the periodic table\nquery GetAllElements {\n  elements {\n    atomicNumber\n    name\n    symbol\n  }\n}\n```\nOther fields return different data depending on which user queries them:\n```graphql\nReturns the current user's documents\nquery GetMyDocuments {\n  myDocuments {\n    id\n    title\n    url\n    updatedAt\n  }\n}\n```\nTo improve the performance of your server-side response cache, fetch these two types of fields in separate queries whenever possible. By doing so, your server can cache just a single response for a query like `GetAllElements` above, while caching separate responses for each user that executes `GetMyDocuments`.\nSet your app's `name` and `version` for metrics reporting (paid)\n\nThis recommendation is most pertinent to Apollo Studio organizations with a paid plan, however it can be helpful for all apps.\n\nThe constructor of `ApolloClient` accepts the `name` and `version` options:\n`js {4-5}\nconst client = new ApolloClient({\n  uri: 'http://localhost:4000/graphql',\n  cache: new InMemoryCache(),\n  name: 'MarketingSite',\n  version: '1.2'\n});`\nIf you specify these values, Apollo Client automatically adds them to each operation request as HTTP headers (`apollographql-client-name` and `apollographql-client-version`).",
    "tag": "apollo-client"
  },
  {
    "title": "`client.refetchQueries`",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/source/data/refetching.mdx",
    "content": "\ntitle: Refetching queries in Apollo Client\nimport RefetchQueriesOptions from '../../shared/refetchQueries-options.mdx';\nApollo Client allows you to make local modifications to your GraphQL data by updating the cache, but sometimes it's more straightforward to update your client-side GraphQL data by refetching queries from the server.\nIn theory, you could refetch every active query after a client-side update, but you can save time and network bandwidth by refetching queries more selectively. The `InMemoryCache` helps you determine which active queries might have been invalidated by recent cache updates.\nLocal cache updates and refetching work especially well in combination: your application can display the results of local cache modifications immediately, while also refetching in the background to obtain the very latest data from the server. The UI is then rerendered only if there are differences between local data and refetched data.\nRefetching is especially common after a mutation, so mutate functions accept options like refetchQueries and onQueryUpdated to specify which queries should be refetched, and how.\nTo selectively refetch queries outside of a mutation, you instead use the `refetchQueries` method of `ApolloClient`, which is documented here.\n`client.refetchQueries`\n\nThis method is new in Apollo Client 3.4.\n\nRefetch options\n\nRefetch results\nThe `client.refetchQueries` method collects the `TResult` results returned by `onQueryUpdated`, defaulting to `TResult = Promise<ApolloQueryResult<any>>` if `onQueryUpdated` is not provided. It combines those results into a single `Promise<TResolved[]>` using `Promise.all(results)`.\n\nThanks to the `Promise`-unwrapping behavior of `Promise.all`, this `TResolved` type is often the same type as `TResult`, except when `TResult` is a `PromiseLike<TResolved>` or a `boolean`.\n\nThe returned `Promise` object has two other useful properties:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `queries`\n\n`ObservableQuery[]`\n\n\n\nAn array of `ObservableQuery` objects that were refetched.\n\n\n\n\n\n\n###### `results`\n\n`TResult[]`\n\n\n\nAn array of results that were either returned by `onQueryUpdated`, or provided by default in the absence of `onQueryUpdated`, including pending promises.\n\nIf `onQueryUpdated` returns `false` for a given query, no result is provided for that query.\n\nIf `onQueryUpdated` returns `true`, the resulting `Promise>` is included in the `results` array instead of `true`.\n\n\n\n\n\nThese two arrays parallel each other: they have the same length, and `results[i]` is the result produced by `onQueryUpdated` when called with the `ObservableQuery` found at `queries[i]`, for any index `i`.\nRefetch recipes\nRefetching a specific query\nTo refetch a specific query by name, use the `include` option by itself:\n`ts\nawait client.refetchQueries({\n  include: [\"SomeQueryName\"],\n});`\nThe `include` option can also refetch a specific query using its `DocumentNode`:\n`ts\nawait client.refetchQueries({\n  include: [SOME_QUERY],\n});`\nRefetching all queries\nTo refetch all active queries, pass the `\"active\"` shorthand for `include`:\n`ts\nawait client.refetchQueries({\n  include: \"active\",\n});`\nTo refetch all queries managed by Apollo Client (even those with no observers, or whose components are currently unmounted), pass `\"all\"` for `include`:\n`ts\nawait client.refetchQueries({\n  include: \"all\", // Consider using \"active\" instead!\n});`\nRefetching queries affected by cache updates\nYou can refetch queries affected by cache updates performed in the `updateCache` callback:\n`ts\nawait client.refetchQueries({\n  updateCache(cache) {\n    cache.evict({ fieldName: \"someRootField\" });\n  },\n});`\nThis refetches any queries that depend on `Query.someRootField`, without requiring you to know in advance which queries might be included. Any combination of cache operations (`writeQuery`, `writeFragment`, `modify`, `evict`, etc.) is allowed within `updateCache`.\nUpdates performed by `updateCache` persist in the cache by default. You can perform them in a temporary optimistic layer instead, if you want them to be discarded immediately after `client.refetchQueries` is done observing them, leaving the cache unchanged:\n```ts\nawait client.refetchQueries({\n  updateCache(cache) {\n    cache.evict({ fieldName: \"someRootField\" });\n  },\n// Evict Query.someRootField only temporarily, in an optimistic layer.\n  optimistic: true,\n});\n```\nAnother way to \"update\" the cache without actually changing cache data is to use `cache.modify` and its `INVALIDATE` sentinel object:\n`ts\nawait client.refetchQueries({\n  updateCache(cache) {\n    cache.modify({\n      fields: {\n        someRootField(value, { INVALIDATE }) {\n          // Update queries that involve Query.someRootField, without actually\n          // changing its value in the cache.\n          return INVALIDATE;\n        },\n      },\n    });\n  },\n});`\n\nBefore `client.refetchQueries` was introduced, the `INVALIDATE` sentinel was not very useful, because invalidated queries with `fetchPolicy: \"cache-first\"` would typically re-read unchanged results, and therefore decide not to perform a network request. The `client.refetchQueries` method makes this invalidation system more accessible to application code, so you can control the refetching behavior of invalidated queries.\n\nIn all of the examples above, whether we use `include` or `updateCache`, `client.refetchQueries` refetches affected queries from the network and includes the resulting `Promise<ApolloQueryResult<any>>` results in the `Promise<TResolved[]>` returned by `client.refetchQueries`.\nIf a particular query is included both by `include` and by `updateCache`, that query is refetched only once. In other words, the `include` option is a good way to make sure certain queries are always included, no matter which queries are included by `updateCache`.\nRefetching selectively\nIn development, you probably want to make sure the appropriate queries are getting refetched, rather than blindly refetching them. To intercept each query before refetching, you can specify an `onQueryUpdated` callback:\n```ts\nconst results = await client.refetchQueries({\n  updateCache(cache) {\n    cache.evict({ fieldName: \"someRootField\" });\n  },\nonQueryUpdated(observableQuery) {\n    // Logging and/or debugger breakpoints can be useful in development to\n    // understand what client.refetchQueries is doing.\n    console.log(`Examining ObservableQuery ${observableQuery.queryName}`);\n    debugger;\n\n\n```// Proceed with the default refetching behavior, as if onQueryUpdated\n// was not provided.\nreturn true;\n```\n\n\n},\n});\nresults.forEach(result => {\n  // These results will be ApolloQueryResult objects, after all\n  // results have been refetched from the network.\n});\n```\nNotice how adding `onQueryUpdated` in this example did not change the refetching behavior of `client.refetchQueries`, allowing us to use `onQueryUpdated` purely for diagnostic or debugging purposes.\nIf you want to skip certain queries that would otherwise be included, return `false` from `onQueryUpdated`:\n```ts\nawait client.refetchQueries({\n  updateCache(cache) {\n    cache.evict({ fieldName: \"someRootField\" });\n  },\nonQueryUpdated(observableQuery, { complete, result, missing }) {\n    console.log(`Examining ObservableQuery ${\n      observableQuery.queryName\n    } whose latest result is ${JSON.stringify(result)} which is ${\n      complete ? \"complete\" : \"incomplete\"\n    }`);\n\n\n```if (shouldIgnoreQuery(observableQuery)) {\n  return false;\n}\n\n// Refetch the query unconditionally from the network.\nreturn true;\n```\n\n\n},\n});\n```\nIn case the `ObservableQuery` does not provide enough information, you can also examine the latest `result` for the query, along with information about its `complete`ness and `missing` fields, using the `Cache.DiffResult` object passed as the second parameter to `onQueryUpdated`:\n```ts\nawait client.refetchQueries({\n  updateCache(cache) {\n    cache.evict({ fieldName: \"someRootField\" });\n  },\nonQueryUpdated(observableQuery, { complete, result, missing }) {\n    if (shouldIgnoreQuery(observableQuery)) {\n      return false;\n    }\n\n\n```if (complete) {\n  // Update the query according to its chosen FetchPolicy, rather than\n  // refetching it unconditionally from the network.\n  return observableQuery.reobserve();\n}\n\n// Refetch the query unconditionally from the network.\nreturn true;\n```\n\n\n},\n});\n```\nBecause `onQueryUpdated` has the ability to filter queries dynamically, it also pairs well with the bulk `include` options mentioned above:\n```ts\nawait client.refetchQueries({\n  // Include all active queries by default, which may be ill-advised unless\n  // you also use onQueryUpdated to filter those queries.\n  include: \"active\";\n// Called once for every active query, allowing dynamic filtering:\n  onQueryUpdated(observableQuery) {\n    return !shouldIngoreQuery(observableQuery);\n  },\n});\n```\nHandling refetch errors\nIn the examples above, we `await client.refetchQueries(...)` to find out the final `ApolloQueryResult<any>` results for all the refetched queries. This combined promise is created with `Promise.all`, so a single failure rejects the entire `Promise<TResolved[]>`, potentially hiding other successful results. If this is a problem, you can use the `queries` and `results` arrays returned by\n`client.refetchQueries` instead of (or in addition to) `await`ing the `Promise`:\n```ts\nconst { queries, results } = client.refetchQueries({\n  // Specific client.refetchQueries options are not relevant to this example.\n});\nconst finalResults = await Promise.all(\n  results.map((result, i) => {\n    return Promise.resolve(result).catch(error => {\n      console.error(`Error refetching query ${queries[i].queryName}: ${error}`);\n      return null; // Silence this Promise rejection.\n    });\n  })\n});\n```\nIn the future, just as additional input options may be added to the `client.refetchQueries` method, additional properties may be added to its result object, supplementing its `Promise`-related properties and the `queries` and `results` arrays.\nIf you discover that some specific additional `client.refetchQueries` input options or result properties would be useful, please feel free to open an issue or start a discussion explaining your use case(s).\nCorresponding `client.mutate` options\nFor refetching after a mutation, `client.mutate` supports options similar to `client.refetchQueries`, which you should use instead of `client.refetchQueries`, because it's important for refetching logic to happen at specific times during the mutation process.\nFor historical reasons, `client.mutate` options have slightly different names from the new `client.refetchQueries` options, but their internal implementation is substantially the same, so you can translate between them using the following table:\n| `client.mutate(options)` | | `client.refetchQueries(options)` |\n| - | - | - |\n| options.refetchQueries | \u21d4 | `options.include` |\n| options.update | \u21d4 | `options.updateCache` |\n| options.onQueryUpdated | \u21d4 | `options.onQueryUpdated` |",
    "tag": "apollo-client"
  },
  {
    "title": "useFragment-options.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/useFragment-options.mdx",
    "content": "\n\n\nName /Type\nDescription\n\n\n\n\n\n\n**Operation options**\n\n\n\n\n\n\n###### `from`\n\n`string | StoreObject | Reference`\n\n\n\n**Required.** An object containing a `__typename` and primary key fields (such as `id`) identifying the entity object from which the fragment will be retrieved, or a `{ __ref: \"...\" }` reference, or a `string` ID (uncommon).\n\n\n\n\n\n\n###### `fragment`\n\n`DocumentNode`\n\n\n\n**Required.** A GraphQL fragment document parsed into an AST with the `gql` template literal.\n\n\n\n\n\n\n###### `fragmentName`\n\n`string`\n\n\n\nThe name of the fragment defined in the [`fragment`](#fragment) document to use in the call.\n\n**Required** if the `fragment` document includes more than one fragment, optional otherwise.\n\n\n\n\n\n\n###### `optimistic`\n\n`boolean`\n\n\n\nIf `true`, `readFragment` returns optimistic results.\n\nThe default value is `true`.\n\n\n\n\n\n\n###### `variables`\n\n`{ [key: string]: any }`\n\n\n\nAn object containing all of the GraphQL variables your fragment requires.\n\nEach key in the object corresponds to a variable name, and that key's value corresponds to the variable value.\n\n\n\n\n\n\n###### `returnPartialData`\n\n`boolean`\n\n\n\nIf `true`, the query can return _partial_ results from the cache if the cache doesn't contain results for _all_ queried fields.\n\nThe default value is `true`.\n\n\n\n\n\n\n###### `canonizeResults`\n\n`boolean`\n\n\n\nIf `true`, result objects read from the cache will be _canonized_, which means deeply-equal objects will also be `===` (literally the same object), allowing much more efficient comparison of past/present results.\n\nThe default value is `false`.\n\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "query-options.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/query-options.mdx",
    "content": "\n\n\nName /Type\nDescription\n\n\n\n\n\n\n**Operation options**\n\n\n\n\n\n\n###### `query`\n\n`DocumentNode`\n\n\n\nA GraphQL query string parsed into an AST with the `gql` template literal.\n\n**Optional** for the `useQuery` hook, because the query can be provided as the first parameter to the hook. **Required** for the `Query` component.\n\n\n\n\n\n###### `variables`\n\n`{ [key: string]: any }`\n\n\n\nAn object containing all of the GraphQL variables your query requires to execute.\n\nEach key in the object corresponds to a variable name, and that key's value corresponds to the variable value.\n\n\n\n\n\n\n###### `errorPolicy`\n\n`ErrorPolicy`\n\n\n\nSpecifies how the query handles a response that returns both GraphQL errors and partial results.\n\nFor details, see [GraphQL error policies](/react/data/error-handling/#graphql-error-policies).\n\nThe default value is `none`, meaning that the query result includes error details but _not_ partial results.\n\n\n\n\n\n\n###### `onCompleted`\n\n`(data: TData | {}) => void`\n\n\n\nA callback function that's called when your query successfully completes with zero errors (or if `errorPolicy` is `ignore` and partial data is returned).\n\nThis function is passed the query's result `data`.\n\n\n\n\n\n\n###### `onError`\n\n`(error: ApolloError) => void`\n\n\n\nA callback function that's called when the query encounters one or more errors (unless `errorPolicy` is `ignore`).\n\nThis function is passed an [`ApolloError`](https://github.com/apollographql/apollo-client/blob/d96f4578f89b933c281bb775a39503f6cdb59ee8/src/errors/index.ts#L36-L39) object that contains either a `networkError` object or a `graphQLErrors` array, depending on the error(s) that occurred.\n\n\n\n\n\n\n###### `skip`\n\n`boolean`\n\n\n\nIf `true`, the query is _not_ executed. **Not available with `useLazyQuery`.**\n\nThis property is part of Apollo Client's React integration, and it is _not_ available in the [core `ApolloClient` API](/react/api/core/ApolloClient/).\n\nThe default value is `false`.\n\n\n\n\n\n\n**Networking options**\n\n\n\n\n\n\n###### `pollInterval`\n\n`number`\n\n\n\nSpecifies the interval (in milliseconds) at which the query polls for updated results.\n\nThe default value is `0` (no polling).\n\n\n\n\n\n\n###### `notifyOnNetworkStatusChange`\n\n`boolean`\n\n\n\nIf `true`, the in-progress query's associated component re-renders whenever the network status changes or a network error occurs.\n\nThe default value is `false`.\n\n\n\n\n\n\n###### `context`\n\n`Record`\n\n\n\nIf you're using [Apollo Link](/react/api/link/introduction/), this object is the initial value of the `context` object that's passed along your link chain.\n\n\n\n\n\n\n###### `ssr`\n\n`boolean`\n\n\n\nPass `false` to skip executing the query during [server-side rendering](/react/performance/server-side-rendering/).\n\n\n\n\n\n\n###### `client`\n\n`ApolloClient`\n\n\n\nThe instance of `ApolloClient` to use to execute the query.\n\nBy default, the instance that's passed down via context is used, but you can provide a different instance here.\n\n\n\n\n\n\n**Caching options**\n\n\n\n\n\n\n###### `fetchPolicy`\n\n`FetchPolicy`\n\n\n\nSpecifies how the query interacts with the Apollo Client cache during execution (for example, whether it checks the cache for results before sending a request to the server).\n\nFor details, see [Setting a fetch policy](/react/data/queries/#setting-a-fetch-policy).\n\nThe default value is `cache-first`.\n\n\n\n\n\n\n###### `nextFetchPolicy`\n\n`FetchPolicy`\n\n\n\nSpecifies the [`fetchPolicy`](#fetchpolicy) to use for all executions of this query _after_ this execution.\n\nFor example, you can use this to switch back to a `cache-first` fetch policy after using `cache-and-network` or `network-only` for a single execution.\n\n\n\n\n\n\n###### `returnPartialData`\n\n`boolean`\n\n\n\nIf `true`, the query can return _partial_ results from the cache if the cache doesn't contain results for _all_ queried fields.\n\nThe default value is `false`.\n\n\n\n\n\n\n**Deprecated options**\n\n\n\n\n\n\n###### `partialRefetch`\n\n`boolean`\n\n\n\n**Deprecated.** If `true`, causes a query `refetch` if the query result is detected as partial. Setting this option is unnecessary in Apollo Client 3, thanks to a more consistent application of fetch policies. It might be removed in a future release.\n\nThe default value is `false`.\n\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "link-chain.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/link-chain.mdx",
    "content": "```js title=\"index.js\"\nimport { ApolloClient, InMemoryCache, HttpLink, from } from \"@apollo/client\";\nimport { onError } from \"@apollo/client/link/error\";\nconst httpLink = new HttpLink({\n  uri: \"http://localhost:4000/graphql\"\n});\nconst errorLink = onError(({ graphQLErrors, networkError }) => {\n  if (graphQLErrors)\n    graphQLErrors.forEach(({ message, locations, path }) =>\n      console.log(\n        `[GraphQL error]: Message: ${message}, Location: ${locations}, Path: ${path}`,\n      ),\n    );\nif (networkError) console.log(`[Network error]: ${networkError}`);\n});\n// If you provide a link chain to ApolloClient, you\n// don't provide the `uri` option.\nconst client = new ApolloClient({\n  // The `from` function combines an array of individual links\n  // into a link chain\n  link: from([errorLink, httpLink]),\n  cache: new InMemoryCache()\n});",
    "tag": "apollo-client"
  },
  {
    "title": "mutation-options.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/mutation-options.mdx",
    "content": "\n\n\nName /Type\nDescription\n\n\n\n\n\n\n**Operation options**\n\n\n\n\n\n\n###### `mutation`\n\n`DocumentNode`\n\n\n\nA GraphQL query string parsed into an AST with the `gql` template literal.\n\n**Optional** for the `useMutation` hook, because the mutation can also be provided as the first parameter to the hook.\n\n**Required** for the `Mutation` component.\n\n\n\n\n\n###### `variables`\n\n`{ [key: string]: any }`\n\n\n\nAn object containing all of the GraphQL variables your mutation requires to execute.\n\nEach key in the object corresponds to a variable name, and that key's value corresponds to the variable value.\n\n\n\n\n\n\n###### `errorPolicy`\n\n`ErrorPolicy`\n\n\n\nSpecifies how the mutation handles a response that returns both GraphQL errors and partial results.\n\nFor details, see [GraphQL error policies](/react/data/error-handling/#graphql-error-policies).\n\nThe default value is `none`, meaning that the mutation result includes error details but _not_ partial results.\n\n\n\n\n\n\n###### `onCompleted`\n\n`(data?: TData, clientOptions?: BaseMutationOptions) => void`\n\n\n\nA callback function that's called when your mutation successfully completes with zero errors (or if `errorPolicy` is `ignore` and partial data is returned).\n\nThis function is passed the mutation's result `data` and any options passed to the mutation.\n\n\n\n\n\n\n###### `onError`\n\n`(error: ApolloError, clientOptions?: BaseMutationOptions) => void`\n\n\n\nA callback function that's called when the mutation encounters one or more errors (unless `errorPolicy` is `ignore`).\n\nThis function is passed an [`ApolloError`](https://github.com/apollographql/apollo-client/blob/d96f4578f89b933c281bb775a39503f6cdb59ee8/src/errors/index.ts#L36-L39) object that contains either a `networkError` object or a `graphQLErrors` array, depending on the error(s) that occurred, as well as any options passed the mutation.\n\n\n\n\n\n\n###### `onQueryUpdated`\n\n`(observableQuery: ObservableQuery, diff: Cache.DiffResult, lastDiff: Cache.DiffResult | undefined) => boolean | TResult`\n\n\n\n\nOptional callback for intercepting queries whose cache data has been updated by the mutation, as well as any queries specified in the [`refetchQueries: [...]`](#refetchQueries) list passed to `client.mutate`.\n\nReturning a `Promise` from `onQueryUpdated` will cause the final mutation `Promise` to await the returned `Promise`. Returning `false` causes the query to be ignored.\n\n\n\n\n\n\n###### `refetchQueries`\n\n`Array | ((mutationResult: FetchResult) => Array)`\n\n\n\nAn array (or a function that _returns_ an array) that specifies which queries you want to refetch after the mutation occurs.\n\nEach array value can be either:\n\n* An object containing the `query` to execute, along with any `variables`\n* A string indicating the operation name of the query to refetch\n\n\n\n\n\n\n###### `awaitRefetchQueries`\n\n`boolean`\n\n\n\nIf `true`, makes sure all queries included in `refetchQueries` are completed before the mutation is considered complete.\n\nThe default value is `false` (queries are refetched asynchronously).\n\n\n\n\n\n\n###### `ignoreResults`\n\n`boolean`\n\n\n\nIf `true`, the mutation's `data` property is not updated with the mutation's result.\n\nThe default value is `false`.\n\n\n\n\n\n\n**Networking options**\n\n\n\n\n\n\n###### `notifyOnNetworkStatusChange`\n\n`boolean`\n\n\n\nIf `true`, the in-progress mutation's associated component re-renders whenever the network status changes or a network error occurs.\n\nThe default value is `false`.\n\n\n\n\n\n\n###### `client`\n\n`ApolloClient`\n\n\n\nThe instance of `ApolloClient` to use to execute the mutation.\n\nBy default, the instance that's passed down via context is used, but you can provide a different instance here.\n\n\n\n\n\n\n###### `context`\n\n`Record`\n\n\n\nIf you're using [Apollo Link](/react/api/link/introduction/), this object is the initial value of the `context` object that's passed along your link chain.\n\n\n\n\n\n\n**Caching options**\n\n\n\n\n\n\n###### `update`\n\n`(cache: ApolloCache, mutationResult: FetchResult) => void`\n\n\n\nA function used to update the Apollo Client cache after the mutation completes.\n\nFor more information, see [Updating the cache after a mutation](/react/data/mutations#updating-the-cache-after-a-mutation).\n\n\n\n\n\n\n###### `optimisticResponse`\n\n`Object`\n\n\n\nIf provided, Apollo Client caches this temporary (and potentially incorrect) response until the mutation completes, enabling more responsive UI updates.\n\nFor more information, see [Optimistic mutation results](/react/performance/optimistic-ui/).\n\n\n\n\n\n\n###### `fetchPolicy`\n\n`MutationFetchPolicy`\n\n\n\nProvide `no-cache` if the mutation's result should _not_ be written to the Apollo Client cache.\n\nThe default value is `network-only` (which means the result _is_ written to the cache).\n\nUnlike queries, mutations _do not_ support [fetch policies](/react/data/queries/#setting-a-fetch-policy) besides `network-only` and `no-cache`.\n\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "mutation-result.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/mutation-result.mdx",
    "content": "Mutate function:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `mutate`\n\n`(options?: MutationOptions) => Promise`\n\n\n\nA function to trigger the mutation from your UI. You can optionally pass this function any of the following options:\n\n* `awaitRefetchQueries`\n* `context`\n* `fetchPolicy`\n* `onCompleted`\n* `onError`\n* `optimisticResponse`\n* `refetchQueries`\n* `update`\n* `variables`\n* `client`\n\nAny option you pass here overrides any existing value for that option that you passed to `useMutation`.\n\nThe mutate function returns a promise that fulfills with your mutation result.\n\n\n\n\nMutation result:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `data`\n\n`TData`\n\n\n\nThe data returned from your mutation. Can be `undefined` if `ignoreResults` is `true`.\n\n\n\n\n\n###### `loading`\n\n`boolean`\n\n\n\nIf `true`, the mutation is currently in flight.\n\n\n\n\n\n###### `error`\n\n`ApolloError`\n\n\n\nIf the mutation produces one or more errors, this object contains either an array of `graphQLErrors` or a single `networkError`. Otherwise, this value is `undefined`.\n\nFor more information, see [Handling operation errors](/react/data/error-handling/).\n\n\n\n\n\n\n###### `called`\n\n`boolean`\n\n\n\nIf `true`, the mutation's mutate function has been called.\n\n\n\n\n\n\n###### `client`\n\n`ApolloClient`\n\n\n\nThe instance of Apollo Client that executed the mutation.\n\nCan be useful for manually executing followup operations or writing data to the cache.\n\n\n\n\n\n\n###### `reset`\n\n`() => void`\n\n\n\nA function that you can call to reset the mutation's result to its initial, uncalled state.\n\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "subscription-options.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/subscription-options.mdx",
    "content": "| Option | Type | Description |\n| - | - | - |\n| `subscription` | DocumentNode | A GraphQL subscription document parsed into an AST by `graphql-tag`. Optional for the `useSubscription` Hook since the subscription can be passed in as the first parameter to the Hook. Required for the `Subscription` component. |\n| `variables` | { [key: string]: any } | An object containing all of the variables your subscription needs to execute |\n| `shouldResubscribe` | boolean | Determines if your subscription should be unsubscribed and subscribed again when an input to the hook (such as `subscription` or `variables`) changes. |\n| `skip` | boolean | Determines if the current subscription should be skipped. Useful if, for example, variables depend on previous queries and are not ready yet. |\n| `onSubscriptionData` | Deprecated. (options: OnSubscriptionDataOptions<TData>) => any | Allows the registration of a callback function that will be triggered each time the `useSubscription` Hook / `Subscription` component receives data. The callback `options` object param consists of the current Apollo Client instance in `client`, and the received subscription data in `subscriptionData`. |\n| `onData` | (options: OnDataOptions<TData>) => any | Allows the registration of a callback function that will be triggered each time the `useSubscription` Hook / `Subscription` component receives data. The callback `options` object param consists of the current Apollo Client instance in `client`, and the received subscription data in `data`. |\n| `onError` | (error: ApolloError) => void | Allows the registration of a callback function that will be triggered each time the `useSubscription` Hook / `Subscription` component receives an error. |\n| `onSubscriptionComplete` | Deprecated. () => void | Allows the registration of a callback function that will be triggered when the `useSubscription` Hook / `Subscription` component completes the subscription. |\n| `onComplete` | () => void | Allows the registration of a callback function that will be triggered each time the `useSubscription` Hook / `Subscription` component completes the subscription. |\n| `fetchPolicy` | FetchPolicy | How you want your component to interact with the Apollo cache. For details, see Setting a fetch policy. |\n| `context` | Record<string, any> | Shared context between your component and your network interface (Apollo Link). |",
    "tag": "apollo-client"
  },
  {
    "title": "refetchQueries-options.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/refetchQueries-options.mdx",
    "content": "The `client.refetchQueries` method take an `options` object that conforms to the\nfollowing TypeScript interface:\n```ts\ninterface RefetchQueriesOptions<\n  TCache extends ApolloCache,\n  TResult = Promise>,\n\n{\n  updateCache?: (cache: TCache) => void;\n  include?: Array | \"all\" | \"active\";\n  onQueryUpdated?: (\n    observableQuery: ObservableQuery,\n    diff: Cache.DiffResult,\n    lastDiff: Cache.DiffResult | undefined,\n  ) => boolean | TResult;\n  optimistic?: boolean;\n}\n```\n\nThese fields are described below:\n\n\n\nName /Type\nDescription\n\n\n\n\n\n\n###### `updateCache`\n\n`(cache: TCache) => void`\n\n\n\nOptional function that updates cached fields to trigger refetches of queries that include those fields.\n\n\n\n\n\n\n###### `include`\n\n`Array | \"all\" | \"active\"`\n\n\n\nOptional array specifying queries to refetch. Each element can be either a query's string name or a `DocumentNode` object.\n\nAnalogous to the [`options.refetchQueries`](/react/data/mutations/#options) array for mutations.\n\nPass `\"active\"` (or `\"all\"`) as a shorthand to refetch all (active) queries.\n\n\n\n\n\n\n###### `onQueryUpdated`\n\n`(observableQuery: ObservableQuery, diff: Cache.DiffResult, lastDiff: Cache.DiffResult | undefined) => boolean | TResult`\n\n\n\n\nOptional callback function that's called once for each `ObservableQuery` that's either affected by `options.updateCache` or listed in `options.include` (or both).\n\nIf `onQueryUpdated` is not provided, the default implementation returns the\nresult of calling `observableQuery.refetch()`. When `onQueryUpdated` is\nprovided, it can dynamically decide whether (and how) each query should be\nrefetched.\n\nReturning `false` from `onQueryUpdated` prevents the associated query\nfrom being refetched.\n\n\n\n\n\n\n###### `optimistic`\n\n`boolean`\n\n\n\nIf `true`, the `options.updateCache` function is executed on a temporary optimistic layer of `InMemoryCache`, so its modifications can be discarded from the cache after observing which fields it invalidated.\n\nDefaults to `false`, meaning `options.updateCache` updates the cache in a\nlasting way.\n\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "useSuspenseQuery-result.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/useSuspenseQuery-result.mdx",
    "content": "\n\n\nName /Type\nDescription\n\n\n\n\n\n\n**Operation result**\n\n\n\n\n\n\n###### `data`\n\n`TData`\n\n\n\nAn object containing the result of your GraphQL query after it completes.\n\nThis value might be `undefined` if a query results in one or more errors (depending on the query's `errorPolicy`).\n\n\n\n\n\n\n###### `error`\n\n`ApolloError`\n\n\n\nIf the query produces one or more errors, this object contains either an array of `graphQLErrors` or a single `networkError`. Otherwise, this value is `undefined`.\n\nThis property can be ignored when using the default `errorPolicy` or an `errorPolicy` of `none`. The hook will throw the error instead of setting this property.\n\n\n\n\n\n\n**Network info**\n\n\n\n\n\n\n###### `client`\n\n`ApolloClient`\n\n\n\nThe instance of Apollo Client that executed the query.\n\nCan be useful for manually executing followup queries or writing data to the cache.\n\n\n\n\n\n\n**Helper functions**\n\n\n\n\n\n\n###### `refetch`\n\n`(variables?: Partial) => Promise`\n\n\n\nA function that enables you to re-execute the query, optionally passing in new `variables`.\n\nTo guarantee that the refetch performs a network request, its `fetchPolicy` is set to `network-only` (unless the original query's `fetchPolicy` is `no-cache` or `cache-and-network`, which also guarantee a network request). \n\nCalling this function will cause the component to re-suspend, unless the `suspensePolicy` option is set to `initial`.\n\n\n\n\n\n\n###### `fetchMore`\n\n`({ query?: DocumentNode, variables?: TVariables, updateQuery: Function}) => Promise`\n\n\n\nA function that helps you fetch the next set of results for a [paginated list field](/react/pagination/core-api/).\n\nCalling this function will cause the component to re-suspend, unless the `suspensePolicy` option is set to `initial`.\n\n\n\n\n\n\n###### `subscribeToMore`\n\n`(options: { document: DocumentNode, variables?: TVariables, updateQuery?: Function, onError?: Function}) => () => void`\n\n\n\nA function that enables you to execute a [subscription](/react/data/subscriptions/), usually to subscribe to specific fields that were included in the query.\n\nThis function returns _another_ function that you can call to terminate the subscription.\n\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "useSuspenseQuery-options.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/useSuspenseQuery-options.mdx",
    "content": "\n\n\nName /Type\nDescription\n\n\n\n\n\n\n**Operation options**\n\n\n\n\n\n\n###### `variables`\n\n`{ [key: string]: any }`\n\n\n\nAn object containing all of the GraphQL variables your query requires to execute.\n\nEach key in the object corresponds to a variable name, and that key's value corresponds to the variable value.\n\n\n\n\n\n\n###### `errorPolicy`\n\n`ErrorPolicy`\n\n\n\nSpecifies how the query handles a response that returns both GraphQL errors and partial results.\n\nFor details, see [GraphQL error policies](/react/data/error-handling/#graphql-error-policies).\n\nThe default value is `none`, which causes the hook to throw the error.\n\n\n\n\n\n**Networking options**\n\n\n\n\n\n\n###### `suspensePolicy`\n\n`SuspensePolicy`\n\n\n\nDetermines whether the component should re-suspend when refetching data. Set to\n`initial` to avoid re-suspending the component on a refetch.\n\nThe default value is `always`, which will cause the component to always\nre-suspend when refetching data.\n\n\n\n\n\n###### `context`\n\n`Record`\n\n\n\nIf you're using [Apollo Link](/react/api/link/introduction/), this object is the initial value of the `context` object that's passed along your link chain.\n\n\n\n\n\n\n###### `client`\n\n`ApolloClient`\n\n\n\nThe instance of `ApolloClient` to use to execute the query.\n\nBy default, the instance that's passed down via context is used, but you can provide a different instance here.\n\n\n\n\n\n\n**Caching options**\n\n\n\n\n\n\n###### `fetchPolicy`\n\n`SuspenseQueryHookFetchPolicy`\n\n\n\nSpecifies how the query interacts with the Apollo Client cache during execution (for example, whether it checks the cache for results before sending a request to the server).\n\nFor details, see [Setting a fetch\npolicy](/react/data/queries/#setting-a-fetch-policy). This hook only supports\nthe `cache-first`, `network-only`, `no-cache`, and `cache-and-network` fetch\npolicies.\n\nThe default value is `cache-first`.\n\n\n\n\n\n\n###### `nextFetchPolicy`\n\n`SuspenseQueryHookFetchPolicy`\n\n\n\nSpecifies the [`fetchPolicy`](#fetchpolicy) to use for all executions of this query _after_ this execution.\n\nFor example, you can use this to switch back to a `cache-first` fetch policy after using `cache-and-network` or `network-only` for a single execution.\n\n\n\n\n\n\n###### `returnPartialData`\n\n`boolean`\n\n\n\nIf `true`, the query can return _partial_ results from the cache if the cache doesn't contain results for _all_ queried fields.\n\nThe default value is `false`.\n\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "query-result.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/query-result.mdx",
    "content": "\n\n\nName /Type\nDescription\n\n\n\n\n\n\n**Operation data**\n\n\n\n\n\n\n###### `data`\n\n`TData`\n\n\n\nAn object containing the result of your GraphQL query after it completes.\n\nThis value might be `undefined` if a query results in one or more errors (depending on the query's `errorPolicy`).\n\n\n\n\n\n\n###### `previousData`\n\n`TData`\n\n\n\nAn object containing the result from the most recent _previous_ execution of this query.\n\nThis value is `undefined` if this is the query's first execution.\n\n\n\n\n\n\n###### `error`\n\n`ApolloError`\n\n\n\nIf the query produces one or more errors, this object contains either an array of `graphQLErrors` or a single `networkError`. Otherwise, this value is `undefined`.\n\nFor more information, see [Handling operation errors](/react/data/error-handling/).\n\n\n\n\n\n\n###### `variables`\n\n`{ [key: string]: any }`\n\n\n\nAn object containing the variables that were provided for the query.\n\n\n\n\n\n\n**Network info**\n\n\n\n\n\n\n###### `loading`\n\n`boolean`\n\n\n\nIf `true`, the query is still in flight and results have not yet been returned.\n\n\n\n\n\n\n###### `networkStatus`\n\n`NetworkStatus`\n\n\n\nA number indicating the current network state of the query's associated request. [See possible values.](https://github.com/apollographql/apollo-client/blob/d96f4578f89b933c281bb775a39503f6cdb59ee8/src/core/networkStatus.ts#L4)\n\nUsed in conjunction with the [`notifyOnNetworkStatusChange`](#notifyonnetworkstatuschange) option.\n\n\n\n\n\n\n###### `client`\n\n`ApolloClient`\n\n\n\nThe instance of Apollo Client that executed the query.\n\nCan be useful for manually executing followup queries or writing data to the cache.\n\n\n\n\n\n\n###### `called`\n\n`boolean`\n\n\n\nIf `true`, the associated lazy query has been executed.\n\nThis field is only present on the result object returned by [`useLazyQuery`](/react/data/queries/#executing-queries-manually).\n\n\n\n\n\n\n**Helper functions**\n\n\n\n\n\n\n###### `refetch`\n\n`(variables?: Partial) => Promise`\n\n\n\nA function that enables you to re-execute the query, optionally passing in new `variables`.\n\nTo guarantee that the refetch performs a network request, its `fetchPolicy` is set to `network-only` (unless the original query's `fetchPolicy` is `no-cache` or `cache-and-network`, which also guarantee a network request).\n\nSee also [Refetching](/react/data/queries/#refetching).\n\n\n\n\n\n\n###### `fetchMore`\n\n`({ query?: DocumentNode, variables?: TVariables, updateQuery: Function}) => Promise`\n\n\n\nA function that helps you fetch the next set of results for a [paginated list field](/react/pagination/core-api/).\n\n\n\n\n\n\n###### `startPolling`\n\n`(interval: number) => void`\n\n\n\nA function that instructs the query to begin re-executing at a specified interval (in milliseconds).\n\n\n\n\n\n\n###### `stopPolling`\n\n`() => void`\n\n\n\nA function that instructs the query to stop polling after a previous call to `startPolling`.\n\n\n\n\n\n\n###### `subscribeToMore`\n\n`(options: { document: DocumentNode, variables?: TVariables, updateQuery?: Function, onError?: Function}) => () => void`\n\n\n\nA function that enables you to execute a [subscription](/react/data/subscriptions/), usually to subscribe to specific fields that were included in the query.\n\nThis function returns _another_ function that you can call to terminate the subscription.\n\n\n\n\n\n\n###### `updateQuery`\n\n`(mapFn: (previousResult: TData, options: { variables: TVariables }) => TData) => void`\n\n\n\nA function that enables you to update the query's cached result without executing a followup GraphQL operation.\nSee [using updateQuery and updateFragment](/react/caching/cache-interaction/#using-updatequery-and-updatefragment) for additional information.\n\n\n",
    "tag": "apollo-client"
  },
  {
    "title": "useFragment-result.mdx",
    "source": "https://github.com/apollographql/apollo-client/tree/main/docs/shared/useFragment-result.mdx",
    "content": "\n\n\nName /Type\nDescription\n\n\n\n\n\n\n**Operation result**\n\n\n\n\n\n\n###### `data`\n\n`TData`\n\n\n\nAn object containing the data for a given GraphQL fragment.\n\nThis value might be `undefined` if a query results in one or more errors (depending on the query's `errorPolicy`).\n\n\n\n\n\n\n###### `complete`\n\n`boolean`\n\n\n\nA boolean indicating whether the data returned for the fragment is complete. When `false`, the `missing` field should explain which fields were responsible for the incompleteness.\n\n\n\n\n\n\n###### `missing`\n\n`MissingTree`\n\n\n\nA tree of all `MissingFieldError` messages reported during fragment reading, where the branches of the tree indicate the paths of the errors within the query result.\n\n\n\n",
    "tag": "apollo-client"
  }
]