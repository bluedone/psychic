[
  {
    "title": "Developing Supabase Docs",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/DEVELOPERS.md",
    "content": "Developing Supabase Docs\nGetting started\nThanks for your interest in Supabase docs and for wanting to contribute! Before you begin, read the\ncode of conduct and check out the\nexisting issues.\nThis document describes how to set up your development environment to contribute to Supabase docs.\nFor a complete run-down on how all of our tools work together, see the main DEVELOPERS.md. That readme describes how to get set up locally in lots of detail, including minimum requirements, our Turborepo setup, installing packages, sharing components across projects, and more. This readme deals specifically with the docs site.\nLocal setup\nsupabase.com/docs is a Next.JS site. You can get setup by following the same steps for all of our other Next.JS projects:\n\nFollow the steps outlined in the Local Development section of the main DEVELOPERS.md\nIf you work at Supabase, run `dev:secrets:pull` to pull down the internal environment variables. If you're a community member, create a `.env` file and add this line to it: `NEXT_PUBLIC_IS_PLATFORM=false`\nStart the local docs site by navigating to `/apps/docs` and running `npm run dev`\nVisit http://localhost:3001/docs in your browser - don't forget to append the `/docs` to the end\nYour local site should look exactly like https://supabase.com/docs\n\nTypes of documentation\nhttps://supabase.com/docs has several different kinds of documentation, all coming from different sources.\nGuides\nThe primary, instructional type of content. Basically anything that lives on the `https://supabase.com/docs/guides` route. This includes Guides for Auth, Database, Storage, Realtime, Edge Functions, as well as general resources, self-hosting instructions, and integrations. These are all .mdx files \u2014\u00a0a combination of Markdown and Javascript.\nThings to know\nHere's a simple example `.mdx` Guide, and here is the source on Github.\nSome things to note:\n\nThe files need to import a Layout at the top\nThe files need to export a `Page` at the bottom with the `<Layout>` component\nThe files frontmatter is stored in `const meta = {}`. You should always include `title` and `description`.\nYou can write Markdown as you normally would, but you can also write regular Javascript and JSX. Note the `examples` array that we iterate over.\nAny Javascript variables you use in these files need to be exported in order to be used (i.e., `export const examples = []`).\n\nUsing components\nYou can use any standard React components in these `.mdx` files without having to explicitly import them in each file. All components get imported in a common components file and can be used in any `.mdx` file. Components can also be \"intercepted\" and modified via this file. Note how we're intercepting the `h2`, `h3` and `code` tags and modifying them before converting the `mdx` to `html`.\nReference docs for client libraries\nWe maintain client libraries for Javascript and Flutter/Dart (with more to come). These reference docs document every object and method available for developers to use. The are assembled from different sources and work much differently than the `.mdx` Guides we just looked at.\nThe client libraries are essentially wrappers around the clients for the various tools we use \u2014\u00a0GoTrue, PostgREST, Storage, Functions, and Realtime. The easiest way to describe how the things fit together is to look at an example and trace where the various pieces of information are coming from.\nExample\nLet's look at the `updateUser()` function in the `supabase-js` library.\nCommon file\nSeveral pieces of information for this function come from a common file where we store information shared by all libraries.\n\nid \u2014\u00a0used to identify this function\ntitle - the human-readable title\nslug \u2014 the url slug\nproduct - the Supabase tool or product that \"owns\" this function. Since `updateUser()` is an auth function, its product is `auth`\ntype \u2014\u00a0`updateUser()` is a function and marked as such, but we can also have sections of markdown interspersed with these function definitions.\n\nWhen a new function is added, this info would need to be manually added to the common file.\nFunction Parameters\nThe `updateUser()` function takes one parameter: `attributes`. The details for this parameter live in the GoTrue client library, referenced via a `$ref` property in the `supabase-js` spec file. Here, the `$ref` property is pointing to the actual function definition in the `gotrue-js` library. The accepted values for the `attributes` parameter come from the type definition.\nThese individual library spec files are fetched via this Makefile, and get transformed to combine the information we need (params, types, etc). Unless you're a library maintainer, you shouldn't need to worry about this part of the process.\nIf you are a library maintainer, the last important note about these library files is that the Makefile pulls from the `gh-pages` branch of the client library repo. Here's an example of the realtime-js spec file. Updating something like function params or returns, the process is:\n\nGet your changes merged to `master` in your library\nThis will kick off an action that automatically updates the spec file in the library's `gh-pages` branch\nRun `make` in `/spec` of the `supabase/supabase` repo. This will regenerate all of the `tsdoc` files that the docs site uses\nYou should now see the changes you've made in the docs site locally\n\nFunction Examples\nThe `updateUser()` function has three examples listed with it. The examples are stored along with the `$ref` property in the supabase_js_v2 spec file.\nRendering in Next.JS\nThese reference docs are rendered by Next.JS via a dynamic route using a [...slug.tsx]. Here, we use the library spec file and the common file to output the info you see on the page.\nOther reference docs\nThe reference docs for the Supabase Management API and the Supabase CLI are a little more straightforward than the client libraries. Both files also have a common file which handles things like `title`, `id` and `slug`. Both also have a spec file detailing things like parameters, descriptions, and responses (Management API / CLI)\nOn the Next.JS side of things, these work almost exactly the same as the client libaries with a dynamic [...slug.tsx].\nMisc\nSearch",
    "tag": "supabase"
  },
  {
    "title": "Reference Docs",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/",
    "content": "Reference Docs\nSupabase Reference Docs\nMaintainers\nIf you are a maintainer of any tools in the Supabase ecosystem, you can use this site to provide documentation for the tools & libraries that you maintain.\nTypes of docs\nThere are many types of docs:\n\nGuides: teach developers how to use a product. \"I have XX problem, how do I solve it?\"\nTutorials: walk-throughs, have a large outcome. \"Build a React application with Supabase\".\nExplanations: teach developers about a broad topic. \"What is a database?\"\nReference: technical descriptions of tools and how to use them. \"What errors does the API return?\"\n\nIn these docs, you should focus only on the fourth type: \"Reference Docs\".\nVersioning\nAll tools have versioned docs, which are kept in separate folders. For example, the CLI has the following folders and files:\n\n`cli`: the \"next\" release.\n`cli_spec`: contains the DocSpec for the \"next\" release (see below).\n`cli_versioned_docs`: a version of the documentation for every release (including the most current version).\n`cli_versioned_sidebars`: a version of the sidebar for every release (including the most current version).\n\nWhen you release a new version of a tool, you should also release a new version of the docs. You can do this via the command line. For example, if you just released the CLI version `1.0.1`:\n`npm run cli:version 1.0.1`\nDocSpec\nWe use documentation specifications which can be used to generate human-readable docs.\n\nOpenAPI: for documenting API endpoints.\nSDKSpec (custom to Supabase): for SDKs and client libraries.\nConfigSpec (custom to Supabase): for configuration options.\nCLISpec (custom to Supabase): for CLI commands and usage.\n\nThe benefit of using custom specifications is that we can generate many other types from a strict schema (eg, HTML and manpages).",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/self-hosting-storage/introduction.mdx",
    "content": "\nid: introduction\ntitle: Introduction\nhideTitle: true\n\n\n\n\nSelf-Hosting Storage\n\n\n\n\nAn S3 compatible object storage service that integrates with Postgres.\n\nUses Postgres as it's datastore for storing metadata\nAuthorization rules are written as Postgres Row Level Security policies\nIntegrates with S3 as the storage backend (with more in the pipeline!)\nExtremely lightweight and performant\n\n\n\n\n\n```### Client libraries\n\n- [JavaScript](https://github.com/supabase/storage-js)\n- [Dart](https://github.com/supabase/storage-dart)\n\n### Additional links\n\n- [Source code](https://github.com/supabase/storage-api)\n- [Known bugs and issues](https://github.com/supabase/storage-js/issues)\n- [Storage guides](/docs/guides/storage)\n- [OpenAPI docs](https://supabase.github.io/storage-api/)\n- [Why we built a new object storage service](https://supabase.com/blog/supabase-storage)\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "installing.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/dart/installing.mdx",
    "content": "\nid: installing\ntitle: 'Installing'\nslug: installing\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/supabase.yml\n\nInstall from pub.dev\n\n\n\n\n```You can install Supabase package from [pub.dev](https://pub.dev/packages/supabase_flutter)\n```\n\n\n\n\n\n\n```<Tabs\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"flutter\"\n>\n  <TabPanel id=\"flutter\" label=\"Flutter\">\n\n    ```sh Terminal\n    flutter pub add supabase_flutter\n    ```\n\n  </TabPanel>\n  <TabPanel id=\"dart\" label=\"Other Dart Project\">\n\n    ```sh Terminal\n    dart pub add supabase\n    ```\n\n  </TabPanel>\n</Tabs>\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/dart/introduction.mdx",
    "content": "\nid: introduction\ntitle: Introduction\nhideTitle: true\n\n\n\n\nFlutter Client Library\nsupabase-flutter\n\n\n\n\nThis reference documents every object and method available in Supabase's Flutter\nlibrary,\u00a0[supabase-flutter](https://pub.dev/packages/supabase_flutter). You can\nuse\u00a0supabase-flutter to interact with your Postgres database, listen to database changes, invoke\nDeno Edge Functions, build login and user management functionality, and manage large files.\n\nWe also provide a [supabase](https://pub.dev/packages/supabase) package for non-Flutter projects.",
    "tag": "supabase"
  },
  {
    "title": "Upgrade the client library",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/dart/v0/upgrade-guide.mdx",
    "content": "\nid: upgrade-guide\ntitle: Upgrade to supabase-flutter v1\ndescription: 'Learn how to upgrade to supabase-flutter v1.'\n\nsupabase-flutter focuses on improving the developer experience and making it easier to use. This guide demonstrates how to upgrade from supabase-flutter v0 to v1.\nUpgrade the client library\n\n\nUpdate the package in your pubspec.yaml file.\n\n\n`yaml\nsupabase_flutter: ^1.0.0`\n\n\nError handling\n\n\nThe way supabase-flutter throws error has changed in v1. In v0, errors were returned as a response. In v1, errors are thrown as exceptions. This makes it more intuitive as a Flutter developer to handle errors.\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nfinal res = await supabase.from('my_table').select().execute();\nfinal error = res.error;\nif (error != null) {\n  // handle error\n}\nfinal data = res.data;`\n\n\n`dart\ntry {\n    final data = supabase.from('my_table').select();\n} catch (error) {\n    // handle error\n}`\n\n\n\n\nAuth classes and methods\nUsage of `SupabaseAuthState` and `SupabaseAuthRequiredState` classes\n\n\nIn v0, `SupabaseAuthState` and `SupabaseAuthRequiredState` were required to handle automatic token refresh and to listen to auth state change. In v1, `SupabaseAuthState` and `SupabaseAuthRequiredState` are deprecated, and token refresh will happen automatically just by initializing Supabase. onAuthStateChange can be used to action on auth state change.\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n```dart\nawait Supabase.initialize(\n  url: 'SUPABASE_URL',\n  anonKey: 'SUPABASE_ANON_KEY',\n);\n...\nclass AuthState extends SupabaseAuthState {\n  ...\n}\n...\nclass AuthRequiredState extends SupabaseAuthState {\n  ...\n}\n```\n\n\n`dart\nawait Supabase.initialize(\n  url: 'SUPABASE_URL',\n  anonKey: 'SUPABASE_ANON_KEY',\n);`\n\n\n\n\nListening to auth state change\n\n\n`onAuthStateChange` now returns a `Stream`.\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n```dart\nfinal authSubscription = supabase.auth.onAuthStateChange((event, session) {\n  // handle auth state change\n});\n// Unsubscribe when no longer needed\nauthSubscription.data?.unsubscribe();\n```\n\n\n```dart\nfinal authSubscription = supabase.auth.onAuthStateChange.listen((data) {\n      final AuthChangeEvent event = data.event;\n      final Session? session = data.session;\n      // handle auth state change\n    });\n// Unsubscribe when no longer needed\nauthSubscription.cancel();\n```\n\n\n\n\nSign in with email and password\n\n\n`signIn()` has been deprecated in favor of more explicit method signatures to help with type hinting. Previously it was difficult for developers to know what they were missing (e.g., a lot of developers didn't realize they could use passwordless magic links).\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nawait supabase.auth.signIn(email: email, password: password);`\n\n\n`dart\nawait supabase.auth.signInWithPassword(email: email, password: password);`\n\n\n\n\n\n\nSign in with magic link\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nawait supabase.auth.signIn(email: email);`\n\n\n`dart\nawait supabase.auth.signInWithOtp(email: email);`\n\n\n\n\n\n\nSign in with a third-party OAuth provider\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nawait supabase.auth.signInWithProvider(\n  Provider.github,\n  options: AuthOptions(\n      redirectTo: kIsWeb\n          ? null\n          : 'io.supabase.flutter://reset-callback/'),\n);`\n\n\n`dart\nawait supabase.auth.signInWithOAuth(\n  Provider.github,\n  redirectTo: kIsWeb ? null : 'io.supabase.flutter://reset-callback/',\n);`\n\n\n\n\n\n\nSign in with phone\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nawait supabase.auth.signIn(\n  phone: '+13334445555',\n  password: 'example-password',\n);`\n\n\n`dart\nawait supabase.auth.signInWithPassword(\n  phone: '+13334445555',\n  password: 'example-password',\n);`\n\n\n\n\n\n\nSign in with phone using OTP\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nfinal res = await supabase.auth.signIn(phone: phone);`\n\n\n```dart\nawait supabase.auth.signInWithOtp(\n  phone: phone,\n);\n// After receiving a SMS with a OTP.\nawait supabase.auth.verifyOTP(\n  type: OtpType.sms,\n  token: token,\n  phone: phone,\n);\n```\n\n\n\n\n\n\nReset password for email\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nawait supabase.auth.api.resetPasswordForEmail(\n  email,\n  options:\n      AuthOptions(redirectTo: 'io.supabase.flutter://reset-callback/'),\n);`\n\n\n`dart\nawait supabase.auth.resetPasswordForEmail(\n  email,\n  redirectTo: kIsWeb ? null : 'io.supabase.flutter://reset-callback/',\n);`\n\n\n\n\n\n\nGet the user's current session\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nfinal session = supabase.auth.session();`\n\n\n`dart\nfinal Session? session = supabase.auth.currentSession;`\n\n\n\n\n\n\nGet the logged-in user\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nfinal user = supabase.auth.user();`\n\n\n`dart\nfinal User? user = supabase.auth.currentUser;`\n\n\n\n\n\n\nUpdate user data for a logged-in user\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nawait supabase.auth.update(\n  UserAttributes(data: {'hello': 'world'})\n);`\n\n\n`dart\nawait supabase.updateUser(\n  UserAttributes(\n    data: { 'hello': 'world' },\n  ),\n);`\n\n\n\n\nData methods\n`.insert()` / `.upsert()` / `.update()` / `.delete()` no longer return rows by default. Previously, these methods return inserted/updated/deleted rows by default (which caused some confusion), and you can opt to not return it by specifying `returning: 'minimal'`. Now the default behavior is to not return rows. To return inserted/updated/deleted rows, add a `.select()` call at the end.\nAlso, calling `.execute()` at the end of the query was a requirement in v0, but deprecated in v1.\n\n\nInsert without returning inserted data\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n```dart\nawait supabase\n  .from('my_table')\n  .insert(data, returning: ReturningOption.minimal)\n  .execute();\n```\n\n\n`dart\nawait supabase.from('my_table').insert(data);`\n\n\n\n\n\n\nInsert with returning inserted data\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nfinal res = await supabase\n  .from('my_table')\n  .insert(data)\n  .execute();`\n\n\n`dart\nfinal insertedData = await supabase.from('my_table').insert(data).select();`\n\n\n\n\nRealtime methods\n\n\nStream\n`.stream()` no longer needs the `.execute()` at the end. Also, filtering by `eq` is a lot easier now. `primaryKey` is now a named parameter to make it more obvious what to pass.\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nsupabase.from('my_table:id=eq.120')\n  .stream(['id'])\n  .listen();`\n\n\n`dart\nsupabase.from('my_table')\n  .stream(primaryKey: ['id'])\n  .eq('id', '120')\n  .listen();`\n\n\n\n\n\n\nSubscribe\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nfinal subscription = supabase\n  .from('countries')\n  .on(SupabaseEventTypes.all, (payload) {\n    // Handle realtime payload\n  })\n  .subscribe();`\n\n\n`dart\nfinal channel = supabase.channel('*');\nchannel.on(\n  RealtimeListenTypes.postgresChanges,\n  ChannelFilter(event: '*', schema: '*'),\n  (payload, [ref]) {\n    // Handle realtime payload\n  },\n).subscribe();`\n\n\n\n\n\n\nUnsubscribe\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"0.x\"\n\n\n\n`dart\nsupabase.removeSubscription(subscription);`\n\n\n`dart\nawait supabase.removeChannel(channel);`\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/dart/v0/introduction.mdx",
    "content": "\nid: introduction\ntitle: Introduction\nhideTitle: true\n\n\n\n\nFlutter Client Library\nsupabase-flutter\n\n\n\n\n  You're viewing the docs for an older version of the `supabase-flutter` library. Learn how to\n  [upgrade to the latest version](/docs/reference/dart/v0/upgrade-guide).\n\n\nThis reference documents every object and method available in Supabase's Flutter library,\u00a0[supabase-flutter](https://pub.dev/packages/supabase_flutter).\nYou can use\u00a0supabase-flutter to interact with your Postgres database, listen to database changes, invoke\nDeno Edge Functions, build login and user management functionality, and manage large files.\n\nWe also provide a [supabase](https://pub.dev/packages/supabase) package for non-Flutter projects.",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/cli/introduction.mdx",
    "content": "\nid: introduction\ntitle: Introduction\nhideTitle: true\n\n\n\n\nSupabase CLI\n\n\n\n\n\n\n```The Supabase CLI provides tools to develop your project locally and deploy to the Supabase Platform.\nThe CLI is still under development, but it contains all the functionality for working with your Supabase projects and the Supabase Platform.\n\n- Run Supabase locally: [`supabase init`](/docs/reference/cli/usage#supabase-init) and [`supabase start`](/docs/reference/cli/usage#supabase-start)\n- Manage database migrations: [`supabase migration`](/docs/reference/cli/usage#supabase-migration)\n- CI/CD for releasing to production: [`supabase db push`](/docs/reference/cli/usage#supabase-db-push)\n- Manage your Supabase projects: [`supabase projects`](/docs/reference/cli/usage#supabase-projects)\n- Generate types directly from your database schema: [`supabase gen types`](/docs/reference/cli/usage#supabase-gen)\n  - A [community-supported GitHub Action](https://github.com/lyqht/generate-supabase-db-types-github-action) to generate TypeScript types\n- Shell autocomplete: [`supabase completion`](/docs/reference/cli/usage#supabase-completion)\n  - A [community-supported Fig autocomplete spec](https://fig.io/manual/supabase) for macOS terminal\n```\n\n\n\n\n\n\n```### Additional links\n\n- [Install the Supabase CLI](/docs/guides/cli)\n- [Source code](https://github.com/supabase/cli)\n- [Known bugs and issues](https://github.com/supabase/cli/issues)\n- [Supabase CLI v1 and Management API Beta](https://supabase.com/blog/supabase-cli-v1-and-admin-api-beta)\n- [Video: Announcing CLI V1 and Management API Beta](https://www.youtube.com/watch?v=OpPOaJI_Z28)\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "Why not just use PostgreSQL's `NOTIFY`?",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/realtime/realtime.mdx",
    "content": "\nslug: /\nsidebar_position: 1\nid: realtime\ntitle: Supabase Realtime Server\nsidebar_label: Supabase Realtime Server\n\nSupabase Realtime is a server built with Elixir using the Phoenix Framework that allows you to listen to changes in your PostgreSQL database via logical replication and then broadcast those changes via WebSockets.\nThere are two versions of this server: `Realtime` and `Realtime RLS`.\n`Realtime` server works by:\n\nlistening to PostgreSQL's replication functionality (using PostgreSQL's logical decoding)\nconverting the byte stream into JSON\nbroadcasting to all connected clients over WebSockets\n\n`Realtime RLS` server works by:\n\npolling PostgreSQL's replication functionality (using PostgreSQL's logical decoding and wal2json output plugin)\npassing database changes to a Write Ahead Log Realtime Unified Security (WALRUS) PostgresSQL function and receiving a list of authorized subscribers depending on Row Level Security (RLS) policies\nconverting the changes into JSON\nbroadcasting to authorized subscribers over WebSockets\n\nWhy not just use PostgreSQL's `NOTIFY`?\nA few reasons:\n\nYou don't have to set up triggers on every table.\n`NOTIFY` has a payload limit of 8000 bytes and will fail for anything larger. The usual solution is to send an ID and then fetch the record, but that's heavy on the database.\n`Realtime` server consumes two connections to the database, then you can connect many clients to this server. Easier on your database, and to scale up you just add additional `Realtime` servers.\n\nBenefits\n\nThe beauty of listening to the replication functionality is that you can make changes to your database from anywhere - your API, directly in the DB, via a console, etc. - and you will still receive the changes via WebSockets.\nDecoupling. For example, if you want to send a new slack message every time someone makes a new purchase you might build that functionality directly into your API. This allows you to decouple your async functionality from your API.\nThis is built with Phoenix, an extremely scalable Elixir framework.\n\nDoes this server guarantee delivery of every data change?\nNot yet! Due to the following limitations:\n\nPostgres database runs out of disk space due to Write-Ahead Logging (WAL) buildup, which can crash the database and prevent Realtime server from receiving and broadcasting changes. This can be mitigated in the Realtime RLS version of this server by setting the Postgres config `max_slot_wal_keep_size` to a reasonable size.\nRealtime server can crash due to a larger replication lag than available memory, forcing the creation of a new replication slot and resetting replication to read from the latest WAL data.\nWhen Realtime server falls too far behind for any reason, for example disconnecting from database as WAL continues to build up, then database can delete WAL segments the server still needs to read from, for example after reconnecting.\n\nClient libraries\n\nJavaScript\nDart\n\nAdditional Links\n\nSource Code\nKnown bugs and issues\n",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/self-hosting-realtime/introduction.mdx",
    "content": "\nid: introduction\ntitle: Introduction\nhideTitle: true\n\n\n\n\nSelf-Hosting Realtime\n\n\n\n\n\n\n```Supabase Realtime is a server built with Elixir using the [Phoenix Framework](https://www.phoenixframework.org) that allows you to listen to changes in your PostgreSQL database via logical replication and then broadcast those changes via WebSockets.\n\nThere are two versions of this server: `Realtime` and `Realtime RLS`.\n\n`Realtime` server works by:\n\n1. Listening to PostgreSQL's replication functionality (using PostgreSQL's logical decoding)\n2. Converting the byte stream into JSON\n3. Broadcasting to all connected clients over WebSockets\n\n`Realtime RLS` server works by:\n\n1. Polling PostgreSQL's replication functionality (using PostgreSQL's logical decoding and [wal2json](https://github.com/eulerto/wal2json) output plugin)\n2. Passing database changes to a [Write Ahead Log Realtime Unified Security (WALRUS)](https://github.com/supabase/walrus) PostgresSQL function and receiving a list of authorized subscribers depending on Row Level Security (RLS) policies\n3. Converting the changes into JSON\n4. Broadcasting to authorized subscribers over WebSockets\n\n## Why not just use PostgreSQL's `NOTIFY`?\n\nA few reasons:\n\n1. You don't have to set up triggers on every table.\n2. `NOTIFY` has a payload limit of 8000 bytes and will fail for anything larger. The usual solution is to send an ID and then fetch the record, but that's heavy on the database.\n3. `Realtime` server consumes two connections to the database, then you can connect many clients to this server. Easier on your database, and to scale up you just add additional `Realtime` servers.\n\n## Benefits\n\n1. The beauty of listening to the replication functionality is that you can make changes to your database from anywhere - your API, directly in the DB, via a console, etc. - and you will still receive the changes via WebSockets.\n2. Decoupling. For example, if you want to send a new slack message every time someone makes a new purchase you might build that functionality directly into your API. This allows you to decouple your async functionality from your API.\n3. This is built with Phoenix, an [extremely scalable Elixir framework](https://www.phoenixframework.org/blog/the-road-to-2-million-websocket-connections).\n\n## Does this server guarantee delivery of every data change?\n\nNot yet! Due to the following limitations:\n\n1. Postgres database runs out of disk space due to Write-Ahead Logging (WAL) buildup, which can crash the database and prevent Realtime server from receiving and broadcasting changes. This can be mitigated in the Realtime RLS version of this server by setting the Postgres config `max_slot_wal_keep_size` to a reasonable size.\n2. Realtime server can crash due to a larger replication lag than available memory, forcing the creation of a new replication slot and resetting replication to read from the latest WAL data.\n3. When Realtime server falls too far behind for any reason, for example disconnecting from database as WAL continues to build up, then database can delete WAL segments the server still needs to read from, for example after reconnecting.\n```\n\n\n\n\n\n\n```### Client libraries\n\n- [JavaScript](https://github.com/supabase/realtime-js)\n- [Dart](https://github.com/supabase/realtime-dart)\n\n### Additional links\n\n- [Source code](https://github.com/supabase/realtime)\n- [Known bugs and issues](https://github.com/supabase/realtime/issues)\n- [Realtime guides](/docs/guides/realtime)\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/self-hosting-auth/introduction.mdx",
    "content": "\nid: introduction\ntitle: Introduction\nhideTitle: true\n\n\n\n\nSelf-Hosting Auth\n\n\n\n\nThe Supabase Auth Server (GoTrue) is a JSON Web Token (JWT)-based API for managing users and issuing access tokens.\nGoTrue is an open-source API written in Golang, that acts as a self-standing API service for handling user registration and authentication for JAM projects. It's based on OAuth2 and JWT and handles user signup, authentication, and custom user data.\n\n\n\n\n```### Client libraries\n\n- [JavaScript](https://github.com/supabase/gotrue-js)\n- [Dart](https://github.com/supabase/gotrue-dart)\n\n### Additional links\n\n- [Source code](https://github.com/supabase/gotrue)\n- [Known bugs and issues](https://github.com/supabase/gotrue/issues)\n- [Auth guides](/docs/guides/auth)\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/api/introduction.mdx",
    "content": "\nid: introduction\ntitle: introduction\nhideTitle: true\n\n\n\n\nManagement API\n\n\n\n\n\n\n```  Manage your Supabase organizations and projects programmatically.\n\n  ## Status\n\n  The Management API is in `beta`. It is usable in it's current state, but it's likely that there will be breaking changes.\n\n  ## Authentication\n\n  All API requests require a Supabase Personal token to be included in the Authorization header: `Authorization Bearer <supabase_personal_token`.\n  To generate or manage your API token, visit your [account](https://app.supabase.com/account/tokens) page.\n  Your API tokens carry the same privileges as your user account, so be sure to keep it secret.\n\n  ```bash\n    curl https://api.supabase.com/v1/projects \\\n    -H \"Authorization: Bearer sbp_bdd0\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u20224f23\"\n  ```\n\n  All API requests must be authenticated and made over HTTPS.\n\n  ## Rate limits\n\n  The API is currently subject to our fair-use policy. In the future, are likely to introduce rate limits.\n  All resources created via the API are subject to the pricing detailed on our [Pricing](https://supabase.com/pricing) pages.\n\n</RefSubLayout.Details>\n\n<RefSubLayout.Examples>\n\n  Additional links\n\n  - [OpenAPI Docs](https://api.supabase.com/api/v1)\n  - [OpenAPI Spec](https://api.supabase.com/api/v1-json)\n  - [Report bugs and issues](https://github.com/supabase/supabase)\n\n  </RefSubLayout.Examples>\n```\n\n",
    "tag": "supabase"
  },
  {
    "title": "Status",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/api/api.mdx",
    "content": "\nslug: /\nsidebar_position: 1\nid: management-api\ntitle: Management API\nsidebar_label: Management API\n\nThe Management API allows you to manage your projects programmatically.\nStatus\nThe Management API is in `beta`. It is usable in it's current state, but it's likely that there will be breaking changes.\nAuthentication\nAll API requests require a Supabase Personal token to be included in the Authorization header: `Authorization Bearer <supabase_personal_token`.\nTo generate or manage your API token, visit your account page.\nYour API tokens carry the same privileges as your user account, so be sure to keep it secret.\n`bash\n$ curl https://api.supabase.com/v1/projects \\\n-H \"Authorization: Bearer sbp_bdd0\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u20224f23\"`\nAll API requests must be authenticated and made over HTTPS.\nRate limits\nThe API is currently subject to our fair-use policy. In the future, are likely to introduce rate limits.\nAll resources created via the API are subject to the pricing detailed on our Pricing pages.\nAdditional links\n\nOpenAPI Docs\nOpenAPI Spec\n",
    "tag": "supabase"
  },
  {
    "title": "installing.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/csharp/installing.mdx",
    "content": "\nid: installing\ntitle: 'Installing & Initialization'\nslug: installing\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/supabase.yml\n\nInstall from NuGet\n\n\n\n\n```You can install Supabase package from [nuget.org](https://www.nuget.org/packages/supabase-csharp/)\n```\n\n\n\n\n\n\n```<Tabs\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"csharp\">\n  <TabPanel id=\"csharp\" label=\"Terminal\">\n\n    ```sh Terminal\n    dotnet add package supabase-csharp\n    ```\n\n  </TabPanel>\n</Tabs>\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "0.8.0 - 2023-01-31",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/csharp/release-notes.mdx",
    "content": "\nid: release-notes\ntitle: Release Notes\n\n0.8.0 - 2023-01-31\n\nUpdate dependency: realtime-csharp@5.0.0\nRe: #21 Provide API for `presence`, `broadcast` and `postgres_changes`\n[Major, New] `Channel.PostgresChanges` event will receive the wildcard `*` changes event, not `Channel.OnMessage`.\n[Major] `Channel.OnInsert`, `Channel.OnUpdate`, and `Channel.OnDelete` now conform to the server's payload of `Response.Payload.**Data**`\n[Major] `Channel.OnInsert`, `Channel.OnUpdate`, and `Channel.OnDelete` now return `PostgresChangesEventArgs`\n[Minor] Rename `Channel` to `RealtimeChannel`\nSupports better handling of disconnects in `RealtimeSocket` and adds a `Client.OnReconnect` event.\n[Minor] Moves `ChannelOptions` to `Channel.ChannelOptions`\n[Minor] Moves `ChannelStateChangedEventArgs` to `Channel.ChannelStateChangedEventArgs`\n[Minor] Moves `Push` to `Channel.Push`\n[Minor] Moves `Channel.ChannelState` to `Constants.ChannelState`\n[Minor] Moves `SocketResponse`, `SocketRequest`, `SocketResponsePayload`, `SocketResponseEventArgs`, and `SocketStateChangedEventArgs` to `Socket` namespace.\n[New] Adds `RealtimeBroadcast`\n[New] Adds `RealtimePresence`\n[Improvement] Better handling of disconnection/reconnection\n\n\nUpdate dependency: postgrest-csharp@3.1.3\nAnother fix for #61 which further typechecks nullable values.\n\n0.7.2 - 2023-01-27\n\nUpdate dependency: gotrue-csharp@3.0.4\nMakes `Session.CreatedAt` a publicly settable property, which should fix incorrect dates on retrieved `Session`s.\nUpdate dependency: postgrest-csharp@3.1.2\nFix #61 which did not correctly parse Linq `Where` when encountering a nullable type.\nAdd missing support for transforming for `== null` and `!= null`\n\n0.7.1 - 2023-01-17\n\nUpdate dependency: postgrest-csharp@3.1.1\nFix issue from supabase-community/supabase-csharp#48 where boolean model properties would not be evaluated in predicate expressions\n\n0.7.0 - 2023-01-16\n\nUpdate dependency: postgrest-csharp@3.1.0\n[Minor] Breaking API Change: `PrimaryKey` attribute defaults to `shouldInsert: false` as most uses will have the Database generate the primary key.\nMerged #60 which Added linq support for `Select`, `Where`, `OnConflict`, `Columns`, `Order`, `Update`, `Set`, and `Delete`\n\n0.6.2 - 2022-11-22\n\nUpdate dependency: postgrest-csharp@3.0.4\n`GetHeaders` is now passed to `ModeledResponse` and `BaseModel` so that the default `Update` and `Delete` methods use the latest credentials\n`GetHeaders` is used in `Rpc` calls (re: #39)\n\n0.6.1 - 2022-11-12\n\n[Hotfix] `GetHeaders` was not passing properly to `SupabaseTable` and `Gotrue.Api`\n\n0.6.0 - 2022-11-12\n[BREAKING CHANGES]\n\n`Client` is no longer a singleton, singleton interactions (if desired) are left to the developer to implement.\n`Client` supports injection of dependent clients after initialization via property:\n`Auth`\n`Functions`\n`Realtime`\n`Postgrest`\n`Storage`\n`SupabaseModel` contains no logic but remains for backwards compatibility. (Marked `Obsolete`)\n`ClientOptions.ShouldInitializeRealtime` was removed (no longer auto initialized)\n`ClientOptions` now references an `ISupabaseSessionHandler` which specifies expected functionality for session persistence on Gotrue (replaces `ClientOptions.SessionPersistor`, `ClientOptions.SessionRetriever`, and `ClientOptions.SessionDestroyer`).\n`supabase-csharp` and all child libraries now have support `nullity`\n\nOther Changes:\n\nUpdate dependency: functions-csharp@1.2.1\nUpdate dependency: gotrue-csharp@3.0.2\nUpdate dependency: postgrest-csharp@3.0.2\nUpdate dependency: realtime-csharp@4.0.1\nUpdate dependency: supabase-storage-csharp@1.2.3\nUpdate dependency: supabase-core@0.0.2\n\nBig thank you to @veleek for his insight into these changes.\nRe: #35, #34, #23, #36\n0.5.3 - 2022-10-11\n\nUpdate dependency: postgrest-csharp@2.1.0\n[Minor] Breaking API change: Remove `BaseModel.PrimaryKeyValue` and `BaseModel.PrimaryKeyColumn` in favor of a `PrimaryKey` dictionary with support for composite keys.\nRe: #48 - Add support for derived models on `ReferenceAttribute`\nRe: #49 - Added `Match(T model)`\n\n0.5.2 - 2022-9-13\n\nUpdate dependency: postgrest-csharp@2.0.12\nMerged #47 which added cancellation token support to `Table<T>` methods. Thanks @devpikachu!\n\n0.5.1 - 2022-8-1\n\nUpdate dependency: postgrest-csharp@2.0.11\nUpdate dependency: supabase-storage-csharp@1.1.1\n\n0.5.0 - 2022-7-17\n\nUpdate dependency: postgrest-csharp@2.0.9\nUpdate dependency: realtime-csharp@3.0.1\nUpdate dependency: supabase-storage-csharp@1.1.0\nAPI Change [Breaking/Minor] Library no longer uses `WebClient` and instead leverages `HttpClient`. Progress events on `Upload` and `Download` are now handled with `EventHandler<float>` instead of `WebClient` EventHandlers.\n\n0.4.4 - 2022-5-24\n\nUpdate dependency: gotrue-csharp@2.4.5\nUpdate dependency: postgrest-csharp@2.0.8\n\n0.4.3 - 2022-5-13\n\nUpdate dependency: gotrue-csharp@2.4.4\n\n0.4.2 - 2022-4-30\n\nUpdate dependency: gotrue-csharp@2.4.3\n\n0.4.1 - 2022-4-23\n\nUpdate dependency: gotrue-csharp@2.4.2\n\n0.4.0 - 2022-4-12\n\nAdd support for functions-csharp@1.0.1, giving access to invoking Supabase's edge functions.\nUpdate dependency: gotrue-csharp@2.4.1\n\n0.3.5 - 2022-4-11\n\nUpdate dependency: postgres-csharp@2.0.7\n\n0.3.4 - 2022-03-28\n\nUpdate dependency: gotrue-csharp@2.4.0\n\n0.3.3 - 2022-02-27\n\nUpdate dependency: gotrue-csharp@2.3.6\nUpdate dependency: supabase-storage-csharp@1.0.2\n\n0.3.2 - 2022-02-18\n\nUpdate dependency: realtime-csharp@3.0.0\nExchange existing websocket client: WebSocketSharp for Marfusios/websocket-client which adds support for Blazor WASM apps.\n    Ref: #14\n\n0.3.1 - 2022-01-20\n\nUpdate dependency: gotrue-csharp@2.3.5\n#23 Added `redirect_url` option for MagicLink sign in (Thanks @MisterJimson)\n#21 Added SignOut method to Stateless Client (Thanks @fplaras)\n\n0.3.0 - 2021-12-30\n\nUpdate dependency: postgrest-csharp@2.0.6\nAdd support for `NullValueHandling` to be specified on a `Column` Attribute and for it to be honored on Inserts and Updates. Defaults to: `NullValueHandling.Include`.\nImplements #38\n\n\nUpdate dependency: realtime-csharp@2.0.8\nImplement Upstream Realtime RLS Error Broadcast Handler\nImplements #12\n\n\n`SocketResponse` now exposes a method: `OldModel`, that hydrates the `OldRecord` property into a model.\n\n0.2.12 - 2021-12-29\n\nUpdate dependency: gotrue-csharp@2.3.3\n`SignUp` will return a `Session` with a populated `User` object on an unconfirmed signup.\nFixes #19\nDevelopers who were using a `null` check on `Session.User` will need to adjust accordingly.\n\n\nUpdate dependency: postgrest-csharp@2.0.5\nFix for #37 - Return Type `minimal` would fail to resolve because of incorrect `Accept` headers. Added header and test to verify for future.\nFix for #36 - Inserting/Upserting bulk records would fail while doing an unnecessary generic coercion.\n\n0.2.11 - 2021-12-24\n\nUpdate dependency: gotrue-csharp@2.3.2 (changes CreateUser parameters to conform to `AdminUserAttributes`)\nSee #15\nSee #16\nUpdate dependency: realtime-csharp@2.0.7\nSee #13\n\n0.2.10 - 2021-12-23\n\nUpdate dependency: gotrue-csharp@2.3.0 (adds metadata support for user signup, see #14)\n\n0.2.9 - 2021-12-9\n\nSeparate Storage client from Supabase repo and into `storage-csharp`, `supabase-csharp` now references new repo.\n\n0.2.8 - 2021-12-4\n\nUpdate gotrue-csharp to 2.2.4\nAdds support for `ListUsers` (paginate, sort, filter), `GetUserById`, `CreateUser`, and `UpdateById`\n\n0.2.7 - 2021-12-2\n\nUpdate gotrue-csharp to 2.2.3\nAdds support for sending password resets to users.\n\n0.2.6 - 2021-11-29\n\nSupport for #12\nUpdate realtime-csharp to 2.0.6\nUpdate gotrue-csharp to 2.2.2\n",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/csharp/introduction.mdx",
    "content": "\nid: introduction\ntitle: Introduction\nhideTitle: true\n\n\n\n\nC# Client Library\n@supabase-community/supabase-csharp\n\n\n\n  This reference documents every object and method available in Supabase's C# library,\n  [supabase-csharp](https://www.nuget.org/packages/supabase-csharp). You can use supabase-csharp to\n  interact with your Postgres database, listen to database changes, invoke Deno Edge Functions,\n  build login and user management functionality, and manage large files.\n\n\nThe C# client library is created and maintained by the Supabase community, and is not an official library. Please be tolerant of areas where the library is still being developed, and \u2014 as with all the libraries \u2014 feel free to contribute wherever you find issues.\n\n  Huge thanks to official maintainer, [Joseph Schultz](https://github.com/acupofjose), and to [Ben\n  Randall](https://github.com/veleek) and [Rhuan Barros](https://github.com/rhuanbarros) for their\n  help.\n",
    "tag": "supabase"
  },
  {
    "title": "installing.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/javascript/installing.mdx",
    "content": "\nid: installing\ntitle: 'Installing'\nslug: installing\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/supabase.yml\n\nInstall as package\n\n\n\n\n```You can install @supabase/supabase-js via the terminal.\n```\n\n\n\n\n\n\n```<Tabs\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n>\n  <TabPanel id=\"npm\" label=\"npm\">\n\n    ```sh Terminal\n    npm install @supabase/supabase-js\n    ```\n\n  </TabPanel>\n  <TabPanel id=\"yarn\" label=\"Yarn\">\n\n    ```sh Terminal\n    yarn add @supabase/supabase-js\n    ```\n\n  </TabPanel>\n</Tabs>\n```\n\n\n\n\nInstall via CDN\n\n\n\n\n```You can install @supabase/supabase-js via CDN links.\n```\n\n\n\n\n\n\n``````js\n<script src=\"https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2\"></script>\n//or\n<script src=\"https://unpkg.com/@supabase/supabase-js@2\"></script>\n```\n```\n\n\n\n\nUse at runtime in Deno\n\n\n\n\n```You can use supabase-js in the Deno runtime via esm.sh:\n```\n\n\n\n\n\n\n``````ts\n  import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'\n```\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "release-notes.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/javascript/release-notes.mdx",
    "content": "\nid: release-notes\ntitle: Release Notes 2.0.0\n\nSupabase.js v2 release notes.\n\n\n\n\n```Install the latest version of @supabase/supabase-js\n```\n\n\n\n\n\n\n``````bash Terminal\n  npm install @supabase/supabase-js\n```\n```\n\n\n\n\nExplicit constructor options\n\n\n\n\n```All client specific options within the constructor are keyed to the library.\n\nSee [PR](https://github.com/supabase/supabase-js/pull/458):\n```\n\n\n\n\n\n\n``````jsx\n  const supabase = createClient(apiURL, apiKey, {\n    db: {\n      schema: 'public',\n    },\n    auth: {\n      storage: AsyncStorage,\n      autoRefreshToken: true,\n      persistSession: true,\n      detectSessionInUrl: true,\n    },\n    realtime: {\n      channels,\n      endpoint,\n    },\n    global: {\n      fetch: customFetch,\n      headers: DEFAULT_HEADERS,\n    },\n  })\n```\n```\n\n\n\n\nTypescript support\n\n\n\n\n```The libraries now support typescript.\n```\n\n\n\n\n\n\n```  ```ts v1.0\n    // previously definitions were injected in the `from()` method\n    supabase.from<Definitions['Message']>('messages').select('\\*')\n  ```\n\n  ---\n\n  ```ts v2.0\n    import type { Database } from './DatabaseDefinitions'\n\n    // definitions are injected in `createClient()`\n    const supabase = createClient<Database>(SUPABASE_URL, ANON_KEY)\n\n    const { data } = await supabase.from('messages').select().match({ id: 1 })\n  ```\n```\n\n\n\n\n\n\n```Types can be generated via the CLI:\n```\n\n\n\n\n\n\n``````bash Terminal\nsupabase start\nsupabase gen types typescript --local > DatabaseDefinitions.ts\n```\n```\n\n\n\n\nData operations return minimal\n\n\n\n\n````.insert()` / `.upsert()` / `.update()` / `.delete()` don't return rows by default: [PR](https://github.com/supabase/postgrest-js/pull/276).\n\nPreviously, these methods return inserted/updated/deleted rows by default (which caused [some confusion](https://github.com/supabase/supabase/discussions/1548)), and you can opt to not return it by specifying `returning: 'minimal'`. Now the default behavior is to not return rows. To return inserted/updated/deleted rows, add a `.select()` call at the end, e.g.:\n```\n\n\n\n\n\n\n``````sql\nconst { data, error } = await supabase\n    .from('my_table')\n    .delete()\n    .eq('id', 1)\n    .select()\n```\n```\n\n\n\n\nNew ordering defaults\n\n\n\n\n````.order()` now defaults to Postgres\u2019s default: [PR](https://github.com/supabase/postgrest-js/pull/283).\n\nPreviously `nullsFirst` defaults to `false` , meaning `null`s are ordered last. This is bad for performance if e.g. the column uses an index with `NULLS FIRST` (which is the default direction for indexes).\n```\n\n\n\n\n\n\nCookies and localstorage namespace\n\n\n\n\n```Storage key name in the Auth library has changed to include project reference which means that existing websites that had their JWT expiry set to a longer time could find their users logged out with this upgrade.\n```\n\n\n\n\n\n\n``````jsx\nconst defaultStorageKey = `sb-${new URL(this.authUrl).hostname.split('.')[0]}-auth-token`\n```\n```\n\n\n\n\nNew Auth Types\n\n\n\n\n```Typescript typings have been reworked. `Session` interface now guarantees that it will always have an `access_token`, `refresh_token` and `user`\n```\n\n\n\n\n\n\n``````jsx ./types.ts\ninterface Session {\n  provider_token?: string | null\n  access_token: string\n  expires_in?: number\n  expires_at?: number\n  refresh_token: string\n  token_type: string\n  user: User\n}\n```\n```\n\n\n\n\nNew Auth methods\n\n\n\n\n```We're removing the `signIn()` method in favor of more explicit function signatures:\n`signInWithPassword()`, `signInWithOtp()`, and `signInWithOtp()`.\n```\n\n\n\n\n\n\n```  ```ts v1.0\n    const { data } = await supabase.auth.signIn({\n      email: 'hello@example',\n      password: 'pass',\n    })\n  ```\n  ---\n\n  ```ts v2.0\n    const { data } = await supabase.auth.signInWithPassword({\n      email: 'hello@example',\n      password: 'pass',\n    })\n  ```\n```\n\n\n\n\nNew Realtime methods\n\n\n\n\n```There is a new `channel()` method in the Realtime library, which will be used for our Multiplayer updates.\n\nWe will deprecate the `.from().on().subscribe()` method previosuly used for listening to postgres changes.\n```\n\n\n\n\n\n\n``````ts\nsupabase\n  .channel('any_string_you_want')\n  .on('presence', { event: 'track' }, (payload) => {\n    console.log(payload)\n  })\n  .subscribe()\n\nsupabase\n  .channel('any_string_you_want')\n  .on(\n    'postgres_changes',\n    {\n      event: 'INSERT',\n      schema: 'public',\n      table: 'movies',\n    },\n    (payload) => {\n      console.log(payload)\n    }\n  )\n  .subscribe()\n```\n```\n\n\n\n\nDeprecated setAuth()\nDeprecated and removed `setAuth()` . To set a custom `access_token` jwt instead, pass the custom header into the `createClient()` method provided: (PR)\nAll changes\n\n`supabase-js`\n`shouldThrowOnError` has been removed until all the client libraries support this option (PR).\n`postgrest-js`\nTypeScript typings have been reworked PR\nUse `undefined` instead of `null` for function params, types, etc. (https://github.com/supabase/postgrest-js/pull/278)\nSome features are now obsolete: (https://github.com/supabase/postgrest-js/pull/275)\nfilter shorthands (e.g. `cs` vs. `contains`)\n`body` in response (vs. `data`)\n`upsert`ing through the `.insert()` method\n`auth` method on `PostgrestClient`\nclient-level `throwOnError`\n\n\n`gotrue-js`\n`supabase-js` client allows passing a `storageKey` param which will allow the user to set the key used in local storage for storing the session. By default, this will be namespace-d with the supabase project ref. (PR)\n`signIn` method is now split into `signInWithPassword` , `signInWithOtp` , `signInWithOAuth` (PR)\nDeprecated and removed `session()` , `user()` in favour of using `getSession()` instead. `getSession()` will always return a valid session if a user is already logged in, meaning no more random logouts. (PR)\nDeprecated and removed setting for `multitab` support because `getSession()` and gotrue\u2019s reuse interval setting takes care of session management across multiple tabs (PR)\nNo more throwing of random errors, gotrue-js v2 always returns a custom error type: (PR)\n`AuthSessionMissingError`\nIndicates that a session is expected but missing\n`AuthNoCookieError`\nIndicates that a cookie is expected but missing\n`AuthInvalidCredentialsError`\nIndicates that the incorrect credentials were passed\n\n\nRenamed the `api` namespace to `admin` , the `admin` namespace will only contain methods that should only be used in a trusted server-side environment with the service role key\nMoved `resetPasswordForEmail` , `getUser` and `updateUser` to the `GoTrueClient` which means they will be accessible from the `supabase.auth` namespace in `supabase-js` instead of having to do `supabase.auth.api` to access them\nRemoved `sendMobileOTP` , `sendMagicLinkEmail` in favor of `signInWithOtp`\nRemoved `signInWithEmail`, `signInWithPhone` in favor of `signInWithPassword`\nRemoved `signUpWithEmail` , `signUpWithPhone` in favor of `signUp`\nReplaced `update` with `updateUser`\n`storage-js`\nReturn types are more strict. Functions types used to indicate that the data returned could be null even if there was no error. We now make use of union types which only mark the data as null if there is an error and vice versa. (PR)\nThe `upload` and `update` function returns the path of the object uploaded as the `path` parameter. Previously the returned value had the bucket name prepended to the path which made it harder to pass the value on to other storage-js methods since all methods take the bucket name and path separately. We also chose to call the returned value `path` instead of `Key` (PR)\n`getPublicURL` only returns the public URL inside the data object. This keeps it consistent with our other methods of returning only within the data object. No error is returned since this method cannot does not throw an error (PR)\nsigned urls are returned as `signedUrl` instead of `signedURL` in both `createSignedUrl` and `createSignedUrls` (PR)\nEncodes URLs returned by `createSignedUrl`, `createSignedUrls` and `getPublicUrl` (PR)\n`createsignedUrl` used to return a url directly and and within the data object. This was inconsistent. Now we always return values only inside the data object across all methods. (PR)\n`createBucket` returns a data object instead of the name of the bucket directly. (PR)\nFixed types for metadata (PR)\nBetter error types make it easier to track down what went wrong quicker.\n`SupabaseStorageClient` is no longer exported. Use `StorageClient` instead. (PR).\n`realtime-js`\n`RealtimeSubscription` class no longer exists and replaced by `RealtimeChannel`.\n`RealtimeClient`'s `disconnect` method now returns type of `void` . It used to return type of `Promise<{ error: Error | null; data: boolean }`.\nRemoved `removeAllSubscriptions` and `removeSubscription` methods from `SupabaseClient` class.\nRemoved `SupabaseRealtimeClient` class.\nRemoved `SupabaseQueryBuilder` class.\nRemoved `SupabaseEventTypes` type.\nThinking about renaming this to something like `RealtimePostgresChangeEvents` and moving it to `realtime-js` v2.\n\n\nRemoved `.from(\u2019table\u2019).on(\u2019INSERT\u2019, () \u21d2 {}).subscribe()` in favor of new Realtime client API.\n`functions-js`\nsupabase-js v1 only threw an error if the fetch call itself threw an error (network errors, etc) and not if the function returned HTTP errors like 400s or 500s. We have changed this behaviour to return an error if your function throws an error.\nWe have introduced new error types to distinguish between different kinds of errors. A `FunctionsHttpError` error is returned if your function throws an error, `FunctionsRelayError` if the Supabase Relay has an error processing your function and `FunctionsFetchError` if there is a network error in calling your function.\nThe correct content-type headers are automatically attached when sending the request if you don\u2019t pass in a `Content-Type` header and pass in an argument to your function. We automatically attach the content type for `Blob`, `ArrayBuffer`, `File`, `FormData` ,`String` . If it doesn\u2019t match any of these we assume the payload is `json` , we serialise the payload as JSON and attach the content type as `application/json`.\n",
    "tag": "supabase"
  },
  {
    "title": "Generating types",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/javascript/typescript-support.mdx",
    "content": "\nid: typescript-support\ntitle: Typescript Support\n\n`supabase-js` supports Typescript.\nGenerating types\n\n\n\n\n```You can use our CLI to generate types:\n```\n\n\n\n\n\n\n``````bash Terminal\nsupabase start\nsupabase gen types typescript --local > lib/database.types.ts\n```\n```\n\n\n\n\n\n\n\n\n```These types are generated directly from your database.\n\nThere is a difference between `selects`, `inserts`, and `updates`, because often you will set default values in your database for specific columns.\nWith default values you do not need to send any data over the network, even if that column is a \"required\" field. Our type system is granular\nenough to handle these situations.\n```\n\n\n\n\n\n\n```Given a table `public.movies`, the definition will provide the following data:\n\n```ts /types.ts\ninterface Database {\n  public: {\n    Tables: {\n      movies: {\n        Row: {} // The data expected to be returned from a \"select\" statement.\n        Insert: {} // The data expected passed to an \"insert\" statement.\n        Update: {} // The data expected passed to an \"update\" statement.\n      }\n    }\n  }\n}\n```\n```\n\n\n\n\nInjecting type definitions\n\n\n\n\n```You can enrich the supabase client with the types you generated with Supabase.\n```\n\n\n\n\n    ```ts ./index.tsx\n    import { createClient } from '@supabase/supabase-js'\n    import { Database } from 'lib/database.types'\n\n\n```const supabase = createClient<Database>(\n  process.env.SUPABASE_URL,\n  process.env.SUPABASE_ANON_KEY\n)\n```\n```\n\n\n\n\nType hints\n\n\n\n\n````supabase-js` always returns a `data` object (for success), and an `error` response (for unsuccessful requests).\n\nThis provides a simple interface to get the relevant types returned from any function:\n```\n\n\n\n\n```ts\n    export async function getMovies() {\n      return await supabase.from('movies').select(`id, title`)\n    }\n\n\n```type MoviesResponse = Awaited<ReturnType<typeof getMovies>>\nexport type MoviesResponseSuccess = MoviesResponse['data']\nexport type MoviesResponseError = MoviesResponse['error']\n\n````\n```\n\n\n\n\nNested tables\n\n\n    For advanced queries such as nested tables, you may want to construct your own types.\n  \n\n    ```ts ./index.ts\n      import supabase from '~/lib/supabase'\n      import type { Database } from '~/lib/database.types'\n\n\n```  async function getMovies() {\n    return await supabase.from('movies').select('id, title, actors(\\*)')\n  }\n\n  type Actors = Database['public']['tables']['actors']['row']\n  type MoviesResponse = Awaited<ReturnType<typeof getMovies>>\n  type MoviesResponseSuccess = MoviesResponse['data'] & {\n  actors: Actors[]\n  }\n\n```\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "Upgrade the client library",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/javascript/v1/upgrade-guide.mdx",
    "content": "\nid: upgrade-guide\ntitle: Upgrade to supabase-js v2\ndescription: 'Learn how to upgrade to supabase-js v2.'\n\nsupabase-js v2 focuses on \"quality-of-life\" improvements for developers and addresses some of the largest pain points in v1. v2 includes type support, a rebuilt Auth library with async methods, improved errors, and more.\nNo new features will be added to supabase-js v1 , but we'll continuing merging security fixes to v1, with maintenance patches for the next 3 months.\nUpgrade the client library\n\n\n\n\n```Install the latest version\n```\n\n\n\n\n`sh\nnpm install @supabase/supabase-js@2`\n\n\n\n\nOptionally if you are using custom configuration with `createClient` then follow below:\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n\n`ts title=src/supabaseClient.ts\nconst supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY, {\n  schema: 'custom',\n  persistSession: false,\n})`\n\n\n`ts title=src/supabaseClient.ts\nconst supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY, {\n  db: {\n    schema: 'custom',\n  },\n  auth: {\n    persistSession: true,\n  },\n})`\n\n\n\n\nRead more about the constructor options.\nAuth methods\nThe signIn() method has been deprecated in favor of more explicit method signatures to help with type hinting. Previously it was difficult for developers to know what they were missing (e.g., a lot of developers didn't realize they could use passwordless magic links).\n\n\nSign in with email and password\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { user, error } = await supabase\n  .auth\n  .signIn({ email, password })`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst {\n  data: { user },\n  error,\n} = await supabase\n  .auth\n  .signInWithPassword({ email, password })`\n\n\n\n\n\n\nSign in with magic link\n\n\n <Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { error } = await supabase\n  .auth\n  .signIn({ email })`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst { error } = await supabase\n  .auth\n  .signInWithOtp({ email })`\n\n\n\n\n\n\nSign in with a third-party provider\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { error } = await supabase\n  .auth\n  .signIn({ provider })`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst { error } = await supabase\n  .auth\n  .signInWithOAuth({ provider })`\n\n\n\n\n\n\nSign in with phone\n\n\n <Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { error } = await supabase\n  .auth\n  .signIn({ phone, password })`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst { error } = await supabase\n  .auth\n  .signInWithPassword({ phone, password })`\n\n\n\n\n\n\nSign in with phone using OTP\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { error } = await supabase\n  .auth\n  .api\n  .sendMobileOTP(phone)`\n\n\n\n{/ prettier-ignore /}\n```ts\nconst { data, error } = await supabase\n  .auth\n  .signInWithOtp({ phone })\n// After receiving a SMS with a OTP.\nconst { data, error } = await supabase\n.auth\n.verifyOtp({ phone, token })\n```\n\n\n\n\n\n\nReset password for email\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .auth\n  .api\n  .resetPasswordForEmail(email)`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .auth\n  .resetPasswordForEmail(email)`\n\n\n\n\n\n\nGet the user's current session\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n\n`ts\nconst session = supabase.auth.session()`\n\n\n`ts\nconst {\n  data: { session },\n} = await supabase.auth.getSession()`\n\n\n\n\n\n\nGet the logged-in user\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n\n`ts\nconst user = supabase.auth.user()`\n\n\n`ts\nconst {\n  data: { session },\n} = await supabase.auth.getSession()\nconst { user } = session`\n\n\n\n\n\n\nUpdate user data for a logged-in user\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { user, error } = await supabase\n  .auth\n  .update({ attributes })`\n\n\n\n`ts\nconst {\n  data: { user },\n  error,\n} = await supabase.auth.updateUser({ attributes })`\n\n\n\n\n\n\nUse a custom `access_token` JWT with Supabase\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n\n`ts\nconst { user, error } = supabase.auth.setAuth(access_token)`\n\n\n{/ prettier-ignore /}\n`ts\nconst supabase = createClient(\n  SUPABASE_URL,\n  SUPABASE_ANON_KEY,\n  {\n    global: {\n      headers: {\n        Authorization: `Bearer ${access_token}`,\n      },\n    },\n  }\n)`\n\n\n\n\nCookie methods\nThe cookie-related methods like `setAuthCookie` and `getUserByCookie` have been removed.\nFor Next.js you can use the Auth Helpers to help you manage cookies.\nIf you can't use the Auth Helpers, you can use server-side rendering.\nSome the PR for additional background information.\nData methods\n`.insert()` / `.upsert()` / `.update()` / `.delete()` don't return rows by default: PR.\nPreviously, these methods return inserted/updated/deleted rows by default (which caused some confusion), and you can opt to not return it by specifying `returning: 'minimal'`. Now the default behavior is to not return rows. To return inserted/updated/deleted rows, add a `.select()` call at the end.\n\n\nInsert and return data\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .from('my_table')\n  .insert({ new_data })`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .from('my_table')\n  .insert({ new_data })\n  .select()`\n\n\n\n\n\n\nUpdate and return data\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .from('my_table')\n  .update({ new_data })\n  .eq('id', id)`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .from('my_table')\n  .update({ new_data })\n  .eq('id', id)\n  .select()`\n\n\n\n\n\n\nUpsert and return data\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .from('my_table')\n  .upsert({ new_data })`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .from('my_table')\n  .upsert({ new_data })\n  .select()`\n\n\n\n\n\n\nDelete and return data\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .from('my_table')\n  .delete()\n  .eq('id', id)`\n\n\n\n{/ prettier-ignore /}\n`ts\nconst { data, error } = await supabase\n  .from('my_table')\n  .delete()\n  .eq('id', id)\n  .select()`\n\n\n\n\nRealtime methods\n\n\nSubscribe\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n\n`ts\nconst userListener = supabase\n  .from('users')\n  .on('*', (payload) => handleAllEventsPayload(payload.new))\n  .subscribe()`\n\n\n`ts\nconst userListener = supabase\n  .channel('public:user')\n  .on('postgres_changes', { event: '*', schema: 'public', table: 'user' }, (payload) =>\n    handleAllEventsPayload()\n  )\n  .subscribe()`\n\n\n\n\n\n\nUnsubscribe\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"1.0x\"\n\n\n\n`ts\nuserListener.unsubscribe()`\n\n\n`ts\nsupabase.removeChannel(userListener)`\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "introduction.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/ref/javascript/v1/introduction.mdx",
    "content": "\nid: introduction\ntitle: Introduction\nhideTitle: true\n\n\n\n\nJavascript Client Library\n@supabase/supabase-js\n\n\n\n\n  You're viewing the docs for an older version of the `supabase-js` library. Learn how to [upgrade\n  to the latest version](/docs/reference/javascript/v1/upgrade-guide).\n\n\nThis reference documents every object and method available in Supabase's isomorphic JavaScript\nlibrary,\u00a0supabase-js. You can use\u00a0supabase-js to interact with your Postgres database, listen to\ndatabase changes, invoke Deno Edge Functions, build login and user management functionality, and\nmanage large files.",
    "tag": "supabase"
  },
  {
    "title": "Additional Links",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/javascript.mdx",
    "content": "\nslug: /\nsidebar_position: 1\nid: supabase-js\ntitle: Supabase JavaScript Library\nsidebar_label: Supabase JavaScript Library\nhide_table_of_contents: true\n\nThis reference documents every object and method available in Supabase's isomorphic JavaScript library, `supabase-js`.\nYou can use the `supabase-js` library to:\n\ninteract with your Postgres database\nlisten to database changes\ninvoke Deno Edge Functions\nbuild login and user management functionality\nmanage large files\n\nAdditional Links\n\nSource Code: github.com/supabase/supabase-js\nTypeDoc: supabase.github.io/supabase-js\nNPM: npmjs.com/package/@supabase/supabase-js\n",
    "tag": "supabase"
  },
  {
    "title": "Additional Links",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/cli.mdx",
    "content": "\nid: intro\nslug: /\nsidebar_position: 1\nsidebar_label: Supabase CLI\ntitle: Supabase CLI\nhide_table_of_contents: true\n\nThe Supabase CLI provides tools to develop your project locally and deploy to the Supabase Platform.\nThe CLI is still under development, but it contains all the functionality for working with your Supabase projects and the Supabase Platform.\n\nRun Supabase locally: supabase start\nManage database migrations: supabase migration\nCI/CD for releasing to production: supabase db push\nManage your Supabase projects: supabase projects\nGenerate types directly from your database schema: supabase gen types\nA community-supported GitHub Action to generate TypeScript types\nShell autocomplete: supabase completion\nA community-supported Fig autocomplete spec for macOS terminal\n\nAdditional Links\n\nInstall the Supabase CLI\nSource code\nKnown bugs and issues\nSupabase CLI v1 and Management API Beta\n",
    "tag": "supabase"
  },
  {
    "title": "Client libraries",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/auth.mdx",
    "content": "\nslug: /\nsidebar_position: 1\nid: auth-server\ntitle: Supabase Auth Server\nsidebar_label: Supabase Auth Server\n\nThe Supabase Auth Server (GoTrue) is a JSON Web Token (JWT)-based API for managing users and issuing access tokens.\nGoTrue is an open-source API written in Golang, that acts as a self-standing API service for handling user registration and authentication for JAM projects. It's based on OAuth2 and JWT and handles user signup, authentication, and custom user data.\nClient libraries\n\nJavaScript\nDart\n\nAdditional Links\n\nSource Code\nKnown bugs and issues\n",
    "tag": "supabase"
  },
  {
    "title": "For non-Flutter projects",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/dart.mdx",
    "content": "\nid: intro\nslug: /\ntitle: Supabase Flutter Library\nsidebar_label: Supabase Flutter Library\n\nThis reference documents every object and method available in Supabase's isomorphic Flutter library, supabase-flutter.\nYou can use the `supabase-flutter` library to:\n\ninteract with your Postgres database\nlisten to database changes\ninvoke Deno Edge Functions\nbuild login and user management functionality\nmanage large files\n\nFor non-Flutter projects\nWe also have supabase-dart for non-Flutter Dart projects, such as server-side Dart or Angular-Dart.\nsupabase-dart shares most of the APIs with supabase-flutter without being dependent on Flutter so that you can use Supabase anywhere you can run Dart!\nAdditional Links\n\nSource Code: github.com/supabase/supabase-flutter\n",
    "tag": "supabase"
  },
  {
    "title": "Status",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/api.mdx",
    "content": "\nslug: /\nsidebar_position: 1\nid: management-api\ntitle: Management API\nsidebar_label: Management API\n\nThe Management API allows you to manage your projects programmatically.\nStatus\nThe Management API is in `beta`. It is usable in it's current state, but it's likely that there will be breaking changes.\nAuthentication\nAll API requests require a Supabase Personal token to be included in the Authorization header: `Authorization Bearer <supabase_personal_token`.\nTo generate or manage your API token, visit your account page.\nYour API tokens carry the same privileges as your user account, so be sure to keep it secret.\n`bash\n$ curl https://api.supabase.com/v1/projects \\\n-H \"Authorization: Bearer sbp_bdd0\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u20224f23\"`\nAll API requests must be authenticated and made over HTTPS.\nRate limits\nThe API is currently subject to our fair-use policy. In the future, are likely to introduce rate limits.\nAll resources created via the API are subject to the pricing detailed on our Pricing pages.\nAdditional links\n\nOpenAPI Docs\nOpenAPI Spec\n",
    "tag": "supabase"
  },
  {
    "title": "Why not just use PostgreSQL's `NOTIFY`?",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/realtime.mdx",
    "content": "\nslug: /\nsidebar_position: 1\nid: realtime\ntitle: Supabase Realtime Server\nsidebar_label: Supabase Realtime Server\n\nSupabase Realtime is a server built with Elixir using the Phoenix Framework that allows you to listen to changes in your PostgreSQL database via logical replication and then broadcast those changes via WebSockets.\nThere are two versions of this server: `Realtime` and `Realtime RLS`.\n`Realtime` server works by:\n\nlistening to PostgreSQL's replication functionality (using PostgreSQL's logical decoding)\nconverting the byte stream into JSON\nbroadcasting to all connected clients over WebSockets\n\n`Realtime RLS` server works by:\n\npolling PostgreSQL's replication functionality (using PostgreSQL's logical decoding and wal2json output plugin)\npassing database changes to a Write Ahead Log Realtime Unified Security (WALRUS) PostgresSQL function and receiving a list of authorized subscribers depending on Row Level Security (RLS) policies\nconverting the changes into JSON\nbroadcasting to authorized subscribers over WebSockets\n\nWhy not just use PostgreSQL's `NOTIFY`?\nA few reasons:\n\nYou don't have to set up triggers on every table.\n`NOTIFY` has a payload limit of 8000 bytes and will fail for anything larger. The usual solution is to send an ID and then fetch the record, but that's heavy on the database.\n`Realtime` server consumes two connections to the database, then you can connect many clients to this server. Easier on your database, and to scale up you just add additional `Realtime` servers.\n\nBenefits\n\nThe beauty of listening to the replication functionality is that you can make changes to your database from anywhere - your API, directly in the DB, via a console, etc. - and you will still receive the changes via WebSockets.\nDecoupling. For example, if you want to send a new slack message every time someone makes a new purchase you might build that functionality directly into your API. This allows you to decouple your async functionality from your API.\nThis is built with Phoenix, an extremely scalable Elixir framework.\n\nDoes this server guarantee delivery of every data change?\nNot yet! Due to the following limitations:\n\nPostgres database runs out of disk space due to Write-Ahead Logging (WAL) buildup, which can crash the database and prevent Realtime server from receiving and broadcasting changes. This can be mitigated in the Realtime RLS version of this server by setting the Postgres config `max_slot_wal_keep_size` to a reasonable size.\nRealtime server can crash due to a larger replication lag than available memory, forcing the creation of a new replication slot and resetting replication to read from the latest WAL data.\nWhen Realtime server falls too far behind for any reason, for example disconnecting from database as WAL continues to build up, then database can delete WAL segments the server still needs to read from, for example after reconnecting.\n\nClient libraries\n\nJavaScript\nDart\n\nAdditional Links\n\nSource Code\nKnown bugs and issues\n",
    "tag": "supabase"
  },
  {
    "title": "Client libraries",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/storage.mdx",
    "content": "\nslug: /\nsidebar_position: 1\nid: storage-server\ntitle: Supabase Storage Server\nsidebar_label: Supabase Storage Server\n\nAn S3 compatible object storage service that integrates with Postgres.\n\nUses Postgres as it's datastore for storing metadata\nAuthorization rules are written as Postgres Row Level Security policies\nIntegrates with S3 as the storage backend (with more in the pipeline!)\nExtremely lightweight and performant\n\nRead this post on why we decided to build a new object storage service.\nClient libraries\n\nJavaScript\nDart\n\nAdditional Links\n\nSource Code\nKnown bugs and issues\nStorage Guides\n",
    "tag": "supabase"
  },
  {
    "title": "Additional Links",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/dart/v0.mdx",
    "content": "\nid: intro\nslug: /\nsidebar_label: Supabase Dart Library\ntitle: Supabase Dart Library\n\n\nYou're viewing the docs for an older version of the `supabase-flutter` library.\n\nThis reference documents every object and method available in Supabase's isomorphic Dart library, `supabase-dart`.\nYou can use the `supabase-dart` library to:\n\ninteract with your Postgres database\nlisten to database changes\ninvoke Deno Edge Functions\nbuild login and user management functionality\nmanage large files\n\nAdditional Links\n\nSource Code: github.com/supabase/supabase-dart\n",
    "tag": "supabase"
  },
  {
    "title": "Flutter",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/dart/initializing.mdx",
    "content": "\nid: initializing\ntitle: 'Initializing'\nslug: initializing\n\nimport Tabs from '@theme/Tabs'\nimport TabItem from '@theme/TabItem'\nFlutter\nFor `supabase-flutter`, you will be using the static `initialize()` method on `Supabase` class.\nFlutter `initialize()`\n`dart title=main.dart\nFuture<void> main() async {\n  await Supabase.initialize(url: 'https://xyzcompany.supabase.co', anonKey: 'public-anon-key');\n  runApp(MyApp());\n}`\nAccess `SupabaseClient` instance\nOnce you initialize Supabase in your `main()` method, you can access the `SupabaseClient` instance from anywhere in your app.\n`dart\nfinal supabase = Supabase.instance.client;`\nCall `initialize()` with custom headers\nYou can pass `headers` to initialize your Supabase client with customer headers. \nHere is an example of passing a custom auth header to Supabase client.\n`dart title=main.dart\nFuture<void> main() async {\n  await Supabase.initialize(\n    url: 'https://xyzcompany.supabase.co',\n    anonKey: 'public-anon-key',\n    headers: {\n      'Authorization': 'Bearer $accessToken',\n    },\n  );\n  runApp(const MyApp());\n}`\nCall `initialize()`multiple times\nYou can initialize Supabase multiple times in your app. When doing so, call `dispose()` each time before you initialize again.\n```dart\nSupabase.instance.dispose();\nawait Supabase.initialize(url: 'https://xyzcompany.supabase.co', anonKey: 'public-anon-key');\n```\nOther Dart Projects\nYou can initialize a new Supabase client using the `SupabaseClient()` method.\nThe Supabase client is your entrypoint to the rest of the Supabase functionality\nand is the easiest way to interact with everything we offer within the Supabase ecosystem.\nDart `SupabaseClient()`\n```dart\nfinal supabase = SupabaseClient('https://xyzcompany.supabase.co', 'public-anon-key');",
    "tag": "supabase"
  },
  {
    "title": "Examples",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/postgres/columns.mdx",
    "content": "\nid: columns\ntitle: \"Columns\"\nslug: columns\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/postgres.yml\n\nimport Tabs from '@theme/Tabs';\nimport TabsPanel from '@theme/TabsPanel';\nCreating columns.\n\n\n`sql\ncreate table table_name (\n  id integer primary key,\n  data jsonb,\n  name text\n);`\n\n\nExamples\nDuring table creation\n\n\n`sql\ncreate table table_name (\n  id integer primary key,\n  data jsonb,\n  name text\n);`\n\n\nCreate column\n\n\n`sql\nalter table new_table\nadd new_column text;`\n",
    "tag": "supabase"
  },
  {
    "title": "Notes",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/postgres/changing-timezones.mdx",
    "content": "\nid: changing-timezones\ntitle: \"Changing Timezones\"\nslug: changing-timezones\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/postgres.yml\n\nimport Tabs from '@theme/Tabs';\nimport TabsPanel from '@theme/TabsPanel';\nData types.\n\n\n`sql\nalter database postgres \nset timezone to 'America/New_York';`\n\n\nNotes\n\nView a full list of timezones on Wikipedia.\n\nExamples\nChange timezone\n\n\n`sql\nalter database postgres \nset timezone to 'America/New_York';`\n\n\nFull list of timezones\nGet a full list of timezones supported by your database. This will return the following columns:\n\n`name`: Time zone name\n`abbrev`: Time zone abbreviation\n`utc_offset`: Offset from UTC (positive means east of Greenwich)\n`is_dst`: True if currently observing daylight savings\n\n\n\n`sql\nselect name, abbrev, utc_offset, is_dst\nfrom pg_timezone_names() \norder by name;`\n\n\nSearch for a specific timezone\nUse `ilike` (case insensitive search) to find specific timezones.\n\n\n`sql\nselect * \nfrom pg_timezone_names() \nwhere name ilike '%york%';`\n",
    "tag": "supabase"
  },
  {
    "title": "or ",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/postgres/connection-strings.mdx",
    "content": "\nid: connection-strings\ntitle: \"Connection Strings\"\nslug: connection-strings\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/postgres.yml\n\nimport Tabs from '@theme/Tabs';\nimport TabsPanel from '@theme/TabsPanel';\nThere are various ways to connect to your database, depending on the configuration of your Postgres instance and the tool which you are connecting with.\n\n\n```bash\npostgres://postgres:postgres@localhost:5432/postgres\nor\npostgresql://postgres:postgres@localhost:5432/postgres\n```\n\n\nNotes\n\nOfficial Documentation.\nAvoid using special characters usernames and passwords. If you use special characters in a connection URL, you'll need to URL encode any special characters.\n\nExamples\nBasic connection string\nIf you're using a default setup, your postgres connection string will likely be in the format: \n`postgres://{user}:{password}@{host}:{port}/{database_name}`\n\n\n```bash\npostgres://postgres:postgres@localhost:5432/postgres\nor\npostgresql://postgres:postgres@localhost:5432/postgres\n```\n\n\nJDBC\nSee full documentation.\n\n\n`bash\njdbc:postgresql://{host}:{port}/{database_name}`\n\n\nADO.NET\nSee full documentation.\n\n\n`bash\nServer=host;Port=5432;User Id=username;Password=secret;Database=database_name;`\n\n\nPHP\nSee full documentation.\n\n\n`bash\nhost=hostname port=5432 dbname=databasename user=username password=secret`\n",
    "tag": "supabase"
  },
  {
    "title": "Examples",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/postgres/publications.mdx",
    "content": "\nid: publications\ntitle: \"Publications\"\nslug: publications\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/postgres.yml\n\nimport Tabs from '@theme/Tabs';\nimport TabsPanel from '@theme/TabsPanel';\nPublications are a way of grouping changes generated from a table or a group of tables. \nThese changes can then be sent to other systems (usually another Postgres database).\nExamples\nCreate a Publication\nThis publication will contain all changes to all tables.\n\n\n`sql\ncreate publication publication_name \nfor all tables;`\n\n\nCreate a Publication which listens to individual tables\n\n\n`sql\ncreate publication publication_name \nfor table table_one, table_two;`\n\n\nAdd tables to an existing publication\n\n\n`sql\nalter publication publication_name \nadd table table_name;`\n\n\nListens to inserts only\n\n\n`sql\ncreate publication publication_name \nfor all tables\nwith (publish = 'insert');`\n\n\nListens to updates only\n\n\n`sql\ncreate publication publication_name \nfor all tables\nwith (publish = 'update');`\n\n\nListens to deletions only\n\n\n`sql\ncreate publication publication_name \nfor all tables\nwith (publish = 'delete');`\n\n\nRemove a Publication\n\n\n`sql\ndrop publication if exists publication_name;`\n\n\nRecreate a Publication\nIf you are planning to re-create a publication, it's best to do it in a transaction to ensure the operation succeeds.\n\n\n```sql\nbegin; \n  -- remove the realtime publication\n  drop publication if exists publication_name; \n-- re-create the publication but don't enable it for any tables\n  create publication publication_name;\ncommit;\n```\n",
    "tag": "supabase"
  },
  {
    "title": "with schema ",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/postgres/tables.mdx",
    "content": "\nid: tables\ntitle: \"Tables\"\nslug: tables\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/postgres.yml\n\nimport Tabs from '@theme/Tabs';\nimport TabsPanel from '@theme/TabsPanel';\nTables are similar to excel spreadsheets. They contain columns & rows of data. There are a few key differences from a spreadsheet however:\n\nEvery column is a strict type of data. When you set up a column, you must define what \"data type\" it is.\nTables can be joined together through relationships. For example you can have a \"users\" table, which is joined to a \"teams\" table.\n\n\n\n```sql\ncreate table table_name (\n  id integer primary key,\n  data jsonb,\n  name text\n);\nwith schema\ncreate table schema_name.table_name (\n  id integer primary key,\n  data jsonb,\n  name text\n);\n```\n\n\nNotes\n\nTables contain columns, rows, triggers, comments, \nIt is best practice to use lowercase and underscores when naming tables. For example: `table_name`, not `Table Name`.\nTables belong to schemas. If you don't explicitly pass the schema, Postgres will assume that you want to create the table in the `public` schema.\n\nExamples\nCreate table\n\n\n```sql\ncreate table table_name (\n  id integer primary key,\n  data jsonb,\n  name text\n);\nwith schema\ncreate table schema_name.table_name (\n  id integer primary key,\n  data jsonb,\n  name text\n);\n```\n\n\nPrimary keys using multiple columns\n\n\n`sql\ncreate table table_name (\n  column_1 data_type,\n  column_2 data_type\n  -- Constraints:\n  primary key (column_1, column_2)\n);`\n\n\nMultiple foreign keys to the same table\n\n\n`sql\nalter table table_name\n  add constraint constraint_name_1 foreign key (column_1) references foreign_table(id),\n  add constraint constraint_name_2 foreign key (column_2) references foreign_table(id);`\n\n\nDelete a table\n\n\n`sql\ndelete table if exists table_name;`\n",
    "tag": "supabase"
  },
  {
    "title": "Notes",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/postgres/schemas.mdx",
    "content": "\nid: schemas\ntitle: \"Schemas\"\nslug: schemas\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/postgres.yml\n\nimport Tabs from '@theme/Tabs';\nimport TabsPanel from '@theme/TabsPanel';\nSchemas are like \"folders\". They help to keep your database organized. \nSchemas are particularly useful for security. You can set different permissions on each schema. \nFor example, you might want to use a `public` schema for user-facing data, and an `auth` schema for all logins and secured data.\n\n\n`sql\ncreate schema schema_name;`\n\n\nNotes\n\nSchemas contain tables, columns, triggers, functions, etc.\nPostgres comes with a `public` schema set up by default.\nIt is best practice to use lowercase and underscores when naming schemas. For example: `schema_name`, not `Schema Name`.\n\nExamples\nCreating a schema\n\n\n`sql\ncreate schema schema_name;`\n\n\nRemoving a schema\n\n\n`sql\ndrop schema if exists schema_name;`\n\n\nUsing special characters\nAlthough it's not recommended, you can use uppercase and spaces when naming your schema by wrapping the name with double-quotes.\nAs a result, you will always need to use double-quotes when referencing your schema.\n\n\n`sql\ncreate schema \"Schema Name\";`\n",
    "tag": "supabase"
  },
  {
    "title": "installing.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/csharp/installing.mdx",
    "content": "\nid: installing\ntitle: 'Installing & Initialization'\nslug: installing\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/supabase.yml\n\nInstall from NuGet\n\n\n\n\n```You can install Supabase package from [nuget.org](https://www.nuget.org/packages/supabase-csharp/)\n```\n\n\n\n\n\n\n```<Tabs\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"csharp\">\n  <TabPanel id=\"csharp\" label=\"Terminal\">\n\n    ```sh Terminal\n    dotnet add package supabase-csharp\n    ```\n\n  </TabPanel>\n</Tabs>\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "initializing.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/csharp/initializing.mdx",
    "content": "\nid: initializing\ntitle: 'Initializing'\nslug: initializing\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/web/spec/supabase.yml\n\nInitializing a new Client\n\n\nInitializing a new client is pretty straightforward. Find your project url and public key from the\nadmin panel and pass it into your client initialization function.\n\n\n\n\n```<Tabs\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"csharp-init-standard\">\n  <TabPanel id=\"csharp-init-standard\" label=\"Standard\">\n\n    ```csharp\n    var url = Environment.GetEnvironmentVariable(\"SUPABASE_URL\");\n    var key = Environment.GetEnvironmentVariable(\"SUPABASE_KEY\");\n\n    var options = new Supabase.SupabaseOptions\n    {\n      AutoConnectRealtime = true\n    };\n\n    var supabase = new Supabase.Client(url, key, options);\n    await supabase.InitializeAsync();\n    ```\n\n  </TabPanel>\n\n  <TabPanel id=\"csharp-init-maui\" label=\"Dependency Injection (Maui-like)\">\n\n    ```csharp\n    public static MauiApp CreateMauiApp()\n    {\n          // ...\n          var builder = MauiApp.CreateBuilder();\n\n          var url = Environment.GetEnvironmentVariable(\"SUPABASE_URL\");\n          var key = Environment.GetEnvironmentVariable(\"SUPABASE_KEY\");\n          var options = new SupabaseOptions\n          {\n            AutoRefreshToken = true,\n            AutoConnectRealtime = true,\n            SessionHandler = new SupabaseSessionHandler()\n          };\n\n          // Note the creation as a singleton.\n          builder.Services.AddSingleton(provider => new Supabase.Client(url, key, options));\n    }\n    ```\n\n  </TabPanel>\n</Tabs>\n```\n\n\n",
    "tag": "supabase"
  },
  {
    "title": "2.0.0",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/javascript/release-notes.mdx",
    "content": "\nid: release-notes\ntitle: Release Notes\n\nSupabase.js v2 release notes.\n2.0.0\nInstall the latest with `npm install @supabase/supabase-js`.\nExplicit constructor options\nAll client specific options within the constructor are keyed to the library: PR:\n`jsx\nconst supabase = createClient(apiURL, apiKey, {\n  db: {\n    schema: 'public',\n  },\n  auth: {\n    storage: AsyncStorage,\n    autoRefreshToken: true,\n    persistSession: true,\n    detectSessionInUrl: true,\n  },\n  realtime: {\n    channels,\n    endpoint,\n  },\n  global: {\n    fetch: customFetch,\n    headers: DEFAULT_HEADERS,\n  },\n})`\nTypescript support\nThe libraries now support typescript.\n```ts\n// v2 - definitions are injected in`createClient()`\nimport type { Database } from './DatabaseDefinitions'\nconst supabase = createClient(SUPABASE_URL, ANON_KEY)\nconst { data } = await supabase.from('messages').select().match({ id: 1 })\n// v1 -- previously definitions were injected in the `from()` method\nsupabase.from('messages').select('*')\n```\nTypes can be generated via the CLI:\n`bash\nsupabase start\nsupabase gen types typescript --local > DatabaseDefinitions.ts`\nData operations return minimal\n`.insert()` / `.upsert()` / `.update()` / `.delete()` don't return rows by default: PR.\nPreviously, these methods return inserted/updated/deleted rows by default (which caused some confusion), and you can opt to not return it by specifying `returning: 'minimal'`. Now the default behavior is to not return rows. To return inserted/updated/deleted rows, add a `.select()` call at the end, e.g.:\n`sql\nconst { data, error } = await supabase\n    .from('my_table')\n    .delete()\n    .eq('id', 1)\n    .select()`\nNew ordering defaults\n`.order()` now defaults to Postgres\u2019s default: PR.\nPreviously `nullsFirst` defaults to `false` , meaning `null`s are ordered last. This is bad for performance if e.g. the column uses an index with `NULLS FIRST` (which is the default direction for indexes).\nCookies and localstorage namespace\nStorage key name in the Auth library has changed to include project reference which means that existing websites that had their JWT expiry set to a longer time could find their users logged out with this upgrade.\n`jsx\nconst defaultStorageKey = `sb-${new URL(this.authUrl).hostname.split('.')[0]}-auth-token``\nNew Auth Types\nTypescript typings have been reworked. `Session` interface now guarantees that it will always have an `access_token`, `refresh_token` and `user`\n`jsx\ninterface Session {\n    provider_token?: string | null\n    access_token: string\n    expires_in?: number\n    expires_at?: number\n    refresh_token: string\n    token_type: string\n    user: User\n}`\nNew Auth methods\nWe're removing the `signIn()` method in favor of more explicit function signatures:\n`signInWithPassword()`, `signInWithOtp()`, and `signInWithOtp()`.\n`ts\n// v2\nconst { data } = await supabase.auth.signInWithPassword({\n  email: 'hello@example',\n  password: 'pass',\n})\n// v1\nconst { data } = await supabase.auth.signIn({\n  email: 'hello@example',\n  password: 'pass',\n})`\nNew Realtime methods\nThere is a new `channel()` method in the Realtime library, which will be used for our Multiplayer updates.\n```ts\nsupabase\n  .channel('any_string_you_want')\n  .on('presence', { event: 'track' }, (payload) => {\n    console.log(payload)\n  })\n  .subscribe()\nsupabase\n  .channel('any_string_you_want')\n  .on(\n    'postgres_changes',\n    {\n      event: 'INSERT',\n      schema: 'public',\n      table: 'movies',\n    },\n    (payload) => {\n      console.log(payload)\n    }\n  )\n  .subscribe()\n```\nWe will deprecate the `.from().on().subscribe()` method previosuly used for listening to postgres changes.\nDeprecated setAuth()\nDeprecated and removed `setAuth()` . To set a custom `access_token` jwt instead, pass the custom header into the `createClient()` method provided: (PR)\nAll changes\n\n`supabase-js`\n`shouldThrowOnError` has been removed until all the client libraries support this option (PR).\n`postgrest-js`\nTypeScript typings have been reworked PR\nUse `undefined` instead of `null` for function params, types, etc. (https://github.com/supabase/postgrest-js/pull/278)\nSome features are now obsolete: (https://github.com/supabase/postgrest-js/pull/275)\nfilter shorthands (e.g. `cs` vs. `contains`)\n`body` in response (vs. `data`)\n`upsert`ing through the `.insert()` method\n`auth` method on `PostgrestClient`\nclient-level `throwOnError`\n\n\n`gotrue-js`\n`supabase-js` client allows passing a `storageKey` param which will allow the user to set the key used in local storage for storing the session. By default, this will be namespace-d with the supabase project ref. (PR)\n`signIn` method is now split into `signInWithPassword` , `signInWithOtp` , `signInWithOAuth` (PR)\nDeprecated and removed `session()` , `user()` in favour of using `getSession()` instead. `getSession()` will always return a valid session if a user is already logged in, meaning no more random logouts. (PR)\nDeprecated and removed setting for `multitab` support because `getSession()` and gotrue\u2019s reuse interval setting takes care of session management across multiple tabs (PR)\nNo more throwing of random errors, gotrue-js v2 always returns a custom error type: (PR)\n`AuthSessionMissingError`\nIndicates that a session is expected but missing\n`AuthNoCookieError`\nIndicates that a cookie is expected but missing\n`AuthInvalidCredentialsError`\nIndicates that the incorrect credentials were passed\n\n\nRenamed the `api` namespace to `admin` , the `admin` namespace will only contain methods that should only be used in a trusted server-side environment with the service role key\nMoved `resetPasswordForEmail` , `getUser` and `updateUser` to the `GoTrueClient` which means they will be accessible from the `supabase.auth` namespace in `supabase-js` instead of having to do `supabase.auth.api` to access them\nRemoved `sendMobileOTP` , `sendMagicLinkEmail` in favor of `signInWithOtp`\nRemoved `signInWithEmail`, `signInWithPhone` in favor of `signInWithPassword`\nRemoved `signUpWithEmail` , `signUpWithPhone` in favor of `signUp`\nReplaced `update` with `updateUser`\n`storage-js`\nReturn types are more strict. Functions types used to indicate that the data returned could be null even if there was no error. We now make use of union types which only mark the data as null if there is an error and vice versa. (PR)\nThe `upload` and `update` function returns the path of the object uploaded as the `path` parameter. Previously the returned value had the bucket name prepended to the path which made it harder to pass the value on to other storage-js methods since all methods take the bucket name and path separately. We also chose to call the returned value `path` instead of `Key` (PR)\n`getPublicURL` only returns the public URL inside the data object. This keeps it consistent with our other methods of returning only within the data object. No error is returned since this method cannot does not throw an error (PR)\nsigned urls are returned as `signedUrl` instead of `signedURL` in both `createSignedUrl` and `createSignedUrls` (PR)\nEncodes URLs returned by `createSignedUrl`, `createSignedUrls` and `getPublicUrl` (PR)\n`createsignedUrl` used to return a url directly and and within the data object. This was inconsistent. Now we always return values only inside the data object across all methods. (PR)\n`createBucket` returns a data object instead of the name of the bucket directly. (PR)\nFixed types for metadata (PR)\nBetter error types make it easier to track down what went wrong quicker.\n`SupabaseStorageClient` is no longer exported. Use `StorageClient` instead. (PR).\n`realtime-js`\n`RealtimeSubscription` class no longer exists and replaced by `RealtimeChannel`.\n`RealtimeClient`'s `disconnect` method now returns type of `void` . It used to return type of `Promise<{ error: Error | null; data: boolean }`.\nRemoved `removeAllSubscriptions` and `removeSubscription` methods from `SupabaseClient` class.\nRemoved `SupabaseRealtimeClient` class.\nRemoved `SupabaseQueryBuilder` class.\nRemoved `SupabaseEventTypes` type.\nThinking about renaming this to something like `RealtimePostgresChangeEvents` and moving it to `realtime-js` v2.\n\n\nRemoved `.from(\u2019table\u2019).on(\u2019INSERT\u2019, () \u21d2 {}).subscribe()` in favor of new Realtime client API.\n`functions-js`\nsupabase-js v1 only threw an error if the fetch call itself threw an error (network errors, etc) and not if the function returned HTTP errors like 400s or 500s. We have changed this behaviour to return an error if your function throws an error.\nWe have introduced new error types to distinguish between different kinds of errors. A `FunctionsHttpError` error is returned if your function throws an error, `FunctionsRelayError` if the Supabase Relay has an error processing your function and `FunctionsFetchError` if there is a network error in calling your function.\nThe correct content-type headers are automatically attached when sending the request if you don\u2019t pass in a `Content-Type` header and pass in an argument to your function. We automatically attach the content type for `Blob`, `ArrayBuffer`, `File`, `FormData` ,`String` . If it doesn\u2019t match any of these we assume the payload is `json` , we serialise the payload as JSON and attach the content type as `application/json`.\n",
    "tag": "supabase"
  },
  {
    "title": "Generating types",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/javascript/typescript-support.mdx",
    "content": "\nid: typescript-support\ntitle: Typescript Support\n\n`supabase-js` supports Typescript.\nGenerating types\nYou can use our CLI to generate types:\n`bash\nsupabase start\nsupabase gen types typescript --local > lib/database.types.ts`\nThese types are generated directly from your database. Given a table `public.movies`, the definition will provide the following data:\n`tsx hello.ts\ninterface Database {\n  public: {\n    Tables: {\n      movies: {\n        Row: {} // The data expected to be returned from a \"select\" statement.\n        Insert: {} // The data expected passed to an \"insert\" statement.\n        Update: {} // The data expected passed to an \"update\" statement.\n      }\n    }\n  }\n}`\nThere is a difference between `selects`, `inserts`, and `updates`, because often you will set default values in your database for specific columns.\nWith default values you do not need to send any data over the network, even if that column is a \"required\" field. Our type system is granular\nenough to handle these situations.\nInjecting type definitions\nYou can enrich the supabase client with the types you generated with Supabase.\n```ts\nimport { createClient } from '@supabase/supabase-js'\nimport { Database } from 'lib/database.types'\nconst supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_ANON_KEY)\n```\nType hints\n`supabase-js` always returns a `data` object (for success), and an `error` response (for unsuccessful requests).\nThis provides a simple interface to get the relevant types returned from any function:\n```ts\nexport async function getMovies() {\n  return await supabase.from('movies').select(`id, title`)\n}\ntype MoviesResponse = Awaited>\nexport type MoviesResponseSuccess = MoviesResponse['data']\nexport type MoviesResponseError = MoviesResponse['error']\n```\nNested tables\nFor advanced queries such as nested tables, you may want to construct your own types.\n```ts\nimport supabase from '~/lib/supabase'\nimport type { Database } from '~/lib/database.types'\nasync function getMovies() {\n  return await supabase.from('movies').select('id, title, actors(*)')\n}\ntype Actors = Database['public']['Tables']['actors']['Row']\ntype MoviesResponse = Awaited>\ntype MoviesResponseSuccess = MoviesResponse['data'] & {\n  actors: Actors[]\n}",
    "tag": "supabase"
  },
  {
    "title": "JavaScript",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/javascript/v1/installing.mdx",
    "content": "\nid: installing\ntitle: 'Installing'\nslug: installing\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/spec/supabase_js_v1.yml\n\nimport Tabs from '@theme/Tabs'\nimport TabItem from '@theme/TabItem'\nAll JavaScript libraries are built directly by the Supabase team.\nOther languages are built by the community and supported by Supabase.\nJavaScript\nVia NPM\n`bash\nnpm install @supabase/supabase-js`\nVia Yarn\n`bash\nyarn add @supabase/supabase-js`\nFind the source code on GitHub.\nOr via CDN\n```js\n\n//or\n",
    "tag": "supabase"
  },
  {
    "title": "Usage with TypeScript",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/javascript/v1/generating-types.mdx",
    "content": "\nid: generating-types\ntitle: 'Generating Types'\nslug: generating-types\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/spec/supabase_js_v1.yml\n\nimport Tabs from '@theme/Tabs'\nimport TabItem from '@theme/TabItem'\nSupabase will soon release native type generators that dump your database types for various languages. For now, we support TypeScript through third-party tools.\nUsage with TypeScript\n`supabase-js` ships with type definitions for usage with TypeScript and for convenient IntelliSense auto-complete and documentation in your editor.\nWhen using TypeScript, you can pass the type of database row as a type parameter to the `from` method to get better auto-completion support down the chain.\nIf you don't provide a type for the row you need to explicitly pass `from<any>('tableName')`.\n```ts\ntype Message = {\n  id: number\n  inserted_at: string\n  message: string\n  user_id: string\n  channel_id: number\n  author: { username: string }\n}\nconst response = await supabase\n  .from('messages') // Message maps to the type of the row in your database.\n  .select('*, author:user_id(username)')\n  .match({ channel_id: 2 }) // Your IDE will be able to help with auto-completion.\nresponse.data // Response data will be of type Array.\n// If you don't provide a type for the row you need to explicitly pass `from<any>('tableName')`.\nconst response = await supabase\n  .from('messages')\n  .select('*, author:user_id(username)')\n  .match({ channel_id: 2 })\nresponse.data // Response data will be of type Array.",
    "tag": "supabase"
  },
  {
    "title": "Parameters",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/docs/reference/javascript/v1/initializing.mdx",
    "content": "\nid: initializing\ntitle: 'Initializing'\nslug: initializing\ncustom_edit_url: https://github.com/supabase/supabase/edit/master/spec/supabase_js_v1.yml\n\nimport Tabs from '@theme/Tabs'\nimport TabItem from '@theme/TabItem'\nYou can initialize a new Supabase client using the `createClient()` method.\nThe Supabase client is your entrypoint to the rest of the Supabase functionality\nand is the easiest way to interact with everything we offer within the Supabase ecosystem.\nParameters\n\n\n\n\n      supabaseUrl\n    \n\n      required\n    \n\n`string`\n\n\n\n\nThe unique Supabase URL which is supplied when you create a new project in your project dashboard.\n\n  \n\n\n\n\n      supabaseKey\n    \n\n      required\n    \n\n`string`\n\n\n\n\nThe unique Supabase Key which is supplied when you create a new project in your project dashboard.\n\n  \n\n\n\n\n      options\n    \n\n      optional\n    \n\n`SupabaseClientOptions`\n\n\n\n\nNo description provided.\n\n  \n\n\nExamples\ncreateClient()\n```js\nimport { createClient } from '@supabase/supabase-js'\n// Create a single supabase client for interacting with your database\nconst supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n```\nWith additional parameters\n```js\nimport { createClient } from '@supabase/supabase-js'\nconst options = {\n  schema: 'public',\n  headers: { 'x-my-custom-header': 'my-app-name' },\n  autoRefreshToken: true,\n  persistSession: true,\n  detectSessionInUrl: true,\n}\nconst supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key', options)\n```\nAPI schemas\n```js\nimport { createClient } from '@supabase/supabase-js'\n// Provide a custom schema. Defaults to \"public\".\nconst supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key', {\n  schema: 'other_schema',\n})\n```\nBy default the API server points to the `public` schema. You can enable other database schemas within the Dashboard.\nGo to `Settings > API > Schema` and add the schema which you want to expose to the API. You also need to grant `USAGE` on your new schema with the grants you desire, such as `SELECT, INSERT, UPDATE, DELETE`. \nNote: each client connection can only access a single schema, so the code above can access the `other_schema` schema but cannot access the `public` schema.\nCustom `fetch` implementation\n```js\nimport { createClient } from '@supabase/supabase-js'\nconst supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key', {\n  fetch: fetch.bind(globalThis),\n})\n```\n`supabase-js` uses the cross-fetch library to make HTTP requests,\nbut an alternative `fetch` implementation can be provided as an option.",
    "tag": "supabase"
  },
  {
    "title": "Project setup",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/components/MDX/project_setup.mdx",
    "content": "import UserManagementSQLTemplate from './user_management_quickstart_sql_template.mdx'\nimport { Tabs } from 'ui'\nexport const TabPanel = Tabs.Panel\nProject setup\nBefore we start building we're going to set up our Database and API. This is as simple as starting a new Project in Supabase and then creating a \"schema\" inside the database.\nCreate a project\n\nCreate a new project in the Supabase Dashboard.\nEnter your project details.\nWait for the new database to launch.\n\nSet up the database schema\nNow we are going to set up the database schema. We can use the \"User Management Starter\" quickstart in the SQL Editor, or you can just copy/paste the SQL from below and run it yourself.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the SQL Editor page in the Dashboard.\nClick User Management Starter.\nClick Run.\n\n\n\n\n\n\nGet the API Keys\nNow that you've created some database tables, you are ready to insert data using the auto-generated API.\nWe just need to get the Project URL and `anon` key from the API settings.\n\nGo to the API Settings page in the Dashboard.\n",
    "tag": "supabase"
  },
  {
    "title": "storage_management.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/components/MDX/storage_management.mdx",
    "content": "If you upload additional profile photos, they'll accumulate\nin the `avatars` bucket because of their random names with only the latest being referenced\nfrom `public.profiles` and the older versions getting orphaned.\nTo automatically remove obsolete storage objects, extend the database\ntriggers. Note that it is not sufficient to delete the objects from the\n`storage.objects` table because that would orphan and leak the actual storage objects in\nthe S3 backend. Instead, invoke the storage API within Postgres via the `http` extension. \nEnable the http extension for the extensions schema in the Dashboard.\nThen, define the following SQL functions in the SQL Editor to delete\nstorage objects via the API:\n```SQL\ncreate or replace function delete_storage_object(bucket text, object text, out status int, out content varchar)\nreturns record\nlanguage 'plpgsql'\nsecurity definer\nas $$\ndeclare\n  project_url varchar := '';\n  service_role_key varchar := ''; --  full access needed\n  url varchar := project_url||'/storage/v1/object/'||bucket||'/'||object;\nbegin\n  select\n      into status, content\n           result.status::int, result.content::varchar\n      FROM extensions.http((\n    'DELETE',\n    url,\n    ARRAY[extensions.http_header('authorization','Bearer '||service_role_key)],\n    NULL,\n    NULL)::extensions.http_request) as result;\nend;\n$$;\ncreate or replace function delete_avatar(avatar_url text, out status int, out content varchar)\nreturns record\nlanguage 'plpgsql'\nsecurity definer\nas $$\nbegin\n  select\n      into status, content\n           result.status, result.content\n      from public.delete_storage_object('avatars', avatar_url) as result;\nend;\n$$;\n```\nNext, add a trigger that removes any obsolete avatar whenever the\nprofile is updated or deleted:\n```SQL\ncreate or replace function delete_old_avatar()\nreturns trigger\nlanguage 'plpgsql'\nsecurity definer\nas $$\ndeclare\n  status int;\n  content varchar;\nbegin\n  if coalesce(old.avatar_url, '') <> ''\n      and (tg_op = 'DELETE' or (old.avatar_url <> new.avatar_url)) then\n    select\n      into status, content\n      result.status, result.content\n      from public.delete_avatar(old.avatar_url) as result;\n    if status <> 200 then\n      raise warning 'Could not delete avatar: % %', status, content;\n    end if;\n  end if;\n  if tg_op = 'DELETE' then\n    return old;\n  end if;\n  return new;\nend;\n$$;\ncreate trigger before_profile_changes\n  before update of avatar_url or delete on public.profiles\n  for each row execute function public.delete_old_avatar();\n```\nFinally, delete the `public.profile` row before a user is deleted.\nIf this step is omitted, you won't be able to delete users without\nfirst manually deleting their avatar image.\n```SQL\ncreate or replace function delete_old_profile()\nreturns trigger\nlanguage 'plpgsql'\nsecurity definer\nas $$\nbegin\n  delete from public.profiles where id = old.id;\n  return old;\nend;\n$$;\ncreate trigger before_delete_user\n  before delete on auth.users\n  for each row execute function public.delete_old_profile();",
    "tag": "supabase"
  },
  {
    "title": "quickstart_intro.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/components/MDX/quickstart_intro.mdx",
    "content": "This tutorial demonstrates how to build a basic user management app. The app authenticates and identifies the user, stores their profile information in the database, and allows the user to log in, update their profile details, and upload a profile photo. The app uses:\n\nSupabase Database - a Postgres database for storing your user data and Row Level Security so data is protected and users can only access their own information.\nSupabase Auth - users log in through magic links sent to their email (without having to set up passwords).\n",
    "tag": "supabase"
  },
  {
    "title": "user_management_quickstart_sql_template.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/components/MDX/user_management_quickstart_sql_template.mdx",
    "content": "```sql\n-- Create a table for public profiles\ncreate table profiles (\n  id uuid references auth.users not null primary key,\n  updated_at timestamp with time zone,\n  username text unique,\n  full_name text,\n  avatar_url text,\n  website text,\nconstraint username_length check (char_length(username) >= 3)\n);\n-- Set up Row Level Security (RLS)\n-- See https://supabase.com/docs/guides/auth/row-level-security for more details.\nalter table profiles\n  enable row level security;\ncreate policy \"Public profiles are viewable by everyone.\" on profiles\n  for select using (true);\ncreate policy \"Users can insert their own profile.\" on profiles\n  for insert with check (auth.uid() = id);\ncreate policy \"Users can update own profile.\" on profiles\n  for update using (auth.uid() = id);\n-- This trigger automatically creates a profile entry when a new user signs up via Supabase Auth.\n-- See https://supabase.com/docs/guides/auth/managing-user-data#using-triggers for more details.\ncreate function public.handle_new_user()\nreturns trigger as $$\nbegin\n  insert into public.profiles (id, full_name, avatar_url)\n  values (new.id, new.raw_user_meta_data->>'full_name', new.raw_user_meta_data->>'avatar_url');\n  return new;\nend;\n$$ language plpgsql security definer;\ncreate trigger on_auth_user_created\n  after insert on auth.users\n  for each row execute procedure public.handle_new_user();\n-- Set up Storage!\ninsert into storage.buckets (id, name)\n  values ('avatars', 'avatars');\n-- Set up access controls for storage.\n-- See https://supabase.com/docs/guides/storage#policy-examples for more details.\ncreate policy \"Avatar images are publicly accessible.\" on storage.objects\n  for select using (bucket_id = 'avatars');\ncreate policy \"Anyone can upload an avatar.\" on storage.objects\n  for insert with check (bucket_id = 'avatars');\ncreate policy \"Anyone can update their own avatar.\" on storage.objects\n  for update using (auth.uid() = owner) with check (bucket_id = 'avatars');",
    "tag": "supabase"
  },
  {
    "title": "[WIP] Adding navigation for a new section",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/data/nav",
    "content": "[WIP] Adding navigation for a new section\n[Note] This isn't the best way for versioning in my opinion, but this is the current way to do it while we're migrating to Next.js\nThis folder holds the structure for the side navigation menu in the reference documentation pages. Each reference section (as well as their individual versions where applicable) have its own set of navigation.\nThe following are relevant to adding navigation for a new section:\n\n`getPageType()` from `lib/helpers`\n`menuItems` and `REFERENCES` from `components/Navigation/Navigation.constants`\n`NavMenu` from `components/Navigation/Navigation.types`\n\nAdding navigation for a section that doesn't require versioning\nExample for standalone sections are the API and CLI reference pages. You'll just need to add a new file in this folder following the `NavMenu` interface (naming is arbitrary).\nThereafter, update `getPageType` to be able to get the page type based on the URL path - preferably follow the syntax of `reference/{section_name}`.\nFinally, add the menu to `menuItems` under a new key - the key should be what you added to `getPageType` before.\nAdding navigation for a section that requires versioning\nThis is more applicable for client libraries (e.g supabase-js and supabase-dart). Versions will all sit within their own folder - if the folder doesn't exist yet, just create one. The navigation for each section will then be named as 'v1', 'v2', and so on.\nThen, update `REFERENCES` accordingly.\nThereafter, update `getPageType` to be able to get the page type based on the URL path - preferably follow the syntax of `reference/{section_name}/{version}`. Typically the latest version available will not have the `/{version}` in it.",
    "tag": "supabase"
  },
  {
    "title": "index.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/index.mdx",
    "content": "import Layout from '~/layouts/DefaultLayout'\nimport Link from 'next/link'\nimport { GlassPanel, IconPanel, Button, IconChevronRight } from 'ui'\nexport const meta = {\n  title: 'Supabase Docs',\n  description:\n    'Supabase is an open source Firebase alternative providing all the backend features you need to build a product.',\n  subtitle: 'Supabase Developer Documentation and API Reference',\n}\n\n  Supabase is an open source Firebase alternative providing all the backend features you need to\n  build a product. [Learn more](/docs/guides/getting-started/architecture) about Supabase, follow a\n  quickstart for an overview, or dive straight into the different products and APIs.\n\n{/ start container /}\n\n\n\n\n\n\nGetting Started\n\n        Discover how to set up a database to an app making queries in just a few minutes.\n\n        What you will learn\n\n\n\n\n\nSetting up a Supabase project and app\n\n\n\n\n\nAdding some sample data to your project\n\n\n\n\n\nSelect() from your new database table\n\n\n\n\nGet started\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReady to make a fully working app?\nFollow the step-by-step tutorials.\n\n\n\n\n\n\n    ### Product Documentation\n\n  \n\n    {products.map((product) => {\n      return (\n        \n\n\n              {product.description}\n            \n\n        \n      )\n\n})}\n\n    {platform.map((product) => {\n      return (\n        \n\n\n              {product.description}\n            \n\n        \n      )\n\n})}\n\n  \n\n\n\n\n    ### Reference Documentation\n\n  \n\n    {apis.map((product) => {\n      return (\n        \n\n\n              {product.description}\n            \n\n        \n      )\n\n})}\n\n  \n\n\n{/* end of container */}\n\n\nexport const products = [\n  {\n    title: 'Database',\n    icon: '/docs/img/icons/menu/database',\n    hasLightIcon: true,\n    href: '/guides/database',\n    description:\n      'Supabase provides a full Postgres database for every project with Realtime functionality, database backups, extensions, and more.',\n    span: 'col-span-12 md:col-span-6',\n  },\n  {\n    title: 'Auth',\n    icon: '/docs/img/icons/menu/auth',\n    hasLightIcon: true,\n    href: '/guides/auth/overview',\n    description:\n      'Add and manage email and password, passwordless, OAuth, and mobile logins to your project through a suite of identity providers and APIs.',\n    span: 'col-span-12 md:col-span-6',\n  },\n  {\n    title: 'Storage',\n    icon: '/docs/img/icons/menu/storage',\n    hasLightIcon: true,\n    href: '/guides/storage',\n    description:\n      'Store, organize, transform, and serve large files\u2014fully integrated with your Postgres database with Row Level Security access policies.',\n  },\n  {\n    title: 'Realtime',\n    icon: '/docs/img/icons/menu/realtime',\n    hasLightIcon: true,\n    href: '/guides/realtime',\n    description:\n      'Listen to database changes, store and sync user states across clients, broadcast data to clients subscribed to a channel, and more.',\n  },\n  {\n    title: 'Edge Functions',\n    icon: '/docs/img/icons/menu/functions',\n    hasLightIcon: true,\n    href: '/guides/functions',\n    description:\n      'Globally distributed, server-side functions to execute your code closest to your users for the lowest latency.',\n  },\n]\nexport const apis = [\n  {\n    title: 'JavaScript Client Library',\n    icon: '/docs/img/icons/menu/reference-javascript',\n    hasLightIcon: true,\n    href: 'reference/javascript/introduction',\n    description: 'Official client libraries for JavaScript and TypeScript.',\n    span: 'col-span-12 md:col-span-6',\n  },\n  {\n    title: 'Flutter Client Library',\n    icon: '/docs/img/icons/menu/reference-dart',\n    hasLightIcon: true,\n    href: 'reference/dart/introduction',\n    description: 'Official client libraries for Flutter and Dart.',\n    span: 'col-span-12 md:col-span-6',\n  },\n  {\n    title: 'Management API',\n    icon: '/docs/img/icons/menu/reference-api',\n    hasLightIcon: true,\n    href: 'reference/api/introduction',\n    description: 'Manage your Supabase projects and organizations programmatically.',\n    span: 'col-span-12 md:col-span-6',\n  },\n  {\n    title: 'Supabase CLI',\n    icon: '/docs/img/icons/menu/reference-api',\n    hasLightIcon: true,\n    href: 'reference/cli/introduction',\n    description:\n      'Use the CLI to develop your project locally, manage database migrations, and deploy to the Supabase Platform or self-host.',\n    span: 'col-span-12 md:col-span-6',\n  },\n  {\n    title: 'Self-Hosting Auth',\n    icon: '/docs/img/icons/menu/reference-auth',\n    hasLightIcon: true,\n    href: 'reference/self-hosting-auth/introduction',\n    description: 'Self-host your own Auth server.',\n  },\n  {\n    title: 'Self-Hosting Storage',\n    icon: '/docs/img/icons/menu/reference-storage',\n    hasLightIcon: true,\n    href: 'reference/self-hosting-storage/introduction',\n    description: 'Self-host your own Storage server.',\n  },\n  {\n    title: 'Self-Hosting Realtime',\n    icon: '/docs/img/icons/menu/reference-realtime',\n    hasLightIcon: true,\n    href: 'reference/self-hosting-realtime/introduction',\n    description: 'Self-host your own Realtime server.',\n  },\n]\nexport const platform = [\n  {\n    // header: '/docs/img/cards/sample-card-header-3.svg',\n    title: 'Platform Guides',\n    icon: '/docs/img/icons/menu/platform',\n    hasLightIcon: true,\n    href: 'guides/platform',\n    description:\n      'Learn more about the tools and services powering the Supabase Platform, available add-ons, and how to customize the platform for your needs.',\n  },\n  {\n    // header: '/docs/img/cards/sample-card-header-2.svg',\n    title: 'Resources',\n    icon: '/docs/img/icons/menu/resources',\n    hasLightIcon: true,\n    href: 'guides/resources',\n    description: 'View examples, curated content from the community, migration guides, and more.',\n  },\n  {\n    title: 'Self-Hosting Supabase',\n    icon: '/docs/img/icons/menu/platform',\n    hasLightIcon: true,\n    href: 'guides/self-hosting',\n    description: 'Learn how to self-host Supabase and deploy to your own infrastructure.',\n  },\n  {\n    // header: '/docs/img/cards/sample-card-header-2.svg',\n    title: 'Integrations',\n    icon: '/docs/img/icons/menu/integrations',\n    hasLightIcon: true,\n    href: 'guides/integrations',\n    description: 'Explore a variety of integrations from Supabase partners.',\n  },\n]\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Community Support",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/support.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'support',\n  title: 'Support',\n  description: 'Supabase Support',\n}\nHow can we help?\nCommunity Support\nFor help and questions about best practices, we have a discussion forum set up on GitHub: https://github.com/supabase/supabase/discussions\nBusiness Support\nWe offer email based support for business users. You can email us at support@supabase.com.\nIf you need SLAs, guaranteed response times, or other enterprise level services, please contact us at this email address.\nSlack Support",
    "tag": "supabase"
  },
  {
    "title": "faq.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/faq.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'faq',\n  title: 'FAQs',\n  description: 'Most frequently asked questions regarding Supabase',\n}\nWhere do I find support?\nChoose the support channel relevant for your situation here: supabase.com/support\nHow much does it cost?\nSelf-hosting Supabase is free. If you wish to use our cloud-platform, we provide simple, predictable pricing.\nHow do I host Supabase?\nYou can use the docker compose script here, and find detailed instructions here.\nSupabase is an amalgamation of open source tools. Some of these tools are made by Supabase (like our Realtime Server), some we support directly (like PostgREST), and some are third-party tools (like KonSupabase is an amalgamation open sourceg).\nAll of the tools we use in Supabase are MIT, Apache 2.0, or PostgreSQL licensed. This is one of the requirements to be considered for the Supabase stack.\nHow can you be a Firebase alternative if you're built with a relational database?\nWe started Supabase because we love the functionality of Firebase, but we personally experienced the scaling issues that many others experienced. We chose Postgres because it's well-trusted, with phenomenal scalability.\nOur goal is to make Postgres as easy to use as Firebase, so that you no longer have to choose between usability and scalability.\nWe're sure that once you start using Postgres, you'll love it more than any other database.\nDo you support `[some other database]`?\nWe only support PostgreSQL. It's unlikely we'll ever move away from Postgres; however, you can vote on a new database if you want us to start development.\nDo you have a library for `[some other language]`?\nWe officially support JavaScript and Flutter.\nYou can find community-supported libraries in our GitHub Community, and you can also help us to identify the most popular languages by voting for a new client library.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "auth-policies.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/learn/auth-deep-dive/auth-policies.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-policies',\n  title: 'Part Three: Policies',\n  description: 'Supabase Auth Deep Dive Part 3: User Based Access Policies',\n  video: 'https://www.youtube.com/v/0LvCOlELs5U',\n}\nAbout\nHow to restrict table access to authenticated users, row level policies, and email domain based access.\nWatch\n\n\n\nUser based row level policies\nNow that we know how to restrict access to tables based on JWT roles, we can combine this with user management to give us much more control over what data your users can read to and write from your database.\nWe'll start with how user sessions work in Supabase, and later move on to writing user-centric policies.\nLet's say we're signing a user up to our service for the first time. The typical way to do this is by invoking the following method in supabase-js:\n`jsx\n// see full api reference here: /docs/reference/javascript/auth-signup\nsupabase.auth.signUp({ email, password })`\nBy default this will send a confirmation email to the user. When the user clicks the link in the email, they will be redirected to your site (you need to provide your site url in Auth > Settings on the dashboard. By default this is http://localhost:3000) and the full URL including query params will look something like this:\n`http://localhost:3000/#access_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjE2NDI5MDY0LCJzdWIiOiI1YTQzNjVlNy03YzdkLTRlYWYtYThlZS05ZWM5NDMyOTE3Y2EiLCJlbWFpbCI6ImFudEBzdXBhYmFzZS5pbyIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6ImVtYWlsIn0sInVzZXJfbWV0YWRhdGEiOnt9LCJyb2xlIjoiYXV0aGVudGljYXRlZCJ9.4IFzn4eymqUNYYo2AHLxNRL8m08G93Qcg3_fblGqDjo&expires_in=3600&refresh_token=RuioJv2eLV05lgH5AlJwTw&token_type=bearer&type=signup`\nLet's break this up so that it's easier to read:\n```jsx\n// the base url - whatever you set in the Auth Settings in app.supabase.com dashboard\nhttp://localhost:3000/\n// note we use the '#' (fragment) instead of '?' query param\n// the access token is a JWT issued to the user\naccess_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjE2NDI5MDY0LCJzdWIiOiI1YTQzNjVlNy03YzdkLTRlYWYtYThlZS05ZWM5NDMyOTE3Y2EiLCJlbWFpbCI6ImFudEBzdXBhYmFzZS5pbyIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6ImVtYWlsIn0sInVzZXJfbWV0YWRhdGEiOnt9LCJyb2xlIjoiYXV0aGVudGljYXRlZCJ9.4IFzn4eymqUNYYo2AHLxNRL8m08G93Qcg3_fblGqDjo\n// valid for 60 minutes by default\n&expires_in=3600\n// use to get a new access_token before 60 minutes expires\n&refresh_token=RuioJv2eLV05lgH5AlJwTw\n// can use as the Authorization: Bearer header in requests to your API\n&token_type=bearer\n// why was this token issued? was it a signup, login, password reset, or magic link?\n&type=signup\n```\nIf we put the access_token into https://jwt.io we'll see it decodes to:\n`jsx\n{\n  \"aud\": \"authenticated\",\n  \"exp\": 1616429064,\n  \"sub\": \"5a4365e7-7c7d-4eaf-a8ee-9ec9432917ca\",\n  \"email\": \"ant@supabase.io\",\n  \"app_metadata\": {\n    \"provider\": \"email\"\n  },\n  \"user_metadata\": {},\n  \"role\": \"authenticated\"\n}`\nThe `authenticated` role is special in Supabase, it tells the API that this is an authenticated user and will know to compare the JWT against any policies you've added to the requested resource (table or row).\nThe `sub` claim is usually what we use to match the JWT to rows in your database, since by default it is the unique identifier of the user in the `auth.users` table (as a side note - it's generally not recommended to alter the `auth` schema in any way in your Supabase database since the Auth API relies on it to function correctly).\nFor the curious, try heading to the SQL editor and querying:\n`sql\nselect * from auth.users;`\nIf supabase-js is loaded on your site (in this case http://localhost:3000) it automatically plucks the `access_token` out of the URL and initiates a session. You can retrieve the session to see if there is a valid session:\n`jsx\nconsole.log(supabase.auth.getSession())`\nNow that we can use methods to issue JWTs to users, we want to start fetching resources specific to that user. So let's make some. Go to the SQL editor and run:\n```sql\ncreate table my_scores (\n    name text,\n    score int,\n    user_id uuid not null\n);\nALTER TABLE my_scores ENABLE ROW LEVEL SECURITY;\ninsert into my_scores(name, score, user_id)\nvalues\n  ('Paul', 100, '5a4365e7-7c7d-4eaf-a8ee-9ec9432917ca'),\n  ('Paul', 200, '5a4365e7-7c7d-4eaf-a8ee-9ec9432917ca'),\n  ('Leto', 50,  '9ec94326-2e2d-2ea2-22e3-3a535a4365e7');\n-- use UUIDs from the auth.users table if you want to try it\n-- for yourself\n```\nNow we'll write our policy, again in SQL, but note it's also possible to add via the dashboard in Auth > Policies:\n`sql\nCREATE POLICY user_update_own_scores ON my_scores\n    FOR ALL\n    USING (auth.uid() = user_id);`\nNow, assuming you have an active session in your javascript/supabase-js environment you can do:\n`jsx\nsupabase.from('my_scores').select('*').then(console.log)`\nand you should only receive scores belonging to the current logged in user. Alternatively you can use Bash like:\n`bash\ncurl 'https://sjvwsaokcugktsdaxxze.supabase.co/rest/v1/my_scores?select=*' \\\n-H \"apikey: <ANON_KEY>\" \\\n-H \"Authorization: Bearer <ACCESS_TOKEN>\"`\nNote that the `anon key` (or `service role key`) is always needed to get past the API gateway. This can be passed in the `apikey` header or in a query param named `apikey`. It is passed automatically in supabase-js as long as you used it to instantiate the client.\nThere are some more notes here on how to structure your schema to best integrate with the `auth.users` table.\nOnce you get the hang of policies you can start to get a little bit fancy. Let's say I work at Blizzard and I only want Blizzard staff members to be able to update people's high scores, I can write something like:\n`sql\ncreate policy \"Only Blizzard staff can update leaderboard\"\n  on my_scores\n  for update using (\n    right(auth.jwt() ->> 'email', 13) = '@blizzard.com'\n  );`\nSupabase comes with two built-in helper functions: `auth.uid()` and `auth.jwt()`.\nTo create your own functions, navigate to the SQL editor and create a a new query.\n`sql\ncreate or replace function user_agent() \nreturns text \nlanguage sql\nas $$\n  select nullif(current_setting('request.headers', true)::json->>'user-agent', '')::text;\n$$;`\nSee the full PostgreSQL policy docs here: https://www.postgresql.org/docs/12/sql-createpolicy.html\nYou can get as creative as you like with these policies.\nResources\n\nJWT debugger: https://jwt.io\u200b\nPostgeSQL Policies: https://www.postgresql.org/docs/12/sql-createpolicy.html\nPostgREST Row Level Security: https://postgrest.org/en/v7.0.0/auth.html\n\nNext steps\n\nWatch Part One: JWTs\nWatch Part Two: Row Level Security\n  {/  /}\nWatch Part Four: GoTrue\nWatch Part Five: Google Oauth\nSign up for Supabase: app.supabase.com\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "auth-deep-dive-jwts.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/learn/auth-deep-dive/auth-deep-dive-jwts.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-deep-dive-jwts',\n  title: 'Part One: JWTs',\n  description: 'Supabase Auth Deep Dive Part 1 - JWTs',\n  video: 'https://www.youtube.com/v/v3Exg5YpJvE',\n}\nAbout\nAn introduction to JWTs and how they are used in Supabase Auth\nWatch\n\n\n\nWhat are JSON Web Tokens (JWTs)?\nJWTs are JSON objects that are encoded and signed and sent around as a string. They are distributed to users of a service or website, who can later show the JWT to the website or service as proof that they have the right to access certain content.\nWhat exactly do we mean when we say \"encoded\" and \"signed\"?\nWell, the JSON object starts out looking something like this:\n`js\n{\n  \"sub\": \"0001\",\n  \"name\": \"Sam Vimes\",\n  \"iat\": 1516239022,\n  \"exp\": 1518239022\n}`\n`sub` is the \"subject\", which is usually the UUID of the user. `name` is self-explanatory, and `iat` is the Unix timestamp at which the token was created. Many JWTs will also have an `exp`, which is the date at which the token is set to expire and can no longer be used. These are some of the standard fields you may find in a JWT, but you can pretty much store whatever you want in there, for example:\n`js\n{\n  \"sub\": \"0002\",\n  \"name\": \"V\u011bra Hrab\u00e1nkov\u00e1\",\n  \"iat\": 1516239022,\n  \"exp\": 1518239022,\n  \"theme\": {\n      \"primary\" : \"#D80C14\",\n      \"secondary\" : \"#FFFFFF\"\n  }\n}`\nJust note that the more data you store in your token, the longer the encoded string will be.\nWhen we want to send the JWT to the user, we first encode the data using an algorithm such as `HS256`. There are many libraries (and several different algorithms) that can be used to do this encoding/decoding, such as jsonwebtoken. I made a repl here so you can try it for yourself. The signing is as simple as:\n`js\n// from https://replit.com/@awalias/jsonwebtokens#index.js\nlet token = jwt.sign({ name: 'Sam Vimes' }, 'some-secret')`\nAnd the resulting string will look like this:\n`js\neyJhbGciOiJIUzI1NiJ9\n  .eyJzdWIiOiIwMDAxIiwibmFtZSI6IlNhbSBWaW1lcyIsImlhdCI6MTUxNjIzOTAyMiwiZXhwIjoxNTE4MjM5MDIyfQ\n  .zMcHjKlkGhuVsiPIkyAkB2rjXzyzJsMMgpvEGvGtjvA`\nYou will notice that the string is actually made up of three components, which we'll address one by one:\nThe first segment `eyJhbGciOiJIUzI1NiJ9` is known as the \"header\", and when decoded just tells us which algorithm was used to do the encoding:\n`js\n{\n  \"alg\": \"HS256\"\n}`\nThe second segment `eyJzdWIiOiIwMDAxIiwibmFtZSI6IlNhbSBWaW1lcyIsImlhdCI6MTUxNjIzOTAyMiwiZXhwIjoxNTE4MjM5MDIyfQ` contains our original payload:\n`js\n{\n  \"sub\": \"0001\",\n  \"name\": \"Sam Vimes\",\n  \"iat\": 1516239022,\n  \"exp\": 1518239022\n}`\nThe last segment `zMcHjKlkGhuVsiPIkyAkB2rjXzyzJsMMgpvEGvGtjvA` is the signature itself, which is the part used by the website or service provider to verify that a token sent by some user is legitimate. It is produced in the first instance by running the cryptographic function HS256 on the following input:\n`js\nHMACSHA256(\n  base64UrlEncode(header) + \".\" +\n  base64UrlEncode(payload)\n  <jwt_secret>\n)`\nYou can test out minting your own tokens on https://jwt.io.\nIt is important to note that anyone who possesses the `jwt_secret` here can create new tokens, and also verify existing ones. More advanced JWT algorithms use two secrets: one for the creation of tokens, and a separate one to verify the validity of signed tokens.\nYou might wonder why JWTs are so popular all of a sudden. The answer is that with the mass adoption of microservice architecture, we were in a situation where several distinct microservices (APIs, websites, servers, etc.) want to easily validate that a user is who they say they are, or are in other words a \"logged-in\" user. Traditional session tokens are no use here, since they would require each microservice to either maintain a record of currently valid session tokens or to query a central database each time a user wants to access a resource in order to check the validity of the session token \u2013 very inefficient indeed. JWT-based auth in this sense is decentralized, since anyone with the `jwt_secret` can verify a token without needing access to a centralized database.\nNote: One downside of JWTs is that they are not easily voidable, like session tokens. If a JWT is leaked to a malicious actor, they will be able to redeem it anywhere until the expiry date is reached \u2013 unless of course the system owner updates the `jwt_secret` (which will of course invalidate everyone's existing tokens).\nJWTs in Supabase\nIn Supabase we issue JWTs for three different purposes:\n\n`anon key`: This key is used to bypass the Supabase API gateway and can be used in your client-side code.\n`service role key`: This key has super admin rights and can bypass your Row Level Security. Do not put it in your client-side code. Keep it private.\n`user specific jwts`: These are tokens we issue to users who log into your project/service/website. It's the modern equivalent of a session token, and can be used by a user to access content or permissions specific to them.\n\nThe first token here, the `anon key` token, is for developers to send along with their API requests whenever they want to interact with their Supabase database.\nLet's say you want to read the names of all the rows in a table `colors`. We would make a request like:\n`bash\ncurl 'https://xscduanzzfseqszwzhcy.supabase.co/rest/v1/colors?select=name' \\\n-H \"apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlhdCI6MTYxNDIwNTE3NCwiZXhwIjoxOTI5NzgxMTc0fQ.-NBR1WnZyQGpRLdXJfgfpszoZ0EeE6KHatJsDPLIX8c\"`\nIf we put this token into https://jwt.io, we see it decodes to:\n`js\n{\n  \"role\": \"anon\",\n  \"iss\": \"supabase\",\n  \"iat\": 1614205174,\n  \"exp\": 1929781174\n}`\nThis JWT is signed by a `jwt_secret` specific to the developer's Supabase token (you can find this secret alongside this encoded \"anon key\" on your Dashboard under Settings > API page) and is required to get past the Supabase API gateway and access the developer's project.\nThe idea with this particular key is that it's safe to put into your client, meaning it's okay if your end users see this key \u2013 but only if you first enable Row Level Security, which is the topic of Part Two in this series.\nThe second key, `service role key`, should only ever be used on one of your own servers or environments, and should never be shared with end users. You might use this token to do things like make batch inserts of data.\nThe `user access token` is the JWT issued when you call for example:\n`js\nsupabase.auth.signIn({\n  email: 'lao.gimmie@gov.sg',\n  password: 'They_Live_1988!',\n})`\nThis token should be passed in addition to the `apikey` header as an `Authorization Bearer` header like:\n`bash\ncurl 'https://xscduanzzfseqszwzhcy.supabase.co/rest/v1/colors?select=name' \\\n-H \"apikey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlhdCI6MTYxNDIwNTE3NCwiZXhwIjoxOTI5NzgxMTc0fQ.-NBR1WnZyQGpRLdXJfgfpszoZ0EeE6KHatJsDPLIX8c\" \\\n-H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjE1ODI0Mzg4LCJzdWIiOiIwMzM0NzQ0YS1mMmEyLTRhYmEtOGM4YS02ZTc0OGY2MmExNzIiLCJlbWFpbCI6InNvbWVvbmVAZW1haWwuY29tIiwiYXBwX21ldGFkYXRhIjp7InByb3ZpZGVyIjoiZW1haWwifSwidXNlcl9tZXRhZGF0YSI6bnVsbCwicm9sZSI6ImF1dGhlbnRpY2F0ZWQifQ.I-_oSsJamtinGxniPETBf-ezAUwDW2sY9bJIThvdX9s\"`\nYou'll notice that this token is quite a bit longer, since it contains information specific to the user such as:\n`js\n{\n  \"aud\": \"authenticated\",\n  \"exp\": 1615824388,\n  \"sub\": \"0334744a-f2a2-4aba-8c8a-6e748f62a172\",\n  \"email\": \"d.l.solove@gmail.com\",\n  \"app_metadata\": {\n    \"provider\": \"email\"\n  },\n  \"user_metadata\": null,\n  \"role\": \"authenticated\"\n}`\nNow that you understand what JWTs are and where they're used in Supabase, you can explore how to use them in combination with Row Level Security to start restricting access to certain tables, rows, and columns in your Postgres database: Part Two: Row Level Security\nResources\n\nJWT debugger: https://jwt.io/\n\nNext steps\n{/  /}\n\nPart Two: Row Level Security\nPart Three: Policies\nPart Four: GoTrue\nPart Five: Google Oauth\nSign up for Supabase: app.supabase.com\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "auth-google-oauth.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/learn/auth-deep-dive/auth-google-oauth.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-google-oauth',\n  title: 'Part Five: Google Oauth',\n  description: 'Supabase Deep Dive Part 5: Google OAuth Provider',\n  video: 'https://www.youtube.com/v/_XM9ziOzWk4',\n}\nAbout\nHow to add Google OAuth Logins to your Supabase Application.\nWatch\n\n\n\nLogging in with external OAuth providers\nConnecting social logins such as Google, GitHub, or Facebook couldn't be easier. In this guide we'll walk you through the process of connecting Google, but the process is basically the same for all of the providers which includes: azure, bitbucket, github, gitlab, facebook, and google.\nFirst you'll need to create a google project inside their cloud console, in other providers they may refer to this as an \"app\" and is usually available on the company's developer portal.\n\nOnce you have a project, type \"OAuth\" into the search bar and open up \"OAuth Consent Screen\"\n\nSelect 'External' and proceed to fill out the rest of the form fields\n\nNext open up Credentials page on the left\n\nAnd click to create a new set of credentials, select OAuth client ID as the option\n\nNow choose Web Application (assuming you're creating a web app) and in the Authorized redirect URI section you need to add: `https://<your-ref>.supabase.co/auth/v1/callback`. You can find your Supabase URL in Settings > API inside the Supabase dashboard.\n\nNow you can grab the client ID and secret from the popup, and insert them into the google section inside the Supabase dashboard in Auth > Settings:\n\n\nHit save. Now you should be able to navigate in the browser to:\n`https://<your-ref>.supabase.co/auth/v1/authorize?provider=google`\nAnd log in to your service using any google or gmail account.\nYou can additionally add a query parameter `redirect_to=` to the end of the URL for example:\n`https://<your-ref>.supabase.co/auth/v1/authorize?provider=google&redirect_to=http://localhost:3000/welcome`\nBut make sure any URL you enter here is on the same host as the site url that you have entered on the Auth > Settings page on the Supabase dashboard. (There is additional functionality coming soon, where you'll be able to add additional URLs to the allow list).\nIf you want to redirect the user to a specific page in your website or app after a successful authentication.\nYou also have the option of requesting additional scopes from the oauth provider. Let's say for example you want the ability to send emails on behalf of the user's gmail account. You can do this by adding the query parameter `scopes`, like:\n`https://<your-ref>.supabase.co/auth/v1/authorize?provider=google&https://www.googleapis.com/auth/gmail.send`\nNote however that your app will usually have to be verified by Google before you can request advanced scopes such as this.\nThe only thing left to implement is the UI, but if you prefer to use something pre-built, we have a handy Auth Widget, where you can enable/disable whichever auth providers you want to support.\nFor any support please get in touch at beta at supabase.com or for feature requests open an issue in the backend or frontend repos.\nResources\n\nJWT debugger\n\nNext steps\n\nWatch Part One: JWTs\nWatch Part Two: Row Level Security\nWatch Part Three: Policies\nWatch Part Four: GoTrue\n  {/  /}\nSign up for Supabase: app.supabase.com\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "auth-row-level-security.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/learn/auth-deep-dive/auth-row-level-security.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-row-level-security',\n  title: 'Part Two: Row Level Security',\n  description: 'Supabase Auth Deep Dive Part Two - Row Level Security',\n  video: 'https://www.youtube.com/v/qY_iQ10IUhs',\n}\nAbout\nLearn how to restrict access to your database tables by enabling Row Level Security and writing Postgres Policies in the Supabase Dashboard.\nWatch\n\n\n\nSecuring Your Tables\nIn Supabase, you can access your data directly from the client (often the web browser), you do this by passing your Supabase URL and Anon key to supabase-js like so:\n`js\nconst supabase = createClient(\n  'https://qwertyuiop.supabase.co',\n  'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c'\n)`\nThis raises an interesting question however: \"if my anon key is in the client, then can't someone read my javascript and steal my key?\", the answer is yes. And this is where Postgres policies come in.\nUsing Postgres's \"Row-Level-Security\" policies, we can set rules on what data the anon key is allowed or not allowed to access by default.\nWe can say for example that the anon key should only be able to read from a particular table, but not write, update, nor delete.\nAnd these rules can be as complex as we want. We could say that the anon key can only delete rows which were inserted on a Thursday afternoon between 4 and 6pm, and where the id column is an even number. Pretty strange, but it shows the power of policies.\nLet's say we create a leaderboard table. We want people on our website to be able to read the leaderboard, but not write, update, or delete from it. We start by defining our table in SQL and adding some dummy data:\n```sql\ncreate table leaderboard (\n    name text,\n    score int\n);\ninsert into leaderboard(name, score)\nvalues ('Paul', 100), ('Leto', 50), ('Chani', 200);\n```\nNow let's set up a client to read the data, I've created a repl here to show a living example: https://replit.com/@awalias/supabase-leaderboard-demo#index.js. If you copy the snippet you can plug in your own Supabase URL and anon key.\nYou can see that it's possible to freely read from and write to the table by using:\n```js\n// Writing\nlet { data, error } = await supabase.from('leaderboard').insert({ name: 'Bob', score: 99999 })\n// Reading\nlet { data, error } = await supabase\n  .from('leaderboard')\n  .select('name, score')\n  .order('score', { ascending: false })\n```\nNow let's restrict access. We'll start by fully restricting the table. We can do this in the SQL editor by making a query:\n`sql\nALTER TABLE leaderboard ENABLE ROW LEVEL SECURITY;`\nor via the Supabase Dashboard, by navigating to Auth > Policies, and clicking the red padlock on the leaderboard table, so that it turns white.\n\nYou'll notice that both reading and writing now fail with an error like:\n`jsx\n{\n  hint: null,\n  details: null,\n  code: '42501',\n  message: 'new row violates row-level security policy for table \"leaderboard\"'\n}`\nNow we need to add a policy to enable reading of the table, for everyone who sends the anon key (JWT) in the `Authorization: Bearer` header.\nIn SQL this can be done with:\n`sql\nCREATE POLICY anon_read_leaderboard ON leaderboard\n    FOR SELECT\n    TO 'anon'\n    USING (true);`\n`anon_read_leaderboard` here is just a name that you choose for your policy. `leaderboard` is the table name. `FOR SELECT` says that we only want this policy to apply for reads (or rather \"selects\" in SQL). `TO` means that this policy will only apply to the `anon` Postgres role. And finally the rule itself is `true'`, which means it will allow any `selects` to the `anon` user.\nIf you'd prefer to use the dashboard to add your policy you can do so by clicking \"Add Policy\" in the Policies tab and making a policy like this:\n\nYou should now be able to read from your leaderboard, but will still not be able to write, update, or delete from it, which is exactly what we wanted!\nA quick reminder that you can always use your `service_role` API key to bypass these row level security policies. But be extra careful that you don't leak this key by including it in the client. This can be useful if you're building internal admin tools, or if you need to bulk insert or delete data via the API.\nIn the next guide we will look at using Policies in combination with User Accounts, so that you can restrict access to data on a User by User basis: Watch Part Three: Policies\nResources\n\nJWT debugger: https://jwt.io/\nRESTED: https://github.com/RESTEDClient/RESTED\n\nNext steps\n\nWatch Part One: JWTs\n  {/  /}\nWatch Part Three: Policies\nWatch Part Four: GoTrue\nWatch Part Five: Google Oauth\nSign up for Supabase: app.supabase.com\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "replace <project-ref> with your own project reference",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/learn/auth-deep-dive/auth-gotrue.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-gotrue',\n  title: 'Part Four: GoTrue',\n  description: 'Supabase Deep Dive Part 4: Gotrue Overview',\n}\nAbout\nHow to restrict table access to authenticated users, row level policies, and email domain based access.\nWatch\n\n\n\nGotrue Server\nGotrue is an auth API server written in Go by the Netlify team, find the Supabase fork here: https://github.com/supabase/gotrue. The list of available API endpoints is available here.\nWhen you deploy a new Supabase project, we deploy a new instance of this server alongside your database, and also inject your database with the required `auth` schema.\nIt makes it super easy to, for example, send magic link emails which your users can use to login:\n```bash\nreplace  with your own project reference\nand SUPABASE_KEY with your anon api key\ncurl -X POST 'https://.supabase.co/auth/v1/magiclink' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"email\": \"someone@email.com\"\n}'\n```\nGotrue is responsible for issuing access tokens for your users, sends confirmation, magic-link, and password recovery emails (by default we send these from a Supabase SMTP server, but you can easily plug in your own inside the dashboard at Auth > Settings) and also transacting with third party OAuth providers to get basic user data.\nThe community even recently built in the functionality to request custom OAuth scopes, if your users need to interact more closely with the provider. See the scopes parameter here: https://github.com/supabase/gotrue#get-authorize.\nSo let's say you want to send emails on behalf of a user via gmail, you might request the gmail.send scope by directing them to:\n`https://sjvwsaokcugktsdaxxze.supabase.co/auth/v1/authorize?provider=google&https://www.googleapis.com/auth/gmail.send`\nYou'll have to make sure your google app is verified of course in order to request these advanced scopes.\nGotrue-js (and also gotrue-csharp, gotrue-py, gotrue-kt, and gotrue-dart) are all wrappers around the gotrue API endpoints, and make for easier session management inside your client.\nBut all the functionality of gotrue-js is also available in supabase-js, which uses gotrue-js internally when you do things like:\n`jsx\nconst { user, session, error } = await supabase.auth.signIn({\n  email: 'example@email.com',\n  password: 'example-password',\n})`\nIf you want to request a feature, or contribute to the project directly, just head to https://github.com/supabase/gotrue and open some issues/PRs, we're always open to help.\nIn the next guide we'll be looking at how to setup external OAuth providers: Watch Part Five: Google Oauth\nResources\n\nJWT debugger: https://jwt.io\u200b\n\nNext steps\n\nWatch Part One: JWTs\nWatch Part Two: Row Level Security\nWatch Part Three: Policies\n  {/  /}\nWatch Part Five: Google Oauth\nSign up for Supabase: app.supabase.com\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "How to contribute",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/handbook/contributing.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'contributing',\n  title: 'Contributing',\n  description: 'Want to help?',\n}\nHow to contribute\nSupabase has many open source repos. Some of the more popular ones are:\n\nSupabase - Our Dashboard, Websites, and example apps\nSupabase-js - A clientside library written in Typescript\nGotrue - Our auth server, written in Go\nRealtime - A server for streaming changes from Postgres, written in Elixir\nbrowse all\n\nWant to contribute? Why not jump into our GitHub repo and:\n\nSponsor Supabase.\nAnswer Discussions.\nSubmit an issue to one of our repos\nReport a performance issue or a part of the documentation that you find confusing.\nCreate a pull request in one of our repos\nTranslate our Readme.\nTry our products and give feedback.\nSpread the word if you like what we are doing.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Opensource",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/handbook/introduction.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'introduction',\n  title: 'Supabase Handbook',\n  description: 'The Supabase public handbook and manifesto',\n}\nSupabase is thinking in public. Everything is online, no matter how raw the current state of things.\nThis is our public handbook and manifesto. We are completely opensource and this means that you, our users, are also our team members.\n\nOpensource\nWherever we can we will support existing opensource tools and libraries.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Projects",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'platform',\n  title: 'Supabase Platform',\n  description: 'Getting started with the Supabase Platform.',\n  sidebar_label: 'Overview',\n}\nSupabase is a hosted platform which makes it very simple to get started without needing to manage any infrastructure.\nVisit app.supabase.com and sign in to start creating projects.\nProjects\nEach project on Supabase comes with:\n\nA dedicated Postgres database\nAuto-generated APIs\nAuth and user management\nEdge Functions\nRealtime API\nStorage\n\nOrganizations\nOrganizations are a way to group your projects. Each organization can be configured with different team members and billing settings.\nRefer to access control for more information on how to manage team members within an organization.\nPlatform status\nIf Supabase experiences outages, we keep you as informed as possible, as early as possible. We provide the following feedback channels:\n\nStatus page: status.supabase.com\nRSS Feed: status.supabase.com/history.rss\nAtom Feed: status.supabase.com/history.atom\nSlack Alerts: You can receive updates via the RSS feed, using Slack's built-in RSS functionality `/feed subscribe https://status.supabase.com/history.atom`\n\nMake sure to review our SLA for details on our commitment to Platform Stability.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Installation",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/cli.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Supabase CLI',\n  description:\n    'The Supabase CLI provides tools to develop your project locally and deploy to the Supabase Platform.',\n}\nThe Supabase CLI provides tools to develop your project locally and deploy to the Supabase Platform.\nYou can also use the CLI to manage your Supabase projects, handle database migrations and CI/CD workflows, and generate types directly from your database schema.\nInstallation\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n\n\n\nInstall the CLI as dev dependency via npm:\n`sh\nnpm install supabase --save-dev`\n\n\nInstall the CLI with Homebrew:\n`sh\nbrew install supabase/tap/supabase`\n\n\nInstall the CLI with Scoop:\n`powershell\nscoop bucket add supabase https://github.com/supabase/scoop-bucket.git\nscoop install supabase`\n\n\nThe CLI is available through Homebrew and Linux packages.\nHomebrew\n`sh\nbrew install supabase/tap/supabase`\nLinux packages\nLinux packages are provided in Releases.\nTo install, download the `.apk`/`.deb`/`.rpm` file depending on your package manager\nand run one of the following:\n\n`sudo apk add --allow-untrusted <...>.apk`\n`sudo dpkg -i <...>.deb`\n`sudo rpm -i <...>.rpm`\n\n\n\nUpdates\nWhen a new version is released, you can update the CLI using the same methods.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n\n\n\n`sh\nnpm update supabase --save-dev`\n\n\n`sh\nbrew upgrade supabase`\n\n\n`powershell\nscoop update supabase`\n\n\n`sh\nbrew upgrade supabase`\n\n\nSee also\n\nSupabase CLI Reference\nSupabase CLI Configuration\nLocal Development\nManaging Environments\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Postgres or PostgreSQL?",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'database',\n  title: 'Database',\n  description: 'Use Supabase to manage your data.',\n  sidebar_label: 'Overview',\n}\nEvery Supabase project comes with a full Postgres database, a free and open source\ndatabase which is considered one of the world's most stable and advanced databases.\nPostgres or PostgreSQL?\nPostgreSQL the database was derived from the POSTGRES Project, a package written at the University of California at Berkeley in 1986.\nThis package included a query language called \"PostQUEL\".\nIn 1994, Postgres95 was built on top of POSTGRES code, adding an SQL language interpreter as a replacement for PostQUEL.\nEventually, Postgres95 was renamed to PostgreSQL to reflect the SQL query capability.\nAfter this, many people referred to it as Postgres since it's less prone to confusion. Supabase is all about\nsimplicity, so we also refer to it as Postgres.\nFeatures\nTable View\nYou don't have to be a database expert to start using Supabase. Our table view makes Postgres as easy to use as a spreadsheet.\n\nRelationships\nDig into the relationships within your data.\n\n\n\nClone tables\nYou can duplicate your tables, just like you would inside a spreadsheet.\n\n\n\nThe SQL Editor\nSupabase comes with a SQL Editor. You can also save your favorite queries to run later!\n\n\n\nAdditional features\n\nSupabase extends Postgres with realtime functionality using our Realtime Server.\nEvery project is a full Postgres database, with `postgres` level access.\nSupabase manages your database backups.\nImport data directly from a CSV or excel spreadsheet.\n\n\nDatabase backups do not include objects stored via the Storage API, as the database only\nincludes metadata about these objects. Restoring an old backup does not restore objects that have\nbeen deleted since then.\n\nExtensions\nTo expand the functionality of your Postgres database, you can use extensions.\nYou can enable Postgres extensions with the click of a button within the Supabase dashboard.\n\n\n\nLearn more about all the extensions provided on Supabase.\nTips\nRead about resetting your database password here and changing the timezone of your server here.\nNext steps\n\nRead more about Postgres\nSign in: app.supabase.com\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Examples",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'functions',\n  title: 'Edge Functions',\n  description: 'Globally distributed TypeScript functions.',\n  sidebar_label: 'Overview',\n  hide_table_of_contents: true,\n}\nEdge Functions are server-side TypeScript functions, distributed globally at the edge\u2014close to your users. They can be used for listening to webhooks or integrating your Supabase project with third-parties like Stripe. Edge Functions are developed using Deno, which offers a few benefits to you as a developer:\n\nIt is open source.\nIt is portable. Supabase Edge Functions run locally, and on any other Deno-compatible platform (including self-hosted infrastructure).\nIt is TypeScript first and supports WASM.\nEdge Functions are globally distributed for low-latency.\n\n\n\n    Get started\n  \n\nExamples\nCheck out the Edge Function Examples in our GitHub repository.\n\n  {examples.map((x) => (\n    \n\n\n\n            {x.description}\n          \n\n\n  ))}\n\nexport const examples = [\n  {\n    name: 'With supabase-js',\n    description: 'Use the Supabase client inside your Edge Function.',\n    href: '/guides/functions/auth',\n  },\n  {\n    name: 'With CORS headers',\n    description: 'Send CORS headers for invoking from the browser.',\n    href: '/guides/functions/cors',\n  },\n  {\n    name: 'React Native with Stripe',\n    description: 'Full example for using Supabase and Stripe, with Expo.',\n    href: 'https://github.com/supabase-community/expo-stripe-payments-with-supabase-functions',\n  },\n  {\n    name: 'Flutter with Stripe',\n    description: 'Full example for using Supabase and Stripe, with Flutter.',\n    href: 'https://github.com/supabase-community/flutter-stripe-payments-with-supabase-functions',\n  },\n  {\n    name: 'Building a RESTful Service API',\n    description:\n      'Learn how to use HTTP methods and paths to build a RESTful service for managing tasks.',\n    href: 'https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/restful-tasks/index.ts',\n  },\n  {\n    name: 'Working with Supabase Storage',\n    description: 'An example on reading a file from Supabase Storage.',\n    href: 'https://github.com/supabase/supabase/blob/master/examples/edge-functions/supabase/functions/read-storage/index.ts',\n  },\n  {\n    name: 'Open Graph Image Generation',\n    description: 'Generate Open Graph images with Deno and Supabase Edge Functions.',\n    href: '/guides/functions/examples/og-image',\n  },\n  {\n    name: 'OG Image Generation & Storage CDN Caching',\n    description: 'Cache generated images with Supabase Storage CDN.',\n    href: 'https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/og-image-with-storage-cdn',\n  },\n  {\n    name: 'Get User Location',\n    description: `Get user location data from user's IP address.`,\n    href: 'https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/location',\n  },\n  {\n    name: 'Cloudflare Turnstile',\n    description: `Protecting Forms with Cloudflare Turnstile.`,\n    href: '/guides/functions/examples/cloudflare-turnstile',\n  },\n  {\n    name: 'Connect to Postgres',\n    description: `Connecting to Postgres from Edge Functions.`,\n    href: '/guides/functions/examples/connect-to-postgres',\n  },\n  {\n    name: 'Github Actions',\n    description: `Deploying Edge Functions with GitHub Actions.`,\n    href: '/guides/functions/examples/github-actions',\n  },\n  {\n    name: 'Oak Server Middleware',\n    description: `Request Routing with Oak server middleware.`,\n    href: 'https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/oak-server',\n  },\n  {\n    name: 'OpenAI',\n    description: `Using OpenAI in Edge Functions.`,\n    href: '/guides/functions/examples/openai',\n  },\n  {\n    name: 'Stripe Webhooks',\n    description: `Handling signed Stripe Webhooks with Edge Functions.`,\n    href: '/guides/functions/examples/stripe-webhooks',\n  },\n  {\n    name: 'Send emails',\n    description: `Send emails in Edge Functions.`,\n    href: 'https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/send-email-smtp',\n  },\n  {\n    name: 'Web Stream',\n    description: `Server-Sent Events in Edge Functions.`,\n    href: 'https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/streams',\n  },\n  {\n    name: 'Puppeteer',\n    description: `Generate screenshots with Puppeteer.`,\n    href: 'https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/puppeteer',\n  },\n  {\n    name: 'Discord Bot',\n    description: `Building a Slash Command Discord Bot with Edge Functions.`,\n    href: '/guides/functions/examples/discord-bot',\n  },\n  {\n    name: 'Telegram Bot',\n    description: `Building a Telegram Bot with Edge Functions.`,\n    href: '/guides/functions/examples/telegram-bot',\n  },\n  {\n    name: 'Upload File',\n    description: `Process multipart/form-data.`,\n    href: 'https://github.com/supabase/supabase/tree/master/examples/edge-functions/supabase/functions/file-upload-storage',\n  },\n  {\n    name: 'Upstash Redis',\n    description: `Build an Edge Functions Counter with Upstash Redis.`,\n    href: '/guides/functions/examples/upstash-redis',\n  },\n]\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "getting-started.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started.mdx",
    "content": "import Layout from '~/layouts/DefaultLayout'\nimport Link from 'next/link'\nimport { GlassPanel, IconPanel, Button, IconChevronRight } from 'ui'\nexport const meta = {\n  id: 'getting-started',\n  title: 'Getting Started',\n  description: 'Resources for getting started with Supabase.',\n}\n\n\n\n    {resources.map((resource) => {\n      return (\n        \n\n\n              {resource.description}\n            \n\n        \n      )\n\n})}\n\n  \n\n\nFramework Quickstarts\n\n  {quickstarts.map((item) => {\n    return (\n      \n\n\n            {item.description}\n          \n\n      \n    )\n  })}\n\nWeb App Tutorials\n\n  {webapps.map((item) => {\n    return (\n      \n\n\n            {item.description}\n          \n\n      \n    )\n  })}\n\nMobile Tutorials\n\n  {mobile.map((item) => {\n    return (\n      \n\n\n            {item.description}\n          \n\n      \n    )\n  })}\n\nexport const quickstarts = [\n  {\n    title: 'React',\n    href: '/guides/getting-started/quickstarts/reactjs',\n    description:\n      'Learn how to create a Supabase project, add some sample data to your database, and query the data from a React app.',\n    icon: '/docs/img/icons/react-icon',\n  },\n  {\n    title: 'NextJS',\n    href: '/guides/getting-started/quickstarts/nextjs',\n    description:\n      'Learn how to create a Supabase project, add some sample data to your database, and query the data from a NextJS app.',\n    icon: '/docs/img/icons/nextjs-icon',\n  },\n  {\n    title: 'Flutter',\n    href: '/guides/getting-started/quickstarts/flutter',\n    description:\n      'Learn how to create a Supabase project, add some sample data to your database, and query the data from a Flutter app.',\n    icon: '/docs/img/icons/flutter-icon',\n  },\n]\nexport const webapps = [\n  {\n    title: 'NextJS',\n    href: '/guides/getting-started/tutorials/with-nextjs',\n    description:\n      'Learn how to build a user management app with NextJS and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/nextjs-icon',\n  },\n  {\n    title: 'React',\n    href: '/guides/getting-started/tutorials/with-react',\n    description:\n      'Learn how to build a user management app with React and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/react-icon',\n  },\n  {\n    title: 'Vue 3',\n    href: '/guides/getting-started/tutorials/with-vue-3',\n    description:\n      'Learn how to build a user management app with Vue 3 and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/vuejs-icon',\n  },\n  {\n    title: 'Nuxt 3',\n    href: '/guides/getting-started/tutorials/with-nuxt-3',\n    description:\n      'Learn how to build a user management app with Nuxt 3 and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/nuxt-icon',\n  },\n  {\n    title: 'Angular',\n    href: '/guides/getting-started/tutorials/with-angular',\n    description:\n      'Learn how to build a user management app with Angular and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/angular-icon',\n  },\n  {\n    title: 'RedwoodJS',\n    href: '/guides/getting-started/tutorials/with-redwoodjs',\n    description:\n      'Learn how to build a user management app with RedwoodJS and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/redwood-icon',\n  },\n  {\n    title: 'Svelte',\n    href: '/guides/getting-started/tutorials/with-svelte',\n    description:\n      'Learn how to build a user management app with Svelte and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/svelte-icon',\n  },\n  {\n    title: 'SvelteKit',\n    href: '/guides/getting-started/tutorials/with-sveltekit',\n    description:\n      'Learn how to build a user management app with SvelteKit and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/svelte-icon',\n  },\n]\nexport const mobile = [\n  {\n    title: 'Flutter',\n    href: '/guides/getting-started/tutorials/with-flutter',\n    description:\n      'Learn how to build a user management app with Flutter and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/flutter-icon',\n  },\n  {\n    title: 'Expo',\n    href: '/guides/getting-started/tutorials/with-expo',\n    description:\n      'Learn how to build a user management app with Expo and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/expo-icon',\n  },\n  {\n    title: 'Ionic React',\n    href: '/guides/getting-started/tutorials/with-ionic-react',\n    description:\n      'Learn how to build a user management app with Ionic React and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/ionic-icon',\n  },\n  {\n    title: 'Ionic Vue',\n    href: '/guides/getting-started/tutorials/with-ionic-vue',\n    description:\n      'Learn how to build a user management app with Ionic Vue and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/ionic-icon',\n  },\n  {\n    title: 'Ionic Angular',\n    href: '/guides/getting-started/tutorials/with-ionic-angular',\n    description:\n      'Learn how to build a user management app with Ionic Angular and Supabase Database, Auth, and Storage functionality.',\n    icon: '/docs/img/icons/ionic-icon',\n  },\n]\nexport const resources = [\n  {\n    title: 'Features',\n    hasLightIcon: true,\n    href: '/guides/getting-started/features',\n    description: 'A non-exhaustive list of features that Supabase provides for every project.',\n  },\n  {\n    title: 'Architecture',\n    hasLightIcon: true,\n    href: '/guides/getting-started/architecture',\n    description: \"An overview of Supabase's architecture and product principles.\",\n  },\n]\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "integrations.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations.mdx",
    "content": "import Layout from '~/layouts/DefaultLayout'\nimport Link from 'next/link'\nimport Image from 'next/image'\nimport { GlassPanel } from 'ui'\nimport { integrations } from '~/components/Navigation/NavigationMenu/NavigationMenu.constants'\nexport const meta = {\n  title: 'Integrations',\n}\nExplore a variety of integrations from Supabase partners. Need a different integration? Find a Supabase expert to help build your next idea.\n\n  {integrations.items.map((item) => (\n  \n{item.name}\n\n      {item.items.map((integration) => (\n        \n\n}\n            >\n              {integration.description}\n\n            \n\n        \n      ))}\n\n    \n\n  ))}\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "See Also",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/realtime.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'realtime',\n  title: 'Realtime',\n  description: 'Supabase Realtime with Broadcast, Presence, and Postgres Changes.',\n  sidebar_label: 'Overview',\n}\nSupabase provides a globally distributed cluster of Realtime servers that enable the following functionality:\n\nBroadcast: Send ephemeral messages from client to clients with low latency.\nPresence: Track and synchronize shared state between clients.\nPostgres Changes: Listen to Postgres database changes and send them to authorized clients.\n\nA channel is the basic building block of Realtime and narrows the scope of data flow to subscribed clients. You can think of a channel as a chatroom where participants are able to see who's online and send and receive messages; similar to a Discord or Slack channel.\nAll clients can connect to a channel and take advantage of the built-in features, Broadcast and Presence, while extensions, like Postgres Changes, must be enabled prior to use.\nSee Also\n\nQuickstart\nRealtime: Multiplayer Edition blog post\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "resources.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources.mdx",
    "content": "import Layout from '~/layouts/DefaultLayout'\nimport Link from 'next/link'\nimport { GlassPanel, IconPanel, Button, IconChevronRight } from 'ui'\nexport const meta = {\n  title: 'Resources',\n  description: 'Resources for getting started building with Supabase.',\n}\n\n\n\n    {resources.map((resource) => {\n      return (\n        \n\n\n              {resource.description}\n            \n\n        \n      )\n\n})}\n\n  \n\n\n\n\n### Migrate to Supabase\n\n  \n\n    {migrationGuides.map((product) => {\n      return (\n        \n\n\n              {product.description}\n            \n\n        \n      )\n\n})}\n\n  \n\n\n\n\n### Postgres Resources\n\n  \n\n    {postgres.map((resource) => {\n      return (\n        \n\n\n              {resource.description}\n            \n\n        \n      )\n\n})}\n\n  \n\n\n{/* end of container */}\n\n\nexport const resources = [\n  {\n    title: 'Examples',\n    hasLightIcon: true,\n    href: '/guides/resources/examples',\n    description: 'Official GitHub examples, curated content from the community, and more.',\n  },\n  {\n    title: 'Glossary',\n    hasLightIcon: true,\n    href: '/guides/resources/glossary',\n    description: 'Definitions for terminology and acronyms used in the Supabase documentation.',\n  },\n]\nexport const migrationGuides = [\n  {\n    title: 'Firebase Auth',\n    icon: '/docs/img/icons/firebase-icon',\n    href: '/guides/resources/migrating-to-supabase/firebase-auth',\n    description: 'Move your auth users from a Firebase project to a Supabase project.',\n  },\n  {\n    title: 'Firestore Data',\n    icon: '/docs/img/icons/firebase-icon',\n    href: '/guides/resources/migrating-to-supabase/firestore-data',\n    description: 'Migrate the contents of a Firestore collection to a single PostgreSQL table.',\n  },\n  {\n    title: 'Firebase Storage',\n    icon: '/docs/img/icons/firebase-icon',\n    href: '/guides/resources/migrating-to-supabase/firebase-storage',\n    description: 'Convert your Firebase Storage files to Supabase Storage.',\n  },\n  {\n    title: 'Heroku',\n    icon: '/docs/img/icons/heroku-icon',\n    href: '/guides/resources/migrating-to-supabase/heroku',\n    description: 'Migrate your Heroku Postgres database to Supabase.',\n  },\n  {\n    title: 'Render',\n    icon: '/docs/img/icons/render-icon',\n    href: '/guides/resources/migrating-to-supabase/render',\n    description: 'Migrate your Render Postgres database to Supabase.',\n  },\n]\nexport const postgres = [\n  {\n    title: 'Drop all tables in schema',\n    hasLightIcon: true,\n    href: '/guides/resources/postgres/dropping-all-tables-in-schema',\n    description: 'Delete all tables in a given schema.',\n  },\n  {\n    title: 'Select first row per group',\n    hasLightIcon: true,\n    href: '/guides/resources/postgres/first-row-in-group',\n    description: 'Retrieve the first row in each distinct group.',\n  },\n  {\n    title: 'Print PostgreSQL version',\n    hasLightIcon: true,\n    href: '/guides/resources/postgres/which-version-of-postgres',\n    description: 'Find out which version of Postgres you are running.',\n  },\n]\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Files",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/storage.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'storage',\n  title: 'Storage',\n  description: 'Use Supabase to store and serve files.',\n  sidebar_label: 'Overview',\n  video: 'https://www.youtube.com/v/J9mTPY8rIXE',\n}\nSupabase Storage makes it simple to store and serve large files.\nFiles\nFiles can be any sort of media file. This includes images, GIFs, and videos. It is best practice to store files outside of your database because of their sizes. For security, HTML files are returned as plain text.\nFolders\nFolders are a way to organize your files (just like on your computer).\nThere is no right or wrong way to\norganize your files. You can store them in whichever folder structure suits your project.\nBuckets\nBuckets are distinct containers for files and folders. You can think of them like \"super folders\".\nGenerally you would create distinct buckets for different Security and Access Rules. For example, you might\nkeep all video files in a \"video\" bucket, and profile pictures in an \"avatar\" bucket.\n\n\n\nSee also\n\nRead more about Supabase Storage in the blog post\nSupabase Storage on GitHub\nSwagger API documentation\nOfficial JavaScript and Dart documentation\nCommunity libraries\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Architecture",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/self-hosting.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Self-Hosting',\n  description: 'Getting started with self-hosting Supabase.',\n}\nThere are several ways to use Supabase:\n\nSupabase Cloud: you don't need to deploy anything. We will manage and scale your infrastructure.\nDocker: deploy to your own infrastructure.\nKubernetes: coming soon.\n\nArchitecture\nSupabase is a combination of open source tools, each specifically chosen for Enterprise-readiness.\nIf the tools and communities already exist, with an MIT, Apache 2, or equivalent open license, we will use and support that tool.\nIf the tool doesn't exist, we build and open source it ourselves.\n\n\nKong is a cloud-native API gateway.\nGoTrue is an SWT based API for managing users and issuing SWT tokens.\nPostgREST is a web server that turns your PostgreSQL database directly into a RESTful API\nRealtime is an Elixir server that allows you to listen to PostgreSQL inserts, updates, and deletes using websockets. Realtime polls Postgres' built-in replication functionality for database changes, converts changes to JSON, then broadcasts the JSON over websockets to authorized clients.\nStorage provides a RESTful interface for managing Files stored in S3, using Postgres to manage permissions.\npostgres-meta is a RESTful API for managing your Postgres, allowing you to fetch tables, add roles, and run queries, etc.\nPostgreSQL is an object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.\n\nConfiguration\nEach system has a number of configuration options which can be found in the relevant product documentation.\n\nPostgres\nPostgREST\nRealtime\nGoTrue\nStorage\nKong\n\nManaging your database\nIt is recommended that you decouple your database from the middleware so that you can upgrade the middleware without any downtime.\nThe \"middleware\" is everything except Postgres, and it should work with any Postgres provider (such as AWS RDS), or your own Postgres cluster.\nExtensions\nSupabase requires some Postgres extensions to be enabled by default for the API and Auth system to work. You can find the extensions inside the\nschema migration scripts. These are mounted at `/docker-entrypoint-initdb.d`\nto run automatically when starting the database container.\nWe recommend installing all extensions into an `extensions` schema. This will keep your API clean,\nsince all tables in the `public` schema are exposed via the API.\n`sql\ncreate schema if not exists extensions;\ncreate extension if not exists \"uuid-ossp\" with schema extensions;\ncreate extension if not exists pgcrypto with schema extensions;\ncreate extension if not exists pgjwt with schema extensions;`\n`uuid-ossp`\nFor UUID functions, required for PostgreSQL `<13`.\n`pgcrypto` and `pgjwt`\nFor working with JWT and Auth functions.\nRoles\nSupabase creates several default roles in your Postgres database. To restore defaults at any time you can run the commands inside the\nschema initialization scripts. Remember to change your\nrole passwords before deploying to production environments.\n`postgres`\nThe default PostgreSQL role. This has admin privileges.\n`anon`\nFor \"anonymous access\". This is the role which the API (PostgREST) will use when a user is not logged in.\n`authenticator`\nA special role for the API (PostgREST). It has very limited access, and is used to validate a JWT and then\n\"change into\" another role determined by the JWT verification.\n`authenticated`\nFor \"authenticated access\". This is the role which the API (PostgREST) will use when a user is logged in.\n`service_role`\nFor elevated access. This role is used by the API (PostgREST) to bypass Row Level Security.\n`supabase_auth_admin`\nUsed by the Auth middleware to connect to the database and run migration. Access is scoped to the `auth` schema.\n`supabase_storage_admin`\nUsed by the Auth middleware to connect to the database and run migration. Access is scoped to the `storage` schema.\n`dashboard_user`\nFor running commands via the Supabase UI.\n`supabase_admin`\nSupabase Administrative role for maintaining your database.\nRealtime Logs\nSet your database's `log_min_messages` configuration to `fatal` to prevent redundant database logs generated by Realtime. However, you might miss important log messages such as database errors. Configure `log_min_messages` based on your needs.\nAPI Keys\nThe API Gateway (Kong) uses JWT to authenticate access through to the database. The JWT should correspond to a relevant Postgres Role,\nand Supabase is designed to work with 2 roles: an `ANON_KEY` for unauthenticated access and a `SERVICE_KEY` for elevated access.\nUse this tool to generate keys:\n\nManaging your secrets\nMany components inside Supabase use secure secrets and passwords. These are listed in the self-hosting\nenv file, but we strongly recommend using a\nsecrets manager when deploying to production. Plain text files like dotenv lead to accidental costly leaks.\nSome suggested systems include:\n\nDoppler\nKey Vault by Azure\nSecrets Manager by AWS\nSecrets Manager by GCP\nVault by Hashicorp\n\nMigrating and Upgrading\nIf you have decoupled your database from the middleware, then you should be able to redeploy the latest middleware at any time as long as it has no breaking changes.\nSupabase is evolving fast, and we'll continue to improve the migration strategy as part of our core offering.\nWe realize that database migrations are difficult, and this is one of the problems we plan to make easy for developers.\nDeployment options\nWhile Supabase officially supports Docker, we have several other deployment strategies managed by the community:\n\nsupabase-docker (Official)\nsupabase-kubernetes (Unofficial)\nsupabase-terraform (Unofficial)\nsupabase-traefik (Unofficial)\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Resources",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/sql-to-api.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'sql-to-api',\n  title: 'Converting SQL to JavaScript API',\n  description: 'Implementing common SQL patterns in the JavaScript API',\n}\n{/ @TODO: this one is a very daunting read on first attempt. Need to check what is the purpose of it /}\nSelect a set of columns from a single table with where, order by, and limit clauses.\n`sql\nselect first_name, last_name, team_id, age from players\nwhere age between 20 and 24 and team_id <> 'STL'\norder by last_name, first_name desc\nlimit 20`\n`js\nconst { data, error } = await supabase\n  .from('players')\n  .select('first_name,last_name,team_id,age')\n  .gte('age', 20)\n  .lte('age', 24)\n  .not('team_id', 'eq', 'STL')\n  .order('last_name', { ascending: true }) // or just .order('last_name')\n  .order('first_name', { ascending: false })\n  .limit(20)`\nSelect all columns from a single table with a complex where clause: OR AND OR\n`sql\nselect * from players\nwhere ((team_id = 'CHN' or team_id is null) and (age > 35 or age is null))`\n`js\nconst { data, error } = await supabase\n  .from('players')\n  .select() // or .select('*')\n  .or('team_id.eq.CHN,team_id.is.null')\n  .or('age.gt.35,age.is.null') // additional filters imply \"AND\"\n  .not('team_id', 'eq', 'STL')`\nSelect all columns from a single table with a complex where clause: AND OR AND\n`sql\nselect * from players\nwhere ((team_id = 'CHN' and age > 35) or (team_id <> 'CHN' and age is not null))`\n`js\nconst { data, error } = await supabase\n  .from('players')\n  .select() // or .select('*')\n  .or('and(team_id.eq.CHN,age.gt.35),and(team_id.neq.CHN,.not.age.is.null)')`\nGet a count of rows, but don't return any data.\n`sql\nselect count(*) from players\nwhere team_id = 'NYM'`\n`js\nconst { data, error } = await supabase\n  .from('players')\n  .select('*', { count: 'exact', head: true }) // exact, planned, or executed\n  .eq('team_id', 'NYM')`\nResources\n\nSupabase Account - Free Tier OK\nPostgrest Operators\nSupabase API: JavaScript select\nSupabase API: JavaScript modifiers\nSupabase API: JavaScript filters\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Postgres or PostgreSQL?",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/overview.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'database',\n  title: 'Database',\n  description: 'Use Supabase to manage your data.',\n  sidebar_label: 'Overview',\n}\nEvery Supabase project comes with a full Postgres database, a free and open source\ndatabase which is considered one of the world's most stable and advanced databases.\nPostgres or PostgreSQL?\nPostgreSQL the database was derived from the POSTGRES Project, a package written at the University of California at Berkeley in 1986.\nThis package included a query language called \"PostQUEL\".\nIn 1994, Postgres95 was built on top of POSTGRES code, adding an SQL language interpreter as a replacement for PostQUEL.\nEventually, Postgres95 was renamed to PostgreSQL to reflect the SQL query capability.\nAfter this, many people referred to it as Postgres since it's less prone to confusion. Supabase is all about\nsimplicity, so we also refer to it as Postgres.\nFeatures\nTable View\nYou don't have to be a database expert to start using Supabase. Our table view makes Postgres as easy to use as a spreadsheet.\n\nRelationships\nDig into the relationships within your data.\n\n\n\nClone tables\nYou can duplicate your tables, just like you would inside a spreadsheet.\n\n\n\nThe SQL Editor\nSupabase comes with a SQL Editor. You can also save your favorite queries to run later!\n\n\n\nAdditional features\n\nSupabase extends Postgres with realtime functionality using our Realtime Server.\nEvery project is a full Postgres database, with `postgres` level access.\nSupabase manages your database backups.\nImport data directly from a CSV or excel spreadsheet.\n\n\nDatabase backups do not include objects stored via the Storage API, as the database only\nincludes metadata about these objects. Restoring an old backup does not restore objects that have\nbeen deleted since then.\n\nExtensions\nTo expand the functionality of your Postgres database, you can use extensions.\nYou can enable Postgres extensions with the click of a button within the Supabase dashboard.\n\n\n\nLearn more about all the extensions provided on Supabase.\nTips\nRead about resetting your database password here and changing the timezone of your server here.\nNext steps\n\nRead more about Postgres\nSign in: app.supabase.com\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Create a table with an array column",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/arrays.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'arrays',\n  title: 'Working With Arrays',\n  description: 'How to use arrays in PostgreSQL and the Supabase API.',\n}\nPostgreSQL supports flexible array types. These arrays are also supported in the Supabase Dashboard and in the JavaScript API.\nCreate a table with an array column\nCreate a test table with a text array (an array of strings):\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Table editor page in the Dashboard.\nClick New Table and create a table with the name `arraytest`.\nClick Save.\nClick New Column and create a column with the name `textarray`, type `text`, and select Define as array.\nClick Save.\n\n\n\n`sql\nCREATE TABLE arraytest (id integer NOT NULL, textarray text ARRAY);`\n\n\nInsert a record with an array value\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Table editor page in the Dashboard.\nSelect the `arraytest` table.\nClick Insert row and add `[\"Harry\", \"Larry\", \"Moe\"]`.\nClick Save.\n\n\n\n`sql\nINSERT INTO arraytest (id, textarray) VALUES (1, ARRAY['Harry', 'Larry', 'Moe']);`\n\n\nInsert a record from the JavaScript client:\n`js\nconst { data, error } = await supabase\n  .from('arraytest')\n  .insert([{ id: 2, textarray: ['one', 'two', 'three', 'four'] }])`\n\n\nView the results\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Table editor page in the Dashboard.\nSelect the `arraytest` table.\n\nYou should see:\n| id  | textarray               |\n| --- | ----------------------- |\n| 1   | [\"Harry\",\"Larry\",\"Moe\"] |\n\n\n`sql\nSELECT * FROM arraytest;`\nYou should see:\n| id  | textarray               |\n| --- | ----------------------- |\n| 1   | [\"Harry\",\"Larry\",\"Moe\"] |\n\n\nQuery array data\nPostgreSQL uses 1-based indexing (e.g., `textarray[1]` is the first item in the array).\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\nTo select the first item from the array and get the total length of the array:\n`js\nSELECT textarray[1], array_length(textarray, 1) FROM arraytest;`\nreturns:\n| textarray | array_length |\n| --------- | ------------ |\n| Harry     | 3            |\n\n\nThis returns the entire array field:\n`js\nconst { data, error } = await supabase.from('arraytest').select('textarray[]')\nconsole.log(JSON.stringify(data, null, 2))`\nreturns:\n`js\n;[\n  {\n    textarray: ['Harry', 'Larry', 'Moe'],\n  },\n]`\n\n\nResources\n\nSupabase JS Client\nSupabase Account - Free Tier OK\nPostgreSQL Arrays\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "managing-timezones.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/managing-timezones.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'managing-timezones',\n  title: 'Timezones',\n  slug: 'managing-timezones',\n  description: 'How to change your database timezone.',\n}\nEvery Supabase database is set to UTC timezone by default. We strongly recommend keeping it this way, even if your users are in a different location.\nThis is because it makes it much easier to calculate differences between timezones if you adopt the mental model that \"everything in my database is in UTC time\".\nChange timezone\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nalter database postgres\nset timezone to 'America/New_York';`\n\n\nFull list of timezones\nGet a full list of timezones supported by your database. This will return the following columns:\n\n`name`: Time zone name\n`abbrev`: Time zone abbreviation\n`utc_offset`: Offset from UTC (positive means east of Greenwich)\n`is_dst`: True if currently observing daylight savings\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect name, abbrev, utc_offset, is_dst\nfrom pg_timezone_names()\norder by name;`\n\n\nSearch for a specific timezone\nUse `ilike` (case insensitive search) to find specific timezones.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect *\nfrom pg_timezone_names()\nwhere name ilike '%york%';`\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Create a table with a JSON column",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/json.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'json',\n  title: 'JSON',\n  description: 'Using the JSON data type in PostgreSQL.',\n}\nPostgreSQL supports JSON functions and operators which gives flexibility when storing data inside a database column.\nPostgreSQL supports two types of JSON columns: `JSON` and `JSONB`.\nThe recommended type is `JSONB` for almost all cases.\nWhen you use the `JSONB` format, the data is parsed when it's put into the database so it's faster when querying and also it can be indexed.\nCreate a table with a JSON column\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Table Editor page in the Dashboard.\nClick New Table and create a table called `books`.\nInclude a primary key with the following properties:\nName: `id`\nType: `int8`\nDefault value: `Automatically generate as indentity`\nClick Save.\nClick New Column and add 3 columns with the following properties:\ntitle column\nName: `title`\nType: `text`\n\n\nauthor column\nName: `author`\nType: `text`\n\n\nmetadata column\nName: `metadata`\nType: `jsonb`\n\n\n\n\n\n`sql\ncreate table books (\n  id serial primary key,\n  title text,\n  author text,\n  metadata jsonb\n);`\n\n\nInsert data into the table\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Table Editor page in the Dashboard.\nSelect the `books` table in the sidebar.\nClick + Insert row and add 5 rows with the following properties:\n\n| id  | title                               | author                 | metadata                                                                                                              |\n| --- | ----------------------------------- | ---------------------- | --------------------------------------------------------------------------------------------------------------------- |\n| 1   | The Poky Little Puppy               | Janette Sebring Lowrey | `json {\"ages\":[3,6],\"price\":5.95,\"description\":\"Puppy is slower than other, bigger animals.\"}`                        |\n| 2   | The Tale of Peter Rabbit            | Beatrix Potter         | `json {\"ages\":[2,5],\"price\":4.49,\"description\":\"Rabbit eats some vegetables.\"}`                                       |\n| 3   | Tootle                              | Gertrude Crampton      | `json {\"ages\":[2,5],\"price\":3.99,\"description\":\"Little toy train has big dreams.\"}`                                   |\n| 4   | Green Eggs and Ham                  | Dr. Seuss              | `json {\"ages\":[4,8],\"price\":7.49,\"description\":\"Sam has changing food preferences and eats unusually colored food.\"}` |\n| 5   | Harry Potter and the Goblet of Fire | J.K. Rowling           | `json {\"ages\":[10,99],\"price\":24.95,\"description\":\"Fourth year of school starts, big drama ensues.\"}`                 |\n\n\n`sql\ninsert into books\n  (title, author, metadata)\nvalues\n  (\n    'The Poky Little Puppy',\n    'Janette Sebring Lowrey',\n    '{\"description\":\"Puppy is slower than other, bigger animals.\",\"price\":5.95,\"ages\":[3,6]}'\n  ),\n  (\n    'The Tale of Peter Rabbit',\n    'Beatrix Potter',\n    '{\"description\":\"Rabbit eats some vegetables.\",\"price\":4.49,\"ages\":[2,5]}'\n  ),\n  (\n    'Tootle',\n    'Gertrude Crampton',\n    '{\"description\":\"Little toy train has big dreams.\",\"price\":3.99,\"ages\":[2,5]}'\n  ),\n  (\n    'Green Eggs and Ham',\n    'Dr. Seuss',\n    '{\"description\":\"Sam has changing food preferences and eats unusually colored food.\",\"price\":7.49,\"ages\":[4,8]}'\n  ),\n  (\n    'Harry Potter and the Goblet of Fire',\n    'J.K. Rowling',\n    '{\"description\":\"Fourth year of school starts, big drama ensues.\",\"price\":24.95,\"ages\":[10,99]}'\n  );`\n\n\n`js\nconst { data, error } = await supabase.from('books').insert([\n  {\n    title: 'The Poky Little Puppy',\n    author: 'Janette Sebring Lowrey',\n    metadata: {\n      description: 'Puppy is slower than other, bigger animals.',\n      price: 5.95,\n      ages: [3, 6],\n    },\n  },\n  {\n    title: 'The Tale of Peter Rabbit',\n    author: 'Beatrix Potter',\n    metadata: {\n      description: 'Rabbit eats some vegetables.',\n      price: 4.49,\n      ages: [2, 5],\n    },\n  },\n  {\n    title: 'Tootle',\n    author: 'Gertrude Crampton',\n    metadata: {\n      description: 'Little toy train has big dreams.',\n      price: 3.99,\n      ages: [2, 5],\n    },\n  },\n  {\n    title: 'Green Eggs and Ham',\n    author: 'Dr. Seuss',\n    metadata: {\n      description: 'Sam has changing food preferences and eats unusually colored food.',\n      price: 7.49,\n      ages: [4, 8],\n    },\n  },\n  {\n    title: 'Harry Potter and the Goblet of Fire',\n    author: 'J.K. Rowling',\n    metadata: {\n      description: 'Fourth year of school starts, big drama ensues.',\n      price: 24.95,\n      ages: [10, 99],\n    },\n  },\n])`\n\n\nView the data\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect *\nfrom books;`\n\n\n`js\nconst { data, error } = await supabase.from('books').select('*')\nconsole.log(JSON.stringify(data, null, 2))`\n\n\n| id  | title                               | author                 | metadata                                                                                                              |\n| --- | ----------------------------------- | ---------------------- | --------------------------------------------------------------------------------------------------------------------- |\n| 1   | The Poky Little Puppy               | Janette Sebring Lowrey | `json{\"ages\":[3,6],\"price\":5.95,\"description\":\"Puppy is slower than other, bigger animals.\"}`                         |\n| 2   | The Tale of Peter Rabbit            | Beatrix Potter         | `json{\"ages\":[2,5],\"price\":4.49,\"description\":\"Rabbit eats some vegetables.\"}`                                       |\n| 3   | Tootle                              | Gertrude Crampton      | `json{\"ages\":[2,5],\"price\":3.99,\"description\":\"Little toy train has big dreams.\"}`                                   |\n| 4   | Green Eggs and Ham                  | Dr. Seuss              | `json{\"ages\":[4,8],\"price\":7.49,\"description\":\"Sam has changing food preferences and eats unusually colored food.\"}` |\n| 5   | Harry Potter and the Goblet of Fire | J.K. Rowling           | `json{\"ages\":[10,99],\"price\":24.95,\"description\":\"Fourth year of school starts, big drama ensues.\"}`                 |\nThe data as it appears here has the `JSONB` fields in a different order than when inserted. As mentioned earlier, data is parsed as its inserted when using the JSONB format.\n\n\nQuery the `JSONB` data\nSelect the title, description, price, and age range for each book.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  title,\n  metadata -> 'description' AS description,\n  metadata -> 'price' as price,\n  metadata -> 'ages' -> 0 as low_age,\n  metadata -> 'ages' -> 1 as high_age\nfrom\n  books;`\n\n\n`js\nconst { data, error } = await supabase\n  .from('books')\n  .select(\n    'title,description:metadata->description,price:metadata->price,low_age:metadata->ages->0,high_age:metadata->ages->1'\n  )\nconsole.log(JSON.stringify(data, null, 2))`\n\n\n| title                               | description                                                        | price | low_age | high_age |\n| ----------------------------------- | ------------------------------------------------------------------ | ----- | ------- | -------- |\n| The Poky Little Puppy               | Puppy is slower than other, bigger animals.                        | 5.95  | 3       | 6        |\n| The Tale of Peter Rabbit            | Rabbit eats some vegetables.                                       | 4.49  | 2       | 5        |\n| Tootle                              | Little toy train has big dreams.                                   | 3.99  | 2       | 5        |\n| Green Eggs and Ham                  | Sam has changing food preferences and eats unusually colored food. | 7.49  | 4       | 8        |\n| Harry Potter and the Goblet of Fire | Fourth year of school starts, big drama ensues.                    | 24.95 | 10      | 99       |\n\n\nNote that the `->` operator returns JSONB data. If you want TEXT/STRING data returned, use the `->>` operator.\n\nmetadata -> 'description' (returns a JSON object)\nmetadata ->> 'description' (returns STRING/TEXT data)\n\nResources\n\nSupabase JS Client\nPostgreSQL: JSON Functions and Operators\nPostgreSQL JSON types\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Creating a webhook",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/webhooks.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'webhooks',\n  title: 'Database Webhooks',\n  description: 'Trigger external payloads on database events.',\n  video: 'https://www.youtube.com/v/codAs9-NeHM',\n}\nDatabase Webhooks allow you to send real-time data from your database to another system whenever a table event occurs.\nYou can hook into three table events: `INSERT`, `UPDATE`, and `DELETE`. All events are fired after a database row is changed.\nDatabase Webhooks are very similar to triggers, and that's because Database Webhooks are just a convenience wrapper around triggers\nusing the pg_net extension. This extension is asynchronous, and therefore will not block your database changes for long-running network requests.\nThis video demonstrates how you can create a new customer in Stripe each time a row is inserted into a `profiles` table:\n\nDatabase Webhooks were previously known as Function Hooks.\n\n\n\n\nCreating a webhook\n\nCreate a new Database Webhook in the Dashboard.\nGive your Webhook a name.\nSelect the table you want to hook into.\nSelect one or more events (table inserts, updates, or deletes) you want to hook into.\n\nWe currently support HTTP webhooks. These are sent as a `POST` request with a JSON payload.\nPayload\nThe payload is automatically generated from the underlying table record:\n`typescript\ntype InsertPayload = {\n  type: 'INSERT'\n  table: string\n  schema: string\n  record: TableRecord<T>\n  old_record: null\n}\ntype UpdatePayload = {\n  type: 'UPDATE'\n  table: string\n  schema: string\n  record: TableRecord<T>\n  old_record: TableRecord<T>\n}\ntype DeletePayload = {\n  type: 'DELETE'\n  table: string\n  schema: string\n  record: null\n  old_record: TableRecord<T>\n}`\nResources\n\npg_net: an async networking extension for PostgreSQL\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Creating a test",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/testing.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'testing',\n  title: 'Testing Your Database',\n  description: 'Test your database schema, tables, functions, and policies.',\n}\nYou can use the Supabase CLI to test your database. The minimum required version of the CLI is v1.11.4. To get started:\n\nInstall the Supabase CLI on your local machine\n\nCreating a test\nCreate a tests folder inside the supabase folder:\n`bash\nmkdir -p ./supabase/tests/database`\nCreate a new file with the `.sql` extension which will contain the test.\n`bash\ntouch ./supabase/tests/database/hello_world.test.sql`\nWriting tests\nAll `sql` files use pgTAP as the test runner.\nLet's write a simple test to check that our `auth.users` table has an ID column. Open `hello_world.test.sql` and add the following code:\n```sql\nbegin;\nselect plan(1); -- only one statement to run\nSELECT has_column(\n    'auth',\n    'users',\n    'id',\n    'id should exist'\n);\nselect * from finish();\nrollback;\n```\nRunning tests\nTo run the test, you can use:\n`bash\nsupabase test db`\nThis will produce the following output:\n`bash\n$ supabase test db\nsupabase/tests/database/hello_world.test.sql .. ok\nAll tests successful.\nFiles=1, Tests=1,  1 wallclock secs ( 0.01 usr  0.00 sys +  0.04 cusr  0.02 csys =  0.07 CPU)\nResult: PASS`\nMore resource\n\npgTAP extension\nOfficial pgTAP documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Types of Connection",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/connecting-to-postgres.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'connecting-to-postgres',\n  title: 'Database Connections',\n  description: 'There are various ways to connect to your Postgres database.',\n}\nSupabase provides several options for programmatically connecting to your Postgres database:\nTypes of Connection\n\nHTTP connections using the API.\nDirect connections using Postgres' standard connection system.\nConnection pooling using PgBouncer.\n\nDirect vs Pooling vs API\n\nA \"direct connection\" is when a connection is made to the database using Postgres' native connection implementation. You should use this for tools which are always alive - usually installed on a long-running server.\nA \"connection pool\" is a system (external to Postgres) which keeps connections \"open\". You should use this for serverless functions and tools which disconnect from the database frequently.\nThe API is an auto-generated REST interface. You should use this for all browser and application interactions. The API server internally handles a connection pool.\n\nWhy would you use a connection pool? Primarily because the way that Postgres handles connections isn't very scalable for a large number of temporary connections.\nYou can use these simple questions to determine which connection method to use:\n\nAre you connecting to a database and maintaining a connection? If yes, use a direct connection.\nAre you connecting to your database and then disconnecting immediately (e.g. a serverless environment)? If yes, use a connection pool.\n\nAPI\nSupabase provides an auto-updating API. This is the easiest way to get started if you are managing data (fetching, inserting, updating).\nInterfaces\nWe provides several types of API to suit your preferences and use-case:\n\nREST: interact with your database through a REST interface.\nGraphQL: interact with your database through a GraphQL interface.\nRealtime: listen to database changes over websockets.\n\nYou cannot manage the database schema via the API (for security reasons). To do that you can use the dashboard or connect directly to your database.\nAPI URL and Keys\nYou can find the API URL and Keys in the Dashboard.\n\n\n\nDirect connections\nEvery Supabase project provides a full Postgres database. You can connect to the database using any tool which supports Postgres.\nFinding your connection string\n\nGo to the `Settings` section.\nClick `Database`.\nFind your Connection Info and Connection String. Direct connections are on port `5432`.\n\n\n\n\nConnection Pool\nConnection pools are useful for managing a large number of temporary connections. For example, if you are using Prisma deployed to a Serverless environment.\nHow connection pooling works\nA \"connection pool\" is a system (external to Postgres) which manages connections, rather than PostgreSQL's native system. Supabase uses PgBouncer for connection pooling.\nWhen a client makes a request, PgBouncer \"allocates\" an available connection to the client.\nWhen the client transaction or session is completed the connection is returned to the pool and is free to be used by another client.\n\nPool modes\nPool Mode determines how PgBouncer handles a connection.\nSession\nWhen a new client connects, a connection is assigned to the client until it disconnects. Afterward, the connection is returned back to the pool.\nAll PostgreSQL features can be used with this option.\nTransaction\nThis is the suggested option for serverless functions. A connection is only assigned to the client for the duration of a transaction. Two consecutive transactions from the same client\ncould be executed over two different connections.\nSome session-based PostgreSQL features such as prepared statements are not available with this option.\nA comprehensive list of incompatible features can be found here.\nStatement\nThis is the most granular option. Connections are returned to the pool after every statement. Transactions with multiple statements are not allowed. This is best used when `AUTOCOMMIT` is in use.\nFinding the connection pool config\n\nGo to the `Settings` section.\nClick `Database`.\nFind your Connection Info and Connection String. Connection pooling is on port `6543`.\n\n\n\n\nConnecting with SSL\nUse this when connecting to your database to prevent snooping and man-in-the-middle attacks.\nObtain your connection info and Server root certificate from your application\u2019s dashboard.\n\nAssuming you\u2019ve downloaded your certificate and it\u2019s located at `$HOME/Downloads/prod-ca-2021.cer`, and your Host address is `db.abcdefghijklm.supabase.co` you can connect to the DB with\nSSL enabled as illustrated below:\n\nWith `psql`\n\n`psql \"sslmode=verify-full sslrootcert=$HOME/Downloads/prod-ca-2021.cer host=db.abcdefghijklm.supabase.co dbname=postgres user=postgres\"`\n\nWith `pgAdmin`\n   a. Register a new Postgres server\n   \n\nb. Name your server to your liking and add the connection info.\n   \n\n\nNavigate to the SSL tab and change the SSL mode to Require. Next navigate to the Root certificate input, it will open up a\n   file-picker modal. Select the certificate you downloaded from your Supabase dashboard and save the server details. PgAdmin\n   should now be able to connect to your Postgres via SSL.\n   \n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Quick demo",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/functions.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'functions',\n  title: 'Database Functions',\n  description: 'Creating and using Postgres functions.',\n  video: 'https://www.youtube.com/v/MJZCCpCYEqk',\n}\nPostgres has built-in support for SQL functions.\nThese functions live inside your database, and they can be used with the API.\nQuick demo\n\n\n\nGetting started\nSupabase provides several options for creating database functions. You can use the Dashboard or create them directly using SQL.\nWe provide a SQL editor within the Dashboard, or you can connect to your database\nand run the SQL queries yourself.\n\nGo to the \"SQL editor\" section.\nClick \"New Query\".\nEnter the SQL to create or replace your Database function.\nClick \"Run\" or cmd+enter (ctrl+enter).\n\nSimple Functions\nLet's create a basic Database Function which returns a string \"hello world\".\n```sql\ncreate or replace function hello_world() -- 1\nreturns text -- 2\nlanguage sql -- 3\nas $$  -- 4\n  select 'hello world';  -- 5\n$$; --6\n```\n\nShow/Hide Details\n\nAt it's most basic a function has the following parts:\n\n1. `create or replace function hello_world()`: The function declaration, where `hello_world` is the name of the function. You can use either `create` when creating a new function or `replace` when replacing an existing function. Or you can use `create or replace` together to handle either.\n2. `returns text`: The type of data that the function returns. If it returns nothing, you can `returns void`.\n3. `language sql`: The language used inside the function body. This can also be a procedural language: `plpgsql`, `plv8`, `plpython`, etc.\n4. `as $$`: The function wrapper. Anything enclosed inside the `$$` symbols will be part of the function body.\n5. `select 'hello world';`: A simple function body. The final `select` statement inside a function body will be returned if there are no statements following it.\n6. `$$;`: The closing symbols of the function wrapper.\n\n\n\nAfter the Function is created, we have several ways of \"executing\" the function - either directly inside the database using SQL, or with one of the client libraries.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect hello_world();`\n\n\n`js\nconst { data, error } = await supabase.rpc('hello_world')`\nReference: rpc()\n\n\n`dart\nfinal data = await supabase\n  .rpc('hello_world');`\nReference: rpc()\n\n\nReturning data sets\nDatabase Functions can also return data sets from Tables or Views.\nFor example, if we had a database with some Star Wars data inside:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"data\"\n\n\n\nPlanets\n| id  | name     |\n| --- | -------- |\n| 1   | Tattoine |\n| 2   | Alderaan |\n| 3   | Kashyyyk |\nPeople\n| id  | name             | planet_id |\n| --- | ---------------- | --------- |\n| 1   | Anakin Skywalker | 1         |\n| 2   | Luke Skywalker   | 1         |\n| 3   | Princess Leia    | 2         |\n| 4   | Chewbacca        | 3         |\n\n\n```sql\ncreate table planets (\n  id serial primary key,\n  name text\n);\ninsert into planets (id, name)\nvalues\n  (1, 'Tattoine'),\n  (2, 'Alderaan'),\n  (3, 'Kashyyyk');\ncreate table people (\n  id serial primary key,\n  name text,\n  planet_id bigint references planets\n);\ninsert into people (id, name, planet_id)\nvalues\n  (1, 'Anakin Skywalker', 1),\n  (2, 'Luke Skywalker', 1),\n  (3, 'Princess Leia', 2),\n  (4, 'Chewbacca', 3);\n```\n\n\nWe could create a function which returns all the planets:\n`sql\ncreate or replace function get_planets()\nreturns setof planets\nlanguage sql\nas $$\n  select * from planets;\n$$;`\nBecause this function returns a table set, we can also apply filters and selectors. For example, if we only wanted the first planet:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect *\nfrom get_planets()\nwhere id = 1;`\n\n\n`js\nconst { data, error } = supabase.rpc('get_planets').eq('id', 1)`\n\n\n`dart\nfinal data = await supabase\n  .rpc('get_planets')\n  .eq('id', 1);`\n\n\nPassing parameters\nLet's create a Function to insert a new planet into the `planets` table and return the new ID. Note that this time we're using the `plpgsql` language.\n```sql\ncreate or replace function add_planet(name text)\nreturns bigint\nlanguage plpgsql\nas $$\ndeclare\n  new_row bigint;\nbegin\n  insert into planets(name)\n  values (add_planet.name)\n  returning id into new_row;\nreturn new_row;\nend;\n$$;\n```\nOnce again, you can execute this function either inside your database using a `select` query, or with the client libraries:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect * from add_planet('Jakku');`\n\n\n`js\nconst { data, error } = await supabase.rpc('add_planet', { name: 'Jakku' })`\n\n\n`dart\nfinal data = await supabase\n  .rpc('add_planet', params: { 'name': 'Jakku' });`\n\n\nSuggestions\nDatabase Functions vs Edge Functions\nFor data-intensive operations, use Database Functions, which are executed within your database\nand can be called remotely using the REST and GraphQL API.\nFor use-cases which require low-latency, use Edge Functions, which are globally-distributed and can be written in Typescript.\nSecurity `definer` vs `invoker`\nPostgres allows you to specify whether you want the function to be executed as the user calling the function (`invoker`), or as the creator of the function (`definer`). For example:\n`sql\ncreate function hello_world()\nreturns text\nlanguage plpgsql\nsecurity definer set search_path = public\nas $$\nbegin\n  select 'hello world';\nend;\n$$;`\nIt is best practice to use `security invoker` (which is also the default). If you ever use `security definer`, you must set the `search_path`.\nThis limits the potential damage if you allow access to schemas which the user executing the function should not have.\nFunction privileges\nBy default, database functions can be executed by any role. You can restrict this by altering the default privileges and then choosing which roles can execute functions.\n```sql\nALTER DEFAULT PRIVILEGES REVOKE EXECUTE ON FUNCTIONS FROM PUBLIC;\n-- Choose which roles can execute functions\nGRANT EXECUTE ON FUNCTION hello_world TO authenticated;\nGRANT EXECUTE ON FUNCTION hello_world TO service_role;\n```\nResources\n\nOfficial Client libraries: JavaScript and Flutter\nCommunity client libraries: github.com/supabase-community\nPostgreSQL Official Docs: Chapter 9. Functions and Operators\nPostgreSQL Reference: CREATE FUNCTION\n\nDeep Dive\nCreate Database Functions\n\n\n\nCall Database Functions using JavaScript\n\n\n\nUsing Database Functions to call an external API\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Preparation",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/full-text-search.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'full-text-search',\n  title: 'Full Text Search',\n  description: 'How to use full text search in PostgreSQL.',\n  video: 'https://www.youtube.com/v/b-mgca_2Oe4',\n}\nPostgres has built-in functions to handle `Full Text Search` queries. This is like a \"search engine\" within Postgres.\n\n\n\nPreparation\nFor this guide we'll use the following example data:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"data\"\n\n\n\n| id  | title                               | author                 | description                                                        |\n| --- | ----------------------------------- | ---------------------- | ------------------------------------------------------------------ |\n| 1   | The Poky Little Puppy               | Janette Sebring Lowrey | Puppy is slower than other, bigger animals.                        |\n| 2   | The Tale of Peter Rabbit            | Beatrix Potter         | Rabbit eats some vegetables.                                       |\n| 3   | Tootle                              | Gertrude Crampton      | Little toy train has big dreams.                                   |\n| 4   | Green Eggs and Ham                  | Dr. Seuss              | Sam has changing food preferences and eats unusually colored food. |\n| 5   | Harry Potter and the Goblet of Fire | J.K. Rowling           | Fourth year of school starts, big drama ensues.                    |\n\n\n```sql\ncreate table books (\n  id serial primary key,\n  title text,\n  author text,\n  description text\n);\ninsert into books (title, author, description)\nvalues\n  ('The Poky Little Puppy','Janette Sebring Lowrey','Puppy is slower than other, bigger animals.'),\n  ('The Tale of Peter Rabbit','Beatrix Potter','Rabbit eats some vegetables.'),\n  ('Tootle','Gertrude Crampton','Little toy train has big dreams.'),\n  ('Green Eggs and Ham','Dr. Seuss','Sam has changing food preferences and eats unusually colored food.'),\n  ('Harry Potter and the Goblet of Fire','J.K. Rowling','Fourth year of school starts, big drama ensues.');\n```\n\n\nUsage\nThe functions we'll cover in this guide are:\n`to_tsvector()` [#to-tsvector]\nConverts your data into searchable \"tokens\". `to_tsvector()` stands for \"to text search vector\". For example:\n```sql\nselect to_tsvector('green eggs and ham')\n-- Returns 'egg':2 'green':1 'ham':4\n```\nCollectively these tokens are called a \"document\" which Postgres can use for comparisons.\n`to_tsquery()` [#to-tsquery]\nConverts a query string into \"tokens\" to match. `to_tsquery()` stands for \"to text search query\".\nThis conversion step is important because we will want to \"fuzzy match\" on keywords.\nFor example if a user searches for \"eggs\", and a column has the value \"egg\", we probably still want to return a match.\nMatch: `@@` [#match]\nThe `@@` symbol is the \"match\" symbol for Full Text Search. It returns any matches between a `to_tsvector` result and a `to_tsquery` result.\nTake the following example:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect *\nfrom books\nwhere title = 'Harry';`\n\n\n`js\nconst { data, error } = await supabase.from('books').select().eq('title', 'Harry')`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .eq('title', 'Harry');`\n\n\nThe equality symbol above (`=`) is very \"strict\" on what it matches. In a full text search context, we might want to find all \"Harry Potter\" books and so we can rewrite the\nexample above:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect *\nfrom books\nwhere to_tsvector(title) @@ to_tsquery('Harry');`\n\n\n`js\nconst { data, error } = await supabase.from('books').select().textSearch('title', `'Harry'`)`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .textSearch('title', \"'Harry'\");`\n\n\nBasic Full Text Queries\nSearch a single column\nTo find all `books` where the `description` contain the word `big`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  *\nfrom\n  books\nwhere\n  to_tsvector(description)\n  @@ to_tsquery('big');`\n\n\n`js\nconst { data, error } = await supabase.from('books').select().textSearch('description', `'big'`)`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .textSearch('description', \"'big'\");`\n\n\n| id  | title                               | author            | description                                     |\n| --- | ----------------------------------- | ----------------- | ----------------------------------------------- |\n| 3   | Tootle                              | Gertrude Crampton | Little toy train has big dreams.                |\n| 5   | Harry Potter and the Goblet of Fire | J.K. Rowling      | Fourth year of school starts, big drama ensues. |\n\n\nSearch multiple columns\nTo find all `books` where `description` or `title` contain the word `little`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  *\nfrom\n  books\nwhere\n  to_tsvector(description || ' ' || title) -- concat columns, but be sure to include a space to separate them!\n  @@ to_tsquery('little');`\n\n\n| id  | title                 | author                 | description                                 |\n| --- | --------------------- | ---------------------- | ------------------------------------------- |\n| 1   | The Poky Little Puppy | Janette Sebring Lowrey | Puppy is slower than other, bigger animals. |\n| 3   | Tootle                | Gertrude Crampton      | Little toy train has big dreams.            |\n\n\nMatch all search words\nTo find all `books` where `description` contains BOTH of the words `little` and `big`, we can use the `&` symbol:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  *\nfrom\n  books\nwhere\n  to_tsvector(description)\n  @@ to_tsquery('little & big'); -- use & for AND in the search query`\n\n\n`js\nconst { data, error } = await supabase\n  .from('books')\n  .select()\n  .textSearch('description', `'little' & 'big'`)`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .textSearch('description', \"'little' & 'big'\");`\n\n\n| id  | title  | author            | description                      |\n| --- | ------ | ----------------- | -------------------------------- |\n| 3   | Tootle | Gertrude Crampton | Little toy train has big dreams. |\n\n\nMatch any search words\nTo find all `books` where `description` contain ANY of the words `little` or `big`, use the `|` symbol:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  *\nfrom\n  books\nwhere\n  to_tsvector(description)\n  @@ to_tsquery('little | big'); -- use | for OR in the search query`\n\n\n`js\nconst { data, error } = await supabase\n  .from('books')\n  .select()\n  .textSearch('description', `'little' | 'big'`)`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .textSearch('description', \"'little' | 'big'\");`\n\n\n| id  | title                 | author                 | description                                 |\n| --- | --------------------- | ---------------------- | ------------------------------------------- |\n| 1   | The Poky Little Puppy | Janette Sebring Lowrey | Puppy is slower than other, bigger animals. |\n| 3   | Tootle                | Gertrude Crampton      | Little toy train has big dreams.            |\n\n\nNotice how searching for `big` includes results with the word `bigger` (or `biggest`, etc).\nCreating Indexes\nNow that we have Full Text Search working, let's create an `index`. This will allow Postgres to \"build\" the documents pre-emptively so that they\ndon't need to be created at the time we execute the query. This will make our queries much faster.\nSearchable columns\nLet's create a new column `fts` inside the `books` table to store the searchable index of the `title` and `description` columns.\nWe can use a special feature of Postgres called\nGenerated Columns\nto ensure that the index is updated any time the values in the `title` and `description` columns change.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n```sql\nalter table\n  books\nadd column\n  fts tsvector generated always as (to_tsvector('english', description || ' ' || title)) stored;\ncreate index books_fts on books using gin (fts); -- generate the index\nselect id, fts\nfrom books;\n```\n\n\n| id  | fts                                                                                                             |\n| --- | --------------------------------------------------------------------------------------------------------------- |\n| 1   | 'anim':7 'bigger':6 'littl':10 'poki':9 'puppi':1,11 'slower':3                                                 |\n| 2   | 'eat':2 'peter':8 'rabbit':1,9 'tale':6 'veget':4                                                               |\n| 3   | 'big':5 'dream':6 'littl':1 'tootl':7 'toy':2 'train':3                                                         |\n| 4   | 'chang':3 'color':9 'eat':7 'egg':12 'food':4,10 'green':11 'ham':14 'prefer':5 'sam':1 'unus':8                |\n| 5   | 'big':6 'drama':7 'ensu':8 'fire':15 'fourth':1 'goblet':13 'harri':9 'potter':10 'school':4 'start':5 'year':2 |\n\n\nSearch using the new column\nNow that we've created and populated our index, we can search it using the same techniques as before:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  *\nfrom\n  books\nwhere\n  fts @@ to_tsquery('little & big');`\n\n\n`js\nconst { data, error } = await supabase.from('books').select().textSearch('fts', `'little' & 'big'`)`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .textSearch('fts', \"'little' & 'big'\");`\n\n\n| id  | title  | author            | description                      | fts                                                     |\n| --- | ------ | ----------------- | -------------------------------- | ------------------------------------------------------- |\n| 3   | Tootle | Gertrude Crampton | Little toy train has big dreams. | 'big':5 'dream':6 'littl':1 'tootl':7 'toy':2 'train':3 |\n\n\nQuery Operators\nVisit PostgreSQL: Text Search Functions and Operators\nto learn about additional query operators you can use to do more advanced `full text queries`, such as:\nProximity: `<->` [#proximity]\nThe proximity symbol is useful for searching for terms that are a certain \"distance\" apart.\nFor example, to find the phrase `big dreams`, where the a match for \"big\" is followed immediately by a match for \"dreams\":\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  *\nfrom\n  books\nwhere\n  to_tsvector(description) @@ to_tsquery('big <-> dreams');`\n\n\n`js\nconst { data, error } = await supabase\n  .from('books')\n  .select()\n  .textSearch('description', `'big' <-> 'dreams'`)`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .textSearch('description', \"'big' <-> 'dreams'\");`\n\n\nWe can also use the `<->` to find words within a certain distance of eachother. For example to find `year` and `school` within 2 words of each other:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  *\nfrom\n  books\nwhere\n  to_tsvector(description) @@ to_tsquery('year <2> school');`\n\n\n`js\nconst { data, error } = await supabase\n  .from('books')\n  .select()\n  .textSearch('description', `'year' <2> 'school'`)`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .textSearch('description', \"'year' <2> 'school'\");`\n\n\nNegation: `!` [#negation]\nThe negation symbol can be used to find phrases which don't contain a search term.\nFor example, to find records that have the word `big` but not `little`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect\n  *\nfrom\n  books\nwhere\n  to_tsvector(description) @@ to_tsquery('big & !little');`\n\n\n`js\nconst { data, error } = await supabase\n  .from('books')\n  .select()\n  .textSearch('description', `'big' & !'little'`)`\n\n\n`dart\nfinal result = await client\n  .from('books')\n  .select()\n  .textSearch('description', \"'big' & !'little'\");`\n\n\nResources\n\nPostgreSQL: Text Search Functions and Operators\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "extensions.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'extensions',\n  title: 'Postgres Extensions Overview',\n  description: 'Using Postgres extensions.',\n}\nExtensions are exactly as they sound - they \"extend\" the database with functionality which isn't part of the Postgres core.\nSupabase has pre-installed some of the most useful open source extensions.\nEnable and disable extensions\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick Extensions in the sidebar.\nEnable or disable an extension.\n\n\n\n```sql\n -- Example: enable the \"pgtap\" extension and ensure it is installed\ncreate extension pgtap\nwith\n  schema extensions;\n-- Example: disable the \"pgtap\" extension\ndrop\n  extension pgtap;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension call `drop extension`.\n\nEnabling some extensions with `create extension <extension-name> with schema extensions` may lead to permission issues (e.g., `dblink`, `http`, `pg_cron`).\n\n\n\nFull list of extensions\nSupabase is pre-configured with over 50 extensions. You can also install your own SQL extensions directly in the database through our SQL editor.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Changing your project password",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/managing-passwords.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'managing-passwords',\n  title: 'Passwords',\n  description: 'How to change your PostgreSQL database password.',\n}\nYour PostgreSQL database is the core of your Supabase project, so it's important that it has a strong, secure password at all times.\nIf you use special symbols in your postgres password, you must remember to percent-encode your password later if using the postgres connection string e.g. `postgresql://postgres:p%3Dword@db.cvwawazfelidkloqmbma.supabase.co:5432/postgres`\nChanging your project password\nWhen you created your project you were also asked to enter a password. This is actually the password for your database, specifically for the `postgres` user.\nYou can update this from the Dashboard under the database settings page.\nCreating a secure password\nIt's absolutely critical that you store your customers' data safely. Here are some tips for creating a secure password.\n\nUse a password manager to generate it.\nMake a long password (12 characters at least).\nDon't use any common dictionary words.\nUse both upper and lower case characters, numbers, and special symbols.\n\nResources\n\nPostgreSQL ALTER USER Documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Append /rest/v1/ to your URL, and then use the table name as the route",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/api.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'api',\n  title: 'Serverless APIs',\n  description: 'Auto-generating and Realtime APIs.',\n  sidebar_label: 'Overview',\n  video: 'https://www.youtube.com/v/rPAJJFdtPw0',\n}\nSupabase auto-generates three types of API directly from your database schema.\n\nREST - interact with your database through a restful interface.\nRealtime - listen to database changes.\nGraphQL - in beta.\n\nThe APIs are:\n\nInstant and auto-generated. As you update your database the changes are immediately accessible through your API.\nSelf documenting. Supabase generates documentation in the Dashboard which updates as you make database changes.\nSecure. The API is configured to work with PostgreSQL's Row Level Security, provisioned behind an API gateway with key-auth enabled.\nFast. Our benchmarks for basic reads are more than 300% faster than Firebase. The API is a very thin layer on top of Postgres, which does most of the heavy lifting.\nScalable. The API can serve thousands of simultaneous requests, and works well for Serverless workloads.\n\nREST API [#rest-api-overview]\nSupabase provides a RESTful API using PostgREST. This is a very thin API layer on top of Postgres.\nIt provides everything you need from a CRUD API:\n\nBasic CRUD operations\nDeeply nested joins, allowing you to fetch data from multiple tables in a single fetch\nWorks with Postgres Views\nWorks with Postgres Functions\nWorks with the Postgres security model - including Row Level Security, Roles, and Grants.\n\n\n\n\nGraphQL API [#graphql-api-overview]\n\nGraphQL is in Beta, and may have breaking changes. It is only available on self-hosted setups and Supabase projects created after 28th March 2022.\n\nGraphQL in Supabase works through pg_graphql, an open source PostgreSQL extension for GraphQL.\nRealtime API [#realtime-api-overview]\nSupabase provides a Realtime API using Realtime. You can use this to listen to database changes over websockets.\nRealtime leverages PostgreSQL's built-in logical replication. You can manage your Realtime API simply by managing Postgres publications.\nGo to your project's Replication section to get started.\nGetting started\nAll APIs are auto-created from Database tables. After you have added tables or functions to your database, you can use the APIs provided.\nCreating API Routes\nAPI routes are automatically created when you create Postgres Tables, Views, or Functions.\nLet's create our first\nAPI route by creating a table called `todos` to store tasks.\nThis creates a corresponding route `todos` which can accept `GET`, `POST`, `PATCH`, & `DELETE` requests.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Table editor page in the Dashboard.\nClick New Table and create a table with the name `todos`.\nClick Save.\nClick New Column and create a column with the name `task` and type `text`.\nClick Save.\n\n\n\n\n\n\n```sql\n-- Create a table called \"todos\" with a column to store tasks.\ncreate table todos (\n  id bigint generated by default as identity primary key,\n  task text check (char_length(task) > 3)\n);\n```\n\n\nAPI URL and Keys\nEvery Supabase project has a unique API URL. Your API is secured behind an API gateway which requires an API Key for every request.\n\nGo to the Settings page in the Dashboard.\nClick API in the sidebar.\nFind your API `URL`, `anon`, and `service_role` keys on this page.\n\n\n\n\nThe REST API and the GraphQL API are both accessible through this URL:\n\nREST: `https://<project_ref>.supabase.co/rest/v1`\nGraphQL: `https://<project_ref>.supabase.co/graphql/v1`\n\nBoth of these routes require the `anon` key to be passed through an `apikey` header.\nAPI Keys\nYou are provided with two keys:\n\nan `anon` key, which is safe to be used in a browser context.\na `service_role` key, which should only be used on a server. This key can bypass Row Level Security. NEVER use this key in a browser.\n\nAccessing the docs in the Dashboard\nREST API [#rest-api-dashboard-docs]\nSupabase generates documentation in the Dashboard which updates as you make database changes.\nLet's view the documentation for a `countries` table which we created in our database.\n\nGo to the API page in the Dashboard.\nFind the `countries` table under Tables and Views in the sidebar.\nSwitch between the JavaScript and the cURL docs using the tabs.\n\n\n\n\nGraphQL\nThe GraphQL Endpoint that we provide (`https://<project_ref>.supabase.co/graphql/v1`) is compatible with any GraphiQL implementation that can pass an `apikey` header.\nSome suggested applications:\n\npaw.cloud\ninsomnia.rest\npostman.com/graphql\nSelf-hosted GraphiQL: GraphiQL can be served through a simple HTML file. See this discussion for more details.\n\nUsing the API\nREST API\nYou can interact with your API directly via HTTP requests, or you can use the client libraries which we provide.\nLet's see how to make a request to the `todos` table which we created in the first step,\nusing the API URL (`SUPABASE_URL`) and Key (`SUPABASE_ANON_KEY`) we provided:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"javascript\"\n\n\n\n```javascript\n// Initialize the JS client\nimport { createClient } from '@supabase/supabase-js'\nconst supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY)\n// Make a request\nconst { data: todos, error } = await supabase.from('todos').select('*')\n```\n\n\n```bash\nAppend /rest/v1/ to your URL, and then use the table name as the route\ncurl '/rest/v1/todos' \\\n-H \"apikey: \" \\\n-H \"Authorization: Bearer \"\n```\n\n\nJS Reference: select(),\ninsert(),\nupdate(),\nupsert(),\ndelete(),\nrpc() (call Postgres functions).\nGraphQL API\nYou can use any GraphQL client with the Supabase GraphQL API. For our GraphQL example we will use urql.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"javascript\"\n\n\n\n```javascript\nimport { createClient, useQuery } from 'urql'\n// Prepare API key and Authorization header\nconst headers = {\n  apikey: ,\n  authorization: `Bearer ${<SUPABASE_ANON_KEY>}`,\n}\n// Create GraphQL client\n// See: https://formidable.com/open-source/urql/docs/basics/react-preact/#setting-up-the-client\nconst client = createClient({\n  url: '/graphql/v1',\n  fetchOptions: function createFetchOptions() {\n    return { headers }\n  },\n})\n// Prepare our GraphQL query\nconst TodosQuery = `query {\n    todosCollection {\n      edges {\n        node {\n          id\n          title\n        }\n      }\n    }\n  }`\n// Query for the data (React)\nconst [result, reexecuteQuery] = useQuery({\n  query: TodosQuery,\n})\n// Read the result\nconst { data, fetching, error } = result\n```\n\n\n```bash\nAppend /graphql/v1/ to your URL, and then use the table name as the route\ncurl --request POST '/graphql/v1' \\\n-H 'apikey: ' \\\n-H 'Authorization: Bearer ' \\\n-H 'Content-Type: application/json' \\\n-d '{ \"query\":\"{ todos(first: 3) { edges { node { id } } } }\" }'\n```\n\n\nRealtime API\nBy default Realtime is disabled on your database. Let's turn on Realtime for the `todos` table.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Replication in the sidebar.\nControl which database events are sent by toggling Insert, Update, and Delete.\nControl which tables broadcast changes by selecting Source and toggling each table.\n\n\n\n\n\n\n`sql\nalter publication supabase_realtime add table todos;`\n\n\nFrom the client, we can listen to any new data that is inserted into the `todos` table:\n```javascript\n// Initialize the JS client\nimport { createClient } from '@supabase/supabase-js'\nconst supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY)\n// Create a function to handle inserts\nconst handleInserts = (payload) => {\n  console.log('Change received!', payload)\n}\n// Listen to inserts\nconst { data: todos, error } = await supabase.from('todos').on('INSERT', handleInserts).subscribe()\n```\nUse subscribe() to listen to database changes.\nThe Realtime API works through PostgreSQL's replication functionality. Postgres sends database changes to a publication\ncalled `supabase_realtime`, and by managing this publication you can control which data is broadcast.\nAPI Security\nSecuring your Routes\nYour API is designed to work with Postgres Row Level Security (RLS). If you use Supabase Auth, you can restrict data based on the logged-in user.\nTo control access to your data, you can use Policies.\nWhen you create a table in Postgres, Row Level Security is disabled by default. To enable RLS:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Authentication page in the Dashboard.\nClick on Policies in the sidebar.\nSelect Enable RLS to enable Row Level Security.\n\n\n\n`sql\nalter table todos enable row level security;`\n\n\nThe `service_role` key\nNever expose the `service_role` key in a browser or anywhere where a user can see it. This Key is designed to bypass Row Level Security - so it should only be used on a private server.\nA common use case for the `service_role` key is to run data analytics jobs on the backend. To support joins on user id, it is often useful to grant the service role read access to `auth.users` table.\n`sql\ngrant select on table auth.users to service_role;`\nWe have partnered with GitHub to scan for Supabase `service_role` keys pushed to public repositories.\nIf they detect any keys with service_role privileges being pushed to GitHub, they will forward the API key to us, so that we can automatically revoke the detected secrets and notify you, protecting your data against malicious actors.\nSafeguards towards accidental deletes and updates\nFor all projects, by default, the Postgres extension safeupdate is enabled for all queries coming from the API.\nThis ensures that any `delete()` or `update()` would fail if there are no accompanying filters provided.\nTo confirm that safeupdate is enabled for queries going through the API of your project, the following query could be run:\n`sql\nselect usename,useconfig from pg_shadow where usename = 'authenticator' ;`\nThe expected value for `useconfig` should be:\n`sql\n['session_preload_libraries=supautils, safeupdate']`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Creating Tables",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/tables.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'tables',\n  title: 'Tables and Data',\n  description: 'Creating and using Postgres tables.',\n  video: 'https://www.youtube.com/v/TKwF3IGij5c',\n}\nTables are where you store your data.\nTables are similar to excel spreadsheets. They contain columns and rows.\nFor example, this table has 3 \"columns\" (`id`, `name`, `description`) and 4 \"rows\" of data:\n| `id` | `name`               | `description`                                                                                                                                                 |\n| ---- | -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | The Phantom Menace   | Two Jedi escape a hostile blockade to find allies and come across a young boy who may bring balance to the Force.                                             |\n| 2    | Attack of the Clones | Ten years after the invasion of Naboo, the Galactic Republic is facing a Separatist movement.                                                                 |\n| 3    | Revenge of the Sith  | As Obi-Wan pursues a new threat, Anakin acts as a double agent between the Jedi Council and Palpatine and is lured into a sinister plan to rule the galaxy.   |\n| 4    | Star Wars            | Luke Skywalker joins forces with a Jedi Knight, a cocky pilot, a Wookiee and two droids to save the galaxy from the Empire's world-destroying battle station. |\nThere are a few important differences from a spreadsheet, but it's a good starting point if you're new to Relational databases.\nCreating Tables\nWhen creating a table, it's best practice to add columns at the same time.\n\nYou must define the \"data type\" of each column when it is created. You can add and remove columns at any time after creating a table.\nSupabase provides several options for creating tables. You can use the Dashboard or create them directly using SQL.\nWe provide a SQL editor within the Dashboard, or you can connect to your database\nand run the SQL queries yourself.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\n\n\n\nGo to the Table Editor page in the Dashboard.\nClick New Table and create a table with the name `todos`.\nClick Save.\nClick New Column and create a column with the name `task` and type `text`.\nClick Save.\n\n\n\n`sql\ncreate table movies (\n  id bigint generated by default as identity primary key,\n  name text,\n  description text\n);`\n\n\n\nWhen naming tables, use lowercase and underscores instead of spaces (e.g., `table_name`, not `Table Name`).\n\nColumns\nYou must define the \"data type\" when you create a column.\nData types\nEvery column is a predefined type. PostgreSQL provides many default types, and you can even design your own (or use extensions)\nif the default types don't fit your needs. You can use any data type that Postgres supports via the SQL editor. We only support a subset of these in the Table Editor in an effort to keep the experience simple for people with less experience with databases.\n\nShow/Hide default data types\n\n| `Name`                            | `Aliases`   | `Description`                                                    |\n| --------------------------------- | ----------- | ---------------------------------------------------------------- |\n| bigint                            | int8        | signed eight-byte integer                                        |\n| bigserial                         | serial8     | autoincrementing eight-byte integer                              |\n| bit                               |             | fixed-length bit string                                          |\n| bit varying                       | varbit      | variable-length bit string                                       |\n| boolean                           | bool        | logical Boolean (true/false)                                     |\n| box                               |             | rectangular box on a plane                                       |\n| bytea                             |             | binary data (\u201cbyte array\u201d)                                       |\n| character                         | char        | fixed-length character string                                    |\n| character varying                 | varchar     | variable-length character string                                 |\n| cidr                              |             | IPv4 or IPv6 network address                                     |\n| circle                            |             | circle on a plane                                                |\n| date                              |             | calendar date (year, month, day)                                 |\n| double precision                  | float8      | double precision floating-point number (8 bytes)                 |\n| inet                              |             | IPv4 or IPv6 host address                                        |\n| integer                           | int, int4   | signed four-byte integer                                         |\n| interval \\[ fields \\]             |             | time span                                                        |\n| json                              |             | textual JSON data                                                |\n| jsonb                             |             | binary JSON data, decomposed                                     |\n| line                              |             | infinite line on a plane                                         |\n| lseg                              |             | line segment on a plane                                          |\n| macaddr                           |             | MAC (Media Access Control) address                               |\n| macaddr8                          |             | MAC (Media Access Control) address (EUI-64 format)               |\n| money                             |             | currency amount                                                  |\n| numeric                           | decimal     | exact numeric of selectable precision                            |\n| path                              |             | geometric path on a plane                                        |\n| pg_lsn                            |             | PostgreSQL Log Sequence Number                                   |\n| pg_snapshot                       |             | user-level transaction ID snapshot                               |\n| point                             |             | geometric point on a plane                                       |\n| polygon                           |             | closed geometric path on a plane                                 |\n| real                              | float4      | single precision floating-point number (4 bytes)                 |\n| smallint                          | int2        | signed two-byte integer                                          |\n| smallserial                       | serial2     | autoincrementing two-byte integer                                |\n| serial                            | serial4     | autoincrementing four-byte integer                               |\n| text                              |             | variable-length character string                                 |\n| time \\[ without time zone \\]      |             | time of day (no time zone)                                       |\n| time with time zone               | timetz      | time of day, including time zone                                 |\n| timestamp \\[ without time zone \\] |             | date and time (no time zone)                                     |\n| timestamp with time zone          | timestamptz | date and time, including time zone                               |\n| tsquery                           |             | text search query                                                |\n| tsvector                          |             | text search document                                             |\n| txid_snapshot                     |             | user-level transaction ID snapshot (deprecated; see pg_snapshot) |\n| uuid                              |             | universally unique identifier                                    |\n| xml                               |             | XML data                                                         |\n\n\n\nYou can \"cast\" columns from one type to another, however there can be some incompatibilities between types.\nFor example, if you cast a `timestamp` to a `date`, you will lose all the time information that was previously saved.\nPrimary Keys\nA table can have a \"primary key\" - a unique identifier for every row of data. A few tips for Primary Keys:\n\nIt's recommended to create a Primary Key for every table in your database.\nYou can use any column as a primary key, as long as it is unique for every row.\nIt's common to use a `uuid` type or a numbered `identity` column as your primary key.\n\n`sql\ncreate table movies (\n  id bigint generated always as identity primary key\n);`\nIn the example above, we have:\n\ncreated a column called `id`\nassigned the data type `bigint`\ninstructed the database that this should be `generated always as identity`, which means that Postgres will automatically assign a unique number to this column.\nBecause it's unique, we can also use it as our `primary key`.\n\nWe could also use `generated by default as identity`, which would allow us to insert our own unique values.\n`sql\ncreate table movies (\n  id bigint generated by default as identity primary key\n);`\nLoading data\nThere are several ways to load data in Supabase. You can load data directly into the database or using the APIs.\nUse the \"Bulk Loading\" instructions if you are loading large data sets.\nBasic data loading\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\ninsert into movies\n  (name, description)\nvalues\n  ('The Empire Strikes Back', 'After the Rebels are brutally overpowered by the Empire on the ice planet Hoth, Luke Skywalker begins Jedi training with Yoda.'),\n  ('Return of the Jedi', 'After a daring mission to rescue Han Solo from Jabba the Hutt, the Rebels dispatch to Endor to destroy the second Death Star.');`\n\n\n`sql\nconst { data, error } = await supabase\n  .from('movies')\n  .insert([{\n    name: 'The Empire Strikes Back',\n    description: 'After the Rebels are brutally overpowered by the Empire on the ice planet Hoth, Luke Skywalker begins Jedi training with Yoda.'\n  }, {\n    name: 'Return of the Jedi',\n    description: 'After a daring mission to rescue Han Solo from Jabba the Hutt, the Rebels dispatch to Endor to destroy the second Death Star.'\n  }])`\n\n\n`sql\nawait supabase\n  .from('movies')\n  .insert([{\n    name: 'The Empire Strikes Back',\n    description: 'After the Rebels are brutally overpowered by the Empire on the ice planet Hoth, Luke Skywalker begins Jedi training with Yoda.'\n  }, {\n    name: 'Return of the Jedi',\n    description: 'After a daring mission to rescue Han Solo from Jabba the Hutt, the Rebels dispatch to Endor to destroy the second Death Star.'\n  }]);`\n\n\nBulk data loading\nWhen inserting large data sets it's best to use PostgreSQL's COPY command.\nThis loads data directly from a file into a table. There are several file formats available for copying data: text, csv, binary, JSON, etc.\nFor example, if you wanted to load a CSV file into your movies table:\n`csv title=./movies.csv\n\"The Empire Strikes Back\", \"After the Rebels are brutally overpowered by the Empire on the ice planet Hoth, Luke Skywalker begins Jedi training with Yoda.\"\n\"Return of the Jedi\", \"After a daring mission to rescue Han Solo from Jabba the Hutt, the Rebels dispatch to Endor to destroy the second Death Star.\"`\nYou would connect to your database directly and load the file with the COPY command:\n`bash\npsql -h DATABASE_URL -p 5432 -d postgres -U postgres \\\n  -c \"\\COPY movies FROM './movies.csv';\"`\nAdditionally use the `DELIMITER`, `HEADER` and `FORMAT` options as defined in the PostgreSQL COPY docs.\n`bash\npsql -h DATABASE_URL -p 5432 -d postgres -U postgres \\\n  -c \"\\COPY movies FROM './movies.csv' WITH DELIMITER ',' CSV HEADER\"`\nIf you receive an error `FATAL:  password authentication failed for user \"postgres\"`, reset your database password in the Database Settings and try again.\nJoining tables with Foreign Keys\nTables can be \"joined\" together using Foreign Keys.\n\nThis is where the \"Relational\" naming comes from, as data typically forms some sort of relationship.\nIn our \"movies\" example above, we might want to add a \"category\" for each movie (for example, \"Action\", or \"Documentary\").\nLet's create a new table called `categories` and \"link\" our `movies` table.\n```sql\ncreate table categories (\n  id bigint generated always as identity primary key,\n  name text -- category name\n);\nalter table movies\n  add column category_id bigint references categories;\n```\nYou can also create \"many-to-many\" relationships by creating a \"join\" table.\nFor example if you had the following situations:\n\nYou have a list of `movies`.\nA movie can have several `actors`.\nAn `actor` can perform in several movies.\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\n\n\n\n\n```sql\ncreate table movies (\n  id bigint generated by default as identity primary key,\n  name text,\n  description text\n);\ncreate table actors (\n  id bigint generated by default as identity primary key,\n  name text\n);\ncreate table performances (\n  id bigint generated by default as identity primary key,\n  movie_id bigint not null references movies,\n  actor_id bigint not null references actors\n);\n```\n\n\nSchemas\nTables belong to `schemas`. Schemas are a way of organizing your tables, often for security reasons.\n\nIf you don't explicitly pass a schema when creating a table, Postgres will assume that you want to create the table in the `public` schema.\nWe can create schemas for organizing tables. For example, we might want a private schema which is hidden from our API:\n`sql\ncreate schema private;`\nNow we can create tables inside the `private` schema:\n`sql\ncreate table salaries (\n  id bigint generated by default as identity primary key,\n  salary bigint not null,\n  actor_id bigint not null references public.actors\n);`\nViews\nA View is a convenient shortcut to a query. Creating a view does not involve new tables or data. When run, an underlying query is executed, returning its results to the user.\n\nBy default, PostgreSQL views bypass Row Level Security unless you change their owner (see https://github.com/supabase/supabase/discussions/901). PostgreSQL v15 (coming soon) will have a more intuitive control for this through security invoker views and the previous step won't be needed.\n\nSay we have the following tables from a database of a university:\n`students`\n| id  | name             | type          |\n| --- | ---------------- | ------------- |\n| 1   | Princess Leia    | undergraduate |\n| 2   | Yoda             | graduate      |\n| 3   | Anakin Skywalker | graduate      |\n`courses`\n| id  | title                    | code    |\n| --- | ------------------------ | ------- |\n| 1   | Introduction to Postgres | PG101   |\n| 2   | Authentication Theories  | AUTH205 |\n| 3   | Fundamentals of Supabase | SUP412  |\n`grades`\n| id  | student_id | course_id | result |\n| --- | ---------- | --------- | ------ |\n| 1   | 1          | 1         | B+     |\n| 2   | 1          | 3         | A+     |\n| 3   | 2          | 2         | A      |\n| 4   | 3          | 1         | A-     |\n| 5   | 3          | 2         | A      |\n| 6   | 3          | 3         | B-     |\nCreating a view consisting of all the three tables will look like this:\n```sql\ncreate view transcripts as\n    select\n        students.name,\n        students.type,\n        courses.title,\n        courses.code,\n        grades.result\n    from grades\n    left join students on grades.student_id = students.id\n    left join courses on grades.course_id = courses.id;\nalter view transcripts owner to authenticated;\n```\nOnce done, we can now access the underlying query with:\n`sql\nselect * from transcripts;`\nWhen to use views\nViews provide the several benefits:\n\nSimplicity\nConsistency\nLogical Organization\nSecurity\n\nSimplicity\nAs a query becomes complex it becomes a hassle to call it. Especially when we run it at regularly. In the example above, instead of repeatedly running:\n`sql\nselect\n    students.name,\n    students.type,\n    courses.title,\n    courses.code,\n    grades.result\nfrom grades\nleft join students on grades.student_id = students.id\nleft join courses on grades.course_id = courses.id;`\nWe can run this instead:\n`sql\nselect * from transcripts;`\nAdditionally, a view behaves like a typical table. We can safely use it in table `JOIN`s or even create new views using existing views.\nConsistency\nViews ensure that the likelihood of mistakes decreases when repeatedly executing a query. In our example above, we may decide that we want to exclude the course Introduction to Postgres. The query would become:\n`sql\nselect\n    students.name,\n    students.type,\n    courses.title,\n    courses.code,\n    grades.result\nfrom grades\n    left join students on grades.student_id = students.id\n    left join courses on grades.course_id = courses.id\nwhere courses.code != 'PG101';`\nWithout a view, we would need to go into every dependent query to add the new rule. This would increase in the likelihood of errors and inconsistencies, as well as introducing a lot of effort for a developer. With views, we can alter just the underlying query in the view transcripts. The change will be applied to all applications using this view.\nLogical Organization\nWith views, we can give our query a name. This is extremely useful for teams working with the same database. Instead of guessing what a query is supposed to do, a well-named view can easily explain it. For example, by looking at the name of the view transcripts, we can infer that the underlying query might involve the students, courses, and grades tables.\nSecurity\nViews can restrict the amount and type of data presented to a user. Instead of allowing a user direct access to a set of tables, we provide them a view instead. We can prevent them from reading sensitive columns by excluding them from the underlying query.\nMaterialized Views\nA materialized view is a form of view but it also stores the results to disk. In subsequent reads of a materialized view, the time taken to return its results would be much faster than a conventional view. This is because the data is readily available for a materialized view while the conventional view executes the underlying query each time it is called.\nUsing our example above, a materialized view can be created like this:\n`sql\ncreate materialized view transcripts as\n    select\n        students.name,\n        students.type,\n        courses.title,\n        courses.code,\n        grades.result\n    from grades\n    left join students on grades.student_id = students.id\n    left join courses on grades.course_id = courses.id;`\nReading from the materialized view is the same as a conventional view:\n`sql\nselect * from transcripts;`\nRefreshing materialized views\nUnfortunately, there is a trade-off - data in materialized views are not always up to date. We need to refresh it regularly to prevent the data from becoming too stale. To do so:\n`sql\nrefresh materialized view transcripts;`\nIt's up to you how regularly refresh your materialized views, and it's probably different for each view depending on its use-case.\nMaterialized views vs Conventional views\nMaterialized views are useful when execution times for queries or views are too slow. These could likely occur in views or queries involving multiple tables and billions of rows. When using such a view, however, there should be tolerance towards data being outdated. Some use-cases for materialized views are internal dashboards and analytics.\nCreating a materialized view is not a solution to inefficient queries. You should always seek to optimize a slow running query even if you are implementing a materialized view.\nResources\n\nOfficial Docs: Create table\nOfficial Docs: Create view\nPostgreSQL Tutorial: Create tables\nPostgreSQL Tutorial: Add column\nPostgreSQL Tutorial: Views\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Manage publications in the Dashboard",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/replication.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'replication',\n  title: 'Replication',\n  slug: 'replication',\n}\nReplication is a technique for copying the data from one database to another. Supabase uses replication functionality to provide a real-time API. Replication is useful for:\n\nSpreading out the \"load.\" For example, if your database has a lot of reads, you might want to split it between two databases.\nReducing latency. For example, you may want one database in London to serve your European customers, and one in New York to serve the US.\n\nReplication is done through publications, a method of choosing which changes to send to other systems (usually another Postgres database). Publications can be managed in the Dashboard or with SQL.\nManage publications in the Dashboard\n\nGo to the Database page in the Dashboard.\nClick on Replication in the sidebar.\nControl which database events are sent by toggling Insert, Update, and Delete.\nControl which tables broadcast changes by selecting Source and toggling each table.\n\n\n\n\nCreate a publication\nThis publication contains changes to all tables.\n`sql\ncreate publication publication_name\nfor all tables;`\nCreate a publication to listen to individual tables\n`sql\ncreate publication publication_name\nfor table table_one, table_two;`\nAdd tables to an existing publication\n`sql\nalter publication publication_name\nadd table table_name;`\nListen to `insert`\n`sql\ncreate publication publication_name\nfor all tables\nwith (publish = 'insert');`\nListen to `update`\n`sql\ncreate publication publication_name\nfor all tables\nwith (publish = 'update');`\nListen to `delete`\n`sql\ncreate publication publication_name\nfor all tables\nwith (publish = 'delete');`\nRemove a publication\n`sql\ndrop publication if exists publication_name;`\nRecreate a publication\nIf you're recreating a publication, it's best to do it in a transaction to ensure the operation succeeds.\n```sql\nbegin;\n  -- remove the realtime publication\n  drop publication if exists publication_name;\n-- re-create the publication but don't enable it for any tables\n  create publication publication_name;\ncommit;\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "timeouts.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/timeouts.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'timeouts',\n  title: 'Timeouts',\n  description: 'Timeouts and optimization',\n}\nBy default, Supabase limits the maximum statement execution time to 3 seconds for users accessing the API using the anon key, and 8 seconds for authenticated users. Additionally, all users are subject to a global limit of 2 minutes. This serves as a backstop against resource exhaustion due to either poorly written queries, or abusive usage.\nChanging the default timeout\nThe timeout values were picked as a reasonable default for the majority of use-cases, but can be modified using the alter role statement:\n`sql\nalter role authenticated set statement_timeout = '15s';`\nYou can also update the statement timeout for a session:\n`sql\nset statement_timeout to 60000; -- 1 minute in milliseconds`\nStatement Optimization\nAll Supabase projects come with the pg_stat_statements extension installed, which tracks planning and execution statistics for all statements executed against it. These statistics can be used in order to diagnose the performance of your project.\nThis data can further be used in conjunction with the explain functionality of Postgres to optimize your usage.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/plpgsql_check.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'plpgsql_check',\n  title: 'plpgsql_check: PL/pgSQL Linter',\n  description: 'Lint PL/pgSQL code',\n}\nplpgsql_check is a PostgreSQL extension that lints plpgsql for syntax, semantic and other related issues. The tool helps developers to identify and correct errors before executing the code. plpgsql_check is most useful for developers who are working with large or complex SQL codebases, as it can help identify and resolve issues early in the development cycle.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"plpgsql_check\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"plpgsql_check\" extension\ncreate extension plpgsql_check;\n-- Disable the \"plpgsql_check\" extension\ndrop extension if exists plpgsql_check;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\n\n\nAPI\n\nplpgsql_check_function( ... ): Scans a function for errors.\n\n`plpgsql_check_function` is highly customizable. For a complete list of available arguments see the docs\nUsage\nTo demonstrate `plpgsql_check` we can create a function with a known error. In this case we create a function `some_func`, that references a non-existent column `place.created_at`.\n{/ prettier-ignore /}\n```sql\ncreate table place(\n  x float,\n  y float\n);\ncreate or replace function public.some_func()\n  returns void\n  language plpgsql\nas $$\ndeclare\n  rec record;\nbegin\n  for rec in select * from place\n  loop\n    -- Bug: There is no column `created_at` on table `place`\n    raise notice '%', rec.created_at;\n  end loop;\nend;\n$$;\n```\nNote that executing the function would not catch the invalid reference error because the `loop` does not execute if no rows are present in the table.\n{/ prettier-ignore /}\n```sql\nselect public.some_func();\n  some_func\n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n(1 row)\n```\nNow we can use plpgsql_check's `plpgsql_check_function` function to identify the known error.\n{/ prettier-ignore /}\n```sql\nselect plpgsql_check_function('public.some_func()');\n\n\n```               plpgsql_check_function\n```\n\n\n\nerror:42703:8:RAISE:record \"rec\" has no field \"created_at\"\n Context: SQL expression \"rec.created_at\"\n```\nResources\n\nOfficial plpgsql_check documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Quick demo",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/http.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'http',\n  title: 'http: RESTful Client',\n  description: 'An HTTP Client for PostgreSQL Functions.',\n  video: 'https://www.youtube.com/v/rARgrELRCwY',\n}\nThe `http` extension allows you to call RESTful endpoints within Postgres.\nQuick demo\n\n\n\nOverview\nLet's cover some basic concepts:\n\nREST: stands for REpresentational State Transfer. It's simply a way to request data from external services.\nRESTful APIs are servers which accept HTTP \"calls\". The calls are typically:\n`GET` \u2212 Read only access to a resource.\n`POST` \u2212 Creates a new resource.\n`DELETE` \u2212 Removes a resource.\n`PUT` \u2212 Updates an existing resource or creates a new resource.\n\nYou can use the `http` extension to make these network requests from Postgres.\nUsage\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"http\" and enable the extension.\n\n\n\n```sql\n-- Example: enable the \"http\" extension\ncreate extension http with schema extensions;\n-- Example: disable the \"http\" extension\ndrop extension if exists http;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension, call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep the `public` schema clean.\n\n\nAvailable functions\nWhile the main usage is simply `http('http_request')`, there are 5 wrapper functions for specific functionality:\n\n`http_get()`\n`http_post()`\n`http_put()`\n`http_delete()`\n`http_head()`\n\nReturned values\nA successful call to a web URL from the `http` extension returns a record with the following fields:\n\n`status`: integer\n`content_type`: character varying\n`headers`: http_header[]\n`content`: character varying. Typically you would want to cast this to `jsonb` using the format `content::jsonb`\n\nExamples\nSimple `GET` example\n`sql\nselect\n  \"status\", \"content\"::jsonb\nfrom\n  http_get('https://jsonplaceholder.typicode.com/todos/1');`\nSimple `POST` example\n`sql\nselect\n  \"status\", \"content\"::jsonb\nfrom\n  http_post(\n    'https://jsonplaceholder.typicode.com/posts',\n    '{ \"title\": \"foo\", \"body\": \"bar\", \"userId\": 1 }',\n    'application/json'\n  );`\nResources\n\nOfficial http GitHub Repository\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgjwt.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgjwt',\n  title: 'pgjwt: JSON Web Tokens',\n  description: 'Encode and decode JWTs in PostgreSQL',\n}\nThe pgjwt (PostgreSQL JSON Web Token) extension allows you to create and parse JSON Web Tokens (JWTs) within a PostgreSQL database. JWTs are commonly used for authentication and authorization in web applications and services.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pgjwt\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pgjwt\" extension\ncreate extension pgjwt schema extensions;\n-- Disable the \"pgjwt\" extension\ndrop extension if exists pgjwt;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep the `public` schema clean.\n\n\nAPI\n\nsign(payload json, secret text, algorithm text default 'HSA256'): Signs a JWT containng payload with secret using algorithm.\nverify(token text, secret text, algorithm text default 'HSA256'): Decodes a JWT token that was signed with secret using algorithm.\n\nWhere:\n\n`payload` is an encrypted JWT represented as a string.\n`secret` is the private/secret passcode which is used to sign the JWT and verify its integrity.\n`algorithm` is the method used to sign the JWT using the secret.\n`token` is an encrypted JWT represented as a string.\n\nUsage\nOnce the extension is installed, you can use its functions to create and parse JWTs. Here's an example of how you can use the `sign` function to create a JWT:\n{/ prettier-ignore /}\n`sql\nselect\n  extensions.sign(\n    payload   := '{\"sub\":\"1234567890\",\"name\":\"John Doe\",\"iat\":1516239022}',\n    secret    := 'secret',\n    algorithm := 'HS256'\n  );`\nThe pgjwt_encode function returns a string that represents the JWT, which can then be safely transmitted between parties.\n{/ prettier-ignore /}\n```\n              sign\n\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpX\n VCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiw\n ibmFtZSI6IkpvaG4gRG9lIiwiaWF0Ijo\n xNTE2MjM5MDIyfQ.XbPfbIHMI6arZ3Y9\n 22BhjWgQzWXcXNrz0ogtVhfEd2o\n(1 row)\n```\nTo parse a JWT and extract its claims, you can use the `verify` function. Here's an example:\n{/ prettier-ignore /}\n`sql\nselect\n  extensions.verify(\n    token := 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoiRm9vIn0.Q8hKjuadCEhnCPuqIj9bfLhTh_9QSxshTRsA5Aq4IuM',\n    secret    := 'secret',\n    algorithm := 'HS256'\n  );`\nWhich returns the decoded contents and some associated metadata.\n{/ prettier-ignore /}\n`sql\n           header            |    payload     | valid\n-----------------------------+----------------+-------\n {\"alg\":\"HS256\",\"typ\":\"JWT\"} | {\"name\":\"Foo\"} | t\n(1 row)`\nResources\n\nOfficial pgjwt documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/postgis.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'postgis',\n  title: 'PostGIS: Geo queries',\n  description: 'Working with geo-spatial data in Postgres',\n}\nPostGIS is a Postgres extension that allows you to interact with Geo data within Postgres. You can sort your data by geographic location, get data within certain geographic boundaries, and do much more with it.\nOverview\nWhile you may be able to store simple lat/long geographic coordinates as a set of decimals, it does not scale very well when you try to query through a large data set. PostGIS comes with special data types that are efficient, and indexable for high scalability.\nThe additional data types that PostGIS provides include Point, Polygon, Linestring, and many more to represent different types of geographical data. In this guide, we will mainly focus on how to interact with `Point` type, which represents a single set of latitude and longitude. If you are interested in digging deeper, you can learn more about different data types on the data management section of PostGIS docs.\nEnable the extension\nYou can get started with PostGIS by enabling the PostGIS extension in your Supabase dashboard.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"postgis\" and enable the extension.\n\n\n\n```sql\n-- Example: enable the \"postgis\" extension\ncreate extension postgis with schema extensions;\n-- Example: disable the \"postgis\" extension\ndrop extension if exists postgis;\n```\n\n\nExamples\nNow that we are ready to get started with PostGIS, let\u2019s create a table and see how we can utilize PostGIS for some typical use cases. Let\u2019s imagine we are creating a simple restaurant-searching app.\nLet\u2019s create our table. Each row represents a restaurant with its location stored in `location` column as a `Point` type.\n`sql\ncreate table if not exists public.restaurants (\n    id int generated by default as identity primary key,\n    name text not null,\n    location geography(POINT) not null\n);`\nWe can then set a spatial index on the `location` column of this table.\n`sql\ncreate index restaurants_geo_index\n  on public.restaurants\n  using GIST (location);`\nInserting data\nYou can insert geographical data through SQL or through our API.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"data\"\n\n\n\nRestaurants\n| id  | name        | location                         |\n| --- | ----------- | -------------------------------- |\n| 1   | Supa Burger | lat: 40.807416, long: -73.946823 |\n| 2   | Supa Pizza  | lat: 40.807475, long: -73.94581  |\n| 3   | Supa Taco   | lat: 40.80629, long: -73.945826  |\n\n\n`sql\ninsert into public.restaurants\n(name, location)\nvalues\n  ('Supa Burger', st_point(-73.946823, 40.807416)),\n  ('Supa Pizza', st_point(-73.94581, 40.807475)),\n  ('Supa Taco', st_point(-73.945826, 40.80629));`\n\n\n`js\nconst { error } = await supabase.from('restaurants').insert([\n  {\n    name: 'Supa Burger',\n    location: 'POINT(-73.946823 40.807416)',\n  },\n  {\n    name: 'Supa Pizza',\n    location: 'POINT(-73.94581 40.807475)',\n  },\n  {\n    name: 'Supa Taco',\n    location: 'POINT(-73.945826 40.80629)',\n  },\n])`\n\n\n`dart\nawait supabase.from('restaurants').insert([\n  {\n    'name': 'Supa Burger',\n    'location': 'POINT(-73.946823 40.807416)',\n  },\n  {\n    'name': 'Supa Pizza',\n    'location': 'POINT(-73.94581 40.807475)',\n  },\n  {\n    'name': 'Supa Taco',\n    'location': 'POINT(-73.945826 40.80629)',\n  },\n]);`\n\n\nNotice the order in which you pass the latitude and longitude. Longitude comes first, and is because longitude represents the x-axis of the location. Another thing to watch for is when inserting data from the client library, there is no comma between the two values, just a single space.\nAt this point, if you go into your Supabase dashboard and look at the data, you will notice that the value of the `location` column looks something like this.\n`0101000020E6100000A4DFBE0E9C91614044FAEDEBC0494240`\nWe can query the `restaurants` table directly, but it will return the `location` column in the format you see above. We will create database functions so that we can use the st_astext() function to convert it back to a human-readable format like `POINT(-73.946713 40.807313)`.\nOrder by distance\nSorting datasets from closest to farthest, sometimes called nearest-neighbor sort, is a very common use case in Geo-queries. PostGIS can handle it very easily with the use of the <-> operator. `<->` operator returns the two-dimensional distance between two geometries and will utilize the spatial index when used within `order by` clause. You can create the following database function to sort the restaurants from closest to farthest by passing the current locations as parameters.\n`sql\ncreate or replace function nearby_restaurants(lat float, long float)\nreturns setof record\nlanguage sql\nas $$\n  select id, name, st_astext(location) as location, st_distance(location, st_point(long, lat)::geography) as dist_meters\n  from public.restaurants\n  order by location <-> st_point(long, lat)::geography;\n$$;`\nYou can call this function from your client using `rpc()` like this:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nconst { data, error } = await supabase.rpc('nearby_restaurants', {\n  lat: 40.807313,\n  long: -73.946713,\n})`\n\n\n`dart\nfinal data = await supabase.rpc('nearby_restaurants',params: {\n  'lat': 40.807313,\n  'long': -73.946713,\n});`\n\n\n`json\n[\n  {\n    \"id\": 1,\n    \"name\": \"Supa Burger\",\n    \"location\": \"POINT(-73.946823 40.807416)\",\n    \"dist_meters\": 14.73033739\n  },\n  {\n    \"id\": 2,\n    \"name\": \"Supa Pizza\",\n    \"location\": \"POINT(-73.94581 40.807475)\",\n    \"dist_meters\": 78.28980007\n  },\n  {\n    \"id\": 3,\n    \"name\": \"Supa Taco\",\n    \"location\": \"POINT(-73.945826 40.80629)\",\n    \"dist_meters\": 136.04329002\n  }\n]`\n\n\nFinding all data points within a bounding box\n\nWhen you are working on a map-based application where the user scrolls through your map, you might want to load the that lies within the bounding box of the map every time your users scroll. PostGIS can return the rows that are within the bounding box just by supplying the bottom left and the top right coordinates. Let\u2019s look at what the function would look like.\n`sql\ncreate or replace function restaurants_in_view(min_lat float, min_long float, max_lat float, max_long float)\nreturns setof record\nlanguage sql\nas $$\n    select id, name, st_astext(location) as location\n    from public.restaurants\n    where location && ST_SetSRID(ST_MakeBox2D(ST_Point(min_long, min_lat), ST_Point(max_long, max_lat)),4326)\n$$;`\n&& operator used in the `where` statement here returns a boolean of whether the bounding box of the two geometries intersect or not. We basically are creating a bounding box from the two points and finding those points that fall under the bounding box. We are also utilizing a few different PostGIS functions here.\n\nST_MakeBox2D: Creates a 2-dimensional box from two points.\nST_SetSRID: Sets the SRID, which is an identifier of what coordinate system to use, for the geometry. 4326 the standard longitude and latitude coordinate systems.\n\nYou can call this function from your client using `rpc()` like this:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nconst { data, error } = await supabase.rpc('restaurants_in_view', {\n  min_lat: 40.807,\n  min_long: -73.946,\n  max_lat: 40.808,\n  max_long: -73.945,\n})`\n\n\n`dart\nfinal data = await supabase.rpc('restaurants_in_view', params: {\n  'min_lat': 40.807,\n  'min_long': -73.946,\n  'max_lat': 40.808,\n  'max_long': -73.945,\n});`\n\n\n`json\n[\n  {\n    \"id\": 2,\n    \"name\": \"Supa Pizza\",\n    \"location\": \"POINT(-73.94581 40.807475)\"\n  }\n]`\n\n\nResources\n\nOfficial PostGIS documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/plv8.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'plv8',\n  title: 'plv8: JavaScript Language',\n  description: 'JavaScript language for PostgreSQL.',\n}\nThe `plv8` extension allows you use JavaScript within Postgres.\nOverview\nWhile Postgres natively runs SQL, it can also run other \"procedural languages\".\n`plv8` allows you to run JavaScript code - specifically any code that runs on the V8 JavaScript engine.\nIt can be used for database functions, triggers, queries and more.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"plv8\" and enable the extension.\n\n\n\n```sql\n-- Example: enable the \"plv8\" extension\ncreate extension plv8;\n-- Example: disable the \"plv8\" extension\ndrop extension if exists plv8;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension, call `drop extension`.\nProcedural languages are automatically installed within `pg_catalog`, so you don't need to specify a schema.\n\n\nCreate `plv8` functions\nFunctions written in `plv8` are written just like any other PostgreSQL functions, only\nwith the `language` identifier set to `plv8`.\n`sql\ncreate or replace function function_name()\nreturns void as $$\n    // V8 JavaScript\n    // code\n    // here\n$$ language plv8;`\nYou can call `plv8` functions like any other Postgres function:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"sql\"\n\n\n\n`sql\nselect function_name();`\n\n\n`js\nconst { data, error } = supabase.rpc('function_name')`\n\n\nExamples\nScalar functions\nA scalar function is anything that takes in some user input and returns a single result.\n```sql\ncreate or replace function hello_world(name text)\nreturns text as $$\n\n\n```let output = `Hello, ${name}!`;\nreturn output;\n```\n\n\n$$ language plv8;\n```\nExecuting SQL\nYou can execute SQL within `plv8` code using the plv8.execute function.\n```sql\ncreate or replace function update_user(id bigint, first_name text)\nreturns smallint as $$\n\n\n```var num_affected = plv8.execute(\n    'update profiles set first_name = $1 where id = $2',\n    [first_name, id]\n);\n\nreturn num_affected;\n```\n\n\n$$ language plv8;\n```\nSet-returning functions\nA set-returning function is anything that returns a full set of results - for example, rows in a table.\n```sql\ncreate or replace function get_messages()\nreturns setof messages as $$\n\n\n```var json_result = plv8.execute(\n    'select * from messages'\n);\n\nreturn json_result;\n```\n\n\n$$ language plv8;\nselect * from get_messages();\n```\nResources\n\nOfficial plv8 documentation\nplv8 GitHub Repository\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the Extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pg_hashids.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pg_hashids',\n  title: 'pg_hashids: Short UIDs',\n  description: 'Generate Short UIDs from Numbers',\n}\npg_hashids provides a secure way to generate short, unique, non-sequential ids from numbers. The hashes are intended to be small, easy-to-remember identifiers that can be used to obfuscate data (optionally) with a password, alphabet, and salt. For example, you may wish to hide data like user IDs, order numbers, or tracking codes in favor of `pg_hashid`'s unique identifers.\nEnable the Extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pg_hashids\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pg_hashids\" extension\ncreate extension pg_hashids with schema extensions;\n-- Disable the \"pg_hashids\" extension\ndrop extension if exists pg_hashids;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep your `public` schema clean.\n\n\nUsage\nSuppose we have a table that stores order information, and we want to give customers a unique identifer without exposing the sequential `id` column. To do this, we can use `pg_hashid`'s `id_encode` function.\n```sql\ncreate table orders (\n  id serial primary key,\n  description text,\n  price_cents bigint\n);\ninsert into orders (description, price_cents)\nvalues ('a book', 9095);\nselect\n  id,\n  id_encode(id) as short_id,\n  description,\n  price_cents\nfrom\n  orders;\nid | short_id | description | price_cents\n----+----------+-------------+-------------\n  1 | jR       | a book      |        9095\n(1 row)\n```\nTo reverse the `short_id` back into an `id`, there is an equivalent function named `id_decode`.\nResources\n\nOfficial pg_hashids documention\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgnet.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgnet',\n  title: 'pg_net: Async Networking',\n  description: 'pg_net: an async networking extension for PostgreSQL.',\n}\n\nThe pg_net API is in alpha. Functions signatures may change.\n\npg_net is a PostgreSQL extension exposing a SQL interface for async networking with a focus on scalability and UX.\nIt differs from the `http` extension in that it is asynchronous by default. This makes it useful in blocking functions (like triggers).\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pg_net\" and enable the extension.\n\n\n\n```sql\n-- Example: enable the \"pg_net\" extension.\ncreate extension pg_net;\n-- Note: The extension creates its own schema/namespace named \"net\" to avoid naming conflicts.\n-- Example: disable the \"pg_net\" extension\ndrop extension if exists pg_net;\ndrop schema net;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension, call `drop extension`.\nProcedural languages are automatically installed within `pg_catalog`, so you don't need to specify a schema.\n\n\n`http_get`\nCreates an HTTP GET request returning the request's ID. HTTP requests are not started until the transaction is committed.\nSignature [#get-signature]\n\nThis is a Postgres SECURITY DEFINER function.\n\n```sql\nnet.http_get(\n    -- url for the request\n    url text,\n    -- key/value pairs to be url encoded and appended to the`url`\n    params jsonb default '{}'::jsonb,\n    -- key/values to be included in request headers\n    headers jsonb default '{}'::jsonb,\n    -- WARNING: this is currently ignored, so there is no timeout\n    -- the maximum number of milliseconds the request may take before being cancelled\n    timeout_milliseconds int default 1000\n)\n    -- request_id reference\n    returns bigint\n\n\n```strict\nvolatile\nparallel safe\nlanguage plpgsql\n```\n\n\n```\nUsage [#get-usage]\n```sql\nselect net.http_get('https://news.ycombinator.com') as request_id;\nrequest_id\n\n\n\n```     1\n```\n\n\n(1 row)\n```\nAfter triggering `http_get`, use http_get_result to get the result of the request.\n`http_post`\nCreates an HTTP POST request with a JSON body, returning the request's ID. HTTP requests are not started until the transaction is committed.\nThe body's character set encoding matches the database's `server_encoding` setting.\nSignature [#post-signature]\n\nThis is a Postgres SECURITY DEFINER function\n\n```sql\nnet.http_post(\n    -- url for the request\n    url text,\n    -- body of the POST request\n    body jsonb default '{}'::jsonb,\n    -- key/value pairs to be url encoded and appended to the`url`\n    params jsonb default '{}'::jsonb,\n    -- key/values to be included in request headers\n    headers jsonb default '{\"Content-Type\": \"application/json\"}'::jsonb,\n    -- WARNING: this is currently ignored, so there is no timeout\n    -- the maximum number of milliseconds the request may take before being cancelled\n    timeout_milliseconds int default 1000\n)\n    -- request_id reference\n    returns bigint\n\n\n```volatile\nparallel safe\nlanguage plpgsql\n```\n\n\n```\nUsage [#post-usage]\n```sql\nselect\n    net.http_post(\n        url:='https://httpbin.org/post',\n        body:='{\"hello\": \"world\"}'::jsonb\n    ) as request_id;\nrequest_id\n\n\n\n```     1\n```\n\n\n(1 row)\n```\nAfter triggering `http_post`, use http_get_result to get the result of the request.\nExamples\nInvoke a Supabase Edge Function\nMake a POST request to a Supabase Edge Function with auth header and JSON body payload:\n`sql\nselect\n    net.http_post(\n        url:='https://project-ref.functions.supabase.co/function-name',\n        headers:='{\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer YOUR_ANON_KEY\"}'::jsonb,\n        body:='{\"name\": \"pg_net\"}'::jsonb\n    ) as request_id;`\nResources\n\nSource code: github.com/supabase/pg_net\nOfficial Docs: supabase.github.io/pg_net\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pg_stat_monitor.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pg_stat_monitor',\n  title: 'pg_stat_monitor: Query Performance Monitoring',\n  description: 'Query performance monitoring for PostgreSQL',\n}\npg_stat_monitor is query performance monitoring tool that provides query execution statistics in a SQL view named `pg_stat_monitor`. It tracks a superset of statistics available in pg_stat_statements. Some of the most useful features are:\n\nTime Interval Grouping: configurable time buckets to track query usage over time\nCapture Parameters: optionally track parameters passed into queries instead of generic placeholders e.g. `$1`\nQuery Plan: store query plans used for execution\n\nFor more information on query optimization, check out the query performance guide.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pg_stat_monitor\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pg_stat_monitor\" extension\ncreate extension pg_stat_monitor with schema extensions;\n-- Disable the \"pg_stat_monitor\" extension\ndrop extension if exists pg_stat_monitor;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep the `public` schema clean.\n\n\nViews\n{/ prettier-ignore /}\n`sql\nselect * from extensions.pg_stat_monitor;`\nThe following table shows a subset of available columns:\n| Column Type                           | Description                                                                                                                  |\n| ------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| bucket bigint                         | Data collection unit. The number shows what bucket in a chain a record belongs to                                            |\n| bucket_start_time timestampz          | The start time of the bucket                                                                                                 |\n| userid oid (references pg_authid.oid) | OID of user who executed the statement                                                                                       |\n| dbid oid (references pg_database.oid) | OID of database in which the statement was executed                                                                          |\n| toplevel bool                         | True if the query was executed as a top-level statement (always true if pg_stat_statements.track is set to top)              |\n| client_ip inet                        | The IP address of a client that ran the query                                                                                |\n| queryid bigint                        | Hash code to identify identical normalized queries.                                                                          |\n| planid text                           | An internally generated ID of a query plan                                                                                   |\n| query_plan text                       | The sequence of steps used to execute a query. This parameter is only available when pgsm_enable_query_plan is enabled       |\n| query text                            | Text of a representative statement                                                                                           |\n| plans bigint                          | Number of times the statement was planned (if pg_stat_statements.track_planning is enabled, otherwise zero)                  |\n| total_plan_time double precision      | Total time spent planning the statement, in milliseconds (if pg_stat_statements.track_planning is enabled, otherwise zero)   |\n| min_plan_time double precision        | Minimum time spent planning the statement, in milliseconds (if pg_stat_statements.track_planning is enabled, otherwise zero) |\nA full list of statistics is available in the pg_stat_monitor docs.\nFunctions\n\npg_stat_monitor_reset(): Resets the statistics tracked by the `pg_stat_monitor` view and deletes all previous data.\npg_stat_monitor_version(): Displays the version of the `pg_stat_monitor` extension.\n\nResources\n\nOfficial pg_stat_monitor documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pg_plan_filter.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pg_plan_filter',\n  title: 'pg_plan_filter: Restrict Total Cost',\n  description: 'Block queries over a total cost limit',\n}\npg_plan_filter is PostgreSQL extension to block execution of statements where query planner's estimate of the total cost exceeds a threshold. This is intended to give database administrators a way to restrict the contribution an individual query has on database load.\nEnable the extension\n`pg_plan_filter` can be enabled on a per connection basis:\n{/ prettier-ignore /}\n`sql\nload 'plan_filter';`\nor for all connections:\n{/ prettier-ignore /}\n`sql\nalter database some_db set session_preload_libraries = 'plan_filter';`\nAPI\n`plan_filter.statement_cost_limit`: restricts the maximum total cost for executed statements\n`plan_filter.limit_select_only`: restricts to `select` statements\nNote that `limit_select_only = true` is not the same as read-only because `select` statements may modfiy data e.g. through a function call.\nExample\nTo demonstrate total cost filtering, we'll compare how `plan_filter.statement_cost_limit` treats queries that are under and over its cost limit. First, we set up a table with some data:\n{/ prettier-ignore /}\n```sql\ncreate table book(\n  id int primary key\n);\n-- CREATE TABLE\ninsert into book(id) select * from generate_series(1, 10000);\n-- INSERT 0 10000\n```\nNext, we can review the explain plans for a single record select, and a whole table select.\n{/ prettier-ignore /}\n```sql\nexplain select * from book where id =1;\n                                QUERY PLAN\n\nIndex Only Scan using book_pkey on book  (cost=0.28..2.49 rows=1 width=4)\n   Index Cond: (id = 1)\n(2 rows)\nexplain select * from book;\n                       QUERY PLAN\n\nSeq Scan on book  (cost=0.00..135.00 rows=10000 width=4)\n(1 row)\n```\nNow we can choose a `statement_cost_filter` value between the total cost for the single select (2.49) and the whole table select (135.0) so one statement will succeed and one will fail.\n{/ prettier-ignore /}\n```sql\nload 'plan_filter';\nset plan_filter.statement_cost_limit = 50; -- between 2.49 and 135.0\nselect * from book where id = 1;\n id\n\n1\n(1 row)\n-- SUCCESS\n```\n{/ prettier-ignore /}\n```sql\nselect * from book;\nERROR:  plan cost limit exceeded\nHINT:  The plan for your query shows that it would probably have an excessive run time. This may be due to a logic error in the SQL, or it maybe just a very costly query. Rewrite your query or increase the configuration parameter \"plan_filter.statement_cost_limit\".\n-- FAILURE\n```\nResources\n\nOfficial pg_plan_filter documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pg_stat_statements.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pg_stat_statements',\n  title: 'pg_stat_statements: Query Performance Monitoring',\n  description:\n    'Track planning and execution statistics of all SQL statements executed on the database.',\n}\n`pg_stat_statements` is a database extension that exposes a view, of the same name, to track statistics about SQL statements executed on the database. The following table shows some of the available statistics and metadata:\n| Column Type                           | Description                                                                                                                  |\n| ------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |\n| userid oid (references pg_authid.oid) | OID of user who executed the statement                                                                                       |\n| dbid oid (references pg_database.oid) | OID of database in which the statement was executed                                                                          |\n| toplevel bool                         | True if the query was executed as a top-level statement (always true if pg_stat_statements.track is set to top)              |\n| queryid bigint                        | Hash code to identify identical normalized queries.                                                                          |\n| query text                            | Text of a representative statement                                                                                           |\n| plans bigint                          | Number of times the statement was planned (if pg_stat_statements.track_planning is enabled, otherwise zero)                  |\n| total_plan_time double precision      | Total time spent planning the statement, in milliseconds (if pg_stat_statements.track_planning is enabled, otherwise zero)   |\n| min_plan_time double precision        | Minimum time spent planning the statement, in milliseconds (if pg_stat_statements.track_planning is enabled, otherwise zero) |\nA full list of statistics is available in the pg_stat_statements docs.\nFor more information on query optimization, check out the query performance guide.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pg_stat_statements\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pg_stat_statements\" extension\ncreate extension pg_stat_statements with schema extensions;\n-- Disable the \"pg_stat_statements\" extension\ndrop extension if exists pg_stat_statements;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep the `public` schema clean.\n\n\nInspecting activity\nA common use for `pg_stat_statements` is to track down expensive or slow queries. The `pg_stat_statements` view contains a row for each executed query with statistics inlined. For example, you can leverage the statistics to identify frequently executed and slow queries against a given table.\n{/ prettier-ignore /}\n`sql\nselect\n    calls,\n    mean_exec_time,\n    max_exec_time,\n    total_exec_time,\n    stddev_exec_time,\n    query,\nfrom\n    pg_stat_statements\nwhere\n    calls > 50                   -- at least 50 calls\n    and mean_exec_time > 2.0     -- averaging at least 2ms/call\n    and total_exec_time > 60000  -- at least one minute total server time spent\n    and query ilike '%user_in_organization%' -- filter to queries that touch the user_in_organization table\norder by\n    calls desc`\nFrom the results, we can make an informed decision about which queries to optimize or index.\nResources\n\nOfficial pg_stat_statements documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pg_graphql.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pg_graphql',\n  title: 'pg_graphql: GraphQL for PostgreSQL',\n  description: 'A GraphQL Interface for PostgreSQL',\n}\npg_graphql is PostgreSQL extension for interacting with the database using GraphQL instead of SQL.\nThe extension reflects a GraphQL schema from the existing SQL schema and exposes it through a SQL function, `graphql.resolve(...)`. This enables any programming language that can connect to PostgreSQL to query the database via GraphQL with no additional servers, processes, or libraries.\nThe `pg_graphql` resolve method is designed to interop with PostgREST, the tool that underpins the Supabase API, such that the `graphql.resolve` function can be called via RPC to safely and performantly expose the GraphQL API over HTTP/S.\nFor more information about how the SQL schema is reflected into a GraphQL schema, see the pg_graphql API docs.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pg_graphql\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pg_graphql\" extension\ncreate extension pg_graphql;\n-- Disable the \"pg_graphql\" extension\ndrop extension if exists pg_graphql;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\n\n\nUsage\nGiven a table\n{/ prettier-ignore /}\n```sql\ncreate table \"Blog\"(\n  id serial primary key,\n  name varchar(255) not null,\n  description varchar(255),\n);\ninsert into \"Blog\"(name)\nvalues ('My Blog');\n```\nThe reflected GraphQL schema can be queries immediately as\n{/ prettier-ignore /}\n`sql\nselect\n  graphql.resolve($$\n    {\n      blogCollection(first: 1) {\n        edges {\n          node {\n            id,\n            name\n          }\n        }\n      }\n    }\n  $$);`\nreturning the JSON\n{/ prettier-ignore /}\n`json\n{\n  \"data\": {\n    \"blogCollection\": {\n      \"edges\": [\n        {\n          \"node\": {\n            \"id\": 1\n            \"name\": \"My Blog\"\n          }\n        }\n      ]\n    }\n  }\n}`\nNote that `pg_graphql` fully supports schema introspection so you can connect any GraphQL IDE or schema inspection tool to see the full set of fields and arguments available in the API.\nAPI\n\ngraphql.resolve: A SQL function for executing GraphQL queries.\n\nResources\n\nOfficial pg_graphql documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgaudit.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgaudit',\n  title: 'PGAudit: Postgres Auditing',\n  description: 'Session and object auditing via PostgreSQL standard logging',\n}\nPGAudit is a PostgreSQL extension for logging session and object auditing over the standard PostgreSQL logging utility.\nPGAudit grants fine grain control over which statements and objects are emitted to logs.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pgaudit\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pgaudit\" extension\ncreate extension pgaudit;\n-- Disable the \"pgaudit\" extension\ndrop extension if exists pgaudit;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\n\n\nSettings\nThe `pgaudit.log` setting controls which statements to log. Available values include:\n\nread: `SELECT` and `COPY` when the source is a relation or a query.\nwrite: `INSERT`, `UPDATE`, `DELETE`, `TRUNCATE`, and `COPY` when the destination is a relation.\nfunction: Function calls and `DO` blocks.\nrole: Statements related to roles and privileges: `GRANT`, `REVOKE`, `CREATE/ALTER/DROP ROLE`.\nddl: All `DDL` that is not included in the `ROLE` class.\nmisc: Miscellaneous commands, e.g. `DISCARD`, `FETCH`, `CHECKPOINT`, `VACUUM`, `SET`.\n\nmisc_set: Miscellaneous `SET` commands, e.g. `SET ROLE`.\n\n\nall: Include all of the above.\n\n\nFor a full list of available settings see settings docs. Be aware that the `all` setting will generate a very large volume of logs.\nExample\nGiven a pgaudit setting\n{/ prettier-ignore /}\n`sql\nset pgaudit.log = 'read, ddl';`\nThe following create table, insert and select statements\n{/ prettier-ignore /}\n```sql\ncreate table account (\n  id int primary key,\n  name text,\n  description text\n);\ninsert into account (id, name, description)\nvalues (1, 'Foo Barsworth', 'Customer account');\nselect * from account;\n```\nResults in the log output\n`text\nAUDIT: SESSION,1,1,DDL,CREATE TABLE,TABLE,public.account,create table account(\n  id int,\n  name text,\n  description text\n);,<not logged>\nAUDIT: SESSION,2,1,READ,SELECT,,,select * from account,,<not logged>`\nNote that the insert statement is not logged because we did not include the `write` option for `pgaudit.log`.\nResources\n\nOfficial PGAudit documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgsodium.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgsodium',\n  title: 'pgsodium: Encryption Features',\n  description: 'Encryption library for PostgreSQL',\n}\npgsodium is a PostgreSQL extension which provides SQL access to libsodium's high-level cryptographic algorithms. It also enables some Postgres specific features including:\n\nServer Key Management\nTransparent Column Encryption\n\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pgsodium\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pgsodium\" extension\ncreate extension pgsodium;\n-- Disable the \"pgsodium\" extension\ndrop extension if exists pgsodium;\n```\n\n\nResources\n\nOfficial pgsodium documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgtap.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgtap',\n  title: 'pgTAP: Unit Testing',\n  description: 'Unit testing in PostgreSQL.',\n}\n`pgTAP` is a unit testing extension for PostgreSQL.\nOverview\nLet's cover some basic concepts:\n\nUnit tests: allow you to test small parts of a system (like a database table!).\nTAP: stands for Test Anything Protocol. It is an framework which aims to simplify the error reporting during testing.\n\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pgtap\" and enable the extension.\n\n\n\n```sql\n-- Enable the \"pgtap\" extension\ncreate extension pgtap with schema extensions;\n-- Disable the \"pgtap\" extension\ndrop extension if exists pgtap;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep the `public` schema clean.\n\n\nTesting tables\n```sql\nbegin;\nselect plan( 1 );\nselect has_table( 'profiles' );\nselect * from finish();\nrollback;\n```\nAPI:\n\nhas_table(): Tests whether or not a table exists in the database\nhas_index(): Checks for the existence of a named index associated with the named table.\nhas_relation(): Tests whether or not a relation exists in the database.\n\nTesting columns\n```sql\nbegin;\nselect plan( 2 );\nselect has_column( 'profiles', 'id' );  # test that the \"id\" column exists in the \"profiles\" table\nselect col_is_pk( 'profiles', 'id' );   # test that the \"id\" column is a primary key\nselect * from finish();\nrollback;\n```\nAPI:\n\nhas_column(): Tests whether or not a column exists in a given table, view, materialized view or composite type.\ncol_is_pk(): Tests whether the specified column or columns in a table is/are the primary key for that table.\n\nTesting RLS Policies\n```sql\nbegin;\nselect plan( 1 );\nselect policies_are(\n  'public',\n  'profiles',\n  ARRAY [\n    'Profiles are public', # Test that there is a policy called  \"Profiles are public\" on the \"profiles\" table.\n    'Profiles can only be updated by the owner'  # Test that there is a policy called  \"Profiles can only be updated by the owner\" on the \"profiles\" table.\n  ]\n);\nselect * from finish();\nrollback;\n```\nAPI:\n\npolicies_are(): Tests that all of the policies on the named table are only the policies that should be on that table.\npolicy_roles_are(): Tests whether the roles to which policy applies are only the roles that should be on that policy.\npolicy_cmd_is(): Tests whether the command to which policy applies is same as command that is given in function arguments.\n\nYou can also use the `results_eq()` method to test that a Policy returns the correct data:\n```sql\nbegin;\nselect plan( 1 );\nselect results_eq(\n    'select * from profiles()',\n    $$VALUES ( 1, 'Anna'), (2, 'Bruce'), (3, 'Caryn')$$\n    'profiles() should return all users'\n);\nselect * from finish();\nrollback;\n```\nAPI:\n\nresults_eq()\nresults_ne()\n\nTesting Functions\n```sql\nbegin;\nselect plan( 1 );\nselect function_returns( 'hello_world', 'text' );                   # test if the function \"hello_world\" returns text\nselect function_returns( 'is_even', ARRAY['integer'], 'boolean' );  # test if the function \"is_even\" returns a boolean\nselect results_eq('select * from hello_world()', 'hello');          # test if the function \"hello_world\" returns \"hello\"\nselect * from finish();\nrollback;\n```\nAPI:\n\nfunction_returns(): Tests that a particular function returns a particular data type\nis_definer(): Tests that a function is a security definer (i.e., a \u201csetuid\u201d function).\n\nResources\n\nOfficial pgTAP documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/hypopg.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'hypopg',\n  title: 'HypoPG: Hypothetical indexes',\n  description: 'Quickly check if an index can be used without creating it.',\n}\n`HypoPG` is PostgreSQL extension for creating hypothetical/virtual indexes. HypoPG allows users to rapidly create hypothetical/virtual indexes that have no resource cost (CPU, disk, memory) that are visible to the PostgreSQL query planner.\nThe motivation for HypoPG is to allow users to quickly search for an index to improve a slow query without consuming server resources or waiting for them to build.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"hypopg\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"hypopg\" extension\ncreate extension hypopg with schema extensions;\n-- Disable the \"hypopg\" extension\ndrop extension if exists hypopg;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep the `public` schema clean.\n\n\nSpeeding up a query\nGiven the following table and a simple query to select from the table by `id`:\n{/ prettier-ignore /}\n```sql\ncreate table account (\n  id int,\n  address text\n);\ninsert into account(id, address)\nselect\n  id,\n  id || ' main street'\nfrom\n  generate_series(1, 10000) id;\n```\nWe can generate an explain plan for a description of how the PostgreSQL query planner\nintends to execute the query.\n{/ prettier-ignore /}\n```sql\nexplain select * from account where id=1;\n\n\n```                  QUERY PLAN\n```\n\n\n\nSeq Scan on account  (cost=0.00..180.00 rows=1 width=13)\n   Filter: (id = 1)\n(2 rows)\n```\nUsing HypoPG, we can create a hypothetical index on the `account(id)` column to check if it would be useful to the query planner and then re-run the explain plan.\nNote that the virtual indexes created by HypoPG are only visible in the PostgreSQL connection that they were created in. Supabase connects to PostgreSQL through a connection pooler so the `hypopg_create_index` statement and the `explain` statement should be executed in a single query.\n{/ prettier-ignore /}\n```sql\nselect * from hypopg_create_index('create index on account(id)');\nexplain select * from account where id=1;\n\n\n```                                 QUERY PLAN\n```\n\n\n\nIndex Scan using <13504>btree_account_id on hypo  (cost=0.29..8.30 rows=1 width=13)\n   Index Cond: (id = 1)\n(2 rows)\n```\nThe query plan has changed from a `Seq Scan` to an `Index Scan` using the newly created virtual index, so we may choose to create a real version of the index to improve performance on the target query:\n{/ prettier-ignore /}\n`sql\ncreate index on account(id);`\nFunctions\n\nhypo_create_index(text): A function to create a hypothetical index.\nhypopg_list_indexes: A View that lists all hypothetical indexes that have been created.\nhypopg(): A function that lists all hypothetical indexes that have been created with the same format as pg_index.\nhypopg_get_index_def(oid): A function to display the `create index` statement that would create the index.\nhypopg_get_relation_size(oid): A function to estimate how large a hypothetical index would be.\nhypopg_drop_index(oid): A function to remove a given hypothetical index by oid.\nhypopg_reset(): A function to remove all hypothetical indexes.\n\nResources\n\nOfficial HypoPG documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pg-safeupdate.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pg-safeupdate',\n  title: 'pg-safeupdate: Required Where Clauses',\n  description: 'Requires a where clause for update and delete',\n}\npg-safeupdate is a PostgreSQL extension designed to prevent users from accidentally updating or deleting too many records in a single statement by requiring a \"where\" clause in all update and delete statements.\nThe `pg-safeupdate` extension is a useful tool for protecting data integrity and preventing accidental data loss. Without it, a user could accidentally execute an update or delete statement that affects all records in a table. With `pg-safeupdate`, users are required to be more deliberate in their update and delete statements, which reduces the risk of significant error.\nEnable the extension\n`pg-safeupdate` can be enabled on a per connection basis:\n{/ prettier-ignore /}\n`sql\nload 'safeupdate';`\nor for all connections:\n{/ prettier-ignore /}\n`sql\nalter database some_db set session_preload_libraries = 'safeupdate';`\nUsage\nLet's take a look at an example to see how pg-safeupdate works. Suppose we have a table called `employees` with the following columns: `id`, `name`, `department`, and `date_of_birth`. We want to update the `date_of_birth` for a specific employee with the `id` of 12345. Here is what the query would look like if we forgot to add a \"where\" clause:\n{/ prettier-ignore /}\n```sql\nload 'safeupdate';\nupdate employees set date_of_birth = '1987-01-28';\n```\nThis query updates the `date_of_birth` for all employees to 1987-01-28, which is not what we intended. With `pg-safeupdate` enabled, we receive an error message prompting us to add a \"where\" clause to the query:\n{/ prettier-ignore /}\n`sql\nERROR: UPDATE requires a WHERE clause`\nWe would then update our query to include a \"where\" clause specifying the employee with the `id` of 12345:\n{/ prettier-ignore /}\n`sql\nupdate employees set date_of_birth = '1987-01-28' where id = 12345;`\nResources\n\nOfficial pg-safeupdate documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgroonga.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgroonga',\n  title: 'PGroonga: Multilingual Full Text Search',\n  description: 'Full Text Search for multiple languages in PostgreSQL',\n}\n`PGroonga` is a PostgreSQL extension adding a full text search indexing method based on Groonga. While native PostgreSQL supports full text indexing, it is limited to alphabet and digit based languages. `PGroonga` offers a wider range of character support making it viable for a superset of languages supported by PostgreSQL including Japanese, Chinese, etc.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pgroonga\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pgroonga\" extension\ncreate extension pgroonga with schema extensions;\n-- Disable the \"pgroonga\" extension\ndrop extension if exists pgroonga;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\n\n\nCreating a full text search index\nGiven a table with a `text` column:\n{/ prettier-ignore /}\n`sql\ncreate table memos (\n  id serial primary key,\n  content text\n);`\nWe can index the column for full text search with a `pgroonga` index:\n{/ prettier-ignore /}\n`sql\ncreate index ix_memos_content ON memos USING pgroonga(content);`\nTo test the full text index, we'll add some data.\n{/ prettier-ignore /}\n`sql\ninsert into memos(content)\nvalues\n  ('PostgreSQL is a relational database management system.'),\n  ('Groonga is a fast full text search engine that supports all languages.'),\n  ('PGroonga is a PostgreSQL extension that uses Groonga as index.'),\n  ('There is groonga command.');`\nThe PostgreSQL query planner is smart enough to know that, for extremely small tables, it's faster to scan the whole table rather than loading an index. To force the index to be used, we can disable sequential scans:\n{/ prettier-ignore /}\n`sql\n-- For testing only. Don't do this in production\nset enable_seqscan = off;`\nNow if we run an explain plan on a query filtering on `memos.content`:\n{/ prettier-ignore /}\n```sql\nexplain select * from memos where content like '%engine%';\n\n\n```                           QUERY PLAN\n```\n\n\n\nIndex Scan using ix_memos_content on memos  (cost=0.00..1.11 rows=1 width=36)\n  Index Cond: (content ~~ '%engine%'::text)\n(2 rows)\n```\nThe pgroonga index is used to retrive the result set:\n`markdown\n| id  | content                                                                  |\n| --- | ------------------------------------------------------------------------ |\n| 2   | 'Groonga is a fast full text search engine that supports all languages.' |`\nResources\n\nOfficial PGroonga documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Usage",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/wrappers.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'wrappers',\n  title: 'wrappers: 3rd Party Integrations',\n  description: '3rd party integrations for PostgreSQL ',\n}\nsupabase/wrappers is a PostgreSQL extension that provides integrations with external sources so you can interact with third-party data using SQL. \nFor example, the Stripe wrapper connects to Stripe's API and exposes each endpoint as a SQL table.\n{/ prettier-ignore /}\n```sql\nselect\n  customer_id\n  currency\nfrom\n   stripe.customers;\n\n\n```customer_id     | currency\n```\n\n\n--------------------+-----------\n cus_MJiBtCqOF1Bb3F | usd    \n(1 row)\n```\nUsage\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"wrappers\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"wrappers\" extension\ncreate extension wrappers;\n-- Disable the \"wrappers\" extension\ndrop extension if exists wrappers;\n```\n\n\nInstructions for setting up connections to each 3rd party service via SQL are available at the links in the integrations section below.\nA web interface for connecting to external data is coming to Supabase Studio in 2023.\nIntegrations\n\nFirebase\nStripe\nAirtable - Coming Soon\nBigQuery - Coming Soon\nClickhouse - Coming Soon\n\nResources\n\nOfficial supabase/wrappers documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Requirements",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgrepack.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'pg_repack: Physical storage optimization and maintenance',\n  description:\n    'A tool to remove bloat from tables and indexes and optimize physical data order and physical storage',\n}\npg_repack is a PostgreSQL extension to remove bloat from tables and indexes, and optionally restore the physical order of clustered indexes. Unlike CLUSTER and VACUUM FULL it works online, without holding an exclusive lock on the processed tables during processing. pg_repack is efficient to boot, with performance comparable to using CLUSTER directly.\npg_repack provides the following methods to optimize physical storage:\n\nOnline CLUSTER: ordering table data by cluster index in a non-blocking way\nOrdering table data by specified columns\nOnline VACUUM FULL: packing rows only in a non-blocking way\nRebuild or relocate only the indexes of a table\n\nRequirements\n\nOnly superusers can use the utility.\nTarget table must have a PRIMARY KEY, or a UNIQUE total index on a NOT NULL column.\nPerforming a full-table repack requires free disk space about twice as large as the target table and its indexes.\n\nUsage\nEnable the extension\nGet started with pg_repack by enabling the extension in the Supabase Dashboard.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pg_repack\" and enable the extension.\n\n\n\n```sql\n-- Example: enable the \"pg_repack\" extension\ncreate extension pg_repack with schema extensions;\n-- Example: disable the \"pg_repack\" extension\ndrop extension if exists pg_repack;\n```\n\n\nSyntax\n`sh\npg_repack [OPTION]... [DBNAME]`\nExamples\nIt's useful for performance to support tables data ordered on disk and physically remove deleted data that remain\notherwise.\nPerform an online CLUSTER of all the clustered tables in the database `db`, and perform an online `VACUUM FULL` of all the non-clustered tables:\n`sh\npg_repack db`\nPerform an online `VACUUM FULL` on the tables `table1` and `table2` in the database `db` (an eventual cluster index is ignored):\n`sh\npg_repack --no-order --table table1 --table table2 db`\nMoving indexes to a tablespace on a faster volume increases performance of `SELECT` queries using these indexes\ndrastically. `INSERT`s and `UPDATE`s of a table with indexes on a fast volume are also faster. This is very useful\nwhen the fast volume is small and can not accommodate all tables, as indexes are much smaller than tables.\nMove all indexes of table `table1` to tablespace `tbs`:\n`sh\npg_repack -d db --table table1 --only-indexes --tablespace tbs`\nMove the specified index `idx` to tablespace `tbs`:\n`sh\npg_repack -d db --index idx --tablespace tbs`\nSee the official pg_repack documentation for the full list of options.\nRestrictions\n\npg_repack cannot reorganize temp tables.\npg_repack cannot cluster tables by GiST indexes.\nYou cannot perform DDL commands of the target tables except VACUUM or ANALYZE while pg_repack is working.\n  pg_repack holds an ACCESS SHARE lock on the target table to enforce this restriction.\n\nResources\n\nOfficial pg_repack documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Concepts",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgvector.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgvector',\n  title: 'pgvector: Embeddings and vector similarity',\n  description:\n    'pgvector: a PostgreSQL extension for storing embeddings and performing vector similarity search.',\n}\npgvector is a PostgreSQL extension for vector similarity search. It can also be used for storing embeddings.\nConcepts\nVector similarity\nVector similarity refers to a measure of the similarity between two related items. For example, if you have a list of products, you can use vector similarity to find similar products. To do this, you need to convert each product into a \"vector\" of numbers, using a mathematical model. You can use a similar model for text, images, and other types of data. Once all of these vectors are stored in the database, you can use vector similarity to find similar items.\nEmbeddings\nThis is particularly useful if you're building on top of OpenAI's GPT-3. You can create and store embeddings which match the GPT model you're using.\nUsage\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"vector\" and enable the extension.\n\n\n\n```sql\n -- Example: enable the \"vector\" extension.\ncreate extension vector\nwith\n  schema extensions;\n-- Example: disable the \"vector\" extension\ndrop\n  extension if exists vector;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension, call `drop extension`.\n\n\nUsage\nCreate a table to store vectors\n`sql\ncreate table\n  posts (\n    id serial primary key,\n    title text not null,\n    body text not null,\n    embedding vector (1536)\n  );`\nStoring a vector / embedding\nIn this example we'll generate a vector using the OpenAI API client, then store it in the database using the Supabase client.\n```js\nconst title = 'First post!'\nconst body = 'Hello world!'\n// Generate a vector using OpenAI\nconst embeddingResponse = await openai.createEmbedding({\n  model: 'text-embedding-ada-002',\n  input: body,\n})\nconst [responseData] = embeddingResponse.data.data.\n// Store the vector in Postgres\nconst { data, error } = await supabase.from('posts').insert({\n  title,\n  body,\n  embedding: responseData.embedding,\n})\n```\nResources\n\nSource code: github.com/pgvector/pgvector\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Usage",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgcron.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgcron',\n  title: 'pg_cron: Job Scheduling',\n  description:\n    'pgnet: a simple cron-based job scheduler for PostgreSQL that runs inside the database.',\n}\nThe `pg_cron` extension is a simple cron-based job scheduler for PostgreSQL that runs inside the database.\nUsage\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pg_cron\" and enable the extension.\n\n\n\n```sql\n-- Example: enable the \"pg_cron\" extension\ncreate extension pg_cron with schema extensions;\n-- If you're planning to use a non-superuser role to schedule jobs,\n-- ensure that they are granted access to the cron schema and its underlying objects beforehand.\n-- Failure to do so would result in jobs by these roles to not run at all.\ngrant usage on schema cron to {{DB user}};\ngrant all privileges on all tables in schema cron to {{DB user}};\n-- Example: disable the \"pg_cron\" extension\ndrop extension if exists pg_cron;\n```\n\n\nSyntax\nThe schedule uses the standard cron syntax, in which * means \"run every time period\", and a specific number means \"but only at this time\":\n```bash\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 min (0 - 59)\n \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month (1 - 31)\n \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of week (0 - 6) (0 to 6 are Sunday to\n \u2502 \u2502 \u2502 \u2502 \u2502                  Saturday, or use names; 7 is also Sunday)\n \u2502 \u2502 \u2502 \u2502 \u2502\n \u2502 \u2502 \u2502 \u2502 \u2502\n\n```\nYou can use crontab.guru to help validate your cron schedules.\nExamples\nDelete data every week\nDelete old data on Saturday at 3:30am (GMT):\n`sql\nselect cron.schedule (\n    'saturday-cleanup', -- name of the cron job\n    '30 3 * * 6', -- Saturday at 3:30am (GMT)\n    $$ delete from events where event_time < now() - interval '1 week' $$\n);`\nRun a vacuum every day\nVacuum every day at 3:00am (GMT)\n`sql\nSELECT cron.schedule('nightly-vacuum', '0 3 * * *', 'VACUUM');`\nInvoke Supabase Edge Function every minute\nMake a POST request to a Supabase Edge Function every minute. Note: this requires the pg_net extension to be enabled.\n`sql\nselect\n  cron.schedule(\n    'invoke-function-every-minute',\n    '* * * * *', -- every minute\n    $$\n    select\n      net.http_post(\n          url:='https://project-ref.functions.supabase.co/function-name',\n          headers:='{\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer YOUR_ANON_KEY\"}'::jsonb,\n          body:=concat('{\"time\": \"', now(), '\"}')::jsonb\n      ) as request_id;\n    $$\n  );`\nUnschedule a job\nUnschedules a job called `'nightly-vacuum'`\n`sql\nSELECT cron.unschedule('nightly-vacuum');`\nResources\n\npg_cron GitHub Repository\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pgrouting.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgrouting',\n  title: 'pgrouting: Geospatial Routing',\n  description: 'Extends PostGIS with Geospatial Routing',\n}\npgRouting is PostgreSQL and PostGIS extension adding geospatial routing functionality.\nThe core functionality of `pgRouting` is a set of path finding algorithms including:\n\nAll Pairs Shortest Path, Johnson\u2019s Algorithm\nAll Pairs Shortest Path, Floyd-Warshall Algorithm\nShortest Path A*\nBi-directional Dijkstra Shortest Path\nBi-directional A* Shortest Path\nShortest Path Dijkstra\nDriving Distance\nK-Shortest Path, Multiple Alternative Paths\nK-Dijkstra, One to Many Shortest Path\nTraveling Sales Person\nTurn Restriction Shortest Path (TRSP)\n\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pgrouting\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pgRouting\" extension\ncreate extension pgrouting cascade;\n-- Disable the \"pgRouting\" extension\ndrop extension if exists pgRouting;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\n\n\nExample\nAs an example, we'll solve the traveling salesman probelem using the pgRouting's `pgr_TSPeuclidean` function from some PostGIS coodinates.\nA summary of the traveling salesman problem is, given a set of city coordinates, solve for a path that goes through each city and minimizes the total distance traveled.\nFirst we populate a table with some X, Y coordinates\n{/ prettier-ignore /}\n```sql\ncreate table wi29 (\n  id bigint,\n  x float,\n  y float,\n  geom geometry\n);\ninsert into wi29 (id, x, y)\nvalues\n  (1,20833.3333,17100.0000),\n  (2,20900.0000,17066.6667),\n  (3,21300.0000,13016.6667),\n  (4,21600.0000,14150.0000),\n  (5,21600.0000,14966.6667),\n  (6,21600.0000,16500.0000),\n  (7,22183.3333,13133.3333),\n  (8,22583.3333,14300.0000),\n  (9,22683.3333,12716.6667),\n  (10,23616.6667,15866.6667),\n  (11,23700.0000,15933.3333),\n  (12,23883.3333,14533.3333),\n  (13,24166.6667,13250.0000),\n  (14,25149.1667,12365.8333),\n  (15,26133.3333,14500.0000),\n  (16,26150.0000,10550.0000),\n  (17,26283.3333,12766.6667),\n  (18,26433.3333,13433.3333),\n  (19,26550.0000,13850.0000),\n  (20,26733.3333,11683.3333),\n  (21,27026.1111,13051.9444),\n  (22,27096.1111,13415.8333),\n  (23,27153.6111,13203.3333),\n  (24,27166.6667,9833.3333),\n  (25,27233.3333,10450.0000),\n  (26,27233.3333,11783.3333),\n  (27,27266.6667,10383.3333),\n  (28,27433.3333,12400.0000),\n  (29,27462.5000,12992.2222);\n```\nNext we use the `pgr_TSPeuclidean` function to find the best path.\n{/ prettier-ignore /}\n`sql\nselect\n    *\nfrom\n     pgr_TSPeuclidean($$select * from wi29$$)`\n{/ prettier-ignore /}\n`sql\n seq | node |       cost       |     agg_cost     \n-----+------+------------------+------------------\n   1 |    1 |                0 |                0\n   2 |    2 |  74.535614157127 |  74.535614157127\n   3 |    6 | 900.617093380362 | 975.152707537489\n   4 |   10 | 2113.77757765045 | 3088.93028518793\n   5 |   11 | 106.718669615254 | 3195.64895480319\n   6 |   12 | 1411.95293791574 | 4607.60189271893\n   7 |   13 | 1314.23824873744 | 5921.84014145637\n   8 |   14 | 1321.76283931305 | 7243.60298076942\n   9 |   17 | 1202.91366735569 |  8446.5166481251\n  10 |   18 | 683.333268292684 | 9129.84991641779\n  11 |   15 | 1108.05137466134 | 10237.9012910791\n  12 |   19 | 772.082339448903 |  11009.983630528\n  13 |   22 | 697.666150054665 | 11707.6497805827\n  14 |   23 | 220.141999627513 | 11927.7917802102\n  15 |   21 | 197.926372783442 | 12125.7181529937\n  16 |   29 | 440.456596290771 | 12566.1747492844\n  17 |   28 | 592.939989005405 | 13159.1147382898\n  18 |   26 | 648.288376333318 | 13807.4031146231\n  19 |   20 | 509.901951359278 | 14317.3050659824\n  20 |   25 | 1330.83095428717 | 15648.1360202696\n  21 |   27 |  74.535658878487 | 15722.6716791481\n  22 |   24 | 559.016994374947 |  16281.688673523\n  23 |   16 | 1243.87392358622 | 17525.5625971092\n  24 |    9 |  4088.0585364911 | 21613.6211336004\n  25 |    7 |  650.85409697993 | 22264.4752305803\n  26 |    3 | 891.004385199336 | 23155.4796157796\n  27 |    4 | 1172.36699411442 |  24327.846609894\n  28 |    8 | 994.708187806297 | 25322.5547977003\n  29 |    5 | 1188.01888359478 | 26510.5736812951\n  30 |    1 | 2266.91173136004 | 28777.4854126552`\nResources\n\nOfficial pgRouting documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Usage",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/rum.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'rum',\n  title: 'RUM: improved inverted index for full-text search based on GIN index',\n  description: 'A GIN-like index with additional tree-organized data for each index entry',\n}\nRUM is an extension which adds a RUM index to Postgresql.\nRUM index is based on GIN that stores additional per-entry information in a posting tree. For example, positional information of lexemes or timestamps. In comparison to GIN it can use this information to make faster index-only scans for:\n\nPhrase search\nText search with ranking by text distance operator\nText `SELECT`s with ordering by some non-indexed additional column e.g. by timestamp.\n\nRUM works best in scenarios when the possible keys are highly repeatable. I.e. all texts are composed of a\nlimited amount of words, so per-lexeme indexing gives significant speed-up in searching texts containing word\ncombinations or phrases.\nMain operators for ordering are:\ntsvector `<=>` tsquery | float4 | Distance between tsvector and tsquery.\nvalue `<=>` value | float8 | Distance between two values.\nWhere value is timestamp, timestamptz, int2, int4, int8, float4, float8, money and oid\nUsage\nEnable the extension\nYou can get started with rum by enabling the extension in your Supabase dashboard.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"rum\" and enable the extension.\n\n\n\n```sql\n-- Example: enable the \"rum\" extension\ncreate extension rum with schema extensions;\n-- Example: disable the \"rum\" extension\ndrop extension if exists rum;\n```\n\n\nSyntax\nFor type: tsvector\nTo understand the following you may need first to see Official PostgreSQL documentation on text\nsearch\n`rum_tsvector_ops`\n```sql\nCREATE TABLE test_rum(t text, a tsvector);\nCREATE TRIGGER tsvectorupdate\nBEFORE UPDATE OR INSERT ON test_rum\nFOR EACH ROW EXECUTE PROCEDURE tsvector_update_trigger('a', 'pg_catalog.english', 't');\nINSERT INTO test_rum(t) VALUES ('The situation is most beautiful');\nINSERT INTO test_rum(t) VALUES ('It is a beautiful');\nINSERT INTO test_rum(t) VALUES ('It looks like a beautiful place');\nCREATE INDEX rumidx ON test_rum USING rum (a rum_tsvector_ops);\n```\nAnd we can execute `tsvector` selects with ordering by text distance operator:\n`sql\nSELECT t, a `<=>` to_tsquery('english', 'beautiful | place') AS rank\n    FROM test_rum\n    WHERE a @@ to_tsquery('english', 'beautiful | place')\n    ORDER BY a `<=>` to_tsquery('english', 'beautiful | place');\n                t                |  rank\n---------------------------------+---------\n It looks like a beautiful place | 8.22467\n The situation is most beautiful | 16.4493\n It is a beautiful               | 16.4493\n(3 rows)`\n`rum_tsvector_addon_ops`\n`sql\nCREATE TABLE tsts (id int, t tsvector, d timestamp);\nCREATE INDEX tsts_idx ON tsts USING rum (t rum_tsvector_addon_ops, d)\n    WITH (attach = 'd', to = 't');`\nNow we can execute the selects with ordering distance operator on attached column:\n`sql\nSELECT id, d, d `<=>` '2016-05-16 14:21:25' FROM tsts WHERE t @@ 'wr&qh' ORDER BY d `<=>` '2016-05-16 14:21:25' LIMIT 5;\n id  |                d                |   ?column?\n-----+---------------------------------+---------------\n 355 | Mon May 16 14:21:22.326724 2016 |      2.673276\n 354 | Mon May 16 13:21:22.326724 2016 |   3602.673276\n 371 | Tue May 17 06:21:22.326724 2016 |  57597.326724\n 406 | Wed May 18 17:21:22.326724 2016 | 183597.326724\n 415 | Thu May 19 02:21:22.326724 2016 | 215997.326724\n(5 rows)`\nFor type: anyarray\n`rum_anyarray_ops`\nThis operator class stores anyarray elements with length of the array. It supports operators `&&`, `@>`, `<@`, `=`, `%` operators. It also supports ordering by `<=>` operator.\n`sql\nCREATE TABLE test_array (i int2[]);\nINSERT INTO test_array VALUES ('{}'), ('{0}'), ('{1,2,3,4}'), ('{1,2,3}'), ('{1,2}'), ('{1}');\nCREATE INDEX idx_array ON test_array USING rum (i rum_anyarray_ops);`\nNow we can execute the query using index scan:\n```sql\nSELECT * FROM test_array WHERE i && '{1}' ORDER BY i`<=>` '{1}' ASC;\n     i\n\n{1}\n {1,2}\n {1,2,3}\n {1,2,3,4}\n(4 rows)\n```\n`rum_anyarray_addon_ops`\nThe does the same with anyarray index as `rum_tsvector_addon_ops` i.e. allows to order select results using distance\noperator by attached column.\nLimitations\n`RUM` has slower build and insert times than `GIN` due to:\n\nIt is bigger due to the additional attributes stored in the index.\nIt uses generic WAL records.\n\nResources\n\nOfficial RUM documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/pg_jsonschema.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pg_jsonschema',\n  title: 'pg_jsonschema: JSON Schema Validation',\n  description: 'Validate json/jsonb with JSON Schema in PostgreSQL.',\n}\nJSON Schema is a language for annotating and validating JSON documents. pg_jsonschema is a PostgreSQL extension that adds the ability to validate PostgreSQL's built-in `json` and `jsonb` data types against JSON Schema documents.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"pg_jsonschema\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"pg_jsonschema\" extension\ncreate extension pg_jsonschema with schema extensions;\n-- Disable the \"pg_jsonschema\" extension\ndrop extension if exists pg_jsonschema;\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension you can call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep the `public` schema clean.\n\n\nFunctions\n\njson_matches_schema(schema json, instance json): Checks if a `json` instance conforms to a JSON Schema schema.\njsonb_matches_schema(schema json, instance jsonb): Checks if a `jsonb` instance conforms to a JSON Schema schema.\n\nUsage\nSince `pg_jsonschema` exposes its utilities as functions, we can execute them with a select statement:\n{/ prettier-ignore /}\n`sql\nselect\n  extensions.json_matches_schema(\n    schema := '{\"type\": \"object\"}',\n    instance := '{}'\n  );`\n`pg_jsonschema` is generally used in tandem with a check constraint as a way to constrain the contents of a json/b column to match a JSON Schema.\n{/ prettier-ignore /}\n```sql\ncreate table customer(\n    id serial primary key,\n    ...\n    metadata json,\n\n\n```check (\n    json_matches_schema(\n        '{\n            \"type\": \"object\",\n            \"properties\": {\n                \"tags\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"string\",\n                        \"maxLength\": 16\n                    }\n                }\n            }\n        }',\n        metadata\n    )\n)\n```\n\n\n);\n-- Example: Valid Payload\ninsert into customer(metadata)\nvalues ('{\"tags\": [\"vip\", \"darkmode-ui\"]}');\n-- Result:\n--   INSERT 0 1\n-- Example: Invalid Payload\ninsert into customer(metadata)\nvalues ('{\"tags\": [1, 3]}');\n-- Result:\n--   ERROR:  new row for relation \"customer\" violates check constraint \"customer_metadata_check\"\n--   DETAIL:  Failing row contains (2, {\"tags\": [1, 3]}).\n```\nResources\n\nOfficial pg_jsonschema documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Enable the extension",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/timescaledb.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'timescaledb',\n  title: 'timescaledb: Time-Series data',\n  description: 'Scalable time-series data storage and analysis',\n}\ntimescaledb is a PostgreSQL extension designed for improved handling of time-series data. It provides a scalable, high-performance solution for storing and querying time-series data on top of a standard PostgreSQL database.\n`timescaledb` uses a time-series-aware storage model and indexing techniques to improve performance of PostgreSQL in working with time-series data. The extension divides data into chunks based on time intervals, allowing it to scale efficiently, especially for large data sets. The data is then compressed, optimized for write-heavy workloads, and partitioned for parallel processing. `timescaledb` also includes a set of functions, operators, and indexes that work with time-series data to reduce query times, and make data easier to work with.\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"timescaledb\" and enable the extension.\n\n\n\n{/ prettier-ignore /}\n```sql\n-- Enable the \"timescaledb\" extension\ncreate extension timescaledb;\n-- Disable the \"timescaledb\" extension\ndrop extension if exists timescaledb;\n```\n\n\nUsage\nTo demonstrate how `timescaledb` works, let's consider a simple example where we have a table that stores temperature data from different sensors. We will create a table named \"temperatures\" and store data for two sensors.\nFirst we create a hypertable, which is a virtual table that is partitioned into chunks based on time intervals. The hypertable acts as a proxy for the actual table and makes it easy to query and manage time-series data.\n{/ prettier-ignore /}\n```sql\ncreate table temperatures (\n  time timestamp not null,\n  sensor_id int not null,\n  temperature double precision not null\n);\nselect create_hypertable('temperatures', 'time');\n```\nNext, we can populate some values\n{/ prettier-ignore /}\n`sql\ninsert into temperatures (time, sensor_id, temperature)\nvalues\n    ('2023-02-14 09:00:00', 1, 23.5),\n    ('2023-02-14 09:00:00', 2, 21.2),\n    ('2023-02-14 09:05:00', 1, 24.5),\n    ('2023-02-14 09:05:00', 2, 22.3),\n    ('2023-02-14 09:10:00', 1, 25.1),\n    ('2023-02-14 09:10:00', 2, 23.9),\n    ('2023-02-14 09:15:00', 1, 24.9),\n    ('2023-02-14 09:15:00', 2, 22.7),\n    ('2023-02-14 09:20:00', 1, 24.7),\n    ('2023-02-14 09:20:00', 2, 23.5);`\nAnd finally we can query the table using `timescaledb`'s `time_bucket` function to divide the time-series into intervals of the specified size (in this case, 1 hour) averaging the `temperature` reading within each group.\n{/ prettier-ignore /}\n`sql\nselect\n    time_bucket('1 hour', time) AS hour,\n    avg(temperature) AS average_temperature\nfrom\n    temperatures\nwhere\n    sensor_id = 1\n    and time > NOW() - interval '1 hour'\ngroup by\n    hour;`\nResources\n\nOfficial timescaledb documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/extensions/uuid-ossp.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'uuid-ossp',\n  title: 'uuid-ossp: Unique Identifiers',\n  description: 'A UUID generator for PostgreSQL.',\n}\nThe `uuid-ossp` extension can be used to generate a `UUID`.\nOverview\nA `UUID` is a \"Universally Unique Identifier\" and it is, for practical purposes, unique.\nThis makes them particularly well suited as Primary Keys. It is occasionally referred to as a `GUID`, which stands for \"Globally Unique Identifier\".\nEnable the extension\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Database page in the Dashboard.\nClick on Extensions in the sidebar.\nSearch for \"uuid-ossp\" and enable the extension.\n\nNote:\nCurrently `uuid-ossp` extension is enabled by default and cannot be disabled.\n\n\n```sql\n-- Example: enable the \"uuid-ossp\" extension\ncreate extension \"uuid-ossp\" with schema extensions;\n-- Example: disable the \"uuid-ossp\" extension\ndrop extension if exists \"uuid-ossp\";\n```\nEven though the SQL code is `create extension`, this is the equivalent of \"enabling the extension\".\nTo disable an extension, call `drop extension`.\nIt's good practice to create the extension within a separate schema (like `extensions`) to keep the `public` schema clean.\nNote:\nCurrently `uuid-ossp` extension is enabled by default and cannot be disabled.\n\n\nThe `uuid` type\nOnce the extension is enabled, you now have access to a `uuid` type.\n`uuid_generate_v1()`\nCreates a UUID value based on the combination of computer\u2019s MAC address, current timestamp, and a random value.\n\n  UUIDv1 leaks identifiable details, which might make it unsuitable for certain security-sensitive\n  applications.\n\n`uuid_generate_v4()`\nCreates UUID values based solely on random numbers. You can also use Postgres's built-in gen_random_uuid() function to generate a UUIDv4.\nExamples\nWithin a query\n`sql\nselect uuid_generate_v4();`\nAs a Primary Key\nAutomatically create a unique, random ID in a table:\n```sql\ncreate table contacts (\n  id uuid default uuid_generate_v4(),\n  first_name text,\n  last_name text,\nprimary key (id)\n);\n```\nResources\n\nChoosing a Postgres Primary Key\nThe Basics Of PostgreSQL UUID Data Type\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Generating types using Supabase CLI",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/database/api/generating-types.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'generating-types',\n  title: 'Generating Types',\n  description: 'How to generate types for your API and Supabase libraries.',\n  video: 'https://www.youtube.com/v/7CqlTU9aOR4',\n}\nSupabase APIs are generated from your database, which means that we can use database introspection to generate type-safe API definitions.\n\n\n\nGenerating types using Supabase CLI\nThe Supabase CLI is a single binary Go application that provides everything you need to setup a local development environment.\nYou can install the CLI via npm or other supported package managers. The minimum required version of the CLI is v1.8.1.\n`bash\nnpm i supabase@\">=1.8.1\" --save-dev`\nLogin with your Personal Access Token:\n`bash\nnpx supabase login`\nGenerate types for your project to produce the `types/supabase.ts` file:\n`bash\nnpx supabase gen types typescript --project-id \"$PROJECT_ID\" --schema public > types/supabase.ts`\nAfter you have generated your types, you can use them in `src/index.ts`\n```tsx\nimport { NextApiRequest, NextApiResponse } from 'next'\nimport { createClient } from '@supabase/supabase-js'\nimport { Database } from '../types/supabase'\nconst supabase = createClient(\n  process.env.NEXT_PUBLIC_SUPABASE_URL,\n  process.env.SUPABASE_SECRET_KEY\n)\nexport default async (req: NextApiRequest, res: NextApiResponse) => {\n  const allOnlineUsers = await supabase.from('users').select('*').eq('status', 'ONLINE')\n  res.status(200).json(allOnlineUsers)\n}\n```\nUpdate types automatically with GitHub Actions\nOne way to keep your type definitions in sync with your database is to set up a GitHub action that runs on a schedule.\nAdd the script above to your `package.json` to run it using `npm run update-types`\n`json\n\"update-types\": \"npx supabase gen types typescript --project-id \\\"$PROJECT_ID\\\" > types/supabase.ts\"`\nCreate a file `.github/workflows/update-types.yml` with the following snippet to define the action along with the environment variables. This script will commit new type changes to your repo every night.\n```yaml\nname: Update database types\non:\n  schedule:\n    # sets the action to run daily. You can modify this to run the action more or less frequently\n    - cron: '0 0 *  '\njobs:\n  update:\n    runs-on: ubuntu-latest\n    env:\n      SUPABASE_ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}\n      PROJECT_ID: \n    steps:\n      - uses: actions/checkout@v2\n        with:\n          persist-credentials: false\n          fetch-depth: 0\n      - uses: actions/setup-node@v2.1.5\n        with:\n          node-version: 16\n      - run: npm run update-types\n      - name: check for file changes\n        id: git_status\n        run: |\n          echo \"::set-output name=status::$(git status -s)\"\n      - name: Commit files\n        if: ${{contains(steps.git_status.outputs.status, ' ')}}\n        run: |\n          git add types/database/index.ts\n          git config --local user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --local user.name \"github-actions[bot]\"\n          git commit -m \"Update database types\" -a\n      - name: Push changes\n        if: ${{contains(steps.git_status.outputs.status, ' ')}}\n        uses: ad-m/github-push-action@master\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          branch: ${{ github.ref }}\n```\nAlternatively, you can use a community-supported GitHub action: generate-supabase-db-types-github-action.\nResources\n\nGenerating Supabase types with GitHub Actions\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Get the code",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/self-hosting/docker.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Self-Hosting with Docker',\n  description: 'Learn how to configure and deploy Supabase with Docker.',\n}\nDocker is the easiest way to get started with self-hosted Supabase.\nBefore you begin\nYou need the following installed in your system:\n\nDocker and docker compose\nGit\n\nQuick Start\nGet the code\nCheckout the docker directory in the Supabase repo:\n```sh\nGet the code\ngit clone --depth 1 https://github.com/supabase/supabase\nGo to the docker folder\ncd supabase/docker\nCopy the fake env vars\ncp .env.example .env\nStart\ndocker compose up\n```\nNow visit http://localhost:3000 to start using Supabase Studio.\nSecuring your setup\nWhile we provided you with some example secrets for getting started, you should NEVER deploy your Supabase setup using the defaults we have provided.\nFollow these steps to secure your Docker setup. We strongly recommend using a secrets manager when deploying to production.\nGenerate API Keys\nUse your `JWT_SECRET` to generate a `anon` and `service` API keys using the JWT generator.\nReplace the values in these files:\n\n`.env`:\n`ANON_KEY` - replace with an `anon` key\n`SERVICE_ROLE_KEY` - replace with a `service` key\n`volumes/api/kong.yml`\n`anon` - replace with an `anon` key\n`service_role` - replace with a `service` key\n\nUpdate Secrets\nUpdate the `.env` file with your own secrets. In particular, these are required:\n\n`POSTGRES_PASSWORD`: the password for the `postgres` role.\n`JWT_SECRET`: used by PostgREST and GoTrue, among others.\n`SITE_URL`: the base URL of your site.\n`SMTP_*`: mail server credentials. You can use any SMTP server.\n\nSecuring the Dashboard\nThe Docker setup doesn't include a management database for managing users and logins. If you plan to deploy the Studio to the web we suggest you put it behind a web proxy with Basic Auth or hide it behind a VPN.\nConfiguration\nEach system can be configured to suit your particular use-case.\nTo keep the setup simple, we made some choices that may not be optimal for production:\n\nthe database is in the same machine as the servers\nStorage uses the filesystem backend instead of S3\nAuth should be configured with a production-ready SMTP server\n\nUsing an external database\nWe strongly recommend decoupling your database from `docker-compose` before deploying.\nThe middleware will run with any PostgreSQL database that has logical replication enabled. The following environment variables should be updated\nin the `.env` file to point to your external database:\n```env title=.env\nPOSTGRES_PASSWORD=your-super-secret-and-long-postgres-password\nPOSTGRES_HOST=db\nPOSTGRES_DB=postgres\nPOSTGRES_USER=postgres\nPOSTGRES_PORT=5432\n```\nOnce you have done this, you can safely comment out the `db` section of the `docker-compose` file, and remove any instances where the services `depends_on` the `db` image.\nSupabase services require your external database to be initialized with a specific schema. Refer to our postgres/migrations repository for instructions on running these migrations.\nNote that you need superuser permission on the postgres role to perform the initial schema migration. Once completed, the postgres role will be demoted to non-superuser to prevent abuse.\nSetting database's `log_min_messages`\nBy default, `docker compose` sets the database's `log_min_messages` configuration to `fatal` to prevent redundant logs generated by Realtime.\nHowever, you might miss important log messages such as database errors. Configure `log_min_messages` based on your needs.\nFile storage backend on macOS\nBy default, Storage backend is set to `file`, which is to use local files as the storage backend. To make it work on macOS, you need to choose `VirtioFS` as the Docker container file sharing implementation (in Docker Desktop -> Preferences -> General).\nDeploying\nSee the following guides to deploy Docker Compose setup using your preferred tool and platform:\n\nDocker Swarm\nAWS Fargate\nUsing Kompose for Kubernetes\n\nNext steps\n\nGot a question? Ask here.\nSign in: app.supabase.com\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "config.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/self-hosting/auth/config.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport { getAuthConfigV1 } from '~/lib/mdx/getConfig'\nimport Param from '~/components/Params'\nexport const spec = getAuthConfigV1()\nexport const meta = {\n  title: 'Auth Self-hosting Config',\n  description: 'How to configure and deploy Supabase.',\n}\n{spec.info.description}\n\n{spec.info.tags.map(tag => {\n    return (\n        <>\n            {tag.title}\n{tag.description}\n\nParameters\n\n                {spec.parameters.filter(param => param.tags.includes(tag.id)).map((param) => {\n                    return \n                })}\n\n            \n\n        \n    )\n\n})}\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "config.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/self-hosting/storage/config.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport { getStorageConfigV0 } from '~/lib/mdx/getConfig'\nimport Param from '~/components/Params'\nexport const spec = getStorageConfigV0()\nexport const meta = {\n  title: 'Storage Self-hosting Config',\n  description: 'How to configure and deploy Supabase.',\n}\n{spec.info.description}\n\n{spec.info.tags.map(tag => {\n    return (\n        <>\n            {tag.title}\n{tag.description}\n\nParameters\n\n                {spec.parameters.filter(param => param.tags.includes(tag.id)).map((param) => {\n                    return \n                })}\n\n            \n\n        \n    )\n\n})}\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "config.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/self-hosting/realtime/config.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport { getRealtimeConfigV0 } from '~/lib/mdx/getConfig'\nimport Param from '~/components/Params'\nexport const spec = getRealtimeConfigV0()\nexport const meta = {\n  title: 'Realtime Self-hosting Config',\n  description: 'How to configure and deploy Supabase.',\n}\n{spec.info.description}\n\n{spec.info.tags.map(tag => {\n    return (\n        <>\n            {tag.title}\n{tag.description}\n\nParameters\n\n                {spec.parameters.filter(param => param.tags.includes(tag.id)).map((param) => {\n                    return \n                })}\n\n            \n\n        \n    )\n\n})}\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-email.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-email',\n  title: 'Login With Email',\n  description: 'Use Supabase to Authenticate and Authorize your users using email.',\n}\nOverview\nSetting up Email logins for your Supabase application.\n\nAdd Email authenticator to your Supabase Project\nAdd the login code to your application - JavaScript | Flutter\n\nConfigure email settings\n\nFor Site URL, enter the final (hosted) URL of your app.\nFor Auth Providers, enable email provider.\n\n\nFor self-hosting, you can update your project configuration using the files and environment variables provided.\nSee the self-hosting docs for details.\n\nAdd login code to your client app\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nWhen your user signs in, call signInWithPassword() with their email address and password:\n`js\nasync function signInWithEmail() {\n  const { data, error } = await supabase.auth.signInWithPassword({\n    email: 'example@email.com',\n    password: 'example-password',\n  })\n}`\n\n\nWhen your user signs in, call signInWithPassword() with their email address and password:\n`dart\nFuture<void> signInWithEmail() async {\n  final AuthResponse res = await supabase.auth.signInWithPassword(\n    email: 'example@email.com',\n    password: 'example-password'\n  );\n}`\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signOut() {\n  const { error } = await supabase.auth.signOut()\n}`\n\n\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`dart\nFuture<void> signOut() async {\n   await supabase.auth.signOut();\n}`\n\n\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nSupabase Flutter Client\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/overview.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport { useRouter } from 'next/router'\nexport const meta = {\n  id: 'auth',\n  title: 'Auth',\n  description: 'Use Supabase to Authenticate and Authorize your users.',\n  sidebar_label: 'Overview',\n  video: 'https://www.youtube.com/v/6ow_jW4epf8',\n}\nOverview\nThere are two parts to every Auth system:\n\nAuthentication: should this person be allowed in? If yes, who are they?\nAuthorization: once they are in, what are they allowed to do?\n\nSupabase Auth is designed to work either as a standalone product, or deeply integrated with the other Supabase products.\nPostgres is at the heart of everything we do, and the Auth system follows this principle. We leverage Postgres' built-in Auth functionality wherever possible.\nHere's a quick, 2 minute tour of the Auth features built-in to Supabase:\n\n\n\nAuthentication\nYou can authenticate your users in several ways:\n\nEmail & password.\nMagic links (one-click logins).\nSocial providers.\nPhone logins.\n\nProviders\nWe provide a suite of Providers and login methods, as well as Auth helpers.\nSocial Auth\n\n\n\nPhone Auth\n\n\n\nConfigure third-party providers\nYou can enable third-party providers with the click of a button by navigating to Authentication > Providers > Auth Providers and inputting your `Client ID` and `Secret` for each.\n\nRedirect URLs and wildcards\nWhen using third-party providers, the Supabase client library redirects the user to the provider. When the third-party provider successfully authenticates the user, the provider redirects the user to the Supabase Auth callback URL where they are further redirected to the URL specified in the `redirectTo` parameter. This parameter defaults to the SITE_URL. You can modify the `SITE_URL` or add additional redirect URLs.\nYou can use wildcard match patterns to support preview URLs from providers like Netlify and Vercel. See the full list of supported patterns. Use this tool to test your patterns.\n\n\u26a0\ufe0f WARNING: While the \"globstar\" (`**`) is useful for local development and preview URLs, we recommend setting the exact redirect URL path for your site URL in production.\n\nNetlify preview URLs\nFor deployments with Netlify, set the `SITE_URL` to your official site URL. Add the following additional redirect URLs for local development and deployment previews:\n\n`http://localhost:3000/**`\n`https://**--my_org.netlify.app/**`\n\nVercel preview URLs\nFor deployments with Vercel, set the `SITE_URL` to your official site URL. Add the following additional redirect URLs for local development and deployment previews:\n\n`http://localhost:3000/**`\n`https://*-username.vercel.app/**`\n\nVercel provides an environment variable for the URL of the deployment called `NEXT_PUBLIC_VERCEL_URL`. See the Vercel docs for more details. You can use this variable to dynamically redirect depending on the environment:\n```js\nconst getURL = () => {\n  let url =\n    process?.env?.NEXT_PUBLIC_SITE_URL ?? // Set this to your site URL in production env.\n    process?.env?.NEXT_PUBLIC_VERCEL_URL ?? // Automatically set by Vercel.\n    'http://localhost:3000/';\n  // Make sure to include`https://`when not localhost.\n  url = url.includes('http') ? url :`https://${url}`;\n  // Make sure to including trailing`/`.\n  url = url.charAt(url.length - 1) === '/' ? url :`${url}/`;\n  return url;\n};\nconst { data, error } = await supabase.auth.signInWithOAuth({\n  provider: 'github'\n  options: {\n    redirectTo: getURL()\n  }\n}\n```\nMobile deep linking URIs\nFor mobile applications you can use deep linking URIs. For example for your `SITE_URL` you can specify something like `com.supabase://login-callback/` and for additional redirect URLs something like `com.supabase.staging://login-callback/` if needed.\nAuthorization\nWhen you need granular authorization rules, nothing beats PostgreSQL's Row Level Security (RLS).\nPolicies are PostgreSQL's rule engine. They are incredibly powerful and flexible, allowing you to write complex SQL rules which fit your unique business needs.\nGet started with our Row Level Security Guides.\nRow Level Security\nAuthentication only gets you so far. When you need granular authorization rules, nothing beats PostgreSQL's Row Level Security (RLS). Supabase makes it simple to turn RLS on and off.\n\n\n\nPolicies\nPolicies are PostgreSQL's rule engine. They are incredibly powerful and flexible, allowing you to write complex SQL rules which fit your unique business needs.\n\n\n\nWith policies, your database becomes the rules engine. Instead of repetitively filtering your queries, like this ...\n```js\nconst loggedInUserId = 'd0714948'\nlet { data, error } = await supabase\n  .from('users')\n  .select('user_id, name')\n  .eq('user_id', loggedInUserId)\n// console.log(data)\n// => { id: 'd0714948', name: 'Jane' }\n```\n... you can simply define a rule on your database table, `auth.uid() = user_id`, and your request will return the rows which pass the rule, even when you remove the filter from your middleware:\n```js\nlet { data, error } = await supabase.from('users').select('user_id, name')\n// console.log(data)\n// Still => { id: 'd0714948', name: 'Jane' }\n```\nHow It Works\n\nA user signs up. Supabase creates a new user in the `auth.users` table.\nSupabase returns a new JWT, which contains the user's `UUID`.\nEvery request to your database also sends the JWT.\nPostgres inspects the JWT to determine the user making the request.\nThe user's UID can be used in policies to restrict access to rows.\n\nSupabase provides a special function in Postgres, `auth.uid()`, which extracts the user's UID from the JWT. This is especially useful when creating policies.\nUser Management\nSupabase provides multiple endpoints to authenticate and manage your users:\n\nSign up\nSign in with password\nSign in with passwordless / one-time password (OTP)\nSign in with OAuth\nSign out\n\nWhen users sign up, Supabase assigns them a unique ID. You can reference this ID anywhere in your database. For example, you might create a `profiles` table referencing `id` in the `auth.users` table using a `user_id` field.\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Sign up for hCaptcha",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-captcha.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-captcha',\n  title: 'Enable Captcha Protection',\n  description: 'Add Captcha Protection to your Supabase project',\n  video: 'https://www.youtube.com/v/em1cpOAXknM',\n}\nSupabase provides you with the option of adding captcha to your sign-in, sign-up, and password reset forms. This keeps your website safe from bots and malicious scripts. Supabase authentication has support for hCaptcha.\n\n\n\nSign up for hCaptcha\nGo to the hCaptcha website and sign up for an account. On the welcome page, copy the Sitekey and Secret key.\nIf you have already signed up and didn't copy this information from the welcome page, you can get the Secret key from the settings page.\n\nThe Sitekey can be found in the Settings of the active site you created.\n\nIn the Settings page, look for the Sitekey section and copy the key.\n\nEnable hCaptcha protection for your Supabase project\nNavigate to the Authentication page in the Supabase Dashboard and find the Enable hCaptcha protection toggle under the Security and Protection section.\n\nEnter your hCaptcha Secret key and click Save.\nAdd the hCaptcha frontend component\nThe frontend requires some changes to provide the captcha on-screen for the user. This example uses React and the hCaptcha React component, but hCaptcha can be used with any JavaScript framework.\nInstall `@hcaptcha/react-hcaptcha` in your project as a dependency.\n`bash\nnpm install @hcaptcha/react-hcaptcha`\nNow import the `HCaptcha` component from the `@hcaptcha/react-hcaptcha` library.\n`javascript\nimport HCaptcha from '@hcaptcha/react-hcaptcha'`\nLet\u2019s create a empty state to store our `captchaToken`\n`jsx\nconst [captchaToken, setCaptchaToken] = useState()`\nNow lets add the HCaptcha component to the JSX section of our code\n`html\n<HCaptcha />`\nWe will pass it the sitekey we copied from the hCaptcha website as a property along with a onVerify property which takes a callback function. This callback function will have a token as one of its properties. Let's set the token in the state using `setCaptchaToken`\n`jsx\n<HCaptcha\n  sitekey=\"your-sitekey\"\n\u00a0 onVerify={(token) => { setCaptchaToken(token) }\n/>`\nNow lets use the captcha token we receive in our Supabase signUp function.\n`jsx\nawait supabase.auth.signUp({\n  email,\n  password,\n  options: { captchaToken },\n})`\nWe will also need to reset the captcha challenge after we have made a call to the function above.\nCreate a ref to use on our HCaptcha component.\n`jsx\nconst captcha = useRef()`\nLet's add a ref attribute on the `HCaptcha` component and assign the `captcha` constant to it.\n`jsx\n<HCaptcha\n  ref={captcha}\n  sitekey=\"your-sitekey\"\n  onVerify={(token) => {\n    setCaptchaToken(token)\n  }}\n/>`\nReset the `captcha` after the signUp function is called using the following code:\n`jsx\ncaptcha.current.resetCaptcha()`\nIn order to test that this works locally we will need to use something like ngrok or add an entry to your hosts file. You can read more about this in the hCaptcha docs.\nRun the application and you should now be provided with a captcha challenge.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Creating user tables",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/managing-user-data.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'managing-user-data',\n  title: 'Managing User Data',\n  description: 'Securing your user data with Row Level Security.',\n}\nFor security purposes, the `auth` schema is not exposed on the auto-generated API.\nEven though Supabase provides an `auth.users` table, it can be helpful to create tables in the `public` schema for storing user data that you want to access via the API.\nCreating user tables\nWhen you create tables to store user data, it's helpful to reference the `auth.users` table in the primary key to ensure data integrity. Also specify the `on delete cascade` clause when referencing `auth.users`. Omitting it may cause problems when deleting users. For example, a `public.profiles` table might look like this:\n```sql\ncreate table public.profiles (\n  id uuid not null references auth.users on delete cascade,\n  first_name text,\n  last_name text,\nprimary key (id)\n);\nalter table public.profiles enable row level security;\n```\n\nOnly use primary keys as foreign key references for schemas and tables like `auth.users` which are managed by Supabase. PostgreSQL lets you specify a foreign key reference for columns backed by a unique index (not necessarily primary keys).\nPrimary keys are guaranteed not to change. Columns, indices, constraints or other database objects managed by Supabase may change at any time and you should be careful when referencing them directly.\n\nDeleting Users\nYou may delete users directly or via the management console at Authentication > Users. Note that deleting a user from the `auth.users` table does not automatically sign out a user. As Supabase makes use of JSON Web Tokens (JWT), a user's JWT will remain \"valid\" until it has expired. Should you wish to immediately revoke access for a user, do considering making use of a Row Level Security policy as described below.\nPublic access\nSince Row Level Security is enabled, this table is accessible via the API but no data will be returned unless we set up some Policies.\nIf we wanted the data to be readable by everyone but only allow logged-in users to update their own data, the Policies would look like this:\n```sql\ncreate policy \"Public profiles are viewable by everyone.\"\n  on profiles for select\n  using ( true );\ncreate policy \"Users can insert their own profile.\"\n  on profiles for insert\n  with check ( auth.uid() = id );\ncreate policy \"Users can update own profile.\"\n  on profiles for update\n  using ( auth.uid() = id );\n```\nPrivate access\nIf the data should only be readable by the user who owns the data, we just need to change the `for select` query above.\n`sql\ncreate policy \"Profiles are viewable by users who created them.\"\n  on profiles for select\n  using ( auth.uid() = id );`\nThe nice thing about this pattern? We can now query this table via the API and we don't need to include data filters in our API queries - the Policies will handle that for us:\n```js\n// This will return nothing while the user is logged out\nconst { data } = await supabase.from('profiles').select('id, username, avatar_url, website')\n// After the user is logged in, this will only return\n// the logged-in user's data - in this case a single row\nconst { error } = await supabase.auth.signIn({ email })\nconst { data: profile } = await supabase\n  .from('profiles')\n  .select('id, username, avatar_url, website')\n```\nBypassing Row Level Security\nIf you need to fetch a full list of user profiles, we supply a `service_key` which you can use with your API and Client Libraries to bypass Row Level Security.\nMake sure you NEVER expose this publicly. But it can be used on the server-side to fetch all of the profiles.\nAccessing User Metadata\nYou can assign metadata to users on sign up:\n`js\nconst { data, error } = await supabase.auth.signUp({\n  email: 'example@email.com',\n  password: 'example-password',\n  options: {\n    data: {\n      first_name: 'John',\n      age: 27,\n    },\n  },\n})`\nUser metadata is stored on the `raw_user_meta_data` column of the `auth.users` table. To view the metadata:\n`js\nconst {\n  data: { user },\n} = await supabase.auth.getUser()\nlet metadata = user.user_metadata`\nAdvanced techniques\nUsing triggers\nIf you want to add a row to your `public.profiles` table every time a user signs up, you can use triggers.\nIf the trigger fails however, it could block the user sign ups - so make sure that the code is well-tested.\nFor example:\n```sql\n-- inserts a row into public.profiles\ncreate function public.handle_new_user()\nreturns trigger\nlanguage plpgsql\nsecurity definer set search_path = public\nas $$\nbegin\n  insert into public.profiles (id)\n  values (new.id);\n  return new;\nend;\n$$;\n-- trigger the function every time a user is created\ncreate trigger on_auth_user_created\n  after insert on auth.users\n  for each row execute procedure public.handle_new_user();\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Status",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-helpers.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'index',\n  title: 'Auth Helpers Overview',\n  description: 'A collection of framework-specific Auth utilities for working with Supabase.',\n  sidebar_label: 'Overview',\n}\nA collection of framework-specific Auth utilities for working with Supabase.\n\n\n    {/* Auth UI */}\n    \n\n\n    {/* Next.js */}\n    \n\n\n    {/* SvelteKit */}\n    \n\n\n    {/* Remix */}\n    \n\n\n\n\nStatus\nThe Auth Helpers are in `beta`. They are usable in their current state, but it's likely that there will be breaking changes.\nAdditional Links\n\nSource code\nKnown bugs and issues\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-magic-link.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-magic-link',\n  title: 'Login With Magic Link',\n  description: 'Use Supabase to authenticate and authorize your users using magic links.',\n}\nMagic links are a form of passwordless logins where users click on a link sent to their email address to log in to their accounts.\nMagic links only work with email addresses. By default, a user can only request a magic link once every 60 seconds.\nOverview\nSetting up Magic Link logins for your Supabase application.\n\nAdd Magic Link authenticator to your Supabase Project\nAdd the login code to your application - JavaScript | Flutter\n\nAdd Magic Link into your Supabase Project\n\nFor Site URL, enter the final (hosted) URL of your app.\nFor Auth Providers, enable email provider.\n\nAdd login code to your client app\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\nWhen your user signs in, call signInWithOtp() with their email address:\n\n`js\nasync function signInWithEmail() {\n  const { data, error } = await supabase.auth.signInWithOtp({\n    email: 'example@email.com',\n    options: {\n      emailRedirectTo: 'https://example.com/welcome',\n    },\n  })\n}`\n\n\nWhen your user signs in, call signIn() with their email address:\n`dart\nFuture<void> signInWithEmail() async {\n  final AuthResponse res = await supabase.auth.signinwithotp(email: 'example@email.com');\n}`\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n\n`js\nasync function signOut() {\n  const { error } = await supabase.auth.signOut()\n}`\n\n\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`dart\nFuture<void> signOut() async {\n  await supabase.auth.signOut();\n}`\n\n\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nSupabase Flutter Client\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Terminology",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-email-templates.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Email Templates',\n  description: 'Learn how to configure the email templates on Supabase.',\n}\nYou can customize the email messages used for the authentication flows. You can edit the following email templates:\n\nConfirm signup\nInvite user\nMagic Link\nChange Email Address\nReset Password\n\nTerminology\nThe templating system provides the following variables for use:\n| Name                     | Description                                                                                                                                                                                                       |\n| ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `{{ .ConfirmationURL }}` | Contains the confirmation URL. For example, a signup confirmation URL would look like: `https://project-ref.supabase.co/auth/v1/verify?token={{ .TokenHash }}&type=signup&redirect_to=https://example.com/path` . |\n| `{{ .Token }}`           | Contains a 6-digit One-Time-Password (OTP) that can be used instead of the `{{. ConfirmationURL }}` .                                                                                                             |\n| `{{ .TokenHash }}`       | Contains a hashed version of the `{{ .Token }}`. This is useful for constructing your own email link in the email template.                                                                                       |\n| `{{ .SiteURL }}`         | Contains your application's Site URL. This can be configured in your project's authentication settings.                                                                                                           |\nLimitations\nEmail Prefetching\nCertain email providers may have spam detection or other security features that prefetch URL links from incoming emails.\nIn this scenario, the `{{ .ConfirmationURL }}` sent will be consumed instantly which leads to a \"Token has expired or is invalid\" error.\nTo guard against this:\n\nUse an email OTP instead by including `{{ .Token }}` in the email template.\nCreate your own custom email link to redirect the user to a page where they can click on a button to confirm the action.\n  For example, you can include the following in your email template:\n\n`html\n  <a href=\"{{ .SiteURL }}/confirm-signup?confirmation_url={{ .ConfirmationURL }}\"\n    >Confirm your signup\n  </a>`\nThe user should be brought to a page on your site where they can confirm the action by clicking a button.\n  The button should contain the actual confirmation link which can be obtained from parsing the `confirmation_url={{ .ConfirmationURL }}` query parameter in the URL.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Benefits",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/phone-login.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport { IconPanel, GlassPanel, IconMail } from 'ui'\nimport Link from 'next/link'\nimport { PhoneLoginsItems } from '~/components/Navigation/NavigationMenu/NavigationMenu.constants'\nexport const meta = {\n  title: 'Phone Login',\n  description: 'Learn about logging in to your platform using SMS one-time passwords.',\n}\nPhone Login is a method of authentication that allows users to log in to a website or application without using a password. Instead of entering a password, the user provides another form of authentication through a one-time code sent via SMS.\nBenefits\nThere are several reasons why you might want to add phone login to your applications:\n\n\nImproved user experience: By eliminating the need for users to remember and enter complex passwords, phone login can make it easier and more convenient for users to log in to your application. This can improve the overall user experience and make it more enjoyable for users to interact with your application.\n\n\nIncreased security: Phone login can improve the security of your application by reducing the risk of password-related security breaches, such as password reuse and weak passwords. By using alternative forms of authentication, such as one-time codes or biometric factors, you can make it more difficult for unauthorized users to access your application.\n\n\nReduced support burden: Phone login can also help reduce the support burden for your team by eliminating the need to handle password recovery flows or deal with other password-related issues. This can free up your team to focus on other important tasks and improve the efficiency of your operation.\n\n\nSet up a provider with Supabase Auth\nSupabase supports Phone Login with several communications platforms. Follow the guides below to set up a provider with Supabase Auth.\n\n  {PhoneLoginsItems.map((item) => (\n    \n\n\n          {item.linkDescription}\n        \n\n    \n))}\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Policies",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/row-level-security.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'row-level-security',\n  title: 'Row Level Security',\n  description: 'Secure your data using Postgres Row Level Security.',\n  video: 'https://www.youtube.com/v/Ow_Uzedfohk',\n}\nWhen you need granular authorization rules, nothing beats PostgreSQL's Row Level Security (RLS).\nPolicies are PostgreSQL's rule engine. They are incredibly powerful and flexible, allowing you to write complex SQL rules which fit your unique business needs.\n\n\n\nPolicies\nPolicies are easy to understand once you get the hang of them. Each policy is attached to a table, and the policy is executed\nevery time a table is accessed.\nYou can just think of them as adding a `WHERE` clause to every query. For example a policy like this ...\n`sql\ncreate policy \"Individuals can view their own todos.\"\n    on todos for select\n    using ( auth.uid() = user_id );`\n.. would translate to this whenever a user tries to select from the todos table:\n`sql\nselect *\nfrom todos\nwhere auth.uid() = todos.user_id; -- Policy is implicitly added.`\nHelper Functions\nSupabase provides you with a few easy functions that you can use with your policies.\n`auth.uid()`\nReturns the ID of the user making the request.\n`auth.jwt()`\nReturns the JWT of the user making the request.\nExamples\nHere are some examples to show you the power of PostgreSQL's RLS.\nAllow read access\n```sql\n-- 1. Create table\ncreate table profiles (\n  id uuid references auth.users,\n  avatar_url text\n);\n-- 2. Enable RLS\nalter table profiles\n  enable row level security;\n-- 3. Create Policy\ncreate policy \"Public profiles are viewable by everyone.\"\n  on profiles for select using (\n    true\n  );\n```\n\nCreates a table called `profiles` in the public schema (default schema).\nEnables Row Level Security.\nCreates a policy which allows all `select` queries to run.\n\nRestrict updates\n```sql\n-- 1. Create table\ncreate table profiles (\n  id uuid references auth.users,\n  avatar_url text\n);\n-- 2. Enable RLS\nalter table profiles\n  enable row level security;\n-- 3. Create Policy\ncreate policy \"Users can update their own profiles.\"\n  on profiles for update using (\n    auth.uid() = id\n  );\n```\n\nCreates a table called `profiles` in the public schema (default schema).\nEnables RLS.\nCreates a policy which allows logged in users to update their own data.\n\nOnly anon or authenticated access\nYou can add a Postgres role\n`sql\ncreate policy \"Public profiles are viewable by everyone.\"\non profiles for select\nto authenticated, anon\nusing (\n  true\n);`\nPolicies with joins\nPolicies can even include table joins. This example shows how you can query \"external\" tables to build more advanced rules.\n```sql\ncreate table teams (\n  id serial primary key,\n  name text\n);\n-- 2. Create many to many join\ncreate table members (\n  team_id bigint references teams,\n  user_id uuid references auth.users\n);\n-- 3. Enable RLS\nalter table teams\n  enable row level security;\n-- 4. Create Policy\ncreate policy \"Team members can update team details if they belong to the team.\"\n  on teams\n  for update using (\n    auth.uid() in (\n      select user_id from members\n      where team_id = id\n    )\n  );\n```\nNote: If RLS is also enabled for members, the user must also have read (select) access to members. Otherwise the joined query will not yield any results.\nPolicies with security definer functions\nPolicies can also make use of `security definer functions`. This is useful in a many-to-many relationship where you want to restrict access to the linking table. Following the `teams` and `members` example from above, this example shows how you can use the security definer function in combination with a policy to control access to the `members` table.\n```sql\n-- 1. Follow example for 'Policies with joins' above\n-- 2.  Enable RLS\nalter table members\n  enable row level security\n-- 3.  Create security definer function\ncreate or replace function get_teams_for_authenticated_user()\nreturns setof bigint\nlanguage sql\nsecurity definer\nset search_path = public\nstable\nas $$\n    select team_id\n    from members\n    where user_id = auth.uid()\n$$;\n-- 4. Create Policy\ncreate policy \"Team members can update team members if they belong to the team.\"\n  on members\n  for all using (\n    team_id in (\n      select get_teams_for_authenticated_user()\n    )\n  );\n```\nVerifying email domains\nPostgres has a function `right(string, n)` that returns the rightmost n characters of a string.\nYou could use this to match staff member's email domains.\n```sql\n-- 1. Create table\ncreate table leaderboard (\n  id uuid references auth.users,\n  high_score bigint\n);\n-- 2. Enable RLS\nalter table leaderboard\n  enable row level security;\n-- 3. Create Policy\ncreate policy \"Only Blizzard staff can update leaderboard\"\n  on leaderboard\n  for update using (\n    right(auth.jwt() ->> 'email', 13) = '@blizzard.com'\n  );\n```\nTime to live for rows\nPolicies can also be used to implement TTL or time to live feature that you see in Instagram stories or Snapchat.\nIn the following example, rows of `stories` table are available only if they have been created within the last 24 hours.\n```sql\n-- 1. Create table\ncreate table if not exists stories (\n  id uuid not null primary key DEFAULT uuid_generate_v4(),\n  created_at timestamp with time zone default timezone('utc' :: text, now()) not null,\n  content text not null\n);\n-- 2. Enable RLS\nalter table stories\n  enable row level security;\n-- 3. Create Policy\ncreate policy \"Stories are live for a day\"\n  on stories\n  for select using (\n    created_at > (current_timestamp - interval '1 day')\n  );\n```\nAdvanced policies\nUse the full power of SQL to build extremely advanced rules.\nIn this example, we will create a `posts` and `comments` tables and then create a policy that depends on another policy.\n(In this case, the comments policy depends on the posts policy.)\n```sql\ncreate table posts (\n  id            serial    primary key,\n  creator_id    uuid      not null     references auth.users(id),\n  title         text      not null,\n  body          text      not null,\n  publish_date  date      not null     default now(),\n  audience      uuid[]    null -- many to many table omitted for brevity\n);\ncreate table comments (\n  id            serial    primary key,\n  post_id       int       not null     references posts(id)  on delete cascade,\n  user_id       uuid      not null     references auth.users(id),\n  body          text      not null,\n  comment_date  date      not null     default now()\n);\ncreate policy \"Creator can see their own posts\"\non posts\nfor select\nusing (\n  auth.uid() = posts.creator_id\n);\ncreate policy \"Logged in users can see the posts if they belong to the post 'audience'.\"\non posts\nfor select\nusing (\n  auth.uid() = any (posts.audience)\n);\ncreate policy \"Users can see all comments for posts they have access to.\"\non comments\nfor select\nusing (\n  exists (\n    select 1 from posts\n    where posts.id = comments.post_id\n  )\n);\n```\nTips\nEnable Realtime for database tables\nRealtime server broadcasts database changes to authorized users depending on your Row Level Security (RLS) policies.\nWe recommend that you enable row level security and set row security policies on tables that you add to the publication.\nHowever, you may choose to disable RLS on a table and have changes broadcast to all connected clients.\n```sql\n/*\n * REALTIME SUBSCRIPTIONS\n * Realtime enables listening to any table in your public schema.\n /\nbegin;\n  -- remove the realtime publication\n  drop publication if exists supabase_realtime;\n-- re-create the publication but don't enable it for any tables\n  create publication supabase_realtime;\ncommit;\n-- add a table to the publication\nalter publication supabase_realtime add table products;\n-- add other tables to the publication\nalter publication supabase_realtime add table posts;\n```\nYou don't have to use policies\nYou can also put your authorization rules in your middleware, similar to how you would create security rules with any other `backend <-> middleware <-> frontend` architecture.\nPolicies are a tool. In the case of \"serverless/Jamstack\" setups, they are especially effective because you don't have to deploy any middleware at all.\nHowever, if you want to use another authorization method for your applications, that's also fine. Supabase is \"just Postgres\", so if your application\nworks with Postgres, then it also works with Supabase.\nTip: Make sure to enable RLS for all your tables, so that your tables are inaccessible. Then use the \"Service\" which we provide, which is designed to bypass RLS.\nNever use a service key on the client\nSupabase provides special \"Service\" keys, which can be used to bypass all RLS.\nThese should never be used in the browser or exposed to customers, but they are useful for administrative tasks.\nTesting policies\nTo test policies on the database itself (i.e., from the SQL Editor or from `psql`) without switching to your frontend and logging in as different users, you can utilize the following helper SQL procedures (credits):\n```sql\ngrant anon, authenticated to postgres;\ncreate or replace procedure auth.login_as_user (user_email text)\n    language plpgsql\n    as $$\ndeclare\n    auth_user auth.users;\nbegin\n    select\n        * into auth_user\n    from\n        auth.users\n    where\n        email = user_email;\n    execute format('set request.jwt.claim.sub=%L', (auth_user).id::text);\n    execute format('set request.jwt.claim.role=%I', (auth_user).role);\n    execute format('set request.jwt.claim.email=%L', (auth_user).email);\n    execute format('set request.jwt.claims=%L', json_strip_nulls(json_build_object('app_metadata', (auth_user).raw_app_meta_data))::text);\n\n\n```raise notice '%', format( 'set role %I; -- logging in as %L (%L)', (auth_user).role, (auth_user).id, (auth_user).email);\nexecute format('set role %I', (auth_user).role);\n```\n\n\nend;\n$$;\ncreate or replace procedure auth.login_as_anon ()\n    language plpgsql\n    as $$\nbegin\n    set request.jwt.claim.sub='';\n    set request.jwt.claim.role='';\n    set request.jwt.claim.email='';\n    set request.jwt.claims='';\n    set role anon;\nend;\n$$;\ncreate or replace procedure auth.logout ()\n    language plpgsql\n    as $$\nbegin\n    set request.jwt.claim.sub='';\n    set request.jwt.claim.role='';\n    set request.jwt.claim.email='';\n    set request.jwt.claims='';\n    set role postgres;\nend;\n$$;\n```\nTo switch to a given user (by email), use `call auth.login_as_user('my@email.com');`. You can also switch to the `anon` role using `call auth.login_as_anon();`. When you are done, use `call auth.logout();` to return yourself to the `postgres` role.\nThese procedures can also be used for writing pgTAP unit tests for policies.\n\nClick here to see an example `psql` interaction using this.\n\nThis example shows that the `public.profiles` table from the tutorial example can indeed be updated by the `postgres` role and the owner of the row but not from `anon` connections:\n\n```shell\npostgres=> select id, email from auth.users;\n                  id                  |       email\n--------------------------------------+-------------------\n d4f0aa86-e6f6-41d1-bd32-391f077cf1b9 | user1@example.com\n 15d6811a-16ee-4fa2-9b18-b63085688be4 | user2@example.com\n 4e1010bb-eb37-4a4d-a05a-b0ee315c9d56 | user3@example.com\n(3 rows)\n\npostgres=> table public.profiles;\n                  id                  | updated_at | username | full_name | avatar_url | website\n--------------------------------------+------------+----------+-----------+------------+---------\n d4f0aa86-e6f6-41d1-bd32-391f077cf1b9 |            | user1    | User 1    |            |\n 15d6811a-16ee-4fa2-9b18-b63085688be4 |            | user2    | User 2    |            |\n 4e1010bb-eb37-4a4d-a05a-b0ee315c9d56 |            | user3    | User 3    |            |\n(3 rows)\n\npostgres=> call auth.login_as_anon();\nCALL\npostgres=> update public.profiles set updated_at=now();\nUPDATE 0 -- anon users cannot update any profile but see all of them\npostgres=> table public.profiles;\n                  id                  | updated_at | username | full_name | avatar_url | website\n--------------------------------------+------------+----------+-----------+------------+---------\n d4f0aa86-e6f6-41d1-bd32-391f077cf1b9 |            | user1    | User 1    |            |\n 15d6811a-16ee-4fa2-9b18-b63085688be4 |            | user2    | User 2    |            |\n 4e1010bb-eb37-4a4d-a05a-b0ee315c9d56 |            | user3    | User 3    |            |\n(3 rows)\n\npostgres=> call auth.logout();\nCALL\npostgres=> call auth.login_as_user('user1@example.com');\nNOTICE:  set role authenticated; -- logging in as 'd4f0aa86-e6f6-41d1-bd32-391f077cf1b9' ('user1@example.com')\nCALL\npostgres=> update public.profiles set updated_at=now();\nUPDATE 1 -- authenticated users can update their own profile and see all of them\npostgres=> table public.profiles;\n                  id                  |          updated_at           | username | full_name | avatar_url | website\n--------------------------------------+-------------------------------+----------+-----------+------------+---------\n 15d6811a-16ee-4fa2-9b18-b63085688be4 |                               | user1    | User 1    |            |\n 4e1010bb-eb37-4a4d-a05a-b0ee315c9d56 |                               | user2    | User 2    |            |\n d4f0aa86-e6f6-41d1-bd32-391f077cf1b9 | 2023-02-18 21:39:16.204612+00 | user3    | User 3    |            |\n(3 rows)\n\npostgres=> call auth.logout();\nCALL\npostgres=> update public.profiles set updated_at=now();\nUPDATE 3 -- the 'postgres' role can update and see all profiles\npostgres=> table public.profiles;\n                  id                  |          updated_at           | username | full_name | avatar_url | website\n--------------------------------------+-------------------------------+----------+-----------+------------+---------\n 15d6811a-16ee-4fa2-9b18-b63085688be4 | 2023-02-18 21:40:08.216324+00 | user1    | User 1    |            |\n 4e1010bb-eb37-4a4d-a05a-b0ee315c9d56 | 2023-02-18 21:40:08.216324+00 | user2    | User 2    |            |\n d4f0aa86-e6f6-41d1-bd32-391f077cf1b9 | 2023-02-18 21:40:08.216324+00 | user3    | User 3    |            |\n(3 rows)\n\n```\n\n\nDeprecated features\nWe have deprecate some functions to ensure better performance and extensibilty of RLS policies.\n`auth.role()`\n\nDeprecated: The `auth.role()` function has been deprecated in favour of using the `TO` field, natively supported within Postgres.\n\n```sql\n-- DEPRECATED\ncreate policy \"Public profiles are viewable by everyone.\"\non profiles for select using (\n  auth.role() = 'authenticated' or auth.role() = 'anon'\n);\n-- RECOMMENDED\ncreate policy \"Public profiles are viewable by everyone.\"\non profiles for select\nto authenticated, anon\nusing (\n  true\n);\n```\n`auth.email()`\n\nDeprecated. Use `auth.jwt() ->> 'email'` instead.\n\nReturns the email of the user making the request.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Benefits",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport { IconPanel } from 'ui'\nimport Link from 'next/link'\nimport { SocialLoginItems } from '~/components/Navigation/NavigationMenu/NavigationMenu.constants'\nexport const meta = {\n  title: 'Social Login',\n  description: 'Logging in with social accounts',\n}\nSocial Login (OAuth) is an open standard for authentication that allows users to log in to one website or application using their credentials from another website or application.\nIt is a way for users to grant third-party applications access to their online accounts without sharing their passwords.\nOAuth is commonly used for things like logging in to a social media account from a third-party app. It is a secure and convenient way to authenticate users and share information between applications.\nBenefits\nThere are several reasons why you might want to add social login to your applications:\n\n\nImproved user experience: Users can register and log in to your application using their existing social media accounts, which can be faster and more convenient than creating a new account from scratch. This makes it easier for users to access your application, improving their overall experience.\n\n\nBetter user engagement: You can access additional data and insights about your users, such as their interests, demographics, and social connections. This can help you tailor your content and marketing efforts to better engage with your users and provide a more personalized experience.\n\n\nIncreased security: Social login can improve the security of your application by leveraging the security measures and authentication protocols of the social media platforms that your users are logging in with. This can help protect against unauthorized access and account takeovers.\n\n\nSet up a social provider with Supabase Auth\nSupabase supports a suite of social providers. Follow these guides to configure a social provider for your platform.\n\n  {SocialLoginItems.map((item) => (  \n    \n\n\n          {item.description}\n        \n\n    \n))}\n\n\nProvider Tokens\nOnce the OAuth flow completes, Supabase Auth will sign your user in. You will receive a copy of the provider token used in the OAuth flow in case you need to use it further. For example, you can use the Google provider token to access Google APIs on behalf of your user.\nProvider tokens are intentionally not stored in your project's database, however. This is because provider tokens give access to potentially sensitive user data in third-party systems. Different applications have different needs, and one application's OAuth scopes may be significantly more permissive than another. If you do want to use the provider token outside of the browser that completed the OAuth flow, you will have to send it manually to a secure server under your control.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-mfa.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-mfa',\n  title: 'Multi-Factor Authentication',\n  description:\n    'Add an additional layer of security to your apps with Supabase Auth multi-factor authentication.',\n}\nMulti-factor authentication (MFA), sometimes called two-factor\nauthentication (2FA), adds an additional layer of security to your\napplication by verifying their identity through\nadditional verification steps.\nIt is considered a best practice to use MFA for your applications.\nUsers with weak passwords or compromised social login accounts are\nprone to malicious account takeovers. These can be prevented with\nMFA because they require the user to provide proof of\nboth of these:\n\nSomething they know.\n  Password, or access to a social-login account.\nSomething they have.\n  Access to an authenticator app (a.k.a. TOTP), mobile phone or recovery code.\n\nOverview\nSupabase Auth implements only Time-based One Time Factor(TOTP) multi-factor authentication. This type of\nmulti-factor authentication uses a timed one-time password generated from an\nauthenticator app in the control of users.\nApplications using MFA require two important flows:\n\nEnrollment flow.\n   This lets users set up and control MFA in your app.\nAuthentication flow.\n   This lets users sign in using any factors after the conventional login step.\n\nSupabase Auth provides:\n\nEnrollment API - build rich user interfaces for adding and removing factors.\nChallenge and Verify APIs - securely verify that the user has access to a factor.\nList Factors API - build rich user interfaces for signing in with additional factors.\n\nBelow is a flow chart illustrating how these APIs work together to enable MFA\nfeatures in your app.\ngraph TD;\n  InitS((Setup flow)) --> SAAL1[/Session is AAL1/] --> Enroll[Enroll API] --> ShowQR[Show QR code] --> Scan([User: Scan QR code in authenticator]) --> Enter([User: Enter code]) --> Verify[Challenge + Verify API] --> Check{{Is code correct?}}\n  Check -->|Yes| AAL2[/Upgrade to AAL2/] --> Done((Done))\n  Check -->|No| Enter\n  InitA((Login flow)) --> SignIn([User: Sign-in]) --> AAL1[/Upgrade to AAL1/] --> ListFactors[List Factors API]\n  ListFactors -->|1 or more factors| OpenAuth([User: Open authenticator]) --> Enter\n  ListFactors -->|0 factors| Setup[[Setup flow]]}\n/>\nThese sets of APIs let you control the MFA experience that works for you. You\ncan create flows where MFA is optional, mandatory for all or only specific\ngroups of users.\nOnce users have enrolled or signed-in with a factor, Supabase Auth adds\nadditional metadata to the user's access token (JWT) that your application can\nuse to allow or deny access.\nThis information is represented by an Authenticator Assurance\nLevel, a\nstandard measure about the assurance Supabase Auth has of the user's identity\nfor that particular session. There are two levels recognized today:\n\nAssurance Level 1: `aal1`\n   Means that the user's identity was verified using a conventional login method\n   such as email+password, magic link, one-time password, phone auth or social\n   login.\nAssurance Level 2: `aal2`\n   Means that the user's identity was additionally verified using at least one\n   second factor, such as a TOTP code.\n\nThis assurance level is encoded in the `aal` claim in the JWT associated with\nthe user. By decoding this value you can create custom authorization rules in\nyour frontend, backend and database that will enforce the MFA policy that works\nfor your application. JWTs without an `aal` claim are at the `aal1` level.\nAdding to your app\nAdding MFA to your app involves these four steps:\n\nAdd enrollment flow.\n   You need to provide a UI within your app that your users will be able to set-up\n   MFA in. You can add this right after sign-up, or as part of a separate flow in\n   the settings portion of your app.\nAdd unenrollment flow.\n   You need to support a UI through which users can see existing devices and unenroll\n   devices which are no longer relevant.\nAdd challenge step to login.\n   If a user has set-up MFA, your app's login flow needs to present a challenge\n   screen to the user asking them to prove they have access to the additional\n   factor.\nEnforce rules for MFA logins.\n   Once your users have a way to enroll and log in with MFA, you need to enforce\n   authorization rules across your app: on the frontend, backend, API servers or\n   Row-Level Security policies.\n\nAdd enrollment flow\nAn enrollment flow provides a UI for users to set up additional authentication factors.\nMost applications add the enrollment flow in two places within their app:\n\nRight after login or sign up.\n   This lets users quickly set up MFA immediately after they log in or create an\n   account. We recommend encouraging all users to set up MFA if that makes sense\n   for your application. Many applications offer this as an opt-in step in an\n   effort to reduce onboarding friction.\nFrom within a settings page.\n   Allows users to set up, disable or modify their MFA settings.\n\nWe recommend building one generic flow that you can reuse in both cases with\nminor modifications.\nEnrolling a factor for use with MFA takes three steps:\n\nCall `supabase.auth.mfa.enroll()`.\n   This method returns a QR code and a secret. Display the QR\n   code to the user and ask them to scan it with their authenticator application.\n   If they are unable to scan the QR code, show the secret in plain text which\n   they can type or paste into their authenticator app.\nCalling the `supabase.auth.mfa.challenge()` API.\n   This prepares Supabase Auth to accept a verification code from the user\n   and returns a challenge ID.\nCalling the `supabase.auth.mfa.verify()` API.\n   This verifies that the user has indeed added the secret from step (1) into\n   their app and is working correctly. If the verification succeeds, the factor\n   immediately becomes active for the user account. If not, you should repeat\n   steps 2 and 3.\n\nExample: React\nBelow is an example that creates a new `EnrollMFA` component that illustrates\nthe important pieces of the MFA enrollment flow.\n\nWhen the component appears on screen, the `supabase.auth.mfa.enroll()` API is\n  called once to start the process of enrolling a new factor for the current\n  user.\nThis API returns a QR code in the SVG format, which is shown on screen using\n  a normal `<img>` tag by encoding the SVG as a data URL.\nOnce the user has scanned the QR code with their authenticator app, they\n  should enter the verification code within the `verifyCode` input field and\n  click on `Enable`.\nA challenge is created using the `supabase.auth.mfa.challenge()` API and the\n  code from the user is submitted for verification using the\n  `supabase.auth.mfa.verify()` challenge.\n`onEnabled` is a callback that notifies the other components that enrollment\n  has completed.\n`onCancelled` is a callback that notifies the other components that the user\n  has clicked the `Cancel` button.\n\n```tsx\n/**\n * EnrollMFA shows a simple enrollment dialog. When shown on screen it calls\n * the`enroll`API. Each time a user clicks the Enable button it calls the\n *`challenge`and`verify`APIs to check if the code provided by the user is\n * valid.\n * When enrollment is successful, it calls`onEnrolled`. When the user clicks\n * Cancel the`onCancelled` callback is called.\n */\nexport function EnrollMFA({\n  onEnrolled,\n  onCancelled,\n}: {\n  onEnrolled: () => void\n  onCancelled: () => void\n}) {\n  const [factorId, setFactorId] = useState('')\n  const [qr, setQR] = useState('') // holds the QR code image SVG\n  const [verifyCode, setVerifyCode] = useState('') // contains the code entered by the user\n  const [error, setError] = useState('') // holds an error message\nconst onEnableClicked = () => {\n    setError('')\n    ;(async () => {\n      const challenge = await supabase.auth.mfa.challenge({ factorId })\n      if (challenge.error) {\n        setError(challenge.error.message)\n        throw challenge.error\n      }\n\n\n```  const challengeId = challenge.data.id\n\n  const verify = await supabase.auth.mfa.verify({\n    factorId,\n    challengeId,\n    code: verifyCode,\n  })\n  if (verify.error) {\n    setError(verify.error.message)\n    throw verify.error\n  }\n\n  onEnrolled()\n})()\n```\n\n\n}\nuseEffect(() => {\n    ;(async () => {\n      const { data, error } = await supabase.auth.mfa.enroll({\n        factorType: 'totp',\n      })\n      if (error) {\n        throw error\n      }\n\n\n```  setFactorId(data.id)\n\n  // Supabase Auth returns an SVG QR code which you can convert into a data\n  // URL that you can place in an <img> tag.\n  setQR(data.totp.qr_code)\n})()\n```\n\n\n}, [])\nreturn (\n    <>\n      {error && {error}}\n      \n setVerifyCode(e.target.value.trim())}\n      />\n      \n\n\n  )\n}\n```\nAdd unenrollment flow\nAn unenrollment flow provides a UI for users to manage and unenroll factors linked to their accounts.\nMost applications do so via a factor management page where users can view and unlink selected factors.\nWhen a user unenrolls a factor, call `supabase.auth.mfa.unenroll()` with the ID of the factor.\nFor example, call `supabase.auth.mfa.unenroll({factorId: \"d30fd651-184e-4748-a928-0a4b9be1d429\"})` to unenroll a factor with ID `d30fd651-184e-4748-a928-0a4b9be1d429`.\nExample: React\nBelow is an example that creates a new `UnenrollMFA` component that illustrates\nthe important pieces of the MFA enrollment flow. Note that users can only unenroll a factor after completing the enrollment flow and obtaining\nan `aal2` JWT claim.Here are some points of note:\n\nWhen the component appears on screen, the `supabase.auth.mfa.listFactors()` endpoint\n  fetches all existing factors together with their details.\nThe existing factors for a user are displayed in a table.\nOnce the user has selected a factor to unenroll, they can type in the factorId and click Unenroll\n  which creates a confirmation modal.\n\n\nUnenrolling a factor will downgrade the assurance level from `aal2` to `aal1` only after the refresh interval has lapsed.\nFor an immediate downgrade from `aal2` to `aal1` after enrolling one will need to manually call `refreshSession()`\n\n```tsx\n/*\n * UnenrollMFA shows a simple table with the list of factors together with a button to unenroll.\n * When a user types in the factorId of the factor that they wish to unenroll and clicks unenroll\n * the corresponding factor will be unenrolled.\n /\nexport function UnenrollMFA() {\n  const [factorId, setFactorId] = useState('')\n  const [factors, setFactors] = useState([])\n  const [error, setError] = useState('') // holds an error message\nuseEffect(() => {\n    ;(async () => {\n      const { data, error } = await supabase.auth.mfa.listFactors()\n      if (error) {\n        throw error\n      }\n\n\n```  setFactors(data.totp)\n})()\n```\n\n\n}, [])\nreturn (\n    <>\n      {error && {error}}\n      \n\nFactor ID\nFriendly Name\nFactor Status\n\n       {factors.map(factor => (\n        \n{factor.id}\n{factor.friendly_name}\n{factor.factor_type}\n{factor.status}\n\n      ))}\n      \n setFactorId(e.target.value.trim())}\n      />\n       supabase.auth.mfa.unenroll({factorId})}>Unenroll\n\n  )\n}\n```\nAdd challenge step to login\nOnce a user has logged in via their first factor (email+password, magic link,\none time password, social login...) you need to perform a check if any\nadditional factors need to be verified.\nThis can be done by using the\n`supabase.auth.mfa.getAuthenticatorAssuranceLevel()` API. When the user signs\nin and is redirected back to your app, you should call this method to extract\nthe user's current and next authenticator assurance level (AAL).\nTherefore if you receive a `currentLevel` which is `aal1` but a `nextLevel`\nof `aal2`, the user should be given the option to go through MFA.\nBelow is a table that explains the combined meaning.\n| Current Level | Next Level | Meaning                                                  |\n| ------------: | :--------- | :------------------------------------------------------- |\n|        `aal1` | `aal1`     | User does not have MFA enrolled.                         |\n|        `aal1` | `aal2`     | User has an MFA factor enrolled but has not verified it. |\n|        `aal2` | `aal2`     | User has verified their MFA factor.                      |\n|        `aal2` | `aal1`     | User has disabled their MFA factor. (Stale JWT.)         |\nExample: React\nAdding the challenge step to login depends heavily on the architecture of your\napp. However, a fairly common way to structure React apps is to have a large\ncomponent (often named `App`) which contains most of the authenticated\napplication logic.\nThis example will wrap this component with logic that will show an MFA\nchallenge screen if necessary, before showing the full application. This is\nillustrated in the `AppWithMFA` example below.\n```tsx\nfunction AppWithMFA() {\n  const [readyToShow, setReadyToShow] = useState(false)\n  const [showMFAScreen, setShowMFAScreen] = useState(false)\nuseEffect(() => {\n    ;(async () => {\n      try {\n        const { data, error } = await supabase.auth.mfa.getAuthenticatorAssuranceLevel()\n        if (error) {\n          throw error\n        }\n\n\n```    console.log(data)\n\n    if (data.nextLevel === 'aal2' && data.nextLevel !== data.currentLevel) {\n      setShowMFAScreen(true)\n    }\n  } finally {\n    setReadyToShow(true)\n  }\n})()\n```\n\n\n}, [])\nif (readyToShow) {\n    if (showMFAScreen) {\n      return \n    }\n\n\n```return <App />\n```\n\n\n}\nreturn <>\n}\n```\n\n`supabase.auth.mfa.getAuthenticatorAssuranceLevel()` does return a promise.\n  Don't worry, this is a very fast method (microseconds) as it rarely uses the\n  network.\n`readyToShow` only makes sure the AAL check completes before showing any\n  application UI to the user.\nIf the current level can be upgraded to the next one, the MFA screen is\n  shown.\nOnce the challenge is successful, the `App` component is finally rendered on\n  screen.\n\nBelow is the component that implements the challenge and verify logic.\n```tsx\nfunction AuthMFA() {\n  const [verifyCode, setVerifyCode] = useState('')\n  const [error, setError] = useState('')\nconst onSubmitClicked = () => {\n    setError('')\n    ;(async () => {\n      const factors = await supabase.auth.mfa.listFactors()\n      if (factors.error) {\n        throw factors.error\n      }\n\n\n```  const totpFactor = factors.data.totp[0]\n\n  if (!totpFactor) {\n    throw new Error('No TOTP factors found!')\n  }\n\n  const factorId = totpFactor.id\n\n  const challenge = await supabase.auth.mfa.challenge({ factorId })\n  if (challenge.error) {\n    setError(challenge.error.message)\n    throw challenge.error\n  }\n\n  const challengeId = challenge.data.id\n\n  const verify = await supabase.auth.mfa.verify({\n    factorId,\n    challengeId,\n    code: verifyCode,\n  })\n  if (verify.error) {\n    setError(verify.error.message)\n    throw verify.error\n  }\n})()\n```\n\n\n}\nreturn (\n    <>\n      Please enter the code from your authenticator app.\n      {error && {error}}\n       setVerifyCode(e.target.value.trim())}\n      />\n      \n\n  )\n}\n```\n\nYou can extract the available MFA factors for the user by calling\n  `supabase.auth.mfa.listFactors()`. Don't worry this method is also very quick\n  and rarely uses the network.\nIf `listFactors()` returns more than one factor (or of a different type) you\n  should present the user with a choice. For simplicity this is not shown in\n  the example.\nEach time the user presses the \"Submit\" button a new challenge is created for\n  the chosen factor (in this case the first one) and it is immediately\n  verified. Any errors are displayed to the user.\nOn successful verification, the client library will refresh the session in\n  the background automatically and finally call the `onSuccess` callback, which\n  will show the authenticated `App` component on screen.\n\nEnforce rules for MFA logins\nAdding MFA to your app's UI does not in-and-of-itself offer a higher level of\nsecurity to your users. You also need to enforce the MFA rules in your\napplication's database, APIs and server-side rendering.\nDepending on your application's needs, there are three ways you can choose to\nenforce MFA.\n\nEnforce for all users (new and existing).\n   Any user account will have to enroll MFA to continue using your app.\n   The application will not allow access without going through MFA first.\nEnforce for new users only.\n   Only new users will be forced to enroll MFA, while old users will be encouraged\n   to do so.\n   The application will not allow access for new users without going through MFA\n   first.\nEnforce only for users that have opted-in.\n   Users that want MFA can enroll in it and the application will not allow access\n   without going through MFA first.\n\nDatabase\nYour app should sufficiently deny or allow access to tables or rows based on\nthe user's current and possible authenticator levels.\n\nPostgreSQL has two types of policies: permissive and restrictive. This guide\nuses restrictive policies. Make sure you don't omit the `as restrictive`\nclause.\n\nEnforce for all users (new and existing)\nIf your app falls under this case, this is a template Row Level Security policy\nyou can apply to all your tables:\n`sql\ncreate policy \"Policy name.\"\n  on table_name\n  as restrictive\n  to authenticated\n  using (auth.jwt()->>'aal' = 'aal2');`\n\nHere the policy will not accept any JWTs with an `aal` claim other than\n  `aal2`, which is the highest authenticator assurance level.\nUsing `as restrictive` ensures this policy will restrict all commands on the\n  table regardless of other policies!\n\nEnforce for new users only\nIf your app falls under this case, the rules get more complex. User accounts\ncreated past a certain timestamp must have a `aal2` level to access the\ndatabase.\n`sql\ncreate policy \"Policy name.\"\n  on table_name\n  as restrictive -- very important!\n  to authenticated\n  using\n    (array[auth.jwt()->>'aal'] <@ (\n       select\n         case\n           when created_at >= '2022-12-12T00:00:00Z' then array['aal2']\n           else array['aal1', 'aal2']\n         end as aal\n       from auth.users\n       where auth.uid() = id));`\n\nThe policy will accept both `aal1` and `aal2` for users with a `created_at`\n  timestamp prior to 12th December 2022 at 00:00 UTC, but will only accept\n  `aal2` for all other timestamps.\nThe `<@` operator is PostgreSQL's \"contained in\"\n  operator.\nUsing `as restrictive` ensures this policy will restrict all commands on the\n  table regardless of other policies!\n\nEnforce only for users that have opted-in\nUsers that have enrolled MFA on their account are expecting that your\napplication only works for them if they've gone through MFA.\n`sql\ncreate policy \"Policy name.\"\n  on table_name\n  as restrictive -- very important!\n  to authenticated\n  using (\n    array[auth.jwt()->>'aal'] <@ (\n      select\n          case\n            when count(id) > 0 then array['aal2']\n            else array['aal1', 'aal2']\n          end as aal\n        from auth.mfa_factors\n        where auth.uid() = user_id and status = 'verified'\n    ));`\n\nThe policy will only accept only `aal2` when the user has at least one MFA\n  factor verified.\nOtherwise, it will accept both `aal1` and `aal2`.\nThe `<@` operator is PostgreSQL's \"contained in\"\n  operator.\nUsing `as restrictive` ensures this policy will restrict all commands on the\n  table regardless of other policies!\n\nServer-Side Rendering\n\nWhen using the Supabase JavaScript library in a server-side rendering context,\nmake sure you always create a new object for each request! This will prevent\nyou from accidentally rendering and serving content belonging to different\nusers.\n\nIt is possible to enforce MFA on the Server-Side Rendering level. However, this\ncan be tricky do to well.\nYou can use the `supabase.auth.mfa.getAuthenticatorAssuranceLevel()` and\n`supabase.auth.mfa.listFactors()` APIs to identify the AAL level of the session\nand any factors that are enabled for a user, similar to how you would use these\non the browser.\nHowever, encountering a different AAL level on the server may not actually be a\nsecurity problem. Consider these likely scenarios:\n\nUser signed-in with a conventional method but closed their tab on the MFA\n   flow.\nUser forgot a tab open for a very long time. (This happens more often than\n   you might imagine.)\nUser has lost their authenticator device and is confused about the next\n   steps.\n\nWe thus recommend you redirect users to a page where they can authenticate\nusing their additional factor, instead of rendering a HTTP 401 Unauthorized or\nHTTP 403 Forbidden content.\nAPIs\nIf your application uses the Supabase Database, Storage or Edge Functions, just\nusing Row Level Security policies will give you sufficient protection. In the\nevent that you have other APIs that you wish to protect, follow these general\nguidelines:\n\nUse a good JWT verification and parsing library for your language.\n   This will let you securely parse JWTs and extract their claims.\nRetrieve the `aal` claim from the JWT and compare its value according to\n   your needs.\n   If you've encountered an AAL level that can be increased, ask the user to\n   continue the login process instead of logging them out.\nUse the `https://<project-ref>.supabase.co/rest/v1/auth/factors` REST\n   endpoint to identify if the user has enrolled any MFA factors.\n   Only `verified` factors should be acted upon.\n\nFrequently asked questions\nWhy is there a challenge and verify API when challenge does not do much?\nTOTP is not going to be the only MFA factor Supabase Auth is going to support\nin the future. By separating out the challenge and verify steps, we're making\nthe library forward compatible with new factors we may add in the future --\nsuch as SMS or WebAuthn. For example, for SMS the `challenge` endpoint would\nactually send out the SMS with the authentication code.\nWhat's inside the QR code?\nThe TOTP QR code encodes a URI with the `otpauth` scheme. It was initially\nintroduced by Google\nAuthenticator\nbut is now universally accepted by all authenticator apps.\nHow do I check when a user went through MFA?\nAccess tokens issued by Supabase Auth contain an `amr` (Authentication Methods\nReference) claim. It is an array of objects that indicate what authentication\nmethods the user has used so far.\nFor example, the following structure describes a user that first signed in with\na password-based method, and then went through TOTP MFA 2 minutes and 12\nseconds later. The entries are ordered most recent method first!\n`json\n{\n  \"amr\": [\n    {\n      \"method\": \"totp\",\n      \"timestamp\": 1666086056\n    },\n    {\n      \"method\": \"password\",\n      \"timestamp\": 1666085924\n    }\n  ]\n}`\nUse the `supabase.auth.getAuthenticatorAssuranceLevel()` method to get easy\naccess to this information in your browser app.\nYou can use this PostgreSQL snippet in RLS policies, too:\n`sql\njson_query_path(auth.jwt(), '$.amr[0]')`\n\njson_query_path(json, path)\n  is a function that allows access to elements in a JSON object according to a\n  SQL/JSON\n  path.\n`$.amr[0]` is a SQL/JSON path expression that fetches the most recent\n  authentication method in the JWT.\n\nOnce you have extracted the most recent entry in the array, you can compare the\n`method` and `timestamp` to enforce stricter rules.\nCurrently recognized methods are:\n\n`password` - any password based sign in.\n`otp` - any one-time password based sign in (email code, SMS code, magic\n  link).\n`oauth` - any OAuth based sign in (social login).\n`totp` - a TOTP additional factor.\n\nThis list will expand in the future.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Understanding the authentication flow",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/server-side-rendering.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'server-side-rendering',\n  title: 'Server-Side Rendering',\n  description: 'Render pages with user information on the server.',\n}\nSingle-page apps with server-side rendering (SSR) is a popular way to optimize rendering\nperformance and leverage advanced caching strategies.\nSupabase Auth supports server-side rendering when you need access to user\ninformation, or your server needs to authorize API requests on behalf of your\nuser to render content.\nWhen a user authenticates with Supabase Auth, two pieces of information are\nissued by the server:\n\nAccess token in the form of a JWT.\nRefresh token which is a randomly generated string.\n\nMost Supabase projects have their auth server listening on\n`<project-ref>.supabase.co/auth/v1`, thus the access token and refresh token are\nset as `sb-access-token` and `sb-refresh-token` cookies on the\n`<project-ref>.supabase.co` domain.\n\nThese cookie names are for internal Supabase use only and may change without\nwarning. They are included in this guide for illustration purposes only.\n\nWeb browsers limit access to cookies across domains, consistent with the\nSame-Origin Policy\n(SOP).\nYour web application cannot access these cookies,\nnor will these cookies be sent to your application's server.\nUnderstanding the authentication flow\nWhen you call one of the `signIn` methods, the client library running in the\nbrowser sends the request to the Supabase Auth server. The Auth server determines\nwhether to verify a phone number, email and password combination, a Magic Link,\nor use a social login (if you have any setup in your project).\nUpon successful verification of the identity of the user, the Supabase Auth\nserver redirects the user back to your single-page app.\n\nYou can configure redirects URLs in the Supabase Dashboard. You can use wildcard match patterns\nlike `*` and `**` to allow redirects to different forms of URLs.\n\nThese redirect URLs have the following structure:\n`https://yourapp.com/...#access_token=<...>&refresh_token=<...>&...`\nThe first access and refresh tokens after a successful verification are\ncontained in the URL fragment (anything after the `#` sign) of the redirect\nlocation. This is intentional and not configurable.\nThe client libraries are designed to listen for this type of URL, extract\nthe access token, refresh token and some extra information from it, and finally\npersist it in local storage for further use by the library and your app.\n\nWeb browsers do not send the URL fragment to the server they're making the\nrequest to. Since you may not be hosting the single-page app on a server under\nyour direct control (such as on GitHub Pages or other freemium hosting\nproviders), we want to prevent hosting services from getting access to your\nuser's authorization credentials by default. Even if the server is under your\ndirect control, `GET` requests and their full URLs are often logged. This\napproach also avoids leaking credentials in request or access logs.\n\nBringing it together\nAs seen from the authentication flow, the initial request after successful\nlogin made by the browser to your app's server after user login does not\ncontain any information about the user. This is because first the client-side\nJavaScript library must run before it makes the access and refresh token\navailable to your server.\nIt is very important to make sure that the redirect route right after login\nworks without any server-side rendering. Other routes requiring authorization\ndo not have the same limitation, provided you send the access and refresh\ntokens to your server.\nThis is traditionally done by setting cookies. Here's an example you\ncan add to the root of your application:\n`typescript\nsupabase.auth.onAuthStateChange((event, session) => {\n  if (event === 'SIGNED_OUT' || event === 'USER_DELETED') {\n    // delete cookies on sign out\n    const expires = new Date(0).toUTCString()\n    document.cookie = `my-access-token=; path=/; expires=${expires}; SameSite=Lax; secure`\n    document.cookie = `my-refresh-token=; path=/; expires=${expires}; SameSite=Lax; secure`\n  } else if (event === 'SIGNED_IN' || event === 'TOKEN_REFRESHED') {\n    const maxAge = 100 * 365 * 24 * 60 * 60 // 100 years, never expires\n    document.cookie = `my-access-token=${session.access_token}; path=/; max-age=${maxAge}; SameSite=Lax; secure`\n    document.cookie = `my-refresh-token=${session.refresh_token}; path=/; max-age=${maxAge}; SameSite=Lax; secure`\n  }\n})`\nThis uses the standard\ndocument.cookie API\nto set cookies on all paths of your app's domain. All subsequent requests\nmade by the browser to your app's server include the `my-access-token` and\n`my-refresh-token` cookies (the names of the cookies and additional\nparameters can be changed).\nIn your server-side rendering code you can now access user and session\ninformation:\n```typescript\nconst refreshToken = req.cookies['my-refresh-token']\nconst accessToken = req.cookies['my-access-token']\nif (refreshToken && accessToken) {\n  await supabase.auth.setSession({\n    refresh_token: refreshToken,\n    access_token: accessToken,\n  })\n} else {\n  // make sure you handle this case!\n  throw new Error('User is not authenticated.')\n}\n// returns user information\nawait supabase.auth.getUser()\n```\nUse `setSession({ access_token, refresh_token })` instead of\n`setSession(refreshToken)` or `getUser(accessToken)` as refresh tokens or access tokens alone do not properly identify a user session.\nAccess tokens are valid only for a short amount of time.\nEven though refresh tokens are long-lived, there is no guarantee that a user\nhas an active session. They may have logged out and your application failed to\nremove the `my-refresh-token` cookie, or some other failure occurred that left\na stale refresh token in the browser. Furthermore, a refresh token can only be\nused a few seconds after it was first used. Only use a refresh token if the\naccess token is about to expire, which will avoid the introduction of difficult\nto diagnose logout bugs in your app.\nA good practice is to handle unauthorized errors by deferring rendering the\npage in the browser instead of in the server. Some user information is\ncontained in the access token though, so in certain cases, you may be able to\nuse this potentially stale information to render a page.\nFrequently Asked Questions\nNo session on the server side with Next.js route prefetching?\nWhen you use route prefetching in Next.js using `<Link href=\"/...\">` components or the `Router.push()` APIs can send server-side requests before the browser processes the access and refresh tokens. This means that those requests may not have any cookies set and your server code will render unauthenticated content.\nTo improve experience for your users, we recommend redirecting users to one specific page after sign-in that does not include any route prefetching from Next.js. Once the Supabase client library running in the browser has obtained the access and refresh tokens from the URL fragment, you can send users to any pages that use prefetching.\nHow do I make the cookies `HttpOnly`?\nThis is not necessary. Both the access token and refresh token are designed to\nbe passed around to different components in your application. The browser-based\nside of your application needs access to the refresh token to properly maintain\na browser session anyway.\nMy server is getting invalid refresh token errors. What's going on?\nIt is likely that the refresh token sent from the browser to your server is\nstale. Make sure the `onAuthStateChange` listener callback is free of bugs and\nis registered relatively early in your application's lifetime.\nWhen you receive this error on the server-side, try to defer\nrendering to the browser where the client library can access an up-to-date\nrefresh token and present the user with a better experience.\nShould I set a shorter `Max-Age` parameter on the cookies?\nThe `Max-Age` or `Expires` cookie parameters only control whether the browser\nsends the value to the server. Since a refresh token represents the\nlong-lived authentication session of the user on that browser, setting a short\n`Max-Age` or `Expires` parameter on the cookies only results in a degraded\nuser experience.\nThe only way to ensure that a user has logged out or their session has ended\nis to get the user's details with `getUser()`.\nWhat should I use for the `SameSite` property?\nMake sure you understand the behavior of the property in different\nsituations\nas some properties can degrade the user experience.\nA good default is to use `Lax` which sends cookies when users are\nnavigating to your site. Cookies typically require the `Secure` attribute,\nwhich only sends them over HTTPS. However, this can be a problem when\ndeveloping on `localhost`.\nCan I use server-side rendering with a CDN or cache?\nYes, but you need to be careful to include at least the refresh token cookie\nvalue in the cache key. Otherwise you may be accidentally serving pages with\ndata belonging to different users!\nAlso be sure you set proper cache control headers. We recommend invalidating\ncache keys every hour or less.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-github.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-github',\n  title: 'Login with GitHub',\n  description: 'Add GitHub OAuth to your Supabase project',\n}\nTo enable GitHub Auth for your project, you need to set up a GitHub OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up GitHub logins for your application consists of 3 parts:\n\nCreate and configure a GitHub OAuth App on GitHub\nAdd your GitHub OAuth keys to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nAccess your GitHub account\n\nGo to github.com.\nClick on `Sign In` at the top right to log in.\n\n\nCreate a GitHub Oauth App\nGo to the GitHub Developer Settings page:\n\nClick on your profile photo at the top right\nClick Settings near the bottom of the menu\nIn the left sidebar, click `Developer settings` (near the bottom)\nIn the left sidebar, click `OAuth Apps`\n\nFind your callback URL\n\nRegister a new OAuth application\n\nClick `Register a new application`. If you've created an app before, click `New OAuth App` here.\nIn `Application name`, type the name of your app.\nIn `Homepage URL`, type the full URL to your app's website.\nIn `Authorization callback URL`, type the callback URL of your app.\nEnter the URL in the `Valid OAuth Redirect URIs` box.\nClick `Save Changes` at the bottom right.\nClick `Register Application`.\n\nCopy your new OAuth credentials\n\nCopy and save your `Client ID`.\nClick `Generate a new client secret`.\nCopy and save your `Client secret`.\n\nEnter your GitHub credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `github` as the `provider`:\n`js\nasync function signInWithGitHub() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'github',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nGitHub Developer Settings\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-zoom.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-zoom',\n  title: 'Login with Zoom',\n  description: 'Add Zoom OAuth to your Supabase project',\n}\nTo enable Zoom Auth for your project, you need to set up a Zoom OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up Zoom logins for your application consists of 3 parts:\n\nCreate and configure a Zoom OAuth App on Zoom App Marketplace\nAdd your Zoom OAuth keys to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nAccess your Zoom Developer account\n\nGo to marketplace.zoom.us.\nClick on `Sign In` at the top right to log in.\n\n\nFind your callback URL\n\nCreate a Zoom Oauth App\n\nGo to marketplace.zoom.us.\nClick on `Sign In` at the top right to log in.\nClick `Build App` (from the dropdown Develop)\nIn the OAuth card, click `Create`\nType the name of your app\nChoose app type\nClick `Create`\n\nUnder `App credentials`\n\nCopy and save your `Client ID`.\nCopy and save your `Client secret`.\n\nUnder `Redirect URL for OAuth`\n\nPaste your `Callback URL`\nClick `Continue`\n\nEnter your Zoom credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `zoom` as the `provider`:\n`js\nasync function signInWithZoom() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'zoom',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nZoom App Marketplace\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-gitlab.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-gitlab',\n  title: 'Login with GitLab',\n  description: 'Add GitLab OAuth to your Supabase project',\n}\nTo enable GitLab Auth for your project, you need to set up a GitLab OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up GitLab logins for your application consists of 3 parts:\n\nCreate and configure a GitLab Application on GitLab\nAdd your GitLab Application keys to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nAccess your GitLab account\n\nGo to gitlab.com.\nClick on `Login` at the top right to log in.\n\n\nFind your callback URL\n\nCreate your GitLab Application\n\nClick on your `profile logo` (avatar) in the top-right corner.\nSelect `Edit profile`.\nIn the left sidebar, select Applications.\nEnter the name of the application.\nIn the `Redirect URI` box, type the callback URL of your app.\nCheck the box next to `Confidential` (make sure it is checked).\nCheck the scope named `read_user` (this is the only required scope).\nClick `Save Application` at the bottom.\nCopy and save your `Application ID` (`client_id`) and `Secret` (`client_secret`) which you'll need later.\n\nAdd your GitLab credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `gitlab` as the `provider`:\n`js\nasync function signInWithGitLab() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'gitlab',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nGitLab Account\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-bitbucket.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-bitbucket',\n  title: 'Login with Bitbucket',\n  description: 'Add Bitbucket OAuth to your Supabase project',\n}\nTo enable Bitbucket Auth for your project, you need to set up a BitBucket OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up Bitbucket logins for your application consists of 3 parts:\n\nCreate and configure a Bitbucket OAuth Consumer on Bitbucket\nAdd your Bitbucket OAuth Consumer keys to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nAccess your Bitbucket account\n\nGo to bitbucket.org.\nClick on `Login` at the top right to log in.\n\n\nFind your callback URL\n\nCreate a Bitbucket OAuth app\n\nClick on your profile icon at the bottom left\nClick on `All Workspaces`\nSelect a workspace and click on it to select it\nClick on `Settings` on the left\nClick on `OAuth consumers` on the left under `Apps and Features` (near the bottom)\nClick `Add Consumer` at the top\nEnter the name of your app under `Name`\nIn `Callback URL`, type the callback URL of your app\nCheck the permissions you need (Email, Read should be enough)\nClick `Save` at the bottom\nClick on your app name (the name of your new OAuth Consumer)\nCopy your `Key` (`client_key`) and `Secret` (`client_secret`) codes\n\nAdd your Bitbucket credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `bitbucket` as the `provider`:\n`js\nasync function signInWithBitbucket() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'bitbucket',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nBitbucket Account\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-twitter.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-twitter',\n  title: 'Login with Twitter',\n  description: 'Add Twitter OAuth to your Supabase project',\n}\nTo enable Twitter Auth for your project, you need to set up a Twitter OAuth application with elevated access and add the application credentials in the Supabase Dashboard.\nOverview\nSetting up Twitter logins for your application consists of 3 parts:\n\nCreate and configure a Twitter Project and App on the Twitter Developer Dashboard.\nAdd your Twitter `API Key` and `API Secret Key` to your Supabase Project.\nAdd the login code to your Supabase JS Client App.\n\nAccess your Twitter Developer account\n\nGo to developer.twitter.com.\nClick on `Sign in` at the top right to log in.\n\n\nFind your callback URL\n\nCreate a Twitter OAuth app\n\nClick `+ Create Project`.\nEnter your project name, click `Next`.\nSelect your use case, click `Next`.\nEnter a description for your project, click `Next`.\nEnter a name for your app, click `Complete`.\nCopy and save your `API Key` (this is your `client_id`).\nCopy and save your `API Secret Key` (this is your `client_secret`).\nAt the bottom, under `Next, setup your App` click the link `enable 3rd party authentication`.\nUnder `App Settings`, click on the gear icon next to your app name to go to `App Settings`.\nAt the bottom, next to `Authentication settings`, click `Edit`.\nTurn `Enable 3-legged OAuth` ON.\nTurn `Request email address from users` ON.\nEnter your `Callback URL`.\nEnter your `Website URL`.\nEnter your `Terms of service URL`.\nEnter your `Privacy policy URL`.\nClick `Save`.\n\nEnter your Twitter credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `twitter` as the `provider`:\n`js\nasync function signInWithTwitter() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'twitter',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nTwitter Developer Dashboard\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-discord.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-discord',\n  title: 'Login with Discord',\n  description: 'Add Discord OAuth to your Supabase project',\n}\nTo enable Discord Auth for your project, you need to set up a Discord Application and add the Application OAuth credentials to your Supabase Dashboard.\nOverview\nSetting up Discord logins for your application consists of 3 parts:\n\nCreate and configure a Discord Application Discord Developer Portal\nAdd your Discord OAuth Consumer keys to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nAccess your Discord account\n\nGo to discord.com.\nClick on `Login` at the top right to log in.\n\n\n\nOnce logged in, go to discord.com/developers.\n\n\nFind your callback URL\n\nCreate a Discord Application\n\nClick on `New Application` at the top right.\nEnter the name of your application and click `Create`.\nClick on `OAuth2` under `Settings` in the left side panel.\nClick `Add Redirect` under `Redirects`.\nType or paste your `callback URL` into the `Redirects` box.\nClick `Save Changes` at the bottom.\nCopy your `Client ID` and `Client Secret` under `Client information`.\n\nAdd your Discord credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `discord` as the `provider`:\n`js\nasync function signInWithDiscord() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'discord',\n  })\n}`\nIf your user is already signed in, Discord prompts the user again for authorization.\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nDiscord Account\nDiscord Developer Portal\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-notion.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-notion',\n  title: 'Login with Notion',\n  description: 'Add Notion OAuth to your Supabase project',\n}\nTo enable Notion Auth for your project, you need to set up a Notion Application and add the Application OAuth credentials to your Supabase Dashboard.\nOverview\nSetting up Notion logins for your application consists of 3 parts:\n\nCreate and configure a Notion Application Notion Developer Portal\nRetrieve your OAuth client ID and OAuth client secret and add them to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nCreate your notion integration\n\nGo to developers.notion.com.\nClick \"View my integrations\" and login.\n\n\n\nOnce logged in, go to notion.so/my-integrations and create a new integration.\nWhen creating your integration, ensure that you select \"Public integration\" under \"Integration type\" and \"Read user information including email addresses\" under \"Capabilities\".\nYou will need to add a redirect uri, see Add the redirect uri\nOnce you've filled in the necessary fields, click \"Submit\" to finish creating the integration.\n\n\nAdd the redirect URI\n\nAfter selecting \"Public integration\", you should see an option to add \"Redirect URIs\".\n\n\n\nAdd your Notion credentials into your Supabase Project\n\nOnce you've created your notion integration, you should be able to retrieve the \"OAuth client ID\" and \"OAuth client secret\" from the \"OAuth Domain and URIs\" tab.\n\n\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `notion` as the `provider`:\n`js\nasync function signInWithNotion() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'notion',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nNotion Account\nNotion Developer Portal\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-slack.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-slack',\n  title: 'Login with Slack',\n  description: 'Add Slack OAuth to your Supabase project',\n}\nTo enable Slack Auth for your project, you need to set up a Slack OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up Slack logins for your application consists of 3 parts:\n\nCreate and configure a Slack Project and App on the Slack Developer Dashboard.\nAdd your Slack `API Key` and `API Secret Key` to your Supabase Project.\nAdd the login code to your Supabase JS Client App.\n\nAccess your Slack Developer account\n\nGo to api.slack.com.\nClick on `Your Apps` at the top right to log in.\n\n\nFind your callback URL\n\nCreate a Slack OAuth app\n\nGo to api.slack.com.\nClick on `Create an App`\n\nUnder `Create an app...`:\n\nClick `From scratch`\nType the name of your app\nSelect your `Slack Workspace`\nClick `Create App`\n\nUnder `App Credentials`:\n\nCopy and save your newly-generated `Client ID`\nCopy and save your newly-generated `Client Secret`\nClick `Permissions`\n\nUnder `Redirect URLs`:\n\nClick `Add New Redirect URL`\nPaste your `Callback URL` then click `Add`\nClick `Save URLs`\n\nEnter your Slack credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `slack` as the `provider`:\n`js\nasync function signInWithSlack() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'slack',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nSlack Developer Dashboard\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-spotify.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-spotify',\n  title: 'Login with Spotify',\n  description: 'Add Spotify OAuth to your Supabase project',\n}\nTo enable Spotify Auth for your project, you need to set up a Spotify OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up Spotify logins for your application consists of 3 parts:\n\nCreate and configure a Spotify Project and App on the Spotify Developer Dashboard.\nAdd your Spotify `API Key` and `API Secret Key` to your Supabase Project.\nAdd the login code to your Supabase JS Client App.\n\nAccess your Spotify Developer account\n\nLog into Spotify\nAccess the Spotify Developer Dashboard\n\n\nFind your callback URL\n\nCreate a Spotify OAuth app\n\nLog into Spotify.\nGo to the Spotify Developer Dashboard\nClick `Create an App`\nType your `App name`\nType your `App description`\nCheck the box to agree with the `Developer TOS and Branding Guidelines`\nClick `Create`\nSave your `Client ID`\nSave your `Client Secret`\nClick `Edit Settings`\n\nUnder `Redirect URIs`:\n\nPaste your Supabase Callback URL in the box\nClick `Add`\nClick `Save` at the bottom\n\nEnter your Spotify credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `spotify` as the `provider`:\n`js\nasync function signInWithSpotify() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'spotify',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nSpotify Developer Dashboard\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-workos.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-workos',\n  title: 'Login with WorkOS',\n  description: 'Add WorkOS OAuth to your Supabase project',\n}\nTo enable WorkOS Auth for your project, you need to set up WorkOS OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nIn this guide, we will cover how to use Supabase OAuth with WorkOS to implement Single-Sign-On(SSO).\nThe procedure consists of five broad steps:\n\nCreate a new organization from your WorkOS Dashboard.\nObtain the `Client ID` from the Configuration tab and configure redirect URI.\nObtain the `WorkOS Secret` from the credentials tab.\nConnect a WorkOS Supported Identity Provider\nAdd your WorkOS credentials into your Supabase project\n\nCreate a WorkOS Organization\nLog in to the dashboard and hop over to the Organizations tab to create and organization\n\nObtain the Client ID and configure Redirect URI\nHead over to the Configuration tab and configure the redirect URI.The redirect URI should look like `https://<project-ref>.supabase.co/auth/v1/callback`\nNote that this is distinct from the redirect URI referred to in the Supabase dashboard\n\nObtain the WorkOS Secret\nHead over to the API Keys page and obtain the secret key.\n\nConnect a WorkOS Supported Identity Provider\nSet up the identity provider by visiting the setup link.\n\nYou can pick between any one of the many identity providers that WorkOS supports.\nAdd your WorkOS credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `workos` as the `provider`:\n`js\nasync function signInWithWorkOS() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'workos',\n    options: {\n      queryParams: {\n        connection: '<your_connection>',\n        organization: '<your_organization',\n        provider: '<your_provider>',\n      },\n    },\n  })\n}`\nRefer to the WorkOS Documentation to learn more about the different methods.\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nWorkOS Documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-facebook.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-facebook',\n  title: 'Login with Facebook',\n  description: 'Add Facebook OAuth to your Supabase project',\n}\nTo enable Facebook Auth for your project, you need to set up a Facebook OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up Facebook logins for your application consists of 3 parts:\n\nCreate and configure a Facebook Application on the Facebook Developers Site\nAdd your Facebook keys to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nAccess your Facebook Developer account\n\nGo to developers.facebook.com.\nClick on `Log In` at the top right to log in.\n\n\nCreate a Facebook App\n\nClick on `My Apps` at the top right.\nClick `Create App` near the top right.\nSelect your app type and click `Continue`.\nFill in your app information, then click `Create App`.\nThis should bring you to the screen: `Add Products to Your App`. (Alternatively you can click on `Add Product` in the left sidebar to get to this screen.)\n\n\nSet up FaceBook Login for your Facebook App\nFrom the `Add Products to your App` screen:\n\nClick `Setup` under `Facebook Login`\nSkip the Quickstart screen, instead, in the left sidebar, click `Settings` under `Facebook Login`\nEnter your callback URI under `Valid OAuth Redirect URIs` on the `Facebook Login Settings` page\nEnter this in the `Valid OAuth Redirect URIs` box\nClick `Save Changes` at the bottom right\n\nBe aware that you have to set the right access levels on your Facebook App to enable 3rd party applications to read the email address.\nFrom the `App Review -> Permissions and Features` screen:\n\nClick the button `Request Advanced Access` on the right side of `public_profile` and `email`\n\nYou can read more about access levels here\nCopy your Facebook App ID and Secret\n\nClick `Settings / Basic` in the left sidebar\nCopy your App ID from the top of the `Basic Settings` page\nUnder `App Secret` click `Show` then copy your secret\nMake sure all required fields are completed on this screen.\n\nEnter your Facebook App ID and Secret into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `facebook` as the `provider`:\n`js\nasync function signInWithFacebook() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'facebook',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nFacebook Developers Dashboard\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-apple.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-apple',\n  title: 'Login with Apple',\n  description: 'Add Apple OAuth to your Supabase project',\n}\nTo enable Apple Auth for your project, you need to set up an Apple OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nApple OAuth consists of six broad steps:\n\nObtaining an `App Id` with \u201cSign In with Apple\u201d capabilities.\nObtaining a `Services Id` - this will serve as the `client_id`.\nObtaining a `secret key` that will be used to get our `client_secret`.\nGenerating the `client_secret` using the `secret key`.\nAdd your `client id` and `client secret` keys to your Supabase Project.\nAdd the login code to your Supabase JS Client App.\n\nAccess your Apple Developer account\n\nGo to developer.apple.com.\nClick on `Account` at the top right to log in.\n\n\nObtain an App ID\n\nGo to `Certificates, Identifiers & Profiles`.\nClick on `Identifiers` at the left.\nClick on the `+` sign in the upper left next to `Identifiers`.\nSelect `App IDs` and click `Continue`.\nSelect type `App` and click `Continue`.\nFill out your app information:\nApp description.\nBundle ID (Apple recommends reverse-domain name style, so if your domain is acme.com and your app is called roadrunner, use: \"com.acme.roadrunner\").\nScroll down and check `Sign In With Apple`.\nClick `Continue` at the top right.\nClick `Register` at the top right.\n\nObtain a Services ID\nThis will serve as the `client_id` when you make API calls to authenticate the user.\n\nGo to `Certificates, Identifiers & Profiles`.\nClick on `Identifiers` at the left.\nClick on the `+` sign in the upper left next to `Identifiers`.\nSelect `Services IDs` and click `Continue`.\nFill out your information:\nApp description.\nBundle ID (you can't use the same Bundle ID from the previous step, but you can just add something to the beginning, such as \"app.\" to make it app.com.acme.roadrunner\").\nSAVE THIS ID -- this ID will become your `client_id` later.\nClick `Continue` at the top right.\nClick `Register` at the top right.\n\nFind your callback URL\n\nConfigure your Services ID\n\nUnder `Identifiers`, click on your newly-created Services ID.\nCheck the box next to `Sign In With Apple` to enable it.\nClick `Configure` to the right.\nMake sure your newly created Bundle ID is selected under `Primary App ID`\nAdd your domain to the `Domains and Subdomains` box (do not add `https://`, just add the domain).\nIn the `Return URLs` box, type the callback URL of your app which you found in the previous step and click `Next` at the bottom right.\nClick `Done` at the bottom.\nClick `Continue` at the top right.\nClick `Save` at the top right.\n\nDownload your secret key\nNow you'll need to download a `secret key` file from Apple that will be used to generate your `client_secret`.\n\nGo to `Certificates, Identifiers & Profiles`.\nClick on `Keys` at the left.\nClick on the `+` sign in the upper left next to `Keys`.\nEnter a `Key Name`.\nCheck `Sign In with Apple`.\nClick `Configure` to the right.\nSelect your newly-created Services ID from the dropdown selector.\nClick `Save` at the top right.\nClick `Continue` at the top right.\nClick `Register` at the top right.\nClick `Download` at the top right.\nSave the downloaded file -- this contains your \"secret key\" that will be used to generate your `client_secret`.\nClick `Done` at the top right.\n\nGenerate a `client_secret`\nThe `secret key` you downloaded is used to create the `client_secret` string you'll need to authenticate your users.\nAccording to the Apple Docs it needs to be a JWT\ntoken encrypted using the Elliptic Curve Digital Signature Algorithm (ECDSA) with the P-256 curve and the SHA-256 hash algorithm.\nAt this time, the easiest way to generate this JWT token is with Ruby.\nIf you don't have Ruby installed, you can Download Ruby Here.\n\nInstall Ruby (or check to make sure it's installed on your system).\nInstall ruby-jwt.\nFrom the command line, run: `sudo gem install jwt`.\n\nCreate the script below using a text editor: `secret_gen.rb`\n```ruby\nrequire \"jwt\"\nkey_file = \"Path to the private key\"\nteam_id = \"Your Team ID\"\nclient_id = \"The Service ID of the service you created\"\nkey_id = \"The Key ID of the private key\"\nvalidity_period = 180 # In days. Max 180 (6 months) according to Apple docs.\nprivate_key = OpenSSL::PKey::EC.new IO.read key_file\ntoken = JWT.encode(\n    {\n        iss: team_id,\n        iat: Time.now.to_i,\n        exp: Time.now.to_i + 86400 * validity_period,\n        aud: \"https://appleid.apple.com\",\n        sub: client_id\n    },\n    private_key,\n    \"ES256\",\n    header_fields=\n    {\n        kid: key_id\n    }\n)\nputs token\n```\n\n\nEdit the `secret_gen.rb` file:\n\n\n`key_file` = \"Path to the private key you downloaded from Apple\". It should look like this: `AuthKey_XXXXXXXXXX.p8`.\n\n`team_id` = \"Your Team ID\". This is found at the top right of the Apple Developer site (next to your name).\n`client_id` = \"The Service ID of the service you created\". This is the `Services ID` you created in the above step `Obtain a Services ID`. If you've lost this ID, you can find it in the Apple Developer Site:\nGo to `Certificates, Identifiers & Profiles`.\nClick `Identifiers` at the left.\nAt the top right drop-down, select `Services IDs`.\nFind your Identifier in the list (i.e. app.com.acme.roadrunner).\n`key_id` = \"The Key ID of the private key\". This can be found in the name of your downloaded secret file (For a file named `AuthKey_XXXXXXXXXX.p8` your key_id is `XXXXXXXXXX`). If you've lost this ID, you can find it in the Apple Developer Site:\nGo to `Certificates, Identifiers & Profiles`.\nClick `Keys` at the left.\nClick on your newly-created key in the list.\n\nLook under `Key ID` to find your key_id.\n\n\nFrom the command line, run: `ruby secret_gen.rb > client_secret.txt`.\n\nYour `client_secret` is now stored in this `client_secret.txt` file.\n\nAdd your OAuth credentials to Supabase\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `apple` as the `provider`:\n`js\nasync function signInWithApple() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'apple',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nApple Developer Account.\nRuby Docs.\nruby-jwt library.\nThanks to Janak Amarasena who did all the heavy lifting in How to configure Sign In with Apple.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-google.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-google',\n  title: 'Login with Google',\n  description: 'Add Google OAuth to your Supabase project',\n}\nTo enable Google Auth for your project, you need to set up a Google OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up Google logins for your application consists of 3 parts:\n\nCreate and configure a Google Project on the Google Cloud Platform Console\nAdd your Google OAuth keys to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nAccess your Google Cloud Platform account\n\nGo to cloud.google.com.\nClick on `Sign in` at the top right to log in.\n\n\nCreate a Google Cloud Platform Project\n\nClick on `Select a Project` at the top left.\n(Or, if a project is currently selected, click on the current project name at the top left.)\nClick `New Project` at the top right.\nFill in your app information, then click `Create`.\n(This can take a few minutes.)\nThis should bring you to the dashboard for your new project.\n\nCreate the OAuth Keys for your project\nFrom your project's dashboard screen:\n\nIn the search bar at the top labeled `Search products and resources` type `OAuth`.\nClick on `OAuth consent screen` from the list of results.\nOn the `OAuth consent screen` page select `External`.\nClick `Create`.\n\nEdit your app information\n\nOn the `Edit app registration` page fill out your app information.\nClick `Save and continue` at the bottom.\n\nFind your callback URL\n\nCreate your Google credentials\n\nClick `Credentials` at the left to go to the `Credentials` page on the Google Cloud Platform console.\nClick `Create Credentials` near the top then select `OAuth client ID`\nOn the `Create OAuth client ID` page, select your application type. If you're not sure, choose `Web application`.\nFill in your app name.\nAt the bottom, under `Authorized redirect URIs` click `Add URI`.\nEnter your callback URI under `Authorized redirect URIs` at the bottom.\nEnter your callback URI in the `Valid OAuth Redirect URIs` box.\nClick `Save Changes` at the bottom right.\nClick `Create`.\n\nCopy your new OAuth credentials\n\nA box will appear called `OAuth client created`.\nCopy and save the values under `Your Client ID` and `Your Client Secret`.\n\nEnter your Google credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `google` as the `provider`:\n`js\nasync function signInWithGoogle() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'google',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nGoogle Cloud Platform Console\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-keycloak.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-keycloak',\n  title: 'Login with Keycloak',\n  description: 'Add Keycloak OAuth to your Supabase project',\n}\nTo enable Keycloak Auth for your project, you need to set up an Keycloak OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nTo get started with Keycloak, you can run it in a docker container with: `docker run -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin -p 8080:8080 jboss/keycloak:latest`\nThis guide will be assuming that you are running keycloak in a docker container as described in the command above.\nKeycloak OAuth consists of five broad steps:\n\nCreate a new client in your specified keycloak realm.\nObtain the `issuer` from the \"OpenID Endpoint Configuration\". This will be used as the `Keycloak URL`.\nEnsure that the new client has the \"Client Protocol\" set to \"openid-connect\" and the \"Access Type\" is set to \"confidential\".\nThe `Client ID` of the client created will be used as the `client id`.\nObtain the `Secret` from the credentials tab which will be used as the `client secret`.\nAdd the callback url of your application to your allowlist.\n\nAccess your Keycloak Admin console\n\nLogin by visiting http://localhost:8080 and clicking on \"Administration Console\".\n\nCreate a Keycloak Realm\n\nOnce you've logged in to the Keycloak console, you can add a realm from the side panel. The default realm should be named \"Master\".\nAfter you've added a new realm, you can retrieve the `issuer` from the \"OpenID Endpoint Configuration\" endpoint. The `issuer` will be used as the `Keycloak URL`.\nYou can find this endpoint from the realm settings under the \"General Tab\" or visit http://localhost:8080/realms/my_realm_name/.well-known/openid-configuration\n\n\nCreate a Keycloak Client\nThe \"Client ID\" of the created client will serve as the `client_id` when you make API calls to authenticate the user.\n\nClient Settings\nAfter you've created the client successfully, ensure that you set the following settings:\n\nThe \"Client Protocol\" should be set to \"openid-connect\".\nThe \"Access Type\" should be set to \"confidential\".\nThe \"Valid Redirect URIs\" should be set to: `https://<project-ref>.supabase.co/auth/v1/callback`.\n\n\n\nObtain the Client Secret\nThis will serve as the `client_secret` when you make API calls to authenticate the user.\nUnder the \"Credentials\" tab, the `Secret` value will be used as the `client secret`.\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `keycloak` as the `provider`:\n`js\nasync function signInWithKeycloak() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'keycloak',\n    options: {\n      scopes: 'openid',\n    },\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nYou can find the keycloak openid endpoint configuration under the realm settings.\n  \n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-twitch.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-twitch',\n  title: 'Login with Twitch',\n  description: 'Add Twitch OAuth to your Supabase project',\n}\nTo enable Twitch Auth for your project, you need to set up a Twitch Application and add the Application OAuth credentials to your Supabase Dashboard.\nOverview\nSetting up Twitch logins for your application consists of 3 parts:\n\nCreate and configure a Twitch Application Twitch Developer Console\nAdd your Twitch OAuth Consumer keys to your Supabase Project\nAdd the login code to your Supabase JS Client App\n\nAccess your Twitch Developer account\n\nGo to dev.twitch.tv.\nClick on `Log in with Twitch` at the top right to log in.\nIf you have not already enabled 2-Factor Authentication for your Twitch Account, you will need to do that at Twitch Security Settings before you can continue.\n\n\n\nOnce logged in, go to the Twitch Developer Console.\n\n\nFind your callback URL\n\nCreate a Twitch Application\n\n\nClick on `+ Register Your Application` at the top right.\n\n\n\nEnter the name of your application.\nType or paste your `OAuth Redirect URL` (the callback URL from the previous step.)\nSelect a category for your app.\nCheck the Captcha box and click `Create`.\n\nRetrieve your Twitch OAuth Client ID and Client Secret\n\nClick `Manage` at the right of your application entry in the list.\n\n\n\nCopy your Client ID.\nClick `New Secret` to create a new Client Secret.\nCopy your Client Secret.\n\n\nAdd your Twitch credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `twitch` as the `provider`:\n`js\nasync function signInWithTwitch() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'twitch',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nTwitch Account\nTwitch Developer Console\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-linkedin.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-linkedin',\n  title: 'Login with LinkedIn',\n  description: 'Add LinkedIn OAuth to your Supabase project',\n}\nTo enable LinkedIn Auth for your project, you need to set up a LinkedIn OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nSetting up LinkedIn logins for your application consists of 3 parts:\n\nCreate and configure a LinkedIn Project and App on the LinkedIn Developer Dashboard.\nAdd your LinkedIn `client_id` and `client_secret` to your Supabase Project.\nAdd the login code to your Supabase JS Client App.\n\nAccess your LinkedIn Developer account\n\nGo to LinkedIn Developer Dashboard.\nLog in (if necessary.)\n\n\nFind your callback URL\n\nCreate a LinkedIn OAuth app\n\nGo to LinkedIn Developer Dashboard.\nClick on `Create App` at the top right\nEnter your `LinkedIn Page` and `App Logo`\nSave your app\nClick `Auth` from the top menu\nAdd your `Redirect URL` to the `Authorized Redirect URLs for your app` section\nCopy and save your newly-generated `Client ID`\nCopy and save your newly-generated `Client Secret`\n\nEnter your LinkedIn credentials into your Supabase Project\n\nAdd login code to your client app\nWhen your user signs in, call signInWithOAuth() with `linkedin` as the `provider`:\n`js\nasync function signInWithLinkedIn() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'linkedin',\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nSupabase Account - Free Tier OK\nSupabase JS Client\nLinkedIn Developer Dashboard\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/social-login/auth-azure.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-azure',\n  title: 'Login with Azure',\n  description: 'Add Azure OAuth to your Supabase project',\n}\nTo enable Azure Auth for your project, you need to set up an Azure OAuth application and add the application credentials to your Supabase Dashboard.\nOverview\nAzure OAuth consists of four broad steps:\n\nCreate an application under Azure Active Directory.\nObtain a `Application (client) ID` with \u201cSign In with Azure\u201d capabilities. This will be used as the `client id`.\nCreate a `Secret ID` with \u201cSign In with Azure\u201d capabilities. The value of the secret will be used as the `client secret`.\nAdd the callback url of your application to the allowlist.\n\nAccess your Azure Developer account\n\nGo to portal.azure.com.\nLogin and select \"Azure Active Directory\" under the list of Azure Services.\n\nRegister an application\n\nUnder Azure Active Directory, select \"App registrations\" in the side panel.\nSelect \"New registration\".\nChoose a name and select your preferred option for the supported account types.\nSpecify the \"Redirect URI\".\nThe redirect / callback URI should look like this: `https://<project-ref>.supabase.co/auth/v1/callback`\nClick \"Register\" at the bottom of the form.\n\n\nObtain a Client ID\nThis will serve as the `client_id` when you make API calls to authenticate the user.\n\nOnce your app has been registered, the client id can be found under the list of app registrations under the column titled \"Application (client) ID\".\n\n\nObtain a Secret ID\nThis will serve as the `client_secret` when you make API calls to authenticate the user.\n\nClick on the name of the app registered above.\nUnder \"Essentials\", click on \"Client credentials\".\nNavigate to the \"Client secrets\" tab and select \"New client secret\".\nEnter a description and choose your preferred expiry for the secret.\nOnce the secret is generated, save the `value` (not the secret ID).\n\n\nObtain the Tenant URL\nThis will allow your users to use your custom Azure login page when logging in.\n\nSelect the Directory (Tenant) ID value.\nThe Azure Tenant URL should look like this: `https://login.microsoftonline.com/<tenant-id>`\n\n\nAdd login code to your client app\n\nSupabase Auth requires that Azure returns a valid email address. Therefore you must request the `email` scope in the `signIn` method above.\n\nWhen your user signs in, call signInWithOAuth() with `azure` as the `provider`:\n`js\nasync function signInWithAzure() {\n  const { data, error } = await supabase.auth.signInWithOAuth({\n    provider: 'azure',\n    options: {\n      scopes: 'email',\n    },\n  })\n}`\nWhen your user signs out, call signOut() to remove them from the browser session and any objects from localStorage:\n`js\nasync function signout() {\n  const { error } = await supabase.auth.signOut()\n}`\nResources\n\nAzure Developer Account\nGitHub Discussion\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/phone-login/twilio.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-twilio',\n  title: 'Phone Auth with Twilio',\n  description: 'How to set up and use Mobile OTP with Twilio and Supabase.',\n  video: 'https://www.youtube.com/v/akScoPO01bc',\n}\nOverview\nIn this guide we'll show you how to authenticate your users with SMS based One-Time Password (OTP) tokens.\nThere are two reasons to use Supabase SMS OTP tokens:\n\nYou want users to log in with mobile number + password, and the mobile number should be verified via SMS\nYou want users to log in with mobile number ONLY (i.e. passwordless login)\n\nWe'll cover:\n\nFinding your Twilio credentials\nUsing OTP with password based logins\nUsing OTP as a passwordless sign-in mechanism\n\nWhat you'll need:\n\nA Twilio account (sign up here: https://www.twilio.com/try-twilio)\nA Supabase project (create one here: https://app.supabase.com)\nA mobile phone capable of receiving SMS\n\nVideo\n\n\n\nSteps\nFinding your Twilio credentials\nStart by logging into your Twilio account and starting a new project: https://www.twilio.com/console/projects/create\nGive your project a name and verify the mobile number you'll be using to test with. This is the number that will be receiving the SMS OTPs.\n\n\nSelect 'SMS', 'Identity & Verification', and 'With code' as options on the welcome form.\n\nWhen you're back on the Twilio console screen, you need to scroll down and click 'Get a trial phone number' - this is the number that you'll be sending SMSs from.\n\n\nYou should now be able to see all three values you'll need to get started:\n\nAccount SID\nAuth Token\nSender Phone Number\n\n\nNow go to the Auth > Settings page in the Supabase dashboard (https://app.supabase.com/project/YOUR-PROJECT-REF/auth/settings).\nYou should see an option to enable Phone Signup:\n\nToggle it on, and copy the 3 values over from the twilio dashboard. Click save.\nNote: for \"Twilio Message Service SID\" you can use the Sender Phone Number generated above.\n\nNow the backend should be setup, we can proceed to add our client-side code!\nSMS custom template\nThe SMS message sent to a phone containing an OTP code can be customized. This is useful if you need to mention a brand name or display a website address.\nGo to Auth > Templates page in the Supabase dashboard (https://app.supabase.com/project/YOUR-PROJECT-REF/auth/templates).\nUse the variable `.Code` in the template to display the OTP code. Here's an example in the SMS template.\n\nUsing OTP with password based logins\nIn this scenario we'll be using the user's mobile phone number and a corresponding password as an alternative to signing up with an email address. Note: please thoroughly consider potential security implications when signing up with a combination of phone number and password. Phone numbers are sometimes recycled by phone networks when users cancel their phone contracts or move countries, thereby granting access to the user's account to the subsequent owner of the phone number. In the near future Supabase will support multifactor authentication, which will mitigate this risk, but for now you may want to consider allowing your users to recover their account by some other means in an emergency.\nUsing supabase-js on the client you'll want to use the same `signUp` method that you'd use for email based sign ups, but with the `phone` param instead of the `email param`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signUp({\n  phone: '+13334445555',\n  password: 'some-password',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/signup' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"+13334445555\",\n  \"password\": \"some-password\"\n}'`\n\n\nThe user will now receive an SMS with a 6-digit pin that you will need to receive from them within 60-seconds before they can login to their account.\nYou should present a form to the user so they can input the 6 digit pin, then send it along with the phone number to `verifyOTP`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { session, error } = await supabase.auth.verifyOtp({\n  phone: '+13334445555',\n  token: '123456',\n  type: 'sms',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/verify' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"type\": \"sms\",\n  \"phone\": \"+13334445555\",\n  \"token\": \"123456\"\n}'`\n\n\nIf successful the user will now be logged in and you should receive a valid session like:\n`json\n{\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjI3MjkxNTc3LCJzdWIiOiJmYTA2NTQ1Zi1kYmI1LTQxY2EtYjk1NC1kOGUyOTg4YzcxOTEiLCJlbWFpbCI6IiIsInBob25lIjoiNjU4NzUyMjAyOSIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6InBob25lIn0sInVzZXJfbWV0YWRhdGEiOnt9LCJyb2xlIjoiYXV0aGVudGljYXRlZCJ9.1BqRi0NbS_yr1f6hnr4q3s1ylMR3c1vkiJ4e_N55dhM\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 3600,\n  \"refresh_token\": \"LSp8LglPPvf0DxGMSj-vaQ\"\n}`\nThe access token can be sent in the Authorization header as a Bearer token for any CRUD operations on supabase-js. See our guide on Row Level Security for more info on restricting access on a user basis.\nAlso now that the mobile has been verified, the user can use the number and password to sign in without needing to verify their number each time:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signInWithPassword({\n  phone: '+13334445555',\n  password: 'some-password',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/token?grant_type=password' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"+13334445555\",\n  \"password\": \"some-password\"\n}'`\n\n\nUsing OTP as a passwordless sign-in mechanism\nIn this scenario you are granting your user's the ability to login to their account without needing to set a password on their account, all they have to do to log in is verify their mobile each time using the OTP.\nIn javascript we can use the `signIn` method with a single parameter: `phone`\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signInWithOtp({\n  phone: '+13334445555',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/otp' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"+13334445555\"\n}'`\n\n\nThe second step is the same as the previous section, you need to collect the 6-digit pin from the user and pass it along with their phone number to the verify method:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { session, error } = await supabase.auth.verifyOtp({\n  phone: '+13334445555',\n  token: '123456',\n  type: 'sms',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/verify' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"type\": \"sms\",\n  \"phone\": \"+13334445555\",\n  \"token\": \"123456\"\n}'`\n\n\nand the response should also be the same as above:\n`json\n{\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjI3MjkxNTc3LCJzdWIiOiJmYTA2NTQ1Zi1kYmI1LTQxY2EtYjk1NC1kOGUyOTg4YzcxOTEiLCJlbWFpbCI6IiIsInBob25lIjoiNjU4NzUyMjAyOSIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6InBob25lIn0sInVzZXJfbWV0YWRhdGEiOnt9LCJyb2xlIjoiYXV0aGVudGljYXRlZCJ9.1BqRi0NbS_yr1f6hnr4q3s1ylMR3c1vkiJ4e_N55dhM\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 3600,\n  \"refresh_token\": \"LSp8LglPPvf0DxGMSj-vaQ\"\n}`\nThe user does not have a password therefore will need to sign in via this method each time they want to access your service.\nResources\n\nTwilio Signup\nSupabase Dashboard\nSupabase Row Level Security\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/phone-login/vonage.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-vonage',\n  title: 'Phone Auth with Vonage',\n  description: 'How to set up and use Mobile OTP with Vonage and Supabase.',\n}\nOverview\nIn this guide we'll show you how to authenticate your users with SMS based OTP (One-Time Password) tokens.\nThere are two reasons to use Supabase SMS OTP tokens:\n\nYou want users to log in with mobile + password, and the mobile should be verified via SMS\nYou want users to log in with mobile ONLY (i.e. passwordless login)\n\nWe'll cover:\n\nGetting your Vonage API Key\nUsing OTP with password based logins\nUsing OTP as a passwordless sign-in mechanism\n\nWhat you'll need:\n\nA Vonage account (sign up here: https://dashboard.nexmo.com/sign-up)\nA Supabase project (create one here: https://app.supabase.com)\nA mobile phone capable of receiving SMS\n\nSteps\nGetting your Vonage credentials\nStart by logging into your Vonage Dashboard at https://dashboard.nexmo.com/\nYou will see you API Key and API Secret here, which is actually all you need to get started.\nIn most countries, a phone number is actually optional and you can also use any Alphanumeric Sender ID of up to 11 characters length (8 for India) as a Sender ID (from). This means you do not need a number to test with in most cases.\nTo find out more about supported countries for Alphanumeric Sender ID, check this overview: https://help.nexmo.com/hc/en-us/articles/115011781468-SMS-Features-Overview-Outbound-only-\nHint: Some countries might need a Sender ID Registration to allow sending with an Alphanumeric Sender ID. You can find this information in the help article as well. If Alpha Sender IDs are not supported, you will need to buy a phone number.\nGetting a phone number (optional)\nIf you want a phone number to send SMS from, you can buy one from the Vonage Dashboard under Numbers > Buy Numbers (https://dashboard.nexmo.com/buy-numbers).\nSelect the country you want a number for. You will need a mobile phone number with SMS or SMS+Voice capability. After you have bought the number, you will be able to send SMS from it.\nConfigure Supabase\nNow go to the Auth > Settings page in the Supabase dashboard (https://app.supabase.com/project/YOUR-PROJECT-REF/auth/settings).\nYou should see an option to enable Phone Signup.\nToggle it on, and copy the api key, api secret and optionally phone number values over from the Vonage dashboard. Click save.\nNow the backend should be setup, we can proceed to add our client-side code!\nSMS custom template\nThe SMS message sent to a phone containing an OTP code can be customized. This is useful if you need to mention a brand name or display a website address.\nGo to Auth > Templates page in the Supabase dashboard (https://app.supabase.com/project/YOUR-PROJECT-REF/auth/templates).\nUse the variable `.Code` in the template to display the code.\nUsing OTP with password based logins\nIn this use scenario we'll be using the user's mobile phone number as an alternative to an email address when signing up along with a password. You may want to think hard about the permanency of this however. It is not uncommon for mobile phone numbers to be recycled by phone networks when users cancel their phone contracts or move countries, therefore granting access to the user's account to whoever takes over the phone number in the future.\nUsing supabase-js on the client you'll want to use the same `signUp` method that you'd use for email based sign ups, but with the `phone` param instead of the `email param`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signUp({\n  phone: '491512223334444',\n  password: 'some-password',\n})`\n\n\n`bash\ncurl -X POST 'https://xxx.supabase.co/auth/v1/signup' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"491512223334444\",\n  \"password\": \"some-password\"\n}'`\n\n\nThe user will now receive an SMS with a 6-digit pin that you will need to receive from them within 60-seconds before they can login to their account.\nYou should present a form to the user so they can input the 6 digit pin, then send it along with the phone number to `verifyOTP`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { session, error } = await supabase.auth.verifyOTP({\n  phone: '491512223334444',\n  token: '123456',\n})`\n\n\n`bash\ncurl -X POST 'https://xxx.supabase.co/auth/v1/verify' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"type\": \"sms\",\n  \"phone\": \"491512223334444\",\n  \"token\": \"123456\"\n}'`\n\n\nIf successful the user will now be logged in and you should receive a valid session like:\n`json\n{\n  \"access_token\": \"eyJxxx...\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 3600,\n  \"refresh_token\": \"yyy...\"\n}`\nThe access token can be sent in the Authorization header as a Bearer token for any CRUD operations on supabase-js. See our guide on Row Level Security for more info on restricting access on a user basis.\nAlso now that the mobile has been verified, the user can use the number and password to sign in without needing to verify their number each time:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signInWithPassword({\n  phone: '491512223334444',\n  password: 'some-password',\n})`\n\n\n`bash\ncurl -X POST 'https://xxx.supabase.co/auth/v1/token?grant_type=password' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"491512223334444\",\n  \"password\": \"some-password\"\n}'`\n\n\nUsing OTP as a passwordless sign-in mechanism\nIn this scenario you are granting your user's the ability to login to their account without needing to set a password on their account, all they have to do to log in is verify their mobile each time using the OTP.\nIn javascript we can use the `signIn` method with a single parameter: `phone`\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signInWithOtp({\n  phone: '491512223334444',\n})`\n\n\n`bash\ncurl -X POST 'https://xxx.supabase.co/auth/v1/otp' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"491512223334444\"\n}'`\n\n\nThe second step is the same as the previous section, you need to collect the 6-digit pin from the user and pass it along with their phone number to the verify method:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { session, error } = await supabase.auth.verifyOTP({\n  phone: '491512223334444',\n  token: '123456',\n})`\n\n\n`bash\ncurl -X POST 'https://xxx.supabase.co/auth/v1/verify' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"type\": \"sms\",\n  \"phone\": \"491512223334444\",\n  \"token\": \"123456\"\n}'`\n\n\nand the response should also be the same as above:\n`json\n{\n  \"access_token\": \"eyJxxx...\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 3600,\n  \"refresh_token\": \"yyy...\"\n}`\nThe user does not have a password therefore will need to sign in via this method each time they want to access your service.\nResources\n\nVonage Signup\nSupabase Dashboard\nSupabase Row Level Security\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Overview",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/phone-login/messagebird.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-messagebird',\n  title: 'Phone Auth with MessageBird',\n  description: 'How to set up and use Mobile OTP with MessageBird and Supabase.',\n}\nOverview\nIn this guide we'll show you how to authenticate your users with SMS based OTP (One-Time Password) tokens.\nThere are two reasons to use Supabase SMS OTP tokens:\n\nYou want users to log in with mobile + password, and the mobile should be verified via SMS\nYou want users to log in with mobile ONLY (i.e. passwordless login)\n\nWe'll cover:\n\nFinding your MessageBird credentials\nUsing OTP with password based logins\nUsing OTP as a passwordless sign-in mechanism\n\nWhat you'll need:\n\nA MessageBird account (sign up here: https://dashboard.messagebird.com/en/sign-up)\nA Supabase project (create one here: https://app.supabase.com)\nA mobile phone capable of receiving SMS\n\nSteps\nFinding your MessageBird credentials\nStart by logging into your MessageBird account and verify the mobile number you'll be using to test with: https://dashboard.messagebird.com/en/getting-started/sms\nThis is the number that will be receiving the SMS OTPs.\n\n\nNavigate to the dashboard settings to set the default originator. The messagebird originator is the name or number from which the message is sent.\nFor more information, you can refer to the messagebird article on choosing an originator here\n\nYou will need the following values to get started:\n\nLive API Key / Test API Key\nMessageBird originator\n\nNow go to the Auth > Settings page in the Supabase dashboard (https://app.supabase.com/project/YOUR-PROJECT-REF/auth/settings).\nYou should see an option to enable Phone Signup.\n\nToggle it on, and copy the 2 values over from the messagebird dashboard. Click save.\nNote: If you use the Test API Key, the OTP will not be delivered to the mobile number specified but messagebird will log the response in the dashboard.\nIf the Live API Key is used instead, the OTP will be delivered and there will be a deduction in your free credits.\nPlugin MessageBird credentials\nNow the backend should be setup, we can proceed to add our client-side code!\nSMS custom template\nThe SMS message sent to a phone containing an OTP code can be customized. This is useful if you need to mention a brand name or display a website address.\nGo to Auth > Templates page in the Supabase dashboard (https://app.supabase.com/project/YOUR-PROJECT-REF/auth/templates).\nUse the variable `.Code` in the template to display the code.\nUsing OTP with password based logins\nIn this use scenario we'll be using the user's mobile phone number as an alternative to an email address when signing up along with a password. You may want to think hard about the permanency of this however. It is not uncommon for mobile phone numbers to be recycled by phone networks when users cancel their phone contracts or move countries, therefore granting access to the user's account to whoever takes over the phone number in the future. Soon we'll add multi-factor auth, which will mitigate this risk, but for now you may want to give some thought to allowing your users to recover their account by some other means in an emergency.\nUsing supabase-js on the client you'll want to use the same `signUp` method that you'd use for email based sign ups, but with the `phone` param instead of the `email param`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signUp({\n  phone: '+13334445555',\n  password: 'some-password',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/signup' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"+13334445555\",\n  \"password\": \"some-password\"\n}'`\n\n\nThe user will now receive an SMS with a 6-digit pin that you will need to receive from them within 60-seconds before they can login to their account.\nYou should present a form to the user so they can input the 6 digit pin, then send it along with the phone number to `verifyOTP`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { session, error } = await supabase.auth.verifyOTP({\n  phone: '+13334445555',\n  token: '123456',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/verify' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"type\": \"sms\",\n  \"phone\": \"+13334445555\",\n  \"token\": \"123456\"\n}'`\n\n\nIf successful the user will now be logged in and you should receive a valid session like:\n`json\n{\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjI3MjkxNTc3LCJzdWIiOiJmYTA2NTQ1Zi1kYmI1LTQxY2EtYjk1NC1kOGUyOTg4YzcxOTEiLCJlbWFpbCI6IiIsInBob25lIjoiNjU4NzUyMjAyOSIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6InBob25lIn0sInVzZXJfbWV0YWRhdGEiOnt9LCJyb2xlIjoiYXV0aGVudGljYXRlZCJ9.1BqRi0NbS_yr1f6hnr4q3s1ylMR3c1vkiJ4e_N55dhM\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 3600,\n  \"refresh_token\": \"LSp8LglPPvf0DxGMSj-vaQ\"\n}`\nThe access token can be sent in the Authorization header as a Bearer token for any CRUD operations on supabase-js. See our guide on Row Level Security for more info on restricting access on a user basis.\nAlso now that the mobile has been verified, the user can use the number and password to sign in without needing to verify their number each time:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signInWithPassword({\n  phone: '+13334445555',\n  password: 'some-password',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/token?grant_type=password' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"+13334445555\",\n  \"password\": \"some-password\"\n}'`\n\n\nUsing OTP as a passwordless sign-in mechanism\nIn this scenario you are granting your user's the ability to login to their account without needing to set a password on their account, all they have to do to log in is verify their mobile each time using the OTP.\nIn javascript we can use the `signIn` method with a single parameter: `phone`\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { user, error } = await supabase.auth.signInWithOtp({\n  phone: '+13334445555',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/otp' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"phone\": \"+13334445555\"\n}'`\n\n\nThe second step is the same as the previous section, you need to collect the 6-digit pin from the user and pass it along with their phone number to the verify method:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`js\nlet { session, error } = await supabase.auth.verifyOTP({\n  phone: '+13334445555',\n  token: '123456',\n})`\n\n\n`bash\ncurl -X POST 'https://cvwawazfelidkloqmbma.supabase.co/auth/v1/verify' \\\n-H \"apikey: SUPABASE_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n  \"type\": \"sms\",\n  \"phone\": \"+13334445555\",\n  \"token\": \"123456\"\n}'`\n\n\nand the response should also be the same as above:\n`json\n{\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNjI3MjkxNTc3LCJzdWIiOiJmYTA2NTQ1Zi1kYmI1LTQxY2EtYjk1NC1kOGUyOTg4YzcxOTEiLCJlbWFpbCI6IiIsInBob25lIjoiNjU4NzUyMjAyOSIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6InBob25lIn0sInVzZXJfbWV0YWRhdGEiOnt9LCJyb2xlIjoiYXV0aGVudGljYXRlZCJ9.1BqRi0NbS_yr1f6hnr4q3s1ylMR3c1vkiJ4e_N55dhM\",\n  \"token_type\": \"bearer\",\n  \"expires_in\": 3600,\n  \"refresh_token\": \"LSp8LglPPvf0DxGMSj-vaQ\"\n}`\nThe user does not have a password therefore will need to sign in via this method each time they want to access your service.\nResources\n\nMessageBird Signup\nSupabase Dashboard\nSupabase Row Level Security\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Set up Auth UI",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-helpers/auth-ui.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth-ui',\n  title: 'Auth UI',\n  description: 'A prebuilt, customizable React component for authenticating users.',\n}\nAuth UI is a pre-built React component for authenticating users.\nIt supports custom themes and extensible styles to match your brand and aesthetic.\n\n\n\nSet up Auth UI\nInstall the latest version of supabase-js and the Auth UI package:\n`bash\nnpm install @supabase/supabase-js @supabase/auth-ui-react`\nImport the Auth component\nPass `supabaseClient` from `@supabase/supabase-js` as a prop to the component.\n```js title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth } from '@supabase/auth-ui-react'\nconst supabase = createClient('', '')\nconst App = () => \n```\nThis renders the Auth component without any styling.\nWe recommend using one of the predefined themes to style the UI.\nImport the theme you want to use and pass it to the `appearence.theme` prop.\n```js lines=4,16 title=/src/index.js\nimport {\n  Auth,\n  // Import predefined theme\n  ThemeSupa,\n} from '@supabase/auth-ui-react'\nconst supabase = createClient(\n  '',\n  ''\n)\nconst App = () => (\n  \n)\n```\nSocial Providers\nThe Auth component also supports login with offical social providers.\n```js lines=13 title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth, ThemeSupa } from '@supabase/auth-ui-react'\nconst supabase = createClient('', '')\nconst App = () => (\n  \n)\n```\nSupported Views\nThe Auth component is currently shipped with the following views:\n\nEmail Login\nMagic Link login\nSocial Login\nUpdate password\nForgotten password\n\nWe are planning on adding more views in the future.  Follow along on that repo.\nCustomization\nThere are several ways to customize Auth UI:\n\nUse one of the predefined themes that comes with Auth UI\nExtend a theme by overriding the variable tokens in a theme\nCreate your own theme\nUse your own CSS classes\nUse inline styles\nUse your own labels\n\nPredefined themes\nAuth UI comes with several themes to customize the appearance. Each predefined theme comes with at least two variations, a `default` variation, and a `dark` variation. You can switch between these themes using the `theme` prop. Import the theme you want to use and pass it to the `appearence.theme` prop.\n```js lines=2,13 title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth, ThemeSupa } from '@supabase/auth-ui-react'\nconst supabase = createClient(\n  '',\n  ''\n)\nconst App = () => (\n  \n)\n```\n\nCurrently there is only one predefined theme available, but we plan to add more.\n\nSwitch theme variations\nAuth UI comes with two theme variations: `default` and `dark`. You can switch between these themes with the `theme` prop.\n```js lines=14 title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth, ThemeSupa } from '@supabase/auth-ui-react'\nconst supabase = createClient(\n  '',\n  ''\n)\nconst App = () => (\n  \n)\n```\nIf you don't pass a value to `theme` it uses the `\"default\"` theme. You can pass `\"dark\"` to the theme prop to switch to the `dark` theme. If your theme has other variations, use the name of the variation in this prop.\nOverride themes\nAuth UI themes can be overridden using variable tokens. See the list of variable tokens.\n```js lines=14-21 title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth, ThemeSupa } from '@supabase/auth-ui-react'\nconst supabase = createClient('', '')\nconst App = () => (\n  \n)\n```\nIf you created your own theme, you may not need to override any of the them.\nCreate your own theme [#create-theme]\nYou can create your own theme by following the same structure within a `appearance.theme` property.\nSee the list of tokens within a theme.\n```js title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth } from '@supabase/auth-ui-react'\nconst supabase = createClient(\n  '',\n  ''\n)\nconst customTheme = {\n  default: {\n    colors: {\n      brand: 'hsl(153 60.0% 53.0%)',\n      brandAccent: 'hsl(154 54.8% 45.1%)',\n      brandButtonText: 'white',\n      // ..\n  },\n  dark: {\n    colors: {\n      brandButtonText: 'white',\n      defaultButtonBackground: '#2e2e2e',\n      defaultButtonBackgroundHover: '#3e3e3e',\n      //..\n    },\n  },\n  // You can also add more theme variations with different names.\n  evenDarker: {\n    colors: {\n      brandButtonText: 'white',\n      defaultButtonBackground: '#1e1e1e',\n      defaultButtonBackgroundHover: '#2e2e2e',\n      //..\n    },\n  },\n}\nconst App = () => (\n  \n)\n```\nYou can swich between different variations of your theme with the \"theme\" prop.\nCustom CSS classes [#custom-css-classes]\nYou can use custom CSS classes for the following elements:\n`\"button\"`, `\"container\"`, `\"anchor\"`, `\"divider\"`, `\"label\"`, `\"input\"`, `\"loader\"`, `\"message\"`.\n```js title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth } from '@supabase/auth-ui-react'\nconst supabase = createClient('', '')\nconst App = () => (\n  \n)\n```\nCustom inline CSS [#custom-inline-styles]\nYou can use custom CSS inline styles for the following elements:\n`\"button\"`, `\"container\"`, `\"anchor\"`, `\"divider\"`, `\"label\"`, `\"input\"`, `\"loader\"`, `\"message\"`.\n```js title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth } from '@supabase/auth-ui-react'\nconst supabase = createClient('', '')\nconst App = () => (\n  \n)\n```\nCustom labels [#custom-labels]\nYou can use custom labels with `localization.variables`. See the list of labels that can be overwritten.\n```js title=/src/index.js\nimport { createClient } from '@supabase/supabase-js'\nimport { Auth } from '@supabase/auth-ui-react'\nconst supabase = createClient('', '')\nconst App = () => (\n  \n)\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Install the Next.js helper library",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-helpers/nextjs-server-components.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'nextjs-server-components',\n  title: 'Supabase Auth with Next.js Server Components',\n  description:\n    'Authentication helpers for creating an authenticated Supabase client in Next.js 13 app directory Server Components.',\n  sidebar_label: 'Next.js Server Components',\n}\nThis submodule provides experimental convenience helpers for implementing user authentication in Next.js Server Components - the `app` directory. For examples using the `pages` directory check out Auth Helpers in Next.js.\n\nFor a complete implementation example, check out this repo.\nTo learn more about fetching and caching Supabase data with Next.js 13 Server Components, check out our blog or live stream.\n\nInstall the Next.js helper library\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n\n\n`sh\nnpm install @supabase/auth-helpers-nextjs`\n\nNext.js Server Components and the `app` directory are experimental and likely to change.\n\n\n\n`sh\nyarn add @supabase/auth-helpers-nextjs`\n\nNext.js Server Components and the `app` directory are experimental and likely to change.\n\n\n\nSet up environment variables\nRetrieve your project's URL and anon key from your API settings in the dashboard, and create a `.env.local` file with the following environment variables:\n`bash title=\".env.local\"\nNEXT_PUBLIC_SUPABASE_URL=YOUR_SUPABASE_URL\nNEXT_PUBLIC_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nCreating a Supabase Client\nServer-side\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nCreate a new file at `/utils/supabase-server.js` and populate with the following:\n```js title=\"/utils/supabase-server.js\"\nimport { headers, cookies } from 'next/headers'\nimport { createServerComponentSupabaseClient } from '@supabase/auth-helpers-nextjs'\nexport const createClient = () =>\n  createServerComponentSupabaseClient({\n    headers,\n    cookies,\n  })\n```\n\nThis needs to export a function, as the headers and cookies are not populated with values until the Server Component is requesting data.\n\n\n\nCreate a new file at `/utils/supabase-server.ts` and populate with the following:\n```ts title=\"/utils/supabase-server.ts\"\nimport { headers, cookies } from 'next/headers'\nimport { createServerComponentSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport type { Database } from '../lib/database.types'\nexport const createClient = () =>\n  createServerComponentSupabaseClient({\n    headers,\n    cookies,\n  })\n```\n\nTypeScript types can be generated with the Supabase CLI and passed to `createServerSupabaseClient` to add type support to the Supabase client.\nThis needs to export a function, as the headers and cookies are not populated with values until the Server Component is requesting data.\n\n\n\nThis will be used any time we need to create a Supabase client server-side - in a Server Component, for example.\nNext, we need a middleware file to refresh the user's session on navigation.\n\nIf you were using Middleware prior to 12.2, see the upgrade guide.\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nCreate a new `middleware.js` file at the same level as your `app` (in the root or `src` directory) and populate with the following:\n```jsx title=\"middleware.js\"\nimport { createMiddlewareSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { NextResponse } from 'next/server'\nexport async function middleware(req) {\n  const res = NextResponse.next()\nconst supabase = createMiddlewareSupabaseClient({ req, res })\nconst {\n    data: { session },\n  } = await supabase.auth.getSession()\nreturn res\n}\n```\n\n\nCreate a new `middleware.ts` file at the same level as your `app` (in the root or `src` directory) and populate with the following:\n```tsx title=\"middleware.ts\"\nimport { createMiddlewareSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { NextResponse } from 'next/server'\nimport type { NextRequest } from 'next/server'\nimport type { Database } from '../lib/database.types'\nexport async function middleware(req: NextRequest) {\n  const res = NextResponse.next()\nconst supabase = createMiddlewareSupabaseClient({ req, res })\nconst {\n    data: { session },\n  } = await supabase.auth.getSession()\nreturn res\n}\n```\n\nTypeScript types can be generated with the Supabase CLI and passed to `createMiddlewareSupabaseClient` to add type support to the Supabase client.\n\n\n\nWe can now use our server-side Supabase client to fetch data in Server Components.\n```jsx\nimport 'server-only'\nimport { createClient } from '../../utils/supabase-server'\n// do not cache this page\nexport const revalidate = 0\nexport default async function ServerComponent() {\n  const supabase = createClient()\n  const { data } = await supabase.from('posts').select('*')\nreturn {JSON.stringify({ data }, null, 2)}\n}\n```\nClient-side\nWe still need a Supabase instance client-side for authentication and realtime subscriptions. It is important, when using Supabase client-side, to have a single instance of a client. We can share this singleton instance across our components using providers and React context.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nCreate a new file at `/utils/supabase-browser.js` and populate with the following:\n`js title=\"/utils/supabase-browser.js\"\nimport { createBrowserSupabaseClient } from '@supabase/auth-helpers-nextjs'\nexport const createClient = () => createBrowserSupabaseClient()`\n\n\nCreate a new file at `/utils/supabase-browser.ts` and populate with the following:\n```ts\nimport { createBrowserSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { Database } from '../lib/database.types'\nexport const createClient = () => createBrowserSupabaseClient()\n```\n\nTypeScript types can be generated with the Supabase CLI and passed to `createBrowserSupabaseClient` to add type support to the Supabase client.\n\n\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nNext, we need to create a single instance of Supabase to use client-side. Let's create a new Provider for Supabase at `/components/supabase-provider.jsx` and populate with the following:\n```jsx title=components/supabase-provider.jsx\n'use client'\nimport { createContext, useContext, useState } from 'react'\nimport { createClient } from '../utils/supabase-browser'\nconst Context = createContext()\nexport default function SupabaseProvider({ children }) {\n  const [supabase] = useState(() => createClient())\nuseEffect(() => {\n    const { data: { subscription } } = supabase.auth.onAuthStateChange((event, session) => {\n      if (session?.access_token !== accessToken) {\n        router.refresh()\n      }\n    })\n\n\n```return () => subscription.unsubscribe()\n```\n\n\n}, [accessToken])\nreturn (\n    \n      <>{children}\n    \n  )\n}\nexport const useSupabase = () => useContext(Context)\n```\n\n\nNext, we need to create a single instance of Supabase to use client-side. Let's create a new Provider for Supabase at `/components/supabase-provider.tsx` and populate with the following:\n```tsx title=components/supabase-provider.tsx\n'use client'\nimport { createContext, useContext, useState } from 'react'\nimport { createClient } from '../utils/supabase-browser'\nimport type { SupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport type { Database } from '../lib/database.types'\ntype SupabaseContext = {\n  supabase: SupabaseClient\n}\nconst Context = createContext(undefined)\nexport default function SupabaseProvider({ children }: { children: React.ReactNode }) {\n  const [supabase] = useState(() => createClient())\nreturn (\n    \n      <>{children}\n    \n  )\n}\nexport const useSupabase = () => {\n  let context = useContext(Context);\n  if (context === undefined) {\n    throw new Error(\"useSupabase must be used inside SupabaseProvider\");\n  } else {\n    return context;\n  }\n}\n```\n\nTypeScript types can be generated with the Supabase CLI and passed to `createBrowserSupabaseClient` to add type support to the Supabase client.\n\n\n\nWe need to set up a listener to fetch fresh data whenever our user logs in or out. For this we need to check whether our client and server sessions match. Let's start by installing the `server-only` package.\n`bash\nnpm install server-only`\nThis will ensure that any component that imports this package will be a Server Component, and excluded from the browser bundle.\nNext, let's modify our root layout to fetch the user's session, wrap our application in our Supabase Provider, and pass the server access token as a prop to the `<SupabaseListener />` component (we will create this next).\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx title=app/layout.jsx\nimport 'server-only'\nimport SupabaseListener from '../components/supabase-listener'\nimport SupabaseProvider from '../components/supabase-provider'\nimport './globals.css'\nimport { createClient } from '../utils/supabase-server'\n// do not cache this layout\nexport const revalidate = 0\nexport default async function RootLayout({ children }) {\n  const supabase = createClient()\nconst {\n    data: { session },\n  } = await supabase.auth.getSession()\nreturn (\n    \n      {/\n will contain the components returned by the nearest parent\n      head.tsx. Find out more at https://beta.nextjs.org/docs/api-reference/file-conventions/head\n    /}\n      \n\n\n\n          {children}\n        \n\n\n  )\n}\n```\n\n\n```tsx title=app/layout.tsx\nimport 'server-only'\nimport SupabaseListener from '../components/supabase-listener'\nimport SupabaseProvider from '../components/supabase-provider'\nimport './globals.css'\nimport { createClient } from '../utils/supabase-server'\n// do not cache this layout\nexport const revalidate = 0\nexport default async function RootLayout({ children }: { children: React.ReactNode }) {\n  const supabase = createClient()\nconst {\n    data: { session },\n  } = await supabase.auth.getSession()\nreturn (\n    \n      {/\n will contain the components returned by the nearest parent\n      head.tsx. Find out more at https://beta.nextjs.org/docs/api-reference/file-conventions/head\n    /}\n      \n\n\n\n          {children}\n        \n\n\n  )\n}\n```\n\n\nAnd now create our Supabase listener component that uses the singleton Supabase instance to listen for auth changes.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx title=\"/components/supabase-listener.jsx\"\n'use client'\nimport { useRouter } from 'next/navigation'\nimport { useEffect } from 'react'\nimport { useSupabase } from './supabase-provider'\nexport default function SupabaseListener({ serverAccessToken }) {\n  const { supabase } = useSupabase()\n  const router = useRouter()\nuseEffect(() => {\n    const {\n      data: { subscription },\n    } = supabase.auth.onAuthStateChange((event, session) => {\n      if (session?.access_token !== serverAccessToken) {\n        router.refresh()\n      }\n    })\n\n\n```return () => {\n  subscription.unsubscribe()\n}\n```\n\n\n}, [serverAccessToken, router, supabase])\nreturn null\n}\n```\n\n\n```tsx title=\"/components/supabase-listener.tsx\"\n'use client'\nimport { useRouter } from 'next/navigation'\nimport { useEffect } from 'react'\nimport { useSupabase } from './supabase-provider'\nexport default function SupabaseListener({ serverAccessToken }: { serverAccessToken?: string }) {\n  const { supabase } = useSupabase()\n  const router = useRouter()\nuseEffect(() => {\n    const {\n      data: { subscription },\n    } = supabase.auth.onAuthStateChange((event, session) => {\n      if (session?.access_token !== serverAccessToken) {\n        router.refresh()\n      }\n    })\n\n\n```return () => {\n  subscription.unsubscribe()\n}\n```\n\n\n}, [serverAccessToken, router, supabase])\nreturn null\n}\n```\n\n\n\n`use client` tells Next.js that this is a Client Component. Only Client Components can use hooks like `useEffect` and `useRouter`.\n\nThe function we pass to `onAuthStateChange` is automatically called by Supabase whenever a user's session changes. This component takes an `serverAccessToken` prop, which is the server's state for our user. If the `serverAccessToken` and the new session's `access_token` do not match then the client and server are out of sync, therefore, we want to reload the active route.\nNow we can use our `useSupabase` hook throughout our client-side components.\nAuthentication\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx title=\"/components/login.jsx\"\n'use client'\nimport { useSupabase } from './supabase-provider'\n// Supabase auth needs to be triggered client-side\nexport default function Login() {\n  const { supabase, session } = useSupabase()\nconst handleEmailLogin = async () => {\n    await supabase.auth.signInWithPassword({\n      email: 'jon@supabase.com',\n      password: 'password',\n    })\n  }\nconst handleGitHubLogin = async () => {\n    await supabase.auth.signInWithOAuth({\n      provider: 'github',\n    })\n  }\nconst handleLogout = async () => {\n    await supabase.auth.signOut()\n  }\nreturn (\n    <>\n      Email Login\nGitHub Login\nLogout\n\n  )\n}\n```\n\n\n```tsx title=\"/components/login.tsx\"\n'use client'\nimport { useSupabase } from './supabase-provider'\n// Supabase auth needs to be triggered client-side\nexport default function Login() {\n  const { supabase, session } = useSupabase()\nconst handleEmailLogin = async () => {\n    await supabase.auth.signInWithPassword({\n      email: 'jon@supabase.com',\n      password: 'password',\n    })\n  }\nconst handleGitHubLogin = async () => {\n    await supabase.auth.signInWithOAuth({\n      provider: 'github',\n    })\n  }\nconst handleLogout = async () => {\n    await supabase.auth.signOut()\n  }\nreturn (\n    <>\n      Email Login\nGitHub Login\nLogout\n\n  )\n}\n```\n\n\nRealtime\nA nice pattern for fetching data server-side and subscribing to changes client-side can be done by combining Server and Client components.\n\nTo receive realtime events, you must enable replication on your \"posts\" table in Supabase.\n\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nCreate a new file at `/app/realtime/posts.jsx` and populate with the following:\n```jsx title=\"/app/realtime/posts.jsx\"\n'use client'\nimport { useEffect, useState } from 'react'\nimport { useSupabase } from '../../components/supabase-provider'\nexport default function Posts({ serverPosts }) {\n  const [posts, setPosts] = useState(serverPosts)\n  const { supabase } = useSupabase()\nuseEffect(() => {\n    setPosts(serverPosts)\n  }, [serverPosts])\nuseEffect(() => {\n    const channel = supabase\n      .channel('*')\n      .on('postgres_changes', { event: 'INSERT', schema: 'public', table: 'posts' }, (payload) =>\n        setPosts((posts) => [...posts, payload.new])\n      )\n      .subscribe()\n\n\n```return () => {\n  supabase.removeChannel(channel)\n}\n```\n\n\n}, [supabase, setPosts, posts])\nreturn {JSON.stringify(posts, null, 2)}\n}\n```\nThis can now be used in a Server Component to subscribe to realtime updates.\nCreate a new file at `/app/realtime/page.jsx` and populate with the following:\n```jsx title=\"/app/realtime/page.jsx\"\nimport 'server-only'\nimport { createClient } from '../../utils/supabase-server'\nimport Posts from './posts'\n// do not cache this page\nexport const revalidate = 0\nexport default async function Realtime() {\n  const supabase = createClient()\n  const { data } = await supabase.from('posts').select('*')\nreturn \n}\n```\n\n\nCreate a new file at `/app/realtime/posts.tsx` and populate with the following:\n```tsx title=\"/app/realtime/posts.tsx\"\n'use client'\nimport { useEffect, useState } from 'react'\nimport { useSupabase } from '../../components/supabase-provider'\nimport type { Database } from '../../lib/database.types'\ntype Post = Database['public']['Tables']['posts']['Row']\nexport default function Posts({ serverPosts }: { serverPosts: Post[] }) {\n  const [posts, setPosts] = useState(serverPosts)\n  const { supabase } = useSupabase()\nuseEffect(() => {\n    setPosts(serverPosts)\n  }, [serverPosts])\nuseEffect(() => {\n    const channel = supabase\n      .channel('*')\n      .on('postgres_changes', { event: 'INSERT', schema: 'public', table: 'posts' }, (payload) =>\n        setPosts((posts) => [...posts, payload.new as Post])\n      )\n      .subscribe()\n\n\n```return () => {\n  supabase.removeChannel(channel)\n}\n```\n\n\n}, [supabase, setPosts, posts])\nreturn {JSON.stringify(posts, null, 2)}\n}\n```\n\nTypeScript types can be generated with the Supabase CLI and passed to `createServerSupabaseClient` to add type support to the Supabase client.\n\nThis can now be used in a Server Component to subscribe to realtime updates.\nCreate a new file at `/app/realtime/page.tsx` and populate with the following:\n```tsx title=\"/app/realtime/page.tsx\"\nimport 'server-only'\nimport { createClient } from '../../utils/supabase-server'\nimport Posts from './posts'\n// do not cache this page\nexport const revalidate = 0\nexport default async function Realtime() {\n  const supabase = createClient()\n  const { data } = await supabase.from('posts').select('*')\nreturn \n}\n```\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Find these in your Supabase project settings > API",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-helpers/sveltekit.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'sveltekit',\n  title: 'Supabase Auth with SvelteKit',\n  description: 'Convenience helpers for implementing user authentication in SvelteKit.',\n  sidebar_label: 'SvelteKit',\n}\nThis submodule provides convenience helpers for implementing user authentication in SvelteKit applications.\nInstallation\nThis library supports Node.js `^16.15.0`.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n\n\n\n`sh\nnpm install @supabase/auth-helpers-sveltekit`\n\n\n`sh\nyarn add @supabase/auth-helpers-sveltekit`\n\n\nGetting Started\nConfiguration\nSet up the following env vars. For local development you can set them in a `.env` file. See an example.\n```bash\nFind these in your Supabase project settings > API\nPUBLIC_SUPABASE_URL=https://your-project.supabase.co\nPUBLIC_SUPABASE_ANON_KEY=your-anon-key\n```\nSet up the Supabase client\nStart off by creating a `db.ts` file inside of the `src/lib` directory and instantiate the `supabaseClient`.\n```ts title=src/lib/db.ts\nimport { createClient } from '@supabase/auth-helpers-sveltekit'\nimport { env } from '$env/dynamic/public'\n// or use the static env\n// import { PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY } from '$env/static/public';\nexport const supabaseClient = createClient(env.PUBLIC_SUPABASE_URL, env.PUBLIC_SUPABASE_ANON_KEY)\n```\nTo make sure the client is initialized on the server and the client, include this file in `src/hooks.server.js` and `src/hooks.client.js`:\n`ts\nimport '$lib/db'`\nSynchronizing the page store\nEdit your `+layout.svelte` file and set up the client side.\n```html title=src/routes/+layout.svelte\n\n\n```\nEvery `PageLoad` or `LayoutLoad` using `getSupabase()` will update when `invalidate('supabase:auth')` is called.\nIf some data is not updated on signin/signout you can fall back to `invalidateAll()`.\nSend session to client\nTo make the session available to the UI (pages, layouts), pass the session in the root layout server load function:\n```ts title=src/routes/+layout.server.ts\nimport type { LayoutServerLoad } from './$types'\nimport { getServerSession } from '@supabase/auth-helpers-sveltekit'\nexport const load: LayoutServerLoad = async (event) => {\n  return {\n    session: await getServerSession(event),\n  }\n}\n```\nIn addition you can create a layout load function if you are using `invalidate('supabase:auth')`:\n```ts title=src/routes/+layout.ts\nimport type { LayoutLoad } from './$types'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nexport const load: LayoutLoad = async (event) => {\n  const { session } = await getSupabase(event)\n  return { session }\n}\n```\nThis results in fewer server calls as the client manages the session on its own.\nTypings\nIn order to get the most out of TypeScript and it\u00b4s intellisense, you should import our types into the `app.d.ts` type definition file that comes with your SvelteKit project.\n```ts title=src/app.d.ts\n/// \n// See https://kit.svelte.dev/docs/types#app\n// for information about these interfaces\n// and what to do when importing types\ndeclare namespace App {\n  interface Supabase {\n    // Use the path to where you generated the types using the Supbase CLI.\n    Database: import('../types/supabase').Database;\n    SchemaName: 'public'\n  }\n// interface Locals {}\n  interface PageData {\n    session: import('@supabase/supabase-js').Session | null\n  }\n  // interface Error {}\n  // interface Platform {}\n}\n```\nBasic Setup\nYou can now determine if a user is authenticated on the client-side by checking that the `session` object in `$page.data` is defined.\n```html title=src/routes/+page.svelte\n\n{#if !$page.data.session}\nI am not logged in\n{:else}\nWelcome {$page.data.session.user.email}\nI am logged in!\n{/if}\n```\nClient-side data fetching with RLS\nFor row level security to work properly when fetching data client-side, you need to make sure to import the `{ supabaseClient }` from `$lib/db` and only run your query once the session is defined client-side in `$page.data`:\n```html\n\n{#if $page.data.session}\nclient-side data fetching with RLS\n{JSON.stringify(loadedData, null, 2)}\n{/if}\n```\nServer-side data fetching with RLS\n```html title=src/routes/profile/+page.svelte\n\nProtected content for {user.email}\n{JSON.stringify(tableData, null, 2)}\n{JSON.stringify(user, null, 2)}\n```\nFor row level security to work in a server environment, you need to use the `getSupabase` helper to check if the user is authenticated. The helper requires the `event` and returns `session` and `supabaseClient`:\n```ts title=src/routes/profile/+page.ts\nimport type { PageLoad } from './$types'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nimport { redirect } from '@sveltejs/kit'\nexport const load: PageLoad = async (event) => {\n  const { session, supabaseClient } = await getSupabase(event)\n  if (!session) {\n    throw redirect(303, '/')\n  }\n  const { data: tableData } = await supabaseClient.from('test').select('*')\nreturn {\n    user: session.user,\n    tableData,\n  }\n}\n```\nProtecting API routes\nWrap an API Route to check that the user has a valid session. If they're not logged in the session is `null`.\n```ts title=src/routes/api/protected-route/+server.ts\nimport type { RequestHandler } from './$types'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nimport { json, redirect } from '@sveltejs/kit'\nexport const GET: RequestHandler = async (event) => {\n  const { session, supabaseClient } = await getSupabase(event)\n  if (!session) {\n    throw redirect(303, '/')\n  }\n  const { data } = await supabaseClient.from('test').select('*')\nreturn json({ data })\n}\n```\nIf you visit `/api/protected-route` without a valid session cookie, you will get a 303 response.\nProtecting Actions\nWrap an Action to check that the user has a valid session. If they're not logged in the session is `null`.\n```ts title=src/routes/posts/+page.server.ts\nimport type { Actions } from './$types'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nimport { error, fail } from '@sveltejs/kit'\nexport const actions: Actions = {\n  createPost: async (event) => {\n    const { request } = event\n    const { session, supabaseClient } = await getSupabase(event)\n    if (!session) {\n      // the user is not signed in\n      throw error(403, { message: 'Unauthorized' })\n    }\n    // we are save, let the user create the post\n    const formData = await request.formData()\n    const content = formData.get('content')\n\n\n```const { error: createPostError, data: newPost } = await supabaseClient\n  .from('posts')\n  .insert({ content })\n\nif (createPostError) {\n  return fail(500, {\n    supabaseErrorMessage: createPostError.message,\n  })\n}\nreturn {\n  newPost,\n}\n```\n\n\n},\n}\n```\nIf you try to submit a form with the action `?/createPost` without a valid session cookie, you will get a 403 error response.\nSaving and deleting the session\n```ts\nimport type { Actions } from './$types'\nimport { fail, redirect } from '@sveltejs/kit'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nimport { AuthApiError } from '@supabase/supabase-js'\nexport const actions: Actions = {\n  signin: async (event) => {\n    const { request, cookies, url } = event\n    const { session, supabaseClient } = await getSupabase(event)\n    const formData = await request.formData()\n\n\n```const email = formData.get('email') as string\nconst password = formData.get('password') as string\n\nconst { error } = await supabaseClient.auth.signInWithPassword({\n  email,\n  password,\n})\n\nif (error) {\n  if (error instanceof AuthApiError && error.status === 400) {\n    return fail(400, {\n      error: 'Invalid credentials.',\n      values: {\n        email,\n      },\n    })\n  }\n  return fail(500, {\n    error: 'Server error. Try again later.',\n    values: {\n      email,\n    },\n  })\n}\n\nthrow redirect(303, '/dashboard')\n```\n\n\n},\nsignout: async (event) => {\n    const { supabaseClient } = await getSupabase(event)\n    await supabaseClient.auth.signOut()\n    throw redirect(303, '/')\n  },\n}\n```\nProtecting multiple routes\nTo avoid writing the same auth logic in every single route you can use the handle hook to\nprotect multiple routes at once.\n```ts title=src/hooks.server.ts\nimport type { RequestHandler } from './$types'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nimport { redirect, error } from '@sveltejs/kit'\nexport const handle: Handle = async ({ event, resolve }) => {\n  // protect requests to all routes that start with /protected-routes\n  if (event.url.pathname.startsWith('/protected-routes')) {\n    const { session, supabaseClient } = await getSupabase(event)\n\n\n```if (!session) {\n  throw redirect(303, '/')\n}\n```\n\n\n}\n// protect POST requests to all routes that start with /protected-posts\n  if (event.url.pathname.startsWith('/protected-posts') && event.request.method === 'POST') {\n    const { session, supabaseClient } = await getSupabase(event)\n\n\n```if (!session) {\n  throw error(303, '/')\n}\n```\n\n\n}\nreturn resolve(event)\n}\n```\nMigrate from 0.7.x to 0.8 [#migration]\nSet up the Supabase client [#migration-set-up-supabase-client]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older-0.7\"\n\n\n\n```js title=src/lib/db.ts\nimport { createClient } from '@supabase/supabase-js'\nimport { setupSupabaseHelpers } from '@supabase/auth-helpers-sveltekit'\nimport { dev } from '$app/environment'\nimport { env } from '$env/dynamic/public'\n// or use the static env\n// import { PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY } from '$env/static/public';\nexport const supabaseClient = createClient(env.PUBLIC_SUPABASE_URL, env.PUBLIC_SUPABASE_ANON_KEY, {\n  persistSession: false,\n  autoRefreshToken: false,\n})\nsetupSupabaseHelpers({\n  supabaseClient,\n  cookieOptions: {\n    secure: !dev,\n  },\n})\n```\n\n\n```js title=src/lib/db.ts\nimport { createClient } from '@supabase/auth-helpers-sveltekit'\nimport { env } from '$env/dynamic/public'\n// or use the static env\n// import { PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY } from '$env/static/public';\nexport const supabaseClient = createClient(env.PUBLIC_SUPABASE_URL, env.PUBLIC_SUPABASE_ANON_KEY)\n```\n\n\nInitialize the client [#migration-initialize-client]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older-0.7\"\n\n\n\n```html title=src/routes/+layout.svelte\n\n\n```\n\n\n```html title=src/routes/+layout.svelte\n\n\n```\n\n\nSet up hooks [#migration-set-up-hooks]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older-0-7\"\n\n\n\n```ts title=src/hooks.server.ts\n// make sure the supabase instance is initialized on the server\nimport '$lib/db'\nimport { dev } from '$app/environment'\nimport { auth } from '@supabase/auth-helpers-sveltekit/server'\nexport const handle = auth()\n```\nOptional if using additional handle methods\n```ts title=src/hooks.server.ts\n// make sure the supabase instance is initialized on the server\nimport '$lib/db'\nimport { dev } from '$app/environment'\nimport { auth } from '@supabase/auth-helpers-sveltekit/server'\nimport { sequence } from '@sveltejs/kit/hooks'\nexport const handle = sequence(auth(), yourHandler)\n```\n\n\n`ts title=src/hooks.server.ts\n// make sure the supabase instance is initialized on the server\nimport '$lib/db'`\n`ts title=src/hooks.client.ts\n// make sure the supabase instance is initialized on the client\nimport '$lib/db'`\n\n\nTypings [#migration-typings]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older-0-7\"\n\n\n\n```ts title=src/app.d.ts\n/// \n// See https://kit.svelte.dev/docs/types#app\n// for information about these interfaces\n// and what to do when importing types\ndeclare namespace App {\n  interface Locals {\n    session: import('@supabase/auth-helpers-sveltekit').SupabaseSession\n  }\ninterface PageData {\n    session: import('@supabase/auth-helpers-sveltekit').SupabaseSession\n  }\n// interface Error {}\n  // interface Platform {}\n}\n```\n\n\n```ts title=src/app.d.ts\n/// \n// See https://kit.svelte.dev/docs/types#app\n// for information about these interfaces\n// and what to do when importing types\ndeclare namespace App {\n  interface Supabase {\n    Database: import('./DatabaseDefinitions').Database\n    SchemaName: 'public'\n  }\n// interface Locals {}\n  interface PageData {\n    session: import('@supabase/auth-helpers-sveltekit').SupabaseSession\n  }\n  // interface Error {}\n  // interface Platform {}\n}\n```\n\n\nwithPageAuth [#migration-with-page-auth]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older-0-7\"\n\n\n\n```html title=src/routes/protected-route/+page.svelte\n\nProtected content for {user.email}\nserver-side fetched data with RLS:\n{JSON.stringify(tableData, null, 2)}\nuser:\n{JSON.stringify(user, null, 2)}\n```\n```ts title=src/routes/protected-route/+page.ts\nimport { withAuth } from '@supabase/auth-helpers-sveltekit'\nimport { redirect } from '@sveltejs/kit'\nimport type { PageLoad } from './$types'\nexport const load: PageLoad = withAuth(async ({ session, getSupabaseClient }) => {\n  if (!session.user) {\n    throw redirect(303, '/')\n  }\nconst { data: tableData } = await getSupabaseClient().from('test').select('*')\n  return { tableData, user: session.user }\n})\n```\n\n\n```html title=src/routes/protected-route/+page.svelte\n\nProtected content for {user.email}\n{JSON.stringify(tableData, null, 2)}\n{JSON.stringify(user, null, 2)}\n```\n```ts title=src/routes/protected-route/+page.ts\n// src/routes/profile/+page.ts\nimport type { PageLoad } from './$types'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nimport { redirect } from '@sveltejs/kit'\nexport const load: PageLoad = async (event) => {\n  const { session, supabaseClient } = await getSupabase(event)\n  if (!session) {\n    throw redirect(303, '/')\n  }\n  const { data: tableData } = await supabaseClient.from('test').select('*')\nreturn {\n    user: session.user,\n    tableData,\n  }\n}\n```\n\n\nwithApiAuth [#migration-with-api-auth]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older-0-7\"\n\n\n\n```ts title=src/routes/api/protected-route/+server.ts\nimport type { RequestHandler } from './$types'\nimport { withAuth } from '@supabase/auth-helpers-sveltekit'\nimport { json, redirect } from '@sveltejs/kit'\ninterface TestTable {\n  id: string\n  created_at: string\n}\nexport const GET: RequestHandler = withAuth(async ({ session, getSupabaseClient }) => {\n  if (!session.user) {\n    throw redirect(303, '/')\n  }\nconst { data } = await getSupabaseClient().from('test').select('*')\nreturn json({ data })\n})\n```\n\n\n```ts title=src/routes/api/protected-route/+server.ts\nimport type { RequestHandler } from './$types'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nimport { json, redirect } from '@sveltejs/kit'\nexport const GET: RequestHandler = async (event) => {\n  const { session, supabaseClient } = await getSupabase(event)\n  if (!session) {\n    throw redirect(303, '/')\n  }\n  const { data } = await supabaseClient.from('test').select('*')\nreturn json({ data })\n}\n```\n\n\nMigrate from 0.6.11 and below to 0.7.0 [#migration-0-7]\nThere are numerous breaking changes in the latest 0.7.0 version of this library.\nEnvironment variable prefix\nThe environment variable prefix is now `PUBLIC_` instead of `VITE_` (e.g., `VITE_SUPABASE_URL` is now `PUBLIC_SUPABASE_URL`).\nSet up the Supabase client [#migration-set-up-supabase-client-0-7]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older\"\n\n\n\n```js title=src/lib/db.ts\nimport { createSupabaseClient } from '@supabase/auth-helpers-sveltekit';\nconst { supabaseClient } = createSupabaseClient(\n  import.meta.env.VITE_SUPABASE_URL as string,\n  import.meta.env.VITE_SUPABASE_ANON_KEY as string\n);\nexport { supabaseClient };\n```\n\n\n```js title=src/lib/db.ts\nimport { createClient } from '@supabase/supabase-js'\nimport { setupSupabaseHelpers } from '@supabase/auth-helpers-sveltekit'\nimport { dev } from '$app/environment'\nimport { env } from '$env/dynamic/public'\n// or use the static env\n// import { PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY } from '$env/static/public';\nexport const supabaseClient = createClient(env.PUBLIC_SUPABASE_URL, env.PUBLIC_SUPABASE_ANON_KEY, {\n  persistSession: false,\n  autoRefreshToken: false,\n})\nsetupSupabaseHelpers({\n  supabaseClient,\n  cookieOptions: {\n    secure: !dev,\n  },\n})\n```\n\n\nInitialize the client [#migration-initialize-client-0-7]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older\"\n\n\n\n```html title=src/routes/__layout.svelte\n\n\n\n\n```\n\n\nThe `@supabase/auth-helpers-svelte` library is no longer required as the `@supabase/auth-helpers-sveltekit` library handles all the client-side code.\n```html title=src/routes/+layout.svelte\n\n\n```\n\n\nSet up hooks [#migration-set-up-hooks-0-7]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older\"\n\n\n\n```ts title=src/hooks.ts\nimport { handleAuth } from '@supabase/auth-helpers-sveltekit'\nimport type { GetSession, Handle } from '@sveltejs/kit'\nimport { sequence } from '@sveltejs/kit/hooks'\nexport const handle: Handle = sequence(...handleAuth())\nexport const getSession: GetSession = async (event) => {\n  const { user, accessToken, error } = event.locals\n  return {\n    user,\n    accessToken,\n    error,\n  }\n}\n```\n\n\n```ts title=src/hooks.server.ts\n// make sure the supabase instance is initialized on the server\nimport '$lib/db'\nimport { dev } from '$app/environment'\nimport { auth } from '@supabase/auth-helpers-sveltekit/server'\nexport const handle = auth()\n```\nOptional if using additional handle methods\n```ts title=src/hooks.server.ts\n// make sure the supabase instance is initialized on the server\nimport '$lib/db'\nimport { dev } from '$app/environment'\nimport { auth } from '@supabase/auth-helpers-sveltekit/server'\nimport { sequence } from '@sveltejs/kit/hooks'\nexport const handle = sequence(auth(), yourHandler)\n```\n\n\nTypings [#migration-typings-0-7]\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older\"\n\n\n\n```ts title=src/app.d.ts\n/// \n// See https://kit.svelte.dev/docs/types#app\n// for information about these interfaces\ndeclare namespace App {\n  interface UserSession {\n    user: import('@supabase/supabase-js').User\n    accessToken?: string\n  }\ninterface Locals extends UserSession {\n    error: import('@supabase/supabase-js').ApiError\n  }\ninterface Session extends UserSession {}\n// interface Platform {}\n  // interface Stuff {}\n}\n```\n\n\n```ts title=src/app.d.ts\n/// \n// See https://kit.svelte.dev/docs/types#app\n// for information about these interfaces\n// and what to do when importing types\ndeclare namespace App {\n  interface Locals {\n    session: import('@supabase/auth-helpers-sveltekit').SupabaseSession\n  }\ninterface PageData {\n    session: import('@supabase/auth-helpers-sveltekit').SupabaseSession\n  }\n// interface Error {}\n  // interface Platform {}\n}\n```\n\n\nCheck the user on the client\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older\"\n\n\n\n```html title=src/routes/index.svelte\n\n{#if !$session.user}\nI am not logged in\n{:else}\nWelcome {$session.user.email}\nI am logged in!\n{/if}\n```\n\n\n```html title=src/routes/+page.svelte\n\n{#if !$page.data.session.user}\nI am not logged in\n{:else}\nWelcome {$page.data.session.user.email}\nI am logged in!\n{/if}\n```\n\n\nwithPageAuth\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older\"\n\n\n\n```html title=src/routes/protected-route.svelte\n\n\nProtected content for {user.email}\nserver-side fetched data with RLS:\n{JSON.stringify(data, null, 2)}\nuser:\n{JSON.stringify(user, null, 2)}\n```\n\n\n```html title=src/routes/protected-route/+page.svelte\n\nProtected content for {user.email}\nserver-side fetched data with RLS:\n{JSON.stringify(tableData, null, 2)}\nuser:\n{JSON.stringify(user, null, 2)}\n```\n```ts title=src/routes/protected-route/+page.ts\nimport { withAuth } from '@supabase/auth-helpers-sveltekit'\nimport { redirect } from '@sveltejs/kit'\nimport type { PageLoad } from './$types'\nexport const load: PageLoad = withAuth(async ({ session, getSupabaseClient }) => {\n  if (!session.user) {\n    throw redirect(303, '/')\n  }\nconst { data: tableData } = await getSupabaseClient().from('test').select('*')\n  return { tableData, user: session.user }\n})\n```\n\n\nwithApiAuth\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"older\"\n\n\n\n```ts title=src/routes/api/protected-route.ts\nimport { supabaseServerClient, withApiAuth } from '@supabase/auth-helpers-sveltekit'\nimport type { RequestHandler } from './__types/protected-route'\ninterface TestTable {\n  id: string\n  created_at: string\n}\ninterface GetOutput {\n  data: TestTable[]\n}\nexport const GET: RequestHandler = async ({ locals, request }) =>\n  withApiAuth({ user: locals.user }, async () => {\n    // Run queries with RLS on the server\n    const { data } = await supabaseServerClient(request).from('test').select('*')\n\n\n```return {\n  status: 200,\n  body: { data },\n}\n```\n\n\n})\n```\n\n\n```ts title=src/routes/api/protected-route/+server.ts\nimport type { RequestHandler } from './$types';\nimport { withAuth } from '@supabase/auth-helpers-sveltekit';\nimport { json, redirect } from '@sveltejs/kit';\ninterface TestTable {\n  id: string;\n  created_at: string;\n}\nexport const GET: RequestHandler = withAuth(async ({ session, getSupabaseClient }) => {\n  if (!session.user) {\n    throw redirect(303, '/');\n  }\nconst { data } = await getSupabaseClient()\n    .from('test')\n    .select('*');\nreturn json({ data });\n);\n```\n\n\nAdditional Links\n\nAuth Helpers Source code\nSvelteKit example\nSvelteKit Email/Password example\nSvelteKit Magiclink example\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Install the Next.js helper library",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-helpers/nextjs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'nextjs',\n  title: 'Supabase Auth with Next.js',\n  description: 'Authentication helpers for Next.js API routes, middleware, and SSR.',\n  sidebar_label: 'Next.js',\n}\nThis submodule provides convenience helpers for implementing user authentication in Next.js applications.\nInstall the Next.js helper library\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n\n\n\n`sh\nnpm install @supabase/auth-helpers-nextjs`\nThis library supports the following tooling versions:\n\nNode.js: `^10.13.0 || >=12.0.0`\nNext.js: `>=10`\n\n\nNote: Next.js 13 is stable, however, the new `app` directory and Server Components are still in beta. Check out our experimental guide on using Auth Helpers with Next.js Server Components.\n\nAdditionally, install the React Auth Helpers for components and hooks that can be used across all React-based frameworks.\n`sh\nnpm install @supabase/auth-helpers-react`\n\n\n`sh\nyarn add @supabase/auth-helpers-nextjs`\nThis library supports the following tooling versions:\n\nNode.js: `^10.13.0 || >=12.0.0`\nNext.js: `>=10`\n\n\nNote: Next.js 13 is stable, however, the new `app` directory and Server Components are still in beta. Check out our experimental guide on using Auth Helpers with Next.js Server Components.\n\nAdditionally, install the React Auth Helpers for components and hooks that can be used across all React-based frameworks.\n`sh\nyarn add @supabase/auth-helpers-react`\n\n\nSet up environment variables\nRetrieve your project URL and anon key in your project's API settings in the Dashboard to set up the following environment variables. For local development you can set them in a `.env.local` file. See an example.\n`bash title=.env.local\nNEXT_PUBLIC_SUPABASE_URL=YOUR_SUPABASE_URL\nNEXT_PUBLIC_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nBasic Setup\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nWrap your `pages/_app.js` component with the `SessionContextProvider` component:\n```jsx title=pages/_app.js\nimport { createBrowserSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { SessionContextProvider } from '@supabase/auth-helpers-react'\nimport { useState } from 'react'\nfunction MyApp({ Component, pageProps }) {\n  // Create a new supabase browser client on every first render.\n  const [supabaseClient] = useState(() => createBrowserSupabaseClient())\nreturn (\n    \n\n\n  )\n}\n```\n\n\nWrap your `pages/_app.tsx` component with the `SessionContextProvider` component:\n```tsx lines=2,8 title=pages/_app.tsx\nimport { createBrowserSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { SessionContextProvider, Session } from '@supabase/auth-helpers-react'\nimport { useState } from 'react'\nfunction MyApp({\n  Component,\n  pageProps,\n}: AppProps<{\n  initialSession: Session\n}>) {\n  // Create a new supabase browser client on every first render.\n  const [supabaseClient] = useState(() => createBrowserSupabaseClient())\nreturn (\n    \n\n\n  )\n}\n```\n\n\nYou can now determine if a user is authenticated by checking that the `user` object returned by the `useUser()` hook is defined.\nUsage with TypeScript\nYou can pass types that were generated with the Supabase CLI to the Supabase Client to get enhanced type safety and auto completion:\nBrowser client\nCreating a new supabase client object:\n```tsx\nimport { createBrowserSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { Database } from '../database.types'\nconst supabaseClient = createBrowserSupabaseClient()\n```\nRetrieving a supabase client object from the SessionContext:\n```tsx\nimport { useSupabaseClient } from '@supabase/auth-helpers-react'\nimport { Database } from '../database.types'\nconst supabaseClient = useSupabaseClient()\n```\nServer client\n```tsx\n// Creating a new supabase server client object (e.g. in API route):\nimport { createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport type { NextApiRequest, NextApiResponse } from 'next'\nimport type { Database } from 'types_db'\nexport default async (req: NextApiRequest, res: NextApiResponse) => {\n  const supabaseServerClient = createServerSupabaseClient({\n    req,\n    res,\n  })\n  const {\n    data: { user },\n  } = await supabaseServerClient.auth.getUser()\nres.status(200).json({ name: user?.name ?? '' })\n}\n```\nClient-side data fetching with RLS\nFor row level security to work properly when fetching data client-side, you need to make sure to use the `supabaseClient` from the `useSupabaseClient` hook and only run your query once the user is defined client-side in the `useUser()` hook:\n```jsx lines=10-17\nimport { Auth, ThemeSupa } from '@supabase/auth-ui-react'\nimport { useUser, useSupabaseClient } from '@supabase/auth-helpers-react'\nimport { useEffect, useState } from 'react'\nconst LoginPage = () => {\n  const supabaseClient = useSupabaseClient()\n  const user = useUser()\n  const [data, setData] = useState()\nuseEffect(() => {\n    async function loadData() {\n      const { data } = await supabaseClient.from('test').select('*')\n      setData(data)\n    }\n    // Only run query once user is logged in.\n    if (user) loadData()\n  }, [user])\nif (!user)\n    return (\n      \n    )\nreturn (\n    <>\n       supabaseClient.auth.signOut()}>Sign out\nuser:\n{JSON.stringify(user, null, 2)}\nclient-side data fetching with RLS\n{JSON.stringify(data, null, 2)}\n\n  )\n}\nexport default LoginPage\n```\nServer-side rendering (SSR)\nCreate a server supabase client to retrieve the logged in user's session:\n```jsx title=pages/profile.js\nimport { createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nexport default function Profile({ user }) {\n  return Hello {user.name}\n}\nexport const getServerSideProps = async (ctx) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient(ctx)\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return {\n      redirect: {\n        destination: '/',\n        permanent: false,\n      },\n    }\nreturn {\n    props: {\n      initialSession: session,\n      user: session.user,\n    },\n  }\n}\n```\nServer-side data fetching with RLS\nYou can use the server supabase client to run row level security authenticated queries server-side:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx\nimport { createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nexport default function ProtectedPage({ user, data }) {\n  return (\n    <>\n      Protected content for {user.email}\n{JSON.stringify(data, null, 2)}\n{JSON.stringify(user, null, 2)}\n\n  )\n}\nexport const getServerSideProps = async (ctx) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient(ctx)\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return {\n      redirect: {\n        destination: '/',\n        permanent: false,\n      },\n    }\n// Run queries with RLS on the server\n  const { data } = await supabase.from('users').select('*')\nreturn {\n    props: {\n      initialSession: session,\n      user: session.user,\n      data: data ?? [],\n    },\n  }\n}\n```\n\n\n```tsx\nimport { User, createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { GetServerSidePropsContext } from 'next'\nexport default function ProtectedPage({ user, data }: { user: User; data: any }) {\n  return (\n    <>\n      Protected content for {user.email}\n{JSON.stringify(data, null, 2)}\n{JSON.stringify(user, null, 2)}\n\n  )\n}\nexport const getServerSideProps = async (ctx: GetServerSidePropsContext) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient(ctx)\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return {\n      redirect: {\n        destination: '/',\n        permanent: false,\n      },\n    }\n// Run queries with RLS on the server\n  const { data } = await supabase.from('users').select('*')\nreturn {\n    props: {\n      initialSession: session,\n      user: session.user,\n      data: data ?? [],\n    },\n  }\n}\n```\n\n\nServer-side data fetching to OAuth APIs using `provider token` {`#oauth-provider-token`}\nWhen using third-party auth providers, sessions are initiated with an additional `provider_token` field which is persisted in the auth cookie and can be accessed within the session object. The `provider_token` can be used to make API requests to the OAuth provider's API endpoints on behalf of the logged-in user.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx\nimport { createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nexport default function ProtectedPage({ user, allRepos }) {\n  return (\n    <>\n      Protected content for {user.email}\nData fetched with provider token:\n{JSON.stringify(allRepos, null, 2)}\nuser:\n{JSON.stringify(user, null, 2)}\n\n  )\n}\nexport const getServerSideProps = async (ctx) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient(ctx)\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return {\n      redirect: {\n        destination: '/',\n        permanent: false,\n      },\n    }\n// Retrieve provider_token & logged in user's third-party id from metadata\n  const { provider_token, user } = session\n  const userId = user.user_metadata.user_name\nconst allRepos = await (\n    await fetch(`https://api.github.com/search/repositories?q=user:${userId}`, {\n      method: 'GET',\n      headers: {\n        Authorization: `token ${provider_token}`,\n      },\n    })\n  ).json()\nreturn { props: { user, allRepos } }\n}\n```\n\n\n```tsx\nimport { User, createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { GetServerSidePropsContext } from 'next'\nexport default function ProtectedPage({ user, allRepos }: { user: User; allRepos: any }) {\n  return (\n    <>\n      Protected content for {user.email}\nData fetched with provider token:\n{JSON.stringify(allRepos, null, 2)}\nuser:\n{JSON.stringify(user, null, 2)}\n\n  )\n}\nexport const getServerSideProps = async (ctx: GetServerSidePropsContext) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient(ctx)\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return {\n      redirect: {\n        destination: '/',\n        permanent: false,\n      },\n    }\n// Retrieve provider_token & logged in user's third-party id from metadata\n  const { provider_token, user } = session\n  const userId = user.user_metadata.user_name\nconst allRepos = await (\n    await fetch(`https://api.github.com/search/repositories?q=user:${userId}`, {\n      method: 'GET',\n      headers: {\n        Authorization: `token ${provider_token}`,\n      },\n    })\n  ).json()\nreturn { props: { user, allRepos } }\n}\n```\n\n\nProtecting API routes\nCreate a server supabase client to retrieve the logged in user's session:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx title=pages/api/protected-route.js\nimport { createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nconst ProtectedRoute = async (req, res) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient({ req, res })\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return res.status(401).json({\n      error: 'not_authenticated',\n      description: 'The user does not have an active session or is not authenticated',\n    })\n// Run queries with RLS on the server\n  const { data } = await supabase.from('test').select('*')\n  res.json(data)\n}\nexport default ProtectedRoute\n```\n\n\n```tsx title=pages/api/protected-route.ts\nimport { NextApiHandler } from 'next'\nimport { createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nconst ProtectedRoute: NextApiHandler = async (req, res) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient({ req, res })\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return res.status(401).json({\n      error: 'not_authenticated',\n      description: 'The user does not have an active session or is not authenticated',\n    })\n// Run queries with RLS on the server\n  const { data } = await supabase.from('test').select('*')\n  res.json(data)\n}\nexport default ProtectedRoute\n```\n\n\nAuth with Next.js Middleware\nAs an alternative to protecting individual pages you can use a Next.js Middleware to protect the entire directory or those that match the config object. In the following example, all requests to `/middleware-protected/*` will check whether a user is signed in, if successful the request will be forwarded to the destination route, otherwise the user will be redirected:\n```ts title=middleware.ts\nimport { createMiddlewareSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { NextResponse } from 'next/server'\nimport type { NextRequest } from 'next/server'\nexport async function middleware(req: NextRequest) {\n  // We need to create a response and hand it to the supabase client to be able to modify the response headers.\n  const res = NextResponse.next()\n  // Create authenticated Supabase Client.\n  const supabase = createMiddlewareSupabaseClient({ req, res })\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\n// Check auth condition\n  if (session?.user.email?.endsWith('@gmail.com')) {\n    // Authentication successful, forward request to protected route.\n    return res\n  }\n// Auth condition not met, redirect to home page.\n  const redirectUrl = req.nextUrl.clone()\n  redirectUrl.pathname = '/'\n  redirectUrl.searchParams.set(`redirectedFrom`, req.nextUrl.pathname)\n  return NextResponse.redirect(redirectUrl)\n}\nexport const config = {\n  matcher: '/middleware-protected/:path*',\n}\n```\nMigration Guide\nMigrating to v0.5.X\nTo make these helpers more flexible as well as more maintainable and easier to upgrade for new versions of Next.js, we're stripping them down to the most useful part which is managing the cookies and giving you an authenticated supabase-js client in any environment (client, server, middleware/edge).\nTherefore we're marking the `withApiAuth`, `withPageAuth`, and `withMiddlewareAuth` higher order functions as deprecated and they will be removed in the next minor release (v0.6.X).\nPlease follow the steps below to update your API routes, pages, and middleware handlers. Thanks!\n`withApiAuth` deprecated!\nUse `createServerSupabaseClient` within your `NextApiHandler`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"before\"\n\n\n\n```tsx title=pages/api/protected-route.ts\nimport { withApiAuth } from '@supabase/auth-helpers-nextjs'\nexport default withApiAuth(async function ProtectedRoute(req, res, supabase) {\n  // Run queries with RLS on the server\n  const { data } = await supabase.from('test').select('*')\n  res.json(data)\n})\n```\n\n\n```tsx title=pages/api/protected-route.ts\nimport { NextApiHandler } from 'next'\nimport { createServerSupabaseClient } from '@supabase/auth-helpers-nextjs'\nconst ProtectedRoute: NextApiHandler = async (req, res) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient({ req, res })\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return res.status(401).json({\n      error: 'not_authenticated',\n      description: 'The user does not have an active session or is not authenticated',\n    })\n// Run queries with RLS on the server\n  const { data } = await supabase.from('test').select('*')\n  res.json(data)\n}\nexport default ProtectedRoute\n```\n\n\n`withPageAuth` deprecated!\nUse `createServerSupabaseClient` within `getServerSideProps`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"before\"\n\n\n\n```tsx title=pages/profile.tsx\nimport { withPageAuth, User } from '@supabase/auth-helpers-nextjs'\nexport default function Profile({ user }: { user: User }) {\n  return {JSON.stringify(user, null, 2)}\n}\nexport const getServerSideProps = withPageAuth({ redirectTo: '/' })\n```\n\n\n```tsx title=pages/profile.js\nimport { createServerSupabaseClient, User } from '@supabase/auth-helpers-nextjs'\nimport { GetServerSidePropsContext } from 'next'\nexport default function Profile({ user }: { user: User }) {\n  return {JSON.stringify(user, null, 2)}\n}\nexport const getServerSideProps = async (ctx: GetServerSidePropsContext) => {\n  // Create authenticated Supabase Client\n  const supabase = createServerSupabaseClient(ctx)\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\nif (!session)\n    return {\n      redirect: {\n        destination: '/',\n        permanent: false,\n      },\n    }\nreturn {\n    props: {\n      initialSession: session,\n      user: session.user,\n    },\n  }\n}\n```\n\n\n`withMiddlewareAuth` deprecated!\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"before\"\n\n\n\n```tsx title=middleware.ts\nimport { withMiddlewareAuth } from '@supabase/auth-helpers-nextjs'\nexport const middleware = withMiddlewareAuth({\n  redirectTo: '/',\n  authGuard: {\n    isPermitted: async (user) => {\n      return user.email?.endsWith('@gmail.com') ?? false\n    },\n    redirectTo: '/insufficient-permissions',\n  },\n})\nexport const config = {\n  matcher: '/middleware-protected',\n}\n```\n\n\n```tsx title=middleware.ts\nimport { createMiddlewareSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { NextResponse } from 'next/server'\nimport type { NextRequest } from 'next/server'\nexport async function middleware(req: NextRequest) {\n  // We need to create a response and hand it to the supabase client to be able to modify the response headers.\n  const res = NextResponse.next()\n  // Create authenticated Supabase Client.\n  const supabase = createMiddlewareSupabaseClient({ req, res })\n  // Check if we have a session\n  const {\n    data: { session },\n  } = await supabase.auth.getSession()\n// Check auth condition\n  if (session?.user.email?.endsWith('@gmail.com')) {\n    // Authentication successful, forward request to protected route.\n    return res\n  }\n// Auth condition not met, redirect to home page.\n  const redirectUrl = req.nextUrl.clone()\n  redirectUrl.pathname = '/'\n  redirectUrl.searchParams.set(`redirectedFrom`, req.nextUrl.pathname)\n  return NextResponse.redirect(redirectUrl)\n}\nexport const config = {\n  matcher: '/middleware-protected',\n}\n```\n\n\nMigrating to v0.4.X and supabase-js v2\nWith the update to `supabase-js` v2 the `auth` API routes are no longer required, therefore you can go ahead and delete your `auth` directory under the `/pages/api/` directory. Please refer to the v2 migration guide for the full set of changes within supabase-js.\nThe `/api/auth/logout` API route has been removed, please use the `signout` method instead:\n```jsx\n {\n    await supabaseClient.auth.signOut()\n    router.push('/')\n  }}\n\nLogout\n\n```\n\nThe `supabaseClient` and `supabaseServerClient` have been removed in favor of the `createBrowserSupabaseClient` and `createServerSupabaseClient` methods. This allows you to provide the CLI-generated types to the client:\n```tsx\n// client-side\nimport type { Database } from 'types_db'\nconst [supabaseClient] = useState(() => createBrowserSupabaseClient())\n// server-side API route\nimport type { NextApiRequest, NextApiResponse } from 'next'\nimport type { Database } from 'types_db'\nexport default async (req: NextApiRequest, res: NextApiResponse) => {\n  const supabaseServerClient = createServerSupabaseClient({\n    req,\n    res,\n  })\n  const {\n    data: { user },\n  } = await supabaseServerClient.auth.getUser()\nres.status(200).json({ name: user?.name ?? '' })\n}\n```\n\nThe `UserProvider` has been replaced by the `SessionContextProvider`. Make sure to wrap your `pages/_app.js` componenent with the `SessionContextProvider`. Then, throughout your application you can use the `useSessionContext` hook to get the `session` and the `useSupabaseClient` hook to get an authenticated `supabaseClient`.\nThe `useUser` hook now returns the `user` object or `null`.\nUsage with TypeScript: You can pass types that were generated with the Supabase CLI to the Supabase Client to get enhanced type safety and auto completion:\n\nCreating a new supabase client object:\n```tsx\nimport { Database } from '../database.types'\nconst [supabaseClient] = useState(() => createBrowserSupabaseClient())\n```\nRetrieving a supabase client object from the SessionContext:\n```tsx\nimport { useSupabaseClient } from '@supabase/auth-helpers-react'\nimport { Database } from '../database.types'\nconst supabaseClient = useSupabaseClient()\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Install the Remix helper library",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/auth/auth-helpers/remix.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'remix',\n  title: 'Supabase Auth with Remix',\n  description: 'Authentication helpers for loaders and actions in Remix.',\n  sidebar_label: 'Remix',\n}\nThis submodule provides convenience helpers for implementing user authentication in Remix applications.\n\nCheck out this repo for a full example.\n\nInstall the Remix helper library\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n\n\n\n`sh\nnpm install @supabase/auth-helpers-remix`\nThis library supports the following tooling versions:\n\nRemix: `>=1.7.2`\n\n\n\n`sh\nyarn add @supabase/auth-helpers-remix`\nThis library supports the following tooling versions:\n\nRemix: `>=1.7.2`\n\n\n\nSet up environment variables\nRetrieve your project URL and anon key in your project's API settings in the Dashboard to set up the following environment variables. For local development you can set them in a `.env` file. See an example.\n`bash title=.env\nSUPABASE_URL=YOUR_SUPABASE_URL\nSUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nServer-side\nThe Supabase client can now be used server-side - in loaders and actions - by calling the `createServerClient` function.\nLoader\nLoader functions run on the server immediately before the component is rendered. They respond to all GET requests on a route. You can create an authenticated Supabase client by calling the `createServerClient` function and passing it your `SUPABASE_URL`, `SUPABASE_ANON_KEY`, and a `Request` and `Response`.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx\nimport { json } from '@remix-run/node' // change this import to whatever runtime you are using\nimport { createServerClient } from '@supabase/auth-helpers-remix'\nexport const loader = async ({ request }) => {\n  const response = new Response()\n  // an empty response is required for the auth helpers\n  // to set cookies to manage auth\nconst supabaseClient = createServerClient(\n    process.env.SUPABASE_URL,\n    process.env.SUPABASE_ANON_KEY,\n    { request, response }\n  )\nconst { data } = await supabaseClient.from('test').select('*')\n// in order for the set-cookie header to be set,\n  // headers must be returned as part of the loader response\n  return json(\n    { data },\n    {\n      headers: response.headers,\n    }\n  )\n}\n```\n\nSupabase will set cookie headers to manage the user's auth session, therefore, the `response.headers` must be returned from the `Loader` function.\n\n\n\n```jsx\nimport { json } from '@remix-run/node' // change this import to whatever runtime you are using\nimport { createServerClient } from '@supabase/auth-helpers-remix'\nimport type { LoaderArgs } from '@remix-run/node' // change this import to whatever runtime you are using\nexport const loader = async ({ request }: LoaderArgs) => {\n  const response = new Response()\n  const supabaseClient = createServerClient(\n    process.env.SUPABASE_URL!,\n    process.env.SUPABASE_ANON_KEY!,\n    { request, response }\n  )\nconst { data } = await supabaseClient.from('test').select('*')\nreturn json(\n    { data },\n    {\n      headers: response.headers,\n    }\n  )\n}\n```\n\nSupabase will set cookie headers to manage the user's auth session, therefore, the `response.headers` must be returned from the `Loader` function.\n\n\n\nAction\nAction functions run on the server and respond to HTTP requests to a route, other than GET - POST, PUT, PATCH, DELETE etc. You can create an authenticated Supabase client by calling the `createServerClient` function and passing it your `SUPABASE_URL`, `SUPABASE_ANON_KEY`, and a `Request` and `Response`.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx\nimport { json } from '@remix-run/node' // change this import to whatever runtime you are using\nimport { createServerClient } from '@supabase/auth-helpers-remix'\nexport const action = async ({ request }) => {\n  const response = new Response()\nconst supabaseClient = createServerClient(\n    process.env.SUPABASE_URL,\n    process.env.SUPABASE_ANON_KEY,\n    { request, response }\n  )\nconst { data } = await supabaseClient.from('test').select('*')\nreturn json(\n    { data },\n    {\n      headers: response.headers,\n    }\n  )\n}\n```\n\nSupabase will set cookie headers to manage the user's auth session, therefore, the `response.headers` must be returned from the `Action` function.\n\n\n\n```jsx\nimport { json } from '@remix-run/node' // change this import to whatever runtime you are using\nimport { createServerClient } from '@supabase/auth-helpers-remix'\nimport type { ActionArgs } from '@remix-run/node' // change this import to whatever runtime you are using\nexport const action = async ({ request }: ActionArgs) => {\n  const response = new Response()\nconst supabaseClient = createServerClient(\n    process.env.SUPABASE_URL!,\n    process.env.SUPABASE_ANON_KEY!,\n    { request, response }\n  )\nconst { data } = await supabaseClient.from('test').select('*')\nreturn json(\n    { data },\n    {\n      headers: response.headers,\n    }\n  )\n}\n```\n\nSupabase will set cookie headers to manage the user's auth session, therefore, the `response.headers` must be returned from the `Action` function.\n\n\n\nSession and User\nYou can determine if a user is authenticated by checking their session using the `getSession` function.\n`jsx\nconst {\n  data: { session },\n} = await supabaseClient.auth.getSession()`\nThe session contains a user property.\n`jsx\nconst user = session?.user`\nOr, if you don't need the session, you can call the `getUser()` function.\n`jsx\nconst {\n  data: { user },\n} = await supabaseClient.auth.getUser()`\nClient-side\nWe still need to use Supabase client-side for things like authentication and realtime subscriptions. Anytime we use Supabase client-side it needs to be a single instance.\nCreating a singleton Supabase client\nSince our environment variables are not available client-side, we need to plumb them through from the loader.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx title=app/root.jsx\nexport const loader = () => {\n  const env = {\n    SUPABASE_URL: process.env.SUPABASE_URL,\n    SUPABASE_ANON_KEY: process.env.SUPABASE_ANON_KEY,\n  }\nreturn json({ env })\n}\n```\n\nThese may not be stored in `process.env` for environments other than Node.\n\nNext, we call the `useLoaderData` hook in our component to get the `env` object.\n`jsx title=app/root.jsx\nconst { env } = useLoaderData()`\nWe then want to instantiate a single instance of a Supabase browser client, to be used across our client-side components.\n`jsx title=app/root.jsx\nconst [supabase] = useState(() => createBrowserClient(env.SUPABASE_URL, env.SUPABASE_ANON_KEY))`\nAnd then we can share this instance across our application with Outlet Context.\n`jsx title=app/root.jsx\n<Outlet context={{ supabase }} />`\n\n\n```tsx title=app/root.tsx\nexport const loader = ({}: LoaderArgs) => {\n  const env = {\n    SUPABASE_URL: process.env.SUPABASE_URL!,\n    SUPABASE_ANON_KEY: process.env.SUPABASE_ANON_KEY!,\n  }\nreturn json({ env })\n}\n```\n\nThese may not be stored in `process.env` for environments other than Node.\n\nNext, we call the `useLoaderData` hook in our component to get the `env` object.\n`tsx title=app/root.tsx\nconst { env } = useLoaderData<typeof loader>()`\nWe then want to instantiate a single instance of a Supabase browser client, to be used across our client-side components.\n`tsx title=app/root.tsx\nconst [supabase] = useState(() =>\n  createBrowserClient<Database>(env.SUPABASE_URL, env.SUPABASE_ANON_KEY)\n)`\nAnd then we can share this instance across our application with Outlet Context.\n`tsx title=app/root.tsx\n<Outlet context={{ supabase }} />`\n\n\nSyncing server and client state\nSince authentication happens client-side, we need to tell Remix to re-call all active loaders when the user signs in or out.\nRemix does this automatically when an action completes. Let's create an empty action.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n`jsx title=app/routes/handle-supabase-auth.jsx\nexport const action = () => null`\n\n\n`tsx title=app/routes/handle-supabase-auth.tsx\nexport const action = () => null`\n\n\nNow to determine when to submit a post request to this action, we need to compare the server and client state for the user's access token.\nLet's pipe that through from our loader.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n```jsx title=app/root.jsx\nexport const loader = async ({ request }) => {\n  const env = {\n    SUPABASE_URL: process.env.SUPABASE_URL,\n    SUPABASE_ANON_KEY: process.env.SUPABASE_ANON_KEY,\n  }\nconst response = new Response()\nconst supabase = createServerClient(process.env.SUPABASE_URL, process.env.SUPABASE_ANON_KEY, {\n    request,\n    response,\n  })\nconst {\n    data: { session },\n  } = await supabase.auth.getSession()\nreturn json(\n    {\n      env,\n      session,\n    },\n    {\n      headers: response.headers,\n    }\n  )\n}\n```\n\n\n```tsx title=app/root.tsx\nexport const loader = async ({ request }: LoaderArgs) => {\n  const env = {\n    SUPABASE_URL: process.env.SUPABASE_URL!,\n    SUPABASE_ANON_KEY: process.env.SUPABASE_ANON_KEY!,\n  }\nconst response = new Response()\nconst supabase = createServerClient(process.env.SUPABASE_URL!, process.env.SUPABASE_ANON_KEY!, {\n    request,\n    response,\n  })\nconst {\n    data: { session },\n  } = await supabase.auth.getSession()\nreturn json(\n    {\n      env,\n      session,\n    },\n    {\n      headers: response.headers,\n    }\n  )\n}\n```\n\n\nAnd then use a `fetcher` to simulate submitting a form to our action, inside the `onAuthStateChange` hook.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n```jsx title=app/root.jsx\nconst { env, session } = useLoaderData()\nconst fetcher = useFetcher()\nconst [supabase] = useState(() =>\n  createBrowserClient(env.SUPABASE_URL, env.SUPABASE_ANON_KEY)\n)\nconst serverAccessToken = session?.access_token\nuseEffect(() => {\n  const {\n    data: { subscription },\n  } = supabase.auth.onAuthStateChange((event, session) => {\n    if (session?.access_token !== serverAccessToken) {\n      // server and client are out of sync.\n      // Remix recalls active loaders after actions complete\n      fetcher.submit(null, {\n        method: 'post',\n        action: '/handle-supabase-auth',\n      })\n    }\n  })\nreturn () => {\n    subscription.unsubscribe()\n  }\n}, [serverAccessToken, supabase, fetcher])\n```\n\n\n```tsx title=app/root.tsx\nconst { env, session } = useLoaderData()\nconst fetcher = useFetcher()\nconst [supabase] = useState(() =>\n  createBrowserClient(env.SUPABASE_URL, env.SUPABASE_ANON_KEY)\n)\nconst serverAccessToken = session?.access_token\nuseEffect(() => {\n  const {\n    data: { subscription },\n  } = supabase.auth.onAuthStateChange((event, session) => {\n    if (session?.access_token !== serverAccessToken) {\n      // server and client are out of sync.\n      // Remix recalls active loaders after actions complete\n      fetcher.submit(null, {\n        method: 'post',\n        action: '/handle-supabase-auth',\n      })\n    }\n  })\nreturn () => {\n    subscription.unsubscribe()\n  }\n}, [serverAccessToken, supabase, fetcher])\n```\n\n\n\nCheck out this repo for full implementation example\n\nAuthentication\nNow we can use our outlet context to access our single instance of Supabase and use any of the supported authentication strategies from supabase-js.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n```jsx title=app/components/login.jsx\nexport default function Login() {\n  const { supabase } = useOutletContext()\nconst handleEmailLogin = async () => {\n    await supabase.auth.signInWithPassword({\n      email: 'jon@supabase.com',\n      password: 'password',\n    })\n  }\nconst handleGitHubLogin = async () => {\n    await supabase.auth.signInWithOAuth({\n      provider: 'github',\n    })\n  }\nconst handleLogout = async () => {\n    await supabase.auth.signOut()\n  }\nreturn (\n    <>\n      Email Login\nGitHub Login\nLogout\n\n  )\n}\n```\n\n\n```tsx title=app/components/login.tsx\nexport default function Login() {\n  const { supabase } = useOutletContext<{ supabase: SupabaseClient }>()\nconst handleEmailLogin = async () => {\n    await supabase.auth.signInWithPassword({\n      email: 'jon@supabase.com',\n      password: 'password',\n    })\n  }\nconst handleGitHubLogin = async () => {\n    await supabase.auth.signInWithOAuth({\n      provider: 'github',\n    })\n  }\nconst handleLogout = async () => {\n    await supabase.auth.signOut()\n  }\nreturn (\n    <>\n      Email Login\nGitHub Login\nLogout\n\n  )\n}\n```\n\n\nSubscribe to realtime events\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n```jsx title=app/routes/realtime.jsx\nimport { useLoaderData, useOutletContext } from '@remix-run/react'\nimport { createServerClient } from '@supabase/auth-helpers-remix'\nimport { json } from '@remix-run/node'\nimport { useEffect, useState } from 'react'\nexport const loader = async ({ request }) => {\n  const response = new Response()\n  const supabase = createServerClient(process.env.SUPABASE_URL, process.env.SUPABASE_ANON_KEY, {\n    request,\n    response,\n  })\nconst { data } = await supabase.from('posts').select()\nreturn json({ serverPosts: data ?? [] }, { headers: response.headers })\n}\nexport default function Index() {\n  const { serverPosts } = useLoaderData()\n  const [posts, setPosts] = useState(serverPosts)\n  const { supabase } = useOutletContext()\nuseEffect(() => {\n    setPosts(serverPosts)\n  }, [serverPosts])\nuseEffect(() => {\n    const channel = supabase\n      .channel('*')\n      .on('postgres_changes', { event: 'INSERT', schema: 'public', table: 'posts' }, (payload) =>\n        setPosts([...posts, payload.new])\n      )\n      .subscribe()\n\n\n```return () => {\n  supabase.removeChannel(channel)\n}\n```\n\n\n}, [supabase, posts, setPosts])\nreturn {JSON.stringify(posts, null, 2)}\n}\n```\n\n\n```tsx title=app/routes/realtime.tsx\nimport { useLoaderData, useOutletContext } from '@remix-run/react'\nimport { createServerClient } from '@supabase/auth-helpers-remix'\nimport { json } from '@remix-run/node'\nimport { useEffect, useState } from 'react'\nimport type { SupabaseClient } from '@supabase/auth-helpers-remix'\nimport type { Database } from 'db_types'\ntype Post = Database['public']['Tables']['posts']['Row']\nimport type { LoaderArgs } from '@remix-run/node'\nexport const loader = async ({ request }: LoaderArgs) => {\n  const response = new Response()\n  const supabase = createServerClient(\n    process.env.SUPABASE_URL!,\n    process.env.SUPABASE_ANON_KEY!,\n    {\n      request,\n      response,\n    }\n  )\nconst { data } = await supabase.from('posts').select()\nreturn json({ serverPosts: data ?? [] }, { headers: response.headers })\n}\nexport default function Index() {\n  const { serverPosts } = useLoaderData()\n  const [posts, setPosts] = useState(serverPosts)\n  const { supabase } = useOutletContext<{ supabase: SupabaseClient }>()\nuseEffect(() => {\n    setPosts(serverPosts)\n  }, [serverPosts])\nuseEffect(() => {\n    const channel = supabase\n      .channel('*')\n      .on('postgres_changes', { event: 'INSERT', schema: 'public', table: 'posts' }, (payload) =>\n        setPosts([...posts, payload.new as Post])\n      )\n      .subscribe()\n\n\n```return () => {\n  supabase.removeChannel(channel)\n}\n```\n\n\n}, [supabase, posts, setPosts])\nreturn {JSON.stringify(posts, null, 2)}\n}\n```\n\n`Database` is a TypeScript definitions file generated by the Supabase CLI.\n\n\n\n\nEnsure you have enabled replication on the table you are subscribing to.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Featured",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/examples.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'examples',\n  title: 'Examples and Resources',\n  description: 'Examples you can use to get started with Supabase',\n  video: 'https://www.youtube.com/v/7uKQBl9uZ00',\n}\n{/  /}\nWe have a set of examples in our main repository to help you get started.\nFeatured\nSupabase Crash Course\nBy Traversy Media.\n\n\n\nBuild an App With Supabase and NextJS\nBy @jlengstorf and @jonmeyers_io.\n\n\n\nIs Supabase Legit\nBy Fireship.\n\n\n\nOfficial Examples\nTodo List\nBuild a basic Todo List with Supabase and your favorite frontend framework:\n\nExpo Todo List.\nNext.js Todo List.\nReact Todo List.\nSvelte Todo List.\nVue 3 Todo List (Typescript).\nAngular Todo List.\nNuxt 3 Todo List.\n\nAuth examples\n\nSupabase Auth with vanilla JavaScript.. Use Supabase without any frontend frameworks.\nSupabase Auth with Next.js.\nSupabase Auth with RedwoodJS. Try out Supabase authentication in the RedwoodJS Authentication Playground complete with OAuth support and code samples.\n\nCollaborative\n\nNext.js Slack Clone.\n\nCommunity\nCourses\n\nBuild a FullStack App with Next.js, Supabase & Prisma by @gdangel0: Free course\n\nLibraries\n\nD (in development): GitHub\nFlutter (in development): GitHub\nPython (in development): GitHub\nC# (in development): GitHub\nKotlin (in development): GitHub\n`useSupabase`: Supabase React Hooks. GitHub\n`vue-supabase`: Supabase Vue wrapper. GitHub\n`vue-3-supabase`: Supabase Vue 3 wrapper. GitHub\n`nuxt-supabase`: Supabase Nuxt wrapper. GitHub\n`@nuxtjs/supabase`: Supabase Nuxt 3 module. GitHub\n`react-supabase`: Supabase React Hooks. Docs GitHub\n`@triniwiz/nativescript-supabase`: Supabase NativeScript. GitHub\n\nGuides\n\nSupabase Auth with Redwood. Docs\nSupabase Auth with Sapper SSR. Blog\nSwitch from Firebase Auth to Supabase Auth. Blog\nSetting up Umami Analytics with Supabase. Blog\nCreating New Supabase Users In NextJS. Blog\nCreating Protected Routes In NextJS With Supabase. Blog\nMigrate from Google Cloud Storage (GCS) to Supabase Storage Gist\nSubscriptions with Supabase and Stripe Billing Blog\nFlutter Supabase Authentication Blog\nSupabase in 6 minutes Video\nLet's build SupaAuth - Build an Authentication System using Supabase, Next.js and Typescript 6-part Blog Series\nIn-depth self-hosting guide using Nginx Blog\nBuild an Email and Social Auth for Next JS with Supabase, Tailwind CSS 3.0 and TypeScript Blog\nLink Shortener using Supabase and Ory 3-part Blog Series\n\nExample apps\n\nSupabase + Stripe + Next.js. GitHub\nSupabase + Svelte Trello clone. GitHub\nSupabase + Expo Starter. GitHub\nSupabase + Nest.js. GitHub\nSupabase + Cloudflare Workers. GitHub\nSupabase + Cloudflare Workers + Webpack. GitHub\nRealtime chat app with Supabase + React. GitHub\nRepository.surf: GitHub insights dashboard. GitHub\nSupabase + React Native Instagram Clone. GitHub\nKeepLink: Simple bookmark service with tags and archive. GitHub\nSupabase + Next.js (Next.js Starter Kit) GitHub\nSupabase + Svelte (Svelte Starter Kit) GitHub\nSupabase + SolidJS (SolidJS Starter Kit) GitHub\nSupabase + Nuxt3 (Nuxt Starter Kit) GitHub\nSupabase + Remix (Remix Starter Kit) GitHub\nSupabase + Angular (Angular Starter Kit) GitHub\nSupabase + Nuxt3 + nuxtjs/supabase Github\nSupabase + Ory Kratos & Ory Oathkeeper Github\nSupabase + Ory Cloud Github\nSupabase Auth with React Native + Next.js (Monorepo) Github\n\nBlog Posts\n\nRealtime Subscriptions using Vue + Supabase. Blog\nCreating a microblog using Vue + Supabase. Blog\nTrack Real-time Page Views. Blog\nSupabase as a Sentry alternative. Blog\nUsing Supabase with Chartbrew. Blog\nAuthentication with Supabase and React. Blog\nSupabase Schema Visualizer. Blog\nCreate a real-time UI using Next.js + Supabase. Blog\nHow to add Twitter auth quickly with Supabase to your Next.js site \u26a1 Blog\nUnder the hood: Architecture and Technology Stack of Supabase \u26a1 Blog\n\nPodcasts\n\nSoftware Engineering Daily\nHeavy Bit\nLog Rocket\nFS Jam\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Access token",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/glossary.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'glossary',\n  title: 'Glossary',\n  description: 'Definitions for terminology and acronyms used in the Supabase documentation.',\n}\nDefinitions for terminology and acronyms used in the Supabase documentation.\nAccess token\nAn access token is a short-lived (usually no more than 1 hour) token that authorizes a client to access resources on a server. It comes in the form of a JSON Web Token (JWT).\nAuthentication\nAuthentication (often abbreviated authn.) is the process of verifying the identity of a user. Verification of the identity of a user can happen in multiple ways:\n\nAsking users for something they know. For example: password, passphrase.\nChecking that users have access to something they own. For example: an email address, a phone number, a hardware key, recovery codes.\nConfirming that users have some biological features. For example: a fingerprint, a certain facial structure, an iris print.\n\nAuthenticator app\nAn authenticator app generates time-based one-time passwords (TOTPs). These passwords are generated based off a long and difficult to guess secret string. The secret is initially passed to the application by scanning a QR code.\nAuthorization\nAuthorization (often abbreviated authz.) is the process of verifying if a certain identity is allowed to access resources. Authorization often occurs by verifying an access token.\nIdentity provider\nAn identity provider is software or service that allows third-party applications to identify users without the exchange of passwords. Social login and enterprise single-sign on won't be possible without identity providers.\nSocial login platforms typically use the OAuth protocol, while enterprise single-sign on is based on the OIDC or SAML protocols.\nJSON Web Token (JWT)\nA JSON Web Token is a type of data structure, represented as a string, that usually contains identity and authorization information about a user. It encodes information about its lifetime and is signed with cryptographic key making it tamper resistant.\nAccess tokens are JWTs and by inspecting the information they contain you can allow or deny access to resources. Row level security policies are based on the information present in JWTs.\nJWT signing secret\nJWTs issued by Supabase are signed using the HMAC-SHA256 algorithm. The secret key used in the signing is called the JWT signing secret. You should not share this secret with someone or some thing you don't trust, nor should you post it publicly. Anyone with access to the secret can create arbitrary JWTs.\nMulti-factor authentication (MFA or 2FA)\nMulti-factor authentication is the process of authenticating a user's identity by using a combination of factors: something users know, something users have or something they are.\nNonce\nNonce means number used once. In reality though, it is a unique and difficult to guess string used to either initialize a protocol or algorithm securely, or detect abuse in various forms of replay attacks.\nOAuth\nOAuth is a protocol allowing third-party applications to request and receive authorization from their users. It is typically used to implement social login, and serves as a base for enterprise single-sign on in the OIDC protocol. Applications can request various level of access, and this includes some user identification information at least (name, email address, user identification number).\nOIDC\nOIDC stands for OpenID Connect and is a protocol that enables single-sign on for enterprises. OIDC is based on modern web technologies such as OAuth and JSON Web Tokens. It is commonly used instead of the older SAML protocol.\nOne-time password (OTP)\nA one-time password is a short, randomly generated and difficult to guess password or code that is sent to a device (like a phone number) or generated by a device or application.\nPassword hashing function\nPassword hashing functions are specially-designed algorithms that allow web servers to verify a password without storing it as-is. Unlike other difficult to guess strings generated from secure random number generators, passwords are picked by users and often are easy to guess by attackers. These algorithms slow down and make it very costly for attackers to guess passwords.\nThere are three generally accepted password hashing functions: Argon2, bcrypt and scrypt.\nPassword strength\nPassword strength is a measurement of how difficult a password is to guess. Simple measurement includes calculating the number of possibilities given the types of characters used in the password. For example a password of only letters has fewer variations than ones with letters and digits. Better measurements include strategies such as looking for similarity to words, phrases or already known passwords.\nPKCE\nProof Key for Code Exchange is an extension to the OAuth protocol that enables secure exchange of refresh and access tokens between an application (web app, single-page app or mobile app) and the authorization server. It is used in places where the exchange of the refresh and access token may be intercepted by third parties such as other applications running in the operating system. This is a common problem on mobile devices where the operating system may hand out URLs to other applications. This can sometimes be also exploited in single-page apps too.\nProvider refresh token\nA provider refresh token is a refresh token issued by a third-party identity provider which can be used to refresh the provider token returned.\nProvider tokens\nA provider token is a long-lived token issued by a third-party identity provider. These are issued by social login services (e.g., Google, Twitter, Apple, Microsoft) and uniquely identify a user on those platforms.\nRefresh token\nA refresh token is a long-lived (in most cases with an indefinite lifetime) token that is meant to be stored and exchanged for a new refresh and access tokens only once. Once a refresh token is exchanged it becomes invalid, and can't be exchanged again. In practice, though, a refresh token can be exchanged multiple times but in a short time window.\nRefresh token flow\nThe refresh token flow is a mechanism that issues a new refresh and access token on the basis of a valid refresh token. It is used to extend authorization access for an application. An application that is being constantly used will invoke the refresh token flow just before the access token expires.\nReplay attack\nA replay attack is when sensitive information is stolen or intercepted by attackers who then attempt to use it again (thus replay) in an effort to compromise a system. Commonly replay attacks can be mitigated with the proper use of nonces.\nRow level security policies (RLS)\nRow level security policies are special objects within the Postgres database that limit the available operations or data returned to clients. RLS policies use information contained in a JWT to identify users and the actions and data they are allowed to perform or view.\nSAML\nSAML stands for Security Assertion Markup Language and is a protocol that enables single-sign on for enterprises. SAML was invented in the early 2000s and is based on XML technology. It is the de-facto standard for enabling single-sign on for enterprises, although the more recent OIDC (OpenID Connect) protocol is gaining popularity.\nSession\nA session or authentication session is the concept that binds a verified user identity to a web browser. A session usually is long-lived, and can be terminated by the user logging out. An access and refresh token pair represent a session in the browser, and they are stored in local storage or as cookies.\nSingle-sign on (SSO)\nSingle-sign on allows enterprises to centrally manage accounts and access to applications. They use identity provider software or services to organize employee information in directories and connect those accounts with applications via OIDC or SAML protocols.\nTime-based one-time password (TOTP)\nA time-based one-time password is a one-time password generated at regular time intervals from a secret, usually from an application in a mobile device (e.g., Google Authenticator, 1Password).\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Set up the migration tool [#set-up-migration-tool]",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/migrating-to-supabase/firestore-data.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'firestore-data',\n  title: 'Firestore Data Migration',\n  description: 'Migrate your Firebase Firestore database to a Supabase Postgres database.',\n  sidebar_label: 'Firestore Data',\n}\nSupabase provides several tools to convert data from a Firebase Firestore database to a Supabase PostgreSQL database. The process copies the entire contents of a single Firestore `collection` to a single PostgreSQL `table`.\nThe Firestore `collection` is \"flattened\" and converted to a table with basic columns of one of the following types: `text`, `numeric`, `boolean`, or `jsonb`. If your structure is more complex, you can write a program to split the newly-created `json` file into multiple, related tables before you import your `json` file(s) to Supabase.\nSet up the migration tool [#set-up-migration-tool]\n\nClone the firebase-to-supabase repository:\n\n`bash\ngit clone https://github.com/supabase-community/firebase-to-supabase.git`\n\nIn the `/firestore` directory, create a file named `supabase-service.json` with the following contents:\n\n`json\n{\n  \"host\": \"database.server.com\",\n  \"password\": \"secretpassword\",\n  \"user\": \"postgres\",\n  \"database\": \"postgres\",\n  \"port\": 5432\n}`\n\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection Info, copy the Host string and replace the entry in your `supabase-service.json` file.\nEnter the password you used when you created your Supabase project in the `password` entry in the `supabase-service.json` file.\n\nGenerate a Firebase private key [#generate-firebase-private-key]\n\nLog in to your Firebase Console and open your project.\nClick the gear icon next to Project Overview in the sidebar and select Project Settings.\nClick Service Accounts and select Firebase Admin SDK.\nClick Generate new private key.\nRename the downloaded file to `firebase-service.json`.\n\nCommand line options\nList all Firestore collections\n`node collections.js`\nDump Firestore collection to JSON file\n`node firestore2json.js <collectionName> [<batchSize>] [<limit>]`\n\n`batchSize` (optional) defaults to 1000\noutput filename is `<collectionName>.json`\n`limit` (optional) defaults to 0 (no limit)\n\nCustomize the JSON file with hooks\nYou can customize the way your JSON file is written using a custom hook. A common use for this is to \"flatten\" the JSON file, or to split nested data into separate, related database tables. For example, you could take a Firestore document that looks like this:\n`json title=Firestore%20document\n[{ \"user\": \"mark\", \"score\": 100, \"items\": [\"hammer\", \"nail\", \"glue\"] }]`\nAnd split it into two files (one table for users and one table for items):\n`json title=Users%20table\n[{ \"user\": \"mark\", \"score\": 100 }]`\n`json title=Items%20table\n[\n  { \"user\": \"mark\", \"item\": \"hammer\" },\n  { \"user\": \"mark\", \"item\": \"nail\" },\n  { \"user\": \"mark\", \"item\": \"glue\" }\n]`\nImport JSON file to Supabase (PostgreSQL) [#import-to-supabase]\n`node json2supabase.js <path_to_json_file> [<primary_key_strategy>] [<primary_key_name>]`\n\n`<path_to_json_file>` The full path of the file you created in the previous step (`Dump Firestore collection to JSON file`), such as `./my_collection.json`\n`[<primary_key_strategy>]` (optional) Is one of:\n`none` (default) No primary key is added to the table.\n`smallserial` Creates a key using `(id SMALLSERIAL PRIMARY KEY)` (autoincrementing 2-byte integer).\n`serial` Creates a key using `(id SERIAL PRIMARY KEY)` (autoincrementing 4-byte integer).\n`bigserial` Creates a key using `(id BIGSERIAL PRIMARY KEY)` (autoincrementing 8-byte integer).\n`uuid` Creates a key using `(id UUID PRIMARY KEY DEFAULT uuid_generate_v4())` (randomly generated UUID).\n`firestore_id` Creates a key using `(id TEXT PRIMARY KEY)` (uses existing `firestore_id` random text as key).\n`[<primary_key_name>]` (optional) Name of primary key. Defaults to \"id\".\n\nCustom hooks\nHooks are used to customize the process of exporting a collection of Firestore documents to JSON. They can be used for:\n\nCustomizing or modifying keys\nCalculating data\nFlattening nested documents into related SQL tables\n\nWrite a custom hook\nCreate a .js file for your collection\nIf your Firestore collection is called `users`, create a file called `users.js` in the current folder.\nConstruct your .js file\nThe basic format of a hook file looks like this:\n`js\nmodule.exports = (collectionName, doc, recordCounters, writeRecord) => {\n  // modify the doc here\n  return doc\n}`\nParameters\n\n`collectionName`: The name of the collection you are processing.\n`doc`: The current document (JSON object) being processed.\n`recordCounters`: An internal object that keeps track of how many records have been processed in each collection.\n`writeRecord`: This function automatically handles the process of writing data to other JSON files (useful for \"flatting\" your document into separate JSON files to be written to separate database tables). `writeRecord` takes the following parameters:\n`name`: Name of the JSON file to write to.\n`doc`: The document to write to the file.\n`recordCounters`: The same `recordCounters` object that was passed to this hook (just passes it on).\n\nExamples\nAdd a new (unique) numeric key to a collection\n`js\nmodule.exports = (collectionName, doc, recordCounters, writeRecord) => {\n  doc.unique_key = recordCounter[collectionName] + 1\n  return doc\n}`\nAdd a timestamp of when this record was dumped from Firestore\n`js\nmodule.exports = (collectionName, doc, recordCounters, writeRecord) => {\n  doc.dump_time = new Date().toISOString()\n  return doc\n}`\nFlatten JSON into separate files\nFlatten the `users` collection into separate files:\n`json\n[\n  {\n    \"uid\": \"abc123\",\n    \"name\": \"mark\",\n    \"score\": 100,\n    \"weapons\": [\"toothpick\", \"needle\", \"rock\"]\n  },\n  {\n    \"uid\": \"xyz789\",\n    \"name\": \"chuck\",\n    \"score\": 9999999,\n    \"weapons\": [\"hand\", \"foot\", \"head\"]\n  }\n]`\nThe `users.js` hook file:\n`js\nmodule.exports = (collectionName, doc, recordCounters, writeRecord) => {\n  for (let i = 0; i < doc.weapons.length; i++) {\n    const weapon = {\n      uid: doc.uid,\n      weapon: doc.weapons[i],\n    }\n    writeRecord('weapons', weapon, recordCounters)\n  }\n  delete doc.weapons // moved to separate file\n  return doc\n}`\nThe result is two separate JSON files:\n`json title=users.json\n[\n  { \"uid\": \"abc123\", \"name\": \"mark\", \"score\": 100 },\n  { \"uid\": \"xyz789\", \"name\": \"chuck\", \"score\": 9999999 }\n]`\n`json title=weapons.json\n[\n  { \"uid\": \"abc123\", \"weapon\": \"toothpick\" },\n  { \"uid\": \"abc123\", \"weapon\": \"needle\" },\n  { \"uid\": \"abc123\", \"weapon\": \"rock\" },\n  { \"uid\": \"xyz789\", \"weapon\": \"hand\" },\n  { \"uid\": \"xyz789\", \"weapon\": \"foot\" },\n  { \"uid\": \"xyz789\", \"weapon\": \"head\" }\n]`\nResources\n\nSupabase vs Firebase\nFirestore Storage Migration\nFirebase Auth Migration\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Set up the migration tool [#set-up-migration-tool]",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/migrating-to-supabase/firebase-storage.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'firebase-storage',\n  title: 'Firebase Storage Migration',\n  description: 'Migrate Firebase Storage files to Supabase Storage.',\n  sidebar_label: 'Firebase Storage',\n}\nSupabase provides several tools to convert storage files from Firebase Storage to Supabase Storage. Conversion is a two-step process:\n\nFiles are downloaded from a Firebase storage bucket to a local filesystem.\nFiles are uploaded from the local filesystem to a Supabase storage bucket.\n\nSet up the migration tool [#set-up-migration-tool]\n\nClone the firebase-to-supabase repository:\n\n`bash\ngit clone https://github.com/supabase-community/firebase-to-supabase.git`\n\nIn the `/storage` directory, rename supabase-keys-sample.js to `supabase-keys.js`.\nGo to your Supabase project's API settings in the Dashboard.\nCopy the Project URL and update the `SUPABASE_URL` value in `supabase-keys.js`.\nUnder Project API keys, copy the service_role key and update the `SUPABASE_KEY` value in `supabase-keys.js`.\n\nGenerate a Firebase private key [#generate-firebase-private-key]\n\nLog in to your Firebase Console and open your project.\nClick the gear icon next to Project Overview in the sidebar and select Project Settings.\nClick Service Accounts and select Firebase Admin SDK.\nClick Generate new private key.\nRename the downloaded file to `firebase-service.json`.\n\nCommand line options\nDownload Firestore Storage bucket to a local filesystem folder [#download-firestore-storage-bucket]\n`node download.js <prefix> [<folder>] [<batchSize>] [<limit>] [<token>]`\n\n`<prefix>`: The prefix of the files to download. To process the root bucket, use an empty prefix: \"\".\n`<folder>`: (optional) Name of subfolder for downloaded files. The selected folder is created as a subfolder of the current folder (e.g., `./downloads/`). The default is `downloads`.\n`<batchSize>`: (optional) The default is 100.\n`<limit>`: (optional) Stop after processing this many files. For no limit, use `0`.\n`<token>`: (optional) Begin processing at this pageToken.\n\nTo process in batches using multiple command-line executions, you must use the same parameters with a new `<token>` on subsequent calls. Use the token displayed on the last call to continue the process at a given point.\nUpload files to Supabase Storage bucket [#upload-to-supabase-storage-bucket]\n`node upload.js <prefix> <folder> <bucket>`\n\n`<prefix>`: The prefix of the files to download. To process all files, use an empty prefix: \"\".\n`<folder>`: Name of subfolder of files to upload. The selected folder is read as a subfolder of the current folder (e.g., `./downloads/`). The default is `downloads`.\n`<bucket>`: Name of the bucket to upload to.\n\n\nIf the bucket doesn't exist, it's created as a `non-public` bucket. You must set permissions on this new bucket in the Supabase Dashboard before users can download any files.\n\nResources\n\nSupabase vs Firebase\nFirestore Data Migration\nFirebase Auth Migration\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Quick demo",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/migrating-to-supabase/heroku.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'heroku',\n  title: 'Migrate from Heroku to Supabase',\n  description: 'Migrate your Heroku Postgres database to Supabase.',\n  sidebar_label: 'Heroku',\n  video: 'https://www.youtube.com/v/xsRhPMphtZ4',\n}\nSupabase is one of the best free alternatives to Heroku Postgres. This guide shows how to migrate your Heroku Postgres database to Supabase. This migration requires the pg_dump and psql CLI tools, which are installed automatically as part of the complete PostgreSQL installation package.\nAlternatively, use the Heroku to Supabase migration tool to migrate in just a few clicks.\nQuick demo\n\n\n\nRetrieve your Heroku database credentials [#retrieve-heroku-credentials]\n\nLog in to your Heroku account and select the project you want to migrate.\nClick Resources in the menu and select your Heroku Postgres database.\nClick Settings in the menu.\nClick View Credentials and save the following information:\nHost (`$HEROKU_HOST`)\nDatabase (`$HEROKU_DATABASE`)\nUser (`$HEROKU_USER`)\nPassword (`$HEROKU_PASSWORD`)\n\nRetrieve your Supabase Host [#retrieve-supabase-host]\n\nIf you're new to Supabase, create a project.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection Info, note your Host (`$SUPABASE_HOST`).\n\nExport your Heroku database to a file [#export-heroku-database]\nUse `pg_dump` with your Heroku credentials to export your Heroku database to a file (e.g., `heroku_dump.sql`).\n`bash\npg_dump --clean --if-exists --quote-all-identifiers \\\n -h $HEROKU_HOST -U $HEROKU_USER -d $HEROKU_DATABASE \\\n --no-owner --no-privileges > heroku_dump.sql`\nImport the database to your Supabase project [#import-database-to-supabase]\nUse `psql` to import the Heroku database file to your Supabase project.\n`bash\npsql -h $SUPABASE_HOST -U postgres -f heroku_dump.sql`\nAdditional options\n\nTo only migrate a single database schema, add the `--schema=PATTERN` parameter to your `pg_dump` command.\nTo exclude a schema: `--exclude-schema=PATTERN`.\nTo only migrate a single table: `--table=PATTERN`.\nTo exclude a table: `--exclude-table=PATTERN`.\n\nRun `pg_dump --help` for a full list of options.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Retrieve your Render database credentials [#retrieve-render-credentials]",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/migrating-to-supabase/render.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Migrate from Render to Supabase',\n  description: 'Migrate your Render Postgres database to Supabase.',\n}\nRender is a popular Web Hosting service in the online services category that also has a managed Postgres service. Render has a great developer experience, allowing users to deploy straight from GitHub or GitLab. This is the core of their product and they do it really well. However, when it comes to Postgres databases, it may not be the best option.\nSupabase is one of the best free alternative to Render Postgres. Supabase provide all the backend features developers need to build a product: a Postgres database, authentication, instant APIs, edge functions, realtime subscriptions, and storage. Postgres is the core of Supabase\u2014for example, you can use row-level security and there are more than 40 Postgres extensions available.\nThis guide demonstrates how to migrate from Render to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Render database credentials [#retrieve-render-credentials]\n\nLog in to your Render account and select the project you want to migrate.\nClick Dashboard in the menu and click in your Postgres database.\nScroll down in the Info tab.\nClick on PSQL Command and edit it adding the content after `PSQL_COMMAND=`.\n\n\nExample:\n`bash\n%env PSQL_COMMAND=PGPASSWORD=RgaMDfTS_password_FTPa7 psql -h dpg-a_server_in.oregon-postgres.render.com -U my_db_pxl0_user my_db_pxl0`\nRetrieve your Supabase Host [#retrieve-supabase-host]\n\nIf you're new to Supabase, create a project.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection Info, note your Host (`$SUPABASE_HOST`).\nSave your password or reset it if you forgot it.\n\n\nMigrate the database\nThe fastest way to migrate your database is with the Supabase migration tool on Google Colab. Alternatively, you can use the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"colab\"\n\n\n\n\nSet the environment variables (`PSQL_COMMAND`, `SUPABASE_HOST`, `SUPABASE_PASSWORD`) in the Colab notebook.\nRun the first two steps in the notebook in order. The first sets the variables and the second installs PSQL and the migration script.\nRun the third step to start the migration. This will take a few minutes.\n\n\n\nExport your Render database to a file in console [#export-render-database]\nUse `pg_dump` with your Render credentials to export your Render database to a file (e.g., `render_dump.sql`).\n`bash\npg_dump --clean --if-exists --quote-all-identifiers \\\n -h $RENDER_HOST -U $RENDER_USER -d $RENDER_DATABASE \\\n --no-owner --no-privileges > render_dump.sql`\nImport the database to your Supabase project [#import-database-to-supabase]\nUse `psql` to import the Render database file to your Supabase project.\n`bash\npsql -h $SUPA_URL -U postgres --file render_dump.sql -p 6543 -d postgres`\nAdditional options\n\nTo only migrate a single database schema, add the `--schema=PATTERN` parameter to your `pg_dump` command.\nTo exclude a schema: `--exclude-schema=PATTERN`.\nTo only migrate a single table: `--table=PATTERN`.\nTo exclude a table: `--exclude-table=PATTERN`.\n\nRun `pg_dump --help` for a full list of options.\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Set up the migration tool [#set-up-migration-tool]",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/migrating-to-supabase/firebase-auth.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'firebase-auth',\n  title: 'Firebase Auth Migration',\n  description: 'Migrate Firebase auth users to a Supabase project.',\n  sidebar_label: 'Firebase Auth',\n}\nSupabase provides several tools to help migrate auth users from a Firebase project to a Supabase project. There are two parts to the migration process:\n\n`firestoreusers2json` (TypeScript, JavaScript) exports users from an existing Firebase project to a `.json` file on your local system.\n`import_users` (TypeScript, JavaScript) imports users from a saved `.json` file into your Supabase project (inserting those users into the `auth.users` table of your `PostgreSQL` database instance).\n\nSet up the migration tool [#set-up-migration-tool]\n\nClone the firebase-to-supabase repository:\n\n`bash\ngit clone https://github.com/supabase-community/firebase-to-supabase.git`\n\nIn the `/auth` directory, create a file named `supabase-service.json` with the following contents:\n\n`json\n{\n  \"host\": \"database.server.com\",\n  \"password\": \"secretpassword\",\n  \"user\": \"postgres\",\n  \"database\": \"postgres\",\n  \"port\": 5432\n}`\n\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection Info, copy the Host string and replace the entry in your `supabase-service.json` file.\nEnter the password you used when you created your Supabase project in the `password` entry in the `supabase-service.json` file.\n\nGenerate a Firebase private key [#generate-firebase-private-key]\n\nLog in to your Firebase Console and open your project.\nClick the gear icon next to Project Overview in the sidebar and select Project Settings.\nClick Service Accounts and select Firebase Admin SDK.\nClick Generate new private key.\nRename the downloaded file to `firebase-service.json`.\n\nSave your Firebase password hash parameters [#save-firebase-hash-parameters]\n\nLog in to your Firebase Console and open your project.\nSelect Authentication (Build section) in the sidebar.\nSelect Users in the top menu.\nAt the top right of the users list, open the menu (3 dots) and click Password hash parameters.\nCopy and save the parameters for `base64_signer_key`, `base64_salt_separator`, `rounds`, and `mem_cost`.\n\n`bash title=Sample%20password%20hash%20parameters\nhash_config {\n  algorithm: SCRYPT,\n  base64_signer_key: XXXX/XXX+XXXXXXXXXXXXXXXXX+XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX==,\n  base64_salt_separator: Aa==,\n  rounds: 8,\n  mem_cost: 14,\n}`\nCommand line options\nDump Firestore users to a JSON file [#dump-firestore-users]\n`node firestoreusers2json.js [<filename.json>] [<batch_size>]`\n\n`filename.json`: (optional) output filename (defaults to `./users.json`)\n`batchSize`: (optional) number of users to fetch in each batch (defaults to 100)\n\nImport JSON users file to Supabase Auth (PostgreSQL: auth.users) [#import-json-users-file]\n`node import_users.js <path_to_json_file> [<batch_size>]`\n\n`path_to_json_file`: full local path and filename of .json input file (of users)\n`batch_size`: (optional) number of users to process in a batch (defaults to 100)\n\nNotes\nFor more advanced migrations, including the use of a middleware server component for verifying a user's existing Firebase password and updating that password in your Supabase project the first time a user logs in, see the firebase-to-supabase repo.\nResources\n\nSupabase vs Firebase\nFirestore Data Migration\nFirestore Storage Migration\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "dropping-all-tables-in-schema.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/postgres/dropping-all-tables-in-schema.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Drop all tables in a PostgreSQL schema',\n  description: 'Useful snippet for deleting all tables in a given schema',\n  footerHelpType: 'postgres',\n}\nExecute the following query to drop all tables in a given schema.\nReplace `my-schema-name` with the name of your schema. In Supabase, the default schema is `public`.\n\nThis deletes all tables and their associated data. Ensure you have a recent backup before proceeding.\n\n`sql\ndo $$ declare\n    r record;\nbegin\n    for r in (select tablename from pg_tables where schemaname = 'my-schema-name') loop\n        execute 'drop table if exists ' || quote_ident(r.tablename) || ' cascade';\n    end loop;\nend $$;`\nThis query works by listing out all the tables in the given schema and then executing a `drop table` for each (hence the `for... loop`).\nYou can run this query using the SQL Editor in the Supabase Dashboard, or via `psql` if you're connecting directly to the database.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "first-row-in-group.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/postgres/first-row-in-group.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Select first row for each group in PostgreSQL',\n  description: 'PostgreSQL snippet for grabbing the first row in each distinct group by group',\n  footerHelpType: 'postgres',\n}\nGiven a table `seasons`:\n| id  |   team    | points |\n| --- | :-------: | -----: |\n| 1   | Liverpool |     82 |\n| 2   | Liverpool |     84 |\n| 3   | Brighton  |     34 |\n| 4   | Brighton  |     28 |\n| 5   | Liverpool |     79 |\nWe want to find the rows containing the maximum number of points per team.\nThe expected output we want is:\n| id  |   team    | points |\n| --- | :-------: | -----: |\n| 3   | Brighton  |     34 |\n| 2   | Liverpool |     84 |\nFrom the SQL Editor, you can run a query like:\n`sql\nselect distinct\n  on (team) id,\n  team,\n  points\nfrom\n  seasons\norder BY\n  id,\n  points desc,\n  team;`\nThe important bits here are:\n\nThe `desc` keyword to order the `points` from highest to lowest.\nThe `distinct` keyword that tells Postgres to only return a single row per team.\n\nThis query can also be executed via `psql` or any other query editor if you prefer to connect directly to the database.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "which-version-of-postgres.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/resources/postgres/which-version-of-postgres.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Print PostgreSQL version',\n  description: 'Useful snippet for finding out which version of postgres you are running',\n  footerHelpType: 'postgres',\n}\nIt's important to know which version of PostgreSQL you are running as each major version has different features and may cause breaking changes. You may also need to update your schema when upgrading or downgrading to a major Postgres version.\nRun the following query using the SQL Editor in the Supabase Dashboard:\n`sql\nselect\n  version ();`\nWhich should return something like:\n`sql\nPostgreSQL 15.1 on aarch64-unknown-linux-gnu, compiled by gcc (Ubuntu 10.3.0-1ubuntu1~20.04) 10.3.0, 64-bit`\nThis query can also be executed via `psql` or any other query editor if you prefer to connect directly to the database.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Configure a Custom Domain using the Supabase Dashboard",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/custom-domains.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'custom-domains',\n  title: 'Custom Domains',\n  description: 'Configuring a Custom Domain for your Supabase project.',\n  video: 'https://www.youtube.com/v/6rcGnW_Mh-0',\n}\n\nCustom Domains are currently in beta, and are being slowly made available to projects.\n\nCustom domains allow you to present a branded experience to your users. Custom domains are available as a add-on for projects on a paid tier. Setting up a custom domain requires Owner or Admin permissions for the project. Currently, you must use a subdomain (e.g., `api.example.com`, rather than `example.com`) for the purposes of this guide.\n\n\n\nConfigure a Custom Domain using the Supabase Dashboard\nFollow the Custom Domains steps in the General Settings page in the Dashboard to set up a custom domain for your project.\nConfigure a Custom Domain using the Supabase CLI\nThis example assumes your Supabase project is `foobarbaz` with a corresponding API URL `foobarbaz.supabase.co` and configures a custom domain at `api.example.com`.\nTo get started:\n\nInstall the Supabase CLI 1.11.3+.\nLog in to your Supabase account using the CLI.\n\nConfigure a CNAME\nSet up a CNAME record for `api.example.com`, resolving to `foobarbaz.supabase.co.`, with as low a TTL as possible.\nConfigure TXT Verification\nUse the `create` subcommand of the CLI to notify Supabase of your domain and retrieve TXT verification records:\n`bash\nsupabase domains create --project-ref foobarbaz --custom-hostname api.example.com --experimental`\nThe output of the `create` command includes two TXT records[^1] you will need to set up, in order to verify your control over the domain in question,\nand for us to issue SSL certificates for it. For example:\n`bash\n[...]\nRequired outstanding validation records:\n        _cf-custom-hostname.api.example.com TXT -> 46BBC14D-D50A-409C-8DB5-F862CF5BA660\n        api.example.com TXT -> ca3-F1HvR9i938OgVwpCFwi1jTsbhe1hvT0Ic3efPY3Q`\n[^1] One of the records requires you to replace the CNAME record set up in the first step with a TXT record. You'll be able to restore it back to the CNAME after the verification process has been completed.\nVerify your domain\nSet up both records as instructed, and then use the `reverify` command for the Supabase Platform to verify the records:\n`bash\nsupabase domains reverify --project-ref foobarbaz --experimental`\nYou might need to wait a few minutes before your updated DNS records are propagated, especially if the older records were using a high TTL.\nActivate your domain\nThe final activation step reconfigures your project to start serving traffic on your custom domain (`api.example.com`).\nThe auth service, in particular, will no longer work with the original URL (`foobarbaz.supabase.co`).\nAs such, it is recommended that you schedule a downtime window of 20-30 minutes, depending on the complexity of your project, to update all the services that need to know about your custom domain:\n\nany client code (e.g., frontends, mobile apps)\nany OAuth providers (e.g., google, github)\n\nAdditionally, update the DNS configuration for `api.example.com` to once more use a CNAME record that resolves to `foobarbaz.supabase.co`.\nFinally, you can use the `activate` subcommand to reconfigure your project:\n`bash\nsupabase domains activate --project-ref foobarbaz --experimental`\nRemove a Custom Domain\nIf you have a custom domain (`api.example.com`) set up for your Supabase project (ref `foobarbaz`, with assigned endpoints at `foobarbaz.supabase.co`), and would like to go back to using the Supabase-provisioned endpoints (`foobarbaz.supabase.co`), you can use the `delete` subcommand:\n`bash\nsupabase domains delete --project-ref foobarbaz --experimental`\nAs with the final activation stage of the process for setting up a custom domain, you'll need to update any references in your client code and OAuth providers from the custom domain to the Supabase-provisioned endpoints.\nVanity Subdomains\n\nVanity Subdomains are currently in beta, and are being slowly made available to projects. Contact Support if you'd like to request early access.\n\nVanity Subdomains allow you to present a basic branded experience, compared to custom domains. They allow you to host your services at a custom subdomain on Supabase (e.g., `my-example-brand.supabase.co`) instead of the default, randomly-assigned `foobarbaz.supabase.co`.\nTo get started:\n\nInstall the Supabase CLI 1.22.0+.\nLog in to your Supabase account using the CLI.\nEnsure that you have Owner or Admin permissions for the project you'd like to set up a vanity subdomain for.\nEnsure that your project has a paid subscription (Pro/Pay as you go/Enterprise tier) in the Billing page of the Dashboard.\n\nConfigure a Vanity Subdomain\nThis example assumes your Supabase project is `foobarbaz` with a corresponding API URL `foobarbaz.supabase.co` and configures a vanity subdomain at `my-example-brand.supabase.co`.\nCheck subdomain availability\nUse the `check-availability` subcommand of the CLI to check if your desired subdomain is available for use:\n`bash\nsupabase vanity-subdomains --project-ref foobarbaz check-availability --desired-subdomain my-example-brand --experimental`\nActivate a subdomain\nOnce you've chosen an available subdomain, you can reconfigure your Supabase project to start serving traffic on the vanity subdomain (`my-example-brand.supabase.co`).\nThe auth service, in particular, will no longer work with the original URL (`foobarbaz.supabase.co`).\nAs such, it is recommended that you schedule a downtime window of 20-30 minutes, depending on the complexity of your project, to update all the services that need to know about your vanity subdomain:\n\nany client code (e.g., frontends, mobile apps)\nany OAuth providers (e.g., Google, GitHub)\n\nThe `activate` subcommand can be used to initiate the activation:\n`bash\nsupabase vanity-subdomains --project-ref fwmssjhjgszhnavvqxnt activate --desired-subdomain my-example-subdomain --experimental`\nRemove a Vanity Subdomain\nIf you have a vanity subdomain (`my-example-brand.supabase.co`) set up for your Supabase project (ref `foobarbaz`, with assigned endpoints at `foobarbaz.supabase.co`), and would like to go back to using the Supabase-provisioned endpoints (`foobarbaz.supabase.co`), you can use the `delete` subcommand:\n`bash\nsupabase vanity-subdomains delete --project-ref foobarbaz --experimental`\nAs with the final activation stage of the process for setting up a vanity subdomain, you'll need to update any references in your client code and OAuth providers from the vanity subdomain to the Supabase-provisioned endpoints.\nLimitations\n\nEdge functions do not honor the custom domain or the vanity subdomain setting and they still have to be invoked via the `foobarbaz.supabase.co` domain.\nA Supabase project can\u2014at this time\u2014use either a Custom Domain or a Vanity Subdomain, but not both.\nSome authentication flows like Sign-in with Twitter set cookies to track the progress of the flow. Make sure you use only one domain in your frontend application for this reason. Mixing calls to the Supabase domain `foobarbaz.supabase.co` and your custom domain could cause those flows to stop working due to the Same Origin Policy enforced on cookies by the browser.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Upgrade your project",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/migrating-and-upgrading-projects.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'migrating-and-upgrading-projects',\n  title: 'Migrating and Upgrading Projects',\n  description: 'Upgrade your project to the latest version of Supabase.',\n  sidebar_label: 'Migrating and upgrading',\n}\nSupabase ships fast and we endeavor to add all new features to existing projects wherever possible.\nIn some cases, access to new features require upgrading or migrating your Supabase project.\nUpgrade your project\nThis is only available for projects on the Free plan.\nWhen you pause and restore a project, the restored database includes the latest features. This method does include downtime, so be aware that your project will be inaccessible for a short period of time.\n\nOn the General Settings page in the Dashboard, click Pause project. You will be redirected to the home screen as your project is pausing. This process can take several minutes.\nAfter your project is paused, click Restore project. The restoration can take several minutes depending on how much data your database has. You will receive an email once the restoration is complete.\n\nMigrate your project\nMigrating projects can be achieved using standard PostgreSQL tooling. This is particularly useful for older projects (e.g. to use a newer Postgres version).\nBefore you begin\n\nInstall Postgres so you can run `psql` and `pg_dump`.\nCreate a new Supabase project.\nStore the old project's database URL as `$OLD_DB_URL` and the new project's as `$NEW_DB_URL`.\n\nMigrate the database\n\nEnable Database Webhooks in your new project if you enabled them in your old project.\nIn your new project, enable all extensions that were enabled in your old project.\nRun the following command from your terminal:\n\n```sh\nset -euo pipefail\npg_dump \\\n  --clean \\\n  --if-exists \\\n  --quote-all-identifiers \\\n  --exclude-table-data 'storage.objects' \\\n  --exclude-schema 'extensions|graphql|graphql_public|net|pgbouncer|pgsodium|pgsodium_masks|realtime|supabase_functions|pg_toast|pg_catalog|information_schema' \\\n  --schema '*' \\\n  --dbname \"$OLD_DB_URL\" \\\n| sed 's/^DROP SCHEMA IF EXISTS \"auth\";$/-- DROP SCHEMA IF EXISTS \"auth\";/' \\\n| sed 's/^DROP SCHEMA IF EXISTS \"storage\";$/-- DROP SCHEMA IF EXISTS \"storage\";/' \\\n| sed 's/^CREATE SCHEMA \"auth\";$/-- CREATE SCHEMA \"auth\";/' \\\n| sed 's/^CREATE SCHEMA \"storage\";$/-- CREATE SCHEMA \"storage\";/' \\\n| sed 's/^ALTER DEFAULT PRIVILEGES FOR ROLE \"supabase_admin\"/-- ALTER DEFAULT PRIVILEGES FOR ROLE \"supabase_admin\"/' \\\n\ndump.sql\n\npsql \\\n  --single-transaction \\\n  --variable ON_ERROR_STOP=1 \\\n  --file dump.sql \\\n  --dbname \"$NEW_DB_URL\"\n```\nEnable publication on tables\nReplication for Realtime is disabled for all tables in your new project. On the Replication page in the Dashboard, select your new project and enable replication for tables that were enabled in your old project.\nMigrate Storage objects\nThe new project has the old project's Storage buckets, but the Storage objects need to be migrated manually. Use this script to move storage objects from one project to another.\n```js\n// npm install @supabase/supabase-js@1\nconst { createClient } = require('@supabase/supabase-js')\nconst OLD_PROJECT_URL = 'https://xxx.supabase.co'\nconst OLD_PROJECT_SERVICE_KEY = 'old-project-service-key-xxx'\nconst NEW_PROJECT_URL = 'https://yyy.supabase.co'\nconst NEW_PROJECT_SERVICE_KEY = 'new-project-service-key-yyy'\n;(async () => {\n  const oldSupabaseRestClient = createClient(OLD_PROJECT_URL, OLD_PROJECT_SERVICE_KEY, {\n    schema: 'storage',\n  })\n  const oldSupabaseClient = createClient(OLD_PROJECT_URL, OLD_PROJECT_SERVICE_KEY)\n  const newSupabaseClient = createClient(NEW_PROJECT_URL, NEW_PROJECT_SERVICE_KEY)\n// make sure you update max_rows in postgrest settings if you have a lot of objects\n  // or paginate here\n  const { data: oldObjects, error } = await oldSupabaseRestClient.from('objects').select()\n  if (error) {\n    console.log('error getting objects from old bucket')\n    throw error\n  }\nfor (const objectData of oldObjects) {\n    console.log(`moving ${objectData.id}`)\n    try {\n      const { data, error: downloadObjectError } = await oldSupabaseClient.storage\n        .from(objectData.bucket_id)\n        .download(objectData.name)\n      if (downloadObjectError) {\n        throw downloadObjectError\n      }\n\n\n```  const { _, error: uploadObjectError } = await newSupabaseClient.storage\n    .from(objectData.bucket_id)\n    .upload(objectData.name, data, {\n      upsert: true,\n      contentType: objectData.metadata.mimetype,\n      cacheControl: objectData.metadata.cacheControl,\n    })\n  if (uploadObjectError) {\n    throw uploadObjectError\n  }\n} catch (err) {\n  console.log('error moving ', objectData)\n  console.log(err)\n}\n```\n\n\n}\n})()\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "2XX Success",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/http-status-codes.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'http-status-codes',\n  title: 'HTTP Status Codes',\n  description: 'HTTP Status Codes used by the Supabase platform',\n}\nThe Supabase platform offers several HTTP APIs for each project. These APIs can use the status codes to indicate the state of the project, and the request being processed. The status codes returned for requests can be access via the logs explorer.\n2XX Success\n2XX status codes indicate that the request was processed successfully.\n3XX Redirects\n3XX status codes indicate that the client must initiate another course of action to have the request processed successfully. The most popular usage of 3XX codes is to redirect the client to a different location.\n4XX Client Errors\n4XX status codes indicate an issue on the client's end with the request being made. These could include missing or invalid auth information, a malformed request, making too many requests in too short a time period (\"rate limiting\"), or a network issue on the client's end.\n5XX Server or Project Errors\n5XX status codes indicate that the project was unable to process the request successfully, but not because of an issue with the client's request.\n5XX status codes can be the result of the project not having enough compute to process a complex request being made by a client or not being able to keep up with the volume of requests made against the project.\n54X Project Errors\n54X status codes are custom codes used by the Supabase platform to indicate the state of the project.\n540 Project Paused\nThe project the request was being made against has been paused. The project cannot process requests until it is un-paused by the owner.\nFree-tier projects may be paused due to inactivity, on request by the owner, or in rare instances, due to abuse.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Database space management",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/database-size.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'database-size',\n  title: 'Database size',\n  description: 'Understanding how database size applies to your subscription.',\n}\nDatabase size refers to the monthly average storage usage, as reported by Postgres. This metric is reported in your project's billing usage and is updated daily. As you read this document we will refer to \"database size\" and \"disk size\":\n\n\"Database size\" is the total size of used storage from your database.\n\"Disk size\" describes the size of the underlying available storage.\n\nDatabase space management\nDatabase size\nThis SQL query will show the current size of your Postgres database:\n`sql\nselect\n  sum(pg_database_size (pg_database.datname)) / (1024 * 1024) as db_size_mb\nfrom\n  pg_database;`\nThis value is reported in the database settings page.\nDatabase Space is consumed primarily by your data, indexes, and materialized views. You can reduce your disk size by removing any of these and running a Vacuum operation.\n\nDepending on your billing tier, your database can go into read-only mode which can prevent you inserting and deleting data. There are instructions for managing read-only mode in the Disk Management section.\n\nVacuum operations\nPostgres does not immediately reclaim the physical space used by dead tuples (i.e., deleted rows) in the DB. They are marked as \"removed\" until a vacuum operation is executed. As a result, deleting data from your database may not immediately reduce the reported disk usage.\n\nVacuum operations can temporarily increase resource utilization, which may adversely impact the observed performance of your project until the maintenance is completed.\n\nSupabase projects have automatic vacuuming enabled, which ensures that these operations are performed regularly to keep the database healthy and performant.\nIt is possible to fine-tune\nthe autovacuum parameters,\nor manually initiate vacuum operations.\nRunning a manual vacuum after deleting large amounts of data from your DB could help reduce the database size reported by Postgres.\nPreoccupied Space\nNew Supabase projects have a database size of ~40-60mb. This space includes pre-installed extensions, schemas, and default Postgres data. Additional database size is used when installing extensions, even if those extensions are inactive.\nDisk management\nSupabase uses network-attached storage to balance performance with scalability. The behavior of your disk depends on your billing tier.\nPaid Tier Behavior\nPro and Enterprise projects have auto-scaling Disk Storage.\nDisk storage expands automatically when the database reaches 90% of the disk size. The disk is expanded to be 50% larger (e.g., 8GB -> 12GB). Auto-scaling can only take place once every 6 hours. If within those 6 hours you reach 95% of the disk space, your project will enter read-only mode.\n\nIf you intend to import a lot of data into your database which requires multiple disk expansions then reach out to our team. For example, uploading more than 1.5x the current size of your database storage will put your database into read-only mode.\n\nThe maximum Disk Size for Pro Tier is 1024TB. If you need more than this, contact us to learn more about the Enterprise plan.\nFree Tier Behavior\nFree Tier projects enter read-only mode when you exceed the 500mb limit. Once in read-only mode, you have several options:\n\nUpgrade to the Pro or Enterprise tier to enable auto-scaling and expand beyond the 500mb database size limit.\nDisable read-only mode and reduce your database size.\n\nRead-only mode\nIn some cases Supabase may put your database into read-only mode to prevent your database from exceeding the billing or disk limitations.\nIn read-only mode, clients will encounter errors such as `cannot execute INSERT in a read-only transaction`. Regular operation (read-write mode) is automatically re-enabled once usage is below 95% of the disk size,\nDisabling read-only mode\nYou can manually override read-only mode to reduce disk size. To do this, run the following in the SQL Editor:\n`sql\nSET\n  default_transaction_read_only = 'off';`\nThis allows you to delete data from within the session. After deleting data, you should run a vacuum to reclaim as much space as possible.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Check restrictions",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/network-restrictions.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'network-restrictions',\n  title: 'Network Restrictions',\n  description: \"Apply network restrictions for your project's database.\",\n}\n\nNetwork Restrictions is currently in beta and is slowly being made available to all projects. Contact support if you'd like to request early access.\n\nEach Supabase project comes with configurable restrictions on the IP ranges that are allowed to connect to Postgres and PgBouncer (\"your database\"). These restrictions are enforced before traffic reaches your database. If a connection is not restricted by IP, it still needs to authenticate successfully with valid database credentials.\nTo get started:\n\nInstall the Supabase CLI 1.22.0+.\nLog in to your Supabase account using the CLI.\nIf your project was created before 23rd December 2022, it will need to be upgraded to the latest Supabase version before Network Restrictions can be used.\nEnsure that you have Owner or Admin permissions for the project that you are enabling network restrictions.\n\nCheck restrictions\nYou can use the `get` subcommand of the CLI to retrieve the restrictions currently in effect.\nIf restrictions have been applied, the output of the `get` command will reflect the IP ranges allowed to connect:\n```bash\n\nsupabase network-restrictions --project-ref {ref} get --experimental\nDB Allowed CIDRs: [128.12.1.1/16 183.12.1.1/24]\nRestrictions applied successfully: true\n```\n\nIf restrictions have never been applied to your project, the list of allowed CIDRs will be empty, but they will also not have been applied (\"Restrictions applied successfully: false\"). As a result, all IPs are allowed to connect to your database:\n```bash\n\nsupabase network-restrictions --project-ref {ref} get --experimental\nDB Allowed CIDRs: []\nRestrictions applied successfully: false\n```\n\nUpdate restrictions\nThe `update` subcommand is used to apply network restrictions to your project:\n```bash\n\nsupabase network-restrictions --project-ref {ref} update --db-allow-cidr 128.12.1.1/16 --db-allow-cidr 183.12.1.1/24 --experimental\nDB Allowed CIDRs: [128.12.1.1/16 183.12.1.1/24]\nRestrictions applied successfully: true\n```\n\nThe restrictions specified (in the form of CIDRs) replaces any restrictions that might have been applied in the past.\nTo add to the existing restrictions, you must include the existing restrictions within the list of CIDRs provided to the `update` command.\nRemove restrictions\nTo remove all restrictions on your project, you can use the `update` subcommand with the CIDR `0.0.0.0/0`:\n```bash\n\nsupabase network-restrictions --project-ref {ref} update --db-allow-cidr 0.0.0.0/0 --experimental\nDB Allowed CIDRs: [0.0.0.0/0]\nRestrictions applied successfully: true\n```\n\nLimitations\n\nThe current iteration of Network Restrictions applies to connections to Postgres and PgBouncer and doesn't currently apply to APIs offered over HTTPS (e.g., PostgREST, Storage, and Auth).\nNetwork Restrictions should not be used if you need to connect to your Postgres database using Edge Functions.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Product Logs",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/logs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'logs',\n  title: 'Logging',\n  description: 'Getting started with Supabase Platform Log Browser',\n}\nThe Supabase Platform includes a Logs Explorer that allows log tracing and debugging. Log retention is based on your project's pricing plan.\n\nThese features are not currently available for self-hosting and local development.\nThis is on the roadmap and you can follow the progress in the Logflare repository.\n\nProduct Logs\nSupabase provides a logging interface specific to each product. You can use simple regular expressions for keywords and patterns to search log event messages. You can also export and download the log events matching your query as a spreadsheet.\n{/  /}\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"api\"\n\n\n\nAPI logs show all network requests and response for the REST and GraphQL APIs.\n\n\n\nPostgres logs show queries and activity for your database.\n\n\n\nAuth logs show all server logs for your Auth usage.\n\n\n\nStorage logs shows all server logs for your Storage API.\n\n\n\nRealtime logs show all server logs for your Realtime API usage.\n\n\n\nFor each Edge Function, logs are available under the following tabs:\nInvocations\nThe Invocations tab displays the edge logs of function calls.\n\nLogs\nThe Logs tab displays logs emitted during function execution.\n\n\n\n\nLogging Postgres Queries\nBy default, query logs are disabled for new Supabase projects, as they can reveal metadata about the contents of your database (such as table and column names).\nTo enable query logs:\n\nEnable the pgAudit extension.\nRestart your project using the Fast database reboot option.\nConfigure `pgaudit.log` (see below). Perform a fast reboot if needed.\nView your query logs under Logs > Postgres Logs.\n\nConfiguring `pgaudit.log`\nThe stored value under `pgaudit.log` determines the classes of statements that are logged by pgAudit extension. Refer to the pgAudit documentation for the full list of values.\nTo enable logging for function calls/do blocks, writes, and DDL statements for a single session, execute the following within the session:\n`sql\n-- temporary single-session config update\nset pgaudit.log = 'function, write, ddl';`\nTo permanently set a logging configuration (beyond a single session), execute the following, then perform a fast reboot:\n`sql\n-- equivalent permanent config update.\nalter role postgres set pgaudit.log to 'function, write, ddl';`\nTo reset system-wide settings, execute the following, then perform a fast reboot:\n`sql\n-- resets stored config.\nalter role postgres reset pgaudit.log`\n\nIf any permission errors are encountered when executing `alter role postgres ...`, it is likely that your project has yet to receive the patch to the latest version of supautils, which is currently being rolled out.\n\nLogs Explorer\nThe Logs Explorer exposes logs from each part of the Supabase stack as a separate table that can be queried and joined using SQL.\n\nYou can access the following logs from the Sources drop-down:\n\n`auth_logs`: GoTrue server logs, containing authentication/authorization activity.\n`edge_logs`: Edge network logs, containing request and response metadata retrieved from Cloudflare.\n`function_edge_logs`: Edge network logs for only edge functions, containing network requests and response metadata for each execution.\n`function_logs`: Function internal logs, containing any `console` logging from within the edge function.\n`postgres_logs`: Postgres database logs, containing statements executed by connected applications.\n`realtime_logs`: Realtime server logs, containing client connection information.\n`storage_logs`: Storage server logs, containing object upload and retrieval information.\n\nQuerying with the Logs Explorer\nThe Logs Explorer uses BigQuery and supports all available SQL functions and operators.\nTimestamp Display and Behavior\nEach log entry is stored with a `timestamp` as a `TIMESTAMP` data type. Use the appropriate timestamp function to utilize the `timestamp` field in a query.\nRaw top-level timestamp values are rendered as unix microsecond. To render the timestamps in a human-readable format, use the `DATETIME()` function to convert the unix timestamp display into an ISO-8601 timestamp.\n```sql\n-- timestamp column without datetime()\nselect timestamp from ....\n--  1664270180000\n-- timestamp column with datetime()\nselect datetime(timestamp) from ....\n-- 2022-09-27T09:17:10.439Z\n```\nUnnesting Arrays\nEach log event stores metadata an array of objects with multiple levels, and can be seen by selecting single log events in the Logs Explorer. To query arrays, use `unnest()` on each array field and add it to the query as a join. This allows you to reference the nested objects with an alias and select their individual fields.\nFor example, to query the edge logs without any joins:\n`sql\nselect timestamp, metadata from edge_logs t`\nThe resulting `metadata` key is rendered as an array of objects in the Logs Explorer. In the following diagram, each box represents a nested array of objects:\n{/  /}\n\nPerform a `cross join unnest()` to work with the keys nested in the `metadata` key.\nTo query for a nested value, add a join for each array level:\n`sql\nselect timestamp, request.method, header.cf_ipcountry\nfrom edge_logs t\ncross join unnest(t.metadata) as metadata\ncross join unnest(metadata.request) as request\ncross join unnest(request.headers) as header`\nThis surfaces the following columns available for selection:\n\nThis allows you to select the `method` and `cf_ipcountry` columns. In JS dot notation, the full paths for each selected column are:\n\n`metadata[].request[].method`\n`metadata[].request[].headers[].cf_ipcountry`\n\nLIMIT and Result Row Limitations\nThe Logs Explorer has a maximum of 1000 rows per run. Use `LIMIT` to optimize your queries by reducing the number of rows returned further.\nBest Practices\n\nInclude a filter over timestamp\n\nQuerying your entire log history might seem appealing. For Enterprise customers that have a large retention range, you run the risk of timeouts due additional time required to scan the larger dataset.\n\nAvoid selecting large nested objects. Select individual values instead.\n\nWhen querying large objects, the columnar storage engine selects each column associated with each nested key, resulting in a large number of columns being selected. This inadvertently impacts the query speed and may result in timeouts or memory errors, especially for projects with a lot of logs.\nInstead, select only the values required.\n```sql\n-- \u274c Avoid doing this\nselect\n  datetime(timestamp),\n  m as metadata  -- <- metadata contains many nested keys\nfrom edge_logs t\ncross join unnest(t.metadata) as m;\n-- \u2705 Do this\nselect\ndatetime(timestamp),\nr.method   -- <- select only the required values\nfrom edge_logs t\ncross join unnest(t.metadata) as m\ncross join unnest(m.request) as r\n```\nExamples and Templates\nThe Logs Explorer includes Templates (available in the Templates tab or the dropdown in the Query tab) to help you get started.\nFor example, you can enter the following query in the SQL Editor to retrieve each user's IP address:\n`sql\nselect datetime(timestamp), h.x_real_ip\nfrom edge_logs\n  cross join unnest(metadata) as m\n  cross join unnest(m.request) AS r\n  cross join unnest(r.headers) AS h\nwhere h.x_real_ip is not null and r.method = \"GET\"`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "permissions.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/permissions.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'permissions',\n  title: 'Permissions',\n  description: 'Permissions requirements for the Supabase Cloud hosting environment',\n}\nThe Supabase platform offers additional services (e.g. Storage) on top of the Postgres database that comes with each project. These services default to storing their operational data within your database, to ensure that you retain complete control over it.\nHowever, these services assume a base level of access to their data, in order to e.g. be able to run migrations over it. Breaking these assumptions runs the risk of rendering these services inoperational for your project:\n\nall entitites under the `storage` schema are owned by `supabase_storage_admin`\nall entitites under the `auth` schema are owned by `supabase_auth_admin`\n\nIt is possible for violations of these assumptions to not cause an immediate outage, but take effect at a later time when a newer migration becomes available.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Frequency of Backups",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/backups.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Database Backups',\n  description: 'Learn about the available backup methods for your Supabase project.',\n}\nDatabase backups are an integral part of any disaster recovery plan. Disasters come in many shapes and sizes. It could be as simple as accidentally deleting a table column, the database crashing, or even a natural calamity wiping out the underlying hardware a database is running on. The risks and impact brought by these scenarios can never be fully eliminated, but only minimized or even mitigated. Having database backups is a form of insurance policy. They are essentially snapshots of the database at various points in time. When disaster strikes, database backups allow the project to be brought back to any of these points in time, therefore averting the crisis.\nFrequency of Backups\nWhen deciding how often a database should be backed up, the key business metric Recovery Point Objective (RPO) should be considered. RPO is the threshold for how much data, measured in time, a business could lose when disaster strikes. This amount is fully dependent on a business and its underlying requirements. A low RPO would mean that database backups would have to be taken at an increased cadence throughout the day. Each Supabase project has access to two forms of backups, Daily Backups and Point-in-Time Recovery. The agreed upon RPO would be a deciding factor in choosing which solution best fits a project.\n\n  Database backups do\u00a0not include objects stored via the Storage API, as the database only includes\n  metadata about these objects. Restoring an old backup does not restore objects that have been\n  deleted since then.\n\nDaily Backups\nAll Pro and Enterprise tier Supabase projects are backed up automatically on a daily basis. In terms of Recovery Point Objective (RPO), Daily Backups would be suitable for projects willing to lose up to 24 hours worth of data if disaster hits at the most inopportune time. If a lower RPO is required, enabling Point-in-Time Recovery should be considered.\nBackup Process [#daily-backups-process]\nThe PostgreSQL utility pg_dumpall is used to perform daily backups. An SQL file is generated, zipped up, and sent to our storage servers for safe keeping.\n\nYou can access daily backups in the Scheduled backups settings in the Dashboard. Pro tier projects can access the last 7 days\u2019 worth of daily backups while Enterprise tier projects can access up to 30 days\u2019 worth of daily backups. Users can restore their project to any one of the backups or download them as a zipped SQL file.\nRestoration Process [#daily-backups-restoration-process]\nWhen selecting a backup to restore to, select the closest available one made before the desired point in time to restore to. Earlier backups can always be chosen too but do consider the number of days\u2019 worth of data that could be lost.\n\nThe Dashboard will then prompt for a confirmation before proceeding with the restoration. The project will be inaccessible following this. As such, do ensure to allot downtime beforehand. This is dependent on the size of the database. The larger it is, the longer the downtime will be. Once the confirmation has been given, the underlying SQL of the chosen backup is then run against the project. The PostgreSQL utility psql is used to facilitate the restoration. The Dashboard will display a notification once the restoration completes.\n{/ screenshot of the Dashboard of the project completing restoration /}\nPoint-in-Time Recovery\nPoint-in-Time Recovery (PITR) allows a project to be backed up at much shorter intervals. This provides users an option to restore to any chosen point of up to seconds in granularity. Even with daily backups, a day\u2019s worth of data could still be lost. With PITR, backups could be performed up to the point of disaster.\n\n  This feature is available to all Enterprise tier projects. Pro tier projects can enable PITR as an\n  add-on.\n\nBackup Process [#pitr-backup-process]\nAs discussed here, PITR is made possible by a combination of taking physical backups of a project, as well as archiving Write Ahead Log (WAL) files. Physical backups provide a snapshot of the underlying directory of the database, while WAL files contain records of every change made in the database.\nSupabase uses WAL-G, an open source archival and restoration tool, to handle both aspects of PITR. On a daily basis, a snapshot of the database is taken and sent to our storage servers. Throughout the day, as database transactions occur, WAL files are generated and uploaded.\nBy default, WAL files are backed up at two minute intervals. If these files cross a certain file size threshold, they are backed up immediately. As such, during periods of high amount of transactions, WAL file backups become more frequent. Conversely, when there is no activity in the database, WAL file backups are not made. Overall, this would mean that at the worst case scenario or disaster, the PITR achieves a Recovery Point Objective (RPO) of two minutes.\n\nYou can access PITR in the Point in Time settings in the Dashboard. The recovery period of a project is indicated by the earliest and latest points of recoveries displayed in one\u2019s preferred timezone. If need be, the maximum amount of this recovery period can be modified accordingly.\nNote that the latest restore point of the project could be significantly far from the current time. This occurs when there has not been any recent activity in the database, and therefore no WAL file backups have been made recently. This is perfectly fine as the state of the database at the latest point of recovery would still be indicative of the state of the database at the current time given that no transactions have been made in between.\nRestoration Process [#pitr-restoration-process]\n\nA date and time picker will be provided upon pressing the `Start a restore` button. The process will only proceed if the selected date and time fall within the earliest and latest points of recoveries.\n\nAfter locking in the desired point in time to recover to, The Dashboard will then prompt for a review and confirmation before proceeding with the restoration. The project will be inaccessible following this. As such, do ensure to allot for downtime beforehand. This is dependent on the size of the database. The larger it is, the longer the downtime will be. Once the confirmation has been given, the latest physical backup available is downloaded to the project and the database is partially restored. WAL files generated after this physical backup up to the specified point-in-time are then downloaded. The underlying records of transactions in these files are replayed against the database to complete the restoration. The Dashboard will display a notification once the restoration completes.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Security",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/going-into-prod.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'going-into-prod',\n  title: 'Production Readiness',\n  description: 'Things to do before making your app publicly available',\n}\nAfter developing your project and deciding it's Production Ready, you should run through this checklist to ensure that your project:\n\nis secure\nwon't falter under the expected load\nremains available whilst in production\n\nSecurity\n\nEnsure RLS is enabled\nTables that do not have RLS enabled with reasonable policies allow any client to access and modify their data. This is unlikely to be what you want in the majority of cases.\nLearn more about RLS.\nEnable replication on tables containing sensitive data by enabling Row Level Security (RLS) and setting row security policies:\nGo to the Authentication > Policies page in the Supabase Dashboard to enable RLS and create security policies.\nGo to the Database > Replication page in the Supabase Dashboard to manage replication tables.\nEnable 2FA on GitHub. Since your GitHub account gives you administrative rights to your Supabase project, you should protect it with a strong password and 2FA using a U2F key or a TOTP app.\nEnsure email confirmations are enabled in the `Auth > Settings` page.\nUse a custom SMTP server for auth emails so that your users can see that the mails are coming from a trusted domain (preferably the same domain that your app is hosted on). Grab SMTP credentials from any major email provider such as SendGrid, AWS SES, etc.\nThink hard about how you would abuse your service as an attacker, and mitigate.\nReview these common cybersecurity threats.\n\nPerformance\n\nEnsure that you have suitable indices to cater to your common query patterns\nLearn more about indexes in Postgres.\n`pg_stat_statements` can help you identify hot or slow queries.\nPerform load testing (preferably on a staging env)\nTools like k6 can simulate traffic from many different users.\nUpgrade your database if you require more resources. If you need anything beyond what is listed, contact enterprise@supabase.io.\nIf you are expecting a surge in traffic (for a big launch), let the team know by sending your Project Ref to us (support@supabase.io) with more details about your launch. We'll keep an eye on your project.\n\nAvailability\n\nUse your own SMTP credentials so that you have full control over the deliverability of your transactional auth emails (see Auth > Settings)\nyou can grab SMTP credentials from any major email provider such as SendGrid, AWS SES, etc.\nThe default rate limit for auth emails provided by Supabase is 30 new users per hour, if doing a major public announcement you will likely require more than this.\nIf your application is on the free tier and is not expected to be queried at least once every 7 days, then it may be paused by Supabase to save on server resources.\nYou can restore paused projects from the Supabase dashboard.\nUpgrade to Pro to guarantee that your project will not be paused for inactivity.\nDatabase backups are not available for download on the free tier.\nYou can set up your own backup systems using tools like pg_dump or wal-g.\nNightly backups for Pro tier projects are available on the Supabase dashboard for up to 7 days.\nUpgrading to the Supabase Pro Tier will give you access to email support on support@supabase.io\n\nRate Limiting, Resource Allocation, & Abuse Prevention\n\nSupabase employs a number of safeguards against bursts of incoming traffic to prevent abuse and help maximize stability across the platform\nIf you're expecting high load events including production launches or heavy load testing, or prolonged high resource usage please give us at least 2 weeks notice. You can do this by opening a ticket via the support form.\n\nRate Limits\n\nThe table below shows the rate limit quotas on the following authentication endpoints:\n\n| Endpoint                                         | Path                                                           | Limited By               | Rate Limit                                                                      |\n| ------------------------------------------------ | -------------------------------------------------------------- | ------------------------ | ------------------------------------------------------------------------------- |\n| All endpoints that send emails                   | `/auth/v1/signup` `/auth/v1/recover` `/auth/v1/user`[^1]       | Sum of combined requests | Defaults to 30 emails per hour. Is customizable with custom SMTP set up.        |\n| All endpoints that send One-Time-Passwords (OTP) | `/auth/v1/otp`                                                 | Sum of combined requests | Defaults to 30 OTPs per hour. Is customizable.                                  |\n| Send OTPs or magiclinks                          | `/auth/v1/otp`                                                 | Last request             | Defaults to 60 seconds window before a new request is allowed. Is customizable. |\n| Signup confirmation request                      | `/auth/v1/signup`                                              | Last request             | Defaults to 60 seconds window before a new request is allowed. Is customizable. |\n| Password Reset Request                           | `/auth/v1/recover`                                             | Last request             | Defaults to 60 seconds window before a new request is allowed. Is customizable. |\n| Verification requests                            | `/auth/v1/verify`                                              | IP Address               | 360 requests per hour (with bursts up to 30 requests)                           |\n| Token refresh requests                           | `/auth/v1/token`                                               | IP Address               | 360 requests per hour (with bursts up to 30 requests)                           |\n| Create or Verify an MFA challenge                | `/auth/v1/factors/:id/challenge` `/auth/v1/factors/:id/verify` | IP Address               | 15 requests per minute (with bursts up to 30 requests)                          |\nAbuse Prevention\n\nSupabase provides CAPTCHA protection on the signup, sign-in and password reset endpoints. Please refer to our guide on how to protect against abuse using this method.\n\nEmail Link Validity\n\nWhen working with enterprise systems, email scanners may scan and make a `GET` request to the reset password link or sign up link in your email. Since links in Supabase Auth are single use, a user who opens an email post-scan to click on a link will receive an error. To get around this problem,\n  consider altering the email template to replace the original magic link with a link to a domain you control. The domain can present the user with a \"Sign-in\" button which redirect the user to the original magic link URL when clicked.\n\nNext steps\nThis checklist is always growing so be sure to check back frequently, and also feel free to suggest additions and amendments by making a PR on GitHub.\n[^1]: The rate limit is only applied on `/auth/v1/user` if this endpoint is called to update the user's email address.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Examining Query Performance",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/performance.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'performance',\n  title: 'Performance Tuning',\n  description: 'Getting the best results out of your Supabase project',\n}\nThe Supabase platform automatically optimizes your Postgres database to take advantage of the compute resources of the tier your project is on. However, these optimizations are based on assumptions about the type of workflow the project is being utilized for, and it is likely that better results can be obtained by tuning the database for your particular workflow.\nExamining Query Performance\nUnoptimized queries are a major cause of poor database performance. The techniques on this page can help you identify and understand queries that take the most time and resources from your database.\nDatabase performance is a large topic and many factors can contribute. Some of the most common causes of poor performance include:\n\nAn inefficiently designed schema\nInefficiently designed queries\nA lack of indexes causing slower than required queries over large tables\nUnused indexes causing slow `INSERT`, `UPDATE` and `DELETE` operations\nNot enough compute resources, such as memory, causing your database to go to disk for results too often\nLock contention from multiple queries operating on highly utilized tables\nLarge amount of bloat on your tables causing poor query planning\n\nThankfully there are solutions to all these issues, which we will cover in the following sections.\nPostgres Cumulative Statistics system\nPostgres collects data about its own operations using the cumulative statistics system. In addition to this, every Supabase project has the pg_stat_statements extension enabled by default. This extension records query execution performance details and is the best way to find inefficient queries. This information can be combined with the Postgres query plan analyzer to develop more efficient queries.\nHere are some example queries to get you started.\nMost frequently called queries:\n```sql\nselect\n  auth.rolname,\n  statements.query,\n  statements.calls,\n  -- -- Postgres 13, 14, 15\n  statements.total_exec_time + statements.total_plan_time as total_time,\n  statements.min_exec_time + statements.min_plan_time as min_time,\n  statements.max_exec_time + statements.max_plan_time as max_time,\n  statements.mean_exec_time + statements.mean_plan_time as mean_time,\n  -- -- Postgres <= 12\n  -- total_time,\n  -- min_time,\n  -- max_time,\n  -- mean_time,\n  statements.rows / statements.calls as avg_rows\nfrom pg_stat_statements as statements\n  inner join pg_authid as auth on statements.userid = auth.oid\norder by\n  statements.calls desc\nlimit\n  100;\n```\nThis query shows:\n\nquery statistics, ordered by the number of times each query has been executed\nthe role that ran the query\nthe number of times it has been called\nthe average number of rows returned\nthe cumulative total time the query has spent running \nthe min, max and mean query times.\n\nThis provides useful information about the queries you run most frequently. Queries that have high `max_time` or `mean_time` times and are being called often can be good candidates for optimization.\nSlowest queries by execution time:\n`sql\nselect\n  auth.rolname,\n  statements.query,\n  statements.calls,\n  -- -- Postgres 13, 14, 15\n  statements.total_exec_time + statements.total_plan_time as total_time,\n  statements.min_exec_time + statements.min_plan_time as min_time,\n  statements.max_exec_time + statements.max_plan_time as max_time,\n  statements.mean_exec_time + statements.mean_plan_time as mean_time,\n  -- -- Postgres <= 12\n  -- total_time,\n  -- min_time,\n  -- max_time,\n  -- mean_time,\n  statements.rows / statements.calls as avg_rows\nfrom pg_stat_statements as statements\n    inner join pg_authid as auth on statements.userid = auth.oid\n  order by\n    max_time desc\n  limit\n    100;`\nThis query will show you statistics about queries ordered by the maximum execution time. It is similar to the query above ordered by calls, but this one highlights outliers that may have high executions times. Queries which have high or mean execution times are good candidates for optimisation.\nMost time consuming queries:\n`sql\nselect\n  auth.rolname,\n  statements.query,\n  statements.calls,\n  statements.total_exec_time + statements.total_plan_time as total_time,\n  to_char(((statements.total_exec_time + statements.total_plan_time)/sum(statements.total_exec_time + statements.total_plan_time) over()) * 100, 'FM90D0') || '%'  as prop_total_time\nfrom pg_stat_statements as statements\n  inner join pg_authid as auth on statements.userid = auth.oid\norder by\n  total_time desc\nlimit\n  100;`\nThis query will show you statistics about queries ordered by the cumulative total execution time. It shows the total time the query has spent running as well as the proportion of total execution time the query has taken up.\nQueries which are the most time consuming are not necessarily bad, you may have a very effiecient and frequently ran queries that end up taking a large total % time, but it can be useful to help spot queries that are taking up more time than they should.\nHit rate\nGenerally for most applications a small percentage of data is accessed more regularly than the rest. To make sure that your regularly accessed data is available, Postgres tracks your data access patterns and keeps this in its shared_buffers cache.\nApplications with lower cache hit rates generally perform more poorly since they have to hit the disk to get results rather than serving them from memory. Very poor hit rates can also cause you to burst past your Disk I/O limits causing significant performance issues.\nYou can view your cache and index hit rate by executing the following query:\n`sql\nselect\n  'index hit rate' as name,\n  (sum(idx_blks_hit)) / nullif(sum(idx_blks_hit + idx_blks_read),0) * 100 as ratio\nfrom pg_statio_user_indexes\nunion all\nselect\n  'table hit rate' as name,\n  sum(heap_blks_hit) / nullif(sum(heap_blks_hit) + sum(heap_blks_read),0) * 100 as ratio\nfrom pg_statio_user_tables;`\nThis shows the ratio of data blocks fetched from the Postgres shared_buffers cache against the data blocks that were read from disk/OS cache.\nIf either of your index or table hit rate are < 99% then this can indicate your compute plan is too small for your current workload and you would benefit from more memory. Upgrading your compute is easy and can be done from your project dashboard.\nOptimizing poor performing queries\nPostgres has built in tooling to help you optimize poorly performing queries. You can use the query plan analyzer on any expensive queries that you have identified:\n`sql\nexplain analyze <query-statement-here>;`\nBe careful using `explain analyze` with `insert`/`update`/`delete` queries, because the query will actually run, and could have unintended side-effects.\nUsing the query plan analyzer to optimize your queries is a large topic, with a number of online resources available:\n\nOfficial docs.\nThe Art of PostgreSQL.\nPostgres Wiki.\nEnterprise DB.\n\nYou can pair the information available from `pg_stat_statements` with the detailed system metrics available via your metrics endpoint to better understand the behavior of your DB and the queries you're executing against it.\nOptimizing the number of connections\nBy default, the number of connections allowed to Postgres and PgBouncer is configured based on the resources available to the database.\n| Compute Add-on | Postgresql connections | PGBouncer connections |\n| -------------- | ---------------------- | --------------------- |\n| None           | 60                     | 200                   |\n| Small          | 90                     | 200                   |\n| Medium         | 120                    | 200                   |\n| Large          | 160                    | 300                   |\n| XL             | 240                    | 700                   |\n| 2XL            | 380                    | 1500                  |\n| 4XL            | 480                    | 3000                  |\n| 8XL            | 490                    | 6000                  |\n| 12XL           | 500                    | 9000                  |\n| 16XL           | 500                    | 12000                 |\nIf the number of connections is insufficient, you will receive the following error upon connecting to the DB:\n`shell\n$ psql -U postgres -h ...\nFATAL: remaining connection slots are reserved for non-replication superuser connections`\nIn such a scenario, you can consider:\n\nupgrading to a larger compute add-on\nconfiguring your clients to use fewer connections\nmanually configuring the database for a higher number of connections\n\nConfiguring clients to use fewer connections\nYou can use the pg_stat_activity view to debug which clients are holding open connections on your DB. `pg_stat_activity` only exposes information on direct connections to the database. Information on the number of connections to pgbouncer is available via the metrics endpoint.\nDepending on the clients involved, you might be able to configure them to work with fewer connections (e.g. by imposing a limit on the maximum number of connections they're allowed to use), or shift specific workloads to connect via pgbouncer instead. Transient workflows, which can quickly scale up and down in response to traffic (e.g. serverless functions), can especially benefit from using a connection pooler rather than connecting to the DB directly.\nAllowing higher number of connections\nYou can configure Postgres by executing the following statement, followed by a server restart:\n`sql\nalter system set max_connections = '<val-here>';`\nNote that the default configuration used by the Supabase platform optimizes the database to maximize resource utilization, and as a result, you might also need to configure other options (e.g. `work_mem`, `shared_buffers`, `maintenance_work_mem`) in order to tune them towards your use-case, and to avoid causing instability in your database.\nOnce overridden, the Supabase platform will continue to respect your manually configured value (even if the add-on size is changed), unless the override is removed with the following statement, followed by a server restart:\n`sql\nalter system reset max_connections;\nalter system reset <other-overridden-conf>;\n...`\nConfiguring the number of PgBouncer connections is not supported at this time.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Manage team members",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/access-control.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport { IconCheck } from 'ui'\nexport const meta = {\n  title: 'Access Control',\n  description: 'Roles and permissions at the organization level',\n}\nSupabase provides granular access controls to manage permissions across your organizations.\nFor each organization, a member can have one of the following roles:\n\nOwner\nAdministrator\nDeveloper\n\nA default organization is created when you first sign in and\nyou'll be assigned the Owner role.\nEach member can access all projects under the organization.\nProject level invites are not available at this time.\nCreate a separate organization if you need to restrict access to certain projects.\nManage team members\nTo invite others to collaborate, visit your organization's team settings in the\nDashboard to send an invite link to\nanother user's email. The invite expires after 24 hours.\nTransferring ownership of an organization\nEach Supabase organization can have one or more owners. If you no longer want be an owner of an organization, click Leave team in the members view (`https://app.supabase.com/org/<org-slug>/settings#team`) of your organization.\nHowever, you can only leave an organization when there is at least one other owner.\nIf you are transferring ownership of your organization to someone else, you will need to invite the new member with the Owner role. You can leave the organization after they've accepted the invitation.\nPermissions across roles [#permission-across-roles]\nThe table below shows the corresponding permissions for each available role you can assign a team member in the Dashboard.\n| Permissions              | Owner                   | Administrator           | Developer               |\n| ------------------------ | ----------------------- | ----------------------- | ----------------------- |\n| Organization         |\n| Change organization name |  |                         |                         |\n| Delete organization      |  |                         |                         |\n| Members              |\n| Add an Owner             |  |                         |                         |\n| Remove an Owner          |  |                         |                         |\n| Add an Administrator     |  |  |                         |\n| Remove an Administrator  |  |  |                         |\n| Add a Developer          |  |  |                         |\n| Remove a Developer       |  |  |                         |\n| Revoke an invite         |  |  |                         |\n| Resend an invite         |  |  |                         |\n| Accept an invite[^1]     |  |  |  |\n| Billing              |\n| Read invoices            |  |  |  |\n| Read billing email       |  |  |  |\n| Change billing email     |  |                         |                         |\n| View subscription        |  |  |  |\n| Update subscription      |  |  |                         |\n| Read billing address     |  |  |  |\n| Update billing address   |  |  |                         |\n| Read tax codes           |  |  |  |\n| Update tax codes         |  |  |                         |\n| Read payment methods     |  |  |  |\n| Update payment methods   |  |  |                         |\n| Projects             |\n| Create a project         |  |  |                         |\n| Delete a project         |  |  |                         |\n| Update a project         |  |  |                         |\n| Pause a project          |  |  |                         |\n| Resume a project         |  |  |                         |\n| Restart a project        |  |  |  |\n[^1]:\n    Invites sent from a SSO account can only be accepted by another SSO account\n    coming from the same identity provider. This is a security measure that\n    prevents accidental invites to accounts not managed by your company's\n    enterprise systems.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Accessing the metrics endpoint",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/metrics.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'metrics',\n  title: 'Metrics',\n  description: 'Observability for your Supabase project',\n}\nIn addition to the reports and charts built in to the Supabase dashboard, each project hosted on the Supabase platform comes with a Prometheus-compatible metrics endpoint, which can be used to gather insight into the health and status of your project.\nYou can use this endpoint to ingest data into your own monitoring and alerting infrastructure, as long as it is capable of scraping Prometheus-compatible endpoints, in order to set up custom rules beyond those supported by the Supabase dashboard.\n\nThe endpoint discussed in this article is in beta, and the metrics returned by it might evolve or be changed in the future to increase its utility.\n\n\nThe endpoint discussed in this article is not available on self-hosted.\n\nAccessing the metrics endpoint\nYour project's metrics endpoint is accessible at `https://<project-ref>.supabase.co/customer/v1/privileged/metrics`. Access to the endpoint is secured via HTTP Basic Auth; the username is `service_role`, while the password is the service role JWT available through the Supabase dashboard.\n```shell\n\ncurl https://.supabase.co/customer/v1/privileged/metrics --user 'service_role:'\n```\n\nAdditionally, we maintain a guide on quickly setting up a scraping agent to work with Grafana Cloud.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Dedicated vs. shared CPU",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/compute-add-ons.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'compute-add-ons',\n  title: 'Compute Add-ons',\n  description: \"Learn about your project's instance and additional add-ons.\",\n}\nEvery project on the Supabase Platform comes with its own dedicated Postgres instance running inside a virtual machine (VM). The following table describes the base instance with additional compute add-ons available if you need extra performance when scaling up Supabase.\n| Plan            | Pricing | CPU                     | Memory | Maximum Disk IO Bandwidth | Baseline Disk IO Bandwidth | Connections: Direct (recommended) | Connections: Pooler (recommended) |\n| --------------- | ------- | ----------------------- | ------ | ------------------------- | -------------------------- | --------------------------------- | --------------------------------- |\n| Free (Included) | $0      | 2-core ARM (shared)     | 1 GB   | 2,606 Mbps                | 87 Mbps                    | 10                                | 50                                |\n| Small           | $5      | 2-core ARM (shared)     | 2 GB   | 2,606 Mbps                | 174 Mbps                   | 30                                | 75                                |\n| Medium          | $50     | 2-core ARM (shared)     | 4 GB   | 2,606 Mbps                | 347 Mbps                   | 50                                | 150                               |\n| Large           | $100    | 2-core ARM (dedicated)  | 8 GB   | 4,750 Mbps                | 630 Mbps                   | 100                               | 300                               |\n| XL              | $200    | 4-core ARM (dedicated)  | 16 GB  | 4,750 Mbps                | 1,188 Mbps                 | 200                               | 600                               |\n| 2XL             | $400    | 8-core ARM (dedicated)  | 32 GB  | 4,750 Mbps                | 2,375 Mbps                 | 350                               | 1200                              |\n| 4XL             | $950    | 16-core ARM (dedicated) | 64 GB  | 4,750 Mbps                | 4,750 Mbps                 | 420                               | 2800                              |\n| 8XL             | $1,860  | 32-core ARM (dedicated) | 128 GB | 9,500 Mbps                | 9,500 Mbps                 | 450                               | 5600                              |\n| 12XL            | $2,790  | 48-core ARM (dedicated) | 192 GB | 14,250 Mbps               | 14,250 Mbps                | 480                               | 8600                              |\n| 16XL            | $3,720  | 64-core ARM (dedicated) | 256 GB | 19,000 Mbps               | 19,000 Mbps                | 500                               | 11,600                            |\nContact us if you require a custom plan.\nDedicated vs. shared CPU\nAll Postgres instances on Supabase are dedicated applications running inside dedicated virtual machines. However, the underlying hardware resources, for example the physical CPU, may be shared between multiple VMs, but appear to the OS as if it is a dedicated hardware CPU. This is commonly referred to as a vCPU (virtual CPU). Cloud providers use these shared hardware resources to save cost\u2014you can upgrade to a larger compute add-on to guarantee a dedicated physical CPU for your instance.\nCompute upgrades [#upgrades]\nWhen considering compute upgrades, assess whether your bottlenecks are hardware-constrained or software-constrained. For example, you may want to look into optimizing the number of connections or examining query performance. When you're happy with your Postgres instance's performance, then you can focus on additional compute resources. For example, you can load test your application in staging to understand your compute requirements. You can also start out on a smaller tier, create a report in the Dashboard to monitor your CPU utilization, and upgrade later as needed\nDisk IO bandwidth\nSSD Disks are attached to your servers and the disk performance of your workload is determined by the Disk IO bandwidth of this connection. Smaller compute instances can burst up to the maximum disk IO bandwidth for 30 minutes in a day. Beyond that, the performance reverts to the baseline disk IO bandwidth. For example, the free tier can burst up to 2,606 Mbps for 30 minutes a day and reverts to the baseline performance of 87 Mbps. If you need consistent disk performance, choose the 4XL or larger compute add-on which has the same baseline and maximum disk IO bandwidth.\nIf you're unsure of how many IOPS your application requires, you can load test your project and inspect these metrics in the Dashboard. If the `Daily Disk IO Budget % Remaining` stat is less than 100%, it indicates that your workload has burst beyond the baseline IO throughput during the day. If this metric drops to zero, the workload has used up all the burst IO throughput minutes during the day and is running at the baseline performance. These projects are good candidates for upgrading to a larger compute add with higher baseline throughput.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "HTTP API Issues",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/troubleshooting.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'troubeshooting',\n  title: 'Troubleshooting',\n  description: 'Diagnosing and fixing issues with your hosted Supabase project.',\n}\nLearn how to diagnose and fix common issues with your Supabase project.\nHTTP API Issues\nSymptoms:\n\nHTTP timeouts\n5xx response codes\nHigh response times\n\nUnder-provisioned resources\nThe most common class of issues that causes HTTP timeouts and 5xx response codes is the under-provisioning of resources for your project. This can cause your project to be unable to service the traffic it is receiving.\nEach Supabase project is provisioned with segregated compute resources. This allows the project to serve unlimited requests, as long as they can be handled using the resources that have been provisioned. Complex queries, or queries that process larger amounts of data, will require higher amounts of resources. As such, the amount of resources that can handle a high volume of simple queries (or queries involving small amounts of data), will likely be unable to handle a similar volume of complex queries.\nYou can view the resource utilization of your Supabase Project using the reports in the Dashboard.\nSome common solutions for this issue are:\n\nUpgrading to a larger compute add-on in order to serve higher volumes of traffic.\nOptimizing the queries being executed.\nUsing fewer Postgres connections can reduce the amount of resources needed on the project.\nRestarting the database. This only temporarily solves the issue by terminating any ongoing workloads that might be tying up your compute resources.\n\nIf your Daily Disk IO budget has been drained, you will need to either wait for it to be replenished the next day, or upgrade to a larger compute add-on to increase the budget available to your project.\nUnable to connect to your Supabase Project\nSymptom: You're unable to connect to your Postgres database directly, but can open the Project in the Supabase Dashboard.\nToo many open connections\nErrors about too many open connections can be temporarily resolved by restarting the database. However, this won't solve the underlying issue for a permanent solution.\n\nIf you're receiving a `No more connections allowed (max_client_conn)` error:\nConfigure your applications and services to use fewer connections.\nUpgrade to a larger compute add-on to increase the number of available connections.\nIf you're receiving a `sorry, too many clients already` or `remaining connection slots are reserved for non-replication superuser connections` error message in addition to the above suggestions, switch to using the connection pooler instead.\n\nConnection refused\nIf you receive a `connection refused` error after a few initial failed connection attempts, your client has likely been temporarily blocked in order to protect the database from brute-force attacks. You can wait 30 minutes before trying again with the correct password, or you can contact support with your client's IP address to manually unblock you.\nIf you're also unable to open the project using the Supabase Dashboard, review the solutions for under-provisioned projects.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Check enforcement status",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/ssl-enforcement.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Postgres SSL Enforcement',\n  description: 'Enforce SSL usage for all Postgres connections',\n}\n\nPostgres SSL Enforcement is currently in beta and is slowly being made available to all projects. Contact support if you'd like to request early access.\n\nYour Supabase project supports connecting to the Postgres DB without SSL enabled to maximize client compatibility. For increased security, you can prevent clients from connecting if they're not using SSL.\nSSL enforcement only applies to connections to both Postgres and PgBouncer (\"Connection Pooler\"); all HTTP APIs offered by Supabase (e.g., PostgREST, Storage, Auth) automatically enforce SSL on all incoming connections.\nTo get started:\n\nInstall the Supabase CLI 1.37.0+.\nLog in to your Supabase account using the CLI.\nEnsure that you have Owner or Admin permissions for the project that you are enabling SSL enforcement.\n\nCheck enforcement status\nYou can use the `get` subcommand of the CLI to check whether SSL is currently being enforced:\n```bash\n\nsupabase ssl-enforcement --project-ref {ref} get --experimental\nSSL is being enforced.\n```\n\nOr similarly, if SSL is not being enforced, you will see:\n```bash\n\nsupabase ssl-enforcement --project-ref {ref} get --experimental\nSSL is NOT being enforced.\n```\n\nUpdate enforcement\nThe `update` subcommand is used to change the SSL enforcement status for your project:\n```bash\n\nsupabase ssl-enforcement --project-ref {ref} update --enable-db-ssl-enforcement --experimental\nSSL is now being enforced.\n```\n\nSimilarly, to disable SSL enforcement:\n```bash\n\nsupabase ssl-enforcement --project-ref {ref} update --disable-db-ssl-enforcement --experimental\nSSL is NOT being enforced.\n```\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Understanding setup and implications",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/sso.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Enable SSO for Your Organization',\n  description: 'General information about enabling single sign-on (SSO) for your organization',\n}\nSupabase offers single sign-on (SSO) as a login option to provide additional\naccount security for your team. This allows company administrators to enforce\nthe use of an identity provider when logging into Supabase. SSO\nimproves the onboarding and offboarding experience of the company as the\nemployee only needs a single set of credentials to access third-party\napplications or tools\u2014which can also be revoked easily by an administrator.\n\nSupabase currently provides SAML SSO. Please contact Enterprise\nSales to have this enabled for your\norganization.\n\nUnderstanding setup and implications\nAccounts signing in with SSO have certain limitations.\nThe following sections outline the limitations when SSO is enabled or disabled for your team.\nEnable SSO for your team [#enable-sso]\n\nOrganization invites are restricted to members of the company that belong to\n  the same identity provider.\nEvery user has an organization created by default. They can create as many\n  projects as they want.\nAn SSO user will not be able to update their password or reset their\n  password since their access is managed by the company administrator via the\n  identity provider.\nIf an SSO user with the following email of `alice@foocorp.com` attempts to\n  sign-in with a GitHub account that uses the same email, a separate Supabase\n  account is created and will not be linked to the SSO user's account.\nAn SSO user will not be able to see all organizations / projects created\n  under the same identity provider. They will need to be invited to the\n  Supabase organization first. Refer to access control\n  for more information.\n\nDisable SSO for your team [#disable-sso]\n\nYou can prevent a user's account from further access to Supabase by removing\n  or disabling their account in your identity provider.\nYou should also remove or downgrade their permissions from any organizations\n  inside Supabase.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Open the Google Workspace Web and mobile apps console [#google-workspace-console]",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/sso/gsuite.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Set Up SSO with Google Workspace',\n  description: 'Configure single sign-on with Google Workspace (GSuite).',\n}\nSupabase supports single sign-on (SSO) using Google Workspace (formerly known\nas GSuite).\nStep 1: Open the Google Workspace Web and mobile apps console [#google-workspace-console]\n\nStep 2: Choose Add custom SAML app [#add-custom-saml-app]\nFrom the Add app button in the toolbar choose Add custom SAML app.\n\nStep 3: Fill out app details [#add-app-details]\nThe information you enter here is for visibility into your Google Workspace.\nYou can choose any values you like. `Supabase` as a name works well for most\nuse cases. Optionally enter a description.\n\nStep 4: Download IdP metadata [#download-idp-metadata]\nThis is a very important step. Click on DOWNLOAD METADATA and save the file\nthat was downloaded.\n\nIt's very important to send this file to your support contact at Supabase to\ncomplete the SSO setup process. If you're not sure where to send this file, you\ncan always reach us at support@supabase.com.\nImportant: Make sure the certificate as shown on screen has at least 1 year\nbefore it expires. Mark down this date in your calendar so you will be reminded\nthat you need to update the certificate without any downtime for your users.\nStep 5: Add service provider details [#add-service-provider-details]\nFill out these serivce provider details on the next screen.\n| Detail         | Value                                               |\n| -------------- | --------------------------------------------------- |\n| ACS URL        | `https://alt.supabase.io/auth/v1/sso/saml/acs`      |\n| Entity ID      | `https://alt.supabase.io/auth/v1/sso/saml/metadata` |\n| Start URL      | `https://app.supabase.com`                          |\n| Name ID format | PERSISTENT                                          |\n| Name ID        | Basic Information > Primary email                 |\n\nStep 6: Configure Attribute mapping [#configure-attribute-mapping]\nAttribute mappings allow Supabase to get information about your Google\nWorkspace users on each login.\nA Primary email to `email` mapping is required to exist. Other mappings\nshown below are optional and configurable depending on your Google Workspace\nsetup. If in doubt, replicate the same config as shown.\nPlease share any changes, if any, from this screen with your Supabase support\ncontact.\n\nStep 7: Wait for confirmation [#confirmation]\nOnce you\u2019ve configured the Google Workspace app as shown above, make sure you\nsend the metadata file you downloaded\nand information regarding the attribute mapping (if any\nchanges are applicable) to your support contact at Supabase.\nThis information needs to be entered into Supabase before SSO is activated\nend-to-end.\nWait for confirmation that this information has successfully been added to\nSupabase. It usually takes us 1 business day to configure this information\nfor you.\nSupabase.\nStep 8: Configure user access [#configure-user-access]\nYou can configure which Google Workspace user accounts will get access to\nSupabase. This is important if you wish to limit access to your software\nengineering teams.\nYou can configure this access by clicking on the User\naccess card (or down-arrow). Follow the instructions on screen.\nChanges from this step sometimes take a while to propagate across Google\u2019s\nsystems. Please wait at least 15 minutes before proceeding to the next step.\n\nStep 9: Test single sign-on [#testing]\nOnce you\u2019ve turned on access to Supabase for users in your organization, ask\none of those users to help you out in testing the setup.\nIt often helps to ask them to log out of their Google account and log back in.\nAsk them to enter their email addres in the Sign in with\nSSO page.\nIf sign in is not working correctly, please reach out to your support contact\nat Supabase.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Add and register an Enterprise Application [#add-and-register-enterprise-application]",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/sso/azure.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport { Button, IconArrowDown } from 'ui'\nexport const meta = {\n  title: 'Set Up SSO with Azure AD',\n  description: 'Configure single sign-on with Azure AD (Microsoft Entra).',\n}\nSupabase supports single sign-on (SSO) using Microsoft Azure AD.\nStep 1: Add and register an Enterprise Application [#add-and-register-enterprise-application]\nOpen up the Azure Active\nDirectory\ndashboard for your Azure account.\nClick the Add button then Enterprise application.\n\nStep 2: Choose Create your own application [#create-application]\nYou'll be using the custom enterprise application setup for Supabase.\n\nStep 3: Fill in application details [#add-application-details]\nIn the modal titled Create your own application enter the name you wish\nSupabase to be available to your Azure AD users. `Supabase` works in most\ncases.\nMake sure to choose the third option: Integrate any other application you\ndon't find in the gallery (Non-gallery).\n\nStep 4: Choose the Set up single sign-on option [#set-up-single-sign-on]\nBefore you get to assigning users and groups, which would allow accounts in\nAzure AD to access Supabase, you need to configure the SAML details that allows\nSupabase to accept sign in requests from Azure AD.\n\nStep 5: Select SAML single sign-on method [#saml-sso]\nSupabase only supports the SAML 2.0 protocol for Single Sign-On, which is an\nindustry standard.\n\nStep 6: Upload SAML-based Sign-on metadata file [#upload-saml-metadata]\nFirst you need to download Supabase's SAML metadata file. Click the button\nbelow to initiate a download of the file.\n\n}>\n    Download Supabase SAML Metadata File\n  \n\nAlternatively, visit this page to initiate a download: `https://alt.supabase.io/auth/v1/sso/saml/metadata?download=true`\nClick on the Upload metadata file option in the toolbar and select the file\nyou just downloaded.\n\nAll of the correct information should automatically populate the Basic SAML\nConfiguration screen as shown.\n\nMake sure you input these additional settings.\n| Setting     | Value                                  |\n| ----------- | -------------------------------------- |\n| Sign on URL | `https://app.supabase.com/sign-in-sso` |\n| Relay State | `https://app.supabase.com`             |\nFinally, click the Save button to save the configuration.\nStep 7: Obtain metadata URL and send to Supabase [#send-metadata-url]\nSupabase needs to finalize enabling single sign-on with your Azure AD\napplication. To do this, please copy and send the link under App Federation\nMetadata Url in *section 3 SAML Certificates* to your support\ncontact and await further instructions. If you're not clear who to send this\nlink to or need further assistance, please reach out to\nsupport@supabase.com.\nDo not test the login until you have heard back from the support contact.\n\nStep 8: Wait for confirmation [#confirmation]\nPlease wait for confirmation or further instructions from your support contact\nat Supabase before proceeding to the next step. It usually takes us 1 business\nday to configure SSO for you.\nStep 9: Test single sign-on [#testing]\nTesting sign-on before your Azure AD has been registered with Supabase will\nnot work. Make sure you've received confirmation from your support contact at\nSupabase as laid out in the confirmation step.\nOnce you\u2019ve received confirmation from your support contact at Supabase that\nSSO setup has been completed for your enterprise, you can ask some of your\nusers to sign in via their Azure AD account.\nYou ask them to enter their email address on the Sign in with\nSSO page.\nIf sign in is not working correctly, please reach out to your support contact\nat Supabase for further guidance.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Choose Create App Integration in the Applications dashboard [#create-app-integration]",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/platform/sso/okta.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Set Up SSO with Okta',\n  description: 'Configure single sign-on with Okta.',\n}\nSupabase supports single sign-on (SSO) using Okta.\nStep 1: Choose Create App Integration in the Applications dashboard [#create-app-integration]\nNavigate to the Applications dashboard of the Okta admin console. Choose the\nCreate App Integration button from the toolbar.\n\nStep 2: Choose SAML 2.0 in the app integration dialog [#create-saml-app]\nSupabase supports the SAML 2.0 SSO protocol. Choose it from the Create a new\napp integration dialog.\n\nStep 3: Fill out General Settings [#add-general-settings]\nThe information you enter here is for visibility into your Okta applications\nmenu. You can choose any values you like. `Supabase` as a name works well for\nmost use cases.\n\nStep 4: Fill out SAML Settings [#add-saml-settings]\nThese settings let Supabase use SAML 2.0 properly with your Okta application.\nMake sure you enter this information exactly as shown on in this table and\nscreenshot.\n| Setting                                        | Value                                                |\n| ---------------------------------------------- | ---------------------------------------------------- |\n| Single sign-on URL                             | `https://app.supabase.com/auth/v1/sso/saml/acs`      |\n| Use this for Recipient URL and Destination URL | \u2714\ufe0f                                                   |\n| Audience URI (SP Entity ID)                    | `https://app.supabase.com/auth/v1/sso/saml/metadata` |\n| Default RelayState                             | `https://app.supabase.com`                           |\n| Name ID format                                 | EmailAddress                                         |\n| Application username                           | Email                                                |\n| Update application username on                 | Create and update                                    |\n\nStep 5: Fill out Attribute Statements [#add-attribute-statements]\nAttribute Statements allow Supabase to get information about your Okta users on each login.\nA `email` to `user.email` statement is required to exist. Other mappings\nshown below are optional and configurable depending on your Okta\nsetup. If in doubt, replicate the same config as shown.\nPlease share any changes, if any, from this screen with your Supabase support\ncontact.\n\nStep 6: Obtain IdP metadata URL [#idp-metadata-url]\nSupabase needs to finalize enabling single sign-on with your Okta\napplication.\nTo do this scroll down to the SAML Signing Certificates section on the Sign\nOn tab of the Supabase application. Pick the the SHA-2 row with an\nActive status. Click on the Actions dropdown button and then on the View\nIdP Metadata.\nThis will open up the SAML 2.0 Metadata XML file in a new tab in your browser.\nCopy this URL and send it to your support contact and await further\ninstructions. If you're not clear who to send this link to or need further\nassistance, please reach out to\nsupport@supabase.com.\nThe link usually has this structure: `https://<okta-org>.okta.com/apps/<app-id>/sso/saml/metadata`\n\nStep 7: Wait for confirmation [#confirmation]\nOnce you\u2019ve configured the Okta app as shown above, make sure you send the\nmetadata URL and information regarding the\nattribute statements (if any changes are applicable) to\nyour support contact at Supabase.\nWait for confirmation that this information has successfully been added to\nSupabase. It usually takes us 1 business day to configure this information\nfor you.\nStep 8: Test single sign-on [#testing]\nOnce you\u2019ve received confirmation from your support contact at Supabase that\nSSO setup has been completed for your enterprise, you can ask some of your\nusers to sign in via their Okta account.\nYou ask them to enter their email address on the Sign in with\nSSO page.\nIf sign in is not working correctly, please reach out to your support contact\nat Supabase for further guidance.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Assume the new file is: supabase/migrations/<t+2>_dev_A.sql",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/cli/managing-environments.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'managing-environments',\n  title: 'Managing Environments',\n  description: 'How to deploy Supabase schema changes with a CI / CD pipeline.',\n  video: 'https://www.youtube.com/v/rOLyOsBR1Uc',\n}\nOverview\nThe Supabase CLI provides the tools you need to manage multiple environments.\nThis guide shows you how to set up your local Supabase development environment that integrates with GitHub Actions to automatically\ntest and release schema changes to staging and production Supabase projects.\nTo get started:\n\nInstall the Supabase CLI\nCreate a Supabase project or use an existing one\nInitialize a local Git repository\n\n\n\n\nSet up a local environment\nThe first step is to set up your local repository with the Supabase CLI:\n`bash\nsupabase init`\nYou should see a new `supabase` directory. Then you need to link your local repository with your Supabase project:\n`bash\nsupabase login\nsupabase link --project-ref $PROJECT_ID`\nYou can get your `$PROJECT_ID` from your project's dashboard URL:\n`https://app.supabase.com/project/<project-id>`\nIf you're using an existing Supabase project, you might have made schema changes through the Dashboard.\nRun the following command to pull these changes before making local schema changes from the CLI:\n`sql\nsupabase db remote commit`\nThis command creates a new migration in `supabase/migrations/<timestamp>_remote_commit.sql` which reflects the schema changes you have made previously.\nNow commit your local changes to Git and run the local development setup:\n`bash\ngit add .\ngit commit -m \"init supabase\"\nsupabase start`\nYou are now ready to develop schema changes locally and create your first migration.\nCreate a new migration\nThere are two ways to make schema changes:\n\nManual migration: Write DDL statements manually into a migration file\nAuto schema diff: Make changes through Studio UI and auto generate a schema diff\n\nManual migration\nCreate a new migration script by running:\n`bash\nsupabase migration new new_employee`\nYou should see a new file created: `supabase/migrations/<timestamp>_new_employee.sql`. You can then write SQL statements in this script using a text editor:\n`sql\ncreate table public.employees (\n  id integer primary key generated always as identity,\n  name text\n);`\nApply the new migration to your local database:\n`bash\nsupabase db reset`\nThis command recreates your local database from scratch and applies all migration scripts under `supabase/migrations` directory. Now your local database is up to date.\n\nThe new migration command also supports stdin as input.\nThis allows you to pipe in an existing script from another file or stdout:\n`supabase migration new new_employee < create_employees_table.sql`\n\nAuto schema diff\nUnlike manual migrations, auto schema diff creates a new migration script from changes already applied to your local database.\nCreate an `employees` table under the `public` schema using Studio UI, accessible at localhost:54323 by default.\nNext, generate a schema diff by running the following command:\n`bash\nsupabase db diff -f new_employee`\nYou should see that a new file `supabase/migrations/<timestamp>_new_employee.sql` is created. Open the file and verify that the generated DDL statements are the same as below.\n```sql\n-- This script was generated by the Schema Diff utility in pgAdmin 4\n-- For the circular dependencies, the order in which Schema Diff writes the objects is not very sophisticated\n-- and may require manual changes to the script to ensure changes are applied in the correct order.\n-- Please report an issue for any failure with the reproduction steps.\nCREATE TABLE IF NOT EXISTS public.employees\n(\n    id integer NOT NULL GENERATED ALWAYS AS IDENTITY ( INCREMENT 1 START 1 MINVALUE 1 MAXVALUE 2147483647 CACHE 1 ),\n    name text COLLATE pg_catalog.\"default\",\n    CONSTRAINT employees_pkey PRIMARY KEY (id)\n)\nTABLESPACE pg_default;\nALTER TABLE IF EXISTS public.employees\n    OWNER to postgres;\nGRANT ALL ON TABLE public.employees TO anon;\nGRANT ALL ON TABLE public.employees TO authenticated;\nGRANT ALL ON TABLE public.employees TO postgres;\nGRANT ALL ON TABLE public.employees TO service_role;\n```\nYou may notice that the auto-generated migration script is more verbose than the manually written one.\nThis is because the default schema diff tool does not account for default privileges added by the initial schema.\nCommit the new migration script to git and you are ready to deploy.\n\nAlternatively, you may pass in the `--use-migra` experimental flag to generate a more concise migration using migra.\nWithout the `-f` file flag, the output is written to stdout by default.\n`supabase db diff --use-migra`\n\nDeploy a migration\nIn a production environment, we recommend using a CI/CD pipeline to deploy new migrations with GitHub Actions rather than deploying from your local machine.\n\nThis example uses two Supabase projects, one for production and one for staging.\nPrepare your environments by:\n\nCreating separate Supabase projects for staging and production\nPushing your git repository to GitHub and enabling GitHub Actions\n\n\nYou need a new project for staging. A project which has already been modified to reflect the production project's schema can't be used because the CLI would reapply these changes.\n\nConfigure GitHub Actions\nThe Supabase CLI requires a few environment variables to run in non-interactive mode.\n\n`SUPABASE_ACCESS_TOKEN` is your personal access token\n`SUPABASE_DB_PASSWORD` is your project specific database password\n\nWe recommend adding these as encrypted secrets to your GitHub Actions runners.\nCreate the following files inside the `.github/workflows` directory:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"ci\"\n\n\n\n```yaml title=.github/workflows/ci.yml\nname: CI\non:\n  pull_request:\n  workflow_dispatch:\njobs:\n  test:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n\n\n```  - uses: supabase/setup-cli@v1\n\n  - name: Start Supabase local development setup\n    run: supabase start\n\n  - name: Verify generated types are up-to-date\n    run: |\n      supabase gen types typescript --local > types.ts\n      if [ \"$(git diff --ignore-space-at-eol types.ts | wc -l)\" -gt \"0\" ]; then\n        echo \"Detected uncommitted changes after build. See status below:\"\n        git diff\n        exit 1\n      fi\n```\n\n\n```\n\n\n```yaml title=.github/workflows/staging.yml\nname: Deploy Migrations to Staging\non:\n  push:\n    branches:\n      - develop\n  workflow_dispatch:\njobs:\n  deploy:\n    runs-on: ubuntu-22.04\n\n\n```env:\n  SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}\n  SUPABASE_DB_PASSWORD: ${{ secrets.STAGING_DB_PASSWORD }}\n  STAGING_PROJECT_ID: abcdefghijklmnopqrst\n\nsteps:\n  - uses: actions/checkout@v3\n\n  - uses: supabase/setup-cli@v1\n\n  - run: |\n      supabase link --project-ref $STAGING_PROJECT_ID\n      supabase db push\n```\n\n\n```\n\n\n```yaml title=.github/workflows/production.yml\nname: Deploy Migrations to Production\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\njobs:\n  deploy:\n    runs-on: ubuntu-22.04\n\n\n```env:\n  SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}\n  SUPABASE_DB_PASSWORD: ${{ secrets.PRODUCTION_DB_PASSWORD }}\n  PRODUCTION_PROJECT_ID: abcdefghijklmnopqrst\n\nsteps:\n  - uses: actions/checkout@v3\n\n  - uses: supabase/setup-cli@v1\n\n  - run: |\n      supabase link --project-ref $PRODUCTION_PROJECT_ID\n      supabase db push\n```\n\n\n```\n\n\nThe full example code is available in the demo repository.\nCommit these files to git and push to your `main` branch on GitHub. Update these environment variables to match your Supabase projects:\n\n`SUPABASE_ACCESS_TOKEN`\n`PRODUCTION_PROJECT_ID`\n`PRODUCTION_DB_PASSWORD`\n`STAGING_PROJECT_ID`\n`STAGING_DB_PASSWORD`\n\nWhen configured correctly, your repository will have CI and Release workflows that trigger on new commits pushed to `main` and `develop` branches.\n\nOpen a PR with new migration\nFollow the migration steps to create a `supabase/migrations/<timestamp>_new_employee.sql` file.\nCheckout a new branch `feat/employee` from `develop` , commit the migration file, and push to GitHub.\n`bash\ngit checkout -b feat/employee\ngit add supabase/migrations/<timestamp>_new_employee.sql\ngit commit -m \"Add employee table\"\ngit push --set-upstream origin feat/employee`\nOpen a PR from `feat/employee` to the `develop` branch to see that the CI workflow has been triggered.\nOnce the test error is resolved, merge this PR and watch the deployment in action.\nRelease to production\nAfter verifying your staging project has successfully migrated, create another PR from `develop` to `main` and merge it to deploy the migration to the production project.\nThe `release` job applies all new migration scripts merged in `supabase/migrations` directory to a linked Supabase project. You can control which project the job links to via `PROJECT_ID` environment variable.\nTroubleshooting\nSync production project to staging\nWhen setting up a new staging project, you might need to sync the initial schema with migrations previously applied to the production project.\nOne way is to leverage the Release workflow:\n\nCreate a new branch `develop` and choose `main` as the branch source\nPush the `develop` branch to GitHub\n\nThe GitHub Actions runner will deploy your existing migrations to the staging project.\nAlternatively, you can also apply migrations through your local CLI to a linked remote database.\n`sql\nsupabase db push`\nOnce pushed, check that the migration version is up to date for both local and remote databases.\n`sql\nsupabase migration list`\nPermission denied on db remote commit\nIf you have been using Supabase hosted projects for a long time, you might encounter the following permission error when executing `db remote commit`.\n```bash\nError: Error running pg_dump on remote database: pg_dump: error: query failed: ERROR:  permission denied for table _type\npg_dump: error: query was: LOCK TABLE \"graphql\".\"_type\" IN ACCESS SHARE MODE\n```\nTo resolve this error, you need to grant `postgres` role permissions to `graphql` schema. You can do that by running the following query from Supabase dashboard's SQL Editor.\n`sql\ngrant all on all tables in schema graphql to postgres, anon, authenticated, service_role;\ngrant all on all functions in schema graphql to postgres, anon, authenticated, service_role;\ngrant all on all sequences in schema graphql to postgres, anon, authenticated, service_role;`\nPermission denied on db push\nIf you created a table through Supabase dashboard, and your new migration script contains `ALTER TABLE` statements, you might run into permission error when applying them on staging or production databases.\n`bash\nERROR: must be owner of table employees (SQLSTATE 42501); while executing migration <timestamp>`\nThis is because tables created through Supabase dashboard are owned by `supabase_admin` role while the migration scripts executed through CLI are under `postgres` role.\nOne way to solve this is to reassign the owner of those tables to `postgres` role. For example, if your table is named `users` in the public schema, you can run the following command to reassign owner.\n`sql\nALTER TABLE users OWNER TO postgres;`\nApart from tables, you also need to reassign owner of other entities using their respective commands, including types, functions, and schemas.\nRebasing new migrations\nSometimes your teammate may merge a new migration file to git main branch, and now you need to rebase your local schema changes on top.\nWe can handle this scenario gracefully by renaming your old migration file with a new timestamp.\n```bash\ngit pull\nsupabase migration new dev_A\nAssume the new file is: supabase/migrations/_dev_A.sql\nmv _dev_A.sql _dev_A.sql\nsupabase db reset\n```\nIn case reset fails, you can manually resolve conflicts by editing `<t+2>_dev_A.sql` file.\nOnce validated locally, commit your changes to Git and push to GitHub.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "create your project folder",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/cli/local-development.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'local-development',\n  title: 'Local Development',\n  description: 'How to use Supabase on your local development machine.',\n  video: 'https://www.youtube.com/v/vyHyYpvjaks',\n}\nLearn how to use the Supabase CLI to develop your project locally and deploy to the Supabase Platform.\n\n\n\nPrerequisites\nMake sure you have these installed on your local machine:\n\nDocker\nGit\nSupabase CLI\n\nLog in to the Supabase CLI\n`bash\nsupabase login`\n\nIf you installed the Supabase CLI via NPM you may have to use `npx supabase login`.\n\nInitialize your project\nCreate a new folder for your project and start a new git repository:\n```bash\ncreate your project folder\nmkdir your-project\nmove into the new folder\ncd your-project\nstart a new git repository\ngit init\n```\nStart Supabase services\nInitialize Supabase to set up the configuration for developing your project locally:\n`bash\nsupabase init`\nMake sure Docker is running. The start command uses Docker to start the Supabase services.\nThis command may take a while to run if this is the first time using the CLI.\n`bash\nsupabase start`\nOnce all of the Supabase services are running, you'll see output containing your local Supabase credentials.\nYou can use the stop command at any time to stop all services.\nAccess services\nYou can access services directly with any Postgres client or through the API Gateway (Kong).\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"postgres\"\n\n\n\n```sh\nDefault URL:\npostgresql://postgres:postgres@localhost:54322/postgres\n```\nThe local Postgres instance can be accessed through psql\nor any other Postgres client, such as pgadmin.\nFor example:\n`bash\npsql 'postgresql://postgres:postgres@localhost:54322/postgres'`\n\nTo access the database from an edge function in your local Supabase setup, replace `localhost` with `host.docker.internal`.\n\n\n\n```sh\nDefault URL:\nhttp://localhost:54321\n```\nIf you are accessing these services without the client libraries, you may need to pass the client keys as an `Authorization` header.\nLearn more about JWT headers.\n```sh\ncurl 'http://localhost:54321/rest/v1/' \\\n    -H \"apikey: \" \\\n    -H \"Authorization: Bearer \"\nhttp://localhost:54321/rest/v1/           # REST (PostgREST)\nhttp://localhost:54321/realtime/v1/       # Realtime\nhttp://localhost:54321/storage/v1/        # Storage\nhttp://localhost:54321/auth/v1/           # Auth (GoTrue)\n```\n\n`<anon key>` is provided when you run the command `supabase start`.\n\n\n\nDatabase migrations\nDatabase changes are managed through \"migrations.\" Database migrations are a common way of tracking changes to your database over time.\n\n\n\nMake database changes\nFor this guide, create a table called `employees`. In Supabase Studio, navigate to the SQL Editor page and run the following SQL command:\n`sql\ncreate table\n  employees (\n    id integer primary key generated always as identity,\n    name text\n  );`\n\nYou can execute any SQL using the `DB URL` shown by supabase status.\n\nRun the db diff command to detect changes in the local database:\n`sh\nsupabase db diff create_employees -f create_employees`\nThis creates a new migration named `supabase/migrations/<timestamp>_create_employees.sql`, representing any changes made to the local database since supabase start.\nAdd sample data\nUse the seed script in `supabase/seed.sql` (created with supabase init) to add sample data to the table.\n`sql\n -- in supabase/seed.sql\ninsert into\n  public.employees (name)\nvalues\n  ('Erlich Bachman'),\n  ('Richard Hendricks'),\n  ('Monica Hall');`\nRerun the migration and seed scripts:\n`bash\nsupabase db reset`\nYou should now see the contents of `employees` in Studio.\nReset database changes\nUse the reset command to revert any changes to the local database.\n`sql\n -- run on local database to make a change\nalter table\n  employees add department text default 'Hooli';`\nRun the following command to reset the local database:\n`sh\nsupabase db reset`\nDeploy your project\nGo to the Supabase Dashboard and create a project to deploy the changes.\nLink your project\n\nThere are a few commands required to link your project. We are in the process of consolidating these commands into a single command. Bear with us!\n\nAssociate your project with your remote project using supabase link.\n```bash\nsupabase link --project-ref \nYou can get  from your project\u2019s dashboard URL: https://app.supabase.com/project/\nsupabase db remote commit\nCapture any changes that you have made to your database before setting up the CLI\n```\n`supabase/migrations` is now populated with a migration in `..._remote_commit.sql`.\nThis migration captures any changes required for your local database to match the schema of your remote Supabase project.\nDeploy database changes\nDeploy any local database migrations using db push:\n`sh\nsupabase db push`\nDeploy Edge Functions\nDeploy any Edge Functions using functions deploy:\n`sh\nsupabase functions deploy <function_name>`\nLimitations\nThe local development environment is not as feature-complete as the Supabase Platform. Here are some of the differences:\n\nThe Functions interface is coming soon.\nLogs are not supported through the interface (however you can access them through the Docker containers).\nYou cannot update your project settings in the Dashboard\u2014this must be done using the CLI.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Get a public URL for a transformed image",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/storage/image-transformations.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'storage-image-transformations',\n  title: 'Storage Image Transformations',\n  description: 'Transform images with Storage',\n  sidebar_label: 'Image Transformations',\n  video: 'https://www.youtube.com/v/dLqSmxX3r7I',\n}\nSupabase Storage offers the functionality to transform and resize images dynamically. Any image stored in your buckets can be transformed and optimized for fast delivery.\n\n  Image Resizing is currently in beta and enabled for Pro tier and\n  above.\n\n\n\n\nGet a public URL for a transformed image\nYou can pass a `transform` option to the functions you are currently using to interact with your objects. This returns the public URL that serves the resized image.\n`ts\nsupabase.storage.from('bucket').getPublicUrl('image.jpg', {\n  transform: {\n    width: 500,\n    height: 600,\n  },\n})`\nAn example URL could look like this:\n`https://project_id.supabase.co/storage/v1/render/image/public/bucket/image.jpg?width=500&height=600`\nSigning URLs with transformation options\nTo share a transformed image for a fixed amount of time, provide the transform options when you create the signed URL:\n`ts\nsupabase.storage.from('bucket').createSignedUrl('image.jpg', 60000, {\n  transform: {\n    width: 200,\n    height: 200,\n  },\n})`\nThe transformation options are embedded into the token\u2014they cannot be changed once signed.\nDownloading images\nTo download a transformed image, pass the `transform` option to the `download` function.\n`ts\nsupabase.storage.from('bucket').download('image.jpg', {\n  transform: {\n    width: 800,\n    height: 300,\n  },\n})`\nAutomatic Image Optimisation (WebP)\nWhen using the image transformation API we will automatically find the best format supported by the browser and return that to the client, without any code change.\nFor instance, if you use Chrome when viewing a jpeg image and using transformation options, you'll see that the content-type returned is `webp`.\nAs a result, this will lower the bandwidth that you send to your users and your application will load much faster.\n\n    We currently only support WebP. AVIF support will come in the near future\n\nDisabling automatic optimisation:\nIn case you'd like to return the original format of the image and opt-out from the automatic image optimization detection, you can pass the `format=origin` parameter when requesting a transformed image,\nthis is also supported in the JavaScript SDK starting from v2.2.0\n`ts\nawait storage.from('bucket').download('image.jpeg', {\n      transform: {\n        width: 200,\n        height: 200,\n        format: 'origin',\n      },\n})`\nNextJS Loader\nYou can use Supabase Image Transformation to optimise your NextJS images using a custom Loader.\nTo get started, create a `supabase-image-loader.js` file in your NextJS project which exports a default function:\n```ts\nconst projectId = '' // your supabase project id\nexport default function supabaseLoader({ src, width, quality }) {\n  return `https://${projectId}.supabase.co/storage/v1/render/image/public/${src}?width=${width}&quality=${quality || 75}`\n}\n```\nIn your `nextjs.config.js` file add the following configuration to instruct NextJS to use our custom loader\n`js\nmodule.exports = {\n  images: {\n    loader: 'custom',\n    loaderFile: './supabase-image-loader.js',\n  },\n}`\nAt this point you are ready to use the `Image` component provided by NextJS\n```tsx\nimport Image from 'next/image'\nconst MyImage = (props) => {\n  return \n}\n```\nTransformation options\nWe currently support a few transformation options focusing on resizing and cropping images.\nResizing\nYou can use `width` and `height` parameters to resize an image to a specific dimension. If only one parameter is specified, the image will be resized and cropped, maintaining the aspect ratio.\nModes\nYou can use different resizing modes to fit your needs, each of them uses a different approach to resize the image:\nUse the `resize` parameter with one of the following values:\n\n\n`cover` : resizes the image while keeping the aspect ratio to fill a given size and crops projecting parts. (default)\n\n\n`contain` : resizes the image while keeping the aspect ratio to fit a given size.\n\n\n`fill` : resizes the image without keeping the aspect ratio.\n\n\nExample:\n`ts\nsupabase.storage.from('bucket').download('image.jpg', {\n  transform: {\n    width: 800,\n    height: 300,\n    resize: 'contain', // 'cover' | 'fill'\n  },\n})`\nLimits\n\nWidth and height must be an integer value between 1-2500.\nThe image size cannot exceed 25MB.\nThe image resolution cannot exceed 50MP.\n\nSupported Image Formats\n| Format | Extension | Source | Result |\n| ------ | --------- | ------ | ------ |\n| PNG    | `png`     | \u2611\ufe0f     | \u2611\ufe0f     |\n| JPEG   | `jpg`     | \u2611\ufe0f     | \u2611\ufe0f     |\n| WebP   | `webp`    | \u2611\ufe0f     | \u2611\ufe0f     |\n| AVIF   | `avif`    | \u2611\ufe0f     | \u2611\ufe0f     |\n| GIF    | `gif`     | \u2611\ufe0f     | \u2611\ufe0f     |\n| ICO    | `ico`     | \u2611\ufe0f     | \u2611\ufe0f     |\n| SVG    | `svg`     | \u2611\ufe0f     | \u2611\ufe0f     |\n| HEIC   | `heic`    | \u2611\ufe0f     | \u274c     |\n| BMP    | `bmp`     | \u2611\ufe0f     | \u2611\ufe0f     |\n| TIFF   | `tiff`    | \u2611\ufe0f     | \u2611\ufe0f     |\nSelf Hosting\nOur solution to image resizing and optimisation can be self-hosted as with any other Supabase product.\nUnder the hood we use the awesome Imgproxy\nImgproxy Configuration:\nSimply deploy an imgproxy container with the following configuration:\n`yaml\n  imgproxy:\n    image: darthsim/imgproxy\n    environment:\n      - IMGPROXY_ENABLE_WEBP_DETECTION=true\n      - IMGPROXY_JPEG_PROGRESSIVE=true`\nNote: make sure that this service can only be reachable within an internal network and not exposed to the public internet\nStorage API Configuration:\nOnce Imgproxy is deployed we need to configure a couple of environment variables in your self-hosted storage-api service as follows:\n`shell\nENABLE_IMAGE_TRANSFORMATION=true\nIMGPROXY_URL=yourinternalimgproxyurl.internal.com`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Basic CDN",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/storage/cdn.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'storage-cdn',\n  title: 'Storage CDN',\n  description: 'Learn how Supabase Storage caches objects with a CDN.',\n  sidebar_label: 'CDN',\n}\nAll assets uploaded to Supabase Storage are cached on a Content Delivery Network (CDN) to improve the latency for users all around the world. CDNs are a geographically distributed set of servers or nodes which caches content from an origin server. For Supabase Storage, the origin is the storage server running in the same region as your project. Aside from performance, CDNs also help with security and availability by mitigating Distributed Denial of Service and other application attacks.\nBasic CDN\nOur basic CDN caches objects based on the cache time set when uploading objects.\nExample\nLet\u2019s walk through an example of how a CDN helps with performance.\nA new bucket is created for a Supabase project launched in Singapore. All requests to the Supabase Storage API are routed to the CDN first.\nA user from the United States requests an object and is routed to the U.S. CDN. At this point, that CDN node does not have the object in its cache and pings the origin server in Singapore.\n\nAnother user, also in the United States, requests the same object and is served directly from the CDN cache in the United States instead of routing the request back to Singapore.\n\nCache duration\nBy default, assets are cached both in the CDN and in the user's browser for 1 hour. After this, the CDN nodes ping the storage server to see if an object has been updated. You can modify this cache time when you are uploading or updating an object by modifying the `cacheControl` parameter.\nIf you expect the object to not change at a given URL, setting a longer cache duration is preferable.\nIf you need to update the version of the object stored in the CDN, there are various cache-busting techniques you can use. The most common way to do this is to add a version query parameter in the URL.\nFor example, you can use a URL like `/storage/v1/object/sign/profile-pictures/cat.jpg?token=eyJh...&version=1` in your applications and set a long cache time of 1 year.\nWhen you want to update the cat picture, you can increment the version query parameter in the URL. The CDN treats `/storage/v1/object/sign/profile-pictures/cat.jpg?token=eyJh...&version=2` as a new object and pings the origin for the updated version.\nIf your asset is updated frequently, we recommend that you re-upload the new asset in a different key, this way you'll always have the latest changes available immediately.\nNote that CDNs might still evict your object from their cache if it has not been requested for a while from a specific region. For example, if no user from United States requests your object, it will be removed from the CDN cache even if you set a very long cache control duration.\nThe cache status of a particular request is sent in the `cf-cache-status` header. A cache status of `MISS` indicates that the CDN node did not have the object in its cache and had to ping the origin to get it. A cache status of `HIT` indicates that the object was sent directly from the CDN.\nSmart CDN Caching\n\n  Smart CDN caching is automatically enabled for Pro tiers and\n  above.\n\nWith Smart CDN caching enabled, the asset metadata in your database is synchronized to the edge. This automatically revalidates the cache when the asset is changed or deleted.\nAdditionally, the smart CDN has a higher cache hit ratio as the origin server is shielded from asset requests that haven't changed when using different query strings in the URL.\nCache duration\nWhen Smart CDN is enabled, the asset is cached on the CDN for as long as possible. You can still control how long assets are stored in the browser using the cacheControl option when uploading a file. Smart CDN caching works with all types of storage operations including signed URLs.\nWhen a file is updated or deleted, the CDN cache is automatically invalidated to reflect the change (including transformed images).\nIt can take up to 60 seconds for the CDN cache to be invalidated as the asset metadata has to propagate across all the data-centers around the globe.\nWhen an asset is invalidated at the CDN level, browsers may not update its cache.\nIf your asset is updated frequently, we recommend that you re-upload the new asset in a different key, this way you'll always have the latest changes available without waiting the propagation delay.\nIf you expect your asset to be deleted, we recommend setting a low browser TTL value using the `cacheControl` option when using smart CDN caching, the default is 1 hour which generally is a good default.\nPublic vs Private Buckets\nObjects in public buckets do not require any Authorization to access objects. This leads to a better cache hit rate compared to private buckets. For private buckets, permissions for accessing each object is checked on a per user level. For example, if two different users access the same object in a private bucket from the same region, it results in a cache miss for both the users since they might have different security policies attached to them. On the other hand, if two different users access the same object in a public bucket from the same region, it results in a cache hit for the second user.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Public and private buckets",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/storage/access-control.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'storage-access-control',\n  title: 'Access Control',\n  description: 'Manage who can access your Supabase Storage files.',\n  video: 'https://www.youtube.com/v/4ERX__Y908k',\n}\nSupabase Storage is integrated with your Postgres Database.\nThis means that you can use the same Row Level Security Policies\nfor managing access to your files. Supabase Storage stores metadata in the `objects` and `buckets` table in the storage schema.\nTo allow read access to files, the RLS policy must allow users to `SELECT` the `objects` table and for uploading a new object, the RLS policy must grant users access to `INSERT` into the `objects` table and so on. The mapping between the different API calls and the database permissions required is documented in the Reference docs.\n\nAccess control for Storage is mapped to CRUD operations on the `buckets` and `objects` table via RLS policies.\n\n\n\n\nPublic and private buckets\nStorage buckets are private by default. For private buckets, you can access objects via the download method. This corresponds to `/object/auth/` API endpoint.\nAlternatively, you can create a publicly shareable URL with an expiry date using the createSignedUrl method\nwhich calls the `/object/sign/` API.\nFor public buckets, you can access the assets directly without a token or an Authorisation header. The getPublicUrl\nhelper method returns the full public URL for an asset. This calls the `/object/public/` API endpoint internally. While no authorization is required for accessing objects in a public bucket, proper access control is required for other operations like uploading, deleting objects from public buckets as well. Public buckets also tend to have better performance.\n\nAdvanced: reverse proxy\nThe URLs returned are proxied through the API Proxy. They are prefixed by `/storage/v1`.\n\nFor example, on the hosted Platform they will be\n\n`https://[project_ref].supabase.co/storage/v1/object/public/[id]`\n\nYou can access the storage API directly with the same endpoint. See the API docs for a full list of operations available.\n\n\nHelper functions\nSupabase Storage provides SQL helper functions which you can use in your database queries and\npolicies.\n\n`storage.filename()`\nReturns the name of a file.\n`sql\nselect storage.filename(name)\nfrom storage.objects;`\nFor example, if your file is stored in `public/subfolder/avatar.png` it would return:\n`'avatar.png'`\n\n`storage.foldername()`\nReturns an array path, with all of the subfolders that a file belongs to.\n`sql\nselect storage.foldername(name)\nfrom storage.objects;`\nFor example, if your file is stored in `public/subfolder/avatar.png` it would return:\n`[ 'public', 'subfolder' ]`\n\n`storage.extension()`\nReturns the extension of a file.\n`sql\nselect storage.extension(name)\nfrom storage.objects;`\nFor example, if your file is stored in `public/subfolder/avatar.png` it would return:\n`'png'`\n\nPolicy examples\nAllow public access to a bucket\n`sql\n-- 1. Allow public access to any files in the \"public\" bucket\ncreate policy \"Public Access\"\non storage.objects for select\nusing ( bucket_id = 'public' );`\nAllow logged-in access to a bucket\n`sql\n-- 1. Allow logged-in access to any files in the \"restricted\" bucket\ncreate policy \"Restricted Access\"\non storage.objects for select\nto authenticated\nusing ( bucket_id = 'restricted' );`\nAllow individual access to a file\n`sql\n-- 1. Allow a user to access their own files\ncreate policy \"Individual user Access\"\non storage.objects for select\nusing ( auth.uid() = owner );`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Create a bucket",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/storage/quickstart.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'storage-quickstart',\n  title: 'Storage Quickstart',\n  description: 'Learn how to use Supabase to store and serve files.',\n  sidebar_label: 'Quickstart',\n}\nThis guide shows the basic functionality of Supabase Storage. Find a full example application on GitHub or deploy it with Vercel for a preview:\n\n\nFile, Folder, and Bucket names must follow AWS object key naming guidelines and avoid use of any other characters.\n\nCreate a bucket\nYou can create a bucket using the Supabase Dashboard.\nSince the storage is interoperable with your Postgres database, you can also use SQL or our\nclient libraries. Here we create a bucket called \"avatars\":\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Storage page in the Dashboard.\nClick New Bucket and enter a name for the bucket.\nClick Create Bucket.\n\n\n\n```sql\n-- Use Postgres to create a bucket.\ninsert into storage.buckets (id, name)\nvalues ('avatars', 'avatars');\n```\n\n\n```js\n// Use the JS library to create a bucket.\nconst { data, error } = await supabase.storage.createBucket('avatars')\n```\nReference.\n\n\n```dart\nvoid main() async {\n  final supabase = SupabaseClient('supabaseUrl', 'supabaseKey');\nfinal storageResponse = await supabase\n      .storage\n      .createBucket('avatars');\n}\n```\nReference.\n\n\nUpload a file\nYou can upload a file from the Dashboard, or within a browser using our JS libraries.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Storage page in the Dashboard.\nSelect the bucket you want to upload the file to.\nClick Upload File.\nSelect the file you want to upload.\n\n\n\n`js\nconst avatarFile = event.target.files[0]\nconst { data, error } = await supabase.storage\n  .from('avatars')\n  .upload('public/avatar1.png', avatarFile)`\nReference.\n\n\n```dart\nvoid main() async {\n  final supabase = SupabaseClient('supabaseUrl', 'supabaseKey');\n// Create file `example.txt` and upload it in `public` bucket\n  final file = File('example.txt');\n  file.writeAsStringSync('File content');\n  final storageResponse = await supabase\n      .storage\n      .from('public')\n      .upload('example.txt', file);\n}\n```\nReference.\n\n\nDownload a file\nYou can download a file from the Dashboard, or within a browser using our JS libraries.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Storage page in the Dashboard.\nSelect the bucket that contains the file.\nSelect the file that you want to download.\nClick Download.\n\n\n\n```js\n// Use the JS library to download a file.\nconst { data, error } = await supabase.storage.from('avatars').download('public/avatar1.png')\n```\nReference.\n\n\n```dart\nvoid main() async {\n  final supabase = SupabaseClient('supabaseUrl', 'supabaseKey');\nfinal storageResponse = await supabase\n      .storage\n      .from('public')\n      .download('example.txt');\n}\n```\nReference.\n\n\nAdd security rules\nTo restrict access to your files you can use either the Dashboard or SQL.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"dashboard\"\n\n\n\n\nGo to the Storage page in the Dashboard.\nClick Policies in the sidebar.\nClick Add Policies in the `OBJECTS` table to add policies for Files. You can also create policies for Buckets.\nChoose whether you want the policy to apply to downloads (SELECT), uploads (INSERT), updates (UPDATE), or deletes (DELETE).\nGive your policy a unique name.\nWrite the policy using SQL.\n\n\n\n```sql\n-- Use SQL to create a policy.\ncreate policy \"Public Access\"\n  on storage.objects for select\n  using ( bucket_id = 'public' );\n```\n\n\nSee also\n\nSupabase Storage on GitHub\nSwagger API documentation\nOfficial JavaScript and Dart documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Replication Setup",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/realtime/postgres-changes.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'postgres-changes',\n  title: 'Postgres Changes',\n  description: \"Getting started with Realtime's Postgres Changes feature\",\n}\nRealtime's Postgres Changes feature listens for database changes and sends them to clients. Clients are required to subscribe with a JWT dictating which changes they are allowed to receive based on the database's Row Level Security.\nAnyone with access to a valid JWT signed with the project's JWT secret is able to listen to your database's changes, unless tables have Row Level Security enabled and policies in place.\nClients can choose to receive `INSERT`, `UPDATE`, `DELETE`, or `*` (all) changes for all changes in a schema, a table in a schema, or a column's value in a table. Your clients should only listen to tables in the `public` schema and you must first enable the tables you want your clients to listen to.\nPostgres Changes works out of the box for tables in the `public` schema. You can listen to tables in your private schemas by granting table `SELECT` permissions to the database role found in your access token. You can run a query similar to the following:\n`sql\nGRANT SELECT ON \"private_schema\".\"table\" TO authenticated;`\n\n  We strongly encourage you to enable RLS and create policies for tables in private schemas.\n  Otherwise, any role you grant access to will have unfettered read access to the table.\n\nReplication Setup\nYou can do this in the Replication section in the Dashboard or with the SQL editor:\n```sql\nbegin;\n  -- remove the supabase_realtime publication\n  drop publication if exists supabase_realtime;\n-- re-create the supabase_realtime publication with no tables\n  create publication supabase_realtime;\ncommit;\n-- add a table to the publication\nalter publication supabase_realtime add table messages;\n```\nFull `old` Record\nBy default, only `new` record changes are sent but if you want to receive the `old` record (previous values) whenever you `UPDATE` or `DELETE` a record,\nyou can set the `replica identity` of your table to `full`:\n`sql\nalter table messages replica identity full;`\nSchema Changes\nTo listen to all changes in the `public` schema:\n```js\nconst { createClient } = require('@supabase/supabase-js')\nconst supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY)\n/\n  Channel name can be any string.\n  Event name can can be one of:\n    - INSERT\n    - UPDATE\n    - DELETE\n    - *\n/\nconst channel = supabase\n  .channel('schema-db-changes')\n  .on(\n    'postgres_changes',\n    {\n      event: '*',\n      schema: 'public',\n    },\n    (payload) => console.log(payload)\n  )\n  .subscribe()\n```\nTable Changes\nTo listen to changes on a table in the `public` schema:\n```js\n// Supabase client setup\nconst channel = supabase\n  .channel('table-db-changes')\n  .on(\n    'postgres_changes',\n    {\n      event: 'INSERT',\n      schema: 'public',\n      table: 'messages',\n    },\n    (payload) => console.log(payload)\n  )\n  .subscribe()\n```\nFilter Changes\nTo listen to changes when a column's value in a table matches a client-specified value:\n```js\n// Supabase client setup\nconst channel = supabase\n  .channel('value-db-changes')\n  .on(\n    'postgres_changes',\n    {\n      event: 'UPDATE',\n      schema: 'public',\n      table: 'messages',\n      filter: 'body=eq.hey',\n    },\n    (payload) => console.log(payload)\n  )\n  .subscribe()\n```\nCombination Changes\nTo listen to different events and schema/tables/filters combinations with the same channel:\n```js\n// Supabase client setup\nconst channel = supabase\n  .channel('db-changes')\n  .on(\n    'postgres_changes',\n    {\n      event: '*',\n      schema: 'public',\n      table: 'messages',\n      filter: 'body=eq.bye',\n    },\n    (payload) => console.log(payload)\n  )\n  .on(\n    'postgres_changes',\n    {\n      event: 'INSERT',\n      schema: 'public',\n      table: 'users',\n    },\n    (payload) => console.log(payload)\n  )\n  .subscribe()\n```\nCustom Tokens\nYou may choose to sign your own tokens to customize claims that can be checked in your RLS policies.\nIn order for this to work you must pass `apikey` in both Realtime's `headers` and `params` when creating the client.\nThe `apikey` in `headers` must be either the `anon` or `service_role` token that Supabase signed.\nThis will authenticate your request in the API gateway.\n\n  Do not expose the `service_role` token on the client because the role is authorized to bypass\n  row-level security.\n\nThe `apikey` in `params` can be your custom token signed with the JWT secret of your Supabase project.\nThis is forwarded to the Realtime server and it will verify your custom token and use its claims to authorize database changes\nwhen RLS is enabled.\n```js\nconst { createClient } = require('@supabase/supabase-js')\nconst supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY, {\n  realtime: {\n    headers: {\n      apikey: 'supabase-signed-token',\n    },\n    params: {\n      apikey: 'your-custom-token',\n    },\n  },\n})\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Limits by Plan",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/realtime/rate-limits.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'rate-limits',\n  title: 'Realtime Rate Limits',\n  description: 'Understanding Realtime rate limiting',\n  sidebar_label: 'Rate Limits',\n}\nSupabase Realtime is a global cluster. We've implemented some rate limits to help ensure high availability for all customers.\nRate limits are configurable per project and our cluster supports millions of concurrent connections. Contact support if these limits are causing issues.\nLimits by Plan\nLimits are set on the Free and Pro plans accordingly. See our pricing page for more information.\nEnterprise plans are billed on a usage basis. We still employ limiting on Enterprise plans. If you're on an Enterprise plan simply contact support and we'll increase your limits as needed.\nEnterprise plan limits start at:\n\n500 concurrent clients\n1,000 messages per second\n500 concurrent Channels\n\nSystem Limits\nThe following limits apply to all projects:\n\n500 Channel joins per second\n100 Channels per connected client\n\nClient-Side Limiting\nSome basic WebSocket message rate limiting is implemented client-side.\nFor example, the multiplayer.dev demo instantiates the Supabase client with an `eventsPerSecond` parameter.\nRate Limiting Errors\nRate limiting errors can appear in backend logs and messages in the WebSocket connection.\n\nUse the Realtime Inspector to reproduce an error and share those connection details with Supabase support.\n\nBackend Logs\nIf your project is being rate limited, check your Realtime logs.\nWebSocket Errors\n\n`tenant_events`: Clients will be disconnected if your project is generating too many messages per second. `supabase-js` should reconnect automatically when the message rate decreases below your plan limit.\n\nSome limits can cause a Channel join to be refused. Realtime will reply with one of the following WebSocket messages:\n\n`too_many_channels`: Too many channels currently joined for a single client.\n`too_many_connections`: Too many total concurrent connections for a project.\n`too_many_joins`: Too many Channel joins per second.\n\n\nUse your browser's developer tools to find the WebSocket initiation request and view individual messages.\n\nPayload Limits\nRealtime has a message byte size limit of 1 megabyte.\nPresence Limits\nRealtime Presence is a CRDT backed in-memory key value store based on Phoenix Presence. It's more expensive to update a Presence than Broadcast a message.\nThe following limits apply to Presence messages:\n\n10 keys per object\nMessage rate limit is 10% of your Realtime message rate limit\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Listen to Messages",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/realtime/broadcast.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'broadcast',\n  title: 'Broadcast',\n  description: \"Getting started with Realtime's Broadcast feature\",\n}\nBroadcast follows the publish-subscribe pattern where a client publishes messages to a channel with a unique identifier. For example, a user could send a message to a channel with id `room-1`.\nOther clients can elect to receive the message in real-time by subscribing to the channel with id `room-1`. If these clients are online and subscribed then they will receive the message.\nBroadcast works by connecting your client to the nearest Realtime server, which will communicate with other servers to relay messages to other clients.\nA common use-case is sharing a user's cursor position with other clients in an online game.\nListen to Messages\nYou can get started with Broadcast by creating a client and listening to a channel's messages:\n```js\nconst { createClient } = require('@supabase/supabase-js')\nconst supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY)\nsupabase\n  .channel('test')\n  .on('broadcast', { event: 'supa' }, (payload) => console.log(payload))\n  .subscribe()\n```\nSend Messages\nYou can create another client and send messages to other clients:\n```js\nconst { createClient } = require('@supabase/supabase-js')\nconst supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY)\nsupabase.channel('test').subscribe((status) => {\n  if (status === 'SUBSCRIBED') {\n    channel.send({\n      type: 'broadcast',\n      event: 'supa',\n      payload: { org: 'supabase' },\n    })\n  }\n})\n```\nIn order for clients to successfully send and receive mesages to one another, they must both specify the same `event`.\nWe recommend that the client has successfully subscribed to the channel prior to sending messages.\nSelf-Send Messages\nYou can also choose for a client to receive messages that it sent:\n```js\n// Supabase client setup\nsupabase\n  .channel('test', {\n    config: {\n      broadcast: {\n        self: true,\n      },\n    },\n  })\n  .on('broadcast', { event: 'supa' }, (payload) => console.log(payload))\n  .subscribe((status) => {\n    if (status === 'SUBSCRIBED') {\n      channel.send({\n        type: 'broadcast',\n        event: 'supa',\n        payload: { org: 'supabase' },\n      })\n    }\n  })\n```\nAcknowledge Messages\nYou can ensure that Realtime's servers received your message by:\n```js\n// Supabase client setup\nconst channel = supabase.channel('receipt', {\n  config: {\n    broadcast: { ack: true },\n  },\n})\nchannel.subscribe(async (status) => {\n  if (status === 'SUBSCRIBED') {\n    const resp = await channel.send({\n      type: 'broadcast',\n      event: 'latency',\n      payload: {},\n    })\n    console.log(resp)\n  }\n})\n```\nIf `ack` is not set to `true`, Realtime servers will not acknowledge that it received the sent message and `send` promise resolves immediately.\nClient-Side Rate Limit\nThere is a default client-side rate limit that enables you to send 10 messages per second, or one message every 100 milliseconds. You can customize this when creating the client:\n```js\nconst { createClient } = require('@supabase/supabase-js')\nconst supabase = createClient(\n  process.env.SUPABASE_URL,\n  process.env.SUPABASE_KEY,\n  {\n    realtime: {\n      params: {\n        eventsPerSecond: 20\n      }\n    }\n  }\n```\nBy setting `eventsPerSecond` to 20, you can send one message every 50 milliseconds on a per client basis.\nLearn more by visiting the Rate Limits section.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Install `supabase-js` Client",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/realtime/quickstart.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'quickstart',\n  title: 'Realtime Quickstart',\n  description: \"Getting started with Realtime's Features\",\n  sidebar_label: 'Quickstart',\n  video: 'https://www.youtube.com/v/BelYEMJ2N00',\n}\nLearn how to build multiplayer.dev, a collaborative app that demonstrates Broadcast, Presence, and Postgres Changes using Realtime.\n\n\n\nInstall `supabase-js` Client\n`bash\nnpm install @supabase/supabase-js`\nCursor Positions\nBroadcast allows a client to send messages and multiple clients to receive the messages. The broadcasted messages are ephemeral. They are not persisted to the database and are directly relayed through the Realtime servers. This is ideal for sending information like cursor positions where minimal latency is important, but persisting them is not.\nIn multiplayer.dev, client's cursor positions are sent to other clients in the room. However, cursor positions will be randomly generated for this example.\nYou need to get the public `anon` access token from your project's API settings. Then you can set up the Supabase client and start sending a client's cursor positions to other clients in channel `room1`:\n```js\nconst { createClient } = require('@supabase/supabase-js')\nconst supabase = createClient('https://your-project-ref.supabase.co', 'anon-key', {\n  realtime: {\n    params: {\n      eventsPerSecond: 10,\n    },\n  },\n})\n// Channel name can be any string.\n// Create channels with the same name for both the broadcasting and receiving clients.\nconst channel = supabase.channel('room1')\n// Subscribe registers your client with the server\nchannel.subscribe((status) => {\n  if (status === 'SUBSCRIBED') {\n    // now you can start broadcasting cursor positions\n    setInterval(() => {\n      channel.send({\n        type: 'broadcast',\n        event: 'cursor-pos',\n        payload: { x: Math.random(), y: Math.random() },\n      })\n      console.log(status)\n    }, 100)\n  }\n})\n```\n\nJavaScript client has a default rate limit of 1 Realtime event every 100 milliseconds that's configured by `eventsPerSecond`.\n\nAnother client can subscribe to channel `room1` and receive cursor positions:\n```js\n// Supabase client setup\n// Listen to broadcast messages.\nsupabase\n  .channel('room1')\n  .on('broadcast', { event: 'cursor-pos' }, (payload) => console.log(payload))\n  .subscribe((status) => {\n    if (status === 'SUBSCRIBED') {\n      // your callback function will now be called with the messages broadcast by the other client\n    }\n  })\n```\n\n`type` must be `broadcast` and the `event` must match for clients subscribed to the channel.\n\nRoundtrip Latency\nYou can also configure the channel so that the server must return an acknowledgement that it received the `broadcast` message. This is useful if you want to measure the roundtrip latency:\n```js\n// Supabase client setup\nconst channel = supabase.channel('calc-latency', {\n  config: {\n    broadcast: { ack: true },\n  },\n})\nchannel.subscribe(async (status) => {\n  if (status === 'SUBSCRIBED') {\n    const begin = performance.now()\n\n\n```await channel.send({\n  type: 'broadcast',\n  event: 'latency',\n  payload: {},\n})\n\nconst end = performance.now()\n\nconsole.log(`Latency is ${end - begin} milliseconds`)\n```\n\n\n}\n})\n```\nTrack and Display Which Users Are Online\nPresence stores and synchronize shared state across clients. The `sync` event is triggered whenever the shared state changes. The `join` event is triggered when new clients join the channel and `leave` event is triggered when clients leave.\nEach client can use the channel's `track` method to store an object in shared state. Each client can only track one object, and if `track` is called again by the same client, then the new object overwrites the previously tracked object in the shared state. You can use one client to track and display users who are online:\n```js\n// Supabase client setup\nconst channel = supabase.channel('online-users', {\n  config: {\n    presence: {\n      key: 'user1',\n    },\n  },\n})\nchannel.on('presence', { event: 'sync' }, () => {\n  console.log('Online users: ', channel.presenceState())\n})\nchannel.on('presence', { event: 'join' }, ({ newPresences }) => {\n  console.log('New users have joined: ', newPresences)\n})\nchannel.on('presence', { event: 'leave' }, ({ leftPresences }) => {\n  console.log('Users have left: ', leftPresences)\n})\nchannel.subscribe(async (status) => {\n  if (status === 'SUBSCRIBED') {\n    const status = await channel.track({ online_at: new Date().toISOString() })\n    console.log(status)\n  }\n})\n```\nThen you can use another client to add another user to the channel's Presence state:\n```js\n// Supabase client setup\nconst channel = supabase.channel('online-users', {\n  config: {\n    presence: {\n      key: 'user2',\n    },\n  },\n})\n// Presence event handlers setup\nchannel.subscribe(async (status) => {\n  if (status === 'SUBSCRIBED') {\n    const status = await channel.track({ online_at: new Date().toISOString() })\n    console.log(status)\n  }\n})\n```\nIf a channel is set up without a presence key, the server generates a random UUID. `type` must be `presence` and `event` must be either `sync`, `join`, or `leave`.\nInsert and Receive Persisted Messages\nPostgres Changes enables your client to insert, update, or delete database records and send the changes to clients. Create a `messages` table to keep track of messages created by users in specific rooms:\n```sql\ncreate table messages (\n  id serial primary key,\n  message text,\n  user_id text,\n  room_id text,\n  created_at timestamptz default now()\n)\nalter table messages enable row level security;\ncreate policy \"anon_ins_policy\"\nON messages\nfor insert\nto anon\nwith check (true);\ncreate policy \"anon_sel_policy\"\nON messages\nfor select\nto anon\nusing (true);\n```\nIf it doesn't already exist, create a `supabase_realtime` publication and add `messages` table to the publication:\n```sql\nbegin;\n  -- remove the supabase_realtime publication\n  drop publication if exists supabase_realtime;\n-- re-create the supabase_realtime publication with no tables and only for insert\n  create publication supabase_realtime with (publish = 'insert');\ncommit;\n-- add a table to the publication\nalter publication supabase_realtime add table messages;\n```\nYou can then have a client listen for changes on the `messages` table for a specific room and send and receive persisted messages:\n```js\n// Supabase client setup\nconst channel = supabase.channel('db-messages')\nconst roomId = 'room1'\nconst userId = 'user1'\nchannel.on(\n  'postgres_changes',\n  {\n    event: 'INSERT',\n    schema: 'public',\n    table: 'messages',\n    filter: `room_id=eq.${roomId}`,\n  },\n  (payload) => console.log(payload)\n)\nchannel.subscribe(async (status) => {\n  if (status === 'SUBSCRIBED') {\n    const res = await supabase.from('messages').insert({\n      room_id: roomId,\n      user_id: userId,\n      message: 'Welcome to Realtime!',\n    })\n    console.log(res)\n  }\n})\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Presence State",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/realtime/presence.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'presence',\n  title: 'Presence',\n  description: \"Getting started with Realtime's Presence feature\",\n}\nPresence utilizes an in-memory conflict-free replicated data type (CRDT) to track and synchronize shared state in an eventually consistent manner. It computes the difference between existing state and new state changes and sends the necessary updates to clients via Broadcast.\nWhen a new client subscribes to a channel, it will immediately receive the channel's latest state in a single message instead of waiting for all other clients to send their individual states.\nClients are free to come-and-go as they please, and as long as they are all subscribed to the same channel then they will all have the same Presence state as each other.\nThe neat thing about Presence is that if a client is suddenly disconnected (for example, they go offline), their state will be automatically removed from the shared state. If you've ever tried to build an \u201cI'm online\u201d feature which handles unexpected disconnects, you'll appreciate how useful this is.\nPresence State\nYou can get started by listening to `sync` event messages notifying the client that a channel's state has been synchronized on the server. You can get the state by calling the channel's `presenceState` helper:\n```js\nconst { createClient } = require('@supabase/supabase-js')\nconst supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY)\nconst channel = supabase.channel('test')\nchannel\n  .on('presence', { event: 'sync' }, () => {\n    const state = channel.presenceState()\n    console.log(state)\n  })\n  .subscribe()\n```\nWhenever there's Presence activity on the `'test'` channel, this `sync` event will be broadcast to all clients subscribed to the channel.\nListen to Joins\nYou can create a client and listen to new state joining the channel's Presence:\n```js\n// Supabase client setup\nconst channel = supabase.channel('test')\nchannel\n  .on('presence', { event: 'join' }, ({ key, newPresences }) => {\n    console.log(key, newPresences)\n  })\n  .subscribe()\n```\nTrack Presence\nOn another client, subscribe to the channel and insert state to be tracked by Presence:\n```js\n// Supabase client setup\nconst channel = supabase.channel('test')\nchannel.subscribe(async (status) => {\n  if (status === 'SUBSCRIBED') {\n    const presenceTrackStatus = await channel.track({\n      user: 'user-1',\n      online_at: new Date().toISOString(),\n    })\n    console.log(presenceTrackStatus)\n  }\n})\n```\nPresence Key\nBy default, Presence will generate an `UUIDv1` key on the server to uniquely track a client channel's state but you may pass Presence a custom key when creating the channel.\n```js\n// Supabase client setup\nconst channel = supabase.channel('test', {\n  config: {\n    presence: {\n      key: 'userId-1',\n    },\n  },\n})\nchannel.subscribe(async (status) => {\n  if (status === 'SUBSCRIBED') {\n    const presenceTrackStatus = await channel.track({\n      user: 'user-1',\n      online_at: new Date().toISOString(),\n    })\n    console.log(presenceTrackStatus)\n  }\n})\n```\nListen to Leaves\nYou can create a client and listen to a client channel's state leaving:\n```js\n// Supabase client setup\nconst channel = supabase.channel('test')\nchannel\n  .on('presence', { event: 'leave' }, ({ key, leftPresences }) => {\n    console.log(key, leftPresences)\n  })\n  .subscribe()\n```\nUntrack Presence\nOn another client, subscribe to the channel, and remove tracked state from Presence:\n```js\n// Supabase client setup\nconst channel = supabase.channel('test')\nchannel.subscribe(async (status) => {\n  if (status === 'SUBSCRIBED') {\n    const presenceTrackStatus = await channel.track({\n      user: 'user-1',\n      online_at: new Date().toISOString(),\n    })\n\n\n```if (presenceTrackStatus === 'ok') {\n  const presenceUntrackStatus = await channel.untrack()\n  console.log(presenceUntrackStatus)\n}\n```\n\n\n}\n})\n```\nClient-Side Rate Limit\nThere is a default client-side rate limit that enables you to send 10 messages per second, or one message every 100 milliseconds. You can customize this when creating the client:\n```js\nconst { createClient } = require('@supabase/supabase-js')\nconst supabase = createClient(\n  process.env.SUPABASE_URL,\n  process.env.SUPABASE_KEY,\n  {\n    realtime: {\n      params: {\n        eventsPerSecond: 5\n      }\n    }\n  }\n```\nBy setting `eventsPerSecond` to 5, you can send one message every 200 milliseconds on a per client basis.\nLearn more by visiting the Rate Limits section.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Set up your Backend on Supabase",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/appsmith.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'appsmith',\n  title: 'Appsmith',\n  description:\n    'Get started with Supabase and Appsmith, an open-source framework for building internal tools.',\n}\nThis guide explains how to quickly build a Support Dashboard by connecting a Supabase back-end to an Appsmith front-end.\nAppsmith is an open-source framework for building internal tools. It lets you drag-and-drop UI components to build pages, connect to any API, database or GraphQL source and write logic with JavaScript objects.\nIf you don\u2019t have an Appsmith account, create one\u00a0here.\nLet\u2019s get started!\nStep 1: Set up your Backend on Supabase\n\nOn the Supabase dashboard, click\u00a0`New project`\u00a0and set the name to Support Dashboard\n\n\n\nCreate a new table by clicking on the\u00a0Create Table\u00a0option on the side navigation.\nSupabase provides many ways to add data to the tables, from writing queries to creating schemas using UI to simply uploading CSV files. For our support dashboard, we will be creating the tickets table by uploading the CSV file on Supabase.\n\n\nThe database is now set up.\nStep 2: Connect the database to Appsmith\n\nNote down the database connection information under Project Settings in Supabase.\n\n\n\nOn Appsmith, create a new application under the dashboard under your preferred organization.\nClick on the `+` icon next to Datasources on the left navigation bar under Page1\nNext, click on Create New tab and choose PostgreSQL datasource, you\u2019ll see the following screenshot:\n\n\n\nFill out the form to connect to your Supabase instance. Click Test to test connection and then Save to save the datasource\n\n\nStep 3: Build UI on Appsmith\n\nClick on the\u00a0+\u00a0icon next to widgets and drag and drop a Tab widget. We can configure using the property pane by clicking on the cog icon on the top-right corner.\nAs seen in the below screenshot, we have added four tabs to support the dashboard.\n\n\n\n\nAdd widgets to the Home tab to create the dashboard as shown in the screenshot below. For eg: Critical Open Issues is a Text widget and below it is an Input widget which we will bind later to display the number of open tickets.\n\n\nSet up the New button to open a modal which will have a form to raise a new ticket.\n\n\n\n\nIn the modal widget, add a few widgets to accept input when creating a new ticket. Please refer to the screenshot below.\n\n\nStep 4: Writing Queries in Appsmith and binding data to widgets\n\nClick on the + icon next to Datasources on the navigation bar and click New Query next to the Supabase connection here to create a new query.\n\n\n\nRename the query to create_new_ticket under the query pane; here we can write SQL that can collect the data from the widgets using mustache templates.\n\n`jsx\nINSERT INTO PUBLIC.\"tickets\"(\"id\",\"createdAt\",\"user\",\"updatedAt\",\"description\",\n\"status\",\"priority\",\"category\",\"assignedTo\")\nVALUES('{{appsmith.store.ticket.id}}','{{moment().format('yyyy-mm-ddHH:MM:ss')}}','{{c_user.text}}',\n'{{moment().format('yyyy-mm-ddHH:MM:ss')}}','{{c_description.text}}','{{c_status.selectedOptionValue}}',\n'{{c_property.selectedOptionValue}}',\n'{{c_category.selectedOptionValue}}','{{c_assignee.selectedOptionValue}}');`\n\nClick the Confirm button on the modal and under Events, set the onClick property to execute the\u00a0create_new_ticket query.\nCreate a second query named get_tickets that will list all the tickets.\n\n\n`jsx\nSELECT * FROM public.\"tickets\";`\n\nDrag and drop a table widget under the\u00a0Assigned To Me\u00a0tab. Open the property pane and add the following snippet under Table Data to bind the query results.\n\n`jsx\n{\n  {\n    get_tickets.data.filter(\n      (t) => t.assignedTo === 'confidence@appsmith.com' && t.status !== 'closed'\n    )\n  }\n}`\n\nDrag and drop a table widget under the\u00a0Resolved\u00a0tab. Open the property pane and add the following snippet under Table Data to bind the query results.\n\n`jsx\n{\n  {\n    get_tickets.data.filter((t) => t.status === 'open')\n  }\n}`\n\nDrag and drop a table widget under the\u00a0Closed\u00a0tab. Open the property pane and add the following snippet under Table Data to bind the query results.\n\n`jsx\n{\n  {\n    get_tickets.data.filter((t) => t.status === 'closed')\n  }\n}`\nStep 5: Creating Charts in Appsmith\n\nOn the Home tab, click on the first Chart widget. Add Title Open Issues By Category. Change the Chart Type property to Column Chart.\nUpdate the x-axis and y-axis Labels under Axis on the property pane.\nAdd the following code snippet under the Series Data property to bind the data to be displayed on the x and y axes.\n\n`jsx\n[\n  {\n    \"x\": \"Hardware\",\n    \"y\": {{get_tickets.data.filter(t => t.status==='open' && t.category==='hardware').length}}\n  },\n  {\n    \"x\": \"Software\",\n    \"y\": {{get_tickets.data.filter(t => t.status==='open' && t.category==='software').length}}\n  },\n  {\n    \"x\": \"Other\",\n    \"y\": {{get_tickets.data.filter(t => t.status==='open' && t.category==='other').length}}\n  }\n]`\n\nThe second chart will be a pie chart. Add the title, axes labels as mentioned above,\nAdd the following code snippet under the Series Data property of the pie chart.\n\n`jsx\n[\n  {\n    \"x\": \"High\",\n    \"y\": {{get_tickets.data.filter(t => t.status==='open' && t.priority==='high').length}}\n  },\n  {\n    \"x\": \"Medium\",\n    \"y\": {{get_tickets.data.filter(t => t.status==='open' && t.priority==='medium').length}}\n  },\n  {\n    \"x\": \"Low\",\n    \"y\": {{get_tickets.data.filter(t => t.status==='open' && t.priority==='low').length}}\n  }\n]`\nResources\n\nAppsmith official website.\nAppsmith GitHub.\nAppsmith documentation.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Get the RESTful endpoint and Project API key",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/draftbit.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'draftbit',\n  title: 'Draftbit',\n  description: 'Connect your Supabase postgres database to your Low-code mobile app.',\n}\nThis guide explains how to connect a Supabase back-end to a Draftbit front-end and then configure all CRUD operations necessary to build a simple mobile app.\nDraftbit is a \"pro-code\" low-code mobile app building platform. Draftbit exports React Native source code that is 100% run on open-source languages and libraries.\nDraftbit is back-end agnostic and connects to Supabase via REST API.\n\nNote: For the demonstration purpose of this guide, we are using a pre-populated database in Supabase. We are calling `Groceries`. To follow along, rename it any way you prefer.\n\n\nIf you don\u2019t have a Draftbit account, create one here. Once you\u2019ve got your account set up, Create a New App. You can select `Start From a Blank App` for this demo and proceed to the Builder interface.\nStep 1: Get the RESTful endpoint and Project API key\nTo connect the REST API in the Draftbit app, the following fields are required:\n\nBase URL of the REST API, which is in the format: `https://<your-domain>.supabase.co/rest/v1` where the `<your-domain` is a unique domain name generated by Supabase.\nThe `supabase-key` is the secret key.\n\nYou can find these unique values in the API settings of your Supabase account.\n\nClick the Settings button from the top menu bar.\nIn Settings, select API.\nIn the Project URL section, select and copy the URL. It is the Base URL of your Supabase REST API. It will be required to make a connection to the Draftbit app.\nAlso, under `Project API keys`, select and copy the API key under `anon`. It is required for every request made to the Supabase database.\n\n\nStep 2: Save Supabase API key as Authorization Header in Draftbit\nTo authorize your Draftbit app with Supabse, in the builder interface:\n\nOpen the Settings tab from the top menu bar.\nIn Project Settings, navigate to App Variables.\nEnter a name to access the API Key such as `Authorization_Header`. When making the service connection in the next section, it will be passed as the value for the header `Authorization`.\nThe value of this key requires you to enter an authorization token that starts with syntax `Bearer <your-api-key>` (the space between `Bearer` and `<your-api-key>` is required). Click Add after adding the value.\nEnter another key name to access the API Key such as `Api_Key_Header`. When making the service connection in the next section, it will be passed as the header `apiKey` value.\nThe value of this key requires you to enter an authorization token that starts with syntax is `<your-api-key>`. Click Add after adding the value.\nClick Save to save these keys and close the modal.\n\n\nStep 3: Add Supabase RESTful endpoint in Draftbit\nIn your Draftbit builder interface:\n\nOpen the API & Cloud Services modal from the top menu bar.\n\nFrom the Connect a service menu, click on Rest API.\n\n\nIn Step 1: Enter a name for your REST API. Then, paste your `Base URL` (from the first section) into the Base URL field.\n\nIn Step 2: Under Key add `Authorization` and `apikey`. Then, under Value, select the global variables (from the previous section) to add the actual values for both keys.\nClick Save.\n\n\nMaking API requests with Supabase & Draftbit\nGET request to Fetch all records\nIn this section, let's populate a Fetch component with all the data from a simple Supabase and then display the data fetched from the Supabase data table in a List component.\nFor reference, here is a how the Components tree looks like for this screen:\n\nThe next step is to create an endpoint. Let's try fetching all the data using a `GET` HTTP request. Select the Supabase service in the API & Cloud Services modal, and then:\n\nClick Add endpoint.\nIn Step 1: enter the name for the endpoint. Make sure the Method select is `GET`.\nIn Step 2: add the base name path: `/groceries/select=*`, where `groceries` is the table name in Supabase.\nIn Step 4: click the Test button next to the Endpoint input to verify the response coming from the Supabase.\nClick Save.\n\n\nIn the Builder, on the app screen:\n\nSelect the Fetch component in the Components tree and go to the Data tab from Properties Panel.\nFor Service, select the name of the Supabase Service.\nFor Endpoint, select the endpoint you want to fetch the data from.\nSelect the List component in the Components and go to the Data tab from Properties Panel. In Data, select `Top-Level Response` from the dropdown menu.\nThen, select the Text component in the Components and then go to the Data tab from the Properties Panel.\nAdd a `{{varName}}` value (inside the curly braces) to represent a column field from the Supabase. For example, add `{{title}}` to represent the column name from the Supabase Base.\nUnder Variables, you will see the variable name defined in the previous step. From the dropdown menu, select the appropriate field that represents the data field.\n\n\nGET request to fetch single row\nOpen the API & Cloud services modal from the top menu, select the Supabase service, and then:\n\nClick Add endpoint.\nIn Step 1: enter a name for the endpoint.\nIn Step 2: add the `/groceries/column-name=eq.{{column-name}}` variable. Then, add a Test value for the `{{column-name}}`. For example, it can be the `title` or the `id`.\nIn Step 4: click the Test button next to the Endpoint input to verify the response coming from the Supabase.\nClick Save.\n\n\nOn app screen:\n\nSelect the Fetch component in the Components tree and go to the Data tab from Properties Panel\nFor Service, select the name of the Supabase Service.\nFor endpoint, select the endpoint you want to fetch the data from.\nSet the value for the `id` in the Configuration > URL Structure section to Navigation > id.\nSelect the List component in the Components and go to the Data tab from Properties Panel. In Data, select `Top-Level Response` from the dropdown menu.\nThen, select the Text component in the Components and then go to the Data tab from the Properties Panel.\nAdd a `{{varName}}` value (inside the curly braces) to represent the column field from the Supabase. For example, add `{{title}}` to represent the field and value from the Supabase data table.\nUnder Variables, you will see the variable name defined in the previous step. From the dropdown menu, select the appropriate field that represents the data field.\n\n\nPOST request to submit a new row\nSubmitting new Data from the Draftbit app to Supabase's REST API requires the request to be sent using the HTTP `POST` method.\nFor this section, you need to use at least one component that accepts user input and has a Field Name prop to POST data using Supabase REST API.\nYou can use one of the following components in Draftbit:\n\nText Input\nText Area/Text Field\nCheckbox\nSlider\nRadio Button Group\nRadio Button\n\nIn addition, you need a Touchable component like a Button to attach the POST action. After you have created these components, we will create the `POST` endpoint:\n\nClick Add endpoint.\nIn Step 1: enter a name for the endpoint and select the Method to `POST`.\nIn Step 2: enter the base name as path: `/groceries`.\nIn Step 3: add a valid Body structure to submit a POST request. Add one or many `{{variable}}` for test values. Click Body Preview to validate the structure of the Body in the request. For the example, let's create a variable called `{{inputValue}}`.\nIn Step 4: to see the new row added to the Supabase data table as JSON response inside the Builder, you have to pass a new header called `Prefer` with its value as `return=representation`.\nIn Step 5: click the Test button next to the Endpoint input to verify the response coming from the Supabase and click Save.\n\n\nOnce you follow the above steps, you should get a 200 OK response with exactly the new record as a JSON you have entered for your schema.\nAn example of how Body in a request will look like:\n`json\n{\n  \"title\": {{inputValue}}\n}`\nWhere `title` is the column name in your Supabase database table.\nIn Draftbit, using a Touchable or a Button component, you can trigger the action API Request to submit the data to the endpoint.\nNow, there is a working `POST` request in Draftbit. Map its response to the components on your screen in Draftbit.\nFirst, for each input component, make sure you have set the Field Names (found in the Configs tab, second from the left) to unique values. For example, in the screen below, there is one TextInput field component with the value of the `Field Name` prop of `textInputValue`.\n\nNext, on your Button component, go to the Interactions tab in the Properties panel located on the far-right-hand side. Select an Action called `API request`.\nIn the API request action:\n\nIn Service, select the name to Supabase API Service.\nIn Endpoint, select the name of the Endpoint.\nThen add the configuration for the body request to be sent by selecting the values for `{{inputValue}}`.\n\n\nAfter completing the above steps, you can trigger the API request to submit new data to the Supabase database.\nPATCH request to Update a new record\nUpdating an existing record from the Draftbit app to Supabase's REST API requires the request to be sent using the HTTP `PATCH` method.\nAfter you have created your screen components in the Draftbit builder, open the Supabase service and make the `PATCH` endpoint:\n\nClick Add endpoint.\nIn Step 1: enter a name for the endpoint and select the Method to `PATCH`.\nIn Step 2: enter the base name as path: `/groceries?id=eq.{{id}}`, where `id` is the value of an existing record in the database.\nIn Step 3: add a valid Body structure to submit a PATCH request. Add one or many `{{variable}}` for test values depending on the structure of your app. Click Body Preview to validate the structure of the Body in the request. For the example, let's create a variable called `{{inputValue}}`.\nIn Step 5: click the Test button next to the Endpoint input to verify the response coming from the Supabase and click Save.\n\n\nNext, on your Button component, go to the Interactions tab in the Properties panel located on the far-right-hand side. Select an Action called `API request`.\nIn the API request action:\n\nIn Service, select the name to Supabase API Service.\nIn Endpoint, select the name of the Endpoint.\nThen add the configuration for the query param, and the body request to be sent by selecting the values for `{{inputValue}}`.\n\n\nAfter completing the above steps, you can trigger the API request to update existing data in the Supabase database.\nDELETE request to remove an existing record\nThe `DELETE` request is to the Supabase with an item's `column-name` to remove that particular record from the table. You can use a filter from Supabase to filter the value of a specific `column-name`.\nAfter you have created your screen components in the Draftbit builder, open the Supabase service and create the `DELETE` endpoint:\n\nClick Add endpoint.\nIn Step 1: enter a name for the endpoint and select the Method to `DELETE`.\nIn Step 2: add `/groceries/columnName=eq.{{columnName}}`. Then, add a Test value for the `{{columnName}}`. For example, the `{{columnName}}` here can be `id` of the record.\nIn Step 4: click the Test button next to the Endpoint input to verify the response from the Supabase.\nClick Save.\n\n\nNext, on your Button component, go to the Interactions tab in the Properties panel located on the far-right-hand side. Select an Action called `API request`.\nIn the API Request action:\n\nIn Service, select the name to Supabase API Service.\nIn Endpoint, select the name of the Endpoint.\nThen, add the configuration for the query request to be sent by selecting a value. For example, in this case it will be the `id` of the record coming from the Navigation parameter.\n\n\nResources\n\nDraftbit official website.\nDraftbit Community.\nDraftbit documentation.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Create a new Supabase project",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/supertokens.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'supertokens',\n  title: 'SuperTokens',\n  description:\n    'Create a Next.js application secured by SuperTokens and PostgreSQL Row Level Security.',\n}\nSuperTokens is an open source authentication solution which provides many stratergies for authenticating and managing users. You can use the managed service for easy setup or you can self host the solution to have complete control over your data.\nIn this guide we will build a simple web application using SuperTokens, Supabase, and Next.js. You will be able to sign up using SuperTokens and your email and user ID will be stored in Supabase. Once authenticated the frontend will be able to query Supabase and retrieve the user's email. Our example app will be using the Email-Password and Social Login recipe for authentication and session management.\nWe will use Supabase to store and authorize access to user data. Supabase makes it simple to setup Row Level Security(RLS) policies which ensure users can only read and write data that belongs to them.\nDemo App\nYou can find a demo app using SuperTokens, Supabase and Nexts.js on Github\nStep 1: Create a new Supabase project\nFrom your Supabase dashboard, click `New project`.\nEnter a `Name` for your Supabase project.\nEnter a secure `Database Password`.\nSelect the same `Region` you host your app's backend in.\nClick `Create new project`.\n\nStep 2: Creating tables in Supabase\nFrom the sidebar menu in the Supabase dashboard, click `Table editor`, then `New table`.\nEnter `users` as the `Name` field.\nSelect `Enable Row Level Security (RLS)`.\nRemove the default columns\nCreate two new columns:\n\n`user_id` as `varchar` as primary key\n`email` as `varchar`\n\nClick `Save` to create the new table.\n\nStep 3: Setup your Next.js App with SuperTokens.\nSince the scope of this guide is limited to the integration between SuperTokens and Supabase, you can refer to the SuperTokens website to see how to setup your Next.js app with SuperTokens.\nOnce you finish setting up your app, you will be greeted with the following screen\n\nStep 4: Creating a Supabase JWT to access Supabase\nIn our Nextjs app when a user signs up, we want to store the user's email in Supabase. We would then retrieve this email from Supabase and display it on our frontend.\nTo use the Supabase client to query the database we will need to create a JWT signed with your Supabase app's signing secret. This JWT will also need to contain the user's userId so Supabase knows an authenticated user is making the request.\nTo create this flow we will need to modify SuperTokens so that, when a user signs up or signs in, a JWT signed with Supabase's signing secret is created and attached to the user's session. Attaching the JWT to the user's session will allow us to retrieve the Supabase JWT on the frontend and backend (post session verification), using which we can query Supabase.\nWe want to create a Supabase JWT when we are creating a SuperTokens' session. This can be done by overriding the `createNewSession` function in your backend config.\n```ts\n// config/backendConfig.ts\nimport ThirdPartyEmailPasswordNode from \"supertokens-node/recipe/thirdpartyemailpassword\";\nimport SessionNode from \"supertokens-node/recipe/session\";\nimport { TypeInput } from \"supertokens-node/lib/build/types\";\nimport { appInfo } from \"./appInfo\";\nimport jwt from \"jsonwebtoken\";\nlet backendConfig = (): TypeInput => {\n    return {\n        framework: \"express\",\n        supertokens: {\n            connectionURI: \"https://try.supertokens.com\",\n        },\n        appInfo,\n        recipeList: [\n            ThirdPartyEmailPasswordNode.init({...}),\n            SessionNode.init({\n                override: {\n                    functions: (originalImplementation) => {\n                        return {\n                            ...originalImplementation,\n                            // We want to create a JWT which contains the users userId signed with Supabase's secret so\n                            // it can be used by Supabase to validate the user when retrieving user data from their service.\n                            // We store this token in the accessTokenPayload so it can be accessed on the frontend and on the backend.\n                            createNewSession: async function (input) {\n                                const payload = {\n                                    userId: input.userId,\n                                    exp: Math.floor(Date.now() / 1000) + 60 * 60,\n                                };\n\n\n```                            const supabase_jwt_token = jwt.sign(payload, process.env.SUPABASE_SIGNING_SECRET);\n\n                            input.accessTokenPayload = {\n                                ...input.accessTokenPayload,\n                                supabase_token: supabase_jwt_token,\n                            };\n\n                            return await originalImplementation.createNewSession(input);\n                        },\n                    };\n                },\n            },\n        }),\n    ],\n    isInServerlessEnv: true,\n};\n```\n\n\n};\n```\nAs seen above, we will be using the `jsonwebtoken` library to create a JWT signed with Supabase's signing secret whose payload contains the user's userId.\nWe will be storing this token in the `accessTokenPayload` which will essentially allow us to access the `supabase_token` on the frontend and backend whilst the user is logged in.\nStep 5: Creating a Supabase client\nCreate a new file called `utils/supabase.ts` and add the following:\n```ts\n// utils/supabase.ts\nimport { createClient } from '@supabase/supabase-js'\nconst getSupabase = (access_token) => {\n  const supabase = createClient(\n    process.env.NEXT_PUBLIC_SUPABASE_URL,\n    process.env.NEXT_PUBLIC_SUPABASE_KEY\n  )\nsupabase.auth.session = () => ({\n    access_token,\n  })\nreturn supabase\n}\nexport { getSupabase }\n```\nThis will be our client for talking to Supabase. We can pass it an `access_token` and it will be attached to our request. This `access_token` is the same as the `supabase_token` we had created earlier.\nStep 6: Inserting users into Supabase when they sign up:\nIn our example app there are two ways for signing up a user. Email-Password and Social Login based authentication. We will need to override both these APIs such that when a user signs up, their email mapped to their userId is stored in Supabase.\n```ts\n// config/backendConfig.ts\nimport ThirdPartyEmailPasswordNode from \"supertokens-node/recipe/thirdpartyemailpassword\";\nimport SessionNode from \"supertokens-node/recipe/session\";\nimport { TypeInput } from \"supertokens-node/lib/build/types\";\nimport { appInfo } from \"./appInfo\";\nimport jwt from \"jsonwebtoken\";\nimport { getSupabase } from \"../utils/supabase\";\nlet backendConfig = (): TypeInput => {\n    return {\n        framework: \"express\",\n        supertokens: {\n            connectionURI: \"https://try.supertokens.com\",\n        },\n        appInfo,\n        recipeList: [\n            ThirdPartyEmailPasswordNode.init({\n                providers: [...],\n                override: {\n                    apis: (originalImplementation) => {\n                        return {\n                            ...originalImplementation,\n                            // the thirdPartySignInUpPost function handles sign up/in via Social login\n                            thirdPartySignInUpPOST: async function (input) {\n                                if (originalImplementation.thirdPartySignInUpPOST === undefined) {\n                                    throw Error(\"Should never come here\");\n                                }\n\n\n```                            // call the sign up/in api for social login\n                            let response = await originalImplementation.thirdPartySignInUpPOST(input);\n\n                            // check that there is no issue with sign up and that a new user is created\n                            if (response.status === \"OK\" && response.createdNewUser) {\n\n                                // retrieve the accessTokenPayload from the user's session\n                                const accessTokenPayload = response.session.getAccessTokenPayload();\n\n                                // create a supabase client with the supabase_token from the accessTokenPayload\n                                const supabase = getSupabase(accessTokenPayload.supabase_token);\n\n                                // store the user's email mapped to their userId in Supabase\n                                const { error } = await supabase\n                                    .from(\"users\")\n                                    .insert({ email: response.user.email, user_id: response.user.id });\n\n                                if (error !== null) {\n\n                                    throw error;\n                                }\n                            }\n\n                            return response;\n                        },\n                        // the emailPasswordSignUpPOST function handles sign up via Email-Password\n                        emailPasswordSignUpPOST: async function (input) {\n                            if (originalImplementation.emailPasswordSignUpPOST === undefined) {\n                                throw Error(\"Should never come here\");\n                            }\n\n                            let response = await originalImplementation.emailPasswordSignUpPOST(input);\n\n                            if (response.status === \"OK\") {\n\n                                // retrieve the accessTokenPayload from the user's session\n                                const accessTokenPayload = response.session.getAccessTokenPayload();\n\n                                // create a supabase client with the supabase_token from the accessTokenPayload\n                                const supabase = getSupabase(accessTokenPayload.supabase_token);\n\n                                // store the user's email mapped to their userId in Supabase\n                                const { error } = await supabase\n                                    .from(\"users\")\n                                    .insert({ email: response.user.email, user_id: response.user.id });\n\n                                if (error !== null) {\n\n                                    throw error;\n                                }\n                            }\n\n                            return response;\n                        },\n                    };\n                },\n            },\n        }),\n        SessionNode.init({...}),\n    ],\n    isInServerlessEnv: true,\n};\n```\n\n\n};\n```\nAs seen above, we will be overriding the `emailPasswordSignUpPOST` and `thirdPartySignInUpPOST` APIs such that if a user signs up, we retrieve the Supabase JWT (which we created in the `createNewSession` function) from the user's accessTokenPayload and send a request to Supabase to insert the email-userid mapping.\nStep 7: Retrieving the user's email on the frontend\nNow that our backend is setup we can modify our frontend to retrieve the user's email from Supabase.\n```tsx\n// pages/index.tsx\nimport React, { useState, useEffect } from 'react'\nimport Head from 'next/head'\nimport styles from '../styles/Home.module.css'\nimport ThirdPartyEmailPassword, {\n  ThirdPartyEmailPasswordAuth,\n} from 'supertokens-auth-react/recipe/thirdpartyemailpassword'\nimport dynamic from 'next/dynamic'\nimport { useSessionContext } from 'supertokens-auth-react/recipe/session'\nimport { getSupabase } from '../utils/supabase'\nexport default function Home() {\n  return (\n    // We will wrap the ProtectedPage component with ThirdPartyEmailPasswordAuth so only an\n    // authenticated user can access it. This will also allow us to access the users session information\n    // within the component.\n    \n\n\n  )\n}\nfunction ProtectedPage() {\n  // retrieve the authenticated user's accessTokenPayload and userId from the sessionContext\n  const { accessTokenPayload, userId } = useSessionContext()\nif (sessionContext.loading === true) {\n    return null\n  }\nconst [userEmail, setEmail] = useState('')\n  useEffect(() => {\n    async function getUserEmail() {\n      // retrieve the supabase client who's JWT contains users userId, this will be\n      // used by supabase to check that the user can only access table entries which contain their own userId\n      const supabase = getSupabase(accessTokenPayload.supabase_token)\n\n\n```  // retrieve the user's name from the users table whose email matches the email in the JWT\n  const { data } = await supabase.from('users').select('email').eq('user_id', userId)\n\n  if (data.length > 0) {\n    setEmail(data[0].email)\n  }\n}\ngetUserEmail()\n```\n\n\n}, [])\nreturn (\n    \n\nSuperTokens \ud83d\udcab\n\n\n\n\n```  <main className={styles.main}>\n    <p className={styles.description}>\n      You are authenticated with SuperTokens! (UserId: {userId})\n      <br />\n      Your email retrieved from Supabase: {userEmail}\n    </p>\n  </main>\n</div>\n```\n\n\n)\n}\n```\nAs seen above we will be using SuperTokens `useSessionContext` hook to retrieve the authenticated user's `userId` and `accessTokenPayload`. Using React's `useEffect` hook we can use the Supabase client to retrieve the user's email from Supabase using the JWT retrieved from the user's `accessTokenPayload` and their `userId`.\nStep 8: Create Policies to enforce Row Level Security for Select and Insert requests\nTo enforce Row Level Security for the `Users` table we will need to create policies for Select and Insert requests.\nThese polices will retrieve the userId from the JWT and check if it matches the userId in the Supabase table\nTo do this we will need a PostgreSQL function to extract the userId from the JWT.\nThe payload in the JWT will have the following structure:\n`// JWT payload\n{\n    userId,\n    exp\n}`\nTo create the PostgreSQL function, lets navigate back to the Supabase dashboard, select `SQL` from the sidebar menu, and click `New query`. This will create a new query called `new sql snippet`, which will allow us to run any SQL against our Postgres database.\nWrite the following and click `Run`.\n`sql\ncreate or replace function auth.user_id() returns text as $$\n  select nullif(current_setting('request.jwt.claims', true)::json->>'userId', '')::text;\n$$ language sql stable;`\nThis will create a function called `auth.user_id()`, which will inspect the `userId` field of our JWT payload.\nSELECT query policy\nOur first policy will check whether the user is the owner of the email.\nSelect `Authentication` from the Supabase sidebar menu, click `Policies`, and then `New Policy` on the `Users` table.\n\nFrom the modal, select `Create a policy from scratch` and add the following.\n\nThis policy is calling the PostgreSQL function we just created to get the currently logged in user's ID `auth.user_id()` and checking whether this matches the `user_id` column for the current `email`. If it does, then it will allow the user to select it, otherwise it will continue to deny.\nClick `Review` and then `Save policy`.\nINSERT query policy\nOur second policy will check whether the `user_id` being inserted is the same as the `userId` in the JWT.\nCreate another policy and add the following:\n\nSimilar to the previous policy we are calling the PostgreSQL function we created to get the currently logged in user's ID `auth.user_id()` and check whether this matches the `user_id` column for the row we are trying to insert. If it does, then it will allow the user to insert the row, otherwise it will continue to deny.\nClick `Review` and then `Save policy`.\nStep 9: Test your changes\nYou can now sign up and you should see the following screen:\n\nIf you navigate to your table you should see a new row with the user's `user_id` and `email`.\n\nResources\n\nSuperTokens official website.\nSuperTokens community.\nSuperTokens documentation.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Sign up for Keyri",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/keyri.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'keyri',\n  title: 'Keyri',\n  description:\n    'QR authentication for an easy and flexible biometric solution across all platforms.',\n  video: 'https://www.youtube.com/v/jrjrcpc2PFQ',\n}\nKeyri can be used to incorporate sign-in-with-QR functionality into your Supabase app, allowing users to scan a QR code on your web app with your mobile app and be instantly logged into the web app without having to input any credentials.\nConfiguration is split into Web and Mobile components. On web, the Keyri QR Widget needs to be installed along with an event listener, and in your mobile app, install the Keyri SDK and pass into it the user's refresh token when sign-in-with-QR is initiated. When the refresh token lands in your web app, it's passed into Supabase's `setSession()` method.\nSign up for Keyri\nFirst make a free account on the Keyri dashboard (https://app.keyri.com). On Add Your Application, set a name and input the domain on which your app will eventually be deployed. You can create multiple application in Keyri to account for your development, staging, and production environments\n\nNote your application key from the Keys and Credentials section - this will be used in the Mobile portion of the implementation\n\nWeb\n\n\n\nFor your web app, first download KeyriQR.html (available here) and save it to a public directory.\nNext, embed KeyriQR.html in your login page as an iFrame within the desired div. This serves as the widget that displays the dynamic QR code and connects with the Keyri API.\n```html\n\n\n\n```\nNext, for the same login view, set up an event listener to pick up the session token that the iFrame emits when the QR code is scanned by your app.\n`javascript\nuseEffect(() => {\n    window.addEventListener('message', async (evt) => {\n      if (evt.data.keyri && evt.data.data && document.location.origin == evt.origin) {\n        const { data } = evt;\n        if (!data.error) {\n          let refresh_token = JSON.parse(data.data).refreshToken;\n          await handleQrLogin(refresh_token);\n        } else if (data.error) {\n          console.log(`Keyri error: ${data.message}`);\n        }\n      }\n});`\nThat's it!\nMobile\n\n\n\nInstall Flutter\nFirst, install the Flutter SDK, found at flutter.dev\nMake sure to add Flutter to your PATH, for example: \n`shell\nexport PATH=\"$PATH:`pwd`/flutter/bin\"`\nApple - initial setup\nDownload the latest version of Xcode from the Mac App Store. Make sure the Xcode provided simulator is using a 64-bit device (iPhone 5s or later). You can check the device by viewing the settings in the simulator\u2019s Hardware > Device or File > Open Simulator menus.\nAndroid - initial setup\nDownload the latest version of Android Studio. Install Android SDK and needed emulator(s).\nCreate Project\nRun this command in your terminal/shell at the desired location for your new project\n`shell\n$ flutter create my_app`\nYou can then CD into the new directory, and run the test app with \n`shell\nflutter run`\nThis is a good test - if things are configured correctly so far you should see the default Flutter test app deployed.\nAdd dependencies (Keyri and Supabase)\nOpen your Pubspec.yaml file, which should be at the top level directory in your new project\nAdd Keyri and Supabase under dependencies\n\nOne can now access Supabase and Keyri sdks in their Flutter code\nUtilize the two together\n\nMake a request to Supabase to authenticate the user\nParse the response to extract the token\nAuthenticate using Keyri\nBelow, we show how to utilize the EasyKeyriAuth function, which takes the user through scanning the code, creating the session, displaying the confirmation screen, and finalizing the payload transmission\nNote - you can find your App Key in the Keyri Developer Portal\u200b\n\n\nAlternatively, intermediate functions in the Keyri SDK, discussed in the mobile docs, can provide control over displaying a custom QR Scanner and/or Confirmation screen\n\n\n\n`kotlin\n// Sign in user with email and password\n// Alternatively one can utilize the Supabase API to accomplish the same thing\nfinal response = await client.auth.signIn(email: 'email', password: 'password');\nif (response.error != null) {\n  // Error\n    print('Error: ${response.error?.message}');\n} else {\n    // Success\n    final session = response.data;\n    // This is the payload that needs to be send through Keyri\n    final refreshToken = session.refreshToken\n    // EasyKeyriAuth guides the user through scanning and parsing the QR, confirming the session, and configuring the payload\n    // One can also use the initiateQRSession method to use the Keyri Scanner with a custom Confirmation screen\n    // Or the ProcessLink method if you have your own scanner or are using deep linking\n    await keyri\n        .easyKeyriAuth([App Key],\n            '{\"refreshToken\":\"$refreshToken\"}', [email])\n        .then((authResult) => _onAuthResult(authResult))\n        .catchError((error, stackTrace) => _onError(error));\n}`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Introduction",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/directus.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'directus',\n  title: 'Directus',\n  description:\n    'In this guide, we will show you how to create a Supabase project, install the Directus platform locally and configure the two to connect.',\n}\nIn this guide, we will demonstrate how to create a new Supabase project, install a fresh instance of the Directus platform, then configure the two to work together seamlessly. If you're unfamiliar with either of these systems, don't worry! We'll start off with an overview of each platform and explain how they complement each other, noting any overlap in capabilities.\nIntroduction\n\nSupabase is an open-source Firebase alternative that provides a PostgreSQL database, storage, authentication, and a dynamic REST API based on your schema. While it is possible to self-host Supabase on your own infrastructure, this article will focus on Supabase Cloud's Free tier, which is the fastest and easiest way to get started.\n\nDirectus is an open-source data platform that layers on top of any SQL database, providing a powerful suite of tools. The Directus Engine provides dynamic REST and GraphQL APIs based on your schema, hooks and automation, authentication and access control, and file transformations. Directus Studio enables engineers and non-technical users alike to browse, manage, and visualize database content through a no-code app.\n}\nSupabase is a suite of open-source tools making Postgres databases, file storage, authentication, and edge functions more accessible to developers of all skill levels. Directus is also developer tooling and additionally provides a Data Studio that is safe and intuitive enough for anyone, including non-technical users, to use. This is the crucial bit that gives the two platforms such a strong \u201cnetwork effect.\u201d\nWhen these two systems are brought together, you get a scalable datastore, limitless connectivity options, and a no-code app that allows your technical and business teams to collaborate together efficiently.\nThe two platforms share an overlap of capabilities that deepens their integration and offers developers the freedom of choice across a broader spectrum of connectivity. Key areas of intersection include:\nThe ability to generate powerful APIs dynamically to connect data\nUser management and fine-grained access control\nDigital asset storage and management.\nMore importantly, Directus and Supabase share a common vision for your data, making them quite symbiotic. Both solutions are completely open-source, with self-hosted and cloud deployment options available. They are unopinionated in their approach, with vendor-agnostic data storage, and they both focus on providing a polished developer experience along with comprehensive documentation.\nBy linking the Supabase database with your Directus Project, you get a superset of data tools. You'll benefit from Supabase's Postgres database and its dev-centric admin app with the raw power to run SQL queries, as well as the Directus no-code app, which enables intuitive permissions-based data access for the whole team.\nLet's dive into how we actually set up and link these two platforms to create a modern data stack powerhouse.\nCreate a Supabase Project\nAs mentioned, while you can deploy Supabase locally. For the purpose of this guide, we'll use Supabase Cloud:\n\nCreate a Supabase account by signing in with GitHub.\nGive your organization a name (this can be changed later).\nClick New Project and select your organization.\nFollow the prompts, setting a project Name, Database Password, Region, and Pricing Plan, then click Create New Project.\nAfter your project has been provisioned, navigate to Settings > Database in the sidebar.\nScroll down to Connection Info and take note of your database's Host, Database Name, Port, User, and Password. You will need to enter this during your Directus project setup.\n\nOptional: Add PostGIS to Support Geometry and Mapping\nTo take full advantage of the built-in geometry and mapping features Directus offers, we recommend enabling Geometric Data Support. To add PostGIS, follow these steps:\n\n\nFrom the sidebar, navigate to Database > Extensions.\nUse the search bar to look up `PostGIS`.\nToggle the PostGIS option to enable it.\n\nSet up Directus\nAt the time of writing this article, Directus Cloud does not yet support hybrid deployments for connecting an external database. So, we'll be deploying a self-hosted instance to connect with Supabase. To install a self-hosted instance of Directus that's connected to our Supabase project, follow these steps:\n\nRun the following command in your terminal:\n\n`bash\nnpm init directus-project example-project`\n\nUsing the up/down arrow keys, select `Postgres` from the list:\n\n`bash\n? Choose your database client Postgres`\n\n\nNext, you will be prompted to input database credentials. Add in the Supabase Database Connection Info noted above as follows:\n\n\nDatabase Host \u2013 The IP address for your database.\n\nPort \u2013 Port number your database is running on.\nDatabase Name \u2013 Name of your existing database.\nDatabase User \u2013 Name of existing user in database.\nDatabase Password \u2013 Password to enter database.\nEnable SSL \u2013 Select Y for yes or N for no.\n\nRoot \u2013 The root name.\n\n\nNow, simply set an email and password for your first Directus admin account. To be clear, this is Directus-specific, and is unrelated to your database user:\n\n\n`bash\nCreate your first admin user:\n? Email: admin@example.com\n? Password: ********`\nOnce this is complete, you should see details about your new project:\n`bash\nYour project has been created at <file-path>/example-project.\nThe configuration can be found in <file-path>/example-project/.env`\n\nLastly, navigate to your new project folder (in this case `example-project`) and start the platform:\n\n`bash\ncd example-project\nnpx directus start`\nPlease note: To prevent public accessibility when using the supabase-js library,turn on row level security (RLS) on all these tables inside of the Supabase Dashboard. By default when RLS is turned on these tables cannot be read from or written to with the supabase-js library.\nThat's it! Your project is now up and running locally. You can access the Directus Studio in the browser via the URL displayed, and log in with the Directus admin credentials you entered above:\n`bash\n\u2728 Server started at http://localhost:8055`\nIn a matter of minutes, we've created a flexible data backend, with access to an intuitive no-code app for managing and visualizing data along with a robust connectivity toolkit. This modern data stack is flexible and scalable enough to power any data-driven project\u2026 all you need to do is build the frontend!\nNext Steps\nFrom here, the sky's the limit on what you can build. You'll probably want to invite some new collaborators to your project and start architecting your data model.\nBelow are some additional resources to dive in and start exploring these two platforms:\nDirectus\n\nSee the Directus guides.\nJoin the Directus community on Discord.\nCheck out the source code on the official Directus GitHub Repo.\n\nSupabase\n\nExplore the Supabase documentation\nJoin the Supabase community on Discord\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Set up your Backend on Supabase",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/plasmic.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'plasmic',\n  title: 'Plasmic',\n  description:\n    'Get started with Supabase and Plasmic, an open-source framework for building internal tools.',\n}\nIn this guide, we will show you how to build a crowd-sourced Pokemon Pokedex, by connecting Supabase, an open source Firebase backend alternative, with Plasmic, a visual builder for the web. While many users leverage Plasmic to quickly launch and iterate on landing pages, in this tutorial we\u2019ll show just how powerful Plasmic can be as a general-purpose visual builder for React, which can be used to design and implement fully featured read-write applications.\nYou can play with the live demo here:\nhttps://plasmic-supabase-demo.vercel.app/\nYou can also take a look at the Plasmic project here:\nhttps://studio.plasmic.app/projects/66RKaSPCwKxYjCfXWHCxn6\n\nYou\u2019ll need to enable 3rd-party cookies in your browser for the project to properly load.\n\n\nAt a high level,\n\nSupabase is used to store the database of Pokemon (backed by Postgres) and provides an authentication backend. Our code base includes React components for querying the database, displaying this data, and supporting user sessions.\nPlasmic is used to create the pages and visual design of the application. We import our Supabase components into the Studio, which can be visually assembled and configured there (e.g. for displaying data).\nPlasmic designed pages are rendered back into the Next.js application.\n\nStep 1: Set up your Backend on Supabase\n\nOn the Supabase dashboard, click `New project` and set the name of the project.\n  By default, Supabase will already be set up for user signups with email, with users being stored in a `users` table.\n\n\n\nNavigate to the `Table Editor` on the left side navigation bar. Here we can create a `New table` to store our Pokemon entries. Make sure you are in the `schema public` view. Create a new table called `entries`, with 6 columns:\n`id`: is a unique ID for the entry. This column should be generated automatically as the primary column.\n`user_id`: Create a relation to the `user` table by clicking on the link icon next to the column name. Here, you can select the `id` column of the `user` table.\n`name`, `description`, `imageUrl`: This will store the name, description, and imageUrl for each Pokemon.\n`inserted_at` : This will be an automatically populated column, set to when the row was first inserted.\n\n\nNote: In this tutorial we\u2019ve turned off \u201cRow Level Security (RLS)\u201d. In practice, you will want to create policies that restrict who gets to create, edit, and delete posts. By turning this off, any user can modify the database without restrictions.\n\n\nFor your convenience, feel free to import the following CSV into Supabase to pre-populate your database. In order to import, you must select `Import data via spreadsheet`, in the new table dialog box. (It does not work on existing tables.)\npokedex-export.csv\nStep 2: Set up your codebase\nWe have a working code example for you here. This starter comes with all of the code components you need to get started querying Supabase through Plasmic Studio.\n\nCode components are React components defined in your code base that we import into Plasmic Studio for use. Your project will be configured to look for these at `http://localhost:3000/plasmic-host` You can use these components in your design, as well as style them. Check out `supabase-demo/plasmic-init.ts` to see how they are registered with Plasmic.\n\nFirst, clone the repo to your development machine and install the dependencies.\n`bash\ngit clone git@github.com:plasmicapp/plasmic.git\ncd plasmic/examples/supabase-demo/\nyarn install`\nCopy `.env.example` to `.env.local`, which will store the environment variables when running a local development server. Add your Supabase project\u2019s URL and public key, which you can find in the `API` tab on the left pane of your Supabase dashboard.\nNow run the dev server, which listens at `http://localhost:3000`\n`bash\nyarn dev`\nStep 3: Explore the existing application\nNavigate to http://localhost:3000 in your web browser. The project will already be set up for user signups, logins, and an admin interface for adding and editing Pokemon to the database. Feel free to sign up with your email address for an account and add Pokemon to the database. Supabase will require that you verify your email address before you can log in.\nIf you pre-populated the database in Step 1. you should see the following homepage after logging in. Otherwise, feel free to add Pokemon manually via the UI.\n\nStep 4: Clone the Plasmic project\nNow let\u2019s try to make some additions! The code base is currently configured to a read-only copy of the Plasmic project. Let\u2019s make an editable copy first.\nOpen the default starter Plasmic project here:\nhttps://studio.plasmic.app/projects/66RKaSPCwKxYjCfXWHCxn6\n\nTo make an editable copy, click on the `Copy Project` button in the blue bar. This will clone the project and redirect you to your copy.\nStep 4a: Configure your code base to use the new Plasmic project\nTake note of the `project ID` and `API token`. You can find the project ID in the URL:\n`https://studio.plasmic.app/projects/PROJECTID`.\nThe API token can be found by clicking the `Code` button in the top bar.\n\nNow go back to `.env.local` and update the corresponding project ID and token fields.\nStep 4b: Configure your Plasmic project app host\nTo tell Plasmic to look for your code components on your dev server, you\u2019ll need to update your project\u2019s app host to `http://localhost:3000/plasmic-host`.\n\nNote: At this point, you\u2019ll need to keep your dev server running at `http://localhost:3000`for the project to load.\n\n\n\n\nAfter restarting the dev server and Plasmic Studio, you should now be able to make edits across Plasmic Studio and your codebase.\nStep 5: Create a new page for our Pokedex gallery\nLet\u2019s make a visual gallery for our Pokemon by using the code components from the code base.\nCreate a new page called `Gallery`, and set a path for this page (`/gallery`).\n\n\n\nInsert a `SupabaseGrid` by searching the AddDrawer (by clicking the blue + button)\n\nFor source see `components/CodeComponents/DatabaseComponents.tsx`\n\n\nThen in the right-hand panel, configure the props on `SupabaseGrid`.\n\n`tableName` should match the table you created in Supabase\n`tableColumns` are a comma-delimited list of columns you want to select from the table\nWe also set the number of columns and spacing shown in the grid\n\n\nThe `SupabaseGrid` will loop over the rows from the query.\nNow customize the repeated content by inserting instances of `SupabaseField`. Select the type of content and a selector string to fetch a single value. In the example below, we use `{{row.imageUrl}}` to retrieve the `imageUrl` column of the row. Apply any styling and layout you want on these elements.\n\nPutting it all together (video)\nFor your convenience, the following video shows you how to create the page end-to-end.\n\n\n\nStep 6: Check your dev server\nIf you have been running your development server this whole time, you\u2019ll see that we have been automatically fetching and rebuilding your site as you make changes in Plasmic Studio. If you need to restart your dev server, just run:\n`bash\nyarn dev`\nSee the results at `http://localhost:3000/gallery`.\nHow does this all work under the hood?\nSupabaseGrid\n`SupabaseGrid` is a code component that was registered in `plasmic-init.ts`. The `props` field is used to tell the Plasmic Studio the component prop interface, which allows us to expose these props in the right pane as shown in the screenshots earlier. See the docs for details on component registration.\n```tsx\n// plasmic-init.ts\n...\nPLASMIC.registerComponent(SupabaseGrid, {\n  name: \"SupabaseGrid\",\n  props: {\n    tableName: \"string\",\n    tableColumns: \"string\",\n    queryFilters: \"object\",\n    children: {\n      type: \"slot\",\n      defaultValue: {\n        type: \"text\",\n        value: \"Placeholder\",\n      },\n    },\n    numColumns: {\n      type: \"number\",\n      defaultValue: 4,\n    },\n    columnGap: {\n      type: \"number\",\n      defaultValue: 16,\n    },\n    rowGap: {\n      type: \"number\",\n      defaultValue: 16,\n    },\n    count: \"number\",\n    loading: {\n      type: \"slot\",\n      defaultValue: {\n        type: \"text\",\n        value: \"Loading...\",\n      },\n    },\n  },\n  importPath: \"./components/CodeComponents/DisplayCollections\",\n});\n```\nSupabaseQuery\n`SupabaseGrid` wraps a `SupabaseQuery` component, where we perform the query based on the provided props and store the result in a `SupabaseQueryContext`. This will be used in downstream components to display the data.\n```tsx\n// supabase-demo/components/CodeComponents/DatabaseComponents.tsx\nexport function SupabaseQuery(props: SupabaseQueryProps) {\n    // These props are set in the Plasmic Studio\n  const { children, tableName, columns, className, filters, single } = props;\n  const [result, setResult] = React.useState(undefined);\n...\n\n\n```// Performs the Supabase query\n  let query = supabase.from(tableName!).select(columns + \",id\");\n  query = applyFilter(query, validFilters, contexts);\n  const { data, error, status } = await (single ? query.single() : query.order('id', { ascending: false }));\n\n  if (error && status !== 406) {\n    throw error;\n  } else if (data) {\n    setResult(data);\n  }\n```\n\n\n...\n\n\n```// Save the result in a `SupabaseQueryContext for use with downstream components\n```\n\n\nreturn (\n    \n\n        {children}\n      \n\n  );\n}\n```\nNote that this code component is defined in your codebase. Feel free to augment it to expose more powerful querying capabilities to the Plasmic Studio.\nSupabaseGridCollection\n`SupabaseGrid` also nests a `SupabaseGridCollection` under the `SupabaseQuery`. This code component is a simple CSS grid, where we retrieve the Supabase query results from `SupabaseQueryContext`, and iterate over the results. For each row, we populate a `RowContext`, which will be used by the children to read the results of a single row. Note the use of `repeatedElement`, a special convenience function that enables the component\u2019s children to be repeated. In this case, this represents a single card to be shown in the gallery.\n```tsx\n// supabase-demo/components/CodeComponents/DisplayCollections.tsx\nexport function SupabaseGridCollection(props: SupabaseGridCollectionProps) {\n  const supabaseQuery = React.useContext(SupabaseQueryContext)\n  const { children, columns, columnGap, rowGap, count, className, loading, testLoading } = props\nconst result = supabaseQuery\n  if (!result || testLoading) {\n    return loading\n  }\nreturn (\n    repeat(${columns}, 1fr),\n        columnGap: `${columnGap}px`,\n        rowGap: `${rowGap}px`,\n      }}\n      className={className}\n    >\n      {result.slice(0, count).map((row: any, i: any) => (\n        \n{repeatedElement(i === 0, children)}\n\n      ))}\n    \n  )\n}\n```\nSupabaseField\n`SupabaseField` will either render a `SupabaseTextField` or `SupabaseImgField` depending on the type. These code components simply read a single value from the contexts and display the data.\n```tsx\n// supabase-demo/components/CodeComponents/DisplayCollections.tsx\nexport function SupabaseTextField({ name, className }: { name?: string; className?: string }) {\n  const contexts = useAllContexts()\n  if (!name) {\n    return You need to set the name prop\n  }\n  return {getPropValue(name, contexts)}\n}\n```\nIn summary, by populating state into React contexts, we can store and retrieve data for use in other code components, which can be used for arbitrarily powerful interactions in Plasmic Studio.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Setting up Supabase",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/zuplo.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'zuplo',\n  title: 'Zuplo',\n  description: 'Building a public API backed by Supabase.',\n}\nZuplo is a fully-managed API gateway that offers the easiest way to securely and safely share your API. In this guide we look at how you can combine Zuplo and Supabase to create a public API with rate-limiting, a self-serve developer portal, and API-key authentication. There is an accompanying video for this article.\n\nIn this example we're going to work with a simple table that allows people to read and write entries to a Supabase table that contains some reviews of skis. Because this is an API for developers, we have to assume that they may be calling it from another backend service and can't login as a user using the standard Supabase method. In this scenario, API keys are often a better choice - see Wait, you're not using API keys?.\nWe'll allow people, with a valid API key, to read data from the ski results table and to create new records. Hopefully it's obvious that there are many ways that you can extend this example to add more behavior like roles based access, with custom policies, custom handlers and more.\nSetting up Supabase\nIf you haven't already, create a new project in Supabase and create a table called ski-reviews with the following columns:\n\nid (int8)\ncreated_at (timestamptz)\nmake (varchar)\nmodel (varchar)\nyear (int8)\nrating (int2)\nauthor (varchar)\n\nManually enter a couple of rows of data, so that we have something to read from the DB.\nThe `Get all` reviews route in Zuplo\nLogin to Zuplo at portal.zuplo.com and create a new project in Zuplo - I went with `supabase-ski-reviews`.\nSelect the File tab and choose Routes. Add your first route with the following settings:\n\nmethod: `GET`\npath: `/reviews`\nsummary: `Get all reviews`\nversion: `v1`\nCORS: `Anything goes`\n\nAnd in the request handler section, paste the `READ ALL ROWS` URL of your Supabase backend (you can get to this in the API docs section of Supabase)\n\nURL Rewrite: `https://YOUR_SUPABASE_URL.supabase.co/rest/v1/ski-reviews?select=*`\nForward Search: `unchecked`\n\nIn order to call the Supabase backend I need to add some authentication headers to the outgoing request.\nExpand the Policies section of your route. Click Add policy on the Request pipeline.\nWe don't want to forward any headers that the client sends us to Supabase, so find the Clear Headers Policy and add that to your inbound pipeline. Note, that we will allow the `content-type` header to flow through, so this should be your policy config.\n`json\n{\n  \"export\": \"ClearHeadersInboundPolicy\",\n  \"module\": \"$import(@zuplo/runtime)\",\n  \"options\": {\n    \"exclude\": [\"content-type\"]\n  }\n}`\nNext, we need to add the credentials to the outgoing request. We'll need to get the JWT token from supabase - you'll find it in Settings > API as shown below:\n\nOnce you've got your service_role JWT, click Add Policy again on the Request pipeline and choose the Add/Set Headers Policy and configure it as follows:\n`json\n{\n  \"export\": \"SetHeadersInboundPolicy\",\n  \"module\": \"$import(@zuplo/runtime)\",\n  \"options\": {\n    \"headers\": [\n      {\n        \"name\": \"apikey\",\n        \"value\": \"$env(SUPABASE_API_KEY)\",\n        \"overwrite\": true\n      },\n      {\n        \"name\": \"authorization\",\n        \"value\": \"$env(SUPABASE_AUTHZ_HEADER)\",\n        \"overwrite\": true\n      }\n    ]\n  }\n}`\nSave your changes.\nNext, create two secret environment variables as follows:\n\nSUPABASE_API_KEY: `\"YOUR_SUPABASE_SECRET_ROLE_JWT\"`\nSUPABASE_AUTHZ_HEADER: `\"Bearer YOUR_SUPABASE_SECRET_ROLE_JWT\"`\n\nObviously, in both instances replace `YOUR_SUPABASE_SECRET_ROLE_JWT` with your service_role JWT from Supabase.\nYou are now ready to invoke your API gateway and see data flow through from your Supabase backend!\nClick on the open in browser button shown below and you should see the JSON, flowing from Supabase in your browser \ud83d\udc4f.\n\nAdding authentication\nAt this point, that route is wide open to the world so we need to secure it. We'll do this using API keys. You can follow this guide Add API key Authentication. Be sure to drag the API Key authentication policy to the very top of your Request pipeline. Come back here when you're done.\nWelcome back! You've now learned how to secure your API with API-Keys.\nAdding a Create route\nNext we'll add a route that allows somebody to create a review. Add another route with the following settings\n\nmethod: `POST`\npath: `/reviews`\nsummary: `Create a new review`\nversion: `v1`\nCORS: `Anything goes`\n\nAnd the request handler as follows:\n\nURL Rewrite: `https://YOUR_SUPABASE_URL.supabase.co/rest/v1/ski-reviews`\nForward Search: `unchecked`\n\nExpand the policies section and add the same policies (note you can reuse policies by picking from the existing policies at the top of the library)\n\n\napi-key-auth-inbound\nclear-headers-inbound\nset-headers-inbound\n\nNow your create route is secured and will automatically set the right headers before calling Supabase. That was easy.\nYou can test this out by using the API Test Console to invoke your new endpoint. Go to the API Test Console and create a new test called `create-review.json`.\n\nMethod: `POST`\nPath: `/v1/reviews`\nHeaders:\n`content-type`: `application/json`\n`authorization`: `Bearer YOUR_ZUPLO_API_KEY`\nBody:\n\n`json\n{\n  \"make\": \"Rossignol\",\n  \"model\": \"Soul HD7\",\n  \"rating\": 5,\n  \"year\": 2019\n}`\n\nIf you invoke your API by clicking `Test` you should see that you get a 201 Created - congratulations!\nAdd validation to your post\nTo make your API more usable and more secure it is good practice to validate incoming requests. In this case we will add a JSON Schema document and use it to validate the incoming body to our POST.\nCreate a new schema document called `new-review.json`.\n\nThis example fits the ski-reviews table we described above\n`json\n{\n  \"$id\": \"http://example.com/example.json\",\n  \"type\": \"object\",\n  \"default\": {},\n  \"title\": \"Root Schema\",\n  \"required\": [\"make\", \"model\", \"rating\", \"year\"],\n  \"additionalProperties\": false,\n  \"properties\": {\n    \"make\": {\n      \"type\": \"string\",\n      \"default\": \"\",\n      \"title\": \"The make Schema\",\n      \"examples\": [\"DPS\"]\n    },\n    \"model\": {\n      \"type\": \"string\",\n      \"default\": \"\",\n      \"title\": \"The model Schema\",\n      \"examples\": [\"Pagoda\"]\n    },\n    \"rating\": {\n      \"type\": \"integer\",\n      \"default\": 0,\n      \"title\": \"The rating Schema\",\n      \"examples\": [5]\n    },\n    \"year\": {\n      \"type\": \"integer\",\n      \"default\": 0,\n      \"title\": \"The year Schema\",\n      \"examples\": [2018]\n    }\n  },\n  \"examples\": [\n    {\n      \"make\": \"DPS\",\n      \"model\": \"Pagoda\",\n      \"rating\": 5,\n      \"year\": 2018,\n      \"author\": \"Josh\"\n    }\n  ]\n}`\nNow add a new policy to request pipeline for your `Create new review` route. Choose the JSON Body Validation policy and configure it to use your newly created JSON schema document:\n`json\n{\n  \"export\": \"ValidateJsonSchemaInbound\",\n  \"module\": \"$import(@zuplo/runtime)\",\n  \"options\": {\n    \"validator\": \"$import(./schemas/new-review.json)\"\n  }\n}`\nThis policy can be dragged to the first position in your pipeline.\nNow to test this is working, go back to your API test console and change the body of your `create-review.json` test to be invalid (add a new property for example). You should find that you get a `400 Bad Request` response.\n\nFinally, lean back and marvel at your beautiful Developer Portal that took almost zero effort to get this far, wow! Hopefully you already found the link for this when adding API key support :)\n\nZuplo can also be used to handle Supabase JWT tokens for any API, learn more at API Authentication with Supabase JWT Tokens\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: SignIn to Supabase",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/dhiwise.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'dhiwise',\n  title: 'DhiWise',\n  description:\n    'Get started with Supabase and DhiWise. Convert your Figma designs into Flutter apps, store data, and authenticate your users',\n}\nThis guide explains how to connect Supabase backend to DhiWise Flutter application quickly.\nDhiWise is a Developer tool to convert Figma designs into React and Flutter applications. It lets you quickly integrate Databases and APIs into your React and Flutter Apps.\nIf you don't have a DhiWise account, create one here.\nDhiWise supports easy Supabase Integration in just five steps.\nLet's get started!\nStep 1: SignIn to Supabase\nGo to Supabase, Click `Sign In`, and create a new account by authenticating with GitHub. If you already have an account, you will be logged in.\nStep 2: Create a new project in Supabase\nClick on `New project` from the Dashboard and select an organization. If you don't have an organization, create one using `+ New organization.`\n\nGive your Supabase project a `name.`\nEnter a secure `Database Password.`\nChoose the `region` where your app's backend is hosted.\nClick `Create new project.`\n\n\nStep 3: Find the API key and URL\nOnce your project is created, you can access the API Key and URL string, Or if you already have an account go to your `organization-> app-> settings-> API`.\n\nStep 4: Integrations\nThere are two ways you can integrate Supabase into your DhiWise Flutter applications.\nAuthentication\nYou can integrate `Supabase Email/Password SignUp` or `Supabase Email/Password SignIn` on your components.\n\nOpen the screen of your flutter application\nGo to the component on which you want to add authentication\non the `onClick` method - select `authentication`\nFrom the list, If you want SignUp - select `SignUp with Email/Password`; otherwise, select `SignIn with Email/Password` from Supabase Auth section\n\n\nAnd that's it. Supabase authentication will be added to the selected component.\nAfter downloading the application source code,\n\nAdd Supabase URL and Supabase public key inside lib/core/utils/initial_bindings file.\nFor additional details, refer https://supabase.com/docs/guides/with-flutter\n\nWorking with Data\nWhen you first integrate Supabase in your DhiWise Flutter application, You will be asked to add Supabase auth key and URL. When you add them, all the tables available in your Supabase project will be synced in DhiWise. You can integrate Select and Create queries on your Flutter screen for a particular table in DhiWise.\nSelect records\n\nStep 1:\nSelect the screen from the screen list where you want to integrate Supabase.\nStep 2:\nNext, go to the view where you want to add Integration, and from the suggestion box for the `onClick` property, choose `Supabase integration,` which will take you to the Integration screen. Where you will be asked to `Enter function name.` Enter the name of your function and click `Submit.`\nStep 3:\nAfter submitting the function name, you will be asked to select a type of Supabase integration. To retrieve data from Supabase, choose `select.`\nStep 4:\nNext, select the table from which you want to fetch records from the listed Tables.\nStep 5:\nSelect the type of integration\n| Type         | Description                                       |\n| ------------ | ------------------------------------------------- |\n| Single   | Used to fetch a single record from the database.  |\n| Multiple | Used to fetch multiple records from the database. |\n\nFor Multiple types, you need to set `data limit,` `order by, and`order.`\n\nStep 6:\nYou will be redirected to the API Integration screen, where you can set request and response.\nFor request binding, the below types are supported. Also, Select the operator for comparison before moving forward.\n| Type                    | Description                                                |\n| ----------------------- | ---------------------------------------------------------- |\n| View                | Select any component from your screen.                     |\n| Constant            | Select a constant you've created in your app.              |\n| Get from preference | Select the key you want to fetch from preference.          |\n| Navigation argument | Select data that's been passed from one screen to another. |\nFor response binding, the below types are supported.\n| Type                   | Description                           |\n| ---------------------- | ------------------------------------- |\n| View               | Select any component from the screen. |\n| Save to preference | Storing the data to preference.       |\nSelect 7:\n`Handle action` - Select the action you wish to take once the Supabase call has either been accepted successfully or refused due to an error.\nAvailable action for On success and On error are,\n\nShow Alert\nNavigation\n\nStep 8:\nFinally, you have added Supabase to your application to fetch records on your screen!\n\nSuppose you want to fetch records from Supabase and populate the item list on your screen. You can integrate Supabase as discussed above and bind the response with your list view.\n\n Create records \nStep 1:\nChoose the screen you wish to integrate Supabase for from the list of screens.\nStep 2:\nNext, switch to the component you want to add Integration, and on the `onClick` property, choose `Supabase integration,` which will take you to its integration screen, where you will be asked to Enter function name, which will be used in generated code. Enter the name for it and click `Submit`\nStep 3:\nAfter submitting the function name, you will be asked to select a type of Supabase integration. For example, to create a record in Supabase, choose `Create.`\nStep 4:\nNext, select the table where you want to create a record from the listed Tables.\nStep 5:\nIf you want to create a Single record, Select Select. Otherwise, Multiple.\nStep 6:\nNow, you will be redirected to the API Integration screen, where you can set request and response.\nFor request binding, the below types are supported.\n| Type                    | Description                                                |\n| ----------------------- | ---------------------------------------------------------- |\n| View                | Select any component from the screen                       |\n| Constant            | Select a constant you've created in your app.              |\n| Get from preference | Select the key you want to fetch from preference.          |\n| Navigation argument | Select data that's been passed from one screen to another. |\nFor response binding, the below types are supported.\n| Type                   | Description                          |\n| ---------------------- | ------------------------------------ |\n| View               | Select any component from the screen |\n| Save to preference | Storing the data to preference.      |\nSelect 7:\n`Handle action` - Select the action you wish to take once the Supabase call has either been accepted successfully or refused due to an error.\nAvailable action for On success and On error are,\n\nShow Alert\nNavigation\n\nStep 9:\nFinally, you have added Supabase to your application to create records from your screen data!\nResources\n\nDhiWise Official Website\nDhiWise Documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Connect Sequin to Supabase",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/sequin.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'sequin',\n  title: 'Sequin',\n  description:\n    'Sync platforms like Stripe and Salesforce with your Supabase database in real-time using Sequin.',\n}\nThis guide explains how to quickly setup a sync between Sequin and a Supabase Postgres database.\nSequin allows you to sync platforms like Stripe and Salesforce with Supabase in real-time. You'll be able to read and write to your Stripe customers or Salesforce accounts right from the Supabase client using SQL. Here's how to get setup.\nStep 1: Connect Sequin to Supabase\nTo connect Supabase to Sequin, you'll first need to retrieve the credentials for your Supabase Postgres database:\n\nIn the Supabase dashboard, go to the settings page and open up your Database settings. In the Connection info section, you'll find the credentials you need - like `host` and `user`:\n\n\n\nIn the Sequin console, go to your sync's configuration and open the Destination section. Select Launch or Connect and then click Connect to configure the connection to your Supabase Postgres:\n\n\n\nIn the connection modal that appears, enter the `Host` and `Port` for your Supabase database and click Continue.\n\n\n\nNow, enter the `Database name` and set the `schema` name for your sync. For instance, if your syncing Stripe, you'll likely want to name your synced schema something like `stripe`. Finally, enter the `user` and `password` for your Supabase database and then click Continue. Sequin will verify it can properly connect to your database with the correct permissions.\n\n\n\nSequin is now connected to your Supabase Postgres database and will ask you to confirm which database users should be able to access your synced schema. Select all of the users and click Continue:\n\n\n\nThat's it. Sequin will now create a new schema and permissions group in your Supabase database. Name the database connection in Sequin something like `Supabase` and your done!\n\nIn the Supabase dashboard, you can go to the Table Editor and you'll see a new schema full of your synced platform data.\n\nStep 2: Grant Permissions\nTo ensure the right users can access the synced schema Sequin manages, you'll need to run a couple permission grants.\n\nIn the Sequin console, click the Connect button next to your sync and copy down your `Schema` and unique `Read Group`.\n\n\n\nNow, in the Supabase dashboard, go to the SQL Editor and run the following permission grants:\n\n```sql\n   GRANT sequin_read_\u2592\u2592\u2592\u2592 TO postgres, anon, authenticated, service_role;\nGRANT USAGE ON SCHEMA {{your_schema_name}} TO anon, authenticated, service_role;\nGRANT ALL ON ALL TABLES IN SCHEMA {{your_schema_name}} TO anon, authenticated, service_role;\nALTER DEFAULT PRIVILEGES FOR ROLE postgres, supabase_admin IN SCHEMA {{your_schema_name}} GRANT ALL ON TABLES TO anon, authenticated, service_role;\n   ```\nThese permission grants ensure that the various Supabase database users can access and read all the tables in your synced schema.\nStep 3: Configure the Supabase Client\nFinally, you'll need to define a new Supabase client in your application to access your synced schema. In the file where you initialized your Supabase client, define a new client with a `schema` parameter:\n`javascript\nexport const supabase_schema = createClient(\n  'https://xyzcompany.supabase.co',\n  'public-anon-key',\n  {\n    schema: {{your_schema_name}},\n  }\n);`\nYou'll use this client to query for data in your synced schema.\nResources\n\nSequin official website.\nSequin Console.\nSequin documentation.\nSequin + Supabase + Stripe Tutorial\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 0: Create a PolyScale account",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/polyscale.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'polyscale',\n  title: 'PolyScale',\n  description:\n    'The easiest way to get low-latency reads from your Supabase database for multi-region applications is by using PolyScale, a code-free global caching service.',\n}\nPolyScale is an intelligent, serverless database caching engine which allows low-latency reads from Supabase globally, no coding required. Supabase can be connected to PolyScale in minutes, providing you fast access to your Supabase data around the globe.\nThis guide explains how to connect Supabase to a PolyScale cache.\nThe video below illustrates how to get connected. Or you can read the steps below.\n\n\n\nStep 0: Create a PolyScale account\nIf you do not already have a PolyScale account, you can create an account here. PolyScale offers a free tier and no credit card is required.\nStep 1: Create your PolyScale Cache\n1.1 Retrieve your Supabase Host\nIn your Supabase project, click on `Settings > Database` and scroll down to the `Connection info` section to copy your database `Host`.\n\n1.2 Configure your PolyScale Cache\n\nIn your PolyScale account, click on the New Cache button\nGive the cache a Name\nSelect PostgreSQL for the Type\nEnter the Host from Step 1.1 above\nEnter `5432` for the Port\nClick Create\n\n\nYour cache is now created. PolyScale automatically checks to see that your database is accessible from all our global PoPs.\nStep 2: Connect to your PolyScale Cache\nUsing your PolyScale cache is simple -- instead of connecting to your Supabase database directly, you'll replace your original connection string with the PolyScale connection string in your application.\nFor example, if your original connection string was: `postgres://postgres:zqSPGHFAbPLvVCKw@db.rogpiubvixysbakciwqz.supabase.co:5432`\nYour PolyScale connection string would be: `postgres://postgres:zqSPGHFAbPLvVCKw@psedge.global:5432?application_name=a645cb93-fa53-46b2-9d6c-227e357e5bfb`\nYou can read more about connecting to PolyScale here\nThat's it.\nAll done!\nYou can read more about PolyScale here or check out our documentation.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Create JWT template",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/clerk.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'clerk',\n  title: 'Clerk',\n  description:\n    'This guide explains how to connect your Supabase database with Clerk, a powerful authentication provider built for the modern web.',\n}\nThis guide explains how to connect your Supabase database with Clerk, an authentication provider built for the modern web.\nClerk authenticates users, manages session tokens, and provides user management functionality that can be used in combination with the authorization logic available in Supabase through PostgreSQL Row Level Security (RLS) policies.\nThis guide assumes you have a Supabase account and database project already set up.\nIf you don't have a Clerk account, you can create one now.\nStep 1: Create JWT template\nThe first step is to create a new Clerk application from your Clerk Dashboard if you haven't done so already. You can choose whichever authentication strategy and social login providers you prefer. For more information, check out Clerk's guide.\nAfter your Clerk application has been created, use the lefthand menu to navigate to the JWT Templates page.\nClick on the button to create a new template based on Supabase.\n\nThis will pre-populate the default claims required by Supabase. You can include additional claims or modify them as necessary. Shortcodes are also available for adding dynamic values.\n\u2139\ufe0f\u00a0Note the name of the JWT template (which you can change) because this will be needed later.\n\nStep 2: Sign JWT with Supabase secret\nSupabase requires JWTs be signed with the HS256 signing algorithm and use their signing key. Find the JWT secret key in your Supabase project under Settings > API in the Config section.\n\nClick to reveal the JWT secret, copy it, and then paste it in the Signing key field in the Clerk JWT template.\n\nAfter the key is added, click the Apply Changes button to save your template.\nStep 3: Configure client\nThe next step is to configure your client. Supabase provides an official JavaScript/TypeScript client library and there are libraries in other languages built by the community.\nThis guide will use a Next.js project with the JS client as an example, but the mechanism of setting the authentication token should be similar with other libraries and frameworks.\nAssuming a Next.js application, set the following environment variables in an `.env.local` file:\n`bash\nNEXT_PUBLIC_CLERK_FRONTEND_API=your-frontend-api\nNEXT_PUBLIC_SUPABASE_URL=your-supabase-url\nNEXT_PUBLIC_SUPABASE_KEY=your-supabase-anon-key`\nNote: If you're using Create React App, replace the `NEXT_PUBLIC` prefix with `REACT_APP`\nYour Clerk Frontend API can be found on the API Keys screen.\n\nTo get the ones needed for Supabase, navigate to the same Settings > API page as before and locate the anon public key and URL.\n\nNote: It is recommended that you enable Row Level Security (RLS) for your database tables and configure access policies as needed.\nAfter setting those three environment variables, you should be able to start up your application development server.\nInstall the JavaScript client for Supabase with:\n`bash\nnpm install @supabase/supabase-js`\nInitialize the Supabase client by passing it the environment variables.\nThis can be saved to a common file, for example as `lib/supabaseClient.js`\n```jsx\nimport { createClient } from '@supabase/supabase-js'\nconst supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL\nconst supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_KEY\nexport const supabase = createClient(supabaseUrl, supabaseKey)\nexport default supabase\n```\nStep 4: Set up Clerk Provider\nInstall the latest Clerk Next.js SDK by running the following:\n`bash\nnpm install @clerk/nextjs@next`\nNote: There is also a Clerk library for React and React Native with Expo.\nAfter the package is installed, wrap your application with the `<ClerkProvider />` component.\nIn a Next.js application, this is typically done in `pages/_app.js`:\n```jsx\nimport { ClerkProvider } from '@clerk/nextjs'\nfunction MyApp({ Component, pageProps }) {\n  return (\n    \n\n\n  )\n}\nexport default MyApp\n```\nStep 5: Set auth token with Supabase\nIn order to access the custom JWT, you can use the `getToken` function returned by the Clerk `useAuth` hook and pass it the name of your template (hopefully you remembered from earlier).\nNote: The `getToken({ template: <your-template-name> })` call is asynchronous and returns a Promise that needs to be resolved before accessing the token value. This token is short-lived for better security and should be called before every request to your Supabase backend. The caching and refreshing of the token is handled automatically by Clerk.\nCall `supabase.auth.setAuth(token)` to override the JWT on the current client. The JWT will then be sent to Supabase with all subsequent network requests.\n```jsx\nimport { useAuth } from '@clerk/nextjs'\nimport supabase from '../lib/supabaseClient'\nexport default function Home() {\n  const { getToken } = useAuth()\nconst fetchData = async () => {\n    // TODO #1: Replace with your JWT template name\n    const token = await getToken({ template: 'supabase' })\n\n\n```supabase.auth.setAuth(token)\n\n// TODO #2: Replace with your database table name\nconst { data, error } = await supabase.from('your_table').select()\n\n// TODO #3: Handle the response\n```\n\n\n}\nreturn (\n    \n      Fetch data\n    \n  )\n}\n```\nAccess user ID in RLS policies\nIt is common practice to need access to the user identifier on the database level, especially when working with RLS policies in Postgres. Although Supabase provides a special function `auth.uid()` to extract the user ID from the JWT, this does not work with Clerk. The workaround is to write a custom SQL function to read the `sub` property from the JWT claims.\nIn the SQL Editor section of the Supabase dashboard, click New Query and enter the following:\n`sql\ncreate or replace function requesting_user_id()\nreturns text\nlanguage sql stable\nas $$\n  select nullif(current_setting('request.jwt.claims', true)::json->>'sub', '')::text;\n$$;`\nThis will create a `requesting_user_id()` function that can be used within an RLS policy.\nFor example, this policy would check that the user making the request is authenticated and matches the `user_id` column of a todos table.\nAccess user ID in table column\nIf you would like the requesting user ID from the JWT to automatically populate a text type column in your database table, you can set the Default Value field to the previously defined `requesting_user_id()` function.\n\nResources\n\nClerk + Supabase starter repo\nNext.js + Supabase + Clerk tutorial\nClerk guide for Next.js Authentication\nClerk Community Discord channel\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Connect FlutterFlow to Supabase",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/flutterflow.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'flutterflow',\n  title: 'FlutterFlow',\n  description:\n    'FlutterFlow is a low-code tool that allows you to build Flutter apps incredibly fast.',\n  canonical: 'https://docs.flutterflow.io/actions/actions/backend-database/supabase',\n}\n\n  FlutterFlow and Supabase integration is currently in alpha, and supported features may be limited.\n\nFlutterFlow is a low-code builder for developing native mobile applications using Flutter. You can use the simple drag-and-drop interface to build your app faster than traditional development.\nThis guide gives you a quick overview of implementing basic CRUD operations using FlutterFlow and Supabase. You can find the full docs on FlutterFlow and Supabase here.\n\n\n\nStep 1: Connect FlutterFlow to Supabase\nBefore we dive into the code, this guide assumes that you have the following ready:\n\nSupabase project created\nHave setup tables in your Supabase project\nFlutterFlow project created\n\nYou can then connect your Supabase project to your FlutterFlow project with the following steps:\n\nIn your Supabase project, navigate to Project Settings > API. Copy the Project URL.\nReturn to FlutterFlow, navigate to Settings and Integrations > Integrations > Supabase. Turn on the toggle (i.e., enable Supabase) and paste the API URL.\nSimilarly, from the Supabase API section, copy the anon key (under Project API keys) and paste it inside the FlutterFlow > Settings and Integrations > Integrations > Supabase > Anon Key.\nClick on the Get Schema button. This will show the list of all tables with their schema (structure) created in Supabase.\n(Optional) If you have defined an Array for any Column Data Type in Supabase, you must set its type here. To do so, tap the \"Click to set Array type\" and choose the right one.\n\n\n\n\nStep 2: Inserting rows\nGo to your project page on FlutterFlow and follow the steps below to define the Action to any widget.\n\nSelect the Widget (e.g., Button) on which you want to define the action.\nSelect Actions from the Properties panel (the right menu), and click Open. This will open an Action flow Editor in a new popup window.\nClick on + Add Action.\nOn the right side, search and select the Supabase > Insert Row action.\nSet the Table to your table name (e.g., assignments).\nUnder the Set Fields section, click on the + Add Field button.\nClick on the Field name and scroll down to find the Value Source dropdown and change it to From Variable.\nClick on UNSET and select Widget State > Name of the TextField.\nSimilarly, add the field for the other UI elements.\n\n\n\n\nStep 3: Selecting and displaying rows\nTo query a Supabase table on a ListView:\n\nSelect the ListView widget. Make sure you choose the ListView widget, not the ListTile.\nSelect Backend Query from the properties panel (the right menu), and click Add Backend Query.\nSet the Query Type to Supabase Query.\nSelect your Table from the dropdown list\nSet the Query Type to List of Rows.\nOptional: If you want to display the limited result, say, for example, you have thousands of entries, but you want to display only 100, you can specify the limit.\nClick Confirm.\n\n\n\n\nStep 4: Updating rows\nGo to your project page on FlutterFlow and follow the steps below to define the Action to any widget.\n\nSelect the Widget (e.g., Button) on which you want to define the action.\nSelect Actions from the Properties panel (the right menu), and click Open. This will open an Action flow Editor in a new popup window.\nClick on + Add Action.\nOn the right side, search and select the Supabase > Update Row action.\nSet the Table to your table name (e.g., assignments).\nOptional: If you want to get the rows after the update is finished, enable the Return Matching Rows option.\nNow, you must set the row you want to update. Usually, this is done by finding a row in a table that matches the current row ID. To do so, click + Add Filter button inside the Matching Rows section.\nSet the Field Name to the field that contains the IDs. Typically, this is the id column.\nSet the Relation to Equal To because you want to find a row with the exact id.\nInto the Value Source, you can select the From Variable and provide the id of the row for which you just updated values in the UI.\n\n\nUnder the Set Fields section, click on the + Add Field button.\nClick on the field name.\nScroll down to find the Value Source dropdown and change it to From Variable.\nClick on UNSET and select Widget State > Name of the TextField.\nSimilarly, add the field for the other UI elements.\n\nStep 5: Deleting rows\nGo to your project page on FlutterFlow and follow the steps below to define the Action to any widget.\n\nSelect the Widget (e.g., Button) on which you want to define the action.\nSelect Actions from the Properties panel (the right menu), and click Open. This will open an Action flow Editor in a new popup window.\nClick on + Add Action.\nOn the right side, search and select the Supabase -> Delete Row action.\nSet the Table to your table name (e.g., assignments).\nOptional: Later, if you want to know which rows were deleted from a table, enable the Return Matching Rows option.\nNow, you must set the row you want to delete. Usually, this is done by finding a row in a table that matches the current row ID. To do so, click + Add Filter button inside the Matching Rows section.\nSet the Field Name to the field that contains the IDs. Typically, this is the id column.\nSet the Relation to Equal To because you want to find a row with the exact id.\nInto the Value Source, you can select the From Variable and provide the id of the row you want to delete.\n\n\n\n\n\n\nResources\nYou can find more detailed guides on FlutterFlow\u2019s docs.\n\nFlutterFlow Supabase available actions\nRetrieving Data from Supabase on FlutterFlow\nAdding data to Supabase DB from FlutterFlow\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Create a Supabase project",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/vercel.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'vercel',\n  title: 'Vercel',\n  description:\n    \"The fastest way to get up and running with an application that uses Supabase is with Vercel's Next.js starter and Supabase integration.\",\n}\nThis guide steps through using Vercel's dashboard to create a Next.js project integrated with Supabase. To further streamline the process, we will be using the Next.js starter template, which can be automatically forked to a new GitHub repo, without leaving the dashboard!\nIf you don\u2019t have a Vercel account, create one here.\nStep 1: Create a Supabase project\nThis guide could use an existing Supabase project, but to create the `todo` demo from scratch, navigate to Supabase, click `Sign In` and authenticate with GitHub to login or register a new account.\nFrom the Supabase dashboard, click `New project` and select an organization.\n\nNote: You may need to create an organization first.\n\nGive your project a `name`, `password`, select a `region` close to your potential users and click `Create new project`.\n\nSupabase will take a couple of minutes to configure the infrastructure.\nOnce this is finished, navigate to `SQL Editor` from the sidebar menu and click `New query`.\nThis will create a new SQL snippet called \"New Query\". Copy and paste the following and click `Run`.\n```sql\ncreate table todos (\n  id bigint generated by default as identity primary key,\n  title text,\n  is_complete boolean default false,\n  created_at timestamp with time zone default timezone('utc'::text, now()) not null\n);\nalter table todos enable row level security;\ncreate policy \"Anyone can view todos\" on todos for\n    select using (true);\ncreate policy \"Anyone can add new todos\" on todos for\n    insert with check (true);\ninsert into todos(title)\nvalues\n  ('Create Supabase project'),\n  ('Create Vercel project'),\n  ('Install Supabase integration');\n```\nThis will create a new todos table, enable row level security, add policies for selecting and inserting data, and add some example rows.\n\nNote: To simplify this example, we are allowing anyone to `select` and `insert` rows on the `todos` table. Usually, these actions would be locked down to only allow logged in users to perform them. Check out this video to learn more about Row Level Security and policies.\n\nStep 2: Create Vercel project\nFrom your Vercel dashboard, click `New Project`.\n\nUnder the `Clone Template` menu, click `Next.js`.\n\nIn the `Create Git Repository` section, click `GitHub`, select your username under `GIT SCOPE`, enter a name for your project, choose whether you want your repo `private` or `public`, and click `Create`.\n\nThis will create a new GitHub repository, clone and commit the Next.js starter project, then build and deploy your new project to Vercel.\nOnce you have been redirected to the `Congratulations` screen, click `Go to Dashboard`.\nNavigate to `Settings`, `Integrations`, then click `Browse Marketplace`.\nSearch for `Supabase` and click the Supabase integration.\n\nClick `Add Integration`. Select your account from the `Vercel Scope` dropdown, and click `CONTINUE`.\n\nChoose `Specific Projects` and select your new Vercel project from the dropdown, and click `Add Integration`.\n\nFrom the Supabase popup, select your new Vercel Project and Supabase project from the dropdowns.\n\nStep 3: Clone GitHub repo\nThe fastest way to get this project running locally is to clone the repo that Vercel created for us.\nNavigate back to the Vercel project `Overview` page, and click `View Git Repository`.\n\nThis will open the GitHub repo. From here, click the arrow next to `Code` and copy the url from the dropdown.\n\nOpen a terminal window or CLI and run the following command to clone the GitHub repo.\n`bash\ngit clone your-repo-url.git`\nOpen the project in your code editor of choice, and update the contents of `pages/index.js` to the following:\n```jsx\nimport styles from '../styles/Home.module.css'\nexport default function Home() {\n  return working\n}\n```\nRun a local development server.\n`bash\nnpm run dev`\nNavigate to `http://localhost:3000` to confirm the project is \"working\".\nStep 4: Pull environment variables from Vercel\nFirst, we need to login to Vercel using their CLI tool.\n`bash\nnpx vercel login`\nThis will ask if we are happy to install `vercel`. Type `y` and hit `Enter`.\nWe will then need to authenticate Vercel by selecting `Continue with GitHub`.\nThis will open a browser window where you need to authenticate with your GitHub account.\nNext, we need to link our Vercel project.\n`bash\nnpx vercel link`\nStep through the prompts to link the Vercel project.\n\nCopy the environment variables from our Vercel project.\n`bash\nnpx vercel env pull`\nThis will create a `.env` file containing our Supabase environment variables. Rename this file to `.env.local` to automatically ignore it from git.\nStep 5: Install Supabase.js\nInstall the `supabase-js` library.\n`bash\nnpm i @supabase/supabase-js`\nCreate a new file called `/utils/supabase.js` and add the following.\n```jsx\nimport { createClient } from '@supabase/supabase-js'\nexport default createClient(\n  process.env.NEXT_PUBLIC_SUPABASE_URL,\n  process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY\n)\n```\nCreate a new file called `/components/NewTodo.js` and add the following.\n```jsx\nimport { useState } from 'react'\nimport supabase from '../utils/supabase'\nexport default ({ reload }) => {\n  const [title, setTitle] = useState('')\nconst addTodo = async (e) => {\n    e.preventDefault()\n    await supabase.from('todos').insert({ title })\n    reload()\n    setTitle('')\n  }\nreturn (\n    \n setTitle(e.target.value)} />\n    \n  )\n}\n```\nThis component will be responsible for writing a new `todo` to Supabase.\nLet's import our new component in `pages/index.js` and display a list of todos.\n```jsx\nimport { useState, useEffect } from 'react'\nimport styles from '../styles/Home.module.css'\nimport supabase from '../utils/supabase'\nimport NewTodo from '../components/NewTodo'\nexport default function Home() {\n  const [todos, setTodos] = useState([])\nconst fetchTodos = async () => {\n    const { data } = await supabase.from('todos').select('*')\n    setTodos(data)\n  }\nuseEffect(() => {\n    fetchTodos()\n  }, [])\nreturn (\n    \n\n      {todos.map((todo) => (\n        {todo.title}\n      ))}\n    \n  )\n}\n```\nResources\n\nVercel official website.\nVercel blog.\nVercel docs.\nVercel Integration docs\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Build an integration",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/integrations.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'integrations',\n  title: 'Supabase Marketplace',\n  description: 'Integrations and Partners',\n}\nThe Supabase Marketplace brings together all the tools you need to extend your Supabase project. This includes:\n\nExperts - partners to help you build and support your Supabase project.\nIntegrations - extend your projects with external Auth, Caching, Hosting, and Low-code tools.\n\nBuild an integration\nSupabase provides several integration points:\n\nThe Postgres connection. Anything that works with Postgres also works with Supabase projects.\nThe Project REST API & client libraries.\nThe Project GraphQL API.\nThe Platform API.\n\nList your integration\nApply to the Partners program to list your integration in the Partners marketplace and in the Supabase docs.\nIntegrations are assessed on the following criteria:\n\nBusiness viability\n  While we welcome everyone to built an integration, we only list companies that are deemed to be long-term viable. This includes an official business registration and bank account, meaningful revenue, or Venture Capital backing. We require this criteria to ensure the health of the marketplace.\nCompliance\n  Integrations should not infringe on the Supabase brand/trademark. In short, you cannot use \"Supabase\" in the name. As the listing appears on the Supabase domain, we don't want to mislead developers into thinking that an integration is an official product.\nService Level Agreements\n  All listings are required to have their own Terms and Conditions, Privacy Policy, and Acceptable Use Policy, and the company must have resources to meet their SLAs.\nMaintainability\n  All integrations are required to be maintained and functional with Supabase, and the company may be assessed on your ability to remain functional over a long time horizon.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Get the query plan from Supabase",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/pgmustard.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'pgmustard',\n  title: 'pgMustard',\n  description:\n    'Troubleshoot slow queries on Supabase with pgMustard, a visualization tool that also gives advice.',\n}\nThis guide explains how to troubleshoot slow queries on Supabase using `explain` and pgMustard.\npgMustard is a visualization tool for explain analyze that also gives performance tips.\nStep 1: Get the query plan from Supabase\nUse `explain analyze` to get a query plan from Postgres. This will run the query behind the scenes, so be careful with data modification queries.\npgMustard requires plans to be in json format, and the buffers, verbose, and settings parameters allow it to give better tips.\nSo a good prefix for your query would be:\n`jsx\nexplain (analyze, format json, buffers, verbose, settings)`\nRun the query, and copy the output.\n\nIf you\u2019re using the Supabase SQL Editor, this is easily copied from the cell titled `QUERY PLAN`, as seen above.\nIf you have any trouble, check out pgMustard\u2019s guide for getting a query plan.\nStep 2: Paste the query plan into pgMustard\nPaste the json output into pgMustard and press Submit.\n\nStep 3: Look through the top tips and slowest operations\nReview the top tips in pgMustard. These are scored on a scale of 0 to 5 stars, based on how much time-saving potential they have (5 stars meaning lots of potential).\n\nClick one of the tips, or one of the operations, to see more information.\n\nStep 4: Consider your options\nIf you get some promising suggestions, you may wish to explore them.\nIf you don\u2019t get any tips, your query might be quite fast for the amount of work it\u2019s doing.\nFor the example we saw in Step 3, let's try adding an index on the `customer_name` field in Supabase.\n\nGoing through Steps 1-3 again, we now get an efficient index scan, that will scale nicely as our data grows.\n\nWe could look into why Postgres isn\u2019t choosing to do an index-only scan here, but pgMustard is letting us know that it doesn\u2019t think we\u2019ll gain much by doing so, by scoring the tip 0.3 out of 5.\nResources\n\npgMustard official website.\npgMustard explain glossary.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "How it works",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/authsignal.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'authsignal',\n  title: 'Authsignal',\n  description:\n    'Add an MFA step after sign-in. Use Supabase Auth to sign in with email and password and Authsignal to initiate an Authenticator App challenge.',\n}\nThis guide shows how to integrate Authsignal with Next.js and Supabase in order to add an MFA step after sign-in.\nThe user flow is as follows:\n\nThe user enters their email and password to sign in\nIf the user has set up MFA, they're prompted to complete an MFA challenge (via Authenticator App) in order to complete sign-in\nIf the user has not set up MFA, they're signed in immediately and will see a button to set up MFA\n\nThe approach uses a temporary encrypted cookie to ensure that the Supabase auth cookies (`access_token` and `refresh_token`) are only set if the MFA challenge was successful. Session data is encrypted using @hapi/iron.\nThe full code version of this example can be found here.\nA live demo can be found here.\nHow it works\n\nA sign-in form posts email and password to the Next.js API route `/api/sign-in`\nThe `signIn` API route calls the Supabase client's `signInWithEmail` method and gets back a session object\nThe `signIn` API route then calls the Authsignal client's `track` method to determine if an MFA challenge is required\nIf a challenge is required, the `signIn` API route saves the session object in a temporary encrypted cookie and redirects to Authsignal\nOnce the challenge is completed, Authsignal redirects back to `/api/callback` which retrieves the session and sets the Supabase auth cookies\nThe `callback` API route then redirects to the index page which is protected with Supabase's `withPageAuth` wrapper around `getServerSideProps`\n\nStep 1: Configuring an Authsignal tenant\nGo to the Authsignal Portal and create a new project and tenant.\nYou will also need to enable at least one authenticator for your tenant - for example Authenticator Apps.\nFinally, to configure the sign-in action to always challenge, go here and set the default action outcome to `CHALLENGE` and click save.\n\nStep 2: Creating a Supabase project\nFrom your Supabase dashboard, click `New project`.\nEnter a `Name` for your Supabase project and enter or generate a secure `Database Password`, then click `Create new project`.\nOnce your project is created go to `Authentication -> Settings -> Auth Providers` and ensure `Enable Email provider` is checked and that `Confirm Email` is unchecked.\n\nStep 3: Building a Next.js app\nCreate a new Next.js project:\n`bash\nnpx create-next-app --typescript supabase-authsignal-example\ncd supabase-authsignal-example`\nCreate a `.env.local` file and enter the following values:\n`sh\nNEXT_PUBLIC_SUPABASE_URL=get-from-supabase-dashboard\nNEXT_PUBLIC_SUPABASE_ANON_KEY=get-from-supabase-dashboard\nAUTHSIGNAL_SECRET=get-from-authsignal-dashboard\nTEMP_TOKEN_SECRET=this-is-a-secret-value-with-at-least-32-characters`\nSupabase values can be found under `Settings > API` for your project.\nAuthsignal values can be found under `Settings > API Keys` for your tenant.\n`TEMP_TOKEN_SECRET` is used to encrypt the temporary cookie. Set it to a random 32 character length string.\nRestart your Next.js development server to read in the new values from `.env.local`.\n`bash\nnpm run dev`\nStep 4: Installing dependencies\nInstall the Supabase client and Auth helpers for Next.js:\n`bash\nnpm install @supabase/supabase-js @supabase/auth-helpers-nextjs`\nInstall the Authsignal Node.js client:\n`bash\nnpm install @authsignal/node`\nFinally install 2 packages to help encrypt and serialize session data in cookies:\n`bash\nnpm install @hapi/iron cookie\nnpm install --save-dev @types/cookie`\nStep 5: Initializing the Authsignal client\nAdd the following code to `/lib/authsignal.ts`:\n```ts\nimport { Authsignal } from '@authsignal/node'\nconst secret = process.env.AUTHSIGNAL_SECRET\nif (!secret) {\n  throw new Error('AUTHSIGNAL_SECRET is undefined')\n}\nconst redirectUrl = 'http://localhost:3000/api/callback'\nexport const authsignal = new Authsignal({ secret, redirectUrl })\n```\nThe `redirectUrl` here is a Next.js API route which Authsignal will redirect back to after an MFA challenge. We'll implement this below.\nStep 6: Managing session data in cookies\nNext we will add some helper functions for managing cookies:\n\n`setTempCookie` encrypts and serializes the Supabase session data and sets it in a temporary cookie\n`getSessionFromTempCookie` decrypts and parses this session data back from the cookie\n`setAuthCookie` sets the Supabase auth cookies (`access_token` and `refresh_token`) and clears the temporary cookie\n\nAdd the following code to `/lib/cookies.ts`:\n```ts\nimport Iron from '@hapi/iron'\nimport { Session } from '@supabase/supabase-js'\nimport { parse, serialize } from 'cookie'\nimport { NextApiRequest, NextApiResponse } from 'next'\nexport async function setTempCookie(session: Session, res: NextApiResponse) {\n  const token = await Iron.seal(session, TEMP_TOKEN_SECRET, Iron.defaults)\nconst cookie = serialize(TEMP_COOKIE, token, {\n    maxAge: session.expires_in,\n    httpOnly: true,\n    secure: process.env.NODE_ENV === 'production',\n    path: '/',\n    sameSite: 'lax',\n  })\nres.setHeader('Set-Cookie', cookie)\n}\nexport async function getSessionFromTempCookie(req: NextApiRequest): Promise {\n  const cookie = req.headers.cookie as string\nconst cookies = parse(cookie ?? '')\nconst tempCookie = cookies[TEMP_COOKIE]\nif (!tempCookie) {\n    return undefined\n  }\nconst session = await Iron.unseal(tempCookie, TEMP_TOKEN_SECRET, Iron.defaults)\nreturn session\n}\nexport function setAuthCookie(session: Session, res: NextApiResponse) {\n  const { access_token, refresh_token, expires_in } = session\nconst authCookies = [\n    { name: ACCESS_TOKEN_COOKIE, value: access_token },\n    refresh_token ? { name: REFRESH_TOKEN_COOKIE, value: refresh_token } : undefined,\n  ]\n    .filter(isDefined)\n    .map(({ name, value }) =>\n      serialize(name, value, {\n        maxAge: expires_in,\n        httpOnly: true,\n        secure: process.env.NODE_ENV === 'production',\n        path: '/',\n        sameSite: 'lax',\n      })\n    )\n// Also clear the temp cookie\n  const updatedCookies = [...authCookies, serialize(TEMP_COOKIE, '', { maxAge: -1, path: '/' })]\nres.setHeader('Set-Cookie', updatedCookies)\n}\nconst isDefined = (value: T | undefined): value is T => !!value\nconst TEMP_TOKEN_SECRET = process.env.TEMP_TOKEN_SECRET!\nconst TEMP_COOKIE = 'as-mfa-cookie'\nconst ACCESS_TOKEN_COOKIE = 'sb-access-token'\nconst REFRESH_TOKEN_COOKIE = 'sb-refresh-token'\n```\nStep 7: Building the UI\nWe will add some form components for signing in and signing up as well as a basic home page.\nAdd the following code to `/pages/sign-up.tsx`:\n```ts\nimport Link from 'next/link'\nimport { useRouter } from 'next/router'\nexport default function SignUpPage() {\n  const router = useRouter()\nreturn (\n    \n {\n          e.preventDefault()\n\n\n```      const target = e.target as typeof e.target & {\n        email: { value: string }\n        password: { value: string }\n      }\n\n      const email = target.email.value\n      const password = target.password.value\n\n      await fetch('/api/sign-up', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email, password }),\n      }).then((res) => res.json())\n\n      router.push('/')\n    }}\n  >\n    <label htmlFor=\"email\">Email</label>\n    <input id=\"email\" type=\"email\" name=\"email\" required />\n    <label htmlFor=\"password\">Password</label>\n    <input id=\"password\" type=\"password\" name=\"password\" required />\n    <button type=\"submit\">Sign up</button>\n  </form>\n  <div>\n    {'Already have an account? '}\n    <Link href=\"sign-in\">\n      <a>Sign in</a>\n    </Link>\n  </div>\n</main>\n```\n\n\n)\n}\n```\nThen add the following code to `/pages/sign-in.tsx`:\n```ts\nimport Link from 'next/link'\nimport { useRouter } from 'next/router'\nexport default function SignInPage() {\n  const router = useRouter()\nreturn (\n    \n {\n          e.preventDefault()\n\n\n```      const target = e.target as typeof e.target & {\n        email: { value: string }\n        password: { value: string }\n      }\n\n      const email = target.email.value\n      const password = target.password.value\n\n      const { state, mfaUrl } = await fetch('/api/sign-in', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email, password }),\n      }).then((res) => res.json())\n\n      if (state === 'CHALLENGE_REQUIRED') {\n        window.location.href = mfaUrl\n      } else {\n        router.push('/')\n      }\n    }}\n  >\n    <label htmlFor=\"email\">Email</label>\n    <input id=\"email\" type=\"email\" name=\"email\" required />\n    <label htmlFor=\"password\">Password</label>\n    <input id=\"password\" type=\"password\" name=\"password\" required />\n    <button type=\"submit\">Sign in</button>\n  </form>\n  <div>\n    {\"Don't have an account? \"}\n    <Link href=\"sign-up\">\n      <a>Sign up</a>\n    </Link>\n  </div>\n</main>\n```\n\n\n)\n}\n```\nNow we will use Supabase's `withPageAuth` wrapper around `getServerSideProps` to make the home page require authentication via SSR. Replace the existing code in `/pages/index.tsx` with the following:\n```ts\nimport { getUser, User, withPageAuth } from '@supabase/auth-helpers-nextjs'\nimport { GetServerSideProps } from 'next'\nimport { useRouter } from 'next/router'\nimport { authsignal } from '../lib/authsignal'\ninterface Props {\n  user: User\n  isEnrolled: boolean\n}\nexport const getServerSideProps: GetServerSideProps = withPageAuth({\n  redirectTo: '/sign-in',\n  async getServerSideProps(ctx) {\n    const { user } = await getUser(ctx)\n\n\n```const { isEnrolled } = await authsignal.getUser({ userId: user.id })\n\nreturn {\n  props: { user, isEnrolled },\n}\n```\n\n\n},\n})\nexport default function HomePage({ user, isEnrolled }: Props) {\n  const router = useRouter()\nreturn (\n    \n\n Signed in as: {user?.email}\n {\n            e.preventDefault()\n\n\n```        const { mfaUrl } = await fetch('/api/mfa', {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({ isEnrolled }),\n        }).then((res) => res.json())\n\n        window.location.href = mfaUrl\n      }}\n    >\n      {isEnrolled ? 'Manage MFA settings' : 'Set up MFA'}\n    </button>\n    <button onClick={() => router.push('/api/sign-out')}>Sign out</button>\n  </section>\n</main>\n```\n\n\n)\n}\n```\nOptional: To make things look a bit nicer, you can add the following to `/styles/globals.css`:\n```css\nmain {\n  min-height: 100vh;\n  display: flex;\n  flex: 1;\n  flex-direction: column;\n  justify-content: center;\n  align-items: center;\n}\nsection,\nform {\n  display: flex;\n  flex-direction: column;\n  min-width: 300px;\n}\nbutton {\n  cursor: pointer;\n  font-weight: 500;\n  line-height: 1;\n  border-radius: 6px;\n  border: none;\n  background-color: #24b47e;\n  color: #fff;\n  padding: 0 15px;\n  height: 40px;\n  margin: 10px 0;\n  transition: background-color 0.15s, color 0.15s;\n}\ninput {\n  outline: none;\n  font-family: inherit;\n  font-weight: 400;\n  background-color: #fff;\n  border-radius: 6px;\n  color: #1d1d1d;\n  border: 1px solid #e8e8e8;\n  padding: 0 15px;\n  margin: 5px 0;\n  height: 40px;\n}\na {\n  color: #24b47e;\n  cursor: pointer;\n}\n```\nStep 8: Adding the API routes\nNow we'll replace the existing api routes in `/pages/api/` with 5 new routes:\n\n`/sign-in.ts`: handles signing in with Supabase and initiating the MFA challenge with Authsignal\n`/sign-up.ts`: handles signing up with Supabase\n`/sign-out.ts`: clears the Supabase auth cookies and signs the user out\n`/mfa.ts`: handles the user's attempt to set up MFA or to manage their existing MFA settings\n`/callback.ts`: handles completing the MFA challenge with Authsignal\n\nAdd the following code to `/pages/api/sign-in.ts`:\n```ts\nimport { supabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { NextApiRequest, NextApiResponse } from 'next'\nimport { authsignal } from '../../lib/authsignal'\nimport { setAuthCookie, setTempCookie } from '../../lib/cookies'\nexport default async function signIn(req: NextApiRequest, res: NextApiResponse) {\n  const { email, password } = req.body\nconst { data, error } = await supabaseClient.auth.api.signInWithEmail(email, password)\nif (error || !data?.user) {\n    return res.send({ error })\n  }\nconst { state, url: mfaUrl } = await authsignal.track({\n    action: 'signIn',\n    userId: data.user.id,\n  })\nif (state === 'CHALLENGE_REQUIRED') {\n    await setTempCookie(data, res)\n  } else {\n    setAuthCookie(data, res)\n  }\nres.send({ state, mfaUrl })\n}\n```\nThen to handle new sign-ups add the following to `/pages/api/sign-up.ts`:\n```ts\nimport { supabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { Session } from '@supabase/supabase-js'\nimport { NextApiRequest, NextApiResponse } from 'next'\nimport { setAuthCookie } from '../../lib/cookies'\nexport default async function signUp(req: NextApiRequest, res: NextApiResponse) {\n  const { email, password } = req.body\nconst { data, error } = await supabaseClient.auth.api.signUpWithEmail(email, password)\nif (error || !isSession(data)) {\n    res.send({ error })\n  } else {\n    setAuthCookie(data, res)\n    res.send({ data })\n  }\n}\nconst isSession = (data: any): data is Session => !!data?.access_token\n```\nTo clear the auth cookies on sign-out add the following to `/pages/api/sign-out.ts`:\n```ts\nimport { supabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { NextApiRequest, NextApiResponse } from 'next'\nexport default async function signOut(req: NextApiRequest, res: NextApiResponse) {\n  supabaseClient.auth.api.deleteAuthCookie(req, res, { redirectTo: '/sign-in' })\n}\n```\nTo handle the user's actions to set up MFA or manage their existing MFA settings, add the following to `/pages/api/mfa.ts`:\n```ts\nimport { getUser, withApiAuth } from '@supabase/auth-helpers-nextjs'\nimport { NextApiRequest, NextApiResponse } from 'next'\nimport { authsignal } from '../../lib/authsignal'\nexport default withApiAuth(async function mfa(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).send({ message: 'Only POST requests allowed' })\n  }\nconst { user } = await getUser({ req, res })\nconst { isEnrolled } = req.body\nconst { url: mfaUrl } = await authsignal.track({\n    action: isEnrolled ? 'manageSettings' : 'enroll',\n    userId: user.id,\n    redirectToSettings: isEnrolled,\n  })\nres.send({ mfaUrl })\n})\n```\nBecause the user should be authenticated with Supabase to set up or manage MFA, we can use Supabase's `withApiAuth` wrapper to protect this route.\nThe `redirectToSettings` param specifies whether the user should be redirected to the MFA page settings panel after a challenge, rather than redirecting them immediately back to the application.\nFinally we need a route to handle the redirect back from Authsignal after an MFA challenge. Add the following to `/pages/api/callback.ts`:\n```ts\nimport { NextApiRequest, NextApiResponse } from 'next'\nimport { authsignal } from '../../lib/authsignal'\nimport { getSessionFromTempCookie, setAuthCookie } from '../../lib/cookies'\nexport default async function callback(req: NextApiRequest, res: NextApiResponse) {\n  const token = req.query.token as string\nconst { success } = await authsignal.validateChallenge({ token })\nif (success) {\n    const session = await getSessionFromTempCookie(req)\n\n\n```if (session) {\n  setAuthCookie(session, res)\n}\n```\n\n\n}\nres.redirect('/')\n}\n```\nThat's it! You should now be able to sign up a new user and set up MFA.\nThen if you sign out, you'll be prompted to complete an MFA challenge when signing back in again.\nResources\n\nTo learn more about Authsignal take a look at the API Documentation.\nYou can customize the look and feel of the Authsignal Prebuilt MFA page here.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Creating an Auth0 tenant",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/auth0.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth0',\n  title: 'Auth0',\n  description:\n    'Swap out Supabase authentication with Auth0. Let Auth0 handle tokens and signing users in and out, while Supabase enforces authorization policies with Row Level Security (RLS).',\n}\nThis guide steps through building a Next.js application with Auth0 and Supabase. We configure Auth0 to handle authenticating users and managing tokens, while writing our authorization logic in Supabase - using Row Level Security policies.\n\nNote: This guide is heavily inspired by the Using Next.js and Auth0 with Supabase article on Auth0's blog. Check it out for a practical step-by-step guide on integrating Auth0 and Supabase.\n\nThe full code example for this guide can be found here.\nAuth0 is an authentication and authorization platform, offering numerous strategies to authenticate and manage users. It provides fine-grain control over how users sign in to your application, the token that is generated, and what data is stored about your users.\nNext.js is a web application framework built on top of React. We will be using it for this example, as it allows us to write server-side logic within our application. Auth0 have also written a very well integrated authentication library specifically for Next.js.\n\nNote: API routes (serverless functions) in Next.js closely resemble the structure of Node server frameworks - such as Express, Koa and Fastify. The server-side logic in this guide could easily be refactored in one of these frameworks and managed as a separate application to the front-end.\n\nIf you don\u2019t have an Auth0 account, create one here.\nYou will also need a Supabase account, which can be created by signing in here.\nStep 1: Creating an Auth0 tenant\nFrom the Auth0 dashboard, click the menu to the right of the Auth0 logo, and select `Create tenant`.\n\nEnter a `Domain` for your tenant - this will need to be unique.\nSelect a `Region` - this should be geographically close to the majority of your users.\nSelect `Development` for `Environment Tag` - this should be production when you're ready to go live.\n\nStep 2: Setting up an Auth0 application\nFrom the sidebar menu, select `Applications` > `Applications` and click `Create Application`.\nGive your application a name, select the `Regular Web Applications` option and click `Create`.\n\nSelect `Settings` and navigate to the `Application URIs` section, and update the following:\n`Allowed Callback URLs`: `http://localhost:3000/api/auth/callback`\n`Allowed Logout URLs`: `http://localhost:3000`\nScroll to the bottom of the `Settings` section and reveal the `Advanced Settings`.\nSelect `OAuth` and set `JSON Web Token Signature` to `RS256`.\nConfirm `OIDC Conformant` is `Enabled`.\nClick `Save` to update the settings.\nStep 3: Creating a Supabase project\nFrom your Supabase dashboard, click `New project`.\nEnter a `Name` for your Supabase project.\nEnter a secure `Database Password`.\nSelect the same `Region` you selected for your Auth0 tenant.\nClick `Create new project`.\n\nStep 4: Creating data in Supabase\nFrom the sidebar menu in the Supabase dashboard, click `Table editor`, then `New table`.\nEnter `todo` as the `Name` field.\nSelect `Enable Row Level Security (RLS)`.\nCreate two new columns:\n\n`title` as `text`\n`user_id` as `text`\n`is_complete` as `bool` with the default value `false`\n\nClick `Save` to create the new table.\n\nFrom the `Table editor` view, select the `todo` table and click `Insert row`.\nFill out the `title` field and click `Save`.\n\nClick `Insert row` and add a couple of extra todos.\n\nStep 5: Building a Next.js app\nCreate a new Next.js project:\n`bash\nnpx create-next-app <name-of-project>`\nCreate a `.env.local` file and enter the following values:\n`AUTH0_SECRET=any-secure-value\nAUTH0_BASE_URL=http://localhost:3000\nAUTH0_ISSUER_BASE_URL=https://<name-of-your-tenant>.<region-you-selected>.auth0.com\nAUTH0_CLIENT_ID=get-from-auth0-dashboard\nAUTH0_CLIENT_SECRET=get-from-auth0-dashboard\nNEXT_PUBLIC_SUPABASE_URL=get-from-supabase-dashboard\nNEXT_PUBLIC_SUPABASE_ANON_KEY=get-from-supabase-dashboard\nSUPABASE_JWT_SECRET=get-from-supabase-dashboard`\n\nNote: Auth0 values can be found under `Settings > Basic Information` for your application.\n\n\n\nNote: Supabase values can be found under `Settings > API` for your project.\n\n\nRestart your Next.js development server to read in the new values from `.env.local`.\n`bash\nnpm run dev`\nStep 6: Install Auth0 Next.js library\nInstall the `@auth0/nextjs-auth0` library.\n`bash\nnpm i @auth0/nextjs-auth0`\nCreate a new file `pages/api/auth/[...auth0].js` and add:\n```jsx\n// pages/api/auth/[...auth0].js\nimport { handleAuth } from '@auth0/nextjs-auth0'\nexport default handleAuth()\n```\n\nNote: This will create a few API routes for us. The main ones we will use are `/api/auth/login` and `/api/auth/logout` to handle signing users in and out.\n\nOpen `pages/_app.js` and wrap our `Component` with the `UserProvider` from Auth0:\n```jsx\n// pages/_app.js\nimport React from 'react'\nimport { UserProvider } from '@auth0/nextjs-auth0'\nconst App = ({ Component, pageProps }) => {\n  return (\n    \n\n\n  )\n}\nexport default App\n```\nUpdate `pages/index.js` to ensure the user is logged in to view the landing page.\n```jsx\n// pages/index.js\nimport styles from '../styles/Home.module.css'\nimport { withPageAuthRequired } from '@auth0/nextjs-auth0'\nimport Link from 'next/link'\nconst Index = ({ user }) => {\n  return (\n    \n\n        Welcome {user.name}!{' '}\n        \nLogout\n\n\n  )\n}\nexport const getServerSideProps = withPageAuthRequired()\nexport default Index\n```\n\nNote: `withPageAuthRequired` will automatically redirect the user to `/api/auth/login` if they are not currently logged in.\n\nTest this is working by navigating to `http://localhost:3000` which should redirect you to an Auth0 sign in screen.\n\nEither `Sign up` for a new account, or click `Continue with Google` to sign in.\nYou should now be able to view the landing page.\n\nStep 7: Sign Auth0 token for Supabase\nCurrently, neither Supabase or Auth0 allow for a custom signing secret to be set for their JWT. They also use different signing algorithms.\nTherefore, we need to extract the bits we need from Auth0's JWT, and sign our own to send to Supabase.\nWe can do that using Auth0's `afterCallback` function, which gets called anytime the user authenticates.\nInstall the `jsonwebtoken` library.\n`bash\nnpm i jsonwebtoken`\nUpdate `pages/api/auth/[...auth0].js` with the following:\n```jsx\n// pages/api/auth/[...auth0].js\nimport { handleAuth, handleCallback } from '@auth0/nextjs-auth0'\nimport jwt from 'jsonwebtoken'\nconst afterCallback = async (req, res, session) => {\n  const payload = {\n    userId: session.user.sub,\n    exp: Math.floor(Date.now() / 1000) + 60 * 60,\n  }\nsession.user.accessToken = jwt.sign(payload, process.env.SUPABASE_JWT_SECRET)\nreturn session\n}\nexport default handleAuth({\n  async callback(req, res) {\n    try {\n      await handleCallback(req, res, { afterCallback })\n    } catch (error) {\n      res.status(error.status || 500).end(error.message)\n    }\n  },\n})\n```\nOur `payload` for the JWT will contain our user's unique identifier from Auth0 - `session.user.sub` and an expiry of 1 hour.\nWe are signing this JWT using Supabase's signing secret, so Supabase will be able to validate it is authentic and hasn't been tampered with in transit.\n\nNote: We need to sign the user out and back in again to run the `afterCallback` function, and create our new token.\n\nNow we just need to send the token along with the request to Supabase.\nStep 8: Requesting data from Supabase\nCreate a new file called `utils/supabase.js` and add the following:\n```jsx\n// utils/supabase.js\nimport { createClient } from '@supabase/supabase-js'\nconst getSupabase = (access_token) => {\n  const options = {}\nif (access_token) {\n    options.global = {\n      headers: {\n        Authorization: `Bearer ${access_token}`,\n      },\n    }\n  }\nconst supabase = createClient(\n    process.env.NEXT_PUBLIC_SUPABASE_URL,\n    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY,\n    options\n  )\nreturn supabase\n}\nexport { getSupabase }\n```\nThis will be our client for talking to Supabase. We can pass it an `access_token` and it will be attached to our request.\nLet's load our `todos` from Supabase in our landing page!\n```jsx\n// pages/index.js\nimport styles from '../styles/Home.module.css'\nimport { withPageAuthRequired } from '@auth0/nextjs-auth0'\nimport { getSupabase } from '../utils/supabase'\nimport Link from 'next/link'\nimport { useEffect } from 'react'\nconst Index = ({ user }) => {\n  const [todos, setTodos] = useState([])\n  const supabase = getSupabase(user.accessToken)\nuseEffect(() => {\n    const fetchTodos = async () => {\n      const { data } = await supabase.from('todo').select('*')\n      setTodos(data)\n    }\n\n\n```fetchTodos()\n```\n\n\n}, [])\nreturn (\n    \n\n        Welcome {user.name}!{' '}\n        \nLogout\n\n      {todos?.length > 0 ? (\n        todos.map((todo) => {todo.content})\n      ) : (\n        You have completed all todos!\n      )}\n    \n  )\n}\nexport const getServerSideProps = withPageAuthRequired()\nexport default Index\n```\nAlternatively, we could fetch todos on the server using the `getServerSideProps` function.\n```jsx\n// pages/index.js\nimport styles from '../styles/Home.module.css'\nimport { withPageAuthRequired, getSession } from '@auth0/nextjs-auth0'\nimport { getSupabase } from '../utils/supabase'\nimport Link from 'next/link'\nconst Index = ({ user, todos }) => {\n  return (\n    \n\n        Welcome {user.name}!{' '}\n        \nLogout\n\n      {todos?.length > 0 ? (\n        todos.map((todo) => {todo.content})\n      ) : (\n        You have completed all todos!\n      )}\n    \n  )\n}\nexport const getServerSideProps = withPageAuthRequired({\n  async getServerSideProps({ req, res }) {\n    const {\n      user: { accessToken },\n    } = await getSession(req, res)\n\n\n```const supabase = getSupabase(accessToken)\n\nconst { data: todos } = await supabase.from('todo').select('*')\n\nreturn {\n  props: { todos },\n}\n```\n\n\n},\n})\nexport default Index\n```\nEither way, when we reload our application, we are still getting the empty state for todos.\n\nThis is because we enabled Row Level Security, which blocks all requests by default. To enable our user to select their `todos` we need to write a policy.\nStep 9: Write a policy to allow select\nOur policy will need to know who our currently logged in user is to determine whether or not they should have access. Let's create a PostgreSQL function to extract the current user from our new JWT.\nNavigate back to the Supabase dashboard, select `SQL` from the sidebar menu, and click `New query`. This will create a new query called `new sql snippet`, which will allow us to run any SQL against our Postgres database.\nWrite the following and click `Run`.\n`sql\ncreate or replace function auth.user_id() returns text as $$\n  select nullif(current_setting('request.jwt.claims', true)::json->>'userId', '')::text;\n$$ language sql stable;`\nThis will create a function called `auth.user_id()`, which will inspect the `userId` field of our JWT payload.\n\nNote: To learn more about PostgreSQL functions, check out our deep dive video.\n\nLet's create a policy that checks whether this user is the owner of the todo.\nSelect `Authentication` from the Supabase sidebar menu, click `Policies`, and then `New Policy` on the `todo` table.\n\nFrom the modal, select `Create a policy from scratch` and add the following.\n\nThis policy is calling the function we just created to get the currently logged in user's ID `auth.user_id()` and checking whether this matches the `user_id` column for the current `todo`. If it does, then it will allow the user to select it, otherwise it will continue to deny.\nClick `Review` and then `Save policy`.\n\nNote: To learn more about RLS and policies, check out our deep dive video.\n\nThe last thing we need to do is update the `user_id` columns for our existing `todos`.\nHead back to the Supabase dashboard, and select `Table editor` from the sidebar.\n\nEach of our `user_id` columns are set to `NULL`!\nTo get the ID for our Auth0 user, head over to the Auth0 dashboard, select `User Management` from the sidebar, click `Users` and select your test user.\n\nCopy their `user_id`.\n\nUpdate each row in Supabase.\n\nNow when we refresh our application, we should finally see our list of `todos`!\n\nNote: Check out the repo for an example of writing new `todos` to Supabase.\n\nResources\n\nAuth0 official website.\nAuth0 blog.\nUsing Next.js and Auth0 with Supabase article.\nAuth0 community.\nAuth0 documentation.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Quick explanation",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/dashibase.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'dashibase',\n  title: 'Dashibase',\n  description: 'Create an internal CRUD dashboard with Supabase and Dashibase in 15 mins.',\n}\nAre you tired of building admin panels? Dashibase is a super fast way to build internal CRUD dashboards with a Notion-like UI.\nThis guide walks you through how to build a customer admin panel using Supabase on the backend and Dashibase on the front so that you and your team can easily find and update customer information.\nQuick explanation\nJust so we are on the same page, here are some of the terms we use:\n\nData source: This is the data that powers your dashboard (i.e. your Supabase database).\nDashboard: This is the friendly interface that you build on top of your Supabase database using Dashibase.\nPage: Each dashboard can have multiple pages. Each page can have multiple blocks of text or tables.\n\nNow that is out of the way, let's build our customer admin panel.\n(Start your stopwatch!)\nStep 1. Connect Supabase to Dashibase\nFirst, in Dashibase, go to \u201cData Sources\u201d via the left sidebar and click on \u201cConnect data source\u201d in the upper-right corner.\nNote: We do not download or store any of your database data.\n\nEnter your database credentials, which you can find in Supabase under Settings > Database > Connection info. For additional security, you can also download your SSL certificate and upload it to Dashibase.\n\nStep 2. Set up your data access policy\nOnce you have connected your database, you can also control what your team can see and edit in your database via Dashibase. There are usually certain data that you don\u2019t want others to edit or even see (e.g. address, email, identification number).\nNote: If you prefer to restrict access to your database before you connect to Dashibase for security reasons, you can create a restricted user via Supabase's SQL Editor. The slight advantage of doing this in Dashibase is that there is a GUI, which makes it easier to set up the access control (but we understand some developers might find it more secure to restrict the access themselves).\n\nYou can even control which columns within a table that others can see and edit. In the example below, for the `tags` table, the `name` column can be read and updated, the `created_at` column can be read, and the `id` column cannot even be read.\n\nOnce you are happy with the data access control, you can decide who in your organization can edit this data source (usually other developers) or use this data source to create dashboards.\n\nStep 3. Build your dashboard\nTo create a dashboard, go to \u201cDashboards\u201d via the left sidebar in Dashibase and click on \u201cCreate dashboard\u201d in the upper-right corner.\nHere\u2019s where the fun begins. There are many ways to build your dashboards in Dashibase using features such as markdown formatting and slash command.\nYou will see some automatically-generated content in your dashboard so that you can set up your dashboard more quickly. For this example, let's clear them out and start from scratch.\n\nUsing our Notion-like UI, you can quickly build out your dashboard through typing. For example, you can type '/table' to add a table from your database to your dashboard. No more dragging components across your screen and dropping them on a blank canvas repeatedly.\n\nIf you have set up foreign keys in your Supabase database, you can easily show data from multiple tables on the table in your Dashibase dashboard. Simply click on the \"Columns\" button beside the \"Filter\" button and select the columns you want to show or hide. For this example, we want to show the customers' country and plan price, which are in separate `countries` and `plans` tables.\n\nFor all the tables in your dashboard, you can rename the column headers, add filter and sort, adjust the column width, and more.\nYou can also add text to provide context or instructions for the rest of your team as they are using your dashboard. This saves you the trouble of having your dashboard and documentation in separate places.\n\nMost importantly, we automatically generate a single-item view for each of the items on your table so that you do not have to manually create it yourself. You can easily edit or rearrange the blocks just like in Notion.\n\nStep 4. Share your dashboard with your team\nFinally, save and share the dashboard with your team. There are two levels of access:\n\nEdit dashboard: Edit the text blocks, edit the tables, etc.\nUse dashboard: View and update the data via the dashboard\n\nClick on the \u201cShare\u201d button in the upper-right corner of your dashboard to share access:\n\nNow your team can use this customer admin panel to find and update customer information easily!\nP.S. How long did we take? :)\nResources\n\nDashibase website\nDashibase open-source repo\nDashibase Twitter\nDashibase Discord\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Prerequisites",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/snaplet.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'snaplet',\n  title: 'Snaplet',\n  description:\n    'Get started with Supabase and Snaplet, a developer tool for working with safe, versioned, up-to-date production-like data',\n}\nThis step-by-step guide explains how to use Snaplet to clone your production Supabase project into another development database.\nSnaplet is a developer tool that copies a Postgres database, transforming personal information, so that you can safely code against actual data. This functionality makes it possible to easily achieve environment parity in Supabase.\nLet's get started!\nFollow along in the video below as the founder of Snaplet, Peter Pistorius, takes you through the entire process. Otherwise, you can skip the video and dive into the step-by-step guide.\n\n\n\nStep 1: Prerequisites\n\nA production Supabase project's connection string: These can be found in Supabase via `Organization > Project > Database > Connection Pooling > Connection string`\nA development Supabase project's connection string: Same steps as above, but a different project/environment\nA read-only role in Production (recommended): This can be done by running the following statements on Supabase via `Organization > SQL Editor > + New Query`\n\n\nTo create a read-only role across all schemas you can checkout the Snaplet docs\n\n\nSuperuser access for the development project. This can be done in Supabase via `Organization > SQL Editor > + New Query` and running this statement:\n   `ALTER USER postgres WITH superuser;`\n\nStep 2: Copying your production database\n2.1. Connect your data source\nNavigate to https://www.snaplet.dev/ and sign up for a new account (it\u2019s free). Once you have successfully signed up for a new account, create a team, and start by connecting to your Supabase project.\n\nEnter the credentials of your production Supabase project. Find the \"Connection string\" in Supabase via `Organization > Project > Settings > Database > Connection string` (at the bottom of the page).\nThe password is the same password you used when creating the Supabase project.\n\nYou\u2019ll have to confirm providing Snaplet access to your database. Snaplet will prompt you to only provide `read-only` access to your database. Snaplet has a guide in their documentation on how to do so here.\n\nNote that whatever connection string you provide here will be that of your Data Source \u2013 essentially the production database in a real-life scenario\n\n\n2.2. Transform your data\n\nThe next step is to exclude any schemas that you do not require. You are able to exclude an entire schema by clicking on the drop-down at the top, selecting the schema you would like to exclude and clicking \u2018Exclude schema\u2019. Alternatively, you can select a given schema and exclude only specific tables from that particular schema. Exclude any non-required table data (such as logs) and extensions and view your columns.\nAt this point, Snaplet will automatically detect any columns that have Personally Identifiable Information (PII) and mark them in purple. If there are any additional columns that hold data you would like to anonymise, you can click on the respective column name and provide a replacement value for the data in that column. To complete the onboarding, click on `Review and Save` and proceed to the dashboard.\n\n2.3. Create a Snapshot\nCreate a snapshot of your production database. This is what you\u2019re going to restore later into your data target (more on that later in the guide).\nStep 3: Pasting into your development database\n3.1. Create a data target on Supabase\nYour data target is where you want Snaplet to restore the captured snapshot of your production project. This would most likely be either your staging or developer Supabase project. If you don\u2019t already have a developer database setup on Supabase, create a new data target by setting up a new project on Supabase. To create a new project, follow the steps below:\n\nGo to app.supabase.com\nClick on \u201cnew project\u201d\nEnter your project details\nWait for the new database to launch\n\n\nRemember the password you use when creating the project. You\u2019ll need this password to connect your database to Snaplet later.\n\n3.2. Make your `postgres` user a superuser\nSnaplet requires the ability to drop the database schemas whilst restoring a snapshot. In order to do that, Snaplet requires `superuser` privileges.\n\nNavigate to the `SQL Editor` in your Supabase console\nClick on `new query`\nPaste `alter user postgres with superuser;` into the SQL editor\nRun the query\n\n3.3. Install the Snaplet CLI\n\nOpen your terminal and run `curl -sL https://app.snaplet.dev/get-cli/ | bash`\nRun `snaplet auth`\nNavigate to https://app.snaplet.dev/access-token/cli to get your access token\nPaste your access token in the terminal\n\n3.4. Restore to the data target\nYou're now ready to restore your production snapshot into your Supabase development project.\n\nNavigate to your project directory\nRun `snaplet setup` \u2013 you will be prompted to enter your database credentials. These are the database credentials of your data target. This could be your staging or development database\n\nOnce completed, you will be presented with a list of databases that are connected to your Snaplet account.\n\nSelect a data source from the list\nRun `snaplet snapshot restore`\n\nAll done!\nAs a Supabase user, you can see how this solves an issue developers all typically experience when attempting to create multiple development environments and populating each of those environments with data that can be worked with. Snaplet simplifies this process down to creating the respective Supabase projects, connecting the data source (The production database) to Snaplet and telling Snaplet where to restore that data (staging and development databases).\nIf you want to learn more about Snaplet, you can explore the Snaplet docs. If you have any questions, feel free to reach out on Discord.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Resources",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/illa.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'illa',\n  title: 'ILLA',\n  description:\n    'Get started with Supabase and ILLA, a low-code platform for developers that enables the rapid development and deployment of internal tools.',\n}\nThis tutorial outlines the process of creating an Admin Panel using ILLA Builder and Supabase in a few simple steps. ILLA is a low-code platform for developers that enables the rapid development and deployment of internal tools. It allows for creating pages by dragging and dropping UI components, connecting to any database or API, and writing JavaScript. To learn more about ILLA and give it a try, visit their website at https://www.illacloud.com/. Let's begin!\nStep 1: Set up your Back end on Supabase\nOn the Supabase dashboard, click `New project` and set the name to adminPanel.\n\nCreate a new table by clicking on the `Create a new table` .\nSupabase offers a variety of options for populating tables with data, including writing queries, creating schemas through a user interface, and uploading CSV files.\n\n\nFill out the info in the table. The database is now set up.\nStep 2: Build UI on ILLA Cloud\nOn ILLA Cloud, click Create New to create a new application.\n\nDrag components from the `Insert` panel to the canvas.\nSelect the components on the canvas and configure the property on the `Inspect` panel.\nAs seen in the below screenshot, we have built a simple admin panel.\n\nStep 3: Connect to Supabase and config CRUD\nNote down the database connection information under Project Settings in Supabase.\n\nIn the Action List, click `+ New` and select Supabase DB.\n\nFill out the form to connect to your Supabase instance. Test connection and save resource.\n\nClick `Create Action` to create an action with the Supabase resource and config your CRUD.\n\nUse `{{` to get the front-end input data. The following is an example of the User Management page in the Admin Panel.\nSearch for a user by the name inputted in input1\n`SELECT *\nFROM user\nWHERE name = \"{{input1.value}}\"\n;`\nUpdate user data. Update user information when id matches\n`UPDATE user\nSET name = \"{{input3.value}}\"\n, email = \"{{input4.value}}\"\nWHERE id=\"{{input2.value}}\"\n;`\nInsert user data\n`INSERT INTO user VALUES(\"{{input5.value}}\",\"{{input6.value}}\",\"{{input7.value}}\");`\nDelete a user by id\n`DELETE FROM user WHERE id = \"{{input2.value}}\";`\nStep 4: Show data on components\nConfigure the properties of components with `{{` . For example:\n\nResources\n\nILLA Cloud official website\nILLA Cloud GitHub\nILLA Cloud documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Setup",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/fezto.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'fezto',\n  title: 'Frontend Zero to One',\n  description: 'Create an app automatically from your Supabase Postgres using OpenAPI',\n  video: 'https://www.youtube.com/v/GOC6a0_AlgI',\n}\nFrontend Zero to One is is a service which creates an app for your Supabase Postgres database on-the-fly without any drag and drop, using the OpenAPI spec provided by PostgREST.\n\n\n\nSetup\nIn the Supabase control panel, open your project and click the Settings cog icon, and then \"API\".\nYou will need:\n\nFrom the Project URL copy the project ID from https://your-project-id.supabase.co\nFrom the \"Project API keys\" section copy the \"anon\" \"public\" API Key into the\n\nPaste both into the FEZTO Supabase setup page and click Launch.\nYou can now share and bookmark the browser URL which includes the projectID and anon key with others to launch the same app.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Add the Supabase Data Source Plugin in WeWeb",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/weweb.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'weweb',\n  title: 'WeWeb',\n  description: 'Build user interfaces on top of existing databases.',\n}\nThis guide explains how to connect a Supabase back-end to a WeWeb front-end and then configure all the CRUD operations necessary to build an Admin Portal with user authentication, roles, and permissions.\nWeWeb is a low-code front-end builder that allies the short learning curve of no-code with the freedom of code.\nIt connects to Supabase via two native integrations:\n\none for data manipulation, and\nanother for user authentication.\n\nIf you don't have an WeWeb account, you can create one here.\nLet's get started!\nStep 1: Add the Supabase Data Source Plugin in WeWeb\nIn order to read Supabase data in WeWeb, you'll first need to add the Supabase Data Source Plugin:\n\nOnce you've added it, you will be invited to share your Supabase project URL and public API key:\n\nIn Supabase, you can find both your project URL and public key in the `Settings` > `API` menu:\n\nOnce you have added both to WeWeb, you will have the option to enable realtime tables if you wish to do so:\n\n\ud83d\udea8 Warning \ud83d\udea8\n\nRealtime is disabled by default in Supabase for better database performance and security. Learn more about realtime functionalities.\n\nStep 2: GET Data from Supabase\nOnce you click on `Add a Collection`, you will be invited to give your Collection a name and choose Supabase as a Data source:\n\nYou will then be able to select the Table from which you want to pull data:\n\nNotice that this gives you access to 2 separate modes to access the fields in the table:\n\na \"Guided\" mode, and\nan \"Advanced\" mode.\n\nGuided mode\nBy default, the \"Guided\" mode returns the data from all the fields.\nIn the example below, we decide to exclude the data from the `created_at` field in our `vehicles` table:\n\nAs a result, WeWeb does not fetch the `created_at` field.\nThis is helpful because we can exclude data that we don't want to load in the frontend, either because we don't need it or because it's confidential.\nAdvanced mode\nIn our database, we created 2 separate tables for vehicles and locations.\nIn the `vehicles` table, we made a reference to the `locations` table in our `location_id` field so we know where each car is:\n\nThe problem is, the link only gives us the id of the location in the `locations` table.\nIf you choose the \"Advanced\" mode, you will be able to get the `name` field of the location instead of the `id`.\nHow?\nBy making custom queries to Supabase:\n\nIn the example above, we are telling Supabase:\n\nfrom the table selected in the Collection \u2013 in this case the `vehicles` table \u2013 please send me the data in the `id`, `model`, and `mileage` fields\nlook for the `location_id` in the `vehicles` table in the `locations` table and send me the data in the corresponding `name` field\n\nIf we only ask for the data from the `location` field of the `vehicles` table, Supabase will only return the `id`:\n\n\ud83d\udea8 Warning \ud83d\udea8\n\nIf you have enabled Row-Level Security in Supabase, make sure you have also added a Policy that allows users to read the data in the table. Otherwise, WeWeb won't be able to get the data.\n\nStep 3: Display Supabase Data in WeWeb\nAssuming you were able to fetch data from Supabase in a WeWeb Collection, you'll be able to bind the data from that Collection on your WeWeb pages.\nIn the example below, we chose to display the car model and mileage in the Data Grid element that comes out-of-the-box in WeWeb:\n\nWe chose this element because it includes a built-in inline editing mode we'll want to use later for our CRUD operations.\n\ud83d\udd25 Pro Tip \ud83d\udd25\n\nIn WeWeb, you can bind arrays of data to any Container. Just bear in mind that the first child of the Container you bind the Collection to will be the repeated item. With that in mind, you might want the first child Element to be another Container with a number of items inside like a title, description, button or image.\n\nStep 4: Update a record in Supabase\nOnce you've added a Supabase Collection of data to WeWeb, you might want to allow users to manipulate the data in that Collection.\nIn order to do so, you'll need to create a Workflow in WeWeb.\nIn the example below, we are using the \"Update row\" Workflow that comes by default with WeWeb's Data Grid Element.\nThe trigger is `On Row update`.\nSince we added the Supabase Data Source Plugin above, we have access to all the CRUD actions available in Supabase:\n\nSelect\nInsert\nUpdate\nUpsert\nDelete\n\nIn this case, we choose the \"Update\" action:\n\nThen, in our \"Update\" action, we select the `vehicles` table and map the `id` to the id of the Workflow Event:\n\nFinally, we tell WeWeb we want to update the `mileage` field in our Supabase table, and send the value in the `mileage` column of our Data Grid:\n\nAnd that's it!\nIf you switch to Preview mode, you will be update your Supabase table from your WeWeb Data Grid:\n\n\ud83d\udd25 Pro Tip \ud83d\udd25\n\nBy default, the fields in the Data Grid Element are Text fields but you can change the input type to Number if you need to send numerical data to your database:\n\n\nRestrict who can modify a record in Supabase\nBy default, all the data in the tables that are in the `public` schema of your Supabase project can be read, updated, or deleted.\nSupabase allows you to enable Row-Level Security for each of your tables:\n\nIf you want to restrict certain actions to specific users or roles, you'll need to:\n\nadd Supabase authentication to your WeWeb project, and\nwrite SQL policies in Supabase.\n\nWe provide a number of policy templates to get you started:\n\nIn the example below, we say that users can:\n\nupdate a record\nin the \"locations\" table of the \"public\" schema\nif they are authenticated\n\n\n\ud83d\udd25 Pro Tip \ud83d\udd25\n\nOnce you enable RLS on a Supabase table, you won't be able to access the data in a WeWeb Collection unless you've added a policy.\n\n\nStep 4: Add User Authentication\nOnce you are able to display Supabase data in WeWeb, you might want to restrict access to certain users or display specific data based on a user's role.\nIn order to do that, you'll need to add WeWeb's Supabase Auth Plugin.\nAdd Supabase Auth Plugin in WeWeb\nSupabase comes with an in-built authentication system which you can use in WeWeb.\nTo add the Supabase Auth Plugin in WeWeb, go to `Plugins` > `Authentication`:\n\nAssuming you have already provided your Supabase project URL and public API key when setting up the Supabase Data source, the only thing left to do will be to add your private API key:\n\nIn Supabase, you can find your private API key in `Settings` > `API`:\n\n\ud83d\udea8 Warning \ud83d\udea8\n\nAs the name suggests, you'll want to keep this API key secret! Assuming you copy it properly in the \"Private API key\" field of the Supabase Auth Plugin and don't use it anywhere else in your Weweb project, Weweb will never make it public.\n\nYou will then be invited to choose a page to redirect unauthenticated users, i.e. users who are NOT signed-in:\n\n\ud83d\udea8 Warning \ud83d\udea8\n\nWhen you setup your Login Workflow, make sure you don't redirect unauthenticated users to a page that is only accessible to authenticated users. Otherwise, you'll be creating an infinite loop and your app will crash.\n\nCreate User Sign Up and Sign In Workflows\nIn the `Add` > `UI kit` menu of WeWeb, you can find ready-made Sign in and Sign up Forms:\n\nOnce you've added a Form to the Canvas, you'll be able to style it whichever way you want.\nIn the example below, we added an image with the logo of our project to a Sign up Form and changed the background color of the `Create Form` Container:\n\nTo allow users to sign up, you'll need to create a Sign up Workflow on the Form Container:\n\n\ud83d\udd25 Pro Tip \ud83d\udd25\n\nIt's important that the Workflow is on the Form Container and not the Sign up Button because we want to validate the fields of the Form when users submit it.\n\nIn the Workflow, you will choose the `On submit` trigger and add the Supabase `Sign up` Action:\n\nThen, you'll want to map the email, password, and metadata information in the Form to the email, password, and metadata in Supabase before choosing what page the new user should be redirected to:\n\nIn the example above, we made sure to add the user's name as an item in that user's metadata.\nIn Supabase, you can find the user's metadata in JSON format in a dedicated field of the `users` table, named `raw_user_meta_data`:\n\nThe same logic will apply to any Supabase Action you want to trigger.\nAdding User Roles & Permissions\nNow let's say we want to gate content and set different permissions based on a user's role.\nAdding Roles in Supabase\nIn Supabase, we'll need to create a `roles` table with a list of roles and a join table that links the `roles` table with our `users` table.\nFirst, let's create a `roles` table with three roles and make sure that each role had a UUID and a `name`:\n\n\ud83d\udea8 Warning \ud83d\udea8\n\nIn order for the integration to work with the Users tab in WeWeb, it is crucial that the role title is a text field named `name`.\n\nJoining Roles and Users in Supabase\nSecond, let's create a `userRoles` join table:\n\nIn the join table above, you can see we have an `id` field that is uniquely identifiable thanks to a UUID.\nThis unique `id` is linked to a `userId`, which is also a UUID, more specifically, it is the UUID we find in the `id` field of the `users` table in the `auth` schema:\n\nEach row in our `userRoles` table is also linked to a `roleId` which is the UUID we find in the `id` field of the `roles` table in the `public` schema:\n\nLinking Users in WeWeb to Roles and Users in Supabase\nOnce we've added our list of roles in Supabase and created an empty join table to link our roles with users, it's time to go to WeWeb.\nIn `Plugins` > `Supabase Auth` > `3. Roles table`, we'll click `refresh` and select the relevant Supabase tables we just created:\n\nOnce you've told WeWeb where to find the `roles` and the join table in Supabase, you'll be able to easily view and maintain user roles in the `Users` tab in WeWeb:\n\nWhen you make a change to a User in WeWeb, it will automatically be updated in Supabase.\nUsers vs Profiles\nSo far, we've showed you how to work with the default `users` table that Supabase generates in the `auth` schema when you create a new project.\nNote that, for security purposes, the information in that `users` table is not exposed on the auto-generated API.\nHow does this affect your project in WeWeb?\nLet users update their information\nLet's say you want to let authenticated users update their information, then you don't need to set up anything else in Supabase.\nYou could simply create a user profile page in WeWeb and display their information when they sign in, based on the data you have in the `user` Variable:\n\nDisplay other users' information\nIn some use cases, you might want to display other users' information.\nFor example, if you're building an HR portal in WeWeb, you might want HR employees to have access to a list of applicants and their user profiles.\nYou wouldn't be able to do that with the `users` table in the `auth` schema because each user's information is only available to them.\nFor such a use case, we recommend creating a `profiles` table in the `public` schema to store user data that you want to access via the API.\nIn WeWeb, you would then be able to create a Collection to get data from the `profiles` table.\nLearn more about managing user data in Supabase.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 0: Create a Stytch Account",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/stytch.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'stytch',\n  title: 'Stytch',\n  description:\n    \"Build a Next.js application powered by password-less authentication from Stytch, and Supabase's Row Level Security (RLS).\",\n}\nIn this guide we will build a simple expense tracker web application using Stytch, Supabase, and Next.js.\nStytch provides an all-in-one platform for passwordless auth. Stytch makes it easy for you to embed passwordless solutions into your websites and apps for better security, better conversion rates, and a better end user experience. Their easy-to-use SDKs and direct API access allows for maximum control and customization. In this example we will use Email magic links to create and log in our users, and Session management. There is an additional, optional step to enable Google One Tap which is an especially high-converting Google OAuth sign-up and login flow.\nWe will leverage Supabase to store and authorize access to user data. Supabase makes it simple to set up Row Level Security (RLS) policies which ensure users can only read and write data that they are authorized to do so. If you do not already have a Supabase account, you will need to create one.\nThis guide will use Next.js which is a web application framework built on top of React. Stytch provides a Node.js library and a React library which makes building Next.js apps super easy.\n\nNote: You can find a completed version of this project on Github.\n\nStep 0: Create a Stytch Account\nIf you already have a Stytch account you may skip this step.\nGo to Stytch, and create an account. Note that Stytch provides two ways to create an account, either via Google OAuth, or through Email magic links.\u00a0 This is the same user experience we will be building in this guide!\n\nStep 1: Set up Stytch redirect URLs\nFirst we need to add the redirect URLs that will be used during the Email magic link flow. This step helps ensure bad actors cannot spoof your magic links and hijack redirects.\nNavigate to your redirect URL settings in the Stytch dashboard, and under Test environment create an entry where the URL is `http://localhost:3000/api/authenticate` and the Type is `All`.\n\nAfter pressing Confirm, the redirect URLs dashboard will update to show your new entry. We will use this URL later on.\n\nStep 2: Create a Supabase project\nFrom your Supabase dashboard, click New project.\nEnter a `Name` for your Supabase project.\nEnter a secure `Database Password`.\nClick Create new project. It may take a couple minutes for your project to be provisioned.\n\nStep 3: Creating data in Supabase\nOnce your Supabase project is provisioned, click Table editor, then New table. This tool is available from the sidebar menu in the Supabase dashboard.\nEnter `expenses` as the Name field.\nSelect `Enable Row Level Security (RLS)`.\nAdd three new columns:\n\n\n`user_id` as `text`\n\n\n`title` as `text`\n\n\n`value` as `float8`\n\n\nClick Save to create the new table.\n\nFrom the Table editor view, select the expenses table and click Insert row.\nFill out the title and value fields (leave user_id blank for now) and click Save.\n\nUse Insert Row to further populate the table with expenses.\n\nStep 4: Building a Next.js app\nUsing a terminal, create a new Next.js project:\n`bash\nnpx create-next-app stytch-supabase-example`\nNext, within `stytch-supabase-example` create a `.env.local` file and enter the following values:\n`STYTCH_PROJECT_ENV=test\nSTYTCH_PROJECT_ID=GET_FROM_STYTCH_DASHBOARD\nSTYTCH_PUBLIC_TOKEN=GET_FROM_STYTCH_DASHBOARD\nSTYTCH_SECRET=GET_FROM_STYTCH_DASHBOARD\nNEXT_PUBLIC_SUPABASE_URL=GET_FROM_SUPABASE_DASHBOARD\nNEXT_PUBLIC_SUPABASE_KEY=GET_FROM_SUPABASE_DASHBOARD\nSUPABASE_SIGNING_SECRET=GET_FROM_SUPABASE_DASHBOARD`\n\nNote: Stytch values can be found in the project dashboard under API Keys.\n\n\n\nNote: Supabase values can be found under Settings > API for your project.\n\n\nStart your Next.js development server to read in the new values from `.env.local`.\n`bash\nnpm run dev`\nYou should have a running Next.js application on `localhost:3000`.\nStep 5: Build the Login Form\nNow we will replace the default Next.js home page with a login UI. We will use the Stytch React library.\n\nNote: Stytch provides direct API access for those that want to build login UI themselves\n\nInstall the `@stytch/stytch-react` library.\n`bash\nnpm install @stytch/stytch-react`\nIn the root directory, create a new folder named `components` and file in that folder named `/StytchLogin.js`. Within this file, paste the snippet below. This will configure, and style the Stytch React component to use Email magic links.\n```jsx\n// components/StytchLogin.js\nimport React from 'react'\nimport { Stytch } from '@stytch/stytch-react'\nconst stytchConfig = {\n  loginOrSignupView: {\n    products: ['emailMagicLinks'],\n    emailMagicLinksOptions: {\n      loginRedirectURL: 'http://localhost:3000/api/authenticate',\n      loginExpirationMinutes: 30,\n      signupRedirectURL: 'http://localhost:3000/api/authenticate',\n      signupExpirationMinutes: 30,\n      createUserAsPending: true,\n    },\n  },\n  style: {\n    fontFamily: '\"Helvetica New\", Helvetica, sans-serif',\n    width: '321px',\n    primaryColor: '#0577CA',\n  },\n}\nconst StytchLogin = ({ publicToken }) => {\n  return (\n    \n  )\n}\nexport default StytchLogin\n```\nAdditionally, create a profile component by creating a file called `Profile.js` in `/components`. We will use this component to render our expenses stored in Supabase later on.\n```jsx\n// components/Profile.js\nimport React from 'react'\nimport Link from 'next/link'\nexport default function Profile({ user }) {\n  return (\n    \nWelcome {user.userId}\nYour expenses\n      {user.expenses?.length > 0 ? (\n        user.expenses.map((expense) => (\n          \n            {expense.title}: ${expense.value}\n          \n        ))\n      ) : (\n        You have no expenses!\n      )}\n\n\n```  <Link href=\"/api/logout\" passHref>\n    <button>\n      <a>Logout</a>\n    </button>\n  </Link>\n</div>\n```\n\n\n)\n}\n```\nFinally, replace the contents of the file `/pages/index.js` to render our new `StytchLogin` and `Profile` components.\n```jsx\n// pages/index.js\nimport styles from '../styles/Home.module.css'\nimport Profile from '../components/Profile'\nimport StytchLogin from '../components/StytchLogin'\nconst Index = ({ user, publicToken }) => {\n  let content\n  if (user) {\n    content = \n  } else {\n    content = \n  }\nreturn {content}\n}\nexport async function getServerSideProps({ req, res }) {\n  const user = null // Will update later\n  return {\n    props: { user, publicToken: process.env.STYTCH_PUBLIC_TOKEN },\n  }\n}\nexport default Index\n```\nOn `localhost:3000` there is now a login form prompting for your email address.\n\nEnter your email address and press Continue with email.\n\nIn your inbox you will find a login request from your app.\n\nHowever, if you click the link in the email you will get a 404. We need to build an API route to handle the email magic link authentication.\nStep 6: Authenticate and start a session\nTo make authentication easier we will use the Stytch Node.js library. Run\n`bash\nnpm install stytch`\nAdditionally, we will need to store the authenticated session in a cookie. Run\n`bash\nnpm install cookies-next`\nCreate a new folder named `utils` and inside a file named`stytchLogic.js` with the following contents\n```jsx\n// utils/stytchLogic.js\nimport * as stytch from 'stytch'\nimport { getCookie, setCookies, removeCookies } from 'cookies-next'\nexport const SESSION_COOKIE = 'stytch_cookie'\nlet client\nconst loadStytch = () => {\n  if (!client) {\n    client = new stytch.Client({\n      project_id: process.env.STYTCH_PROJECT_ID,\n      secret: process.env.STYTCH_SECRET,\n      env: process.env.STYTCH_PROJECT_ENV === 'live' ? stytch.envs.live : stytch.envs.test,\n    })\n  }\nreturn client\n}\nexport const getAuthenticatedUserFromSession = async (req, res) => {\n  const sessionToken = getCookie(SESSION_COOKIE, { req, res })\n  if (!sessionToken) {\n    return null\n  }\ntry {\n    const stytchClient = loadStytch()\n    const resp = await stytchClient.sessions.authenticate({\n      session_token: sessionToken,\n    })\n    return resp.session.user_id\n  } catch (error) {\n    console.log(error)\n    return null\n  }\n}\nexport const revokeAndClearSession = async (req, res) => {\n  const sessionToken = getCookie(SESSION_COOKIE, { req, res })\nif (sessionToken) {\n    try {\n      const stytchClient = loadStytch()\n      await stytchClient.sessions.revoke({\n        session_token: sessionToken,\n      })\n    } catch (error) {\n      console.log(error)\n    }\n    removeCookies(SESSION_COOKIE, { req, res })\n  }\nreturn res.redirect('/')\n}\nexport const authenticateTokenStartSession = async (req, res) => {\n  const { token, type } = req.query\n  let sessionToken\n  try {\n    const stytchClient = loadStytch()\n    const resp = await stytchClient.magicLinks.authenticate(token, {\n      session_duration_minutes: 30,\n    })\n    sessionToken = resp.session_token\n  } catch (error) {\n    console.log(error)\n    const errorString = JSON.stringify(error)\n    return res.status(400).json({ errorString })\n  }\nsetCookies(SESSION_COOKIE, sessionToken, {\n    req,\n    res,\n    maxAge: 60 * 60 * 24,\n    secure: true,\n  })\nreturn res.redirect('/')\n}\n```\nThis logic is responsible for setting up the Stytch client we will use to call the API. It provides functions we will use to login, logout, and validate user sessions.\nIn order to complete the email login flow, create a new file `pages/api/authenticate.js` with the contents:\n```jsx\n// pages/api/authenticate.js\nimport { authenticateTokenStartSession } from '../../utils/stytchLogic'\nexport default async function handler(req, res) {\n  return authenticateTokenStartSession(req, res)\n}\n```\nWe will also create a logout API endpoint with similar contents. In `pages/api/logout.js` include the following:\n```jsx\n// pages/api/logout.js\nimport { revokeAndClearSession } from '../../utils/stytchLogic'\nexport default async function handler(req, res) {\n  return revokeAndClearSession(req, res)\n}\n```\nFinally, update `pages/index.js` by importing `getAuthenticatedUserFromSession`, and calling it to set the user variable in `getServerSideProps`.\n```jsx\n// pages/index.js\nimport styles from '../styles/Home.module.css'\nimport StytchLogin from '../components/StytchLogin'\nimport Profile from '../components/Profile'\nimport { getAuthenticatedUserFromSession } from '../utils/stytchLogic'\nconst Index = ({ user, publicToken }) => {\n  let content\n  if (user) {\n    content = \n  } else {\n    content = \n  }\nreturn {content}\n}\nexport async function getServerSideProps({ req, res }) {\n  const userId = await getAuthenticatedUserFromSession(req, res)\n  if (userId) {\n    return {\n      props: { user: { userId }, publicToken: process.env.STYTCH_PUBLIC_TOKEN },\n    }\n  }\n  return {\n    props: { publicToken: process.env.STYTCH_PUBLIC_TOKEN },\n  }\n}\nexport default Index\n```\nReturn to `localhost:3000`, and login again by sending yourself a new email. Upon clicking through in the email you should be presented with \u201cWelcome $USER_ID\u201d. If you refresh the page, you should remain in an authenticated state. If you press Logout then you should return to the login screen.\n\nNow that we have a working login flow with persistent authentication it is time to pull in our expense data from Supabase.\nStep 7: Requesting user data from Supabase\nFirst, install the Supabase client:\n`bash\nnpm install @supabase/supabase-js`\nIn order to pass an authenticated `user_id` to Supabase we will package it within a JWT. Install jsonwebtoken:\n`bash\nnpm install jsonwebtoken`\nCreate a new file `utils/supabase.js` and add the following:\n```jsx\n// utils/supabase.js\nimport { createClient } from '@supabase/supabase-js'\nimport jwt from 'jsonwebtoken'\nconst getSupabase = (userId) => {\n  const supabase = createClient(\n    process.env.NEXT_PUBLIC_SUPABASE_URL,\n    process.env.NEXT_PUBLIC_SUPABASE_KEY\n  )\nif (userId) {\n    const payload = {\n      userId,\n      exp: Math.floor(Date.now() / 1000) + 60 * 60,\n    }\n\n\n```supabase.auth.session = () => ({\n  access_token: jwt.sign(payload, process.env.SUPABASE_SIGNING_SECRET),\n})\n```\n\n\n}\nreturn supabase\n}\nexport { getSupabase }\n```\nOur payload for the JWT will contain our user's unique identifier from Stytch, their `user_id`. We are signing this JWT using Supabase's signing secret, so Supabase will be able to validate it is authentic and hasn't been tampered with in transit.\nLet's load our expenses from Supabase on the home page! Update `pages/index.js` a final time to make a request for expense data from Supabase.\n```jsx\nimport styles from '../styles/Home.module.css'\nimport StytchLogin from '../components/StytchLogin'\nimport Profile from '../components/Profile'\nimport { getAuthenticatedUserFromSession } from '../utils/stytchLogic'\nimport { getSupabase } from '../utils/supabase'\nconst Index = ({ user, publicToken }) => {\n  let content\n  if (user) {\n    content = \n  } else {\n    content = \n  }\nreturn {content}\n}\nexport async function getServerSideProps({ req, res }) {\n  const userId = await getAuthenticatedUserFromSession(req, res)\nif (userId) {\n    const supabase = getSupabase(userId)\n    const { data: expenses } = await supabase.from('expenses').select('*')\n\n\n```return {\n  props: {\n    user: { userId, expenses },\n    publicToken: process.env.STYTCH_PUBLIC_TOKEN,\n  },\n}\n```\n\n\n} else {\n    return {\n      props: { publicToken: process.env.STYTCH_PUBLIC_TOKEN },\n    }\n  }\n}\nexport default Index\n```\nWhen we reload our application, we are still getting the empty state for expenses.\nThis is because we enabled Row Level Security, which blocks all requests by default and lets you granularly control access to the data in your database. To enable our user to select their expenses we need to write a RLS policy.\nStep 8: Write a policy to allow select\nOur policy will need to know who our currently logged in user is to determine whether or not they should have access. Let's create a PostgreSQL function to extract the current user from our new JWT.\nNavigate back to the Supabase dashboard, select SQL from the sidebar menu, and click New query. This will create a new query,, which will allow us to run any SQL against our Postgres database.\nWrite the following and click Run.\n`sql\ncreate or replace function auth.user_id() returns text as $$\n select nullif(current_setting('request.jwt.claims', true)::json->>'userId', '')::text;\n$$ language sql stable;`\nYou should see the output `Success, no rows returned`. This created a function called `auth.user_id()`, which will inspect the `userId` field of our JWT payload.\n\nNote: To learn more about PostgreSQL functions, check out this deep dive video.\n\nLet's create a policy that checks whether this user is the owner of an expense.\nSelect Authentication from the Supabase sidebar menu, click Policies, then New Policy.\n\nFrom the modal, select For full customization create a policy from scratch and add the following.\n\nThis policy is calling the function we just created to get the currently logged in user's `user_id` `auth.user_id()` and checking whether this matches the `user_id` column for the current expense. If it does, then it will allow the user to select it, otherwise it will continue to deny.\nClick Review and then Save policy. After you've saved, click Enable RLS on the table to enable the policy we just created.\n\nNote: To learn more about RLS and policies, check out this video.\n\nThe last thing we need to do is update the `user_id` columns for our existing expenses.\nHead back to the Supabase dashboard, and select Table editor from the sidebar. You will notice each entry has `user_id` set to `NULL`. We need to update this value to the proper `user_id`.\n\nTo get the `user_id` for our Stytch user, you can pull it from the welcome page in our example app (eg `user-test-61497d40-f957-45cd-a6c8-5408d22e93bc`).\n\nUpdate each row in Supabase to this `user_id`.\n\nReturn to `localhost:3000`, and you will see your expenses listed.\n\nWe now have a basic expense tracker application powered by Stytch, Supabase, and Next.js. From here you could add additional features like adding, editing, and organizing your expenses further.\n\nNote: You can find a completed version of this project on Github.\n\nOptional: Add Google One Tap\nIn this optional step, we will extend our application to allow users to login with Google One Tap in addition to Email magic links.\nYou will need to follow the first four steps of this guide to create a Google project, set up Google OAuth consent, and configure credentials and redirect URLs.\nFirst, we will make some adjustments to the `StytchLogin` component. We will update the configuration, so that it uses both Google OAuth, and Email magic links.\n```jsx\n// components/StytchLogin.js\nimport React from 'react'\nimport { Stytch } from '@stytch/stytch-react'\nconst stytchConfig = {\n  loginOrSignupView: {\n    products: ['oauth', 'emailMagicLinks'],\n    oauthOptions: {\n      providers: [\n        {\n          type: 'google',\n          one_tap: true,\n          position: 'embedded',\n        },\n      ],\n      loginRedirectURL: 'http://localhost:3000/api/authenticate?type=oauth',\n      signupRedirectURL: 'http://localhost:3000/api/authenticate?type=oauth',\n    },\n    emailMagicLinksOptions: {\n      loginRedirectURL: 'http://localhost:3000/api/authenticate',\n      loginExpirationMinutes: 30,\n      signupRedirectURL: 'http://localhost:3000/api/authenticate',\n      signupExpirationMinutes: 30,\n      createUserAsPending: true,\n    },\n  },\n  style: {\n    fontFamily: '\"Helvetica New\", Helvetica, sans-serif',\n    width: '321px',\n    primaryColor: '#0577CA',\n  },\n}\nconst StytchLogin = ({ publicToken }) => {\n  return (\n    \n  )\n}\nexport default StytchLogin\n```\nWe also need to make an adjustment to the function `authenticateTokenStartSession` in `stytchLogic.js`. Stytch has separate authentication endpoints for Email magic links and OAuth, so we need to route our token correctly.\n```jsx\n// utils/stytchLogic.js\n// leave the rest of the file contents as is\nexport const authenticateTokenStartSession = async (req, res) => {\n  const { token, type } = req.query\n  let sessionToken\n  try {\n    const stytchClient = loadStytch()\n    if (type == 'oauth') {\n      const resp = await stytchClient.oauth.authenticate(token, {\n        session_duration_minutes: 30,\n        session_management_type: 'stytch',\n      })\n      sessionToken = resp.session.stytch_session.session_token\n    } else {\n      const resp = await stytchClient.magicLinks.authenticate(token, {\n        session_duration_minutes: 30,\n      })\n      sessionToken = resp.session_token\n    }\n  } catch (error) {\n    console.log(error)\n    const errorString = JSON.stringify(error)\n    return res.status(400).json({ errorString })\n  }\nsetCookies(SESSION_COOKIE, sessionToken, {\n    req,\n    res,\n    maxAge: 60 * 60 * 24,\n    secure: true,\n  })\nreturn res.redirect('/')\n}\n```\nWith these two changes you will now have a working Google One Tap authentication method along with email magic links.\n\nResources\n\nStytch blog\nStytch documentation\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Prerequisites",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/estuary.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'estuary',\n  title: 'Estuary',\n  description:\n    'Create a real-time data pipeline connecting Firestore and Supabase to make migration simple.',\n}\nEstuary Flow is a platform for creating real-time data pipelines at scale.\nIt combines the intuitive interface of an ELT service with an event-driven runtime and a variety of open-source connectors.\nYou can use Flow to migrate your data from Firestore to the Postgres database in your Supabase project.\nYou do this by building a real-time pipeline that captures data from Firestore and materializes (loads) that data to Postgres.\nOnce created, the pipeline backfills all your historical data from Firestore and continues to process new data events in real time.\nPrerequisites\nBefore you begin, you'll need:\n\n\nAn Estuary account. Head to the web app to start for free.\n\n\nFor your Firestore database:\n\n\nA Google service account with read access to your Firestore database, via roles/datastore.viewer. You can assign this role when you create the service account, or add it to an existing service account.\n\n\nA generated JSON service account key for the service account.\n\n\nA Supabase project\n\n\nStep 1: Capture your Firestore data\nYou'll start by creating a capture, a task in Flow that connects to your data source system: in this case, Firestore. This process will create one or more data collections, backed by a real-time data lake.\n\n\nGo to the Captures tab of the Flow web app and choose New Capture. \n\n\nLocate and select the Google Firestore card.\n\n\nA form appears with the properties required for a Firestore capture.\n\nSet a name for your capture.\n\nClick inside the Name field to generate a drop-down menu of available prefixes and select one (likely, this will be the name of your organization). Append a unique capture name after the `/` to create the full name, for example, `acmeCo/myFirestoreCapture`.\n\nFill out the required properties for Firestore.\n\nDatabase: Flow can autodetect the database name, but you may optionally specify it here. This is helpful if the service account used has access to multiple Firebase projects. Your database name usually follows the format `projects/$PROJECTID/databases/(default)`.\nCredentials: The JSON service account key created per the prerequisites.\n\nClick Next.\n\nFlow uses the provided configuration to initiate a connection with Firestore. It maps each collection in the Firestore database to a Flow collection. \n\n\nOptionally, use the Collection Selector to remove any collections you don't need to migrate to Supabase.\n\n\nClick Save and Publish.\n\n\nYou'll see a notification when the capture publishes successfully.\nThe data currently in your Firestore database has been captured to Flow, and future updates to it will be captured continuously.\nClick Materialize Collections to continue.\nStep 2: Materialize your collections to Postgres\nNext, you'll add a Postgres materialization to connect the captured collections to tables in your Supabase Postgres database.\n\nOn the Create Materialization page, search for and select the PostgreSQL tile.\n\nA form appears with the properties required for a Postgres materialization.\n\n\nChoose a unique name for your materialization like you did when naming your capture; for example, `acmeCo/mySupabaseMaterialization`.\n\n\nFill out the required properties for Postgres. You can find most of these in Supabase by going to the Settings section and clicking Database.\n\n\nAddress: Format at `<host>:<port>`.\nUser: Usually, this is `postgres`.\nPassword: The password you set when you created your Supabase project.\n\nClick Next. \n\nFlow initiates a connection with the database and the Collection Selector expands. \n   It's populated with your collections from Firestore, each mapped to a Postgres table.\n\nFor each collection, apply a stricter JSON schema. \n   This ensure that the less-structured Firestore data will be written to a Postgres table in the correct shape.\n\nIn the Collection Selector, choose a collection and click its Specification tab.\nClick Schema Inference. Flow scans the data in your collection and infers a new schema to use for materialization. \nReview the new schema and click Apply Inferred Schema.\n\nClick Save and Publish. You'll see a notification when the materialization publishes successfully.\n\nYour Firestore collections are copied to tables in Supabase. As long as you leave the capture and materialation running, any changes to the Firestore data will be reflected in Supabase in milliseconds.\nResources\nFor more information, visit the Flow docs. In particular:\n\nGuide to create a Data Flow\nFirestore capture connector\nPostgres materializaiton connector\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": ".env",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/prisma.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'prisma',\n  title: 'Prisma',\n  description: 'Connect your Supabase postgres database to your Prisma project.',\n}\nThis guide explains how to quickly connect the Postgres database provided by Supabase to a Prisma project.\nPrisma is an open source next-generation ORM. It consists of the following parts:\n\nPrisma Client: Auto-generated and type-safe query builder for Node.js & TypeScript.\nPrisma Migrate: Migration system.\nPrisma Studio: GUI to view and edit data in your database.\n\nStep 1: Get the connection string from Supabase project settings\nGo to the settings page from the sidebar and navigate to the Database tab. You\u2019ll find the database\u2019s connection string with a placeholder for the password you provided when you created the project.\n\nStep 2: Testing the connection\nTo make sure that everything works correctly, let\u2019s try the connection string in a Prisma project.\nIf you already have one, all you need to do is set the `DATABASE_URL` to the connection string (including the password) in your `.env` file, and you\u2019re good to go.\nIn case you don\u2019t have a Prisma project or this is your first time working with Prisma, you\u2019re going to use the repo from the quickstart guide.\nCloning the starter project\nNavigate into a directory of your choice and run the following command in your terminal:\n`bash\ncurl https://codeload.github.com/prisma/prisma-examples/tar.gz/latest | tar -xz --strip=2 prisma-examples-latest/databases/postgresql-supabase`\nYou can now navigate into the directory and install the project\u2019s dependencies:\n`bash\ncd postgresql-supabase\nnpm install`\nA look at the project\u2019s structure\nThis project comes with TypeScript configured and has the following structure.\n\nA `prisma` directory which contains:\nA `seed.ts` file: This is the data used to seed your database.\nA `schema.prisma` file: Where you define the different database models and relations between them.\nA `script.ts` file: where you will run some queries using Prisma Client.\n\nThis starter also comes with the following packages installed:\n- @prisma/client: An auto-generated and type-safe query builder that\u2019s tailored to your data.\n- prisma: Prisma\u2019s command-line interface (CLI). It allows you to initialize new project assets, generate Prisma Client, and analyze existing database structures through introspection to automatically create your application models.\n\nNote: Prisma works with both JavaScript and TypeScript. However, to get the best possible development experience, using TypeScript is highly recommended.\n\nConfiguring the project\nBy default, Prisma migrations will try to drop the `postgres` database, which can lead to conflicts with Supabase databases. For this scenario, use Prisma Shadow Databases.\nCreate a shadow database in your PostgreSQL server within the same Supabase project using the `psql` CLI and the `DATABASE_URL` from the previous steps (or use the local database).\n`bash\npsql postgresql://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].supabase.co:5432`\nAfter you connect to your project's PostgreSQL instance, create another database (e.g., `postgres_shadow`):\n`bash\npostgres=> CREATE DATABASE postgres_shadow;\npostgres=> exit`\nIn the `.env` file, update `DATABASE_URL` and `SHADOW_DATABASE_URL` to the connection string from step 1. The `.env` file should look like:\n```env\n.env\nDATABASE_URL=\"postgres://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].supabase.co:5432/postgres\"\nSHADOW_DATABASE_URL=\"postgres://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].supabase.co:5432/postgres_shadow\"\n```\nThis is what your `schema.prisma` file should look like:\n```go\ndatasource db {\n  provider          = \"postgresql\"\n  url               = env(\"DATABASE_URL\")\n  shadowDatabaseUrl = env(\"SHADOW_DATABASE_URL\")\n}\ngenerator client {\n  provider = \"prisma-client-js\"\n}\nmodel Post {\n  id        Int     @id @default(autoincrement())\n  title     String\n  content   String?\n  published Boolean @default(false)\n  author    User?   @relation(fields: [authorId], references: [id])\n  authorId  Int?\n}\nmodel User {\n  id    Int     @id @default(autoincrement())\n  email String  @unique\n  name  String?\n  posts Post[]\n}\n```\nTo test that everything works correctly, run the following command to create a migration:\n`bash\nnpx prisma migrate dev --name init`\nYou can optionally give your migration a name, depending on the changes you made. Since this is the project\u2019s first migration, you\u2019re setting the `--name` flag to \u201cinit\u201d. If everything works correctly, you should get the following message in your terminal:\n`text\nYour database is now in sync with your schema.\n:heavy_check_mark: Generated Prisma Client (4.x.x) to ./node_modules/@prisma/client in 111ms`\nThis will create a `prisma/migrations` folder inside your `prisma` directory and synchronize your Prisma schema with your database schema.\n\nNote: If you want to skip the process of creating a migration history, you can use the prisma db push command instead of `prisma migrate dev`. However, we recommend using `prisma migrate dev` to evolve your database schema in development.\nIf you would like to get a conceptual overview of how Prisma Migrate works and which commands to use in what environment, refer to this page in the Prisma documentation.\n\nIf you go to your Supabase project, in the table editor, you should see that two tables have been created, a `Post`, `User`, and `_prisma_migrations` tables. The `_prisma_migrations` table is used to keep\n\nThat\u2019s it! You have now successfully connected a Prisma project to a PostgreSQL database hosted on Supabase and ran your first migration.\nConnection pooling with Supabase\nIf you\u2019re working in a serverless environment (for example Node.js functions hosted on AWS Lambda, Vercel or Netlify Functions), you need to set up connection pooling using a tool like PgBouncer. That\u2019s because every function invocation may result in a new connection to the database. \nSupabase supports connection management using PgBouncer.\nGo to the Database page from the sidebar in the Supabase dashboard and navigate to Connection pool settings:\n\nWhen updating your database schema, you need to use the non-pooled connection URL (like the one used in step 1). You can configure the non-pooled connection string by using the `directUrl` property in the datasource block.\nUpdate your `.env` file with the following changes:\n1. Rename the `DATABASE_URL` environment variable to `DIRECT_URL`\n1. Create a `DATABASE_URL` environment variable and paste in the new connection string from the dashboard as its value\nIt is recommended to minimize the number of concurrent connections by setting the `connection_limit` to `1`. You can set connection limit by appending `?connection_limit=1` to your connection string\nYour `.env` file should resemble the following:\n```env\n.env\nPostgreSQL connection string used for migrations\nDIRECT_URL=\"postgres://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].supabase.co:6543/postgres\"\nPostgreSQL connection string with pgBouncer config \u2014 used by Prisma Client\nDATABASE_URL=\"postgres://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].supabase.co:6543/postgres?connection_limit=1\"\nSHADOW_DATABASE_URL=\"postgres://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].supabase.co:5432/postgres_shadow\"\n```\nUpdate your Prisma schema by setting the `directUrl` in the datasource block:\n`go\ndatasource db {\n  provider          = \"postgresql\"\n  url               = env(\"DATABASE_URL\")\n  directUrl         = env(\"DIRECT_URL\")\n  shadowDatabaseUrl = env(\"SHADOW_DATABASE_URL\")\n}`\n\nNote: This feature is available from Prisma version 4.10.0 and higher.\n\nIf you want to learn more about Prisma, check out the docs. Also in case you have any questions or run into any issue, feel free to start a discussion in the repo\u2019s discussions section.\nTroubleshooting\n1. Missing grants\nIf you run `prisma migrate dev --name init` multiple times, it sometimes asks if you want to recreate the whole schema. If you chose yes, it will delete the public schema and recreate it. The default grants are missing after this.\nIf you run into this problem, create a draft migration using `prisma migrate dev --create-only`, and add the following helper SQL:\n```sql\ngrant usage on schema public to postgres, anon, authenticated, service_role;\ngrant all privileges on all tables in schema public to postgres, anon, authenticated, service_role;\ngrant all privileges on all functions in schema public to postgres, anon, authenticated, service_role;\ngrant all privileges on all sequences in schema public to postgres, anon, authenticated, service_role;\nalter default privileges in schema public grant all on tables to postgres, anon, authenticated, service_role;\nalter default privileges in schema public grant all on functions to postgres, anon, authenticated, service_role;\nalter default privileges in schema public grant all on sequences to postgres, anon, authenticated, service_role;\n```\nRun `prisma migrate dev` to apply the draft migration to the database.\n2. Using Prisma with multiple PostgreSQL schemas\nIf you're using multiple database schemas, enable the `multiSchema` Preview feature flag in the `generator` block of your Prisma schema:\n```go\ndatasource db {\n  provider          = \"postgresql\"\n  url               = env(\"DATABASE_URL\")\n  directURL         = env(\"DIRECT_URL\")\n  shadowDatabaseUrl = env(\"SHADOW_DATABASE_URL\")\n}\ngenerator client {\n  provider        = \"prisma-client-js\"\n  previewFeatures = [\"multiSchema\"]\n}\n```\nNext, specify the database schemas you would like to include in your Prisma schema:\n```go\ndatasource db {\n  provider          = \"postgresql\"\n  url               = env(\"DATABASE_URL\")\n  directURL         = env(\"DIRECT_URL\")\n  shadowDatabaseUrl = env(\"SHADOW_DATABASE_URL\")\n  schemas           = [\"public\", \"auth\"]\n}\ngenerator client {\n  provider        = \"prisma-client-js\"\n  previewFeatures = [\"multiSchema\"]\n}\n```\nYou can then specify what schema a model or enum belongs to using the `@@schema` attribute:\n```go\nmodel User {\n  id     Int     @id\n  // ...\n@@schema(\"auth\") // or @@schema(\"public\")\n}\n```\nTo learn more about using Prisma with multiple database schemas, refer to this page in the Prisma docs.\n3. Enabling PosgreSQL extensions\nIf you would like to use a PostgreSQL extension with Prisma, enable the `postgresqlExtensions` Preview feature flag in the `generator` block of your Prisma schema:\n```go\ndatasource db {\n  provider          = \"postgresql\"\n  url               = env(\"DATABASE_URL\")\n  directURL         = env(\"DIRECT_URL\")\n  shadowDatabaseUrl = env(\"SHADOW_DATABASE_URL\")\n}\ngenerator client {\n  provider        = \"prisma-client-js\"\n  previewFeatures = [\"postgresqlExtensions\"]\n}\n```\nNext, specify the extensions you need in the `datasource` block:\n```go\ndatasource db {\n  provider          = \"postgresql\"\n  url               = env(\"DATABASE_URL\")\n  directURL         = env(\"DIRECT_URL\")\n  shadowDatabaseUrl = env(\"SHADOW_DATABASE_URL\")\n  extensions        = [hstore(schema: \"myHstoreSchema\"), pg_trgm, postgis(version: \"2.1\")]\n}\ngenerator client {\n  provider        = \"prisma-client-js\"\n  previewFeatures = [\"postgresqlExtensions\"]\n}\n```\nTo learn more about using Prisma with PostgreSQL extensions, refer to this page in the Prisma docs.\nResources\n\nPrisma official website.\nPrisma GitHub.\nPrisma documentation.\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Step 1: Getting started",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/onesignal.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'onesignal',\n  title: 'OneSignal',\n  description:\n    'OneSignal allows you to send cloud messages to your users. Combine OneSignal with your Supabase apps and you can reach out to your users whenever there is a change in your database.',\n  video: 'https://www.youtube.com/v/mw0DLwItue4',\n}\nOneSignal is a tool that allows you to send messages across different channels such as the following to keep your users engaged.\n\nPush notifications\nSMS\nEmails\nIn-app notifications\n\nHere is William giving us the overview of how OneSignal can work with Supabase to send notifications to your users.\n\n\n\nIn this guide, we will build a similar app and steps you through how you can integrate OneSignal with Supabase to create a seamless cloud messaging experience for your users using Database webhooks and edge functions through a simple Next.js application.\n\nWe will create a simple ordering app and use Supabase Database Webhooks in conjunction with Edge Function to provide a real-time push notification experience.\nYou can find the complete example app along with the edge functions code to send the notifications here.\n\nStep 1: Getting started\nBefore we dive into the code, this guide assumes that you have the following ready\n\nSupabase project created\nOneSignal app created\nSupabase CLI installed on your machine\n\nLet\u2019s create a Next.js app with tailwind CSS pre-installed\n`bash\nnpx create-next-app -e with-tailwindcss --ts`\nWe will then install the Supabase and OneSignal SDK.\n`bash\nnpm i @supabase/supabase-js\nnpm i react-onesignal`\nAfter that, follow the instructions here to set up OneSignal for the web. You can set the URL of the app as a local host if you want to run the app locally, or add a remote URL if you want to deploy your app to a public hosting. You should add the file you obtain in step 4 of the instruction under the `public` directory of your Next.js app like this.\nStep 2: Build Next.js app\nThe Next.js app will have a login form for the user to sign in, and a button that they can press to make an order once they are signed in. Update the `index.tsx` file to the following.\n```tsx title=\"pages/index.tsx\"\nimport { createClient, User } from '@supabase/supabase-js'\nimport type { NextPage } from 'next'\nimport Head from 'next/head'\nimport React, { useEffect, useState } from 'react'\nimport OneSignal from 'react-onesignal'\nconst supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!\nconst supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!\nconst oneSignalAppId = process.env.NEXT_PUBLIC_ONESIGNAL_APP_ID!\nconst supabase = createClient(supabaseUrl, supabaseAnonKey)\nconst Home: NextPage = () => {\n  const [user, setUser] = useState(null)\nconst [oneSignalInitialized, setOneSignalInitialized] = useState(false)\n/*\n   * Initializes OneSignal SDK for a given Supabase User ID\n   * @param uid Supabase User ID\n   /\n  const initializeOneSignal = async (uid: string) => {\n    if (oneSignalInitialized) {\n      return\n    }\n    setOneSignalInitialized(true)\n    await OneSignal.init({\n      appId: oneSignalAppId,\n      notifyButton: {\n        enable: true,\n      },\n\n\n```  allowLocalhostAsSecureOrigin: true,\n})\n\nawait OneSignal.setExternalUserId(uid)\n```\n\n\n}\nconst sendMagicLink = async (event: React.FormEvent) => {\n    event.preventDefault()\n    const { email } = Object.fromEntries(new FormData(event.currentTarget))\n    if (typeof email !== 'string') return\n\n\n```const { error } = await supabase.auth.signInWithOtp({ email })\nif (error) {\n  alert(error.message)\n} else {\n  alert('Check your email inbox')\n}\n```\n\n\n}\n// Place a order with the selected price\n  const submitOrder = async (event: React.FormEvent) => {\n    event.preventDefault()\n    const { price } = Object.fromEntries(new FormData(event.currentTarget))\n    if (typeof price !== 'string') return\n\n\n```const { error } = await supabase.from('orders').insert({ price: Number(price) })\nif (error) {\n  alert(error.message)\n}\n```\n\n\n}\nuseEffect(() => {\n    const initialize = async () => {\n      const initialUser = (await supabase.auth.getUser())?.data.user\n      setUser(initialUser ?? null)\n      if (initialUser) {\n        initializeOneSignal(initialUser.id)\n      }\n    }\n\n\n```initialize()\n\nconst authListener = supabase.auth.onAuthStateChange(async (event, session) => {\n  const user = session?.user ?? null\n  setUser(user)\n  if (user) {\n    initializeOneSignal(user.id)\n  }\n})\n\nreturn () => {\n  authListener.data.subscription.unsubscribe()\n}\n```\n\n\n}, [])\nreturn (\n    <>\n      \nOneSignal Order Notification App\n\n\n\n\n```  <main className=\"flex items-center justify-center min-h-screen bg-black\">\n    {user ? (\n      <form className=\"flex flex-col space-y-2\" onSubmit={submitOrder}>\n        <select\n          className=\"bg-gray-50 border border-gray-300 text-gray-900 text-sm rounded block p-2\"\n          name=\"price\"\n        >\n          <option value=\"100\">$100</option>\n          <option value=\"200\">$200</option>\n          <option value=\"300\">$300</option>\n        </select>\n        <button type=\"submit\" className=\"py-1 px-4 text-lg bg-green-400 rounded\">\n          Place an Order\n        </button>\n      </form>\n    ) : (\n      <form className=\"flex flex-col space-y-2\" onSubmit={sendMagicLink}>\n        <input\n          className=\"border-green-300 border rounded p-2 bg-transparent text-white\"\n          type=\"email\"\n          name=\"email\"\n          placeholder=\"Email\"\n        />\n        <button type=\"submit\" className=\"py-1 px-4 text-lg bg-green-400 rounded\">\n          Send Magic Link\n        </button>\n      </form>\n    )}\n  </main>\n```\n\n\n)\n}\nexport default Home\n```\nThere is quite a bit of stuff going on here, but basically, it\u2019s creating a simple UI for the user to sign in using the magic link, and once the user is signed in, will initialize OneSignal to ask the user to receive notifications on the website.\nNotice that inside the `initializeOneSignal()` function, we are setting the Supabase user ID as an external user ID of OneSignal. This allows us to later send push notifications to the user using their Supabase user ID from the backend, which is very handy.\n`tsx\nawait OneSignal.setExternalUserId(uid)`\nThe front-end side of things is done here. Let\u2019s get into the backend.\nWe also need to set our environment variables. Create a `.env.local` file and use the following template to set the environment variables. You can find your Supabase configuration in your dashboard under `settings > API`, and you can find the OneSignal app ID from `Settings > Keys & IDs`\n`bash\nNEXT_PUBLIC_SUPABASE_URL=YOUR_SUPABASE_URL\nNEXT_PUBLIC_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY\nNEXT_PUBLIC_ONESIGNAL_APP_ID=YOUR_ONESIGNAL_APP_ID`\n\nStep 3: Create the Edge Function\nLet\u2019s create an edge function that will receive database webhooks from the database and calls the OneSignal API to send the push notification.\n`bash\nsupabase functions new notify`\nReplace the contents of `supabase/functions/notify/index.ts` with the following\n```tsx\nimport { serve } from 'https://deno.land/std@0.177.0/http/server.ts'\nimport * as OneSignal from 'https://esm.sh/@onesignal/node-onesignal@1.0.0-beta7'\nconst OnesignalAppId = Deno.env.get('ONESIGNAL_APP_ID')!\nconst OnesignalUserAuthKey = Deno.env.get('USER_AUTH_KEY')!\nconst OnesignalRestApiKey = Deno.env.get('ONESIGNAL_REST_API_KEY')!\nconst configuration = OneSignal.createConfiguration({\n  userKey: OnesignalUserAuthKey,\n  appKey: OnesignalRestApiKey,\n})\nconst onesignal = new OneSignal.DefaultApi(configuration)\nserve(async (req) => {\n  try {\n    const { record } = await req.json()\n\n\n```// Build OneSignal notification object\nconst notification = new OneSignal.Notification()\nnotification.app_id = _OnesignalAppId_\nnotification.include_external_user_ids = [record.user_id]\nnotification.contents = {\n  en: `You just spent $${record.price}!`,\n}\nconst onesignalApiRes = await onesignal.createNotification(notification)\n\nreturn new Response(JSON.stringify({ onesignalResponse: onesignalApiRes }), {\n  headers: { 'Content-Type': 'application/json' },\n})\n```\n\n\n} catch (err) {\n    console.error('Failed to create OneSignal notification', err)\n    return new Response('Server error.', {\n      headers: { 'Content-Type': 'application/json' },\n      status: 400,\n    })\n  }\n})\n```\nIf you see bunch of errors in your editor, it's because your editor is not configured to use Deno. Follow the official setup guide here to setup your IDE to use Deno.\nThe function receives a `record` object, which is the row inserted in your `orders` table, and constructs a notification object to then send to OneSignal to deliver the push notification.\nWe also need to set the environment variable for the function. Create a `.env` file under your `supabase` directory and paste the following.\n`bash\nONESIGNAL_APP_ID=YOUR_ONESIGNAL_APP_ID\nUSER_AUTH_KEY=YOUR_USER_AUTH_KEY\nONESIGNAL_REST_API_KEY=YOUR_ONESIGNAL_REST_API_KEY`\n`ONESIGNAL_APP_ID` and `ONESIGNAL_REST_API_KEY` can be found under `Settings > Keys & IDs` of your OneSignal app, and `USER_AUTH_KEY` can be found by going to `Account & API Keys` page by clicking your icon in the top right corner and scrolling to the `User Auth Key` section.\n\nOnce your environment variables are filled in, you can run the following command to set the environment variable.\n`bash\nsupabase secrets set --env-file ./supabase/.env`\nAt this point, the function should be ready to be deployed! Run the following command to deploy your functions to the edge! The `no-verify-jwt` flag is required if you plan to call the function from a webhook.\n`bash\nsupabase functions deploy notify --no-verify-jwt`\nStep 4: Setting up the Supabase database\nFinally, we get to set up the database! Run the following SQL to set up the `orders` table.\n`sql\ncreate table\n  if not exists public.orders (\n    id uuid not null primary key default uuid_generate_v4 (),\n    created_at timestamptz not null default now (),\n    user_id uuid not null default auth.uid (),\n    price int8 not null\n  );`\nAs you can see, the `orders` table has 4 columns and 3 of them have default values. That means all we need to send from the front-end app is the price. That is why our insert statement looked very simple.\n`tsx\nconst { error } = await supabase.from('orders').insert({\n  price: 100,\n})`\nLet\u2019s also set up the webhook so that whenever a new row is inserted in the `orders` table, it calls the edge function. Go to `Database > Webhooks` and create a new Database Webhook. The table should be set to `orders` and Events should be inserted. The type should be HTTP Request, the HTTP method should be POST, and the URL should be the URL of your edge function. Hit confirm to save the webhook configuration.\n\nAt this point, the app should be complete! Run your app locally with `npm run dev`, or deploy your app to a hosting service and see how you receive a push notification when you place an order!\nRemember that if you decide to deploy your app to a hosting service, you would need to create another OneSignal app configured for your local address.\n\nResources\nThis particular example was using Next.js, but you can apply the same principles to implement send push notification, SMS, Emails, and in-app-notifications on other platforms as well.\n\nOneSignal + Flutter + Supabase example\nOneSignal Mobile Quickstart\nOneSignal Documentation\nOneSignal Onboarding guide\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "start the app",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/integrations/picket.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'picket',\n  title: 'Picket',\n  description:\n    \"Get the best of web2 and web3. Picket allows your users to log in with their wallet without sacrificing Supabase's awesome data management and security features.\",\n}\nPicket is a developer-first, multi-chain web3 auth platform. With Picket, you can easily authenticate users via their wallets and token gate anything.\nThis guide steps through building a simple todo list Next.js application with Picket and Supabase. We use Picket to allow users to login into our app with their wallets and leverage Supabase's Row Level Security (RLS) to securely store user information off-chain.\n\nCheckout a live demo of a Picket + Supabase integration\n\nThe code for this guide is based of this example repo.\nRequirements\n\nYou have Supabase account. If you don't, sign up at https://supabase.com/\nYou have a Picket account. If you don't, sign up at https://picketapi.com/\nYou've read the Picket Setup Guide\nFamiliarity with React and Next.js\n\nStep 1: Create a Picket Project\nFirst, we'll create a new project in our Picket dashboard.\nClick the `Create New Project` button at the top of the Projects section on your Picket dashboard. Edit the project to give it a memorable name.\n\nWe're done for now! We'll revisit this project when we are setting up environment variables in our app.\nStep 2: Create a Supabase Project\nFrom your Supabase dashboard, click `New project`.\nEnter a `Name` for your Supabase project.\nEnter a secure `Database Password`.\nSelect the any `Region`.\nClick `Create new project`.\n\nStep 3: Create new New Table with RLS in Supabase\nCreate a `todos` Table\nFrom the sidebar menu in the Supabase dashboard, click `Table editor`, then `New table`.\nEnter `todos` as the `Name` field.\nSelect `Enable Row Level Security (RLS)`.\nCreate four columns:\n\n`name` as `text`\n`wallet_address` as `text`\n`completed` as `bool` with the default value `false`\n`created_at` as timestamptz with a default value of `now()`\n\nClick `Save` to create the new table.\n\nSetup Row Level Security (RLS)\nNow we want to make sure that only the `todos` owner, the user's `wallet_address`, can access their todos. The key component of the this RLS policy is the expression\n`sql\n((jwt() ->> 'walletAddress'::text) = wallet_address)`\nThis expression checks that the wallet address in the requesting JWT access token is the same as the `wallet_address` in the `todos` table.\n\nStep 4: Create a Next.js app\nNow, let's start building!\nCreate a new Typescript Next.js app\n`bash\nnpx create-next-app@latest --typescript`\nCreate a `.env.local` file and enter the following values\n\n`NEXT_PUBLIC_PICKET_PUBLISHABLE_KEY` => Copy the publishable key from the Picket project you created in step 1\n`PICKET_PROJECT_SECRET_KEY` => Copy the secret key from the Picket project you created in the step 1\n`NEXT_PUBLIC_SUPABASE_URL` => You can find this URL under \"Settings > API\" in your Supabase project\n`NEXT_PUBLIC_SUPABASE_ANON_KEY` => You can find this project API key under \"Settings > API\" in your Supabase project\n`SUAPBASE_JWT_SECRET`=> You can find this secret under \"Settings > API\" in your Supabase project\n\n`txt\nNEXT_PUBLIC_PICKET_PUBLISHABLE_KEY=\"YOUR_PICKET_PUBLISHABLE_KEY\"\nPICKET_PROJECT_SECRET_KEY=\"YOUR_PICKET_PROJECT_SECRET_KEY\"\nNEXT_PUBLIC_SUPABASE_URL=\"YOUR_SUPABASE_URL\"\nNEXT_PUBLIC_SUPABASE_ANON_KEY=\"YOUR_SUPABASE_ANON_KEY\"\nSUPABASE_JWT_SECRET=\"YOUR_SUPABASE_JWT_SECRET\"`\nStep 5: Setup Picket for Wallet Login\n\nFor more information on how to setup Picket in your Next.js app, checkout the Picket getting started guide\nAfter initializing our app, we can setup Picket.\n\nInstall the Picket React and Node libraries\n`bash\nnpm i @picketapi/picket-react @picketapi/picket-node`\nUpdate `pages/_app.tsx` to setup the `PicketProvider`\n```tsx\nimport '../styles/globals.css'\nimport type { AppProps } from 'next/app'\nimport { PicketProvider } from '@picketapi/picket-react'\nexport default function App({ Component, pageProps }: AppProps) {\n  return (\n    \n\n\n  )\n}\n```\nUpdate `pages/index.tsx` to let users log in and out with their wallet\n```tsx\nimport { GetServerSideProps } from 'next'\nimport { useRouter } from 'next/router'\nimport { useCallback } from 'react'\nimport styles from '../styles/Home.module.css'\nimport { usePicket } from '@picketapi/picket-react'\nimport { cookieName } from '../utils/supabase'\ntype Props = {\n  loggedIn: boolean\n}\nexport default function Home(props: Props) {\n  const { loggedIn } = props\n  const { login, logout, authState } = usePicket()\n  const router = useRouter()\nconst handleLogin = useCallback(async () => {\n    let auth = authState\n    // no need to re-login if they've already connected with Picket\n    if (!auth) {\n      // login with Picket\n      auth = await login()\n    }\n\n\n```// login failed\nif (!auth) return\n\n// create a corresponding supabase access token\nawait fetch('/api/login', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    accessToken: auth.accessToken,\n  }),\n})\n// redirect to their todos page\nrouter.push('/todos')\n```\n\n\n}, [authState, login, router])\nconst handleLogout = useCallback(async () => {\n    // clear both picket and supabase session\n    await logout()\n    await fetch('/api/logout', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n    })\n    // refresh the page\n    router.push('/')\n  }, [logout, router])\nreturn (\n    \n\n        {loggedIn ? (\n          Log Out to Switch Wallets\n        ) : (\n          Log In with Your Wallet\n        )}\n      \n\n  )\n}\nexport const getServerSideProps: GetServerSideProps = async ({ req }) => {\n  // get supabase token server-side\n  const accessToken = req.cookies[cookieName]\nif (!accessToken) {\n    return {\n      props: {\n        loggedIn: false,\n      },\n    }\n  }\nreturn {\n    props: {\n      loggedIn: true,\n    },\n  }\n}\n```\nStep 6: Issue a Supabase JWT on Wallet Login\nGreat, now we have setup a typical Picket Next.js app. Next, we need to implement the log in/out API routes to allow users to securely query our Supabase project.\nFirst, install dependencies\n`bash\nnpm install @supabase/supabase-js jsonwebtoken cookie js-cookie`\nCreate a utility function to create a Supabase client with a custom access token in `utils/supabase.ts`\n```ts\nimport { createClient, SupabaseClientOptions } from '@supabase/supabase-js'\nexport const cookieName = 'sb-access-token'\nconst getSupabase = (accessToken: string) => {\n  const options: SupabaseClientOptions<'public'> = {}\nif (accessToken) {\n    options.global = {\n      headers: {\n        // This gives Supabase information about the user (wallet) making the request\n        Authorization: `Bearer ${accessToken}`,\n      },\n    }\n  }\nconst supabase = createClient(\n    process.env.NEXT_PUBLIC_SUPABASE_URL!,\n    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,\n    options\n  )\nreturn supabase\n}\nexport { getSupabase }\n```\nCreate new api route `pages/api/login.ts`. This route validates the Picket access token then issues another equivalent Supabase access token for us to use with the Supabase client.\n```ts\nimport type { NextApiRequest, NextApiResponse } from 'next'\nimport jwt from 'jsonwebtoken'\nimport cookie from 'cookie'\nimport Picket from '@picketapi/picket-node'\nimport { cookieName } from '../../utils/supabase'\n// create picket node client with your picket secret api key\nconst picket = new Picket(process.env.PICKET_PROJECT_SECRET_KEY!)\nconst expToExpiresIn = (exp: number) => exp - Math.floor(Date.now() / 1000)\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  const { accessToken } = req.body\n  // omit expiration time,.it will conflict with jwt.sign\n  const { exp, ...payload } = await picket.validate(accessToken)\n  const expiresIn = expToExpiresIn(exp)\nconst supabaseJWT = jwt.sign(\n    {\n      ...payload,\n    },\n    process.env.SUPABASE_JWT_SECRET!,\n    {\n      expiresIn,\n    }\n  )\n// Set a new cookie with the name\n  res.setHeader(\n    'Set-Cookie',\n    cookie.serialize(cookieName, supabaseJWT, {\n      path: '/',\n      secure: process.env.NODE_ENV !== 'development',\n      // allow the cookie to be accessed client-side\n      httpOnly: false,\n      sameSite: 'strict',\n      maxAge: expiresIn,\n    })\n  )\n  res.status(200).json({})\n}\n```\nAnd now create an equivalent logout api route `/pages/api/logout.ts` to delete the Supabase access token cookie.\n```ts\nimport type { NextApiRequest, NextApiResponse } from 'next'\nimport cookie from 'cookie'\nimport { cookieName } from '../../utils/supabase'\nexport default async function handler(_req: NextApiRequest, res: NextApiResponse) {\n  // Clear the supabase cookie\n  res.setHeader(\n    'Set-Cookie',\n    cookie.serialize(cookieName, '', {\n      path: '/',\n      maxAge: -1,\n    })\n  )\nres.status(200).json({})\n}\n```\nWe can now login and logout to the app with our wallet!\nStep 7: Interacting with Data in Supabase\nNow that we can login to the app, it's time to start interacting with Supabase. Let's make a todo list page for authenticated users.\nCreate a new file `pages/todos.tsx`\n```tsx\nimport { GetServerSideProps } from 'next'\nimport Head from 'next/head'\nimport Link from 'next/link'\nimport { useState, useMemo } from 'react'\nimport jwt from 'jsonwebtoken'\nimport Cookies from 'js-cookie'\nimport styles from '../styles/Home.module.css'\nimport { getSupabase, cookieName } from '../utils/supabase'\ntype Todo = {\n  name: string\n  completed: boolean\n}\ntype Props = {\n  walletAddress: string\n  todos: Todo[]\n}\nconst displayWalletAddress = (walletAddress: string) =>\n  `${walletAddress.slice(0, 6)}...${walletAddress.slice(-4)}`\nexport default function Todos(props: Props) {\n  const { walletAddress } = props\n  const [todos, setTodos] = useState(props.todos)\n// avoid re-creating supabase client every render\n  const supabase = useMemo(() => {\n    const accessToken = Cookies.get(cookieName)\n    return getSupabase(accessToken || '')\n  }, [])\nreturn (\n    \n\nPicket \ud83d\udc9c Supabase\n\n\n\n```  <main className={styles.main}>\n    <h1 className={styles.title}>Your Personal Todo List</h1>\n    <div\n      style={{\n        maxWidth: '600px',\n        textAlign: 'left',\n        fontSize: '1.125rem',\n        margin: '36px 0 24px 0',\n      }}\n    >\n      <p>Welcome {displayWalletAddress(walletAddress)},</p>\n      <p>\n        Your todo list is stored in Supabase and are only accessible to you and your wallet\n        address. Picket + Supabase makes it easy to build scalable, hybrid web2 and web3 apps.\n        Use Supabase to store non-critical or private data off-chain like user app preferences\n        or todo lists.\n      </p>\n    </div>\n    <div\n      style={{\n        textAlign: 'left',\n        fontSize: '1.125rem',\n      }}\n    >\n      <h2>Todo List</h2>\n      {todos.map((todo) => (\n        <div\n          key={todo.name}\n          style={{\n            margin: '8px 0',\n            display: 'flex',\n            alignItems: 'center',\n          }}\n        >\n          <input\n            type=\"checkbox\"\n            checked={todo.completed}\n            onChange={async () => {\n              await supabase.from('todos').upsert({\n                wallet_address: walletAddress,\n                name: todo.name,\n                completed: !todo.completed,\n              })\n              setTodos((todos) =>\n                todos.map((t) => (t.name === todo.name ? { ...t, completed: !t.completed } : t))\n              )\n            }}\n          />\n          <span\n            style={{\n              margin: '0 0 0 8px',\n            }}\n          >\n            {todo.name}\n          </span>\n        </div>\n      ))}\n      <div\n        style={{\n          margin: '24px 0',\n        }}\n      >\n        <Link\n          href={'/'}\n          style={{\n            textDecoration: 'underline',\n          }}\n        >\n          Go back home &rarr;\n        </Link>\n      </div>\n    </div>\n  </main>\n</div>\n```\n\n\n)\n}\nexport const getServerSideProps: GetServerSideProps = async ({ req }) => {\n  // example of fetching data server-side\n  const accessToken = req.cookies[cookieName]\n// require authentication\n  if (!accessToken) {\n    return {\n      redirect: {\n        destination: '/',\n      },\n      props: {\n        walletAddress: '',\n        todos: [],\n      },\n    }\n  }\n// check if logged in user has completed the tutorial\n  const supabase = getSupabase(accessToken)\n  const { walletAddress } = jwt.decode(accessToken) as {\n    walletAddress: string\n  }\n// get todos for the users\n  // if none exist, create the default todos\n  let { data } = await supabase.from('todos').select('*')\nif (!data || data.length === 0) {\n    let error = null\n    ;({ data, error } = await supabase\n      .from('todos')\n      .insert([\n        {\n          wallet_address: walletAddress,\n          name: 'Complete the Picket + Supabase Tutorial',\n          completed: true,\n        },\n        {\n          wallet_address: walletAddress,\n          name: 'Create a Picket Account (https://picketapi.com/)',\n          completed: false,\n        },\n        {\n          wallet_address: walletAddress,\n          name: 'Read the Picket Docs (https://docs.picketapi.com/)',\n          completed: false,\n        },\n        {\n          wallet_address: walletAddress,\n          name: 'Build an Awesome Web3 Experience',\n          completed: false,\n        },\n      ])\n      .select('*'))\n\n\n```if (error) {\n  // log error and redirect home\n  console.error(error)\n  return {\n    redirect: {\n      destination: '/',\n    },\n    props: {\n      walletAddress: '',\n      todos: [],\n    },\n  }\n}\n```\n\n\n}\nreturn {\n    props: {\n      walletAddress,\n      todos: data as Todo[],\n    },\n  }\n}\n```\nThis is a long file, but don't be intimidated. The page is actually straightforward. It\n\nVerifies server-side that the user is authenticated and if they are not redirects them to the homepage\nChecks to see if they already have `todos` . If so, it returns them. If not, it initializes them for the users\nWe render the `todos` and when the user selects or deselects a todo, we update the data in the database\n\nStep 8: Try it Out!\nAnd that's it. If you haven't already, run your app to test it out yourself\n```bash\nstart the app\nnpm run dev\nopen http://localhost:3000\n```\nWhat's Next?\n\nExplore the Picket documentation\nPlay with the live Picket + Supabase demo\nCheckout Picket's example Github repositories\n\nCommon Use-Case for Picket + Supabase\n\nAccount linking. Allow users to associate their wallet address(es) with their existing web2 account in your app\nLeverage Supabase's awesome libraries and ecosystem while still enabling wallet login\nStore app-specific data, like user preferences, about your user's wallet adress off-chain\nCache on-chain data to improve your DApp's performance\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Database",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/features.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'features',\n  title: 'Features',\n  description: 'Supabase features',\n}\nThis is a non-exhaustive list of features that Supabase provides for every project.\nDatabase\nPostgres Database\nEvery project is a full Postgres database. Docs.\nDatabase Extensions\nEvery database comes with a full set of Postgres extensions. Docs.\nDatabase Functions\nCreate custom database functions which you can call from the browser. Docs.\nDatabase Triggers\nAttach triggers to your tables to handle database changes. Docs.\nDatabase Webhooks\nSend database changes to any external service using Webhooks. Link.\nDatabase Backups\nProjects are backed up daily with the option to upgrade to Point in Time recovery.\nSearch\nBuild search functionality using Postgres Full Text Search. Docs.\nSecrets and encryption\nEncrypt sensitive data and store secrets using our Postgres extension, Supabase Vault. Link.\nDatabase migrations\nDevelop locally and push your changes to your production database using migrations. Docs\n\nAuth\nEmail & Password Logins\nBuild email logins for your application or website. Docs.\nMagic Links\nBuild passwordless logins for your application or website.Docs.\nSocial Logins\nProvide social logins - everything from Apple, to GitHub, to Slack. Docs.\nPhone Logins\nProvide phone logins using a third-party SMS provider. Docs.\nRow Level Security\nControl the data each user can access with Postgres Policies. Docs.\nServerside Auth Helpers\nHelpers for implementing user authentication in popular frameworks like Next.js and SvelteKit\nAuth UI Kit\nBuild login and registration pages with custom themes. Docs.\n\nAPIs & Client libraries\nAuto-generated REST API\nRESTful APIs are autogenerated from your database, without a single line of code. Docs.\nAuto-generated GraphQL API\nFast GraphQL APIs using our custom Postgres GraphQL extension. Docs.\nRealtime Database changes\nReceive your database changes through websockets. Docs.\nUser Broadcasting\nSend messages between connected users through websockets. Docs.\nUser Presence\nSynchronize shared state across your users, including online status and typing indicators. Docs.\nClient libraries\nOfficial client libraries for JavaScript and Dart.\nUnofficial libraries supported by the community.\n\nStorage\nFile storage\nSupabase Storage makes it simple to store and serve files. Docs.\nStorage CDN\nCache large files using the Supabase CDN. Docs.\nImage Transformations\nTransform images on the fly. Docs.\n\nEdge Functions\nDeno Edge Functions\nGlobally distributed TypeScript functions to execute custom business logic. Docs.\n\nProject Management\nCLI\nUse our CLI to develop your project locally and deploy to the Supabase Platform. Docs.\nManagement API\nManage your projects programmatically. Docs.\n\nFeature Status\nBoth Postgres and the Supabase Platform are production-ready. Some tools we offer on top of Postgres are still under development.\n| Product                    | Feature                | Stage   |\n| -------------------------- | ---------------------- | ------- |\n| Database                   | Postgres               | `GA`    |\n| Database                   | Triggers               | `GA`    |\n| Database                   | Functions              | `GA`    |\n| Database                   | Extensions             | `GA`    |\n| Database                   | Full Text Search       | `GA`    |\n| Database                   | Webhooks               | `alpha` |\n| Database                   | Point-in-Time Recovery | `alpha` |\n| Database                   | Vault                  | `alpha` |\n| Studio                     |                        | `GA`    |\n| Realtime                   | Postgres Changes       | `GA`    |\n| Realtime                   | Broadcast              | `beta`  |\n| Realtime                   | Presence               | `beta`  |\n| Storage                    |                        | `GA`    |\n| Storage                    | S3 Backend             | `GA`    |\n| Storage                    | CDN                    | `GA`    |\n| Storage                    | Smart CDN              | `beta`  |\n| Storage                    | Image Transformations  | `beta`  |\n| Edge Functions             |                        | `beta`  |\n| Auth                       | OAuth Providers        | `beta`  |\n| Auth                       | Passwordless           | `beta`  |\n| Auth                       | Next.js Auth Helpers   | `alpha` |\n| Auth                       | SvelteKit Auth Helpers | `alpha` |\n| Auth                       | Remix Auth Helpers     | `alpha` |\n| Management API             |                        | `beta`  |\n| CLI                        |                        | `beta`  |\n| Client Library: JavaScript |                        | `GA`    |\n| Client Library: Dart       |                        | `beta`  |\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Architecture",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/architecture.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'architecture',\n  title: 'Architecture',\n  description: 'Supabase design and architecture',\n}\nSupabase is open source. We choose open source tools which are scalable and make them simple to use.\nSupabase is not a 1-to-1 mapping of Firebase. While we are building many of the features that Firebase offers, we are not going about it the same way:\nour technological choices are quite different; everything we use is open source; and wherever possible, we use and support existing tools rather than developing from scratch.\nMost notably, we use Postgres rather than a NoSQL store. This choice was deliberate. We believe that no other database offers the functionality required to compete with Firebase,\nwhile maintaining the scalability required to go beyond it.\nArchitecture\nEach Supabase project consists of several tools:\n\nPostgreSQL (Database)\nPostgreSQL is the core of Supabase. We do not abstract the PostgreSQL database \u2014 you can access it and use it with full privileges. We simply provide tools which makes PostgreSQL as easy to use as Firebase.\n\nOfficial Docs: postgresql.org/docs\nSource code: github.com/postgres/postgres (mirror)\nLicense: PostgreSQL Licence\nLanguage: C\n\nStudio (Dashboard)\nAn open source Dashboard for managing your database and services.\n\nOfficial Docs: Supabase docs\nSource code: github.com/supabase/supabase\nLicense: Apache 2\nLanguage: TypeScript\n\nGoTrue (Auth)\nA JWT-based API for managing users and issuing access tokens. This integrates with PostgreSQL's Row Level Security and the API servers.\n\nOfficial Docs: Supabase Auth reference docs\nSource code: github.com/supabase/gotrue\nLicense: MIT\nLanguage: Go\n\nPostgREST (API)\nA standalone web server that turns your PostgreSQL database directly into a RESTful API.\nWe use this with our pg_graphql extension to provide a GraphQL API.\n\nOfficial Docs: postgrest.org\nSource code: github.com/PostgREST/postgrest\nLicense: MIT\nLanguage: Haskel\n\nRealtime (API & multiplayer)\nA scalable websocket engine for managing user Presence, broadcasting messages, and streaming database changes.\n\nOfficial Docs: Supabase Realtime docs\nSource code: github.com/supabase/realtime\nLicense: Apache 2\nLanguage: Elixir\n\nStorage API (large file storage)\nAn S3-compatible object storage service that stores metadata in Postgres.\n\nOfficial Docs: Supabase Storage reference docs\nSource code: github.com/supabase/storage-api\nLicense: Apache 2.0\nLanguage: NodeJS / TypeScript\n\nDeno (Edge Functions)\nA modern runtime for JavaScript and TypeScript.\n\nOfficial Docs: deno.land\nSource code: github.com/denoland/deno\nLicense: MIT\nLanguage: TypeScript / Rust\n\npostgres-meta (Database management)\nA RESTful API for managing your Postgres. Fetch tables, add roles, and run queries.\n\nOfficial Docs: supabase.github.io/postgres-meta\nSource code: github.com/supabase/postgres-meta\nLicense: Apache 2.0\nLanguage: NodeJS / TypeScript\n\nPgBouncer\nA lightweight connection pooler for PostgreSQL. This is useful for connecting to Postgres when using Serverless functions.\n\nOfficial Docs: pgbouncer.org\nSource code: pgbouncer/pgbouncer\nLicense: ISC\nLanguage: C\n\nKong (API Gateway)\nA cloud-native API gateway, built on top of Nginx.\n\nOfficial Docs: docs.konghq.com\nSource code: github.com/kong/kong\nLicense: Apache 2.0\nLanguage: Lua\n\nProduct Principles\nIt is our goal to provide an architecture that any large-scale company would design for themselves,\nand then provide tooling around that architecture that is easy-to-use for indie-developers and small teams.\nWe use a series of principles to ensure that scalability and usability are never mutually exclusive:\nEverything works in isolation\nEach system must work as a standalone tool with as few moving parts as possible.\nThe litmus test for this is: \"Can a user run this product with nothing but a Postgres database?\"\nEverything is integrated\nSupabase is composable. Even though every product works in isolation, each product on the platform needs to 10x the other products.\nFor integration, each tool should expose an API and Webhooks.\nEverything is extensible\nWe're deliberate about adding a new tool, and prefer instead to extend an existing one.\nThis is the opposite of many cloud providers whose product offering expands into niche use-cases. We provide primitives for developers, which allow them to achieve any goal.\nLess, but better.\nEverything is portable\nTo avoid lock-in, we make it easy to migrate in and out. Our cloud offering is compatible with our self-hosted product.\nWe use existing standards to increase portability (like pg_dump an CSV files). If a new standard emerges which competes with a \"Supabase\" approach, we will deprecate the approach in favor of the standard.\nThis forces us compete on experience. We aim to be the best Postgres hosting service.\nPlay the long game\nWe sacrifice short-term wins for long-term gains. For example, it is tempting to run a fork of Postgres with additional functionality which only our customers need.\nInstead, we prefer to support efforts to upstream missing functionality so that the entire community benefits. This has the additional benefit of ensuring portability and longevity.\nBuild for developers\n\"Developers\" are a specific profile of user: they are builders.\nWhen assessing impact as a function of effort, developers have a large efficiency due to the type of products and systems they can build.\nAs the profile of a developer changes over time, Supabase will continue to evolve the product to fit this evolving profile.\nSupport existing tools\nSupabase supports existing tools and communities wherever possible. Supabase is more like a \"community of communities\" - each tool typically has its own community\nwhich we work with.\nOpen source is something we approach collaboratively: we employ maintainers, sponsor projects, invest in businesses, and develop our own open source tools.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "About RedwoodJS",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-redwoodjs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with RedwoodJS',\n  description: 'Learn how to use Supabase in your RedwoodJS App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n{/ ## Video demo /}\n{/ Coming soon. /}\n{/ Use the annotated timeline to step through this tutorial. /}\n{/ ## Instant deploy /}\n{/ Want to deploy a completed version of this example without following the guide? /}\n{/  /}\n{/ Clicking this button the application will: /}\n{/ - Launch and prepare the Postgres database in Supabase. /}\n{/ - Launch the app in Vercel. /}\n{/ - Fork the example into your own GitHub account. /}\n{/ - Prepare the deployed application with all the necessary environment variables. /}\n{/ If you want to do it yourself, let's get started:` /}\nAbout RedwoodJS\nA Redwood application is split into two parts: a frontend and a backend. This is represented as two node projects within a single monorepo.\nThe frontend project is called `web` and the backend project is called `api`. For clarity, we will refer to these in prose as \"sides\", i.e. the \"web side\" and the \"api side\".\nThey are separate projects because code on the `web side` will end up running in the user's browser while code on the `api side` will run on a server somewhere.\n\nImportant: When this guide refers to \"API\", that means the Supabase API and when it refers to \"api side\", that means the RedwoodJS `api side`.\n\nThe `api side` is an implementation of a GraphQL API. The business logic is organized into \"services\" that represent their own internal API and can be called both from external GraphQL requests and other internal services.\nThe `web side` is built with React. Redwood's router makes it simple to map URL paths to React \"Page\" components (and automatically code-split your app on each route).\nPages may contain a \"Layout\" component to wrap content. They also contain \"Cells\" and regular React components.\nCells allow you to declaratively manage the lifecycle of a component that fetches and displays data.\nFor the sake of consistency with the other framework tutorials, we'll build this app a little differently than normal.\nWe won't use Prisma to connect to the Supabase Postgres database or Prisma migrations as one typically might in a Redwood app.\nInstead, we'll rely on the Supabase client to do some of the work on the `web` side and use the client again on the `api` side to do data fetching as well.\nThat means you will want to refrain from running any `yarn rw prisma migrate` commands and also double check your build commands on deployment to ensure Prisma won't reset your database. Prisma currently doesn't support cross-schema foreign keys, so introspecting the schema fails due\nto how your Supabase `public` schema references the `auth.users`.\n\nBuilding the App\nLet's start building the RedwoodJS app from scratch.\n\nRedwoodJS requires Node.js `>= 14.x <= 16.x` and Yarn `>= 1.15`.\n\nMake sure you have installed yarn since RedwoodJS relies on it to manage its packages in workspaces for its `web` and `api` \"sides\".\nInitialize a RedwoodJS app\nWe can use Create Redwood App command to initialize\nan app called `supabase-redwoodjs`:\n`bash\nyarn create redwood-app supabase-redwoodjs\ncd supabase-redwoodjs`\nWhile the app is installing, you should see:\n```bash\n\u2714 Creating Redwood app\n  \u2714 Checking node and yarn compatibility\n  \u2714 Creating directory 'supabase-redwoodjs'\n\u2714 Installing packages\n  \u2714 Running 'yarn install'... (This could take a while)\n\u2714 Convert TypeScript files to JavaScript\n\u2714 Generating types\nThanks for trying out Redwood!\n```\nThen let's install the only additional dependency supabase-js by running the `setup auth` command:\n`bash\nyarn redwood setup auth supabase`\nWhen prompted:\n\nOverwrite existing /api/src/lib/auth.[jt]s?\n\nSay, yes and it will setup the Supabase client in your app and also provide hooks used with Supabase authentication.\n```bash\n\u2714 Generating auth lib...\n  \u2714 Successfully wrote file`./api/src/lib/auth.js`\n  \u2714 Adding auth config to web...\n  \u2714 Adding auth config to GraphQL API...\n  \u2714 Adding required web packages...\n  \u2714 Installing packages...\n  \u2714 One more thing...\nYou will need to add your Supabase URL (SUPABASE_URL), public API KEY,\n  and JWT SECRET (SUPABASE_KEY, and SUPABASE_JWT_SECRET) to your .env file.\n```\nNext, we want to save the environment variables in a `.env`.\nWe need the `API URL` as well as the `anon` and `jwt_secret` keys that you copied earlier.\n`bash title=.env\nSUPABASE_URL=YOUR_SUPABASE_URL\nSUPABASE_KEY=YOUR_SUPABASE_ANON_KEY\nSUPABASE_JWT_SECRET=YOUR_SUPABASE_JWT_SECRET`\nAnd finally, you will also need to save just the `web side` environment variables to the `redwood.toml`.\n`bash title=redwood.toml\n[web]\n  title = \"Supabase Redwood Tutorial\"\n  port = 8910\n  apiProxyPath = \"/.redwood/functions\"\n  includeEnvironmentVariables = [\"SUPABASE_URL\", \"SUPABASE_KEY\"]\n[api]\n  port = 8911\n[browser]\n  open = true`\nThese variables will be exposed on the browser, and that's completely fine.\nThey allow your web app to initialize the Supabase client with your public anon key\nsince we have Row Level Security enabled on our Database.\nYou'll see these being used to configure your Supabase client in `web/src/App.js`:\n```js title=web/src/App.js\n// ... Redwood imports\nimport { AuthProvider } from '@redwoodjs/auth'\nimport { createClient } from '@supabase/supabase-js'\n// ...\nconst supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_KEY)\nconst App = () => (\n  \n\n\n\n\n\n\n\n\n)\nexport default App\n```\nAnd one optional step is to update the CSS file `web/src/index.css` to make the app look nice.\nYou can find the full contents of this file here.\nStart RedwoodJS and your first Page\nLet's test our setup at the moment by starting up the app:\n`bash\nyarn rw dev`\n\n`rw` is an alias for `redwood`, as in `yarn rw` to run Redwood CLI commands.\n\nYou should see a \"Welcome to RedwoodJS\" page and a message about not having any pages yet.\nSo, let's create a \"home\" page:\n```bash\nyarn rw generate page home /\n\u2714 Generating page files...\n  \u2714 Successfully wrote file `./web/src/pages/HomePage/HomePage.stories.js`\n  \u2714 Successfully wrote file `./web/src/pages/HomePage/HomePage.test.js`\n  \u2714 Successfully wrote file `./web/src/pages/HomePage/HomePage.js`\n\u2714 Updating routes file...\n\u2714 Generating types ...\n```\n\nThe `/` is important here as it creates a root level route.\n\nYou can stop the `dev` server if you want; to see your changes, just be sure to run `yarn rw dev` again.\nYou should see the `Home` page route in `web/src/Routes.js`:\n```bash title=web/src/Routes.js\nimport { Router, Route } from '@redwoodjs/router'\nconst Routes = () => {\n  return (\n    \n\n\n\n  )\n}\nexport default Routes\n```\nSet up a Login component\nLet's set up a Redwood component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\n```bash\nyarn rw g component auth\n\u2714 Generating component files...\n    \u2714 Successfully wrote file `./web/src/components/Auth/Auth.test.js`\n    \u2714 Successfully wrote file `./web/src/components/Auth/Auth.stories.js`\n    \u2714 Successfully wrote file `./web/src/components/Auth/Auth.js`\n```\nNow, update the `Auth.js` component to contain:\n```jsx title=/web/src/components/Auth/Auth.js\nimport { useState } from 'react'\nimport { useAuth } from '@redwoodjs/auth'\nconst Auth = () => {\n  const { logIn } = useAuth()\n  const [loading, setLoading] = useState(false)\n  const [email, setEmail] = useState('')\nconst handleLogin = async (email) => {\n    try {\n      setLoading(true)\n      const { error } = await logIn({ email })\n      if (error) throw error\n      alert('Check your email for the login link!')\n    } catch (error) {\n      alert(error.error_description || error.message)\n    } finally {\n      setLoading(false)\n    }\n  }\nreturn (\n    \n\nSupabase + RedwoodJS\nSign in via magic link with your email below\n\n setEmail(e.target.value)}\n          />\n        \n\n {\n              e.preventDefault()\n              handleLogin(email)\n            }}\n            className={'button block'}\n            disabled={loading}\n          >\n            {loading ? Loading : Send magic link}\n          \n\n\n\n  )\n}\nexport default Auth\n```\nSet up an Account component\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new component for that called `Account.js`.\n```bash\nyarn rw g component account\n\u2714 Generating component files...\n    \u2714 Successfully wrote file `./web/src/components/Account/Account.test.js`\n    \u2714 Successfully wrote file `./web/src/components/Account/Account.stories.js`\n    \u2714 Successfully wrote file `./web/src/components/Account/Account.js`\n```\nAnd then update the file to contain:\n```jsx title=web/src/components/Account/Account.js\nimport { useState, useEffect } from 'react'\nimport { useAuth } from '@redwoodjs/auth'\nconst Account = () => {\n  const { client: supabase, currentUser, logOut } = useAuth()\n  const [loading, setLoading] = useState(true)\n  const [username, setUsername] = useState(null)\n  const [website, setWebsite] = useState(null)\n  const [avatar_url, setAvatarUrl] = useState(null)\nuseEffect(() => {\n    getProfile()\n  }, [supabase.auth.session])\nasync function getProfile() {\n    try {\n      setLoading(true)\n      const user = supabase.auth.user()\n\n\n```  let { data, error, status } = await supabase\n    .from('profiles')\n    .select(`username, website, avatar_url`)\n    .eq('id', user.id)\n    .single()\n\n  if (error && status !== 406) {\n    throw error\n  }\n\n  if (data) {\n    setUsername(data.username)\n    setWebsite(data.website)\n    setAvatarUrl(data.avatar_url)\n  }\n} catch (error) {\n  alert(error.message)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nasync function updateProfile({ username, website, avatar_url }) {\n    try {\n      setLoading(true)\n      const user = supabase.auth.user()\n\n\n```  const updates = {\n    id: user.id,\n    username,\n    website,\n    avatar_url,\n    updated_at: new Date(),\n  }\n\n  let { error } = await supabase.from('profiles').upsert(updates, {\n    returning: 'minimal', // Don't return the value after inserting\n  })\n\n  if (error) {\n    throw error\n  }\n\n  alert('Updated profile!')\n} catch (error) {\n  alert(error.message)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nreturn (\n    \n\nSupabase + RedwoodJS\nYour profile\n\n\nEmail\n\n\n\nName\n setUsername(e.target.value)}\n            />\n          \n\nWebsite\n setWebsite(e.target.value)}\n            />\n          \n\n\n```      <div>\n        <button\n          className=\"button primary block\"\n          onClick={() => updateProfile({ username, website, avatar_url })}\n          disabled={loading}\n        >\n          {loading ? 'Loading ...' : 'Update'}\n        </button>\n      </div>\n\n      <div>\n        <button className=\"button block\" onClick={() => logOut()}>\n          Sign Out\n        </button>\n      </div>\n    </div>\n  </div>\n</div>\n```\n\n\n)\n}\nexport default Account\n```\nYou'll see the use of `useAuth()` several times. Redwood's `useAuth` hook provides convenient ways to access\nlogIn, logOut, currentUser, and access the `supabase` authenticate client. We'll use it to get an instance\nof the supabase client to interact with your API.\nUpdate Home Page\nNow that we have all the components in place, let's update your `HomePage` page to use them:\n```jsx title=web/src/pages/HomePage/HomePage.js\nimport { useAuth } from '@redwoodjs/auth'\nimport { MetaTags } from '@redwoodjs/web'\nimport Account from 'src/components/Account'\nimport Auth from 'src/components/Auth'\nconst HomePage = () => {\n  const { isAuthenticated } = useAuth()\nreturn (\n    <>\n      \n      {!isAuthenticated ?  : }\n  \n  )\n}\nexport default HomePage\n```\n\nWhat we're doing here is showing the sign in form if you aren't logged in and your account profile if you are.\n\nLaunch!\nOnce that's done, run this in a terminal window to launch the `dev` server:\n`bash\nyarn rw dev`\nAnd then open the browser to localhost:8910 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:\n`bash\nyarn rw g component avatar\n  \u2714 Generating component files...\n    \u2714 Successfully wrote file `./web/src/components/Avatar/Avatar.test.js`\n    \u2714 Successfully wrote file `./web/src/components/Avatar/Avatar.stories.js`\n    \u2714 Successfully wrote file `./web/src/components/Avatar/Avatar.js``\nNow, update your Avatar component to contain the following widget:\n```jsx title=web/src/components/Avatar/Avatar.js\nimport { useEffect, useState } from 'react'\nimport { useAuth } from '@redwoodjs/auth'\nconst Avatar = ({ url, size, onUpload }) => {\n  const { client: supabase } = useAuth()\nconst [avatarUrl, setAvatarUrl] = useState(null)\n  const [uploading, setUploading] = useState(false)\nuseEffect(() => {\n    if (url) downloadImage(url)\n  }, [url])\nasync function downloadImage(path) {\n    try {\n      const { data, error } = await supabase.storage.from('avatars').download(path)\n      if (error) {\n        throw error\n      }\n      const url = URL.createObjectURL(data)\n      setAvatarUrl(url)\n    } catch (error) {\n      console.log('Error downloading image: ', error.message)\n    }\n  }\nasync function uploadAvatar(event) {\n    try {\n      setUploading(true)\n\n\n```  if (!event.target.files || event.target.files.length === 0) {\n    throw new Error('You must select an image to upload.')\n  }\n\n  const file = event.target.files[0]\n  const fileExt = file.name.split('.').pop()\n  const fileName = `${Math.random()}.${fileExt}`\n  const filePath = `${fileName}`\n\n  let { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)\n\n  if (uploadError) {\n    throw uploadError\n  }\n\n  onUpload(filePath)\n} catch (error) {\n  alert(error.message)\n} finally {\n  setUploading(false)\n}\n```\n\n\n}\nreturn (\n    \n      {avatarUrl ? (\n        \n      ) : (\n        \n      )}\n      \n\n          {uploading ? 'Uploading ...' : 'Upload'}\n        \n\n\n\n  )\n}\nexport default Avatar\n```\nAdd the new widget\nAnd then we can add the widget to the Account component:\n```jsx title=web/src/components/Account/Account.js\n// Import the new component\nimport Avatar from 'src/components/Avatar'\n// ...\nreturn (\n\n\n    {/* Add to the body */}\n     {\n        setAvatarUrl(url)\n        updateProfile({ username, website, avatar_url: url })\n      }}\n    />\n    {/* ... */}\n  \n)\n```\nStorage management\n\nAt this stage you have a fully functional application!\nSee also\n\nLearn more about RedwoodJS\nVisit the RedwoodJS Discourse Community\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-expo.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Expo',\n  description: 'Learn how to use Supabase in your React Native App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the React Native app from scratch.\nInitialize a React Native app\nWe can use expo to initialize\nan app called `expo-user-management`:\n```bash\nnpx create-expo-app -t expo-template-blank-typescript expo-user-management\ncd expo-user-management\n```\nThen let's install the additional dependencies: supabase-js\n`bash\nnpm install @supabase/supabase-js\nnpm install react-native-elements @react-native-async-storage/async-storage react-native-url-polyfill`\nNow let's create a helper file to initialize the Supabase client.\nWe need the API URL and the `anon` key that you copied earlier.\nThese variables will be exposed on the browser, and that's completely fine since we have\nRow Level Security enabled on our Database.\n```ts title=lib/supabase.ts\nimport AsyncStorage from '@react-native-async-storage/async-storage'\nimport { createClient } from '@supabase/supabase-js'\nconst supabaseUrl = YOUR_REACT_NATIVE_SUPABASE_URL\nconst supabaseAnonKey = YOUR_REACT_NATIVE_SUPABASE_ANON_KEY\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey, {\n  auth: {\n    storage: AsyncStorage as any,\n    autoRefreshToken: true,\n    persistSession: true,\n    detectSessionInUrl: false,\n  },\n})\n```\nSet up a Login component\nLet's set up a React Native component to manage logins and sign ups.\nUsers would be able to sign in with their email and password.\n```tsx title=components/Auth.tsx\nimport React, { useState } from 'react'\nimport { Alert, StyleSheet, View } from 'react-native'\nimport { supabase } from '../lib/supabase'\nimport { Button, Input } from 'react-native-elements'\nexport default function Auth() {\n  const [email, setEmail] = useState('')\n  const [password, setPassword] = useState('')\n  const [loading, setLoading] = useState(false)\nasync function signInWithEmail() {\n    setLoading(true)\n    const { error } = await supabase.auth.signInWithPassword({\n      email: email,\n      password: password,\n    })\n\n\n```if (error) Alert.alert(error.message)\nsetLoading(false)\n```\n\n\n}\nasync function signUpWithEmail() {\n    setLoading(true)\n    const { error } = await supabase.auth.signUp({\n      email: email,\n      password: password,\n    })\n\n\n```if (error) Alert.alert(error.message)\nsetLoading(false)\n```\n\n\n}\nreturn (\n    \n\n setEmail(text)}\n          value={email}\n          placeholder=\"email@address.com\"\n          autoCapitalize={'none'}\n        />\n      \n\n setPassword(text)}\n          value={password}\n          secureTextEntry={true}\n          placeholder=\"Password\"\n          autoCapitalize={'none'}\n        />\n      \n\n signInWithEmail()} />\n      \n\n signUpWithEmail()} />\n      \n\n  )\n}\nconst styles = StyleSheet.create({\n  container: {\n    marginTop: 40,\n    padding: 12,\n  },\n  verticallySpaced: {\n    paddingTop: 4,\n    paddingBottom: 4,\n    alignSelf: 'stretch',\n  },\n  mt20: {\n    marginTop: 20,\n  },\n})\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new component for that called `Account.tsx`.\n```tsx title=components/Account.tsx\nimport { useState, useEffect } from 'react'\nimport { supabase } from '../lib/supabase'\nimport { StyleSheet, View, Alert } from 'react-native'\nimport { Button, Input } from 'react-native-elements'\nimport { Session } from '@supabase/supabase-js'\nexport default function Account({ session }: { session: Session }) {\n  const [loading, setLoading] = useState(true)\n  const [username, setUsername] = useState('')\n  const [website, setWebsite] = useState('')\n  const [avatarUrl, setAvatarUrl] = useState('')\nuseEffect(() => {\n    if (session) getProfile()\n  }, [session])\nasync function getProfile() {\n    try {\n      setLoading(true)\n      if (!session?.user) throw new Error('No user on the session!')\n\n\n```  let { data, error, status } = await supabase\n    .from('profiles')\n    .select(`username, website, avatar_url`)\n    .eq('id', session?.user.id)\n    .single()\n  if (error && status !== 406) {\n    throw error\n  }\n\n  if (data) {\n    setUsername(data.username)\n    setWebsite(data.website)\n    setAvatarUrl(data.avatar_url)\n  }\n} catch (error) {\n  if (error instanceof Error) {\n    Alert.alert(error.message)\n  }\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nasync function updateProfile({\n    username,\n    website,\n    avatar_url,\n  }: {\n    username: string\n    website: string\n    avatar_url: string\n  }) {\n    try {\n      setLoading(true)\n      if (!session?.user) throw new Error('No user on the session!')\n\n\n```  const updates = {\n    id: session?.user.id,\n    username,\n    website,\n    avatar_url,\n    updated_at: new Date(),\n  }\n\n  let { error } = await supabase.from('profiles').upsert(updates)\n\n  if (error) {\n    throw error\n  }\n} catch (error) {\n  if (error instanceof Error) {\n    Alert.alert(error.message)\n  }\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nreturn (\n    \n\n\n\n\n setUsername(text)} />\n      \n\n setWebsite(text)} />\n      \n\n\n```  <View style={[styles.verticallySpaced, styles.mt20]}>\n    <Button\n      title={loading ? 'Loading ...' : 'Update'}\n      onPress={() => updateProfile({ username, website, avatar_url: avatarUrl })}\n      disabled={loading}\n    />\n  </View>\n\n  <View style={styles.verticallySpaced}>\n    <Button title=\"Sign Out\" onPress={() => supabase.auth.signOut()} />\n  </View>\n</View>\n```\n\n\n)\n}\nconst styles = StyleSheet.create({\n  container: {\n    marginTop: 40,\n    padding: 12,\n  },\n  verticallySpaced: {\n    paddingTop: 4,\n    paddingBottom: 4,\n    alignSelf: 'stretch',\n  },\n  mt20: {\n    marginTop: 20,\n  },\n})\n```\nLaunch!\nNow that we have all the components in place, let's update `App.tsx`:\n```tsx title=App.tsx\nimport 'react-native-url-polyfill/auto'\nimport { useState, useEffect } from 'react'\nimport { supabase } from './lib/supabase'\nimport Auth from './components/Auth'\nimport Account from './components/Account'\nimport { View } from 'react-native'\nimport { Session } from '@supabase/supabase-js'\nexport default function App() {\n  const [session, setSession] = useState(null)\nuseEffect(() => {\n    supabase.auth.getSession().then(({ data: { session } }) => {\n      setSession(session)\n    })\n\n\n```supabase.auth.onAuthStateChange((_event, session) => {\n  setSession(session)\n})\n```\n\n\n}, [])\nreturn (\n    \n      {session && session.user ?  : }\n    \n  )\n}\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm start`\nAnd then press the appropriate key for the environment you want to test the app in and you should see the completed app.\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like\nphotos and videos.\nAdditional dependency installation\nYou will need a file picker that works on the environment you will build the project for, we will use react-native-document-picker in this example.\n`bash\nexpo install react-native-document-picker`\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo.\nWe can start by creating a new component:\n```tsx title=components/Avatar.tsx\nimport { useState, useEffect } from 'react'\nimport { supabase } from '../lib/supabase'\nimport { StyleSheet, View, Alert, Image, Button } from 'react-native'\nimport DocumentPicker, { isCancel, isInProgress, types } from 'react-native-document-picker'\ninterface Props {\n  size: number\n  url: string | null\n  onUpload: (filePath: string) => void\n}\nexport default function Avatar({ url, size = 150, onUpload }: Props) {\n  const [uploading, setUploading] = useState(false)\n  const [avatarUrl, setAvatarUrl] = useState(null)\n  const avatarSize = { height: size, width: size }\nuseEffect(() => {\n    if (url) downloadImage(url)\n  }, [url])\nasync function downloadImage(path: string) {\n    try {\n      const { data, error } = await supabase.storage.from('avatars').download(path)\n\n\n```  if (error) {\n    throw error\n  }\n\n  const fr = new FileReader()\n  fr.readAsDataURL(data)\n  fr.onload = () => {\n    setAvatarUrl(fr.result as string)\n  }\n} catch (error) {\n  if (error instanceof Error) {\n    console.log('Error downloading image: ', error.message)\n  }\n}\n```\n\n\n}\nasync function uploadAvatar() {\n    try {\n      setUploading(true)\n\n\n```  const file = await DocumentPicker.pickSingle({\n    presentationStyle: 'fullScreen',\n    copyTo: 'cachesDirectory',\n    type: types.images,\n    mode: 'open',\n  })\n\n  const photo = {\n    uri: file.fileCopyUri,\n    type: file.type,\n    name: file.name,\n  }\n\n  const formData = new FormData()\n  formData.append('file', photo)\n\n  const fileExt = file.name.split('.').pop()\n  const filePath = `${Math.random()}.${fileExt}`\n\n  let { error } = await supabase.storage.from('avatars').upload(filePath, formData)\n\n  if (error) {\n    throw error\n  }\n\n  onUpload(filePath)\n} catch (error) {\n  if (isCancel(error)) {\n    console.warn('cancelled')\n    // User cancelled the picker, exit any dialogs or menus and move on\n  } else if (isInProgress(error)) {\n    console.warn('multiple pickers were opened, only the last will be considered')\n  } else if (error instanceof Error) {\n    Alert.alert(error.message)\n  } else {\n    throw error\n  }\n} finally {\n  setUploading(false)\n}\n```\n\n\n}\nreturn (\n    \n      {avatarUrl ? (\n        \n      ) : (\n        \n      )}\n      \n\n\n\n  )\n}\nconst styles = StyleSheet.create({\n  avatar: {\n    borderRadius: 5,\n    overflow: 'hidden',\n    maxWidth: '100%',\n  },\n  image: {\n    objectFit: 'cover',\n    paddingTop: 0,\n  },\n  noImage: {\n    backgroundColor: '#333',\n    border: '1px solid rgb(200, 200, 200)',\n    borderRadius: 5,\n  },\n})\n```\nAdd the new widget\nAnd then we can add the widget to the Account page:\n```tsx title=components/Account.tsx\n// Import the new component\nimport Avatar from './Avatar'\n// ...\n  return (\n    \n      {/ Add to the body /}\n      \n {\n            setAvatarUrl(url)\n            updateProfile({ username, website, avatar_url: url })\n          }}\n        />\n      \n      {/ ... /}\n    \n  )\n}\n// ...\n```\nNow you will need to run the prebuild command to get the application working on your chosen platform.\n`bash\nexpo prebuild`\nStorage management\n\nAt this stage you have a fully functional application!\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-react.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with React',\n  description: 'Learn how to use Supabase in your React App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the React app from scratch.\nInitialize a React app\nWe can use Create React App to initialize\nan app called `supabase-react`:\n`bash\nnpx create-react-app supabase-react\ncd supabase-react`\nThen let's install the only additional dependency: supabase-js.\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in a `.env.local` file.\nAll we need are the API URL and the `anon` key that you copied earlier.\n`bash title=.env\nREACT_APP_SUPABASE_URL=YOUR_SUPABASE_URL\nREACT_APP_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nNow that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed\non the browser, and that's completely fine since we have Row Level Security enabled on our Database.\nCreate and edit `src/supabaseClient.js`:\n```js title=src/supabaseClient.js\nimport { createClient } from '@supabase/supabase-js'\nconst supabaseUrl = process.env.REACT_APP_SUPABASE_URL\nconst supabaseAnonKey = process.env.REACT_APP_SUPABASE_ANON_KEY\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey)\n```\nAnd one optional step is to update the CSS file `src/index.css` to make the app look nice.\nYou can find the full contents of this file here.\nSet up a Login component\nLet's set up a React component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\nCreate and edit `src/Auth.js`:\n```jsx title=src/Auth.js\nimport { useState } from 'react'\nimport { supabase } from './supabaseClient'\nexport default function Auth() {\n  const [loading, setLoading] = useState(false)\n  const [email, setEmail] = useState('')\nconst handleLogin = async (e) => {\n    e.preventDefault()\n\n\n```try {\n  setLoading(true)\n  const { error } = await supabase.auth.signInWithOtp({ email })\n  if (error) throw error\n  alert('Check your email for the login link!')\n} catch (error) {\n  alert(error.error_description || error.message)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nreturn (\n    \n\nSupabase + React\nSign in via magic link with your email below\n        {loading ? (\n          'Sending magic link...'\n        ) : (\n          \nEmail\n setEmail(e.target.value)}\n            />\n            \n              Send magic link\n            \n\n        )}\n      \n\n  )\n}\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new component for that called `src/Account.js`.\n```jsx title=src/Account.js\nimport { useState, useEffect } from 'react'\nimport { supabase } from './supabaseClient'\nconst Account = ({ session }) => {\n  const [loading, setLoading] = useState(true)\n  const [username, setUsername] = useState(null)\n  const [website, setWebsite] = useState(null)\n  const [avatar_url, setAvatarUrl] = useState(null)\nuseEffect(() => {\n    getProfile()\n  }, [session])\nconst getProfile = async () => {\n    try {\n      setLoading(true)\n      const { user } = session\n\n\n```  let { data, error, status } = await supabase\n    .from('profiles')\n    .select(`username, website, avatar_url`)\n    .eq('id', user.id)\n    .single()\n\n  if (error && status !== 406) {\n    throw error\n  }\n\n  if (data) {\n    setUsername(data.username)\n    setWebsite(data.website)\n    setAvatarUrl(data.avatar_url)\n  }\n} catch (error) {\n  alert(error.message)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nconst updateProfile = async (e) => {\n    e.preventDefault()\n\n\n```try {\n  setLoading(true)\n  const { user } = session\n\n  const updates = {\n    id: user.id,\n    username,\n    website,\n    avatar_url,\n    updated_at: new Date(),\n  }\n\n  let { error } = await supabase.from('profiles').upsert(updates)\n\n  if (error) {\n    throw error\n  }\n} catch (error) {\n  alert(error.message)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nreturn (\n    \n      {loading ? (\n        'Saving ...'\n      ) : (\n        \nEmail: {session.user.email}\n\nName\n setUsername(e.target.value)}\n            />\n          \n\nWebsite\n setWebsite(e.target.value)}\n            />\n          \n\n\n              Update profile\n            \n\n\n      )}\n       supabase.auth.signOut()}>\n        Sign Out\n      \n\n  )\n}\nexport default Account\n```\nLaunch!\nNow that we have all the components in place, let's update `src/App.js`:\n```jsx title=src/App.js\nimport './index.css'\nimport { useState, useEffect } from 'react'\nimport { supabase } from './supabaseClient'\nimport Auth from './Auth'\nimport Account from './Account'\nexport default function App() {\n  const [session, setSession] = useState(null)\nuseEffect(() => {\n    supabase.auth.getSession().then(({ data: { session } }) => {\n      setSession(session)\n    })\n\n\n```supabase.auth.onAuthStateChange((_event, session) => {\n  setSession(session)\n})\n```\n\n\n}, [])\nreturn (\n    \n      {!session ?  : }\n    \n  )\n}\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm start`\nAnd then open the browser to localhost:3000 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:\nCreate and edit `src/Avatar.js`:\n```jsx title=src/Avatar.js\nimport { useEffect, useState } from 'react'\nimport { supabase } from './supabaseClient'\nexport default function Avatar({ url, size, onUpload }) {\n  const [avatarUrl, setAvatarUrl] = useState(null)\n  const [uploading, setUploading] = useState(false)\nuseEffect(() => {\n    if (url) downloadImage(url)\n  }, [url])\nconst downloadImage = async (path) => {\n    try {\n      const { data, error } = await supabase.storage.from('avatars').download(path)\n      if (error) {\n        throw error\n      }\n      const url = URL.createObjectURL(data)\n      setAvatarUrl(url)\n    } catch (error) {\n      console.log('Error downloading image: ', error.message)\n    }\n  }\nconst uploadAvatar = async (event) => {\n    try {\n      setUploading(true)\n\n\n```  if (!event.target.files || event.target.files.length === 0) {\n    throw new Error('You must select an image to upload.')\n  }\n\n  const file = event.target.files[0]\n  const fileExt = file.name.split('.').pop()\n  const fileName = `${Math.random()}.${fileExt}`\n  const filePath = `${fileName}`\n\n  let { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)\n\n  if (uploadError) {\n    throw uploadError\n  }\n\n  onUpload(filePath)\n} catch (error) {\n  alert(error.message)\n} finally {\n  setUploading(false)\n}\n```\n\n\n}\nreturn (\n    \nhttps://place-hold.it/${size}x${size}}\n        alt={avatarUrl ? 'Avatar' : 'No image'}\n        className=\"avatar image\"\n        style={{ height: size, width: size }}\n      />\n      {uploading ? (\n        'Uploading...'\n      ) : (\n        <>\n          \n            Upload an avatar\n          \n\n\n\n\n      )}\n    \n  )\n}\n```\nAdd the new widget\nAnd then we can add the widget to the Account page at `src/Account.js`:\n```jsx title=src/Account.js\n// Import the new component\nimport Avatar from './Avatar'\n// ...\nreturn (\n\n\n    {/* Add to the body */}\n     {\n        setAvatarUrl(url)\n        updateProfile({ username, website, avatar_url: url })\n      }}\n    />\n    {/* ... */}\n  \n)\n```\n\n### Storage management\n\n\n\nAt this stage you have a fully functional application!\n\nexport const Page = ({ children }) => \n",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-svelte.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Svelte',\n  description: 'Learn how to use Supabase in your Svelte App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Svelte app from scratch.\nInitialize a Svelte app\nWe can use the Vite Svelte TypeScript Template to initialize an app called `supabase-svelte`:\n`bash\nnpm create vite@latest supabase-svelte -- --template svelte-ts\ncd supabase-svelte\nnpm install`\nThen let's install the only additional dependency: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in a `.env`.\nAll we need are the API URL and the `anon` key that you copied earlier.\n`bash title=.env\nVITE_SUPABASE_URL=YOUR_SUPABASE_URL\nVITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nNow that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed\non the browser, and that's completely fine since we have Row Level Security enabled on our Database.\n```js title=src/supabaseClient.ts\nimport { createClient } from '@supabase/supabase-js'\nconst supabaseUrl = import.meta.env.VITE_SUPABASE_URL\nconst supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey)\n```\nAnd one optional step is to update the CSS file `src/app.css` to make the app look nice.\nYou can find the full contents of this file here.\nSet up a Login component\nLet's set up a Svelte component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\n```html title=src/lib/Auth.svelte\n\n\n\nSupabase + Svelte\nSign in via magic link with your email below\n\n\nEmail\n\n\n\n\n{loading ? 'Loading' : 'Send magic link'}\n\n\n\n\n\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new component for that called `Account.svelte`.\n```html title=src/lib/Account.svelte\n\n\nEmail: {session.user.email}\n\nName\n\n\n\nWebsite\n\n\n\n\n      {loading ? 'Saving ...' : 'Update profile'}\n    \n\n supabase.auth.signOut()}>\n    Sign Out\n  \n\n```\nLaunch!\nNow that we have all the components in place, let's update `App.svelte`:\n```html title=src/App.svelte\n\n\n  {#if !session}\n  \n  {:else}\n  \n  {/if}\n\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm run dev`\nAnd then open the browser to localhost:5173 and you should see the completed app.\n\n\u26a0\ufe0f WARNING: Svelte uses Vite and the default port is `5173`, Supabase uses `port 3000`. To change the redirection port for supabase go to: `Authentication > Settings` and change the `Site Url` to `localhost:5173`\n\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:\n```html title=src/lib/Avatar.svelte\n\n\n  {#if avatarUrl}  {:else}\n  \n  {/if}\n  \n\n      {uploading ? 'Uploading ...' : 'Upload avatar'}\n    \n\n\n\n\n\n```\nAdd the new widget\nAnd then we can add the widget to the Account page:\n```html title=src/lib/Account.svelte\n\n\n\n\n\n\n```\nStorage management\n\nAt this stage you have a fully functional application!\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-angular.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Angular',\n  description: 'Learn how to use Supabase in your Angular App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Angular app from scratch.\nInitialize an Angular app\nWe can use the Angular CLI to initialize\nan app called `supabase-angular`:\n`bash\nnpx ng new supabase-angular --routing false --style css\ncd supabase-angular`\nThen let's install the only additional dependency: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in the `environment.ts` file.\nAll we need are the API URL and the `anon` key that you copied earlier.\nThese variables will be exposed on the browser, and that's completely fine since we have Row Level Security enabled on our Database.\n`ts title=environment.ts\nexport const environment = {\n  production: false,\n  supabaseUrl: 'YOUR_SUPABASE_URL',\n  supabaseKey: 'YOUR_SUPABASE_KEY',\n}`\nNow that we have the API credentials in place, let's create a SupabaseService with `ng g s supabase` to initialize the Supabase client and implement functions to communicate with the Supabase API.\n```ts title=src/app/supabase.service.ts\nimport { Injectable } from '@angular/core'\nimport {\n  AuthChangeEvent,\n  AuthSession,\n  createClient,\n  Session,\n  SupabaseClient,\n  User,\n} from '@supabase/supabase-js'\nimport { environment } from 'src/environments/environment'\nexport interface Profile {\n  id?: string\n  username: string\n  website: string\n  avatar_url: string\n}\n@Injectable({\n  providedIn: 'root',\n})\nexport class SupabaseService {\n  private supabase: SupabaseClient\n  _session: AuthSession | null = null\nconstructor() {\n    this.supabase = createClient(environment.supabaseUrl, environment.supabaseKey)\n  }\nget session() {\n    this.supabase.auth.getSession().then(({ data }) => {\n      this._session = data.session\n    })\n    return this._session\n  }\nprofile(user: User) {\n    return this.supabase\n      .from('profiles')\n      .select(`username, website, avatar_url`)\n      .eq('id', user.id)\n      .single()\n  }\nauthChanges(callback: (event: AuthChangeEvent, session: Session | null) => void) {\n    return this.supabase.auth.onAuthStateChange(callback)\n  }\nsignIn(email: string) {\n    return this.supabase.auth.signInWithOtp({ email })\n  }\nsignOut() {\n    return this.supabase.auth.signOut()\n  }\nupdateProfile(profile: Profile) {\n    const update = {\n      ...profile,\n      updated_at: new Date(),\n    }\n\n\n```return this.supabase.from('profiles').upsert(update)\n```\n\n\n}\ndownLoadImage(path: string) {\n    return this.supabase.storage.from('avatars').download(path)\n  }\nuploadAvatar(filePath: string, file: File) {\n    return this.supabase.storage.from('avatars').upload(filePath, file)\n  }\n}\n```\nOptionally, update src/styles.css to style the app.\nSet up a Login component\nLet's set up an Angular component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\nCreate an AuthComponent with `ng g c auth` Angular CLI command.\n```ts title=src/app/auth/auth.component.ts\nimport { Component } from '@angular/core'\nimport { FormBuilder } from '@angular/forms'\nimport { SupabaseService } from '../supabase.service'\n@Component({\n  selector: 'app-auth',\n  templateUrl: './auth.component.html',\n  styleUrls: ['./auth.component.css'],\n})\nexport class AuthComponent {\n  loading = false\nsignInForm = this.formBuilder.group({\n    email: '',\n  })\nconstructor(\n    private readonly supabase: SupabaseService,\n    private readonly formBuilder: FormBuilder\n  ) {}\nasync onSubmit(): Promise {\n    try {\n      this.loading = true\n      const email = this.signInForm.value.email as string\n      const { error } = await this.supabase.signIn(email)\n      if (error) throw error\n      alert('Check your email for the login link!')\n    } catch (error) {\n      if (error instanceof Error) {\n        alert(error.message)\n      }\n    } finally {\n      this.signInForm.reset()\n      this.loading = false\n    }\n  }\n}\n```\n```html title=src/app/auth/auth.component.html\n\n\nSupabase + Angular\nSign in via magic link with your email below\n\n\nEmail\n\n\n\n\n          {{ loading ? 'Loading' : 'Send magic link' }}\n        \n\n\n\n\n```\nAccount page\nUsers also need a way to edit their profile details and manage their accounts after signing in.\nCreate an AccountComponent with the `ng g c account` Angular CLI command.\n```ts title=src/app/account/account.component.ts\nimport { Component, Input, OnInit } from '@angular/core'\nimport { FormBuilder } from '@angular/forms'\nimport { AuthSession } from '@supabase/supabase-js'\nimport { Profile, SupabaseService } from '../supabase.service'\n@Component({\n  selector: 'app-account',\n  templateUrl: './account.component.html',\n  styleUrls: ['./account.component.css'],\n})\nexport class AccountComponent implements OnInit {\n  loading = false\n  profile!: Profile\n@Input()\n  session!: AuthSession\nupdateProfileForm = this.formBuilder.group({\n    username: '',\n    website: '',\n    avatar_url: '',\n  })\nconstructor(private readonly supabase: SupabaseService, private formBuilder: FormBuilder) {}\nasync ngOnInit(): Promise {\n    await this.getProfile()\n\n\n```const { username, website, avatar_url } = this.profile\nthis.updateProfileForm.patchValue({\n  username,\n  website,\n  avatar_url,\n})\n```\n\n\n}\nasync getProfile() {\n    try {\n      this.loading = true\n      const { user } = this.session\n      let { data: profile, error, status } = await this.supabase.profile(user)\n\n\n```  if (error && status !== 406) {\n    throw error\n  }\n\n  if (profile) {\n    this.profile = profile\n  }\n} catch (error) {\n  if (error instanceof Error) {\n    alert(error.message)\n  }\n} finally {\n  this.loading = false\n}\n```\n\n\n}\nasync updateProfile(): Promise {\n    try {\n      this.loading = true\n      const { user } = this.session\n\n\n```  const username = this.updateProfileForm.value.username as string\n  const website = this.updateProfileForm.value.website as string\n  const avatar_url = this.updateProfileForm.value.avatar_url as string\n\n  const { error } = await this.supabase.updateProfile({\n    id: user.id,\n    username,\n    website,\n    avatar_url,\n  })\n  if (error) throw error\n} catch (error) {\n  if (error instanceof Error) {\n    alert(error.message)\n  }\n} finally {\n  this.loading = false\n}\n```\n\n\n}\nasync signOut() {\n    await this.supabase.signOut()\n  }\n}\n```\n```html title=src/app/account/account.component.html\n\n\nEmail\n\n\n\nName\n\n\n\nWebsite\n\n\n\n\n      {{ loading ? 'Loading ...' : 'Update' }}\n    \n\n\nSign Out\n\n\n```\nLaunch!\nNow that we have all the components in place, let's update AppComponent:\n```ts title=src/app/app.component.ts\nimport { Component, OnInit } from '@angular/core'\nimport { SupabaseService } from './supabase.service'\n@Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.css'],\n})\nexport class AppComponent implements OnInit {\n  title = 'angular-user-management'\nsession = this.supabase.session\nconstructor(private readonly supabase: SupabaseService) {}\nngOnInit() {\n    this.supabase.authChanges((_, session) => (this.session = session))\n  }\n}\n```\n```html title=src/app/app.component.html\n\n\n\n\n\n\n```\n`app.module.ts` also needs to be modified to include the `ReactiveFormsModule` from the `@angular/forms` package.\n```ts title=src/app/app.module.ts\nimport { NgModule } from '@angular/core'\nimport { BrowserModule } from '@angular/platform-browser'\nimport { AppComponent } from './app.component'\nimport { AuthComponent } from './auth/auth.component'\nimport { AccountComponent } from './account/account.component'\nimport { ReactiveFormsModule } from '@angular/forms'\nimport { AvatarComponent } from './avatar/avatar.component'\n@NgModule({\n  declarations: [AppComponent, AuthComponent, AccountComponent, AvatarComponent],\n  imports: [BrowserModule, ReactiveFormsModule],\n  providers: [],\n  bootstrap: [AppComponent],\n})\nexport class AppModule {}\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm run start`\nAnd then open the browser to localhost:4200 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo.\nCreate an AvatarComponent with `ng g c avatar` Angular CLI command.\n```ts title=src/app/avatar/avatar.component.ts\nimport { Component, EventEmitter, Input, Output } from '@angular/core'\nimport { SafeResourceUrl, DomSanitizer } from '@angular/platform-browser'\nimport { SupabaseService } from '../supabase.service'\n@Component({\n  selector: 'app-avatar',\n  templateUrl: './avatar.component.html',\n  styleUrls: ['./avatar.component.css'],\n})\nexport class AvatarComponent {\n  _avatarUrl: SafeResourceUrl | undefined\n  uploading = false\n@Input()\n  set avatarUrl(url: string | null) {\n    if (url) {\n      this.downloadImage(url)\n    }\n  }\n@Output() upload = new EventEmitter()\nconstructor(private readonly supabase: SupabaseService, private readonly dom: DomSanitizer) {}\nasync downloadImage(path: string) {\n    try {\n      const { data } = await this.supabase.downLoadImage(path)\n      if (data instanceof Blob) {\n        this._avatarUrl = this.dom.bypassSecurityTrustResourceUrl(URL.createObjectURL(data))\n      }\n    } catch (error) {\n      if (error instanceof Error) {\n        console.error('Error downloading image: ', error.message)\n      }\n    }\n  }\nasync uploadAvatar(event: any) {\n    try {\n      this.uploading = true\n      if (!event.target.files || event.target.files.length === 0) {\n        throw new Error('You must select an image to upload.')\n      }\n\n\n```  const file = event.target.files[0]\n  const fileExt = file.name.split('.').pop()\n  const filePath = `${Math.random()}.${fileExt}`\n\n  await this.supabase.uploadAvatar(filePath, file)\n  this.upload.emit(filePath)\n} catch (error) {\n  if (error instanceof Error) {\n    alert(error.message)\n  }\n} finally {\n  this.uploading = false\n}\n```\n\n\n}\n}\n```\n```html title=src/app/avatar/avatar.component.html\n\n\n\n\n\n\n    {{ uploading ? 'Uploading ...' : 'Upload' }}\n  \n\n\n```\nAdd the new widget\nAnd then we can add the widget on top of the AccountComponent html template:\n```html title=src/app/account.component.html\n\n \n\n\n```\nAnd add an `updateAvatar` function along with an `avatarUrl` getter to the AccountComponent typescript file:\n```ts title=src/app/account.component.ts\n@Component({\n  selector: 'app-account',\n  templateUrl: './account.component.html',\n  styleUrls: ['./account.component.css'],\n})\nexport class AccountComponent implements OnInit {\n  // ...\n  get avatarUrl() {\n    return this.updateProfileForm.value.avatar_url as string\n  }\nasync updateAvatar(event: string): Promise {\n    this.updateProfileForm.patchValue({\n      avatar_url: event,\n    })\n    await this.updateProfile()\n  }\n  // ...\n}\n```\nStorage management\n\nAt this stage you have a fully functional application!\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-flutter.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Flutter',\n  description: 'Learn how to use Supabase in your Flutter App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Flutter app from scratch.\nInitialize a Flutter app\nWe can use flutter create to initialize\nan app called `supabase_quickstart`:\n`bash\nflutter create supabase_quickstart`\nThen let's install the only additional dependency: supabase_flutter\nCopy and paste the following line in your pubspec.yaml to install the package:\n`yaml\nsupabase_flutter: ^1.0.0`\nRun `flutter pub get` to install the dependencies.\nSetup deep links\nNow that we have the dependencies installed let's setup deep links so users who have logged in via magic link or OAuth can come back to the app.\nAdd `io.supabase.flutterquickstart://login-callback/` as a new redirect URL in the Dashboard.\n\nThat is it on Supabase's end and the rest are platform specific settings:\nFor Android, edit the `android/app/src/main/AndroidManifest.xml` file.\nAdd an intent-filter to enable deep linking:\n```xml title=android/app/src/main/AndroidManifest.xml\n\n\n\n\n\n\n\n```  <!-- Add this intent-filter for Deep Links -->\n  <intent-filter>\n    <action android:name=\"android.intent.action.VIEW\" />\n    <category android:name=\"android.intent.category.DEFAULT\" />\n    <category android:name=\"android.intent.category.BROWSABLE\" />\n    <!-- Accepts URIs that begin with YOUR_SCHEME://YOUR_HOST -->\n    <data\n      android:scheme=\"io.supabase.flutterquickstart\"\n      android:host=\"login-callback\" />\n  </intent-filter>\n\n</activity>\n```\n\n\n\n\n```\nFor iOS, edit the ios/Runner/Info.plist file.\nAdd CFBundleURLTypes to enable deep linking:\n```xml title=ios/Runner/Info.plist\"\n\n\n\n\n\n\nCFBundleURLTypes\n\n\nCFBundleTypeRole\nEditor\nCFBundleURLSchemes\n\nio.supabase.flutterquickstart\n\n\n\n\n\n\n```\nFor web:\nThere are no additional configurations.\nMain function\nNow that we have deep links ready let's initialize the Supabase client inside our `main` function with the API credentials that you copied earlier.\nThese variables will be exposed on the app, and that's completely fine since we have\nRow Level Security enabled on our Database.\n```dart title=lib/main.dart\nFuture main() async {\n  WidgetsFlutterBinding.ensureInitialized();\nawait Supabase.initialize(\n    url: 'YOUR_SUPABASE_URL',\n    anonKey: 'YOUR_SUPABASE_ANON_KEY',\n  );\n  runApp(MyApp());\n}\n```\nSetting up some constants and handy functions\nLet's also create a constant file to make it easier to use Supabase client.\nWe will also include an extension method declaration to call `showSnackBar` with one line of code.\n```dart title=lib/constants.dart\nimport 'package:flutter/material.dart';\nimport 'package:supabase_flutter/supabase_flutter.dart';\nfinal supabase = Supabase.instance.client;\nextension ShowSnackBar on BuildContext {\n  void showSnackBar({\n    required String message,\n    Color backgroundColor = Colors.white,\n  }) {\n    ScaffoldMessenger.of(this).showSnackBar(SnackBar(\n      content: Text(message),\n      backgroundColor: backgroundColor,\n    ));\n  }\nvoid showErrorSnackBar({required String message}) {\n    showSnackBar(message: message, backgroundColor: Colors.red);\n  }\n}\n```\nSet up Splash Screen\nLet's create a splash screen that will be shown to users right after they open the app.\nThis screen retrieves the current session and redirects the user accordingly.\n```dart title=lib/pages/splash_page.dart\nimport 'package:flutter/material.dart';\nimport 'package:supabase_quickstart/constants.dart';\nclass SplashPage extends StatefulWidget {\n  const SplashPage({super.key});\n@override\n  _SplashPageState createState() => _SplashPageState();\n}\nclass _SplashPageState extends State {\n  bool _redirectCalled = false;\n  @override\n  void didChangeDependencies() {\n    super.didChangeDependencies();\n    _redirect();\n  }\nFuture _redirect() async {\n    await Future.delayed(Duration.zero);\n    if (_redirectCalled || !mounted) {\n      return;\n    }\n\n\n```_redirectCalled = true;\nfinal session = supabase.auth.currentSession;\nif (session != null) {\n  Navigator.of(context).pushReplacementNamed('/account');\n} else {\n  Navigator.of(context).pushReplacementNamed('/login');\n}\n```\n\n\n}\n@override\n  Widget build(BuildContext context) {\n    return const Scaffold(\n      body: Center(child: CircularProgressIndicator()),\n    );\n  }\n}\n```\nSet up a Login page\nLet's create a Flutter widget to manage logins and sign ups.\nWe'll use Magic Links, so users can sign in with their email without using passwords.\nNotice that this page sets up a listener on the user's auth state using `onAuthStateChange`.\nA new event will fire when the user comes back to the app by clicking their magic link, which this page can catch and redirect the user accordingly.\n```dart title=lib/pages/login_page.dart\nimport 'dart:async';\nimport 'package:flutter/foundation.dart';\nimport 'package:flutter/material.dart';\nimport 'package:supabase_flutter/supabase_flutter.dart';\nimport 'package:supabase_quickstart/constants.dart';\nclass LoginPage extends StatefulWidget {\n  const LoginPage({super.key});\n@override\n  _LoginPageState createState() => _LoginPageState();\n}\nclass _LoginPageState extends State {\n  bool _isLoading = false;\n  bool _redirecting = false;\n  late final TextEditingController _emailController;\n  late final StreamSubscription _authStateSubscription;\nFuture _signIn() async {\n    setState(() {\n      _isLoading = true;\n    });\n    try {\n      await supabase.auth.signInWithOtp(\n        email: _emailController.text,\n        emailRedirectTo:\n            kIsWeb ? null : 'io.supabase.flutterquickstart://login-callback/',\n      );\n      if (mounted) {\n        context.showSnackBar(message: 'Check your email for login link!');\n        _emailController.clear();\n      }\n    } on AuthException catch (error) {\n      context.showErrorSnackBar(message: error.message);\n    } catch (error) {\n      context.showErrorSnackBar(message: 'Unexpected error occurred');\n    }\n\n\n```setState(() {\n  _isLoading = false;\n});\n```\n\n\n}\n@override\n  void initState() {\n    _emailController = TextEditingController();\n    _authStateSubscription = supabase.auth.onAuthStateChange.listen((data) {\n      if (_redirecting) return;\n      final session = data.session;\n      if (session != null) {\n        _redirecting = true;\n        Navigator.of(context).pushReplacementNamed('/account');\n      }\n    });\n    super.initState();\n  }\n@override\n  void dispose() {\n    _emailController.dispose();\n    _authStateSubscription.cancel();\n    super.dispose();\n  }\n@override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      appBar: AppBar(title: const Text('Sign In')),\n      body: ListView(\n        padding: const EdgeInsets.symmetric(vertical: 18, horizontal: 12),\n        children: [\n          const Text('Sign in via the magic link with your email below'),\n          const SizedBox(height: 18),\n          TextFormField(\n            controller: _emailController,\n            decoration: const InputDecoration(labelText: 'Email'),\n          ),\n          const SizedBox(height: 18),\n          ElevatedButton(\n            onPressed: _isLoading ? null : _signIn,\n            child: Text(_isLoading ? 'Loading' : 'Send Magic Link'),\n          ),\n        ],\n      ),\n    );\n  }\n}\n```\nSet up Account page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new widget called `account_page.dart` for that.\n```dart title=lib/pages/account_page.dart\"\nimport 'package:flutter/material.dart';\nimport 'package:supabase_flutter/supabase_flutter.dart';\nimport 'package:supabase_quickstart/components/avatar.dart';\nimport 'package:supabase_quickstart/constants.dart';\nclass AccountPage extends StatefulWidget {\n  const AccountPage({super.key});\n@override\n  _AccountPageState createState() => _AccountPageState();\n}\nclass _AccountPageState extends State {\n  final _usernameController = TextEditingController();\n  final _websiteController = TextEditingController();\n  String? _avatarUrl;\n  var _loading = false;\n/// Called once a user id is received within `onAuthenticated()`\n  Future _getProfile() async {\n    setState(() {\n      _loading = true;\n    });\n\n\n```try {\n  final userId = supabase.auth.currentUser!.id;\n  final data = await supabase\n      .from('profiles')\n      .select()\n      .eq('id', userId)\n      .single() as Map;\n  _usernameController.text = (data['username'] ?? '') as String;\n  _websiteController.text = (data['website'] ?? '') as String;\n  _avatarUrl = (data['avatar_url'] ?? '') as String;\n} on PostgrestException catch (error) {\n  context.showErrorSnackBar(message: error.message);\n} catch (error) {\n  context.showErrorSnackBar(message: 'Unexpected exception occurred');\n}\n\nsetState(() {\n  _loading = false;\n});\n```\n\n\n}\n/// Called when user taps `Update` button\n  Future _updateProfile() async {\n    setState(() {\n      _loading = true;\n    });\n    final userName = _usernameController.text;\n    final website = _websiteController.text;\n    final user = supabase.auth.currentUser;\n    final updates = {\n      'id': user!.id,\n      'username': userName,\n      'website': website,\n      'updated_at': DateTime.now().toIso8601String(),\n    };\n    try {\n      await supabase.from('profiles').upsert(updates);\n      if (mounted) {\n        context.showSnackBar(message: 'Successfully updated profile!');\n      }\n    } on PostgrestException catch (error) {\n      context.showErrorSnackBar(message: error.message);\n    } catch (error) {\n      context.showErrorSnackBar(message: 'Unexpeted error occurred');\n    }\n    setState(() {\n      _loading = false;\n    });\n  }\nFuture _signOut() async {\n    try {\n      await supabase.auth.signOut();\n    } on AuthException catch (error) {\n      context.showErrorSnackBar(message: error.message);\n    } catch (error) {\n      context.showErrorSnackBar(message: 'Unexpected error occurred');\n    }\n    if (mounted) {\n      Navigator.of(context).pushReplacementNamed('/');\n    }\n  }\n@override\n  void initState() {\n    super.initState();\n    _getProfile();\n  }\n@override\n  void dispose() {\n    _usernameController.dispose();\n    _websiteController.dispose();\n    super.dispose();\n  }\n@override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      appBar: AppBar(title: const Text('Profile')),\n      body: ListView(\n        padding: const EdgeInsets.symmetric(vertical: 18, horizontal: 12),\n        children: [\n          TextFormField(\n            controller: _usernameController,\n            decoration: const InputDecoration(labelText: 'User Name'),\n          ),\n          const SizedBox(height: 18),\n          TextFormField(\n            controller: _websiteController,\n            decoration: const InputDecoration(labelText: 'Website'),\n          ),\n          const SizedBox(height: 18),\n          ElevatedButton(\n            onPressed: _updateProfile,\n            child: Text(_loading ? 'Saving...' : 'Update'),\n          ),\n          const SizedBox(height: 18),\n          TextButton(onPressed: _signOut, child: const Text('Sign Out')),\n        ],\n      ),\n    );\n  }\n}\n```\nLaunch!\nNow that we have all the components in place, let's update `lib/main.dart`:\n```dart title=lib/main.dart\nimport 'package:flutter/material.dart';\nimport 'package:supabase_flutter/supabase_flutter.dart';\nimport 'package:supabase_quickstart/pages/account_page.dart';\nimport 'package:supabase_quickstart/pages/login_page.dart';\nimport 'package:supabase_quickstart/pages/splash_page.dart';\nFuture main() async {\n  await Supabase.initialize(\n    // TODO: Replace credentials with your own\n    url: 'YOUR_SUPABASE_URL',\n    anonKey: 'YOUR_SUPABASE_ANON_KEY',\n  );\n  runApp(MyApp());\n}\nclass MyApp extends StatelessWidget {\n  @override\n  Widget build(BuildContext context) {\n    return MaterialApp(\n      title: 'Supabase Flutter',\n      theme: ThemeData.dark().copyWith(\n        primaryColor: Colors.green,\n        textButtonTheme: TextButtonThemeData(\n          style: TextButton.styleFrom(\n            foregroundColor: Colors.green,\n          ),\n        ),\n        elevatedButtonTheme: ElevatedButtonThemeData(\n          style: ElevatedButton.styleFrom(\n            foregroundColor: Colors.white,\n            backgroundColor: Colors.green,\n          ),\n        ),\n      ),\n      initialRoute: '/',\n      routes: {\n        '/': () => const SplashPage(),\n        '/login': () => const LoginPage(),\n        '/account': (_) => const AccountPage(),\n      },\n    );\n  }\n}\n```\nOnce that's done, run this in a terminal window to launch on Android or iOS:\n`bash\nflutter run`\nOr for web, run the following command to launch it on `localhost:3000`\n`bash\nflutter run -d web-server --web-hostname localhost --web-port 3000`\nAnd then open the browser to localhost:3000 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like\nphotos and videos.\nMaking sure we have a public bucket\nWe will be storing the image as a publicly sharable image.\nMake sure your `avatars` bucket is set to public, and if it is not, change the publicity by clicking the dot menu that appears when you hover over the bucket name.\nYou should see an orange `Public` badge next to your bucket name if your bucket is set to public.\nAdding image uploading feature to Account page\nWe will use image_picker plugin to select an image from the device.\nAdd the following line in your pubspec.yaml file to install `image_picker`:\n`yaml\nimage_picker: ^0.8.4`\nUsing image_picker requires some additional preparation depending on the platform.\nFollow the instruction on README.md of image_picker on how to set it up for the platform you are using.\nOnce you are done with all of the above, it is time to dive into coding.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo.\nWe can start by creating a new component:\n```dart title=lib/components/avatar.dart\nimport 'package:flutter/material.dart';\nimport 'package:image_picker/image_picker.dart';\nimport 'package:supabase_flutter/supabase_flutter.dart';\nimport 'package:supabase_quickstart/constants.dart';\nclass Avatar extends StatefulWidget {\n  const Avatar({\n    super.key,\n    required this.imageUrl,\n    required this.onUpload,\n  });\nfinal String? imageUrl;\n  final void Function(String) onUpload;\n@override\n  _AvatarState createState() => _AvatarState();\n}\nclass _AvatarState extends State {\n  bool _isLoading = false;\n@override\n  Widget build(BuildContext context) {\n    return Column(\n      children: [\n        if (widget.imageUrl == null || widget.imageUrl!.isEmpty)\n          Container(\n            width: 150,\n            height: 150,\n            color: Colors.grey,\n            child: const Center(\n              child: Text('No Image'),\n            ),\n          )\n        else\n          Image.network(\n            widget.imageUrl!,\n            width: 150,\n            height: 150,\n            fit: BoxFit.cover,\n          ),\n        ElevatedButton(\n          onPressed: _isLoading ? null : _upload,\n          child: const Text('Upload'),\n        ),\n      ],\n    );\n  }\nFuture _upload() async {\n    final picker = ImagePicker();\n    final imageFile = await picker.pickImage(\n      source: ImageSource.gallery,\n      maxWidth: 300,\n      maxHeight: 300,\n    );\n    if (imageFile == null) {\n      return;\n    }\n    setState(() => _isLoading = true);\n\n\n```try {\n  final bytes = await imageFile.readAsBytes();\n  final fileExt = imageFile.path.split('.').last;\n  final fileName = '${DateTime.now().toIso8601String()}.$fileExt';\n  final filePath = fileName;\n  await supabase.storage.from('avatars').uploadBinary(\n        filePath,\n        bytes,\n        fileOptions: FileOptions(contentType: imageFile.mimeType),\n      );\n  final imageUrlResponse = await supabase.storage\n      .from('avatars')\n      .createSignedUrl(filePath, 60 * 60 * 24 * 365 * 10);\n  widget.onUpload(imageUrlResponse);\n} on StorageException catch (error) {\n  if (mounted) {\n    context.showErrorSnackBar(message: error.message);\n  }\n} catch (error) {\n  if (mounted) {\n    context.showErrorSnackBar(message: 'Unexpected error occurred');\n  }\n}\n\nsetState(() => _isLoading = false);\n```\n\n\n}\n}\n```\nAdd the new widget\nAnd then we can add the widget to the Account page as well as some logic to update the `avatar_url` whenever the user uploads a new avatar.\n```dart title=lib/pages/account_page.dart\nimport 'package:flutter/material.dart';\nimport 'package:supabase_flutter/supabase_flutter.dart';\nimport 'package:supabase_quickstart/components/avatar.dart';\nimport 'package:supabase_quickstart/constants.dart';\nclass AccountPage extends StatefulWidget {\n  const AccountPage({super.key});\n@override\n  _AccountPageState createState() => _AccountPageState();\n}\nclass _AccountPageState extends State {\n  final _usernameController = TextEditingController();\n  final _websiteController = TextEditingController();\n  String? _avatarUrl;\n  var _loading = false;\n/// Called once a user id is received within `onAuthenticated()`\n  Future _getProfile() async {\n    setState(() {\n      _loading = true;\n    });\n\n\n```try {\n  final userId = supabase.auth.currentUser!.id;\n  final data = await supabase\n      .from('profiles')\n      .select()\n      .eq('id', userId)\n      .single() as Map;\n  _usernameController.text = (data['username'] ?? '') as String;\n  _websiteController.text = (data['website'] ?? '') as String;\n  _avatarUrl = (data['avatar_url'] ?? '') as String;\n} on PostgrestException catch (error) {\n  context.showErrorSnackBar(message: error.message);\n} catch (error) {\n  context.showErrorSnackBar(message: 'Unexpected exception occurred');\n}\n\nsetState(() {\n  _loading = false;\n});\n```\n\n\n}\n/// Called when user taps `Update` button\n  Future _updateProfile() async {\n    setState(() {\n      _loading = true;\n    });\n    final userName = _usernameController.text;\n    final website = _websiteController.text;\n    final user = supabase.auth.currentUser;\n    final updates = {\n      'id': user!.id,\n      'username': userName,\n      'website': website,\n      'updated_at': DateTime.now().toIso8601String(),\n    };\n    try {\n      await supabase.from('profiles').upsert(updates);\n      if (mounted) {\n        context.showSnackBar(message: 'Successfully updated profile!');\n      }\n    } on PostgrestException catch (error) {\n      context.showErrorSnackBar(message: error.message);\n    } catch (error) {\n      context.showErrorSnackBar(message: 'Unexpeted error occurred');\n    }\n    setState(() {\n      _loading = false;\n    });\n  }\nFuture _signOut() async {\n    try {\n      await supabase.auth.signOut();\n    } on AuthException catch (error) {\n      context.showErrorSnackBar(message: error.message);\n    } catch (error) {\n      context.showErrorSnackBar(message: 'Unexpected error occurred');\n    }\n    if (mounted) {\n      Navigator.of(context).pushReplacementNamed('/');\n    }\n  }\n/// Called when image has been uploaded to Supabase storage from within Avatar widget\n  Future _onUpload(String imageUrl) async {\n    try {\n      final userId = supabase.auth.currentUser!.id;\n      await supabase.from('profiles').upsert({\n        'id': userId,\n        'avatar_url': imageUrl,\n      });\n      if (mounted) {\n        context.showSnackBar(message: 'Updated your profile image!');\n      }\n    } on PostgrestException catch (error) {\n      context.showErrorSnackBar(message: error.message);\n    } catch (error) {\n      context.showErrorSnackBar(message: 'Unexpected error has occurred');\n    }\n    if (!mounted) {\n      return;\n    }\n\n\n```setState(() {\n  _avatarUrl = imageUrl;\n});\n```\n\n\n}\n@override\n  void initState() {\n    super.initState();\n    _getProfile();\n  }\n@override\n  void dispose() {\n    _usernameController.dispose();\n    _websiteController.dispose();\n    super.dispose();\n  }\n@override\n  Widget build(BuildContext context) {\n    return Scaffold(\n      appBar: AppBar(title: const Text('Profile')),\n      body: ListView(\n        padding: const EdgeInsets.symmetric(vertical: 18, horizontal: 12),\n        children: [\n          Avatar(\n            imageUrl: _avatarUrl,\n            onUpload: _onUpload,\n          ),\n          const SizedBox(height: 18),\n          TextFormField(\n            controller: _usernameController,\n            decoration: const InputDecoration(labelText: 'User Name'),\n          ),\n          const SizedBox(height: 18),\n          TextFormField(\n            controller: _websiteController,\n            decoration: const InputDecoration(labelText: 'Website'),\n          ),\n          const SizedBox(height: 18),\n          ElevatedButton(\n            onPressed: _updateProfile,\n            child: Text(_loading ? 'Saving...' : 'Update'),\n          ),\n          const SizedBox(height: 18),\n          TextButton(onPressed: _signOut, child: const Text('Sign Out')),\n        ],\n      ),\n    );\n  }\n}\n```\nStorage management\n\nCongratulations, you've built a fully functional user management app using Flutter and Supabase!\nSee also\n\nFlutter Tutorial: building a Flutter chat app\nFlutter Tutorial - Part 2: Authentication and Authorization with RLS\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Video Guide",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-nextjs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with NextJS',\n  description: 'Learn how to use Supabase in your Next App.',\n  video: 'https://www.youtube.com/v/0Fs96oZ4se0',\n}\n\n\nVideo Guide\n\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Next.js app from scratch.\nInitialize a Next.js app\nWe can use create-next-app to initialize\nan app called `supabase-nextjs`:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n`bash\nnpx create-next-app@latest --use-npm supabase-nextjs\ncd supabase-nextjs`\n\n\n`bash\nnpx create-next-app@latest --ts --use-npm supabase-nextjs\ncd supabase-nextjs`\n\n\nThen install the Supabase client library: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in a `.env.local`.\nAll we need are the API URL and the `anon` key that you copied earlier.\n`bash title=.env.local\nNEXT_PUBLIC_SUPABASE_URL=YOUR_SUPABASE_URL\nNEXT_PUBLIC_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nAnd one optional step is to update the CSS file `styles/globals.css` to make the app look nice.\nYou can find the full contents of this file here.\nSet up a Login component\nSupabase Auth Helpers\nNext.js is a highly versatile framework offering pre-rendering at build time (SSG), server-side rendering at request time (SSR), API routes, and middleware edge-functions.\nIt can be challenging to authenticate your users in all these different environments, that's why we've created the Supabase Auth Helpers to make user management and data fetching within Next.js as easy as possible.\nInstall the auth helpers for React and Next.js\n`bash\nnpm install @supabase/auth-helpers-react @supabase/auth-helpers-nextjs`\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nWrap your `pages/_app.js` component with the `SessionContextProvider` component:\n```jsx title=pages/_app.js\nimport '../styles/globals.css'\nimport { createBrowserSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { SessionContextProvider } from '@supabase/auth-helpers-react'\nimport { useState } from 'react'\nfunction MyApp({ Component, pageProps }) {\n  const [supabase] = useState(() => createBrowserSupabaseClient())\nreturn (\n    \n\n\n  )\n}\nexport default MyApp\n```\n\n\nWrap your `pages/_app.tsx` component with the `SessionContextProvider` component:\n```jsx lines=2,8 title=pages/_app.tsx\nimport { useState } from 'react'\nimport { createBrowserSupabaseClient } from '@supabase/auth-helpers-nextjs'\nimport { SessionContextProvider, Session } from '@supabase/auth-helpers-react'\nimport { AppProps } from 'next/app'\nfunction MyApp({\n  Component,\n  pageProps,\n}: AppProps<{\n  initialSession: Session,\n}>) {\n  const [supabase] = useState(() => createBrowserSupabaseClient())\nreturn (\n    \n\n\n  )\n}\nexport default MyApp\n```\nSee the Auth Helpers docs for more details on usage with TypeScript.\n\n\nSupabase Auth UI\nWe can use the Supabase Auth UI a pre-built React component for authenticating users via OAuth, email, and magic links.\nInstall the Supabase Auth UI for React\n`bash\nnpm install @supabase/auth-ui-react`\nAdd the `Auth` component to your home page\n```jsx title=pages/index.js\nimport { Auth, ThemeSupa } from '@supabase/auth-ui-react'\nimport { useSession, useSupabaseClient } from '@supabase/auth-helpers-react'\nconst Home = () => {\n  const session = useSession()\n  const supabase = useSupabaseClient()\nreturn (\n    \n      {!session ? (\n        \n      ) : (\n        Account page will go here.\n      )}\n    \n  )\n}\nexport default Home\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\nLet's create a new component for that called `Account.js` within a `components` folder.\n```tsx title=components/Account.js\nimport { useState, useEffect } from 'react'\nimport { useUser, useSupabaseClient } from '@supabase/auth-helpers-react'\nexport default function Account({ session }) {\n  const supabase = useSupabaseClient()\n  const user = useUser()\n  const [loading, setLoading] = useState(true)\n  const [username, setUsername] = useState(null)\n  const [website, setWebsite] = useState(null)\n  const [avatar_url, setAvatarUrl] = useState(null)\nuseEffect(() => {\n    getProfile()\n  }, [session])\nasync function getProfile() {\n    try {\n      setLoading(true)\n\n\n```  let { data, error, status } = await supabase\n    .from('profiles')\n    .select(`username, website, avatar_url`)\n    .eq('id', user.id)\n    .single()\n\n  if (error && status !== 406) {\n    throw error\n  }\n\n  if (data) {\n    setUsername(data.username)\n    setWebsite(data.website)\n    setAvatarUrl(data.avatar_url)\n  }\n} catch (error) {\n  alert('Error loading user data!')\n  console.log(error)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nasync function updateProfile({ username, website, avatar_url }) {\n    try {\n      setLoading(true)\n\n\n```  const updates = {\n    id: user.id,\n    username,\n    website,\n    avatar_url,\n    updated_at: new Date().toISOString(),\n  }\n\n  let { error } = await supabase.from('profiles').upsert(updates)\n  if (error) throw error\n  alert('Profile updated!')\n} catch (error) {\n  alert('Error updating the data!')\n  console.log(error)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nreturn (\n    \n\nEmail\n\n\n\nUsername\n setUsername(e.target.value)}\n        />\n      \n\nWebsite\n setWebsite(e.target.value)}\n        />\n      \n\n\n```  <div>\n    <button\n      className=\"button primary block\"\n      onClick={() => updateProfile({ username, website, avatar_url })}\n      disabled={loading}\n    >\n      {loading ? 'Loading ...' : 'Update'}\n    </button>\n  </div>\n\n  <div>\n    <button className=\"button block\" onClick={() => supabase.auth.signOut()}>\n      Sign Out\n    </button>\n  </div>\n</div>\n```\n\n\n)\n}\n```\n\n\nLet's create a new component for that called `Account.tsx` within a `components` folder.\n```tsx title=components/Account.tsx\nimport { useState, useEffect } from 'react'\nimport { useUser, useSupabaseClient, Session } from '@supabase/auth-helpers-react'\nimport { Database } from '../utils/database.types'\ntype Profiles = Database['public']['Tables']['profiles']['Row']\nexport default function Account({ session }: { session: Session }) {\n  const supabase = useSupabaseClient()\n  const user = useUser()\n  const [loading, setLoading] = useState(true)\n  const [username, setUsername] = useState(null)\n  const [website, setWebsite] = useState(null)\n  const [avatar_url, setAvatarUrl] = useState(null)\nuseEffect(() => {\n    getProfile()\n  }, [session])\nasync function getProfile() {\n    try {\n      setLoading(true)\n      if (!user) throw new Error('No user')\n\n\n```  let { data, error, status } = await supabase\n    .from('profiles')\n    .select(`username, website, avatar_url`)\n    .eq('id', user.id)\n    .single()\n\n  if (error && status !== 406) {\n    throw error\n  }\n\n  if (data) {\n    setUsername(data.username)\n    setWebsite(data.website)\n    setAvatarUrl(data.avatar_url)\n  }\n} catch (error) {\n  alert('Error loading user data!')\n  console.log(error)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nasync function updateProfile({\n    username,\n    website,\n    avatar_url,\n  }: {\n    username: Profiles['username']\n    website: Profiles['website']\n    avatar_url: Profiles['avatar_url']\n  }) {\n    try {\n      setLoading(true)\n      if (!user) throw new Error('No user')\n\n\n```  const updates = {\n    id: user.id,\n    username,\n    website,\n    avatar_url,\n    updated_at: new Date().toISOString(),\n  }\n\n  let { error } = await supabase.from('profiles').upsert(updates)\n  if (error) throw error\n  alert('Profile updated!')\n} catch (error) {\n  alert('Error updating the data!')\n  console.log(error)\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nreturn (\n    \n\nEmail\n\n\n\nUsername\n setUsername(e.target.value)}\n        />\n      \n\nWebsite\n setWebsite(e.target.value)}\n        />\n      \n\n\n```  <div>\n    <button\n      className=\"button primary block\"\n      onClick={() => updateProfile({ username, website, avatar_url })}\n      disabled={loading}\n    >\n      {loading ? 'Loading ...' : 'Update'}\n    </button>\n  </div>\n\n  <div>\n    <button className=\"button block\" onClick={() => supabase.auth.signOut()}>\n      Sign Out\n    </button>\n  </div>\n</div>\n```\n\n\n)\n}\n```\n\n\nLaunch!\nNow that we have all the components in place, let's update `pages/index.js`:\n```jsx lines=3,14 title=pages/index.js\nimport { Auth, ThemeSupa } from '@supabase/auth-ui-react'\nimport { useSession, useSupabaseClient } from '@supabase/auth-helpers-react'\nimport Account from '../components/Account'\nconst Home = () => {\n  const session = useSession()\n  const supabase = useSupabaseClient()\nreturn (\n    \n      {!session ? (\n        \n      ) : (\n        \n      )}\n    \n  )\n}\nexport default Home\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm run dev`\nAnd then open the browser to localhost:3000 and you should see the completed app.\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like\nphotos and videos.\nCreate an upload widget\nLet's create an avatar widget for the user so that they can upload a profile photo. We can start by creating a new component:\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"js\"\n\n\n\n```jsx title=components/Avatar.js\nimport React, { useEffect, useState } from 'react'\nimport { useSupabaseClient } from '@supabase/auth-helpers-react'\nexport default function Avatar({ uid, url, size, onUpload }) {\n  const supabase = useSupabaseClient()\n  const [avatarUrl, setAvatarUrl] = useState(null)\n  const [uploading, setUploading] = useState(false)\nuseEffect(() => {\n    if (url) downloadImage(url)\n  }, [url])\nasync function downloadImage(path) {\n    try {\n      const { data, error } = await supabase.storage.from('avatars').download(path)\n      if (error) {\n        throw error\n      }\n      const url = URL.createObjectURL(data)\n      setAvatarUrl(url)\n    } catch (error) {\n      console.log('Error downloading image: ', error)\n    }\n  }\nconst uploadAvatar = async (event) => {\n    try {\n      setUploading(true)\n\n\n```  if (!event.target.files || event.target.files.length === 0) {\n    throw new Error('You must select an image to upload.')\n  }\n\n  const file = event.target.files[0]\n  const fileExt = file.name.split('.').pop()\n  const fileName = `${uid}.${fileExt}`\n  const filePath = `${fileName}`\n\n  let { error: uploadError } = await supabase.storage\n    .from('avatars')\n    .upload(filePath, file, { upsert: true })\n\n  if (uploadError) {\n    throw uploadError\n  }\n\n  onUpload(filePath)\n} catch (error) {\n  alert('Error uploading avatar!')\n  console.log(error)\n} finally {\n  setUploading(false)\n}\n```\n\n\n}\nreturn (\n    \n      {avatarUrl ? (\n        \n      ) : (\n        \n      )}\n      \n\n          {uploading ? 'Uploading ...' : 'Upload'}\n        \n\n\n\n  )\n}\n```\n\n\n```tsx title=components/Avatar.tsx\nimport React, { useEffect, useState } from 'react'\nimport { useSupabaseClient } from '@supabase/auth-helpers-react'\nimport { Database } from '../utils/database.types'\ntype Profiles = Database['public']['Tables']['profiles']['Row']\nexport default function Avatar({\n  uid,\n  url,\n  size,\n  onUpload,\n}: {\n  uid: string\n  url: Profiles['avatar_url']\n  size: number\n  onUpload: (url: string) => void\n}) {\n  const supabase = useSupabaseClient()\n  const [avatarUrl, setAvatarUrl] = useState(null)\n  const [uploading, setUploading] = useState(false)\nuseEffect(() => {\n    if (url) downloadImage(url)\n  }, [url])\nasync function downloadImage(path: string) {\n    try {\n      const { data, error } = await supabase.storage.from('avatars').download(path)\n      if (error) {\n        throw error\n      }\n      const url = URL.createObjectURL(data)\n      setAvatarUrl(url)\n    } catch (error) {\n      console.log('Error downloading image: ', error)\n    }\n  }\nconst uploadAvatar: React.ChangeEventHandler = async (event) => {\n    try {\n      setUploading(true)\n\n\n```  if (!event.target.files || event.target.files.length === 0) {\n    throw new Error('You must select an image to upload.')\n  }\n\n  const file = event.target.files[0]\n  const fileExt = file.name.split('.').pop()\n  const fileName = `${uid}.${fileExt}`\n  const filePath = `${fileName}`\n\n  let { error: uploadError } = await supabase.storage\n    .from('avatars')\n    .upload(filePath, file, { upsert: true })\n\n  if (uploadError) {\n    throw uploadError\n  }\n\n  onUpload(filePath)\n} catch (error) {\n  alert('Error uploading avatar!')\n  console.log(error)\n} finally {\n  setUploading(false)\n}\n```\n\n\n}\nreturn (\n    \n      {avatarUrl ? (\n        \n      ) : (\n        \n      )}\n      \n\n          {uploading ? 'Uploading ...' : 'Upload'}\n        \n\n\n\n  )\n}\n```\n\n\nAdd the new widget\nAnd then we can add the widget to the Account page:\n```jsx title=components/Account.js\n// Import the new component\nimport Avatar from './Avatar'\n// ...\nreturn (\n\n\n    {/* Add to the body */}\n     {\n        setAvatarUrl(url)\n        updateProfile({ username, website, avatar_url: url })\n      }}\n    />\n    {/* ... */}\n  \n)\n```\nStorage management\n\nAt this stage you have a fully functional application!\nSee also\n\nSee the complete example on GitHub and deploy it to Vercel\nExplore the pre-built Auth UI for React\nExplore the Auth Helpers for Next.js\nExplore the Supabase Cache Helpers\nSee the Next.js Subscription Payments Starter template on GitHub\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-ionic-react.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Ionic React',\n  description: 'Learn how to use Supabase in your Ionic React App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the React app from scratch.\nInitialize an Ionic React app\nWe can use the Ionic CLI to initialize\nan app called `supabase-ionic-react`:\n`bash\nnpm install -g @ionic/cli\nionic start supabase-ionic-react blank --type react\ncd supabase-ionic-react`\nThen let's install the only additional dependency: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in a `.env`.\nAll we need are the API URL and the `anon` key that you copied earlier.\n`bash title=.env\nREACT_APP_SUPABASE_URL=YOUR_SUPABASE_URL\nREACT_APP_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nNow that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed\non the browser, and that's completely fine since we have Row Level Security enabled on our Database.\n```js title=src/supabaseClient.js\nimport { createClient } from '@supabase/supabase-js'\nconst supabaseUrl = process.env.REACT_APP_SUPABASE_URL\nconst supabaseAnonKey = process.env.REACT_APP_SUPABASE_ANON_KEY\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey)\n```\nSet up a Login route\nLet's set up a React component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\n```jsx title=/src/pages/Login.tsx\nimport { useState } from 'react';\nimport {\n  IonButton,\n  IonContent,\n  IonHeader,\n  IonInput,\n  IonItem,\n  IonLabel,\n  IonList,\n  IonPage,\n  IonTitle,\n  IonToolbar,\n  useIonToast,\n  useIonLoading,\n} from '@ionic/react';\nimport { supabase } from '../supabaseClient';\nexport function LoginPage() {\n  const [email, setEmail] = useState('');\nconst [showLoading, hideLoading] = useIonLoading();\n  const [showToast ] = useIonToast();\n  const handleLogin = async (e: React.FormEvent) => {\n    console.log()\n    e.preventDefault();\n    await showLoading();\n    try {\n      await supabase.auth.signIn({ email });\n      await showToast({ message: 'Check your email for the login link!' });\n    } catch (e: any) {\n      await showToast({ message: e.error_description || e.message , duration: 5000});\n    } finally {\n      await hideLoading();\n    }\n  };\n  return (\n    \n\n\nLogin\n\n\n\n\n```  <IonContent>\n    <div className=\"ion-padding\">\n      <h1>Supabase + Ionic React</h1>\n      <p>Sign in via magic link with your email below</p>\n    </div>\n    <IonList inset={true}>\n      <form onSubmit={handleLogin}>\n        <IonItem>\n          <IonLabel position=\"stacked\">Email</IonLabel>\n          <IonInput\n            value={email}\n            name=\"email\"\n            onIonChange={(e) => setEmail(e.detail.value ?? '')}\n            type=\"email\"\n          ></IonInput>\n        </IonItem>\n        <div className=\"ion-text-center\">\n          <IonButton type=\"submit\" fill=\"clear\">\n            Login\n          </IonButton>\n        </div>\n      </form>\n    </IonList>\n  </IonContent>\n</IonPage>\n```\n\n\n);\n}\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new component for that called `Account.tsx`.\n```jsx title=src/pages/Account.tsx\nimport {\n  IonButton,\n  IonContent,\n  IonHeader,\n  IonInput,\n  IonItem,\n  IonLabel,\n  IonPage,\n  IonTitle,\n  IonToolbar,\n  useIonLoading,\n  useIonToast,\n  useIonRouter\n} from '@ionic/react';\nimport { useEffect, useState } from 'react';\nimport { supabase } from '../supabaseClient';\nexport function AccountPage() {\n  const [showLoading, hideLoading] = useIonLoading();\n  const [showToast] = useIonToast();\n  const [session] = useState(() => supabase.auth.session());\n  const router = useIonRouter();\n  const [profile, setProfile] = useState({\n    username: '',\n    website: '',\n    avatar_url: '',\n  });\n  useEffect(() => {\n    getProfile();\n  }, [session]);\n  const getProfile = async () => {\n    console.log('get');\n    await showLoading();\n    try {\n      const user = supabase.auth.user();\n      let { data, error, status } = await supabase\n        .from('profiles')\n        .select(`username, website, avatar_url`)\n        .eq('id', user!.id)\n        .single();\n\n\n```  if (error && status !== 406) {\n    throw error;\n  }\n\n  if (data) {\n    setProfile({\n      username: data.username,\n      website: data.website,\n      avatar_url: data.avatar_url,\n    });\n  }\n} catch (error: any) {\n  showToast({ message: error.message, duration: 5000 });\n} finally {\n  await hideLoading();\n}\n```\n\n\n};\n  const signOut = async () => {\n    await supabase.auth.signOut();\n    router.push('/', 'forward', 'replace');\n  }\n  const updateProfile = async (e?: any, avatar_url: string = '') => {\n    e?.preventDefault();\n\n\n```console.log('update ');\nawait showLoading();\n\ntry {\n  const user = supabase.auth.user();\n\n  const updates = {\n    id: user!.id,\n    ...profile,\n    avatar_url: avatar_url,\n    updated_at: new Date(),\n  };\n\n  let { error } = await supabase.from('profiles').upsert(updates, {\n    returning: 'minimal', // Don't return the value after inserting\n  });\n\n  if (error) {\n    throw error;\n  }\n} catch (error: any) {\n  showToast({ message: error.message, duration: 5000 });\n} finally {\n  await hideLoading();\n}\n```\n\n\n};\n  return (\n    \n\n\nAccount\n\n\n\n\n```  <IonContent>\n    <form onSubmit={updateProfile}>\n      <IonItem>\n        <IonLabel>\n          <p>Email</p>\n          <p>{session?.user?.email}</p>\n        </IonLabel>\n      </IonItem>\n\n      <IonItem>\n        <IonLabel position=\"stacked\">Name</IonLabel>\n        <IonInput\n          type=\"text\"\n          name=\"username\"\n          value={profile.username}\n          onIonChange={(e) =>\n            setProfile({ ...profile, username: e.detail.value ?? '' })\n          }\n        ></IonInput>\n      </IonItem>\n\n      <IonItem>\n        <IonLabel position=\"stacked\">Website</IonLabel>\n        <IonInput\n          type=\"url\"\n          name=\"website\"\n          value={profile.website}\n          onIonChange={(e) =>\n            setProfile({ ...profile, website: e.detail.value ?? '' })\n          }\n        ></IonInput>\n      </IonItem>\n      <div className=\"ion-text-center\">\n        <IonButton fill=\"clear\" type=\"submit\">\n          Update Profile\n        </IonButton>\n      </div>\n    </form>\n\n    <div className=\"ion-text-center\">\n      <IonButton fill=\"clear\" onClick={signOut}>\n        Log Out\n      </IonButton>\n    </div>\n  </IonContent>\n</IonPage>\n```\n\n\n);\n}\n```\nLaunch!\nNow that we have all the components in place, let's update `App.tsx`:\n```jsx title=src/App.tsx\nimport { Redirect, Route } from 'react-router-dom'\nimport { IonApp, IonRouterOutlet, setupIonicReact } from '@ionic/react'\nimport { IonReactRouter } from '@ionic/react-router'\nimport { supabase } from './supabaseClient'\nimport '@ionic/react/css/ionic.bundle.css'\n/ Theme variables /\nimport './theme/variables.css'\nimport { LoginPage } from './pages/Login'\nimport { AccountPage } from './pages/Account'\nimport { useEffect, useState } from 'react'\nimport { Session } from '@supabase/supabase-js'\nsetupIonicReact()\nconst App: React.FC = () => {\n  const [session, setSession] = useState < Session > null\n  useEffect(() => {\n    setSession(supabase.auth.session())\n    supabase.auth.onAuthStateChange((_event, session) => {\n      setSession(session)\n    })\n  }, [])\n  return (\n    \n\n\n {\n              return session ?  : \n            }}\n          />\n          \n\n\n\n\n\n  )\n}\nexport default App\n```\nOnce that's done, run this in a terminal window:\n`bash\nionic serve`\nAnd then open the browser to localhost:3000 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nFirst install two packages in order to interact with the user's camera.\n`bash\nnpm install @ionic/pwa-elements @capacitor/camera`\nCapacitorJS is a cross platform native runtime from Ionic that enables web apps to be deployed through the app store and provides access to native deavice API.\nIonic PWA elements is a companion package that will polyfill certain browser APIs that provide no user interface with custom Ionic UI.\nWith those packages installed we can update our `index.tsx` to include an additional bootstapping call for the Ionic PWA Elements.\n```ts title=src/index.tsx\nimport React from 'react'\nimport ReactDOM from 'react-dom'\nimport App from './App'\nimport * as serviceWorkerRegistration from './serviceWorkerRegistration'\nimport reportWebVitals from './reportWebVitals'\nimport { defineCustomElements } from '@ionic/pwa-elements/loader'\ndefineCustomElements(window)\nReactDOM.render(\n  \n\n,\n  document.getElementById('root')\n)\nserviceWorkerRegistration.unregister()\nreportWebVitals()\n```\nThen create an AvatarComponent.\n```jsx title=src/components/Avatar.tsx\nimport { IonIcon } from '@ionic/react';\nimport { person } from 'ionicons/icons';\nimport { Camera, CameraResultType } from '@capacitor/camera';\nimport { useEffect, useState } from 'react';\nimport { supabase } from '../supabaseClient';\nimport './Avatar.css'\nexport function Avatar({\n  url,\n  onUpload,\n}: {\n  url: string;\n  onUpload: (e: any, file: string) => Promise;\n}) {\n  const [avatarUrl, setAvatarUrl] = useState();\nuseEffect(() => {\n    if (url) {\n      downloadImage(url);\n    }\n  }, [url]);\n  const uploadAvatar = async () => {\n    try {\n      const photo = await Camera.getPhoto({\n        resultType: CameraResultType.DataUrl,\n      });\n\n\n```  const file = await fetch(photo.dataUrl!)\n    .then((res) => res.blob())\n    .then(\n      (blob) =>\n        new File([blob], 'my-file', { type: `image/${photo.format}` })\n    );\n\n  const fileName = `${Math.random()}-${new Date().getTime()}.${\n    photo.format\n  }`;\n  let { error: uploadError } = await supabase.storage\n    .from('avatars')\n    .upload(fileName, file);\n  if (uploadError) {\n    throw uploadError;\n  }\n  onUpload(null, fileName);\n} catch (error) {\n  console.log(error);\n}\n```\n\n\n};\nconst downloadImage = async (path: string) => {\n    try {\n      const { data, error } = await supabase.storage\n        .from('avatars')\n        .download(path);\n      if (error) {\n        throw error;\n      }\n      const url = URL.createObjectURL(data!);\n      setAvatarUrl(url);\n    } catch (error: any) {\n      console.log('Error downloading image: ', error.message);\n    }\n  };\nreturn (\n    \n\n      {avatarUrl ? (\n        \n      ) : (\n        \n      )}\n    \n\n\n```</div>\n```\n\n\n);\n}\n```\nAdd the new widget\nAnd then we can add the widget to the Account page:\n```jsx title=src/pages/Account.tsx\n// Import the new component\nimport { Avatar } from '../components/Avatar';\n// ...\nreturn (\n  \n\n\nAccount\n\n\n\n\n```<IonContent>\n  <Avatar url={profile.avatar_url} onUpload={updateProfile}></Avatar>\n```\n\n\n```\nStorage management\n\nAt this stage you have a fully functional application!\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-ionic-angular.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Ionic Angular',\n  description: 'Learn how to use Supabase in your Ionic Angular App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Angular app from scratch.\nInitialize an Ionic Angular app\nWe can use the Ionic CLI to initialize\nan app called `supabase-ionic-angular`:\n`bash\nnpm install -g @ionic/cli\nionic start supabase-ionic-angular blank --type angular\ncd supabase-ionic-angular`\nThen let's install the only additional dependency: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in the `environment.ts` file.\nAll we need are the API URL and the `anon` key that you copied earlier.\nThese variables will be exposed on the browser, and that's completely fine since we have Row Level Security enabled on our Database.\n`ts title=environment.ts\nexport const environment = {\n  production: false,\n  supabaseUrl: 'YOUR_SUPABASE_URL',\n  supabaseKey: 'YOUR_SUPABASE_KEY',\n}`\nNow that we have the API credentials in place, let's create a SupabaseService with `ionic g s supabase` to initialize the Supabase client and implement functions to communicate with the Supabase API.\n```ts title=src/app/supabase.service.ts\nimport { Injectable } from '@angular/core'\nimport { LoadingController, ToastController } from '@ionic/angular'\nimport { AuthChangeEvent, createClient, Session, SupabaseClient } from '@supabase/supabase-js'\nimport { environment } from '../environments/environment'\nexport interface Profile {\n  username: string\n  website: string\n  avatar_url: string\n}\n@Injectable({\n  providedIn: 'root',\n})\nexport class SupabaseService {\n  private supabase: SupabaseClient\nconstructor(private loadingCtrl: LoadingController, private toastCtrl: ToastController) {\n    this.supabase = createClient(environment.supabaseUrl, environment.supabaseKey)\n  }\nget user() {\n    return this.supabase.auth.user()\n  }\nget session() {\n    return this.supabase.auth.session()\n  }\nget profile() {\n    return this.supabase\n      .from('profiles')\n      .select(`username, website, avatar_url`)\n      .eq('id', this.user?.id)\n      .single()\n  }\nauthChanges(callback: (event: AuthChangeEvent, session: Session | null) => void) {\n    return this.supabase.auth.onAuthStateChange(callback)\n  }\nsignIn(email: string) {\n    return this.supabase.auth.signIn({ email })\n  }\nsignOut() {\n    return this.supabase.auth.signOut()\n  }\nupdateProfile(profile: Profile) {\n    const update = {\n      ...profile,\n      id: this.user?.id,\n      updated_at: new Date(),\n    }\n\n\n```return this.supabase.from('profiles').upsert(update, {\n  returning: 'minimal', // Don't return the value after inserting\n})\n```\n\n\n}\ndownLoadImage(path: string) {\n    return this.supabase.storage.from('avatars').download(path)\n  }\nuploadAvatar(filePath: string, file: File) {\n    return this.supabase.storage.from('avatars').upload(filePath, file)\n  }\nasync createNotice(message: string) {\n    const toast = await this.toastCtrl.create({ message, duration: 5000 })\n    await toast.present()\n  }\ncreateLoader() {\n    return this.loadingCtrl.create()\n  }\n}\n```\nSet up a Login route\nLet's set up an route to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\nCreate an LoginPage with `ionic g page login` Ionic CLI command.\n\nThis guide will show the template inline, but the example app will have templateUrls\n\n```ts title=src/app/login/login.page.ts\nimport { Component, OnInit } from '@angular/core'\nimport { SupabaseService } from '../supabase.service'\n@Component({\n  selector: 'app-login',\n  template: `\n    \n\nLogin\n\n\n\n\n```<ion-content>\n  <div class=\"ion-padding\">\n    <h1>Supabase + Ionic Angular</h1>\n    <p>Sign in via magic link with your email below</p>\n  </div>\n  <ion-list inset=\"true\">\n    <form (ngSubmit)=\"handleLogin($event)\">\n      <ion-item>\n        <ion-label position=\"stacked\">Email</ion-label>\n        <ion-input [(ngModel)]=\"email\" name=\"email\" autocomplete type=\"email\"></ion-input>\n      </ion-item>\n      <div class=\"ion-text-center\">\n        <ion-button type=\"submit\" fill=\"clear\">Login</ion-button>\n      </div>\n    </form>\n  </ion-list>\n</ion-content>\n```\n\n\n`,\n  styleUrls: ['./login.page.scss'],\n})\nexport class LoginPage implements OnInit {\n  email = ''\n  constructor(private readonly supabase: SupabaseService) {}\nngOnInit() {}\n  async handleLogin(event: any) {\n    event.preventDefault()\n    const loader = await this.supabase.createLoader()\n    await loader.present()\n    try {\n      await this.supabase.signIn(this.email)\n      await loader.dismiss()\n      await this.supabase.createNotice('Check your email for the login link!')\n    } catch (error) {\n      await loader.dismiss()\n      await this.supabase.createNotice(error.error_description || error.message)\n    }\n  }\n}\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nCreate an AccountComponent with `ionic g page account` Ionic CLI command.\n```ts title=src/app/account.component.ts\nimport { Component, OnInit } from '@angular/core'\nimport { Router } from '@angular/router'\nimport { Profile, SupabaseService } from '../supabase.service'\n@Component({\n  selector: 'app-account',\n  template: `\n    \n\nAccount\n\n\n\n\n```<ion-content>\n  <form>\n    <ion-item>\n      <ion-label position=\"stacked\">Email</ion-label>\n      <ion-input type=\"email\" [value]=\"session?.user?.email\"></ion-input>\n    </ion-item>\n\n    <ion-item>\n      <ion-label position=\"stacked\">Name</ion-label>\n      <ion-input type=\"text\" name=\"username\" [(ngModel)]=\"profile.username\"></ion-input>\n    </ion-item>\n\n    <ion-item>\n      <ion-label position=\"stacked\">Website</ion-label>\n      <ion-input type=\"url\" name=\"website\" [(ngModel)]=\"profile.website\"></ion-input>\n    </ion-item>\n    <div class=\"ion-text-center\">\n      <ion-button fill=\"clear\" (click)=\"updateProfile()\">Update Profile</ion-button>\n    </div>\n  </form>\n\n  <div class=\"ion-text-center\">\n    <ion-button fill=\"clear\" (click)=\"signOut()\">Log Out</ion-button>\n  </div>\n</ion-content>\n```\n\n\n`,\n  styleUrls: ['./account.page.scss'],\n})\nexport class AccountPage implements OnInit {\n  profile: Profile = {\n    username: '',\n    avatar_url: '',\n    website: '',\n  }\nsession = this.supabase.session\nconstructor(private readonly supabase: SupabaseService, private router: Router) {}\n  ngOnInit() {\n    this.getProfile()\n  }\nasync getProfile() {\n    try {\n      let { data: profile, error, status } = await this.supabase.profile\n      if (error && status !== 406) {\n        throw error\n      }\n      if (profile) {\n        this.profile = profile\n      }\n    } catch (error) {\n      alert(error.message)\n    }\n  }\nasync updateProfile(avatar_url: string = '') {\n    const loader = await this.supabase.createLoader()\n    await loader.present()\n    try {\n      await this.supabase.updateProfile({ ...this.profile, avatar_url })\n      await loader.dismiss()\n      await this.supabase.createNotice('Profile updated!')\n    } catch (error) {\n      await this.supabase.createNotice(error.message)\n    }\n  }\nasync signOut() {\n    console.log('testing?')\n    await this.supabase.signOut()\n    this.router.navigate(['/'], { replaceUrl: true })\n  }\n}\n```\nLaunch!\nNow that we have all the components in place, let's update AppComponent:\n```ts title=src/app/app.component.ts\nimport { Component } from '@angular/core'\nimport { Router } from '@angular/router'\nimport { SupabaseService } from './supabase.service'\n@Component({\n  selector: 'app-root',\n  template: `<ion-app>\n      <ion-router-outlet></ion-router-outlet>\n    </ion-app>`,\n  styleUrls: ['app.component.scss'],\n})\nexport class AppComponent {\n  constructor(private supabase: SupabaseService, private router: Router) {\n    this.supabase.authChanges((_, session) => {\n      console.log(session)\n      if (session?.user) {\n        this.router.navigate(['/account'])\n      }\n    })\n  }\n}\n```\nThen update the AppRoutingModule\n```ts title=src/app/app.ts\"\nimport { NgModule } from '@angular/core'\nimport { PreloadAllModules, RouterModule, Routes } from '@angular/router'\nconst routes: Routes = [\n  {\n    path: '/',\n    loadChildren: () => import('./login/login.module').then((m) => m.LoginPageModule),\n  },\n  {\n    path: 'account',\n    loadChildren: () => import('./account/account.module').then((m) => m.AccountPageModule),\n  },\n]\n@NgModule({\n  imports: [\n    RouterModule.forRoot(routes, {\n      preloadingStrategy: PreloadAllModules,\n    }),\n  ],\n  exports: [RouterModule],\n})\nexport class AppRoutingModule {}\n```\nOnce that's done, run this in a terminal window:\n`bash\nionic serve`\nAnd the browser will auomatically open to show the app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo.\nFirst install two packages in order to interact with the user's camera.\n`bash\nnpm install @ionic/pwa-elements @capacitor/camera`\nCapacitorJS is a cross platform native runtime from Ionic that enables web apps to be deployed through the app store and provides access to native deavice API.\nIonic PWA elements is a companion package that will polyfill certain browser APIs that provide no user interface with custom Ionic UI.\nWith those packages installed we can update our `main.ts` to include an additional bootstapping call for the Ionic PWA Elements.\n```ts title=src/main.ts\nimport { enableProdMode } from '@angular/core'\nimport { platformBrowserDynamic } from '@angular/platform-browser-dynamic'\nimport { AppModule } from './app/app.module'\nimport { environment } from './environments/environment'\nimport { defineCustomElements } from '@ionic/pwa-elements/loader'\ndefineCustomElements(window)\nif (environment.production) {\n  enableProdMode()\n}\nplatformBrowserDynamic()\n  .bootstrapModule(AppModule)\n  .catch((err) => console.log(err))\n```\nThen create an AvatarComponent with this Ionic CLI command:\n`bash\n ionic g component avatar --module=/src/app/account/account.module.ts --create-module`\n```ts title=src/app/avatar.component.ts\nimport { Component, EventEmitter, Input, OnInit, Output } from '@angular/core'\nimport { DomSanitizer, SafeResourceUrl } from '@angular/platform-browser'\nimport { SupabaseService } from '../supabase.service'\nimport { Camera, CameraResultType } from '@capacitor/camera'\n@Component({\n  selector: 'app-avatar',\n  template:`\n\n\n\n\n\n\n`,\n  style: [`\n    :host {\n       display: block;\n       margin: auto;\n       min-height: 150px;\n    }\n     :host .avatar_wrapper {\n       margin: 16px auto 16px;\n       border-radius: 50%;\n       overflow: hidden;\n       height: 150px;\n       aspect-ratio: 1;\n       background: var(--ion-color-step-50);\n       border: thick solid var(--ion-color-step-200);\n    }\n     :host .avatar_wrapper:hover {\n       cursor: pointer;\n    }\n     :host .avatar_wrapper ion-icon.no-avatar {\n       width: 100%;\n       height: 115%;\n    }\n     :host img {\n       display: block;\n       object-fit: cover;\n       width: 100%;\n       height: 100%;\n    }\n  `,\n  ],\n})\nexport class AvatarComponent implements OnInit {\n  _avatarUrl: SafeResourceUrl | undefined\n  uploading = false\n@Input()\n  set avatarUrl(url: string | undefined) {\n    if (url) {\n      this.downloadImage(url)\n    }\n  }\n@Output() upload = new EventEmitter()\nconstructor(private readonly supabase: SupabaseService, private readonly dom: DomSanitizer) {}\nngOnInit() {}\nasync downloadImage(path: string) {\n    try {\n      const { data } = await this.supabase.downLoadImage(path)\n      this._avatarUrl = this.dom.bypassSecurityTrustResourceUrl(URL.createObjectURL(data))\n    } catch (error) {\n      console.error('Error downloading image: ', error.message)\n    }\n  }\nasync uploadAvatar() {\n    const loader = await this.supabase.createLoader()\n    try {\n      const photo = await Camera.getPhoto({\n        resultType: CameraResultType.DataUrl,\n      })\n\n\n```  const file = await fetch(photo.dataUrl)\n    .then((res) => res.blob())\n    .then((blob) => new File([blob], 'my-file', { type: `image/${photo.format}` }))\n\n  const fileName = `${Math.random()}-${new Date().getTime()}.${photo.format}`\n\n  await loader.present()\n  await this.supabase.uploadAvatar(fileName, file)\n\n  this.upload.emit(fileName)\n} catch (error) {\n  this.supabase.createNotice(error.message)\n} finally {\n  loader.dismiss()\n}\n```\n\n\n}\n}\n```\nAdd the new widget\nAnd then we can add the widget on top of the AccountComponent html template:\n```ts title=src/app/account.component.ts\ntemplate:`\n\n\nAccount\n\n\n\n  <app-avatar\n    [avatarUrl]=\"this.profile?.avatar_url\"\n    (upload)=\"updateProfile($event)\"\n\n\n\n\n`\n```\nStorage management\n\nAt this stage you have a fully functional application!\nSee also\n\nAuthentication in Ionic Angular with Supabase\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-solidjs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with SolidJS',\n  description: 'Learn how to use Supabase in your SolidJS App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the SolidJS app from scratch.\nInitialize a SolidJS app\nWe can use Degit to initialize an app called `supabase-solid`:\n`bash\nnpx degit solidjs/templates/ts supabase-solid\ncd supabase-solid`\nThen let's install the only additional dependency: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in a `.env`.\nAll we need are the API URL and the `anon` key that you copied earlier.\n`bash title=.env\nVITE_SUPABASE_URL=YOUR_SUPABASE_URL\nVITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nNow that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed\non the browser, and that's completely fine since we have Row Level Security enabled on our Database.\n```js title=src/supabaseClient.jsx\nimport { createClient } from '@supabase/supabase-js'\nconst supabaseUrl = import.meta.env.VITE_SUPABASE_URL\nconst supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey)\n```\nAnd one optional step is to update the CSS file `src/index.css` to make the app look nice.\nYou can find the full contents of this file here.\nSet up a Login component\nLet's set up a SolidJS component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\n```jsx title=src/Auth.tsx\nimport { createSignal } from 'solid-js'\nimport { supabase } from './supabaseClient'\nexport default function Auth() {\n  const [loading, setLoading] = createSignal(false)\n  const [email, setEmail] = createSignal('')\nconst handleLogin = async (e: SubmitEvent) => {\n    e.preventDefault()\n\n\n```try {\n  setLoading(true)\n  const { error } = await supabase.auth.signInWithOtp({ email: email() })\n  if (error) throw error\n  alert('Check your email for the login link!')\n} catch (error) {\n  if (error instanceof Error) {\n    alert(error.message)\n  }\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nreturn (\n    \n\nSupabase + SolidJS\nSign in via magic link with your email below\n\n\nEmail\n setEmail(e.currentTarget.value)}\n            />\n          \n\n\n              {loading() ? Loading : Send magic link}\n            \n\n\n\n\n  )\n}\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new component for that called `Account.tsx`.\n```jsx title=src/Account.tsx\nimport { AuthSession } from '@supabase/supabase-js'\nimport { Component, createEffect, createSignal } from 'solid-js'\nimport { supabase } from './supabaseClient'\ninterface Props {\n  session: AuthSession;\n}\nconst Account: Component = ({ session }) => {\n  const [loading, setLoading] = createSignal(true)\n  const [username, setUsername] = createSignal(null)\n  const [website, setWebsite] = createSignal(null)\n  const [avatarUrl, setAvatarUrl] = createSignal(null)\ncreateEffect(() => {\n    getProfile()\n  })\nconst getProfile = async () => {\n    try {\n      setLoading(true)\n      const { user } = session\n\n\n```  let { data, error, status } = await supabase\n    .from('profiles')\n    .select(`username, website, avatar_url`)\n    .eq('id', user.id)\n    .single()\n\n  if (error && status !== 406) {\n    throw error\n  }\n\n  if (data) {\n    setUsername(data.username)\n    setWebsite(data.website)\n    setAvatarUrl(data.avatar_url)\n  }\n} catch (error) {\n  if (error instanceof Error) {\n    alert(error.message)\n  }\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nconst updateProfile = async (e: Event) => {\n    e.preventDefault()\n\n\n```try {\n  setLoading(true)\n  const { user } = session\n\n  const updates = {\n    id: user.id,\n    username: username(),\n    website: website(),\n    avatar_url: avatarUrl(),\n    updated_at: new Date().toISOString(),\n  }\n\n  let { error } = await supabase.from('profiles').upsert(updates)\n\n  if (error) {\n    throw error\n  }\n} catch (error) {\n  if (error instanceof Error) {\n    alert(error.message)\n  }\n} finally {\n  setLoading(false)\n}\n```\n\n\n}\nreturn (\n    \n\nEmail: {session.user.email}\n\nName\n setUsername(e.currentTarget.value)}\n          />\n        \n\nWebsite\n setWebsite(e.currentTarget.value)}\n          />\n        \n\n\n            {loading() ? 'Saving ...' : 'Update profile'}\n          \n\n supabase.auth.signOut()}>\n          Sign Out\n        \n\n\n  )\n}\nexport default Account\n```\nLaunch!\nNow that we have all the components in place, let's update `App.tsx`:\n```jsx title=src/App.tsx\nimport { Component, createEffect, createSignal } from 'solid-js'\nimport { supabase } from './supabaseClient'\nimport { AuthSession } from '@supabase/supabase-js'\nimport Account from './Account'\nimport Auth from './Auth'\nconst App: Component = () => {\n  const [session, setSession] = createSignal(null)\ncreateEffect(() => {\n    supabase.auth.getSession().then(({ data: { session } }) => {\n      setSession(session)\n    })\n\n\n```supabase.auth.onAuthStateChange((_event, session) => {\n  setSession(session)\n})\n```\n\n\n})\nreturn (\n    \n      {!session() ?  : }\n    \n  )\n}\nexport default App\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm start`\nAnd then open the browser to localhost:3000 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:\n```jsx title=src/Avatar.tsx\nimport { Component, createEffect, createSignal, JSX } from 'solid-js'\nimport { supabase } from './supabaseClient'\ninterface Props {\n  size: number\n  url: string | null\n  onUpload: (event: Event, filePath: string) => void\n}\nconst Avatar: Component = (props) => {\n  const [avatarUrl, setAvatarUrl] = createSignal(null)\n  const [uploading, setUploading] = createSignal(false)\ncreateEffect(() => {\n    if (props.url) downloadImage(props.url)\n  })\nconst downloadImage = async (path: string) => {\n    try {\n      const { data, error } = await supabase.storage.from('avatars').download(path)\n      if (error) {\n        throw error\n      }\n      const url = URL.createObjectURL(data)\n      setAvatarUrl(url)\n    } catch (error) {\n      if (error instanceof Error) {\n        console.log('Error downloading image: ', error.message)\n      }\n    }\n  }\nconst uploadAvatar: JSX.EventHandler = async (event) => {\n    try {\n      setUploading(true)\n\n\n```  const target = event.currentTarget\n  if (!target?.files || target.files.length === 0) {\n    throw new Error('You must select an image to upload.')\n  }\n\n  const file = target.files[0]\n  const fileExt = file.name.split('.').pop()\n  const fileName = `${Math.random()}.${fileExt}`\n  const filePath = `${fileName}`\n\n  let { error: uploadError } = await supabase.storage.from('avatars').upload(filePath, file)\n\n  if (uploadError) {\n    throw uploadError\n  }\n\n  props.onUpload(event, filePath)\n} catch (error) {\n  if (error instanceof Error) {\n    alert(error.message)\n  }\n} finally {\n  setUploading(false)\n}\n```\n\n\n}\nreturn (\n    \n      {avatarUrl() ? (\n        ${props.size}px, width: `${props.size}px` }}\n        />\n      ) : (\n        ${props.size}px, width: `${props.size}px` }}\n        />\n      )}\n      ${props.size}px }}>\n        \n          {uploading() ? 'Uploading ...' : 'Upload avatar'}\n        \n\n\n\n\n\n  )\n}\nexport default Avatar\n```\nAdd the new widget\nAnd then we can add the widget to the Account page:\n```jsx title=src/Account.tsx\n// Import the new component\nimport Avatar from './Avatar'\n// ...\nreturn (\n\n\n    {/* Add to the body */}\n     {\n        setAvatarUrl(url)\n        updateProfile(e)\n      }}\n    />\n    {/* ... */}\n  \n)\n```\n\n### Storage management\n\n\n\nAt this stage you have a fully functional application!\n\nexport const Page = ({ children }) => \n",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-sveltekit.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with SvelteKit',\n  description: 'Learn how to use Supabase in your SvelteKit App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Svelte app from scratch.\nInitialize a Svelte app\nWe can use the SvelteKit Skeleton Project to initialize\nan app called `supabase-sveltekit` (for this tutorial we will be using TypeScript):\n`bash\nnpm init svelte@next supabase-sveltekit\ncd supabase-sveltekit\nnpm install`\nThen let's install the only additional dependency: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in a `.env`.\nAll we need are the `SUPABASE_URL` and the `SUPABASE_KEY` key that you copied earlier.\n`bash title=.env\nPUBLIC_SUPABASE_URL=\"YOUR_SUPABASE_URL\"\nPUBLIC_SUPABASE_ANON_KEY=\"YOUR_SUPABASE_KEY\"`\nNow that we have the API credentials in place, create a `src/lib/supabaseClient.ts` helper file to initialize the Supabase client.\nThese variables will be exposed on the browser, and that's completely fine since we have Row Level Security enabled on our Database.\n```js title=src/lib/supabaseClient.ts\nimport { createClient } from '@supabase/auth-helpers-sveltekit'\nimport { PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY } from '$env/static/public'\nexport const supabase = createClient(PUBLIC_SUPABASE_URL, PUBLIC_SUPABASE_ANON_KEY)\n```\nOptionally, update `src/routes/styles.css` with the CSS from the example.\nSupabase Auth Helpers\nSvelteKit is a highly versatile framework offering pre-rendering at build time (SSG), server-side rendering at request time (SSR), API routes, and more.\nIt can be challenging to authenticate your users in all these different environments, that's why we've created the Supabase Auth Helpers to make user management and data fetching within SvelteKit as easy as possible.\nInstall the auth helpers for SvelteKit:\n`bash\nnpm install @supabase/auth-helpers-sveltekit`\nUpdate your `src/routes/+layout.svelte`:\n```html title=src/routes/+layout.svelte\n\n\n\n\n```\nCreate a new `src/routes/+layout.ts` file to handle the session on the client-side.\n```ts title=src/routes/+layout.ts\nimport type { LayoutLoad } from './$types'\nimport { getSupabase } from '@supabase/auth-helpers-sveltekit'\nexport const load: LayoutLoad = async (event) => {\n  const { session } = await getSupabase(event)\n  return { session }\n}\n```\nCreate a new `src/routes/+layout.server.ts` file to handle the session on the server-side.\n```ts title=src/routes/+layout.server.ts\nimport type { LayoutServerLoad } from './$types'\nimport { getServerSession } from '@supabase/auth-helpers-sveltekit'\nexport const load: LayoutServerLoad = async (event) => {\n  return {\n    session: await getServerSession(event),\n  }\n}\n```\nBe sure to create `src/hooks.client.ts` and `src/hooks.server.ts` in order to get the auth helper started on the client and server-side.\n`ts title=src/hooks.client.ts\nimport '$lib/supabaseClient'`\n`ts title=src/hooks.server.ts\nimport '$lib/supabaseClient'`\nSet up a Login component\nLet's set up a Svelte component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\nCreate a new `Auth.svelte` component in the `src/routes` directory to handle this functionality.\n```html title=src/routes/Auth.svelte\n\n\n\nSupabase + SvelteKit\nSign in via magic link with your email below\n\n\n\n\n\n\n\n\n```\nAccount component\nAfter a user is signed in, they need to be able to edit their profile details and manage their account.\nCreate a new `Account.svelte` component in the `src/routes` directory to handle this functionality.\n```html title=src/routes/Account.svelte\n\n\n\nEmail\n\n\n\nName\n\n\n\nWebsite\n\n\n\n\n\n\nSign Out\n\n\n```\nLaunch!\nNow that we have all the components in place, let's update `src/routes/+page.svelte`:\n```html title=src/routes/+page.svelte\n\n\nSupabase + SvelteKit\n\n\n{#if !$page.data.session}\n\n{:else}\n\n{/if}\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm run dev`\nAnd then open the browser to localhost:5173 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component called `Avatar.svelte` in the `src/routes` directory:\n```html title=src/routes/Avatar.svelte\n\n\n  {#if avatarUrl}  {:else}\n  \n  {/if}\n\n  \n\n      {uploading ? 'Uploading ...' : 'Upload'}\n    \n\n\n\n```\nAdd the new widget\nAnd then we can add the widget to the Account page:\n```html title=src/routes/Account.svelte\n\n\n\n\n\n\n```\nStorage management\n\nAt this stage you have a fully functional application!\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-nuxt-3.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Nuxt 3',\n  description: 'Learn how to use Supabase in your Nuxt 3 App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Vue 3 app from scratch.\nInitialize a Nuxt 3 app\nWe can use nuxi init to create an app called `nuxt-user-management`:\n```bash\nnpx nuxi init nuxt-user-management\ncd nuxt-user-management\n```\nThen let's install the only additional dependency: NuxtSupabase. We only need to import NuxtSupabase as a dev dependency.\n`bash\nnpm install @nuxtjs/supabase --save-dev`\nAnd finally we want to save the environment variables in a `.env`.\nAll we need are the API URL and the `anon` key that you copied earlier.\n`bash title=.env\nSUPABASE_URL=\"YOUR_SUPABASE_URL\"\nSUPABASE_KEY=\"YOUR_SUPABASE_ANON_KEY\"`\nThese variables will be exposed on the browser, and that's completely fine since we have Row Level Security enabled on our Database.\nAmazing thing about NuxtSupabase is that setting environment variables is all we need to do in order to start using Supabase.\nNo need to initialize Supabase. The library will take care of it automatically.\nAnd one optional step is to update the CSS file `assets/main.css` to make the app look nice.\nYou can find the full contents of this file here.\n```typescript title=nuxt.config.ts\nimport { defineNuxtConfig } from 'nuxt'\n// https://v3.nuxtjs.org/api/configuration/nuxt.config\nexport default defineNuxtConfig({\n  modules: ['@nuxtjs/supabase'],\n  css: ['@/assets/main.css'],\n})\n```\nSet up Auth component\nLet's set up a Vue component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\n```vue title=/components/Auth.vue\n\n\n\n```\nUser state\nTo access the user information, use the composable useSupabaseUser provided by the Supabase Nuxt module.\nAccount component\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new component for that called `Account.vue`.\n```vue title=components/Account.vue\n\n\n\n```\nLaunch!\nNow that we have all the components in place, let's update `app.vue`:\n```vue title=app.vue\n\n\n\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm run dev`\nAnd then open the browser to localhost:3000 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nLet's create an avatar for the user so that they can upload a profile photo. We can start by creating a new component:\n```vue title=components/Avatar.vue\n\n\n\n```\nAdd the new widget\nAnd then we can add the widget to the Account page:\n```vue title=components/Account.vue\n\n\n\n```\nStorage management\n\nThat is it! You should now be able to upload a profile photo to Supabase Storage and you have a fully functional application.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "npm 6.x",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-vue-3.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Vue 3',\n  description: 'Learn how to use Supabase in your Vue 3 App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Vue 3 app from scratch.\nInitialize a Vue 3 app\nWe can quickly use Vite with Vue 3 Template to initialize\nan app called `supabase-vue-3`:\n```bash\nnpm 6.x\nnpm create vite@latest supabase-vue-3 --template vue\nnpm 7+, extra double-dash is needed:\nnpm create vite@latest supabase-vue-3 -- --template vue\ncd supabase-vue-3\n```\nThen let's install the only additional dependency: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in a `.env`.\nAll we need are the API URL and the `anon` key that you copied earlier.\n`bash title=.env\nVITE_SUPABASE_URL=YOUR_SUPABASE_URL\nVITE_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nWith the API credentials in place, create an `src/supabase.js` helper file to initialize the Supabase client. These variables are exposed\non the browser, and that's completely fine since we have Row Level Security enabled on our Database.\n```js title=src/supabase.js\nimport { createClient } from '@supabase/supabase-js'\nconst supabaseUrl = import.meta.env.VITE_SUPABASE_URL\nconst supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey)\n```\nOptionally, update src/style.css to style the app.\nSet up a Login component\nSet up an `src/components/Auth.vue` component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords. \n```vue title=/src/components/Auth.vue\n\n\n\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nCreate a new `src/components/Account.vue` component to handle this.\n```vue title=src/components/Account.vue\n\n\n\n```\nLaunch!\nNow that we have all the components in place, let's update `App.vue`:\n```vue title=src/App.vue\n\n\n\n```\nOnce that's done, run this in a terminal window:\n`bash\nnpm run dev`\nAnd then open the browser to localhost:5173 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nCreate a new `src/components/Avatar.vue` component that allows users to upload profile photos:\n```vue title=src/components/Avatar.vue\n\n\n\n```\nAdd the new widget\nAnd then we can add the widget to the Account page in `src/components/Account.vue`:\n```vue title=src/components/Account.vue\n\n\n\n```\nStorage management\n\nAt this stage you have a fully functional application!\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Building the App",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/tutorials/with-ionic-vue.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Build a User Management App with Ionic Vue',\n  description: 'Learn how to use Supabase in your Ionic Vue App.',\n}\n\n\n\n  If you get stuck while working through this guide, refer to the full example on\n  GitHub.\n\n\nBuilding the App\nLet's start building the Vue app from scratch.\nInitialize an Ionic Vue app\nWe can use the Ionic CLI to initialize\nan app called `supabase-ionic-vue`:\n`bash\nnpm install -g @ionic/cli\nionic start supabase-ionic-vue blank --type vue\ncd supabase-ionic-vue`\nThen let's install the only additional dependency: supabase-js\n`bash\nnpm install @supabase/supabase-js`\nAnd finally we want to save the environment variables in a `.env`.\nAll we need are the API URL and the `anon` key that you copied earlier.\n`bash title=.env\nVUE_APP_SUPABASE_URL=YOUR_SUPABASE_URL\nVUE_APP_SUPABASE_ANON_KEY=YOUR_SUPABASE_ANON_KEY`\nNow that we have the API credentials in place, let's create a helper file to initialize the Supabase client. These variables will be exposed\non the browser, and that's completely fine since we have Row Level Security enabled on our Database.\n```js title=src/supabase.ts\"\nimport { createClient } from '@supabase/supabase-js';\nconst supabaseUrl = process.env.VUE_APP_SUPABASE_URL as string;\nconst supabaseAnonKey = process.env.VUE_APP_SUPABASE_ANON_KEY as string;\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey);\n```\nSet up a Login route\nLet's set up a Vue component to manage logins and sign ups. We'll use Magic Links, so users can sign in with their email without using passwords.\n```html title=/src/views/Login.vue\n\n\n\n```<ion-content>\n  <div class=\"ion-padding\">\n    <h1>Supabase + Ionic Vue</h1>\n    <p>Sign in via magic link with your email below</p>\n  </div>\n  <ion-list inset=\"true\">\n    <form @submit.prevent=\"handleLogin\">\n      <ion-item>\n        <ion-label position=\"stacked\">Email</ion-label>\n        <ion-input v-model=\"email\" name=\"email\" autocomplete type=\"email\"></ion-input>\n      </ion-item>\n      <div class=\"ion-text-center\">\n        <ion-button type=\"submit\" fill=\"clear\">Login</ion-button>\n      </div>\n    </form>\n  </ion-list>\n  <p>{{email}}</p>\n</ion-content>\n```\n\n\n\n\n\n```\nAccount page\nAfter a user is signed in we can allow them to edit their profile details and manage their account.\nLet's create a new component for that called `Account.vue`.\n```html title=src/views/Account.vue\n\n\n\n```<ion-content>\n  <form @submit.prevent=\"updateProfile\">\n    <ion-item>\n      <ion-label>\n        <p>Email</p>\n        <p>{{ session?.user?.email }}</p>\n      </ion-label>\n    </ion-item>\n\n    <ion-item>\n      <ion-label position=\"stacked\">Name</ion-label>\n      <ion-input type=\"text\" name=\"username\" v-model=\"profile.username\"></ion-input>\n    </ion-item>\n\n    <ion-item>\n      <ion-label position=\"stacked\">Website</ion-label>\n      <ion-input type=\"url\" name=\"website\" v-model=\"profile.website\"></ion-input>\n    </ion-item>\n    <div class=\"ion-text-center\">\n      <ion-button fill=\"clear\" type=\"submit\">Update Profile</ion-button>\n    </div>\n  </form>\n\n  <div class=\"ion-text-center\">\n    <ion-button fill=\"clear\" @click=\"signOut\">Log Out</ion-button>\n  </div>\n</ion-content>\n```\n\n\n\n\n\n```\nLaunch!\nNow that we have all the components in place, let's update `App.vue` and our routes:\n```ts title=src/router.index.ts\nimport { createRouter, createWebHistory } from '@ionic/vue-router'\nimport { RouteRecordRaw } from 'vue-router'\nimport LoginPage from '../views/Login.vue'\nimport AccountPage from '../views/Account.vue'\nconst routes: Array = [\n  {\n    path: '/',\n    name: 'Login',\n    component: LoginPage,\n  },\n  {\n    path: '/account',\n    name: 'Account',\n    component: AccountPage,\n  },\n]\nconst router = createRouter({\n  history: createWebHistory(process.env.BASE_URL),\n  routes,\n})\nexport default router\n```\n```html title=src/App.vue\n\n\n```\nOnce that's done, run this in a terminal window:\n`bash\nionic serve`\nAnd then open the browser to localhost:3000 and you should see the completed app.\n\nBonus: Profile photos\nEvery Supabase project is configured with Storage for managing large files like photos and videos.\nCreate an upload widget\nFirst install two packages in order to interact with the user's camera.\n`bash\nnpm install @ionic/pwa-elements @capacitor/camera`\nCapacitorJS is a cross platform native runtime from Ionic that enables web apps to be deployed through the app store and provides access to native deavice API.\nIonic PWA elements is a companion package that will polyfill certain browser APIs that provide no user interface with custom Ionic UI.\nWith those packages installed we can update our `main.ts` to include an additional bootstapping call for the Ionic PWA Elements.\n```ts title=src/main.tsx\"\nimport { createApp } from 'vue'\nimport App from './App.vue'\nimport router from './router'\nimport { IonicVue } from '@ionic/vue'\n/ Core CSS required for Ionic components to work properly /\nimport '@ionic/vue/css/ionic.bundle.css'\n/ Theme variables /\nimport './theme/variables.css'\nimport { defineCustomElements } from '@ionic/pwa-elements/loader'\ndefineCustomElements(window)\nconst app = createApp(App).use(IonicVue).use(router)\nrouter.isReady().then(() => {\n  app.mount('#app')\n})\n```\nThen create an AvatarComponent.\n```html title=src/components/Avatar.vue\n\n\n\n\n```\nAdd the new widget\nAnd then we can add the widget to the Account page:\n```html title=src/views/Account.vue\n\n\n\n```<ion-content>\n  <avatar v-model:path=\"profile.avatar_url\" @upload=\"updateProfile\"></avatar>\n```\n\n\n...\n\n\n```\nStorage management\n\nAt this stage you have a fully functional application!\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "vue.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/quickstarts/vue.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport StepHikeCompact from '~/components/StepHikeCompact'\nexport const meta = {\n  title: 'Use Supabase with Vue',\n  subtitle:\n    'Learn how to create a Supabase project, add some sample data to your database, and query the data from a Vue app.',\n  breadcrumb: 'Framework Quickstarts',\n}\n\n\n\n\n\n```[Create a new project](https://app.supabase.com) in the Supabase Dashboard.\n\nAfter your project is ready, create a table in your Supabase database using the [SQL Editor](https://app.supabase.com/project/_/sql) in the Dashboard. Use the following SQL statement to create a `countries` table with some sample data.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```sql SQL_EDITOR\n    -- Create the table\n    CREATE TABLE countries (\n      id SERIAL PRIMARY KEY,\n      name VARCHAR(255) NOT NULL\n    );\n    -- Insert some sample data into the table\n    INSERT INTO countries (name) VALUES ('United States');\n    INSERT INTO countries (name) VALUES ('Canada');\n    INSERT INTO countries (name) VALUES ('Mexico');\n  ````\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Create a Vue app\">\n\nCreate a Vue app using the `npm init` command.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```sh Terminal\n  npm init vue@latest my-app\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a Vue app.\n\nNavigate to the Vue app and install `supabase-js`.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  cd my-app && npm install @supabase/supabase-js\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Create a `/src/lib` directory in your Vue app, create a file called `supabaseClient.js` and add the following code to initialize the Supabase client with your [project URL and public API (anon) key](https://app.supabase.com/project/_/settings/api).\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```js src/lib/supabaseClient.js\n    import { createClient } from '@supabase/supabase-js'\n\n    export const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Replace the existing content in your `App.vue` file with the following code.\n\n</StepHikeCompact.Details>\n<StepHikeCompact.Code>\n\n\n  ```vue src/App.vue\n    <script setup>\n    import { ref, onMounted } from 'vue'\n    import { supabase } from './lib/supabaseClient'\n\n    const countries = ref([])\n\n    async function getCountries() {\n      const { data } = await supabase.from('countries').select()\n      countries.value = data\n    }\n\n    onMounted(() => {\n      getCountries()\n    })\n    </script>\n\n    <template>\n      <ul>\n        <li v-for=\"country in countries\" :key=\"country.id\">{{ country.name }}</li>\n      </ul>\n    </template>\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Start the app and go to http://localhost:5173 in a browser and you should see the list of countries.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm run dev\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "flutter.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/quickstarts/flutter.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport StepHikeCompact from '~/components/StepHikeCompact'\nexport const meta = {\n  title: 'Use Supabase with Flutter',\n  subtitle:\n    'Learn how to create a Supabase project, add some sample data to your database, and query the data from a Flutter app.',\n  breadcrumb: 'Framework Quickstarts',\n}\n\n\n\n\n\n```[Create a new project](https://app.supabase.com) in the Supabase Dashboard.\n\nAfter your project is ready, create a table in your Supabase database using the [SQL Editor](https://app.supabase.com/project/_/sql) in the Dashboard. Use the following SQL statement to create a `countries` table with some sample data.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n ```sql SQL_EDITOR\n  -- Create the table\n  CREATE TABLE countries (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL\n  );\n  -- Insert some sample data into the table\n  INSERT INTO countries (name) VALUES ('United States');\n  INSERT INTO countries (name) VALUES ('Canada');\n  INSERT INTO countries (name) VALUES ('Mexico');\n  ````\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Create a Flutter app\">\n\nCreate a Flutter app using the `flutter create` command. You can skip this step if you already have a working app.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  flutter create my_app\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Install the Supabase client library\">\n\n  The fastest way to get started is to use the [`supabase_flutter`](https://pub.dev/packages/supabase_flutter) client library which provides a convenient interface for working with Supabase from a Flutter app.\n\n  Open the `pubspec.yaml` file inside your Flutter app and add `supabase_flutter` as a dependency.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```yaml pubspec.yaml\n  supabase_flutter: ^1.2.2\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Initialize the Supabase client\">\n\n  Open `lib/main.dart` and edit the main function to initialize Supabase using your [project URL and public API (anon) key](https://app.supabase.com/project/_/settings/api).\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```dart lib/main.dart\n  import 'package:supabase_flutter/supabase_flutter.dart';\n\n  Future<void> main() async {\n    WidgetsFlutterBinding.ensureInitialized();\n\n    await Supabase.initialize(\n      url: 'YOUR_SUPABASE_URL',\n      anonKey: 'YOUR_SUPABASE_ANON_KEY',\n    );\n    runApp(MyApp());\n  }\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Query data from the app\">\n\n  Use a `FutureBuilder` to fetch the data when the home page loads and display the query result in a `ListView`.\n\n  Replace the default `MyApp` and `MyHomePage` classes with the following code.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```dart lib/main.dart\n  class MyApp extends StatelessWidget {\n    const MyApp({Key? key}) : super(key: key);\n\n    @override\n    Widget build(BuildContext context) {\n      return const MaterialApp(\n        title: 'Countries',\n        home: HomePage(),\n      );\n    }\n  }\n\n  class HomePage extends StatefulWidget {\n    const HomePage({super.key});\n\n    @override\n    State<HomePage> createState() => _HomePageState();\n  }\n\n  class _HomePageState extends State<HomePage> {\n    final _future = Supabase.instance.client\n        .from('countries')\n        .select<List<Map<String, dynamic>>>();\n\n    @override\n    Widget build(BuildContext context) {\n      return Scaffold(\n        body: FutureBuilder<List<Map<String, dynamic>>>(\n          future: _future,\n          builder: (context, snapshot) {\n            if (!snapshot.hasData) {\n              return const Center(child: CircularProgressIndicator());\n            }\n            final countries = snapshot.data!;\n            return ListView.builder(\n              itemCount: countries.length,\n              itemBuilder: ((context, index) {\n                final country = countries[index];\n                return ListTile(\n                  title: Text(country['name']),\n                );\n              }),\n            );\n          },\n        ),\n      );\n    }\n  }\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Run your app on a platform of your choosing! By default an app should launch in your web browser.\n\nNote that `supabase_flutter` is compatible with web, iOS, Android, macOS, and Windows apps.\nRunning the app on MacOS requires additional configuration to [set the entitlements](https://docs.flutter.dev/development/platform-integration/macos/building#setting-up-entitlements).\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  flutter run\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "sveltekit.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/quickstarts/sveltekit.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport StepHikeCompact from '~/components/StepHikeCompact'\nexport const meta = {\n  title: 'Use Supabase with SvelteKit',\n  subtitle:\n    'Learn how to create a Supabase project, add some sample data to your database, and query the data from a SvelteKit app.',\n  breadcrumb: 'Framework Quickstarts',\n}\n\n\n\n\n\n```[Create a new project](https://app.supabase.com) in the Supabase Dashboard.\n\nAfter your project is ready, create a table in your Supabase database using the [SQL Editor](https://app.supabase.com/project/_/sql) in the Dashboard. Use the following SQL statement to create a `countries` table with some sample data.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n ```sql SQL_EDITOR\n -- Create the table\n CREATE TABLE countries (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL\n );\n -- Insert some sample data into the table\n INSERT INTO countries (name) VALUES ('United States');\n INSERT INTO countries (name) VALUES ('Canada');\n INSERT INTO countries (name) VALUES ('Mexico');\n ````\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Create a SvelteKit app\">\n\nCreate a SvelteKit app using the `npm create` command.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm create svelte@latest myapp\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a SvelteKit app.\n\nNavigate to the SvelteKit app and install `supabase-js`.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  cd myapp && npm install @supabase/supabase-js\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Create a `/src/lib` directory in your SvelteKit app, create a file called `supabaseClient.js` and add the following code to initialize the Supabase client with your [project URL and public API (anon) key](https://app.supabase.com/project/_/settings/api).\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```js src/lib/supabaseClient.js\n    import { createClient } from '@supabase/supabase-js'\n\n    export const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Use `load` method to fetch the data server-side and display the query results as a simple list.\n\nCreate `+page.server.js` file in the `routes` directory with the following code.\n\n</StepHikeCompact.Details>\n<StepHikeCompact.Code>\n\n\n  ```js src/routes/+page.server.js\n    import { supabase } from \"$lib/supabaseClient\";\n\n    export async function load() {\n      const { data } = await supabase.from(\"countries\").select();\n      return {\n        countries: data ?? [],\n      };\n    }\n  ```\n\n</StepHikeCompact.Code>\n\n<StepHikeCompact.Details title=\"\">\n\nReplace the existing content in your `+page.svelte` file in the `routes` directory with the following code.\n\n</StepHikeCompact.Details>\n<StepHikeCompact.Code>\n\n\n  ```svelte src/routes/+page.svelte\n    <script>\n      export let data;\n      let { countries } = data;\n      $: ({ countries } = data);\n    </script>\n\n    <ul>\n      {#each countries as country}\n        <li>{country.name}</li>\n      {/each}\n    </ul>\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Start the app and go to http://localhost:5173 in a browser and you should see the list of countries.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm run dev\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "nextjs.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/quickstarts/nextjs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport StepHikeCompact from '~/components/StepHikeCompact'\nexport const meta = {\n  title: 'Use Supabase with NextJS',\n  subtitle:\n    'Learn how to create a Supabase project, add some sample data to your database, and query the data from a NextJS app.',\n  breadcrumb: 'Framework Quickstarts',\n}\n\n\n\n\n\n```[Create a new project](https://app.supabase.com) in the Supabase Dashboard.\n\nAfter your project is ready, create a table in your Supabase database using the [SQL Editor](https://app.supabase.com/project/_/sql) in the Dashboard. Use the following SQL statement to create a `countries` table with some sample data.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n ```sql SQL_EDITOR\n  -- Create the table\n  CREATE TABLE countries (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL\n  );\n  -- Insert some sample data into the table\n  INSERT INTO countries (name) VALUES ('United States');\n  INSERT INTO countries (name) VALUES ('Canada');\n  INSERT INTO countries (name) VALUES ('Mexico');\n  ````\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Create a NextJS app\">\n\nCreate a Next.js app using the `create-next-app` command.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npx create-next-app my-app\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```  The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a NextJS app.\n\n  Navigate to the NextJS app and install `supabase-js`.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  cd my-app && npm install @supabase/supabase-js\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```In the `/lib` directory of your Next.js app, create a file called `supabaseClient.js` and add the following code to initialize the Supabase client with your [project URL and public API (anon) key](https://app.supabase.com/project/_/settings/api).\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```js lib/supabaseClient.js\n    import { createClient } from '@supabase/supabase-js'\n\n    export const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Use the `getServerSideProps` method to fetch the data server-side and display the query result as a simple list.\n\nReplace the existing function in your index file in the `pages` directory with the following code.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```js app/index.js\n    import { supabase } from './../lib/supabaseClient';\n\n    function Page({ countries }) {\n      return (\n        <ul>\n          {countries.map((country) => (\n            <li key={country.id}>{country.name}</li>\n          ))}\n        </ul>\n      );\n    }\n\n    export async function getServerSideProps() {\n      let { data } = await supabase.from('countries').select()\n\n      return {\n        props: {\n         countries: data\n        },\n      }\n    }\n\n    export default Page;\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Start the app and go to http://localhost:3000 in a browser and you should see the list of countries.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm run dev\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "nuxtjs.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/quickstarts/nuxtjs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport StepHikeCompact from '~/components/StepHikeCompact'\nexport const meta = {\n  title: 'Install Supabase with Nuxt.js',\n  subtitle: 'Setting up supabase-js client library in a Nuxt.js app.',\n}\nThe fastest way to get started with supabase and Nuxt.js is to use the supabase-js client library, which provides a convenient interface for working with supabase from a Nuxt.js app. To use supabase-js with Nuxt.js, you can follow these steps:\n\n\n\n\n```<StepHikeCompact.Details title=\"Create a Nuxt.js app\">\n\nStart by creating a new Nuxt.js project if you do not have one set up:\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n    npx create-nuxt-app my-project\n    cd my-project\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```To install the `@supabase/supabase-js` package, you will need to run the following command:\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm install @supabase/supabase-js\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```And finally we want to save the environment variables in a .env. All we need are the API URL and the anon key that you copied earlier.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```text .env\n  SUPABASE_URL=\"YOUR_SUPABASE_URL\"\n  SUPABASE_KEY=\"YOUR_SUPABASE_ANON_KEY\"\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Then let's install the only additional dependency: NuxtSupabase. We only need to import NuxtSupabase as a dev dependency:\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm install @nuxtjs/supabase --save-dev\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```To create a table of countries with their timezones, you will first need to create a table in your Supabase database using SQL. You can use the following SQL statement to create a table called countries:\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n ```sql SQL_EDITOR\n  -- this creates the table\n  CREATE TABLE countries (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL\n  );\n  -- insert some sample data into new table\n  INSERT INTO countries (name) VALUES ('United States');\n  INSERT INTO countries (name) VALUES ('Canada');\n  INSERT INTO countries (name) VALUES ('Mexico');\n  ````\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Start the dev server by running the following commands:\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm run dev\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Next, in your Nuxt.js app, create a file called supabase-client.js and add the following code to initialize the Supabase client and set your project's credentials:\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```js lib/supabaseClient.js\n    import { createClient } from '@supabase/supabase-js'\n\n    const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "solidjs.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/quickstarts/solidjs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport StepHikeCompact from '~/components/StepHikeCompact'\nexport const meta = {\n  title: 'Use Supabase with SolidJS',\n  subtitle:\n    'Learn how to create a Supabase project, add some sample data to your database, and query the data from a SolidJS app.',\n  breadcrumb: 'Framework Quickstarts',\n}\n\n\n\n\n\n```[Create a new project](https://app.supabase.com) in the Supabase Dashboard.\n\nAfter your project is ready, create a table in your Supabase database using the [SQL Editor](https://app.supabase.com/project/_/sql) in the Dashboard. Use the following SQL statement to create a `countries` table with some sample data.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```sql SQL_EDITOR\n    -- Create the table\n    CREATE TABLE countries (\n      id SERIAL PRIMARY KEY,\n      name VARCHAR(255) NOT NULL\n    );\n    -- Insert some sample data into the table\n    INSERT INTO countries (name) VALUES ('United States');\n    INSERT INTO countries (name) VALUES ('Canada');\n    INSERT INTO countries (name) VALUES ('Mexico');\n  ````\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Create a SolidJS app\">\n\nCreate a SolidJS app using the `degit` command.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npx degit solidjs/templates/js my-app\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a SolidJS app.\n\nNavigate to the SolidJS app and install `supabase-js`.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  cd my-app && npm install @supabase/supabase-js\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```In `App.jsx`, create a Supabase client using your [Project URL and public API (anon) key](https://app.supabase.com/project/_/settings/api).\n\nAdd a `getCountries` function to fetch the data and display the query result to the page.\n\n</StepHikeCompact.Details>\n<StepHikeCompact.Code>\n\n\n  ```jsx src/App.jsx\n    import { createClient } from \"@supabase/supabase-js\";\n    import { createEffect, createSignal, For } from \"solid-js\";\n\n    const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>');\n\n    function App() {\n      const [countries, setCountries] = createSignal();\n\n      createEffect(() => {\n        getCountries();\n      });\n\n      async function getCountries() {\n        const { data } = await supabase.from(\"countries\").select();\n        setCountries(data);\n      }\n\n      return (\n        <ul>\n          <For each={countries()}>{(country) => <li>{country.name}</li>}</For>\n        </ul>\n      );\n    }\n\n    export default App;\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Start the app and go to http://localhost:3000 in a browser and you should see the list of countries.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm run dev\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "reactjs.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/getting-started/quickstarts/reactjs.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nimport StepHikeCompact from '~/components/StepHikeCompact'\nexport const meta = {\n  title: 'Use Supabase with React',\n  subtitle:\n    'Learn how to create a Supabase project, add some sample data to your database, and query the data from a React app.',\n  breadcrumb: 'Framework Quickstarts',\n}\n\n\n\n\n\n```[Create a new project](https://app.supabase.com) in the Supabase Dashboard.\n\nAfter your project is ready, create a table in your Supabase database using the [SQL Editor](https://app.supabase.com/project/_/sql) in the Dashboard. Use the following SQL statement to create a `countries` table with some sample data.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n ```sql SQL_EDITOR\n  -- Create the table\n  CREATE TABLE countries (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL\n  );\n  -- Insert some sample data into the table\n  INSERT INTO countries (name) VALUES ('United States');\n  INSERT INTO countries (name) VALUES ('Canada');\n  INSERT INTO countries (name) VALUES ('Mexico');\n  ````\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n```<StepHikeCompact.Details title=\"Create a React app\">\n\nCreate a React app using the `create-react-app` command.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npx create-react-app my-app\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```The fastest way to get started is to use the `supabase-js` client library which provides a convenient interface for working with Supabase from a React app.\n\nNavigate to the React app and install `supabase-js`.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  cd my-app && npm install @supabase/supabase-js\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```In `index.js`, create a Supabase client using your [Project URL and public API (anon) key](https://app.supabase.com/project/_/settings/api).\n\nAdd a `getCountries` function to fetch the data and log the query result to the browser console.\n\n</StepHikeCompact.Details>\n<StepHikeCompact.Code>\n\n\n  ```js src/index.js\n    import { createClient } from '@supabase/supabase-js'\n\n    const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')\n\n    async function getCountries() {\n      const countries = await supabase.from('countries').select()\n      console.log(countries)\n    }\n\n    getCountries()\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\n\n\n\n```Start the app, go to http://localhost:3000 in a browser, and open the browser console and you should see the list of countries.\n\n</StepHikeCompact.Details>\n\n<StepHikeCompact.Code>\n\n  ```bash Terminal\n  npm start\n  ```\n\n</StepHikeCompact.Code>\n```\n\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "cicd-workflow.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/cicd-workflow.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'cicd-workflow',\n  title: 'CI / CD Workflow',\n  description: 'How to deploy Supabase Edge Functions with a CI / CD pipeline.',\n  video: 'https://www.youtube.com/v/6OMVWiiycLs',\n}\nAs described in the Supabase CLI Environments Guide, you can use the setup-cli GitHub Action to run Supabase CLI commands in your GitHub Actions, for example to deploy a Supabase Edge Function:\n```yaml\nname: Deploy Function\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n\n```env:\n  SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}\n  PROJECT_ID: zdtdtxajzydjqzuktnqx\n\nsteps:\n  - uses: actions/checkout@v3\n\n  - uses: supabase/setup-cli@v1\n    with:\n      version: 1.0.0\n\n  - run: supabase functions deploy your-function-name --project-ref $PROJECT_ID\n```\n\n\n```\n\n\n\nSee the example on GitHub.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "debugging.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/debugging.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'functions-debugging',\n  title: 'Debugging Edge Functions',\n  description: 'Debug Edge Functions in production.',\n}\nYou can debug your deployed Edge Functions using the \"Functions\" section of the Dashboard. There are two debugging tools available:\n\nInvocations: shows the Request and Response for each execution.\nLogs: shows any platform events, including deployments and errors.\n\n\nWhen developing locally you will see error messages and console log statements printed to your local terminal window.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Import Map Placement",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/import-maps.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'functions-import-maps',\n  title: 'Import Maps',\n  description: 'Using Import Maps.',\n  video: 'https://www.youtube.com/v/ILr3cneZuFk',\n}\n\n\n\nSince Supabase CLI version `1.33.0` import maps can be used with Supabase Edge Functions.\nImport maps is a web-platform standard that allows you to use bare specifiers with Deno without having to install the Node.js package locally.\nSo if we want to do the following in our code:\n`ts, ignore\nimport lodash from \"lodash\";`\nWe can accomplish this using an import map, and we don't even have to install the `lodash` package locally. We would want to create a JSON file (for example import_map.json) with the following:\n`json\n{\n  \"imports\": {\n    \"lodash\": \"https://cdn.skypack.dev/lodash\"\n  }\n}`\nImport Map Placement\nWe recommend creating one `import_map.json` within the `/supabase/functions` folder (see Organizing your Edge Functions), similar to a `package.json` file, to define imports that can be used across all of your project's functions.\nAlternatively, you can create one `import_map.json` file in each function folder, which will take priority over a top-level file.\nLastly, you can override this default behaviour by providing the `--import-map <string>` flag to the `serve` and `deploy` commands.\nVisual Studio Code Configuration\nIn order for vscode to understand the imports correctly, you need to specify the `deno.importMap` flag in your `.vscode/settings.json` file:\n`json settings.json\n{\n  \"deno.enable\": true,\n  \"deno.unstable\": true,\n  \"deno.importMap\": \"./supabase/functions/import_map.json\"\n}`\nFor a full guide on developing with Deno in Visual Studio Code, see this guide.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Auth Context & RLS",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/auth.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'auth',\n  title: 'Auth',\n  description: 'Supabase Edge Functions and Auth.',\n}\nEdge Functions work seamlessly with Supabase Auth, allowing you to identify which user called your function.\nWhen invoking a function with one of the client libraries, the logged in user's JWT is automatically attached to the function call and becomes accessible within your function.\nThis is important, for example, to identify which customer's credit card should be charged. You can see this concept end-to-end in our Stripe example app.\nAuth Context & RLS\nBy creating a supabase client with the auth context from the function, you can do two things:\n\nGet the user object.\nRun queries in the context of the user with Row Level Security (RLS) policies enforced.\n\n```js lines=14,17-19,22-23 title=supabase/functions/select-from-table-with-auth-rls/index.ts\nimport { serve } from 'https://deno.land/std@0.177.0/http/server.ts'\nimport { createClient } from 'https://esm.sh/@supabase/supabase-js@2'\nserve(async (req: Request) => {\n  try {\n    // Create a Supabase client with the Auth context of the logged in user.\n    const supabaseClient = createClient(\n      // Supabase API URL - env var exported by default.\n      Deno.env.get('SUPABASE_URL') ?? '',\n      // Supabase API ANON KEY - env var exported by default.\n      Deno.env.get('SUPABASE_ANON_KEY') ?? '',\n      // Create client with Auth context of the user that called the function.\n      // This way your row-level-security (RLS) policies are applied.\n      { global: { headers: { Authorization: req.headers.get('Authorization')! } } }\n    )\n    // Now we can get the session or user object\n    const {\n      data: { user },\n    } = await supabaseClient.auth.getUser()\n\n\n```// And we can run queries in the context of our authenticated user\nconst { data, error } = await supabaseClient.from('users').select('*')\nif (error) throw error\n\nreturn new Response(JSON.stringify({ user, data }), {\n  headers: { 'Content-Type': 'application/json' },\n  status: 200,\n})\n```\n\n\n} catch (error) {\n    return new Response(JSON.stringify({ error: error.message }), {\n      headers: { 'Content-Type': 'application/json' },\n      status: 400,\n    })\n  }\n})\n```\nSee the example on GitHub.\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "cors.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/cors.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'functions-cors',\n  title: 'CORS (Cross-Origin Resource Sharing)',\n  description: 'Add CORS headers to invoke Edge Functions from the browser.',\n}\nTo invoke edge functions from the browser, you need to handle CORS Preflight requests.\nSee the example on GitHub.\nRecommended setup\nWe recommend adding a `cors.ts` file within a _shared folder which makes it easy to reuse the CORS headers across functions:\n`ts cors.ts\nexport const corsHeaders = {\n  'Access-Control-Allow-Origin': '*',\n  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',\n}`\nYou can then import and use the CORS headers within your functions:\n```ts index.ts\nimport { serve } from 'https://deno.land/std@0.177.0/http/server.ts'\nimport { corsHeaders } from '../_shared/cors.ts'\nconsole.log(`Function \"browser-with-cors\" up and running!`)\nserve(async (req) => {\n  // This is needed if you're planning to invoke your function from a browser.\n  if (req.method === 'OPTIONS') {\n    return new Response('ok', { headers: corsHeaders })\n  }\ntry {\n    const { name } = await req.json()\n    const data = {\n      message: `Hello ${name}!`,\n    }\n\n\n```return new Response(JSON.stringify(data), {\n  headers: { ...corsHeaders, 'Content-Type': 'application/json' },\n  status: 200,\n})\n```\n\n\n} catch (error) {\n    return new Response(JSON.stringify({ error: error.message }), {\n      headers: { ...corsHeaders, 'Content-Type': 'application/json' },\n      status: 400,\n    })\n  }\n})\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "You can also set secrets individually using:",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/secrets.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'functions-secrets',\n  title: 'Secrets and Environment Variables',\n  description: 'Managing secrets and environment variables.',\n}\nIt's common that you will need to use sensitive information or environment-specific variables inside your Edge Functions. You can access these using Deno's built-in handler\n`js\nDeno.env.get(MY_SECRET_NAME)`\nDefault secrets\nBy default, Edge Functions have access to these secrets:\n\n`SUPABASE_URL`: The API gateway for your Supabase project.\n`SUPABASE_ANON_KEY`: The `anon` key for your Supabase API. This is safe to use in a browser when you have Row Level Security enabled.\n`SUPABASE_SERVICE_ROLE_KEY`: The `service_role` key for your Supabase API. This is safe to use in Edge Functions, but it should NEVER be used in a browser. This key will bypass Row Level Security.\n`SUPABASE_DB_URL`: The URL for your PostgreSQL database. You can use this to connect directly to your database.\n\nLocal secrets\nLet's create a local file for storing our secrets, and inside it we can store a secret `MY_NAME`:\n`bash\necho \"MY_NAME=Yoda\" >> ./supabase/.env.local`\nThis creates a new file `./supabase/.env.local` for storing your local development secrets.\n\nNever check your .env files into Git!\n\nNow let's access this environment variable `MY_NAME` inside our Function. Anywhere in your function, add this line:\n`jsx\nconsole.log(Deno.env.get('MY_NAME'))`\nNow we can invoke our function locally, by serving it with our new `.env.local` file:\n`bash\nsupabase functions serve --env-file ./supabase/.env.local`\nWhen the function starts you should see the name \u201cYoda\u201d output to the terminal.\nProduction secrets\nLet's create a `.env` for production. In this case we'll just use the same as our local secrets:\n`bash\ncp ./supabase/.env.local ./supabase/.env`\nThis creates a new file `./supabase/.env` for storing your production secrets.\n\nNever check your `.env` files into Git!\n\nLet's push all the secrets from the `.env` file to our remote project using supabase secrets set:\n```bash\nsupabase secrets set --env-file ./supabase/.env\nYou can also set secrets individually using:\nsupabase secrets set MY_NAME=Chewbacca\n```\nYou don't need to re-deploy after setting your secrets.\nTo see all the secrets which you have set remotely, use supabase secrets list:\n`bash\nsupabase secrets list`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Prerequisites",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/quickstart.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'functions-quickstart',\n  title: 'Edge Functions Quickstart',\n  description: 'Globally distributed TypeScript Functions.',\n  sidebar_label: 'Quickstart',\n  video: 'https://www.youtube.com/v/rzglqRdZUQE',\n}\nLearn how to build an Edge Function locally and deploy it to the Supabase Platform in less than 7 minutes.\n\n\n\nPrerequisites\nFollow the steps to prepare your Supabase project on your local machine.\n\nInstall the Supabase CLI. Docs.\nLogin to the CLI using the command: `supabase login`. Docs.\nInitialize Supabase inside your project using the command: `supabase init`. Docs.\nLink to your Remote Project using the command `supabase link --project-ref your-project-ref`. Docs.\nOptional: Setup your environment: Follow this setup guide to integrate the Deno language server with your editor.\n\nCreate an Edge Function\nLet's create a new Edge Function called `hello-world` inside your project:\n`bash\nsupabase functions new hello-world`\nThis creates a function stub in your `supabase` folder at `./functions/hello-world/index.ts`.\nDeploy to production\n`bash\nsupabase functions deploy hello-world`\nThis command bundles your Edge Function from `./functions/hello-world/index.ts` and deploys it to the Supabase platform.\nThe command outputs a URL to the Supabase Dashboard which you can open to find view more details. Let's open the link to find the execution command.\n\nBy default, Edge Functions require a valid JWT in the authorization header. This header is automatically set when invoking your function via a Supabase client library.\nIf you want to use Edge Functions to handle webhooks (e.g. Stripe payment webhooks etc.), you need to pass the `--no-verify-jwt` flag when deploying your function.\n\nInvoking remote functions\nYou can invoke Edge Functions using curl:\n`bash\ncurl --request POST 'https://<project_ref>.functions.supabase.co/hello-world' \\\n  --header 'Authorization: Bearer ANON_KEY' \\\n  --header 'Content-Type: application/json' \\\n  --data '{ \"name\":\"Functions\" }'`\n\nIf you receive an error `Invalid JWT`, find the `ANON_KEY` of your project in the Dashboard under `Settings > API`.\n\nor using one of the client libraries, e.g. using supabase-js:\n```js\nimport { createClient } from '@supabase/supabase-js'\n// Create a single supabase client for interacting with your database\nconst supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\nconst { data, error } = await supabase.functions.invoke('hello-world', {\n  body: { name: 'Functions' },\n})\n```\nAfter invoking your Edge Function you should see the response `{ \"message\":\"Hello Functions!\" }`.\nDatabase Functions vs Edge Functions\nFor data-intensive operations we recommend using Database Functions, which are executed within your database\nand can be called remotely using the REST and GraphQL API.\nFor use-cases which require low-latency we recommend Edge Functions, which are globally-distributed and can be written in TypeScript.\nOrganizing your Edge Functions\nWe recommend developing \u201cfat functions\u201d. This means that you should develop few large functions, rather than many small functions. One common pattern when developing Functions is that you need to share code between two or more Functions. To do this, you can store any shared code in a folder prefixed with an underscore (`_`). We recommend this folder structure:\n`bash\n\u2514\u2500\u2500 supabase\n    \u251c\u2500\u2500 functions\n    \u2502   \u251c\u2500\u2500 import_map.json # A top-level import map to use across functions.\n    \u2502   \u251c\u2500\u2500 _shared\n    \u2502   \u2502   \u251c\u2500\u2500 supabaseAdmin.ts # Supabase client with SERVICE_ROLE key.\n    \u2502   \u2502   \u2514\u2500\u2500 supabaseClient.ts # Supabase client with ANON key.\n    \u2502   \u2502   \u2514\u2500\u2500 cors.ts # Reusable CORS headers.\n    \u2502   \u251c\u2500\u2500 function-one # Use hyphens to name functions.\n    \u2502   \u2502   \u2514\u2500\u2500 index.ts\n    \u2502   \u2514\u2500\u2500 function-two\n    \u2502       \u2514\u2500\u2500 index.ts\n    \u251c\u2500\u2500 migrations\n    \u2514\u2500\u2500 config.toml`\nNaming Edge Functions\nWe recommend using hyphens to name functions because hyphens are the most URL-friendly of all the naming conventions (snake_case, camelCase, PascalCase).\nUsing HTTP Methods\nEdge Functions supports `GET`, `POST`, `PUT`, `PATCH`, `DELETE`, and `OPTIONS`. A function can be designed to perform different actions based on a request's HTTP method. See the example on building a RESTful service to learn how to handle different HTTP methods in your function.\nLimitations\n\nDeno Deploy limitations\nDeno does not support outgoing connections to ports `25`, `465`, and `587`.\nCannot read or write to File System\nEdge Functions\nLocal development - only one function at a time\nServing of HTML content is not supported (`GET` requests that return `text/html` will be rewritten to `text/plain`).\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Examples",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/schedule-functions.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'schedule-functions',\n  title: 'Schedule Edge Functions',\n  description: 'Schedule Edge Functions with pg_cron.',\n}\n\n\n\nThe hosted Supabase Platform supports the pg_cron extension, a simple cron-based job scheduler for PostgreSQL that runs inside the database.\nIn combination with the pg_net extension, this allows us to invoke Edge Functions periodically on a set schedule.\nExamples\nInvoke an Edge Function every minute\nMake a POST request to a Supabase Edge Function every minute:\n`sql\nselect\n  cron.schedule(\n    'invoke-function-every-minute',\n    '* * * * *', -- every minute\n    $$\n    select\n      net.http_post(\n          url:='https://project-ref.functions.supabase.co/function-name',\n          headers:='{\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer YOUR_ANON_KEY\"}'::jsonb,\n          body:=concat('{\"time\": \"', now(), '\"}')::jsonb\n      ) as request_id;\n    $$\n  );`\nResources\n\npg_net extension\npg_cron extension\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "local-development.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/local-development.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'functions-local-development',\n  title: 'Local Development',\n  description: 'Run your Edge Functions locally.',\n}\nYou can run your Edge Function locally using supabase functions serve:\n`bash\nsupabase start # start the supabase stack\nsupabase functions serve # start the Functions watcher`\nThe `functions serve` command has hot-reloading capabilities. It will watch for any changes to your files and restart the Deno server.\nInvoking Edge Functions locally\nWhile serving your local Edge Function, you can invoke it using curl:\n`bash\ncurl --request POST 'http://localhost:54321/functions/v1/function-name' \\\n  --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24ifQ.625_WdcF3KHqz5amU0x2X5WWHP-OEs_4qj0ssLNHzTs' \\\n  --header 'Content-Type: application/json' \\\n  --data '{ \"name\":\"Functions\" }'`\nor using one of the client libraries, e.g. using supabase-js:\n```js\nimport { createClient } from '@supabase/supabase-js'\n// Use the credentials outputted in your terminal when running `supabase start`\nconst supabase = createClient(\n  'http://localhost:54321',\n  'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0'\n)\nconst { data, error } = await supabase.functions.invoke('function-name', {\n  body: { name: 'Functions' },\n})\n```\nYou should see the response `{ \"message\":\"Hello Functions!\" }`.\nIf you execute the function with a different payload the response will change. \nModify the `--data '{\"name\":\"Functions\"}'` line to `--data '{\"name\":\"World\"}'` and try invoking the command again!\n\n\nEdge Functions don't serve HTML content (`GET` requests that return `text/html` are rewritten to `text/plain`).\nThe `Authorization` header is required. You can use either the `ANON` key, the `SERVICE_ROLE` key, or a logged-in user's JWT.\nThe Function is proxied through the local API (`http://localhost:54321`)\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Create an application on Discord Developer Portal",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/examples/discord-bot.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'examples-discord-bot',\n  title: 'Discord Bot',\n  description: 'Building a Slash Command Discord Bot with Edge Functions.',\n  video: 'https://www.youtube.com/v/J24Bvo_m7DM',\n}\n\n\n\nCreate an application on Discord Developer Portal\n\nGo to https://discord.com/developers/applications (login using your discord account if required).\nClick on New Application button available at left side of your profile picture.\nName your application and click on Create.\nGo to Bot section, click on Add Bot, and finally on Yes, do it! to confirm.\n\nThat's it. A new application is created which will hold our Slash Command. Don't close the tab as we need information from this application page throughout our development.\nBefore we can write some code, we need to curl a discord endpoint to register a Slash Command in our app.\nFill `DISCORD_BOT_TOKEN` with the token available in the Bot section and `CLIENT_ID` with the ID available on the General Information section of the page and run the command on your terminal.\n`bash\nBOT_TOKEN='replace_me_with_bot_token'\nCLIENT_ID='replace_me_with_client_id'\ncurl -X POST \\\n-H 'Content-Type: application/json' \\\n-H \"Authorization: Bot $BOT_TOKEN\" \\\n-d '{\"name\":\"hello\",\"description\":\"Greet a person\",\"options\":[{\"name\":\"name\",\"description\":\"The name of the person\",\"type\":3,\"required\":true}]}' \\\n\"https://discord.com/api/v8/applications/$CLIENT_ID/commands\"`\nThis will register a Slash Command named `hello` that accepts a parameter named `name` of type string.\nCode\n```ts index.ts\n// Sift is a small routing library that abstracts away details like starting a\n// listener on a port, and provides a simple function (serve) that has an API\n// to invoke a function for a specific path.\nimport { json, serve, validateRequest } from 'sift'\n// TweetNaCl is a cryptography library that we use to verify requests\n// from Discord.\nimport nacl from 'nacl'\nenum DiscordCommandType {\n  Ping = 1,\n  ApplicationCommand = 2,\n}\n// For all requests to \"/\" endpoint, we want to invoke home() handler.\nserve({\n  '/discord-bot': home,\n})\n// The main logic of the Discord Slash Command is defined in this function.\nasync function home(request: Request) {\n  // validateRequest() ensures that a request is of POST method and\n  // has the following headers.\n  const { error } = await validateRequest(request, {\n    POST: {\n      headers: ['X-Signature-Ed25519', 'X-Signature-Timestamp'],\n    },\n  })\n  if (error) {\n    return json({ error: error.message }, { status: error.status })\n  }\n// verifySignature() verifies if the request is coming from Discord.\n  // When the request's signature is not valid, we return a 401 and this is\n  // important as Discord sends invalid requests to test our verification.\n  const { valid, body } = await verifySignature(request)\n  if (!valid) {\n    return json(\n      { error: 'Invalid request' },\n      {\n        status: 401,\n      }\n    )\n  }\nconst { type = 0, data = { options: [] } } = JSON.parse(body)\n  // Discord performs Ping interactions to test our application.\n  // Type 1 in a request implies a Ping interaction.\n  if (type === DiscordCommandType.Ping) {\n    return json({\n      type: 1, // Type 1 in a response is a Pong interaction response type.\n    })\n  }\n// Type 2 in a request is an ApplicationCommand interaction.\n  // It implies that a user has issued a command.\n  if (type === DiscordCommandType.ApplicationCommand) {\n    const { value } = data.options.find(\n      (option: { name: string; value: string }) => option.name === 'name'\n    )\n    return json({\n      // Type 4 responds with the below message retaining the user's\n      // input at the top.\n      type: 4,\n      data: {\n        content: `Hello, ${value}!`,\n      },\n    })\n  }\n// We will return a bad request error as a valid Discord request\n  // shouldn't reach here.\n  return json({ error: 'bad request' }, { status: 400 })\n}\n/* Verify whether the request is coming from Discord. /\nasync function verifySignature(request: Request): Promise<{ valid: boolean; body: string }> {\n  const PUBLIC_KEY = Deno.env.get('DISCORD_PUBLIC_KEY')!\n  // Discord sends these headers with every request.\n  const signature = request.headers.get('X-Signature-Ed25519')!\n  const timestamp = request.headers.get('X-Signature-Timestamp')!\n  const body = await request.text()\n  const valid = nacl.sign.detached.verify(\n    new TextEncoder().encode(timestamp + body),\n    hexToUint8Array(signature),\n    hexToUint8Array(PUBLIC_KEY)\n  )\nreturn { valid, body }\n}\n/* Converts a hexadecimal string to Uint8Array. /\nfunction hexToUint8Array(hex: string) {\n  return new Uint8Array(hex.match(/.{1,2}/g)!.map((val) => parseInt(val, 16)))\n}\n```\nDeploy the Slash Command Handler\n`bash\nsupabase functions deploy discord-bot --no-verify-jwt\nsupabase secrets set DISCORD_PUBLIC_KEY=your_public_key`\nNavigate to your Function details in the Supabase Dashboard to get your Endpoint URL.\nConfigure Discord application to use our URL as interactions endpoint URL\n\nGo back to your application (Greeter) page on Discord Developer Portal\nFill INTERACTIONS ENDPOINT URL field with the URL and click on Save Changes.\n\nThe application is now ready. Let's proceed to the next section to install it.\nInstall the Slash Command on your Discord server\nSo to use the `hello` Slash Command, we need to install our Greeter application on our Discord server. Here are the steps:\n\nGo to OAuth2 section of the Discord application page on Discord Developer Portal\nSelect `applications.commands` scope and click on the Copy button below.\nNow paste and visit the URL on your browser. Select your server and click on Authorize.\n\nOpen Discord, type `/Promise` and press Enter.\nRun locally\n`bash\nsupabase functions serve discord-bot --no-verify-jwt --env-file ./supabase/.env.local\nngrok http 54321`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Code",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/examples/og-image.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'examples-og-image',\n  title: 'Generating OG Images',\n  description: 'Generate Open Graph images with Deno and Supabase Edge Functions.',\n  video: 'https://www.youtube.com/v/jZgyOJGWayQ',\n}\n\n\n\nGenerate Open Graph images with Deno and Supabase Edge Functions. View on GitHub.\nCode\nCreate a `handler.tsx` file to construct the OG image in React:\n```tsx handler.tsx\nimport React from 'https://esm.sh/react@18.2.0'\nimport { ImageResponse } from 'https://deno.land/x/og_edge@0.0.4/mod.ts'\nexport default function handler(req: Request) {\n  return new ImageResponse(\n    (\n      \n        Hello OG Image!\n      \n    )\n  )\n}\n```\nCreate an `index.ts` file to execute the handler on incoming requests:\n```ts index.ts\nimport { serve } from 'https://deno.land/std@0.177.0/http/server.ts'\nimport handler from './handler.tsx'\nconsole.log('Hello from og-image Function!')\nserve(handler)\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Run locally",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/examples/openai.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'examples-openai',\n  title: 'OpenAI',\n  description: 'Using OpenAI in Edge Functions.',\n  video: 'https://www.youtube.com/v/29p8kIqyU_Y',\n}\n\n\n\nUse the OpenAI completions API in Supabase Edge Functions.\n```ts index.ts\nimport 'xhr_polyfill'\nimport { serve } from 'std/server'\nimport { CreateCompletionRequest } from 'openai'\nserve(async (req) => {\n  const { query } = await req.json()\nconst completionConfig: CreateCompletionRequest = {\n    model: 'text-davinci-003',\n    prompt: query,\n    max_tokens: 256,\n    temperature: 0,\n    stream: true,\n  }\nreturn fetch('https://api.openai.com/v1/completions', {\n    method: 'POST',\n    headers: {\n      Authorization: `Bearer ${Deno.env.get('OPENAI_API_KEY')}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify(completionConfig),\n  })\n})\n```\nRun locally\n`bash\nsupabase functions serve --env-file ./supabase/.env.local --no-verify-jwt`\nUse cURL or Postman to make a POST request to http://localhost:54321/functions/v1/openai.\n`bash\ncurl -i --location --request POST http://localhost:54321/functions/v1/openai \\\n  --header 'Content-Type: application/json' \\\n  --data '{\"query\":\"What is Supabase?\"}'`\nDeploy\n`bash\nsupabase functions deploy --no-verify-jwt openai\nsupabase secrets set --env-file ./supabase/.env.local`\nGo deeper\nIf you're interesting in learning how to use this to build your own ChatGPT, read the blog post and check out the video:\n\n\n\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Setup",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/examples/cloudflare-turnstile.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'examples-cloudflare-turnstile',\n  title: 'Cloudflare Turnstile',\n  description: 'Protecting Forms with Cloudflare Turnstile.',\n  video: 'https://www.youtube.com/v/OwW0znboh60',\n}\n\n\n\nCloudflare Turnstile is a friendly, free CAPTCHA replacement, and it works seamlessly with Supabase Edge Functions to protect your forms. View on GitHub.\nSetup\n\nFollow these steps to set up a new site: https://developers.cloudflare.com/turnstile/get-started/\nAdd the Cloudflare Turnstile widget to your site: https://developers.cloudflare.com/turnstile/get-started/client-side-rendering/\n\nCode\nCreate a new function in your project:\n`bash\nsupabase functions new cloudflare-turnstile`\nAnd add the code to the `index.ts` file:\n```ts index.ts\nimport { serve } from 'https://deno.land/std@0.177.0/http/server.ts'\nimport { corsHeaders } from '../_shared/cors.ts'\nconsole.log('Hello from Cloudflare Trunstile!')\nfunction ips(req: Request) {\n  return req.headers.get('x-forwarded-for')?.split(/\\s,\\s/)\n}\nserve(async (req) => {\n  // This is needed if you're planning to invoke your function from a browser.\n  if (req.method === 'OPTIONS') {\n    return new Response('ok', { headers: corsHeaders })\n  }\nconst { token } = await req.json()\n  const clientIps = ips(req) || ['']\n  const ip = clientIps[0]\n// Validate the token by calling the\n  // \"/siteverify\" API endpoint.\n  let formData = new FormData()\n  formData.append('secret', Deno.env.get('CLOUDFLARE_SECRET_KEY') ?? '')\n  formData.append('response', token)\n  formData.append('remoteip', ip)\nconst url = 'https://challenges.cloudflare.com/turnstile/v0/siteverify'\n  const result = await fetch(url, {\n    body: formData,\n    method: 'POST',\n  })\nconst outcome = await result.json()\n  console.log(outcome)\n  if (outcome.success) {\n    return new Response('success', { headers: corsHeaders })\n  }\n  return new Response('failure', { headers: corsHeaders })\n})\n```\nDeploy the server-side validation Edge Functions\n\nhttps://developers.cloudflare.com/turnstile/get-started/server-side-validation/\n\n`bash\nsupabase functions deploy cloudflare-turnstile\nsupabase secrets set CLOUDFLARE_TURNSTILE_SECRET_KEY=your_secret_key`\nInvoke the function from your site\n`js\nconst { data, error } = await supabase.functions.invoke('cloudflare-turnstile', {\n  body: { token },\n})`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "Redis database setup",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/examples/upstash-redis.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  title: 'Upstash Redis',\n  description: 'Build an Edge Functions Counter with Upstash Redis.',\n}\nA Redis counter example that stores a hash of function invocation count per region.\nRedis database setup\nCreate a Redis database using the Upstash Console or Upstash CLI.\nSelect the `Global` type to minimize the latency from all edge locations. Copy the `UPSTASH_REDIS_REST_URL` and `UPSTASH_REDIS_REST_TOKEN` to your .env file.\nYou'll find them under Details > REST API > .env.\n`bash\ncp supabase/functions/upstash-redis-counter/.env.example supabase/functions/upstash-redis-counter/.env`\nCode\nMake sure you have the latest version of the Supabase CLI installed.\nCreate a new function in your project:\n`bash\nsupabase functions new upstash-redis-counter`\nAnd add the code to the `index.ts` file:\n```ts index.ts\nimport { serve } from 'https://deno.land/std@0.177.0/http/server.ts'\nimport { Redis } from 'https://deno.land/x/upstash_redis@v1.19.3/mod.ts'\nconsole.log(`Function \"upstash-redis-counter\" up and running!`)\nserve(async (_req) => {\n  try {\n    const redis = new Redis({\n      url: Deno.env.get('UPSTASH_REDIS_REST_URL')!,\n      token: Deno.env.get('UPSTASH_REDIS_REST_TOKEN')!,\n    })\n\n\n```const deno_region = Deno.env.get('DENO_REGION')\nif (deno_region) {\n  // Increment region counter\n  await redis.hincrby('supa-edge-counter', deno_region, 1)\n} else {\n  // Increment localhost counter\n  await redis.hincrby('supa-edge-counter', 'localhost', 1)\n}\n\n// Get all values\nconst counterHash: Record<string, number> | null = await redis.hgetall('supa-edge-counter')\nconst counters = Object.entries(counterHash!)\n  .sort(([, a], [, b]) => b - a) // sort desc\n  .reduce((r, [k, v]) => ({ total: r.total + v, regions: { ...r.regions, [k]: v } }), {\n    total: 0,\n    regions: {},\n  })\n\nreturn new Response(JSON.stringify({ counters }), { status: 200 })\n```\n\n\n} catch (error) {\n    return new Response(JSON.stringify({ error: error.message }), { status: 200 })\n  }\n})\n```\nRun locally\n`bash\nsupabase start\nsupabase functions serve --no-verify-jwt --env-file supabase/functions/upstash-redis-counter/.env`\nNavigate to http://localhost:54321/functions/v1/upstash-redis-counter.\nDeploy\n`bash\nsupabase functions deploy upstash-redis-counter --no-verify-jwt\nsupabase secrets set --env-file supabase/functions/upstash-redis-counter/.env`\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "github-actions.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/examples/github-actions.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'examples-github-actions',\n  title: 'GitHub Actions',\n  description: 'Deploying Edge Functions with GitHub Actions.',\n  video: 'https://www.youtube.com/v/l2KlzGrhB6w',\n}\n\n\n\nUse the Supabase CLI together with GitHub Actions to automatically deploy our Supabase Edge Functions. View on GitHub.\n```yaml deploy.yaml\nname: Deploy Function\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n\n```env:\n  SUPABASE_ACCESS_TOKEN: YOUR_SUPABASE_ACCESS_TOKEN\n  PROJECT_ID: YOUR_SUPABASE_PROJECT_ID\n\nsteps:\n  - uses: actions/checkout@v3\n\n  - uses: supabase/setup-cli@v1\n    with:\n      version: 1.0.0\n\n  - run: supabase functions deploy github-action-deploy --project-ref $PROJECT_ID\n```\n\n\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  },
  {
    "title": "connect-to-postgres.mdx",
    "source": "https://github.com/supabase/supabase/tree/master/apps/docs/pages/guides/functions/examples/connect-to-postgres.mdx",
    "content": "import Layout from '~/layouts/DefaultGuideLayout'\nexport const meta = {\n  id: 'examples-postgres-on-the-edge',\n  title: 'Connect to Postgres',\n  description: 'Connecting to Postgres from Edge Functions.',\n  video: 'https://www.youtube.com/v/cl7EuF1-RsY',\n}\n\n\n\nSupabase Edge Functions allow you to go beyond HTTP and can connect to your Postgres Database directly!\n```ts index.ts\nimport * as postgres from 'https://deno.land/x/postgres@v0.14.2/mod.ts'\nimport { serve } from 'https://deno.land/std@0.177.0/http/server.ts'\n// Get the connection string from the environment variable \"DATABASE_URL\"\nconst databaseUrl = Deno.env.get('DATABASE_URL')!\n// Create a database pool with three connections that are lazily established\nconst pool = new postgres.Pool(databaseUrl, 3, true)\nserve(async (_req) => {\n  try {\n    // Grab a connection from the pool\n    const connection = await pool.connect()\n\n\n```try {\n  // Run a query\n  const result = await connection.queryObject`SELECT * FROM animals`\n  const animals = result.rows // [{ id: 1, name: \"Lion\" }, ...]\n  console.log(animals)\n\n  // Encode the result as pretty printed JSON\n  const body = JSON.stringify(\n    animals,\n    (key, value) => (typeof value === 'bigint' ? value.toString() : value),\n    2\n  )\n\n  // Return the response with the correct content type header\n  return new Response(body, {\n    status: 200,\n    headers: {\n      'Content-Type': 'application/json; charset=utf-8',\n    },\n  })\n} finally {\n  // Release the connection back into the pool\n  connection.release()\n}\n```\n\n\n} catch (err) {\n    console.error(err)\n    return new Response(String(err?.message ?? err), { status: 500 })\n  }\n})\n```\nexport const Page = ({ children }) => ",
    "tag": "supabase"
  }
]